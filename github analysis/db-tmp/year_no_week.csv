"","id","url","username","repo","path","content","year"
"1",119,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_21/tidytuesday_2019_05_21.R","jmmnyc","tidytuesday","2019_05_21/tidytuesday_2019_05_21.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(janitor)
library(gridExtra)

coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")

# Set custom ggplot theme
my_font <- ""Segoe UI Black""

base_color <- ""#f5f3dc""

font_color <- ""#42ac96"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 7, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 10))

theme_set(theme_light() + my_theme)



# Clean names
coast_vs_waste <- clean_names(coast_vs_waste)

# Let's find out the years included
# Seems we have over 200 countries from around mid 1950's until 2013

coast_vs_waste %>% 
  group_by(year) %>% 
  tally() %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col()

coast_vs_waste %>% 
  group_by(year) %>% 
  tally() %>% 
  tail()

# Let's take a look at the data on mismanged waste
# Looks like we only have data for 2010

coast_vs_waste %>% 
  filter(!is.na(mismanaged_plastic_waste_tonnes)) %>% 
  group_by(entity, year) %>% 
  summarise(mismanaged_plastic_waste_tonnes) %>% 
  View()

# Let's filter to focus 2010 and create a measure for % of population that is coastal

plot_data <- coast_vs_waste %>% 
  filter(year == 2010) %>% 
  mutate(coastal_pop_pct = coastal_population/total_population_gapminder) 


# I would expect to see population size and waste are positively correlated

waste_pop <- plot_data %>% 
  #filter(entity == ""Dominican Republic"") %>% 
  ggplot(aes(x = log(total_population_gapminder), y = log(mismanaged_plastic_waste_tonnes))) +
  geom_point(aes(col = entity), size = 2, alpha = .7) +
  geom_smooth(method = ""lm"") +
  theme(legend.position = ""none"") +
  labs(title = ""Countries with larger populations produce more plastic waste (2010)"",
       x = ""Total population (log scale)"",
       y = ""Mismanaged plastic waste in tonnes (log scale)"",
       caption = """") 


# Maybe countires with larger coastal populations behave differently

waste_coast_pop <- plot_data %>% 
  #filter(entity == ""Dominican Republic"") %>% 
  ggplot(aes(x = coastal_pop_pct, y = log(mismanaged_plastic_waste_tonnes))) +
  geom_point(aes(col = entity), size = 2, alpha = .7) +
  geom_vline(xintercept = 1) +
  geom_text(aes(x = 1, y = 15, 
                label = ""Some data points might have errors \n    with coastal pop greater total"",
                hjust = -0.1),
                size = 3) +
  geom_smooth(method = ""lm"") +
  theme(legend.position = ""none"") +
  labs(title = ""Lower waste produced in countries with higher % of coastal population"",
       x = ""Coastal population as % of total"",
       y = """",
       caption = ""Source: Our World in Data \nVisualization by Jose M @Joseph_Mike"") 


combined_plots <- arrangeGrob(waste_pop, waste_coast_pop, ncol = 2)


ggsave(""TidyTuesday_2019_05_21.png"", combined_plots, width = 12, height = 4, device = ""png"", type = ""cairo"")
  ","2019"
"2",120,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_07/tidytuesday_2019_05_07.R","jmmnyc","tidytuesday","2019_05_07/tidytuesday_2019_05_07.R","
library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

# Set custom theme
my_font <- ""Lucida Sans""

base_color <- ""#f5f3dc""

font_color <- ""#42ac96"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 14))

theme_set(theme_light() + my_theme)

# Subset data
plot_data <- student_ratio %>% 
  filter(str_detect(country, "".countries""),
         indicator %in% c(""Primary Education"", ""Secondary Education"", ""Tertiary Education""),
         year == ""2017"") %>% 
  select(country, year, indicator, student_ratio)

# Viz
plot_data %>% 
  ggplot(aes(student_ratio, reorder(country, -student_ratio), fill = indicator)) +
  geom_point(shape = 21, size = 4, alpha = .6) +
  labs(title = ""Less teachers per students in lower income countries in 2017"",
       subtitle = ""the difference is greater in primary schools (elementary)"",
       x = ""Student:Teacher ratio (# of students per teacher)"",
       y = """",
       caption = ""Source: UNESCO Institute of Statistics \nVisualization by Jose M @Joseph_Mike"",
       fill = """") +
  theme(legend.position = ""top"") +
  scale_fill_manual(values = c(""#984EA3"", ""#FF7F00"")) #, ""#4DAF4A""))""#984EA3""


ggsave(""TidyTuesday_2019_05_07.png"", device = ""png"", type = ""cairo"")","2019"
"3",121,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_05/tidytuesday_2019_03_05.R","jmmnyc","tidytuesday","2019_03_05/tidytuesday_2019_03_05.R","#load packages
library(tidyverse)
library(ggthemes)
library(scales)

jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")

jobs_gender$minor_category <- as.factor(jobs_gender$minor_category)

plot_data <- jobs_gender %>% 
  filter(year == 2016) %>%
  group_by(minor_category) %>% 
  summarise(pct_female_workers = sum(workers_female, na.rm = TRUE)/sum(total_workers, na.rm = TRUE),
            pct_female_wages = sum(total_earnings_female, na.rm = TRUE)/sum(total_earnings_male, na.rm = TRUE)) %>% 
  ungroup() 
  
plot_data %>%   
  ggplot(aes(x = reorder(minor_category, pct_female_wages), y = pct_female_wages)) +
  geom_col() +
  geom_hline(yintercept = 1, linetype = ""dashed"", col = ""red"") +
  theme_economist_white() +
  labs(title = ""Female wages as a % of Male wages by Industry"",
       subtitle = ""100% = pay parity"",
       x = """",
       y = ""Percent"") +
  coord_flip() +
  theme(axis.text.y = element_blank()) +
  geom_text(aes(x = reorder(minor_category, pct_female_wages), y = .35, label = minor_category), size = 4, col = ""white"") +
  scale_y_continuous(labels = percent_format(accuracy = 1))
","2019"
"4",122,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_09/tidytuesday_2019_04_09.R","jmmnyc","tidytuesday","2019_04_09/tidytuesday_2019_04_09.R","library(tidyverse)
library(ggthemes)
library(RColorBrewer)

player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

#set custom theme
my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8),
                  axis.title.x = element_text(margin = margin(15,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,15,0,0)),
                  axis.title = element_text(margin = margin (0,0,15,0))
)

theme_set(theme_light() + my_theme)



age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>% # needs to be datetime
  group_by(name, age, gender) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins)) %>% 
  ungroup() %>% 
  mutate(age = as.numeric(age/365)) 

over_10_wins <- age_slams_comb %>% 
  group_by(name, gender) %>% 
  select(name, total_wins) %>% 
  summarise(max_total_wins = max(total_wins)) %>%
  filter(max_total_wins >= 10) %>% 
  ungroup() %>% 
  group_by(gender) %>% 
  mutate(rank = dense_rank(max_total_wins)) %>% 
  ungroup()

brewer.pal(n=5, name = ""Set1"")

color_map <- data.frame(rank = c(1:5), 
                        color = c(""#E41A1c"", ""#377EB8"", ""#4DAF4A"", ""#984EA3"", ""#FF7F00""))


age_slams_rank <- left_join(age_slams_comb, over_10_wins, by = c(""name"")) 

plot_data <- age_slams_rank %>% 
  mutate(
    line_col = case_when(
      rank == ""1"" ~ ""1"", 
      rank == ""2"" ~ ""2"", 
      rank == ""3"" ~ ""3"", 
      rank == ""4"" ~ ""4"", 
      rank == ""5"" ~ ""5"",
      T ~ ""other"")
  ) 



ggplot(data = plot_data, aes(age, total_wins, group = name, col = line_col)) +
  geom_step(alpha = 0.6) +
  geom_point(data = plot_data %>% 
               group_by(name) %>% 
               filter(total_wins == max(total_wins)), 
             aes(col = line_col), size = 1.5, alpha = 0.6) +
  facet_wrap(~gender.x, nrow = 2) +
  geom_text(data = plot_data %>% 
              group_by(name) %>% 
              filter(age == max(age)) %>% 
              ungroup(),
            aes(x = age, y = total_wins,label=ifelse(total_wins > 10,name,'')),hjust= -0.1,vjust= -0.3, size = 3) +
  labs(title = ""Grand Slam victories by age"",
       x = ""Age"",
       y = ""Grand Slams won"",
       caption = ""\nData sourced from Wikipedia \nPlot by: Jose M. @Joseph_Mike"") +
  scale_x_continuous(limits = c(15,40)) +
  scale_color_manual(values = c(""#FF7F00"", ""#984EA3"", ""#4DAF4A"", ""#377EB8"", ""#E41A1c"", ""#7f7f7f"")) +
  theme(strip.text.x = element_text(size = 14, color = ""black"")) +
  theme(legend.position = ""none"") 
","2019"
"5",123,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_30/tidytuesday_2019_04_30.R","jmmnyc","tidytuesday","2019_04_30/tidytuesday_2019_04_30.R","library(tidyverse)
library(lubridate)
library(ggthemes)
library(extrafont)

bird_col <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

loadfonts(device = ""win"")

my_font <- ""Century Gothic""
base_color <- ""#f5f3dc""
font_color <- ""#42ac96"" # or #213549
my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0)))

theme_set(theme_light() + my_theme)

plot_data <- bird_col %>% 
  mutate(year = year(date)) %>% 
  group_by(year, habitat) %>% 
  summarise(collisions = n()) %>% 
  ungroup()

View(plot_data)

plot <- plot_data %>% 
  ggplot(aes(year, collisions, group = habitat, col = habitat)) +
  geom_line(size = 1) +
  theme(legend.position = ""top"") +
  labs(title = ""Annual trends of reported bird window collisions in Chicago (1978-2016)"",
       x = ""Year"",
       y = ""Reported collisions"",
       colour = ""Habitat"",
       caption = ""Source:  Winger et al https://doi.org/10.1098/rspb.2019.0364 \nVisiualization by Jose M @Joseph_Mike"") +
  scale_color_manual(values = c(""#FF7F00"", ""#984EA3"", ""#4DAF4A""))

ggsave(""TidyTuesday_2019_04_30.png"", dpi = ""retina"", height = 5, width = 8, units = ""in"")
","2019"
"6",124,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_07_30/tidytuesday_2019_07_30.R","jmmnyc","tidytuesday","2019_07_30/tidytuesday_2019_07_30.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(ggsci)
library(lubridate)

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

# Set custom ggplot theme
my_font <- ""Baskerville Old Face""

base_color <- ""#1E1F22""

font_color <- ""#CfC5AA"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 10, color = ""#6173A5""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.x = element_text(size = 12, color = '#99886F'),
                  axis.text.y = element_text(size = 12, color = '#99886F'),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_light() + my_theme)


# Top 10 Video Game publishers by number of titles
top_publishers <- video_games %>% 
  filter(!is.na(publisher),!is.na(price), !is.na(metascore),!is.na(average_playtime)) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE) %>% 
  filter(n >= 30)

# Filter for top 10 publishers
plot_data <- inner_join(video_games, top_publishers, by = ""publisher"") 


plot_data %>% 
  ggplot(aes(metascore, price)) +
  geom_point(aes(color = publisher, alpha = .8), size = 2) +
  scale_x_continuous(breaks = seq(50,100,10), limits = c(45,105)) +
  scale_color_simpsons() +
  theme(legend.position = ""none"") +
  facet_wrap(~publisher, nrow = 2) +
  theme(panel.grid.minor.x = element_blank(),
        strip.text.x = element_text(size = 8, color = ""#f7f5f5""),
        strip.background.x = element_rect(fill = ""#000000"")) +
  labs (title = ""Metascores and Average Playtimes across top Video Game Publishers"",
      subtitle = ""Top game publishers by number of titles"",
      x = ""Metascore"",
      y = ""Price"",
      caption = ""Data from Liza Wood via Steam Spy\nVisualization by Jose M @Joseph_Mike"")

data_by_year <- video_games %>% 
  filter(!is.na(publisher),!is.na(price), !is.na(metascore),!is.na(average_playtime))

metascore_avg <- data_by_year %>% 
  summarise(avg = mean(metascore, na.rm = TRUE)) %>% 
  pull(avg)

arrows <- tibble(
  x_start = c(2004,2007),
  x_end = c(2004.8,2008.5),
  y_start = c(43.5,36.5),
  y_end = c(78,72)
)


data_by_year %>% 
  mutate(year = year(mdy(release_date))) %>%
  group_by(year) %>% 
  mutate(yearly_avg = mean(metascore)) %>% 
  ungroup() %>% 
  ggplot(aes(year, metascore)) +
  geom_hline(yintercept = metascore_avg, color = ""#f3f3f3"", size = 2) +
  geom_jitter(color = '#84A6E1', alpha = .5, size = 1) +
  geom_point(aes(year, yearly_avg), shape = 21, fill = '#84A6E1', size = 6) +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank()) +
  scale_x_continuous(breaks = seq(2004,2018,1), limits = c(2003,2019)) +
  theme(legend.position = ""none"") +
  annotate(""text"", x = 2004, y = 42.5, size = 4, color = ""#f3f3f3"",
           label = paste0(""Yearly average"")) + 
  annotate(""text"", x = 2008, y = 35, size = 4, color = ""#f3f3f3"",
           label = paste0(""Overall metascore average"")) + 
  geom_curve(data = arrows, aes(x = x_start, y = y_start, xend= x_end, yend = y_end),
             arrow = arrow(length = unit(0.08, ""inch"")), size = 0.8,
             color = ""#CFC5AA"", curvature = -0.3) +
  labs (title = ""Video Game Metascore trends from 2004-2018"",
        subtitle = ""Excludes free to play games"",
        x = ""Year"",
        y = ""Metascore"",
        caption = ""Data from Liza Wood via Steam Spy\nVisualization by Jose M @Joseph_Mike"")


ggsave(""TidyTuesday_2019_07_30.png"", width = 8, height = 5,device = ""png"", type = ""cairo"")
  
  
","2019"
"7",125,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_19/tidytuesday_2019_03_19.R","jmmnyc","tidytuesday","2019_03_19/tidytuesday_2019_03_19.R","library(tidyverse)
library(ggthemes)
library(scales)

combined_data <- readr::read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")

View(combined_data)

my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8))

theme_set(theme_light() + my_theme)

rates_by_states <- combined_data %>% 
  filter(!is.na(location) & state != ""RI"") %>%
  select(location, state, driver_race, stop_rate, stops_per_year) %>% 
  group_by(state) %>% 
  mutate(total_state_stops = sum(stops_per_year)) %>% 
  ungroup() %>% 
  mutate(weight = stops_per_year/total_state_stops,
         weighted_stop_rate = weight * stop_rate) %>% 
  select(location, state, driver_race, weighted_stop_rate) %>% 
  spread(driver_race, weighted_stop_rate) %>% 
  group_by(state) %>% 
  summarise(Minority_stop_rate = sum(Black, na.rm = TRUE) + sum(Hispanic, na.rm = TRUE),
            White_stop_rate = sum(White, na.rm = TRUE))
  


plot <- rates_by_states %>% 
  ggplot(aes(x = Minority_stop_rate, y = White_stop_rate, label = state)) + 
  geom_point(color = ""#bc5652"",alpha = .3, size = 8) +
  geom_text(aes(label = state)) +
  geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +
  labs(title = ""Search rate of traffic stops by State"",
       subtitle = ""Points on the line represent parity across driver race"",
       caption = ""Plot: @Joseph_Mike \nData: Stanford Open Policing Project"") +
  scale_x_continuous('White search rate', limits=c(0, .35), labels = percent_format(accuracy = 1), expand=c(0,0)) + 
  scale_y_continuous('Minority search rate', limits=c(0, .35), labels = percent_format(accuracy = 1), expand=c(0,0)) +
  theme(legend.position = ""none"") +
  theme(axis.title.x = element_text(margin = margin(15,0,0,0)),
        axis.title.y = element_text(margin = margin(0,15,0,0)),
        axis.title = element_text(margin = margin (0,0,15,0)))

plot
","2019"
"8",126,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_04/tidytuesday_2019_06_04.R","jmmnyc","tidytuesday","2019_06_04/tidytuesday_2019_06_04.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(ggridges)
library(Cairo)
library(ggsci)

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

# Set custom ggplot theme
my_font <- ""Tempus Sans ITC""

base_color <- ""#ffffff""

font_color <- ""#b85f29"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#293042""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.y = element_text(size = 12),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_light() + my_theme)

# find countries with over 100 ramen dishes rated
top_countries <- ramen_ratings %>% 
  group_by(country) %>% 
  tally(sort = TRUE) %>% 
  filter(n >= 100, 
         !is.na(country)) %>% 
  ungroup()

# filter data for the top 11 countires
plot_data <- inner_join(ramen_ratings, top_countries, by = ""country"") %>% select(-n)

# import image of Naruto eating ramen
img <- png::readPNG(""ramen.png"")

rast <- grid::rasterGrob(img, interpolate = T)

#create plot
plot_data %>% 
  ggplot(aes(stars, reorder(country, stars, median))) +
  annotation_custom(rast, ymin = 1, ymax = 6, xmin = 5.5) +
  geom_density_ridges(scale = 2,
                      aes(fill = country),
                      color = ""#e58f1e"",
                      size = 1,
                      alpha = 0.7) + 
  theme(legend.position = ""none"") +
  scale_fill_igv() +
  scale_x_continuous(breaks = seq(0,6,1), limits = c(1,6)) +
  coord_cartesian(clip = ""off"") +
  theme(panel.grid.minor.x = element_blank()) +
  labs(title = ""Ramen rating distribution by country"",
       subtitle = ""Countries with over 100 ramen dishes reviewed"",
       x = ""Rating"",
       y = ""Country"",
       caption = ""Data from The Ramen Rater \nVisualization by Jose M @Joseph_Mike"") 

ggsave(""TidyTuesday_2019_06_04.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")
","2019"
"9",127,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_25/tidytuesday_2019_06_25.R","jmmnyc","tidytuesday","2019_06_25/tidytuesday_2019_06_25.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(lubridate)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

# Set custom ggplot theme
my_font <- ""Agency FB"" 

base_color <- ""#1E132C""

font_color <- ""#70cd3e"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
                  panel.border = element_blank(),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 10, color = ""#da7792""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.y = element_text(color = ""#f7f5f5"", size = 10),
                  axis.text.x = element_text(color = ""#f7f5f5"", size = 10),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_dark() + my_theme)




plot_data <- ufo_sightings %>% 
  mutate(date_time = parse_date_time(date_time, 'mdy_HM'),
         month = as.factor(month(date_time, label = TRUE)),
         year = year(date_time)) %>% 
  filter(year > 1980,
         year < 2009) %>% 
  mutate(decade = year - year%%10) %>% 
  group_by(decade, month) %>% 
  summarise(count = n()) %>% 
  ungroup() 

plot_data %>% 
  ggplot(aes(month, count)) +
  geom_col(fill = ""#eaa27c"")  +
  facet_wrap(~decade) +
  theme(panel.grid.major.x = element_blank(),
        strip.text.x = element_text(size = 14, color = ""#f7f5f5""),
        strip.background.x = element_rect(fill = ""#eaa27c"")) +
  labs(title = ""Monthly distribution of UFO sightings in last 3 decades"",
        x = ""Month"",
        y = ""UFOs sighted"",
        caption = ""Data from NUFORC\nVisualization by Jose M @Joseph_Mike"")

ggsave(""TidyTuesday_2019_06_25.png"", width = 10, height = 6,device = ""png"", type = ""cairo"")



  ","2019"
"10",128,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_28/tidytuesday_2019_05_28.R","jmmnyc","tidytuesday","2019_05_28/tidytuesday_2019_05_28.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(ggsci)


set.seed(123)

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

# Set custom ggplot theme
my_font <- ""Segoe UI Black""

base_color <- ""#f5f3dc""

font_color <- ""#331C20"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#331C20""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 10))

theme_set(theme_light() + my_theme)


# Remove duplicates
wr2 <- wine_ratings %>% 
  select(-X1) %>% 
  distinct()

# filter out NAs for country, price, and points
# select only necessary columns and view top countries
wr2 %>% 
  filter(!is.na(country),
         !is.na(price),
         !is.na(points)) %>% 
  select(country, price, points) %>% 
  group_by(country) %>% 
  tally(sort = TRUE)


# apply filters from above with additional filter on top 5 countries
# create a column for mean price for each country
# reorder countries
plot_data <- wr2 %>% 
  filter(!is.na(country),
         !is.na(price),
         !is.na(points),
         country %in% c(""US"",""France"",""Italy"",""Spain"",""Portugal"")) %>% 
  mutate(country = ifelse(country == ""US"", ""United States"", country)) %>%
  group_by(country) %>% 
  mutate(cntr_mean_price = mean(price),
         cntr_mean_points = mean(points)) %>% 
  ungroup() %>% 
  mutate(country = fct_reorder(country, cntr_mean_points))

world_avg <- wr2 %>% 
  summarise(avg = mean(points, na.rm = TRUE)) %>% 
  pull(avg)

arrows <- tibble(
  x_start = c(5.0,2.4,1.5,1.5),
  x_end = c(4.8,2,0.9,1.1),
  y_start = c(93,84,83,83),
  y_end = c(88.44,88,85,86)
)

  
plot_data %>%   
  ggplot(aes(country, points, color = country)) +
  geom_segment(aes(x = country, xend = country,
                   y = world_avg, yend = cntr_mean_points),
               size = 0.5) +
  geom_point(aes(country, cntr_mean_points), size = 4) +
  geom_jitter(size = 0.5, alpha = 0.05) +
  geom_hline(yintercept = world_avg, color = ""#2D2D2D"", size = 0.5) +
  coord_flip() +
  scale_y_continuous(limits = c(80,100), expand = c(0.005,0.005)) +
  theme(panel.grid.major.y = element_blank()) +
  scale_color_futurama() +
  theme(legend.position = ""none"") +
  annotate(""text"", x = 5.3, y = 93, size = 4, color = ""#2D2D2D"",
           label = glue::glue(""Average points rating of\n{round(world_avg,1)} across all countries"")) +
  annotate(""text"", x = 2.3, y = 84, size = 4, color = ""#2D2D2D"",
           label = paste0(""Country average"")) + 
  annotate(""text"", x = 1.6, y = 82, size = 4, color = ""#2D2D2D"",
           label = paste0(""Wines\nper country"")) + 
  geom_curve(data = arrows, aes(x = x_start, y = y_start, xend= x_end, yend = y_end),
             arrow = arrow(length = unit(0.08, ""inch"")), size = 0.5,
             color = ""#2D2D2D"", curvature = -0.3) +
  labs(title = ""Distribution of ratings for top 5 sampled countries"",
       x = """",
       y = ""Points rating (only 80 and above were scored)"",
       caption = ""Source: Kaggle \nVisualization by Jose M @Joseph_Mike"")
  
ggsave(""TidyTuesday_2019_05_28.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")

","2019"
"11",129,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_18/tidytuesday_2019_06_18.R","jmmnyc","tidytuesday","2019_06_18/tidytuesday_2019_06_18.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(ggsci)

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

# Set custom ggplot theme
my_font <- ""Segoe UI Black""

base_color <- ""#ffffff""

font_color <- ""#b85f29"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#293042""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.y = element_text(size = 12),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_light() + my_theme)

# Collect top 10 birds by total count
top_birds <- bird_counts %>%
  filter(year >= 2007) %>% 
  select(year, species, how_many_counted) %>% 
  group_by(species) %>% 
  summarize(count = sum(how_many_counted, na.rm = TRUE)) %>% 
  arrange(-count) %>% 
  ungroup() %>% 
  filter(count > quantile(count, .95))
  
# filter for top 10 birds
plot_data <- inner_join(filter(bird_counts, year >= 2007), top_birds, by = ""species"") %>% 
  select(-count) %>% 
  group_by(year) %>% 
  arrange(year, desc(how_many_counted)) %>% 
  mutate(rank = row_number())


plot_data %>% 
  ggplot(aes(year, rank, group = species)) +
  geom_line(aes(color = species, alpha = .9), size = 2) +
  geom_point(aes(color = species, alpha = .9), fill = ""white"", shape = 21, size = 3, stroke = 2) +
  scale_y_reverse(breaks = 1:10) +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_blank()) +
  scale_x_continuous(breaks = seq(2007,2017,1), limits = c(2007,2020)) +
  scale_color_simpsons() +
  theme(legend.position = ""none"") +
  geom_text(data = filter(plot_data, year == 2017), 
            aes(x = 2017.2, label = species, color = species), 
            size = 4, hjust = ""left"", fontface = ""bold"") +
  labs (title = ""Top 10 in the last 10"",
        subtitle = ""Species of birds counted during Christmas in Canada in the last decade"",
        x = ""Year"",
        y = ""Rank"",
        caption = ""Data from Bird Studies Canada @BirdsCanada\nVisualization by Jose M @Joseph_Mike"")

ggsave(""TidyTuesday_2019_06_18.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")
","2019"
"12",130,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_14/tidytuesday_2019_05_14.R","jmmnyc","tidytuesday","2019_05_14/tidytuesday_2019_05_14.R","
library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(lubridate)
library(ggbeeswarm)

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

my_font <- ""Lucida Sans""

base_color <- ""#f5f3dc""

font_color <- ""#42ac96"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 14))

theme_set(theme_light() + my_theme)

plot_data <- nobel_winners %>% 
  mutate(age = prize_year - year(birth_date)) 

plot_data %>% 
  ggplot(aes(x = category, y = age, col = gender)) +
  geom_beeswarm(alpha = 0.7, size = .8) +
  coord_flip() +
  labs(title = ""Nobel prizes by Age and Gender"",
       x = ""Category"",
       y = ""Age"",
       caption = ""Source: Kaggle \nVisualization by Jose M @Joseph_Mike"",
       colour = """") +
  theme(legend.position = ""top"") +
  scale_color_manual(values = c(""#70283D"", ""#E2525B"")) 

ggsave(""TidyTuesday_2019_05_14.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")



  ","2019"
"13",131,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_16/tidytuesday_2019_04_16.R","jmmnyc","tidytuesday","2019_04_16/tidytuesday_2019_04_16.R","library(tidyverse)
library(scales)
library(ggthemes)

women_research <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")





women_research %>% 
  ggplot(aes(x = reorder(country, -percent_women), y = percent_women, group = field, fill = field)) +
  geom_point(size = 3, shape = 21, alpha = .6) +
  theme_economist() +
  geom_hline(yintercept = .5, linetype = ""dashed"", col = ""red"") +
  scale_y_continuous(labels = percent_format(accuracy = 1), limits = c(0,0.65)) +
  labs(title = ""Still a man's world..."",
       subtitle = ""Women among researchers with papers published 2011-2015"",
       y = ""% of Research papers published by Women"",
       x = ""Country"",
       caption = ""\nSource:  'Gender in the Global Research Landscape' by Elsevier; The Economist \nPlot by Jose M. @Joseph_Mike"") +
  theme(legend.position = ""top"",
        legend.title = element_blank(),
        legend.text = element_text(size = 8)) +
  scale_fill_discrete(labels = c(""computer science, math"", ""engineering"", ""health sciences"", ""physical sciences"", ""inventors"")) +
  coord_flip()
  

","2019"
"14",132,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_02/Tidytuesday_2019_04_02.R","jmmnyc","tidytuesday","2019_04_02/Tidytuesday_2019_04_02.R","library(tidyverse)
library(ggthemes)
library(lubridate)

bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

#custom theme
my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8),
                  axis.title.x = element_text(margin = margin(15,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,15,0,0)),
                  axis.title = element_text(margin = margin (0,0,15,0))
)

theme_set(theme_light() + my_theme)



View(bike_traffic)


plot_data <- bike_traffic %>% 
  mutate(date_time = mdy_hms(date),
         date_only = date(date_time),
         year = year(date_time),
         weekday = wday(date_time, label = TRUE),
         weekday_ind = ifelse(weekday %in% c(""Sat"", ""Sun""), ""Weekend"", ""Weekdays""),
         hour = hour(date_time),
         bikes = sum(bike_count, na.rm = TRUE)) %>% 
  filter(year == '2018') %>% 
  group_by(crossing, weekday_ind, hour) %>% 
  summarise(total_bikes = sum(bike_count, na.rm = TRUE))

plot <- plot_data %>% 
  ggplot(aes(x = hour, y = total_bikes/1000)) +
  geom_line(color = ""#bc5652"", size = 1) +
  facet_grid(rows = vars(crossing),
             cols = vars(weekday_ind),
             scales = ""free_y"",
             labeller = labeller(crossing = label_wrap_gen(24))) +
  theme(strip.text.x = element_text(angle = 0, hjust = 0, size = 10)) +
  theme(strip.text.y = element_text(angle = 0, hjust = 0, size = 10)) +
  scale_y_continuous(labels = scales::number_format(accuracy = 1)) +
  labs(title = ""Hourly trends of Seatle bike usage"",
       subtitle = ""2018"",
       y = ""Bike usage (in thousands)"",
       x = ""Time of day"",
       caption = ""Plot: @Joseph_Mike \nData: Seattle Department of Transportation"")
  

plot


","2019"
"15",133,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_02_26/tidytuesday_2019_02_26.R","jmmnyc","tidytuesday","2019_02_26/tidytuesday_2019_02_26.R","#load packages
library(tidyverse)
library(ggthemes)
library(scales)

#get data
full_trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

#create combined date field in order to chart monthly trends across years
full_trains$date <- as.Date(with(full_trains, paste(year, month, ""1"", sep = ""-"")), format = ""%Y-%m-%d"")

#transform the data to get % of trips that are late and count distinct stations
monthly_trips <- full_trains %>%
  group_by(date) %>% 
  summarise(monthly_pct_late = sum(num_late_at_departure) / sum(total_num_trips),
            stations = n_distinct(departure_station)) %>% 
  ungroup()

#plot
plot <- ggplot(monthly_trips, aes(x = date, y = monthly_pct_late)) +
  geom_line(col = ""white"", size = 1) +
  theme_dark() +
  labs(title = ""How has the % of delayed departures changed in 2018?"",
       x = """",
       y = ""% of trains delayed on departure"") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_x_date(limits = as.Date(c('2015-01-01', '2019-02-01')))

plot
","2019"
"16",134,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_12/tidytuesday_2019_03_12.R","jmmnyc","tidytuesday","2019_03_12/tidytuesday_2019_03_12.R","library(tidyverse)
library(ggthemes)

board_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")


#set parameters
number_of_players <- 4
average_play_time <- 15
top_n_games <- 15

#filter the data
test_group <- board_games %>% 
  filter(min_players >= number_of_players & number_of_players <= max_players) %>% 
  filter(playing_time <= average_play_time) %>% 
  arrange(-average_rating) %>% 
  filter(users_rated >= 100) %>% #filter to games with over 100 user ratings
  head(n = top_n_games)

#create a custom theme
my_font <- ""Avenir""
base_color <- ""#faf7ec""
font_color <- ""#399694""  # or ""#213549"" ""#42ac96"" 
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8))

theme_set(theme_light() + my_theme)

#plot
ggplot(test_group, aes(x = reorder(name, average_rating), y = average_rating)) +
  geom_col(fill = ""#c79966"") +
  coord_flip() +
  theme(legend.position = ""none"") +
  labs(title = ""Highest rated games \nfor 4-players and avg. play time <= 15 minutes"",
       x = """",
       y = ""Avg. Rating"",
       caption = ""Plot by: @Joseph_Mike\n Data:  Board Game Geek"") +
  scale_y_continuous(breaks = c(0,2,4,6,8,10), limits = c(0,10))","2019"
"17",135,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_26/tidytuesday_2019_03_26.R","jmmnyc","tidytuesday","2019_03_26/tidytuesday_2019_03_26.R","library(tidyverse)
library(lubridate)
library(ggthemes)

#read data
seattle_pets <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")

#custom theme
my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8),
                  axis.title.x = element_text(margin = margin(15,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,15,0,0)),
                  axis.title = element_text(margin = margin (0,0,15,0))
                  )

theme_set(theme_light() + my_theme)

#structure of data
str(seattle_pets)

#have a look at the data
head(seattle_pets)

#transform data that will be used for the plot
seattle_pets$date <- floor_date(mdy(seattle_pets$license_issue_date), ""month"")

plot_data <- seattle_pets %>% 
  filter(species %in% c(""Cat"", ""Dog""), !is.na(animals_name), !is.na(zip_code), date >= '2015-01-01') %>% 
  group_by(species, date) %>% 
  summarise(pet_count = n()) 

ggplot(plot_data, aes(x = date, y = pet_count, col = species)) +
  geom_line() +
  labs(title = ""Monthly pet registration trends in Seattle"",
       x = """",
       y = ""Number of pets registered"",
       caption = ""Plot: @Joseph_Mike \nData: Seattle's Open Data Portal"") +
  theme(legend.position = ""top"", legend.title = element_blank())
  
","2019"
"18",136,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_11/tidytuesday_2019_06_11.R","jmmnyc","tidytuesday","2019_06_11/tidytuesday_2019_06_11.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(cowplot)


meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

# find the year with the most meotorites
meteorites %>% 
  group_by(year) %>%
  tally(sort = T)

# filter for 2003
plot_data <- meteorites %>% filter(year == 2003)

# plot colors
plot_base <- ""#272238""

land_mass <- ""#8dc6d1""

land_border <- ""#388089""

meteor_points <- ""#ef601f""

# font and font color
my_font <- ""Agency FB"" 

font_color <- ""#f1e1b0"" 

# Initial plot
world_view <- plot_data %>% 
  ggplot() +
  borders(""world"", col = land_border, fill = land_mass, size = .1) +
  theme_map() +
  theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
        plot.caption = element_text(size = 12),
        plot.subtitle = element_text(size = 16),
        plot.title = element_text(margin = margin(0,0,20,0), size = 22)) +
  coord_map(projection = ""mollweide"", orientation = c(90, 0, 0)) +
  geom_point(aes(x = long, y = lat, size = log(mass)), 
             size = 2, 
             alpha = .15,  
             fill = meteor_points,
             shape = 21) +
  labs(title = ""Where did most meteorites fall in 2003?"",
       subtitle = ""The year with the highest meteorite count"",
       caption = ""Data from NASA \nVisualization by Jose M @Joseph_Mike"")

ggdraw(world_view) +
  theme(
    plot.background = element_rect(fill = plot_base),
    panel.background = element_rect(fill = plot_base, color = plot_base),
    plot.margin = unit(c(.2, .2, .2, .2), ""cm"")
  ) 

ggsave(""TidyTuesday_2019_06_11.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")","2019"
"19",137,"https://github.com/bvreede/tidytuesdays/blob/master/20190813_emperors/emperors.R","bvreede","tidytuesdays","20190813_emperors/emperors.R","library(readr)
library(dplyr)
library(magrittr)
library(stringr)
library(lubridate)
library(ggplot2)
library(RColorBrewer)

emperors <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

BCEtransform <- function(date,BCE){
  # transform a positive BCE date to a negative
  # only when BCE is TRUE
  # NB: the year 0000 does not exist; this was the year 1 BCE
  # but the data has taken this into account already
  # and emperors born in BCE have an adjusted year (eg born in 63BCE is 62 in the data)
  if(BCE){
  yr = as.numeric(format(date, ""%Y""))
  date = date - years(2*yr)
  }
  return(date)
}

emperors %<>% mutate(bce_birth = ifelse(!is.na(notes),
                                        # if BCE is mentioned, birth years are BCE
                                        ifelse(str_detect(notes,""BCE""),T,F),
                                        F),
                     birth_corrected = as_date( # weirdly, the date object is not returned as a date
                       mapply(BCEtransform,birth,bce_birth)),
                     # same for reign
                     bce_reign = ifelse(!is.na(notes),
                                        # if ""reign.start are BCE"" is mentioned, reign start is BCE (one guy but still)
                                        ifelse(str_detect(notes,""reign.start are BCE""),T,F),
                                        F),
                     reign_start_corrected = as_date(
                       mapply(BCEtransform,reign_start,bce_reign))
                     )

# express years in age/duration
emperors %<>% mutate(
  ## age at start reign
  age_reign_start = as.numeric(reign_start_corrected-birth_corrected)/365.25,
  ## age at end reign
  age_reign_end = as.numeric(reign_end-birth_corrected)/365.25,
  ## age at death
  age_death = as.numeric(death-birth_corrected)/365.25,
  # reign duration
  reign_duration = as.numeric(reign_end-reign_start_corrected)/365.25
)

# change levels to highest death count first
cause_level <- count(emperors,cause,sort=T)
emperors$cause <- factor(emperors$cause, levels = rev(cause_level$cause))

# adjust esthetics of plot
theme_set(theme_light(base_size = 12, base_family = ""Courier""))
cscale_killer <- c(brewer.pal(8,""Spectral""),brewer.pal(5,""BuPu"")[2:5],brewer.pal(4,""PiYG""))
cscale_rise <- cscale_killer[c(1,3,4,7,8,10,12,13)]


# make plots
emperors %>%
  ggplot(aes(x = cause, y = age_death)) +
  geom_jitter(aes(size = reign_duration, color=killer), width=0.2) +
  scale_colour_manual(values=cscale_killer) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Death to Roman Emperors"",
       y = ""Age at death (years)"",
       x = ""Cause of death"",
       size = ""Duration of reign"",
       color = ""Killed by"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 


emperors %>%
  ggplot(aes(x = cause, y = age_death)) +
  geom_jitter(aes(size = reign_duration, color=rise), width=0.2) +
  scale_colour_manual(values=cscale_rise) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Rise and fall of Roman Emperors"",
       y = ""Age at death (years)"",
       x = ""Cause of death"",
       size = ""Duration of reign"",
       color = ""Rise to power"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 


emperors %>%
  ggplot(aes(x = cause, y = reign_duration)) +
  geom_jitter(aes(size = age_death, color=rise), width=0.2, alpha=0.7) +
  scale_colour_manual(values=cscale_rise) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Rise and fall of Roman Emperors"",
       size = ""Age at death (years)"",
       x = ""Cause of death"",
       y = ""Duration of reign"",
       color = ""Rise to power"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 

# change levels to highest rise to power-count first
rise_level <- count(emperors,rise,sort=T)
emperors$rise <- factor(emperors$rise, levels = rev(rise_level$rise))

emperors %>%
  ggplot(aes(x = rise, y = reign_duration)) +
  geom_jitter(aes(size = age_death, color=cause), width=0.2, alpha=0.7) +
  scale_colour_manual(values=cscale_rise) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Rise and fall of Roman Emperors"",
       size = ""Age at death (years)"",
       color = ""Cause of death"",
       y = ""Duration of reign"",
       x = ""Rise to power"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 
","2019"
"20",178,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-02_media-franchises","jmcastagnetto","tidytuesday-kludges","2019-07-02_media-franchises/01-get-data-process-and-plot.R","library(tidyverse)

# get the data
media_franchises <- read_csv(
  ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"",
  col_types = ""ccdiccc""
)

# store it locally
save(
  media_franchises,
  file = here::here(""2019-07-02_media-franchises/data/media_franchises.Rdata"")
)

# prepare it for plotting
df <- media_franchises %>%
  mutate(
    decade = as.factor((year_created %/% 10) * 10)
  ) %>%
  group_by(decade, revenue_category) %>%
  summarise(
    total_revenue = sum(revenue)
  ) %>%
  ungroup() %>%
  group_by(decade) %>%
  mutate(
    pct_revenue = total_revenue / sum(total_revenue)
  ) %>%
  ungroup() %>%
  select(-total_revenue)

# simple comparison plot
ggplot(df, aes(x = decade, y = pct_revenue, fill = revenue_category)) +
  geom_col() +
  scale_fill_viridis_d(name = ""Revenue\nCategory"", option = ""inferno"") +
  scale_y_continuous(labels = scales::percent) +
  scale_x_discrete(limits = rev(levels(df$decade))) +
  labs(
    x = """",
    y = """",
    title = ""Share of revenue per category over the decades"",
    subtitle = ""#tidytuesday: 'Media Franchises' (2019-07-02)"",
    caption = ""Jesus Castagnetto (@jmcastagnetto), 2019""
  ) +
  #theme_minimal() +
  ggthemes::theme_clean() +
  theme(
    legend.position = ""bottom"",
    legend.text = element_text(size = 7),
    legend.title = element_text(size = 7),
    legend.background = element_blank(),
    plot.background = element_blank(),
    plot.caption = element_text(face = ""italic"",
                                size = 8,
                                color = ""grey30""
                          )
  ) +
  guides (
     fill = guide_legend(nrow = 3, byrow = TRUE)
  ) +
  coord_flip()

# save the plot
ggsave(
  here::here(
    ""2019-07-02_media-franchises"",
    ""20190702-tidytuesday-media-franchises-category-decades.png""
  )
)


","2019"
"21",179,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-02_media-franchises","jmcastagnetto","tidytuesday-kludges","2019-07-02_media-franchises/02-radar.R","library(tidyverse)
library(gganimate)
library(ggiraph)
library(ggiraphExtra)

load(here::here(""2019-07-02_media-franchises/data/media_franchises.Rdata""))

df <- media_franchises %>%
  mutate(
    Decade = as.factor((year_created %/% 10) * 10)
  ) %>%
  group_by(Decade, revenue_category) %>%
  summarise(
    total_revenue = sum(revenue)
  ) %>%
  ungroup() %>%
  group_by(Decade) %>%
  mutate(
    pct_revenue = total_revenue / sum(total_revenue)
  ) %>%
  select(-total_revenue) %>%
  pivot_wider(
    id_cols = Decade,
    names_from = revenue_category,
    values_from = pct_revenue,
    values_fill = list(pct_revenue = 0)
  )

radar_chart <- ggRadar(data = df,
       mapping = aes(
         color = Decade),
       interactive = FALSE, horizontal = TRUE,
       size = 1) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent) +
  theme(
    axis.text.x = element_text(size = 10),
    legend.position = ""none""
  ) +
  labs(
    title = ""Change in revenue distribution for media franchises"",
    subtitle = ""Decade: {closest_state}"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  transition_states(Decade) +
  ease_aes(""linear"")

radar_chart

anim_save(
  filename  = here::here(""2019-07-02_media-franchises/radar-chart.gif""),
  animation = radar_chart
)
","2019"
"22",180,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/01-get-data.R","# library(tidyverse)

# bird_impacts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/bird_impacts.csv"") %>%
#   mutate(
#     phase_of_flt = str_to_lower(phase_of_flt),
#     damage = replace_na(damage, ""U"") # unknown
#   )
#
# save(
#   bird_impacts,
#   file = here::here(""2019-07-23_bird-impacts/data/bird_impacts.Rdata"")
# )

# data dictionary
download.file(
  ""https://wildlife.faa.gov/downloads/fieldlist.xls"",
  destfile = here::here(""2019-07-23_bird-impacts/data/fieldlist.xls"")
)

# original data in MS Access Format
download.file(
  ""https://wildlife.faa.gov/downloads/wildlife.zip"",
  destfile = here::here(""2019-07-23_bird-impacts/data/wildlife.zip"")
)

# see README.md for command line processing of the database","2019"
"23",181,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/02-process-data.R","library(readr)
library(janitor)
library(dplyr)

bird_strikes <- read_csv(
  here::here(""2019-07-23_bird-impacts/data/strike_reports-1990_current.csv.gz"")
) %>%
  clean_names() %>%
  select(incident_date:faaregion,
         opid, operator, atype, ac_class, ac_mass,
         num_engs, type_eng,
         height, speed, phase_of_flt,
         damage, effect,
         species, birds_seen, birds_struck, size,
         sky, precip,
         cost_repairs_infl_adj,
         nr_injuries, nr_fatalities) %>%
  mutate(
    state = replace_na(state, ""UNK""),
    damage = replace_na(damage, ""U""),
    phase_of_flt = str_to_sentence(phase_of_flt),
    size = na_if(size, ""#N/A"") %>%
      replace_na(., ""Unknown"") %>%
      str_to_title(.),
    time_of_day = replace_na(time_of_day, ""Unknown"") %>%
      str_to_title(.),
    species = replace_na(species, ""Unknown"") %>% str_to_title(.),
    birds_struck = replace_na(birds_struck, ""Unknown""),
    operator_type = case_when(
      opid == ""MIL"" ~ ""Military"",
      opid == ""GOV"" ~ ""Government"",
      opid == ""BUS"" ~ ""Business"",
      opid == ""PVT"" ~ ""Private"",
      TRUE ~ ""Commercial""
    )
  )

save(
  bird_strikes,
  file = here::here(""2019-07-23_bird-impacts/data/bird_strikes.Rdata"")
)
","2019"
"24",182,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/03-plot-heatmap-and-movie.R","library(tidyverse)
library(rayshader)

load(
  here::here(""2019-07-23_bird-impacts/data/bird_strikes.Rdata"")
)

tmp_df <- bird_strikes %>%
  mutate(
    op_type_binary = ifelse(operator_type == ""Commercial"",
                            operator_type,
                            ""Non commercial""),
    size = forcats::fct_infreq(size, ordered = TRUE),
    operator_type = forcats::fct_infreq(operator_type,
                                        ordered = TRUE),
  )

p1 <- ggplot(tmp_df , aes(x = incident_date, y = operator_type)) +
  geom_bin2d() +
  theme_minimal() +
  labs(
    title = ""Distribution of wildlife strikes 1990-2019"",
    subtitle = ""Source: FAA Wildlife Strike database, #Tidytuesday, 2019-07-23"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)"",
    x = ""Incident date"",
    y = ""Aircraft operator type"",
    fill = ""Impacts""
  ) +
  scale_fill_viridis_c(option = ""plasma"", direction = -1) +
  facet_grid(time_of_day~size)

ggsave(
  plot = p1,
  filename  = here::here(""2019-07-23_bird-impacts/wildlife-strikes-heatmap.png""),
  width = 12, height = 8, units = ""in""
)

options(
  cores = 3
)

plot_gg(p1,
        multicore=TRUE,
        width=5,
        height=5,
        scale=250)

render_movie(
  filename = here::here(""2019-07-23_bird-impacts/wildlife-strikes-heatmap.mp4"")
)
","2019"
"25",183,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/04-plot-usmap-yearly-heatmap.R","library(maps)
library(tidyverse)
library(rayshader)

us_states <- map_data(""state"")

load(
  here::here(""2019-07-23_bird-impacts/data/bird_strikes.Rdata"")
)

states_df <- data.frame(
  abb = state.abb,
  name = state.name
)

bystate_yr_df <- bird_strikes %>%
  group_by(incident_year, state) %>%
  summarise(
    impacts = n()
  ) %>%
  left_join(
    states_df,
    by = c(""state"" = ""abb"")
  ) %>%
  left_join(
    us_states %>%
      mutate(region = str_to_title(region)) %>%
      select(-subregion),
    by = c(""name"" = ""region"")
  ) %>%
  filter(
    !is.na(group)
  ) # removes Canada, Puerto Rico, Virgin Islands, and non-contiguous


p2 <- ggplot(data = bystate_yr_df) +
  geom_polygon(aes(x = long, y = lat,
                   fill = impacts, group = group),
               color = ""white"") +
  coord_fixed(1.3) +
  scale_fill_viridis_c(option = ""plasma"", direction = -1) +
  labs(
    title = ""Yearly wildlife strikes frequency in the contiguous USA"",
    subtitle = ""Source: FAA Wildlife Strike database, #Tidytuesday, 2019-07-23"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  theme_void() +
  theme(
    legend.position = ""bottom"",
    plot.margin = unit(c(1,1,1,1), ""cm"")
  ) +
  facet_wrap(~incident_year, ncol = 6)

ggsave(
  plot = p2,
  filename  = here::here(""2019-07-23_bird-impacts/wildlife-strikes-usamap.png""),
  width = 12, height = 8, units = ""in""
)

options(
  cores = 3
)

plot_gg(p2,
        multicore=TRUE,
        width=5,
        height=5,
        scale=250)

render_movie(
  filename = here::here(""2019-07-23_bird-impacts/wildlife-strikes-usamap.mp4""),
  phi = 70
)
","2019"
"26",184,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/01-get-data.R","library(tidyverse)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

predecessor <- function(idx, df) {
  emp_df <- df  %>% filter(index == idx)
  pred_df <- df %>%
    filter(index < idx) %>%
    arrange(desc(index)) %>%
    mutate(
      diff_days = int_length(
        interval(reign_end, emp_df$reign_start)
      ) / (3600 * 24)
    ) %>%
    filter(diff_days >= -1) %>%
    filter(diff_days == min(diff_days)) %>%
    select(-diff_days)
  pred_df$index
}

df <- emperors %>%
  mutate(
    prev_reign_end = lag(reign_end),
    interv_days = int_length(
                    interval(prev_reign_end, reign_start)
                  ) / (3600 * 24),
    prev_emperor = sapply(index, predecessor, .) %>%
      str_replace(""c\\("", """") %>%
      str_replace(""\\)"", """"),
    prev_emperor = ifelse(index == 1, NA, prev_emperor)
  ) %>%
  separate_rows(
    prev_emperor
  ) %>%
  select(
    index,
    name,
    rise,
    reign_start,
    reign_end,
    cause,
    killer,
    dynasty,
    era,
    interv_days,
    prev_emperor
  )

save(
  df,
  emperors,
  file = here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
)


# how many have interr_days >= -1
sum(df$interv_days >= -1, na.rm = TRUE)

# what % is that?
sum(df$interv_days >= -1, na.rm = TRUE) / nrow(df)
","2019"
"27",185,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/02-igraph-viz.R","library(tidyverse)
library(igraph)

load(
  here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
)

# Using igraph

links_df <- df %>%
  filter(index > 1) %>%
  mutate(
    link_label = paste0(""("", cause, "", "", rise, "")"")
  ) %>%
  rename(
    from = prev_emperor,
    to = index
  ) %>%
  select(
    from,
    to,
    link_label
  )

nodes_df <- emperors %>%
  mutate(
    node_label = paste0(""Name: "", name,
                        ""\nDynasty: "", dynasty,
                        ""\nEra: "", era),
    shape = ifelse(
      era == ""Principate"",
      ""square"",
      ""circle""
    )
  ) %>%
  select(
    index,
    name,
    node_label,
    shape,
    cause,
    era,
    dynasty
  )

g <- graph_from_data_frame(links_df,
                           vertices = nodes_df,
                           directed = TRUE)


set.seed(1453)
graph_attr(g, ""layout"") <- layout_with_graphopt
plot(
  g,
  vertex.label = V(g)$name,
  vertex.label.cex = 1,
  vertex.label.dist = 1,
  vertex.size = 5,
  vertex.label.color = ""black"",
  vertex.shape = V(g)$shape,
  vertex.color = NA,
  vertex.frame.color = as.factor(V(g)$cause),
  edge.arrow.size = 0.05,
  edge.curved = 0.3,
  main = ""A network of Roman emperors (#TidyTuesday, 2019-08-13)"",
  sub = ""@jmcastagnetto / Jesus M. Castagnetto""
)

set.seed(1453)
clp <- cluster_infomap(g)
graph_attr(g, ""layout"") <- layout_with_graphopt
plot(
  clp,
  g,
  vertex.label = V(g)$name,
  vertex.label.cex = 1,
  vertex.label.dist = 1,
  vertex.size = 5,
  vertex.label.color = ""black"",
  vertex.shape = V(g)$shape,
  vertex.color = NA,
  vertex.frame.color = as.factor(V(g)$cause),
  edge.arrow.size = 0.05,
  edge.curved = 0.3,
  main = ""A network of Roman emperors (#TidyTuesday, 2019-08-13)"",
  sub = ""@jmcastagnetto / Jesus M. Castagnetto""
)
","2019"
"28",186,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/03-ggraph-viz.R","library(tidyverse)
library(igraph)
library(ggraph)

load(
  here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
)

links_df <- df %>%
  filter(index > 1) %>%
  mutate(
    link_label = paste0(""("", cause, "", "", rise, "")"")
  ) %>%
  rename(
    from = prev_emperor,
    to = index
  ) %>%
  select(
    from,
    to,
    link_label
  )

nodes_df <- emperors %>%
  mutate(
    node_label = paste0(""Name: "", name,
                        ""\nDynasty: "", dynasty,
                        ""\nEra: "", era),
    shape = ifelse(
      era == ""Principate"",
      ""square"",
      ""circle""
    )
  ) %>%
  select(
    index,
    name,
    node_label,
    shape,
    cause,
    era,
    dynasty
  )

g <- graph_from_data_frame(links_df,
                           vertices = nodes_df,
                           directed = TRUE)


# Using ggraph
set.seed(1453)
ggraph(g, layout = ""graphopt"") +
  geom_edge_link2(
    arrow = grid::arrow(ends = ""last"",
                        type = ""open"",
                        length = unit(.8, ""cm""))) +
  geom_node_label(aes(label = name,
                      color = as.factor(dynasty))) +
  labs(
    title = ""A network of roman emperors"",
    subtitle = ""#TidyTuesday, dataset from 2019-08-13"",
    caption = ""@jmcastagnetto / Jesus M. Castagnetto"",
    color = ""Dynasty""
  ) +
  theme_void() +
  theme(

    plot.margin = unit(rep(.5, 4), ""cm""),
  )

","2019"
"29",187,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/04-visnetwork-viz.R","  library(tidyverse)
  library(visNetwork)

  load(
    here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
  )

  # Using visNetwork
  links_df <- df %>%
    mutate(
      cause_prev_emperor = lag(cause, 1),
      label = paste(""by"", cause_prev_emperor)
    ) %>%
    filter(index > 1) %>%
    rename(
      from = prev_emperor,
      to = index
    ) %>%
    select(
      from,
      to,
      label
    ) %>%
    mutate(
      font.color = ""red"",
      font.size = 10,
      arrows = ""to""
    )

  nodes_df <- emperors %>%
    mutate(
      label = name,
      group = dynasty,
      title = paste0(""Name: "", name,
                     ""<br/>Dynasty: "", dynasty,
                     ""<br/>Era: "", era,
                     ""<br/>Rise by: "", rise,
                     ""<br/>End by: "",cause),
      shape = ifelse(
        era == ""Principate"",
        ""square"",
        ""triangle""
      )
    ) %>%
    rename(
      id = index
    ) %>%
    select(
      id,
      label,
      title,
      shape,
      group,
      dynasty
    ) %>%
    mutate(
      value = 2
    )

vn <- visNetwork(nodes_df, links_df,
                   main = ""A Network of Roman Emperors"",
                   submain = ""#TidyTuesday, using the 2019-08-13 dataset"",
                   footer = ""@jmcastagnetto (Jesus M. Castagnetto)"",
                   width = 800,
                   height = 600) %>%
    visGroups() %>%
    visOptions(
      highlightNearest = list(
        enabled = TRUE,
        degree = 1,
        hover = TRUE),
      selectedBy = ""dynasty""
    ) %>%
    visInteraction(
      navigationButtons = TRUE
    ) %>%
    visLayout(
      randomSeed = 1453
    )


htmlwidgets::saveWidget(
    vn,
    file = here::here(""2019-08-13_roman-emperors/visnetwork-interactive.html""))

","2019"
"30",188,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-06-25_ufo-sightings","jmcastagnetto","tidytuesday-kludges","2019-06-25_ufo-sightings/01-getdata.R","library(tidyverse)
library(lubridate)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

ufo_sightings <- ufo_sightings %>%
  mutate(
    date_time = mdy_hm(date_time)
  )

save(ufo_sightings, file = here::here(""2019-06-25_ufo-sightings/data/ufo_sightings.Rdata""))
","2019"
"31",189,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-06-25_ufo-sightings","jmcastagnetto","tidytuesday-kludges","2019-06-25_ufo-sightings/02-tmap-animation.R","library(tidyverse)
library(lubridate)
library(tmap)
library(tmaptools)
library(countrycode)

load(here::here(""2019-06-25_ufo-sightings/data/ufo_sightings.Rdata""))

data(""World"")

ufo <- World %>%
  inner_join(
    ufo_sightings %>%
      mutate(
        iso3 = countrycode(country, ""iso2c"", ""iso3c"")
      ) %>%
      group_by(year(date_time), iso3) %>%
      summarise(
        n = n()
      ) %>%
      rename(
        yr = 1
      ),
    by = c(""iso_a3"" = ""iso3"")
  ) %>%
  arrange(
    yr, iso_a3
  )

yrs <- unique(ufo$yr)
countries <- World %>%
  filter(iso_a3 %in% ufo$iso_a3)

breaks <- seq(0, 7000, by = 1000)

mk_tmap_anim <- function(basemap, df, breaks, years) {
  df <- subset(df, yr %in% years)
  fname <- paste0(""animation_"", min(years), ""-"", max(years), "".gif"")
  map1 <- tm_shape(basemap) +
    tm_polygons(NA) +
    tm_shape(df) +
    tm_polygons(""n"", breaks = breaks, title = ""Number of sightings"") +
    tm_facets(along = ""yr"", free.coords = FALSE, free.scales = FALSE)
  tmap_animation(map1,
                 filename = here::here(""2019-06-25_ufo-sightings/"", fname))
}

mk_tmap_anim(countries, ufo, breaks, yrs[1:20])
mk_tmap_anim(countries, ufo, breaks, yrs[21:40])
mk_tmap_anim(countries, ufo, breaks, yrs[41:60])
mk_tmap_anim(countries, ufo, breaks, yrs[61:83])

# small multiples (static) from 2011-2014 (for twitter)
multmap <- tm_shape(countries) +
  tm_polygons(NA) +
  tm_shape(ufo %>% filter(yr %in% yrs[80:83])) +  # 2011-2014
  tm_polygons(""n"", breaks = breaks, title = ""Number of sightings"") +
  tm_facets(by = ""yr"", free.coords = FALSE, free.scales = FALSE, ncol = 2) +
  tm_layout(legend.position = c(""right"", ""bottom""))

tmap_save(multmap,
          filename = here::here(""2019-06-25_ufo-sightings/tmap-facets-ufo-sightings.png""),
          width = 1200, height = 600)

","2019"
"32",190,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-06_bob-ross-paintings","jmcastagnetto","tidytuesday-kludges","2019-08-06_bob-ross-paintings/01-word-cloud.R","library(fivethirtyeight)
library(tidyverse)
library(ggwordcloud)

data(""bob_ross"")

bob_ross <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer) %>%
  select(-episode_num)

# modified from http://www.sthda.com/english/wiki/word-cloud-generator-in-r-one-killer-function-to-do-everything-you-need
mk_text_df <- function(txt, lang = ""en"") {
  library(tm)
  library(SnowballC)

  # Load the text as a corpus
  docs <- Corpus(VectorSource(txt))
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove stopwords for the language
  docs <- tm_map(docs, removeWords, stopwords(lang))
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  # stemming
  docs <- tm_map(docs, stemDocument)
  tdm <- TermDocumentMatrix(docs)
  m <- as.matrix(tdm)
  v <- sort(rowSums(m),decreasing=TRUE)
  df <- tibble(word = names(v),freq=v)
  return(df)
}

set.seed(19421129) # Bob Ross's birth date

br_titles_df <- mk_text_df(paste(bob_ross$title, collapse = "" "")) %>%
  mutate(
    angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))
  )

wp <- ggplot(br_titles_df, aes(label = word, size = freq,
                         color = freq, angle = angle)) +
  geom_text_wordcloud_area(rm_outside = TRUE, shape = ""square"") +
  scale_size_area(max_size = 24) +
  scale_color_viridis_c(option = ""cividis"", direction = -1) +
  labs(
    title = ""Bob Ross loved mountainscapes and winter"",
    subtitle = ""#tidytuesday, 2019-08-06"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  theme_minimal()

ggsave(
  filename = here::here(""2019-08-06_bob-ross-paintings/wordcloud.png""),
  plot = wp,
  width = 12,
  height = 12,
  units = ""cm""
)
","2019"
"33",191,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-06_bob-ross-paintings","jmcastagnetto","tidytuesday-kludges","2019-08-06_bob-ross-paintings/02-elements-by-season.R","library(fivethirtyeight)
library(tidyverse)

data(""bob_ross"")

bob_ross <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer) %>%
  select(-episode_num)

br_elements <- bob_ross %>%
  select(-episode, -title, -season) %>%
  pivot_longer(
    cols = apple_frame:wood_framed,
    names_to = ""element"",
    values_to = ""freq""
  ) %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  ungroup(element) %>%
  mutate(
    element = ifelse(freq < 5, ""** Other"", element)
  ) %>%
  filter(element != ""** Other"") %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  arrange(
    element
  )

valid_elements <- br_elements$element

br_elements_season <- bob_ross %>%
  select(-episode, -title) %>%
  group_by(season) %>%
  mutate_at(
    vars(-group_cols()),
    sum
  ) %>%
  distinct() %>%
  pivot_longer(
    cols = c(-1),
    names_to = ""element"",
    values_to = ""freq""
  ) %>%
  mutate(
    element = ifelse(element %in% valid_elements,
                     element, ""** Other"") %>%
      str_replace_all(""_"", "" "") %>%
      str_to_title() %>%
      forcats::fct_rev()
  )

hm <- ggplot(br_elements_season,
             aes(x = as.factor(season), y = element)) +
  geom_tile(aes(fill = freq)) +
  scale_fill_viridis_c(""Frequency"", option = ""magma"", direction = -1) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_x_discrete(expand = c(0, 0)) +
  labs(
    x = ""Season"",
    y = """",
    title = ""Bob Ross was very consistent in the elements he used"",
    subtitle = ""#tidytuesday, 2019-08-06\nelements with a total frequency < 5 are categorized as '** Other'"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    legend.position = c(0.2, -0.05),
    legend.direction = ""horizontal"",
    legend.key.width = unit(1.5, ""cm""),
    legend.text = element_text(size = 8),
    plot.margin = unit(rep(1, 4), ""cm"")
  )
hm
ggsave(
  filename = here::here(""2019-08-06_bob-ross-paintings/heatmap-elements.png""),
  plot = hm,
  width = 12,
  height = 12
)
","2019"
"34",192,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-06_bob-ross-paintings","jmcastagnetto","tidytuesday-kludges","2019-08-06_bob-ross-paintings/03-circular-barchart.R","# adapted from https://www.r-graph-gallery.com/circular-barplot.html

library(fivethirtyeight)
library(tidyverse)
library(cowplot)

data(""bob_ross"")

br_elements <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer) %>%
  select(-episode_num) %>%
  select(-episode, -title, -season) %>%
  pivot_longer(
    cols = apple_frame:wood_framed,
    names_to = ""element"",
    values_to = ""freq""
  ) %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  ungroup(element) %>%
  mutate(
    element = ifelse(freq < 5, ""** Other"", element) %>%
      str_replace_all(""_"", "" "") %>%
      str_to_title()
  ) %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  ungroup() %>%
  mutate(
    element = paste0(element,""\n(N = "", freq, "")"") %>%
              forcats::fct_reorder(freq)
  )

br_elements$id <- seq(1, nrow(br_elements))
angle <-  90 - (360 * (br_elements$id - 0.5) / nrow(br_elements))
br_elements$hjust <- as.numeric(angle < -90)
br_elements$angle <- angle

cb <- ggplot(br_elements,
       aes(x = element, y = freq)) +
  geom_segment(aes(x = element, xend = element,
                   y = 0, yend = 375),
               color = ""lightgrey"", size = .25,
               linetype = ""dashed"") +
  geom_col(aes(fill = element), width = 1) +
  labs(
    x = """",
    y = """",
    title = ""Frequency of elements in Bob Ross's paintings"",
    subtitle = ""#tidytuesday, 2019-08-06\nelements with a total frequency < 5 are categorized as '** Other'\nbar height in log10 scale"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  scale_fill_viridis_d(option = ""vidiris"") +
  scale_y_log10() + # no reason, except that it looks nicer and colorful
  theme_minimal() +
  theme(
    legend.position = ""none"",
    axis.text.y = element_blank(),
    axis.text.x = element_text(angle = br_elements$angle, size = 9),
    axis.title = element_blank(),
    panel.grid = element_blank(),
  ) +
  coord_polar(start = 0)

ggsave(
  filename = here::here(""2019-08-06_bob-ross-paintings/circular-barchart-elements.png""),
  plot = cb,
  width = 12,
  height = 12
)
","2019"
"35",193,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Africa Cup of Nations 2019/afcon.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""6/22/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce, ggtextures, DT, 
               cowplot, rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```


## AFCON theme


```{r}
theme_afcon <- function(
  title.size = 24,
  subtitle.size = 14,
  caption.size = 8,
  axis.text.size = 14,
  axis.text.x.size = 12,
  axis.text.y.size = 12,
  axis.title.size = 16,
  strip.text.size = 18,
  panel.grid.major.x = element_line(size = 0.5, color = ""white""),
  panel.grid.major.y = element_line(size = 0.5, color = ""white""),
  panel.grid.minor.x = element_blank(),
  panel.grid.minor.y = element_blank(),
  axis.ticks = element_line(color = ""white"")) {
  ## Theme:
  theme(text = element_text(family = ""Roboto Condensed"", color = ""white""),
        plot.title = element_text(family = ""Roboto Condensed"", face = ""bold"", 
                                  size = title.size, color = ""yellow""),
        plot.subtitle = element_text(size = subtitle.size),
        plot.caption = element_text(size = caption.size),
        panel.background = element_rect(fill = ""#CE1127""),
        plot.background = element_rect(fill = ""#000000""),
        axis.text = element_text(size = axis.text.size, color = ""white""),
        axis.text.x = element_text(size = axis.text.x.size, color = ""white""),
        axis.text.y = element_text(size = axis.text.y.size, color = ""white""),
        axis.title = element_text(size = axis.title.size),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        panel.grid.major.x = panel.grid.major.x,
        panel.grid.major.y = panel.grid.major.y,
        panel.grid.minor.x = panel.grid.minor.x,
        panel.grid.minor.y = panel.grid.minor.y,
        strip.text = element_text(color = ""yellow"", face = ""bold"", 
                                  size = strip.text.size, 
                                  margin = margin(4.4, 4.4, 4.4, 4.4)),
        strip.background = element_blank(),
        axis.ticks = axis.ticks
        )
}
```


```{r}
iris %>% 
  ggplot(aes(Sepal.Width, Sepal.Length)) +
  geom_point() +
  labs(title = ""balaljld"", 
       subtitle = ""lajdl"") +
  theme_afcon()
```



## Top Goalscorers

```{r}
base_url <- ""https://en.wikipedia.org/wiki/Africa_Cup_of_Nations_records_and_statistics""

session <- bow(base_url)

afcon_goalscorers_raw <- scrape(session) %>% 
  html_nodes(""table.wikitable:nth-child(9)"") %>% 
  html_table() %>% 
  flatten_df()
  
afcon_goalscorers_raw %>% 
  slice(1:5) %>% 
  ggplot(aes(x = Scorers, y = Goals)) +
  geom_col() +
  coord_flip() + 
  theme_afcon()
```





## Tournament wins

2nd place 3rd place? do i seriously have to iterate over every tournament? -_- dios mio...

```{r}
afcon_champions_raw <- scrape(session) %>% 
  html_nodes(""table.wikitable:nth-child(69)"") %>% 
  html_table() %>% 
  flatten_df()

afcon_champions_clean <- afcon_champions_raw %>% 
  janitor::clean_names() %>% 
  select(-rank) %>% 
  mutate(team = team %>% str_replace(""\\[.*\\]"", """")) %>% 
  arrange(desc(titles))
```




## Goals per squad

most squads don't have goals scored listed.........!!!!!!!!!!!!!!!!!

```{r}
squad_url <- ""https://en.wikipedia.org/wiki/2019_Africa_Cup_of_Nations_squads""

session <- bow(squad_url)

xpaths <- 1:24 %>% 
  map(., ~glue(""//*[@id='mw-content-text']/div/table[{.x}]""))

squads_df_raw <- scrape(session) %>% 
  html_node(xpath = '//*[@id=""toc""]') %>%  
  html_text() %>% 
  str_split(""\n"") %>% 
  unlist() %>% 
  tibble::enframe() %>% 
  rename(country = value) %>% 
  filter(str_detect(country, ""^[1-6]\\.""), !str_detect(country, ""Group"")) %>% 
  separate(country, c(""group"", ""delete"", ""country""), sep = c(1, 3)) %>% 
  slice(1:24) %>% 
  mutate(group = LETTERS[as.numeric(group)], 
         country = str_trim(country), 
         xpaths = xpaths,
         squads = map(xpaths, ~ scrape(session) %>% 
                        html_node(xpath = .x) %>% 
                        html_table())) %>% 
  unnest(squads)

saveRDS(squads_df_raw, ""../data/afcon_squads_df_raw.RDS"")
```

","2019"
"36",194,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Asian Cup 2019/asian_cup_2019.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""December 26, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load packages

```{r message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, ggrepel, stringi, magick, gapminder,
               glue, extrafont, rvest, ggtextures, cowplot, countrycode, ggimage,
               polite)
# necessary for Roboto Condensed font
loadfonts()
```

# Top goal scorers

```{r}
ac_top_scorers <- data.frame(
  player = c(""Ali Daei"", ""Ali Daei"", ""Ali Daei"",
             ""Lee Dong Gook"", ""Lee Dong Gook"",
             ""Naohiro Takahara"", ""Naohiro Takahara"",
             ""Jassem Al-Houwaidi"", ""Jassem Al-Houwaidi"",
             ""Younis Mahmoud"", ""Younis Mahmoud"", ""Younis Mahmoud"", ""Younis Mahmoud""),
  country = c(""Iran"", ""Iran"", ""Iran"",
              ""South Korea"", ""South Korea"",
              ""Japan"", ""Japan"",
              ""Kuwait"", ""Kuwait"",
              ""Iraq"", ""Iraq"", ""Iraq"", ""Iraq""),
  tournament = c(""1996"", ""2000"", ""2004"",
                 ""2000"", ""2004"",
                 ""2000"", ""2004"",
                 ""1996"", ""2000"",
                 ""2004"", ""2007"", ""2011"", ""2015""),
  goals = as.numeric(c(8, 3, 3,
            6, 4,
            5, 4,
            6, 2,
            1, 4, 1, 2)),
  total_goals = as.numeric(c(14, 14, 14,
            10, 10,
            9, 9,
            8, 8,
            8, 8, 8, 8))
)

# soccer ball images
# https://i.pinimg.com/originals/e7/d7/19/e7d7190f0b5b3abd4f6c17e2c7989ec3.jpg
# https://www.emoji.co.uk/files/microsoft-emojis/activity-windows10/8356-soccer-ball.png
ac_top_scorers <- ac_top_scorers %>% 
  mutate(image = case_when(
    tournament == ""2004"" ~ ""http://football-balls.com/ball_files/2004-asian-cup-adidas-roteiro-official-match-ball.png"",
    tournament == ""2007"" ~ ""http://football-balls.com/ball_files/2007-asian-cup-mercurial-veloci-official-match-ball.png"",
    tournament == ""2011"" ~ ""http://football-balls.com/ball_files/2011-asian-cup-nike-total-90-tracer-official-match-ball.png"",
    tournament == ""2015"" ~ ""http://football-balls.com/ball_files/2015-asian-cup-nike-ordem-2-official-match-ball.png"",
    TRUE ~ ""https://www.emoji.co.uk/files/microsoft-emojis/activity-windows10/8356-soccer-ball.png"")) %>% 
  mutate(country_code = country %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))


ac_top_scorers %>% 
  gather(key = ""player"", value = ""tournament"")

ac_top_scorers %>% 
  distinct(player, .keep_all = TRUE)
```


```{r, fig.width=8, fig.height=6}
ac_top_graph <- ac_top_scorers %>% 
  distinct(player, .keep_all = TRUE) %>% 
  ggplot(aes(x = reorder(player, total_goals), y = total_goals,
             image = image)) +
  #ggimage::geom_emoji(aes(image = '26bd'), size = 0.06) +
  geom_isotype_col(img_width = grid::unit(1, ""native""), img_height = NULL,
    ncol = NA, nrow = 1, hjust = 0, vjust = 0.5) +
  coord_flip() +
  #geom_flag(y = -1.5, aes(image = country_code), size = 0.1) +
  scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12, 14),
                     expand = c(0, 0), 
                     limits = c(0, 15)) +
  #expand_limits(y = -2) +
  ggthemes::theme_solarized() +
  labs(title = ""Top Scorers of the Asian Cup!"",
       subtitle = ""Most goals in a single tournament: 8 (Ali Daei, 1996)"",
       y = ""Number of Goals"", x = NULL) +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 18),
        subtitle = element_text(size = 14),
        axis.text = element_text(size = 12),
        axis.line.y = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.ticks.y = element_blank())

# scale them differently as flag sizes are different...
pimage <- axis_canvas(ac_top_graph, axis = 'y') + 
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/c/ca/Flag_of_Iran.svg"", 
             y = 13, scale = 1.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/0/09/Flag_of_South_Korea.svg"", 
             y = 10, scale = 1.7) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/9/9e/Flag_of_Japan.svg"", 
             y = 7, scale = 1.7) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/f/f6/Flag_of_Iraq.svg"", 
             y = 4, scale = 1.6) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/a/aa/Flag_of_Kuwait.svg"", 
             y = 1, scale = 1.2)

# insert the image strip into the bar plot and draw  
ggdraw(insert_yaxis_grob(ac_top_graph, pimage, position = ""left""))
```


```{r}
theme_void
ggthemes::theme_wsj
ggthemes::theme_solarized
```





# Goals scored per tournament

```{r}
wiki_url <- ""https://en.wikipedia.org""
acup_url <- ""https://en.wikipedia.org/wiki/AFC_Asian_Cup""

cup_links <- read_html(acup_url) %>% 
  html_nodes(""br+ i a"") %>% 
  html_attr(""href"") %>% 
  .[-17:-18]


acup_df <- cup_links %>% 
  as_data_frame() %>% 
  mutate(cup = str_remove(value, ""\\/wiki\\/"") %>% str_replace_all(""_"", "" "")) %>% 
  rename(link = value)



goals_info <- function(x) {
  goal_info <- wiki_url %>% 
    html_session() %>% 
    jump_to(x) %>% 
    html_nodes("".vcalendar"") %>% 
    html_table(header = FALSE) %>% 
    flatten_df() %>% 
    spread(key = X1, value = X2) %>% 
    select(`Goals scored`) %>% 
    mutate(`Goals scored` = str_remove_all(`Goals scored`, pattern = "".*\\("") %>% 
             str_extract_all(""\\d+\\.*\\d*"") %>% as.numeric)
}

team_num_info <- function(x) {
  team_num_info <- wiki_url %>% 
    html_session() %>% 
    jump_to(x) %>% 
    html_nodes("".vcalendar"") %>% 
    html_table(header = FALSE) %>% 
    flatten_df() %>% 
    spread(key = X1, value = X2) %>% 
    select(`Teams`) %>% 
    mutate(`Teams` = as.numeric(`Teams`))
}

match_num_info <- function(x) {
  match_num_info <- wiki_url %>% 
    html_session() %>% 
    jump_to(x) %>% 
    html_nodes("".vcalendar"") %>% 
    html_table(header = FALSE) %>% 
    flatten_df() %>% 
    spread(key = X1, value = X2) %>% 
    janitor::clean_names() %>% 
    select(matches_played) %>% 
    mutate(matches_played = as.numeric(matches_played))
}


# all together:
goals_data <- acup_df %>% 
  mutate(goals_per_game = map(acup_df$link, goals_info) %>% unlist,
         team_num = map(acup_df$link, team_num_info) %>% unlist,
         match_num = map(acup_df$link, match_num_info) %>% unlist)

```

```{r}
ac_goals_df <- goals_data %>% 
  mutate(label = cup %>% str_extract(""[0-9]+"") %>% str_replace("".."", ""'""),
         team_num = case_when(
           is.na(team_num) ~ 16,
           TRUE ~ team_num
         )) %>% 
  arrange(cup) %>% 
  mutate(label = factor(label, label),
         team_num = c(4, 4, 4, 5, 6, 6, 10, 10, 10, 8, 12, 12, 16, 16, 16, 16))
```


```{r}
ac_goals_df %>% 
  ggplot(aes(x = label, y = goals_per_game, group = 1)) +
  geom_line() +
  #geom_point() +
  scale_y_continuous(limits = c(NA, 5.35),
                     breaks = c(1.5, 2, 2.5, 3, 3.5, 4, 4.5)) +
  labs(x = ""Tournament (Year)"", y = ""Goals per Game""#,
       # title = ""Goals per Game throughout the Asian Cup."",
       # subtitle = ""Odd dip throughout the 80s to early 90s...""
       ) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        #title = element_text(size = 18),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10)) +
  annotate(geom = ""label"", x = ""'56"", y = 5.23, family = ""Roboto Condensed"",
           color = ""black"", #fill = ""grey"",
           label = ""Total Number of Games Played:"", hjust = 0) +
  annotate(geom = ""text"", x = ""'60"", y = 4.9, 
           label = ""6"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 1, xend = 3, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'68"", y = 4.9, 
           label = ""10"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 3.8, xend = 4.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'72"", y = 4.9, 
           label = ""13"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 4.8, xend = 5.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'76"", y = 4.9, 
           label = ""10"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 5.8, xend = 6.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'84"", y = 4.9, 
           label = ""24"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 7, xend = 9, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'92"", y = 4.9, 
           label = ""16"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 9.8, xend = 10.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 11.5, y = 4.9, 
           label = ""26"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 11, xend = 12, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 14.5, y = 4.9, 
           label = ""32"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 13, xend = 16, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 9, y = 4, family = ""Roboto Condensed"",
           label = glue(""
                        Incredibly low amount of goals in Group B
                        (15 in 10 Games) and in Knock-Out Stages
                        (4 goals in 4, only one scored in normal time)"")) +
  annotate(geom = ""segment"", x = 9, xend = 9, y = 1.6, yend = 3.6,
           color = ""red"") +
  ggimage::geom_emoji(aes(image = '26bd'), size = 0.03) 

ggsave(filename = paste0(here::here(""Asian Cup 2019""), ""/gpg_plot.png""))
plot <- image_read(paste0(here::here(""Asian Cup 2019""), ""/gpg_plot.png""))
```

## add logo

```{r}
logo_raw <- image_read(""https://upload.wikimedia.org/wikipedia/en/a/ad/2019_afc_asian_cup_logo.png"")

logo <- logo_raw %>% 
  image_scale(""100"") %>% 
  image_background(""grey"", flatten = TRUE) %>% 
  image_border(""grey"", ""600x10"") %>% 
  image_annotate(text = glue(""Goals per Game throughout the Asian Cup""),
                 color = ""white"", size = 30, 
                 location = ""+10+50"", gravity = ""northwest"")

final_plot <- image_append(image_scale(c(logo, plot), ""500""), stack = TRUE)

logo_proc <- logo_raw %>% image_scale(""100"")

# create blank canvas
a <- image_blank(width = 6, height = 0.8, color = ""white"")

# combine with logo and shit it to the left, to the left
b <- image_composite(image_scale(a, ""x100""), image_scale(logo_proc, ""x60""), 
                     offset = ""+500+25"")
logo_2 <- b %>% 
  image_annotate(text = glue(""Goals per Game throughout the Asian Cup""),
                 color = ""black"", size = 18, font = ""Roboto Condensed"",
                 location = ""+63+50"", gravity = ""northwest"")

final2_plot <- image_append(image_scale(c(logo_2, plot), ""500""), stack = TRUE)
final2_plot
image_write(final2_plot,
            paste0(here::here(""Asian Cup 2019""), ""/gpg_plot_final.png""))
```

- annotate number of matches played on top as strip
- fit avg goals per game per each sequence of # of matches >>> kinda like splines
- add AFC logo? top right corner
- put top scorer country as geom_point?
- soccer ball emoji as geom_point?
- patchwork to include top scoring countries + other additional info


## add logo 2.0

```{r}
ac_goals_df %>% 
  ggplot(aes(x = label, y = goals_per_game, group = 1)) +
  geom_line() +
  scale_y_continuous(limits = c(NA, 5.35),
                     breaks = c(1.5, 2, 2.5, 3, 3.5, 4, 4.5)) +
  labs(x = ""Tournament (Year)"", y = ""Goals per Game"",
       title = ""Goals per Game throughout the Asian Cup."") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        #title = element_text(size = 18),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10)) +
  annotate(geom = ""label"", x = ""'56"", y = 5.23, family = ""Roboto Condensed"",
           color = ""black"", 
           label = ""Total Number of Games Played:"", hjust = 0) +
  annotate(geom = ""text"", x = ""'60"", y = 4.9, 
           label = ""6"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 1, xend = 3, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'68"", y = 4.9, 
           label = ""10"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 3.8, xend = 4.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'72"", y = 4.9, 
           label = ""13"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 4.8, xend = 5.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'76"", y = 4.9, 
           label = ""10"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 5.8, xend = 6.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'84"", y = 4.9, 
           label = ""24"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 7, xend = 9, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'92"", y = 4.9, 
           label = ""16"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 9.8, xend = 10.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 11.5, y = 4.9, 
           label = ""26"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 11, xend = 12, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 14.5, y = 4.9, 
           label = ""32"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 13, xend = 16, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 9, y = 4, family = ""Roboto Condensed"",
           label = glue(""
                        Incredibly low amount of goals in Group B
                        (15 in 10 Games) and in Knock-Out Stages
                        (4 goals in 4, only one scored in normal time)"")) +
  annotate(geom = ""segment"", x = 9, xend = 9, y = 1.6, yend = 3.6,
           color = ""red"") +
  ggimage::geom_emoji(aes(image = '26bd'), size = 0.03) 

ggsave(filename = paste0(here::here(""Asian Cup 2019""), ""/gpg_title_plot.png""))
plot <- image_read(paste0(here::here(""Asian Cup 2019""), ""/gpg_title_plot.png""))
```


```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}
```



```{r}
add_logo(plot_path = ""gpg_title_plot.png"",
         logo_path = ""https://upload.wikimedia.org/wikipedia/en/a/ad/2019_afc_asian_cup_logo.png"",
         logo_position = ""top right"",
         logo_scale = 15) -> plot_2.0

plot_2.0
```






```{r}
wiki_url %>% 
  html_session() %>% 
  jump_to(""/wiki/2015_AFC_Asian_Cup"") %>% 
  html_nodes("".vcalendar"") %>% 
  html_table(header = FALSE) %>% 
  flatten_df() %>% 
  spread(key = X1, value = X2) %>% 
  select(`Goals scored`) %>% 
  mutate(`Goals scored` = str_remove_all(`Goals scored`, pattern = "".*\\("") %>% 
           str_extract_all(""\\d+\\.*\\d*"") %>% as.numeric)
```


```{r}
###

one_cup <- ""https://en.wikipedia.org/wiki/1968_AFC_Asian_Cup""

copa <- one_cup %>% 
  read_html() %>% 
  html_nodes("".vcalendar"") %>% 
  html_table(header = FALSE) %>% 
  flatten_df() %>% 
  spread(key = X1, value = X2) %>% 
  janitor::clean_names() %>% 
  select(goals_scored) %>% 
  mutate(`Goals scored` = str_remove_all(`Goals scored`, pattern = "".*\\("") %>% 
           str_extract_all(""\\d+\\.*\\d*"") %>% as.numeric) # \\(.*)

```








# Asian Cup record

```{r}
# .navigation-not-searchable+ .jquery-tablesorter

acup_url <- ""https://en.wikipedia.org/wiki/AFC_Asian_Cup""

session <- bow(acup_url)

acup_winners_raw <- scrape(session) %>% 
  html_nodes(""#mw-content-text > div > table:nth-child(30)"") %>% 
  html_table() %>% 
  flatten_df()
```

```{r}
acup_winners_clean <- acup_winners_raw %>% 
  janitor::clean_names() %>% 
  slice(1:8) %>% 
  select(-fourth_place, -total_top_four) %>% 
  separate(winners, into = c(""first_num"", ""first_place_year""), sep = "" "", extra = ""merge"") %>% 
  separate(runners_up, into = c(""second_num"", ""second_place_year""), sep = "" "", extra = ""merge"") %>% 
  separate(third_place, into = c(""third_num"", ""third_place_year""), sep = "" "", extra = ""merge"") %>% 
  mutate_all(funs(str_replace_all(., """", ""0""))) %>% 
  mutate_at(vars(contains(""num"")), funs(as.numeric)) %>% 
  mutate(team = if_else(team == ""Israel1"", ""Israel"", team)) %>% 
  gather(key = ""key"", value = ""value"", -team, 
         -first_place_year, -second_place_year, -third_place_year) %>% 
  mutate(key = case_when(
           key == ""first_num"" ~ ""Champions"",
           key == ""second_num"" ~ ""Runners-up"",
           key == ""third_num"" ~ ""Third Place""
         ),
         key = key %>% fct_relevel(c(""Champions"", ""Runners-up"", ""Third Place""))) %>% 
  # hack-ish solution?
  arrange(key, value) %>% 
  mutate(team = as_factor(team),
         order = row_number(),
         image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))
```

```{r, fig.width = 8, fig.height = 6}
a <- acup_winners_clean %>% 
  ggplot(aes(value, team, color = key)) +
  geom_point(size = 5) +
  scale_color_manual(values = c(""Champions"" = ""#FFCC33"",
                                ""Runners-up"" = ""#999999"",
                                ""Third Place"" = ""#CC6600""),
                     guide = FALSE) +
  labs(x = ""Number of Occurrence"",
       title = ""Winners & Losers of the Asian Cup (1956-2015)"",
       subtitle = glue(""
                       Ordered by number of Asian Cup(s) won.
                       Four-time Champions, Japan, only won their first in 1992!""),
       caption = glue(""
                      Note: Israel was expelled by the AFC in 1974 while Australia joined the AFC in 2006.
                      Source: Wikipedia
                      By @R_by_Ryo"")) +
  facet_wrap(~key) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 18),
        plot.subtitle = element_text(size = 12),
        axis.title.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.text.y = element_text(size = 14),
        axis.text.x = element_text(size = 12),
        plot.caption = element_text(hjust = 0, size = 10),
        panel.border = element_rect(fill = NA, colour = ""grey20""),
        panel.grid.minor.x = element_blank(),
        strip.text = element_text(size = 16))

ggsave(""../Asian Cup 2019/asiancup_winners.png"", width = 8, height = 6)

# a +
#   geom_flag(data = acup_winners_clean, 
#             x = -2, aes(image = image), size = 0.15) +
#   expand_limits(x = -2)

# insert_yaxis_grob()

#null_dev_env <- new.env(parent = emptyenv())
# set_null_device(""pdf"")
# cairo_pdf()
# ggdraw(add_sub(a, label = ""Source: Wikipedia\nBy @R_by_Ryo"", x = 0.95, size = 8))
# 
# Cairo::Cairo(1000, 750, ""test.png"", bg = ""white"")
# last_plot()
# dev.off()
```




# Working hours & Productivity

```{r}
acup_url <- ""https://en.wikipedia.org/wiki/2019_AFC_Asian_Cup""

acup_kickoff <- acup_url %>% 
  read_html() %>% 
  html_nodes(""time"") %>% 
  html_text() %>% 
  as_data_frame()

# time
```

- calculate +90 minutes for entire game duration
- NOT count extra time or stoppage time
- cross-refernce with other local time zones
- count up total number of hours per each spectator country

```{r}
acup_kickoff %>% 
  mutate(match_num = row_number(),
         match_type = if_else(between(match_num, 37, 51), 
                              ""Knock-Out Stage"", ""Group Stage""),
         time = value %>% str_replace(""\\(.*\\)"", """")) %>% 
  mutate(time2 = hm(time),
         time_ac2 = force_tz(time2, ""Asia/Dubai""), # time based in UTC +4
         time_jp = with_tz(time_ac2, tz = ""Asia/Tokyo""), # UTC +4 time converted to Japan
         time_jp_end = time_jp + hm(""2 0""),
         time_ac = with_tz(time2, tz = ""America/New_York""),
         timeZONE2 = tz(time_ac)) %>% 
  mutate(diff = make_difftime(hour = 2),
         int = as.interval(diff, time_ac2),
         jp_start = hm(""09:00"") %>% with_tz(tz = ""Asia/Tokyo""),
         jp_end = hm(""12:00"") %>% with_tz(tz = ""Asia/Tokyo""),
         jp_work = as.interval(jp_start, jp_end),
         overlap = int_overlaps(jp_work, int))


acup_kickoff %>% 
  mutate(match_num = row_number(),
         match_type = if_else(between(match_num, 37, 51), 
                              ""Knock-Out Stage"", ""Group Stage""),
         time = value %>% str_replace(""\\(.*\\)"", """")) %>% 
  mutate(time2 = dmy_hm(time),
         time3 = hour(time2))
```



```{r}
#tz <- ""Asia/""
acup_times_df <- acup_kickoff %>% 
  mutate(time = value %>% str_replace(""\\(.*\\)"", """")) %>% 
  mutate(time2 = dmy_hm(time)) %>%  # proper time var
  arrange(time2) %>% 
  mutate(
         # match num must arrangeDESC time2
         match_num = row_number(),
         match_type = if_else(between(match_num, 37, 51), 
                              ""Knock-Out Stage"", ""Group Stage""),
         # 
         is_weekday = wday(time2, label = TRUE),
         time_ac2 = force_tz(time2, ""Asia/Dubai""), # time based in UTC +4
         time_jp = with_tz(time_ac2, tz = ""Asia/Tokyo""), # UTC +4 time converted to Japan
         time_jp_end = time_jp + hm(""2 0""),
         time_ac = with_tz(time2, tz = ""America/New_York"")) %>% # UTC +4 time to NYC
  mutate(diff = make_difftime(hour = 2),
         int = as.interval(diff, time_ac2),
         # jp_start = ymd_hms(""2019-01-05 09:00:00"", tz = ""Asia/Tokyo""),
         # jp_end = ymd_hms(""2019-01-05 12:00:00"", tz = ""Asia/Tokyo""),
         jp_match = as.interval(time_jp, time_jp_end),
         overlap = int_overlaps(jp_match, int)) %>% 
  select(jp_match, int, overlap)

# now create 9AM-5PM for Japan for each of those days on the match days!!
# is_weekday? T/F

acup_times_df$jp_work %within% acup_times_df$int

```

ymd_hms(""2011-07-01 09:00:00"", tz = ""Pacific/Auckland"")




```{r}
acup_kickoff %>% 
  mutate(time = value %>% str_replace(""\\(.*\\)"", """")) %>% 
  mutate(time2 = dmy_hm(time)) %>%  # proper time var
  arrange(time2) %>% 
  mutate(match_num = row_number(),
         match_type = if_else(between(match_num, 37, 51), 
                              ""Knock-Out Stage"", ""Group Stage""),
         # 
         is_weekday = wday(time2, label = TRUE),
         time_ac2 = force_tz(time2, ""Asia/Dubai""), # time based in UTC +4
         time_ny = with_tz(time_ac2, tz = ""America/New_York""), # converted to NYC
         time_ny_end = time_ny + hm(""2 0"")) %>% 
  mutate(work_time = time %>% str_sub(end = -6),
         work_time_begin = glue(""{work_time} 09:00"") %>% 
           dmy_hm(tz = ""America/New_York""),
         work_time_end = glue(""{work_time} 17:00"") %>% 
           dmy_hm(tz = ""America/New_York"")) %>% 
  # create intervals
  mutate(diff = make_difftime(hour = 2),
         int = as.interval(diff, time_ac2),
         int_ny_work = as.interval(work_time_begin, work_time_end),
         ny_match = as.interval(time_ny, time_ny_end),
         overlap = int_overlaps(ny_match, int_ny_work)) %>% 
  # sum overlapping hours?
  mutate(overlap_num = pmax(pmin(time_ny_end, work_time_end) - 
                              pmax(time_ny, work_time_begin) + 1,0)) %>% 
  mutate(overlap_laplap = map2_dbl(work_time_begin, work_time_end,
                                   ~pmax((pmin(time_ny_end, .y)) - 
                                          pmax(time_ny, .x) + 1), 0)) %>% 
  select(ny_match, int, overlap, overlap_num, overlap_laplap)
```


## NY time

```{r}
acup_kickoff %>% 
  mutate(time = value %>% str_replace(""\\(.*\\)"", """")) %>% 
  mutate(time2 = dmy_hm(time)) %>%  # proper time var
  arrange(time2) %>% 
  mutate(match_num = row_number(),
         match_type = if_else(between(match_num, 37, 51), 
                              ""Knock-Out Stage"", ""Group Stage""),
         # 
         is_weekday = wday(time2, label = TRUE),
         time_ac2 = force_tz(time2, ""Asia/Dubai""), # time based in UTC +4
         time_jp = with_tz(time_ac2, tz = ""Asia/Tokyo""), # UTC +4 time converted to Japan
         time_jp_end = time_jp + hm(""2 0"")) %>% 
  mutate(work_time = time %>% str_sub(end = -6),
         work_time_begin = glue(""{work_time} 09:00"") %>% 
           dmy_hm(tz = ""Asia/Tokyo""),
         work_time_end = glue(""{work_time} 17:00"") %>% 
           dmy_hm(tz = ""Asia/Tokyo"")) %>% 
  # create intervals
  mutate(diff = make_difftime(hour = 2),
         int = as.interval(diff, time_ac2),
         int_jp_work = as.interval(work_time_begin, work_time_end),
         jp_match = as.interval(time_jp, time_jp_end),
         overlap = int_overlaps(jp_match, int_jp_work)) %>% 
  select(jp_match, int, overlap)
```


# Japan vs. RIVALS

- use Kaggle international results
- results UP TO END OF WORLD CUP
- filter AFC Asian Cup, Friendly, AFC Asian Cup qualification
- filter Asia >>> take out UEFA countries like Kazakhstan, Georgia, Israel, etc.


- https://www.kaggle.com/phjulien/a-journey-through-the-history-of-soccer/

```{r}
federation_files <- Sys.glob(""../data/federation_affiliations/*"")

df_federations = data.frame(country = NULL, federation = NULL)
for (f in federation_files) {
    federation = basename(f)
    content = read.csv(f, header=FALSE)
    content <- cbind(content,federation=rep(federation, dim(content)[1]))
    df_federations <- rbind(df_federations, content)
}

colnames(df_federations) <- c(""country"", ""federation"")

df_federations <- df_federations %>% 
  mutate(country = as.character(country) %>% str_trim(side = ""both""))
```

```{r}
results_raw <- read_csv(""../data/results.csv"")

results_japan_raw <- results_raw %>% 
  filter(home_team == ""Japan"" | away_team == ""Japan"") %>% 
  rename(venue_country = country, 
         venue_city = city) %>% 
  mutate(match_num = row_number())

# combine with federation affiliations
results_japan_home <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""home_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(home_federation = federation) #%>% 
  View()

results_japan_away <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""away_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(away_federation = federation) #%>% 
  View()

# combine home-away
results_japan_cleaned <- results_japan_home %>% 
  full_join(results_japan_away)

results_japan_cleaned %>% 
  filter(is.na(home_federation)) %>% 
  pull(home_team) %>% 
  unique()

results_japan_cleaned %>% 
  filter(is.na(away_federation)) %>% 
  pull(away_team) %>% 
  unique()

```



```{r}
results_japan_cleaned <- results_japan_cleaned %>% 
  mutate(
    home_federation = case_when(
      home_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"") ~ ""AFC"",
      home_team == ""USA"" ~ ""Concacaf"",
      home_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ home_federation),
    away_federation = case_when(
      away_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"", ""Taiwan"") ~ ""AFC"",
      away_team == ""USA"" ~ ""Concacaf"",
      away_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ away_federation
    ))
```

Now that it's nice and cleaned up I can reshape it so that the data is set from Japan's perspective.

```{r}
# reshape to Japan p.o.v.

results_jp_asia <- results_japan_cleaned %>% 
  # filter only for Japan games and AFC opponents
  filter(home_team == ""Japan"" | away_team == ""Japan"",
         home_federation == ""AFC"" & away_federation == ""AFC"") %>% 
  select(-contains(""federation""), -contains(""venue""),
         -neutral, -match_num,
         date, home_team, home_score, away_team, away_score, tournament) %>% 
  # reshape columns to Japan vs. opponent
  mutate(
    opponent = case_when(
      away_team != ""Japan"" ~ away_team,
      home_team != ""Japan"" ~ home_team),
    home_away = case_when(
      home_team == ""Japan"" ~ ""home"",
      away_team == ""Japan"" ~ ""away""),
    japan_goals = case_when(
      home_team == ""Japan"" ~ home_score,
      away_team == ""Japan"" ~ away_score),
    opp_goals = case_when(
      home_team != ""Japan"" ~ home_score,
      away_team != ""Japan"" ~ away_score)) %>% 
  # results
  mutate(
    result = case_when(
      japan_goals > opp_goals ~ ""Win"",
      japan_goals < opp_goals ~ ""Loss"",
      japan_goals == opp_goals ~ ""Draw""),
    result = result %>% as_factor() %>% fct_relevel(c(""Win"", ""Draw"", ""Loss""))) %>% 
  select(-contains(""score""), -contains(""team""))


#results_jp_asia %>% View()
```



```{r}
results_jp_asia %>% 
  filter(opponent == ""Uzbekistan"") %>% 
  group_by(result) %>% 
  count()

results_jp_asia %>% 
  filter(opponent == ""Turkmenistan"")

results_jp_asia %>% 
  filter(opponent == ""Oman"") %>% 
  knitr::kable()


results_jp_asia %>% 
  filter(opponent %in% c(""Oman"", ""Uzbekistan"", ""Turkmenistan"")) %>% 
  group_by(result, opponent) %>% 
  tally()

results_jp_asia %>% 
  filter(opponent %in% c(""Oman"", ""Uzbekistan"", ""Turkmenistan"")) %>% 
  group_by(result, opponent) %>% 
  summarize(j_g = sum(japan_goals),
            o_g = sum(opp_goals),
            n = n()) %>% 
  spread(result, n)
```



```{r}
results_jp_asia %>% 
  filter(opponent %in% c(""Australia"", ""Korea Republic"", ""Iran"")) %>% 
  group_by(result, opponent) %>% 
  mutate(n = n()) %>% 
  ungroup() %>% 
  group_by(result, opponent) %>% 
  summarize(j_g = sum(sum(japan_goals)),
            o_g = sum(sum(opp_goals)),
            n = n()) %>% 
  ungroup() %>% 
  spread(result, n) %>% 
  group_by(opponent) %>% 
  mutate(j_g = sum(j_g),
         o_g = sum(o_g),
         Win = sum(Win, na.rm = TRUE),
         Draw = sum(Draw, na.rm = TRUE),
         Loss = sum(Loss, na.rm = TRUE)) %>% 
  distinct()

```

thankfull south korea should be on the otherside of the bracket and we would also only meet Iran in the semifinals

Japan could meet Australia in the Quarters but without Aaron Mooy they're a much weaker side

Japan have unfortunately lost our rising star, Nakajima, to injury but we have replaced him with World Cup hero Takashi Inui.

```{r, echo=FALSE}
results_jp_asia %>% 
  filter(opponent %in% c(""Oman"", ""Vietnam"", ""India"")) %>% 
  group_by(result, opponent) %>% 
  mutate(n = n()) %>% 
  ungroup() %>% 
  group_by(home_away, result, opponent) %>% 
  summarize(j_goals = sum(japan_goals),
         oppo_goals = sum(opp_goals),
         n = n()) %>% 
  ungroup() %>% 
  arrange(opponent, result) %>% 
  spread(result, n) %>% 
  group_by(opponent, home_away) %>% 
  mutate(Win = if(""Win"" %in% names(.)){return(Win)} else{return(0)},
         Draw = if(""Draw"" %in% names(.)){return(Draw)} else{return(0)},
         Loss = if(""Loss"" %in% names(.)){return(Loss)} else{return(0)}) %>% 
  summarize(Win = sum(Win, na.rm = TRUE),
         Draw = sum(Draw, na.rm = TRUE),
         Loss = sum(Loss, na.rm = TRUE),
         j_goals = sum(j_goals),
         o_goals = sum(oppo_goals)) %>% 
  ungroup() %>% 
  group_by(opponent) %>% 
  do(add_row(.,
             opponent = .$opponent %>% unique(),
             home_away = ""total"",
             Win = sum(.$Win, na.rm = TRUE),
             Draw = sum(.$Draw, na.rm = TRUE),
             Loss = sum(.$Loss, na.rm = TRUE),
             j_goals = sum(.$j_goals),
             o_goals = sum(.$o_goals)))
```



# waffle charts

```{r}
library(waffle)

tibble(
  team = c(""Liverpool FC"", ""Draw"", ""Man. Utd""),
  values = c(55, 46, 68)
) -> liv_man

cols <- c(""Liverpool FC"" = ""red"", 
          ""Draw"" = ""grey"",
          ""Man. Utd"" = ""black"")

liv_man %>% 
  mutate(team = as_factor(team) %>% fct_relevel(""Liverpool FC"", ""Draw"", ""Man. Utd"")) %>% 
  ggplot(aes(fill = team, values = values)) +
  geom_waffle(color = ""white"", size = 1.125, n_rows = 6) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_fill_manual(values = cols, name = NULL) +
  #ggthemes::scale_fill_tableau(name=NULL) +
  coord_equal() +
  hrbrthemes::theme_ipsum_rc(grid = """") +
  theme_enhance_waffle() +
  labs(title = ""The North West Derby"")
```


## japan_versus function

```{r}
japan_versus <- function(data, ...) {
  # filter 
  filter_vars <- enquos(...)
  
  jp_vs <- data %>% 
    filter(!!!filter_vars) %>% 
    # count results type per opponent
    group_by(result, opponent) %>% 
    mutate(n = n()) %>% 
    ungroup() %>% 
    # sum amount of goals by Japan and opponent
    group_by(result, opponent) %>% 
    summarize(j_g = sum(japan_goals),
              o_g = sum(opp_goals),
              n = n()) %>% 
    ungroup() %>% 
    # spread results over multiple columns
    spread(result, n) %>% 
    # 1. failsafe against no type of result against an opponent
    # 2. sum up counts per opponent
    group_by(opponent) %>% 
    mutate(Win = if(""Win"" %in% names(.)){return(Win)} else{return(0)},
         Draw = if(""Draw"" %in% names(.)){return(Draw)} else{return(0)},
         Loss = if(""Loss"" %in% names(.)){return(Loss)} else{return(0)}) %>% 
    summarize(Win = sum(Win, na.rm = TRUE),
              Draw = sum(Draw, na.rm = TRUE),
              Loss = sum(Loss, na.rm = TRUE),
              `Goals For` = sum(j_g),
              `Goals Against` = sum(o_g))
  
  return(jp_vs)
}
```

```{r, fig.height = 4, fig.width=3}
library(waffle)
library(extrafont)
loadfonts(device = ""win"")

results_jp_asia <- readRDS(""../data/results_jp_asia.RDS"")

glimpse(results_jp_asia)

jp_aus <- results_jp_asia %>% 
  japan_versus(opponent == ""Australia"") %>% 
  select(-opponent, Japan = Win, Australia = Loss) %>% 
  gather(key = ""team"", value = ""values"", -`Goals For`, -`Goals Against`) %>% 
  select(-contains(""Goals""))

waffle(
  jp_aus, rows = 4, size = 1, 
  title = glue(""
               Japan vs. Australia: 
               The New 'Asian' Rivalry""),
  colors = c(""red"", ""grey"", ""blue""), 
  use_glyph = ""futbol"", glyph_size = 5,
  legend_pos = ""bottom""
)

```



```{r}
pal <- c(""Japan"" = ""blue"", ""Draw"" = ""grey"", ""South Korea"" = ""red"")

results_jp_asia %>% 
  japan_versus(opponent == ""Korea Republic"") %>% 
  select(-opponent, Japan = Win, `South Korea` = Loss) %>% 
  gather(key = ""team"", value = ""values"", -`Goals For`, -`Goals Against`) %>% 
  ggplot(aes(fill = team, values = values)) +
  geom_waffle(color = ""white"", size = 1.125, n_rows = 6) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_fill_manual(values = pal, name = NULL) +
  coord_equal() +
  hrbrthemes::theme_ipsum_rc(grid="""") +
  theme_enhance_waffle() +
  labs(title = ""Japan vs. South Korea"")

```



## time between start-finish + distance travelled

bar plot + calendar plot","2019"
"37",195,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Asian Cup 2019/japan_qatar.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""February 1, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, ggrepel, stringi, magick, 
               glue, extrafont, rvest, ggtextures, cowplot, ggimage, polite)
```

```{r}
federation_files <- Sys.glob(""../data/federation_affiliations/*"")

df_federations = data.frame(country = NULL, federation = NULL)
for (f in federation_files) {
    federation = basename(f)
    content = read.csv(f, header=FALSE)
    content <- cbind(content,federation=rep(federation, dim(content)[1]))
    df_federations <- rbind(df_federations, content)
}

colnames(df_federations) <- c(""country"", ""federation"")

df_federations <- df_federations %>% 
  mutate(country = as.character(country) %>% str_trim(side = ""both""))
```

Now to load the results data and then join it with the affiliations data.

```{r, message=FALSE}
results_raw <- read_csv(""../data/results.csv"")

results_japan_raw <- results_raw %>% 
  filter(home_team == ""Japan"" | away_team == ""Japan"") %>% 
  rename(venue_country = country, 
         venue_city = city) %>% 
  mutate(match_num = row_number())

# combine with federation affiliations
results_japan_home <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""home_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(home_federation = federation) 

results_japan_away <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""away_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(away_federation = federation)

# combine home-away
results_japan_cleaned <- results_japan_home %>% 
  full_join(results_japan_away)
```

Next I need to edit some of the continents for teams that didn't have a match in the federation affiliation data set, for example, ""South Korea"" is ""Korea Republic"" in the Kaggle data set.

```{r}
results_japan_cleaned <- results_japan_cleaned %>% 
  mutate(
    home_federation = case_when(
      home_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"") ~ ""AFC"",
      home_team == ""USA"" ~ ""Concacaf"",
      home_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ home_federation),
    away_federation = case_when(
      away_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"", ""Taiwan"") ~ ""AFC"",
      away_team == ""USA"" ~ ""Concacaf"",
      away_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ away_federation
    ))
```

Now that it's nice and cleaned up I can reshape it so that the data is set from Japan's perspective.

```{r}
results_jp_asia <- results_japan_cleaned %>% 
  # filter only for Japan games and AFC opponents
  filter(home_team == ""Japan"" | away_team == ""Japan"",
         home_federation == ""AFC"" & away_federation == ""AFC"") %>% 
  select(-contains(""federation""), -contains(""venue""),
         -neutral, -match_num,
         date, home_team, home_score, away_team, away_score, tournament) %>% 
  # reshape columns to Japan vs. opponent
  mutate(
    opponent = case_when(
      away_team != ""Japan"" ~ away_team,
      home_team != ""Japan"" ~ home_team),
    home_away = case_when(
      home_team == ""Japan"" ~ ""home"",
      away_team == ""Japan"" ~ ""away""),
    japan_goals = case_when(
      home_team == ""Japan"" ~ home_score,
      away_team == ""Japan"" ~ away_score),
    opp_goals = case_when(
      home_team != ""Japan"" ~ home_score,
      away_team != ""Japan"" ~ away_score)) %>% 
  # label results from Japan's perspective
  mutate(
    result = case_when(
      japan_goals > opp_goals ~ ""Win"",
      japan_goals < opp_goals ~ ""Loss"",
      japan_goals == opp_goals ~ ""Draw""),
    result = result %>% as_factor() %>% fct_relevel(c(""Win"", ""Draw"", ""Loss""))) %>% 
  select(-contains(""score""), -contains(""team""))
```


```{r}
results_jp_asia %>% filter(opponent == ""Qatar"") %>% knitr::kable()
```


```{r}
japan_versus <- function(data, ...) {
  # filter 
  filter_vars <- enquos(...)
  
  jp_vs <- data %>% 
    filter(!!!filter_vars) %>% 
    # count results type per opponent
    group_by(result, opponent) %>% 
    mutate(n = n()) %>% 
    ungroup() %>% 
    # sum amount of goals by Japan and opponent
    group_by(result, opponent) %>% 
    summarize(j_g = sum(japan_goals),
              o_g = sum(opp_goals),
              n = n()) %>% 
    ungroup() %>% 
    # spread results over multiple columns
    spread(result, n) %>% 
    # 1. failsafe against no type of result against an opponent
    # 2. sum up counts per opponent
    group_by(opponent) %>% 
    mutate(Win = if(""Win"" %in% names(.)){return(Win)} else{return(0)},
         Draw = if(""Draw"" %in% names(.)){return(Draw)} else{return(0)},
         Loss = if(""Loss"" %in% names(.)){return(Loss)} else{return(0)}) %>% 
    summarize(Win = sum(Win, na.rm = TRUE),
              Draw = sum(Draw, na.rm = TRUE),
              Loss = sum(Loss, na.rm = TRUE),
              `Goals For` = sum(j_g),
              `Goals Against` = sum(o_g))
  
  return(jp_vs)
}
```



```{r}
results_jp_asia %>% 
  japan_versus(opponent == ""Qatar"") %>% 
  knitr::kable(format = ""html"",
               caption = ""Japan's Record vs. Qatar"") %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c("" "", ""Result"" = 3, ""Goals"" = 2))
```

```{r}
results_jp_asia %>% 
  japan_versus(opponent == ""Iran"") %>% 
  knitr::kable(format = ""html"",
               caption = ""Japan's Record vs. Iran"") %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c("" "", ""Result"" = 3, ""Goals"" = 2))
```





```{r}
library(ggsoccer)
library(SBpitch)

create_Pitch(grass_colour = ""#538032"", 
line_colour =  ""#ffffff"", 
background_colour = ""#538032"", 
goal_colour = ""#000000"")


dat <- data.frame(x = c(92, 80, 80, 80, 80, 
                        70, 70, 62,
                        65, 65,
                        55),
                   y = c(50, 10, 40, 65, 90, 
                         40, 60, 50,
                         10, 90,
                         50),
                  lab = c(""Gonda"", ""Sakai"", ""Yoshida"", ""Tomiyasu"", ""Nagatomo"",
                          ""Shiotani"", ""Shibasaki"", ""Minamino"",
                          ""Haraguchi"", ""Doan"",
                          ""Osako""))
dat %>%
  ggplot(aes(x = x, y = y)) +
  annotate_pitch(fill = ""#538032"", 
                 colour = ""white"") +
  geom_label(aes(label = lab)) +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101))
```

","2019"
"38",196,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Asian Cup 2019/jpn_aus_waffle.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""January 12, 2019""
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

A new rival, Australia, emerged to challenge Japan in Asia as they joined the AFC in 2006. From the come-from-behind defeat in the Group Stages of the 2006 World Cup (still one of my most painful memories as a Japanese football fan...) and to an extra-time win in the 2011 Asian Cup Final, Japan and Australia have dramatically clashed in the past decade.

Using the `waffle` package I can create a graphic that summarizes the results between the two sides.


```{r}
japan_versus <- function(data, ...) {
  # filter 
  filter_vars <- enquos(...)
  
  jp_vs <- data %>% 
    filter(!!!filter_vars) %>% 
    # count results type per opponent
    group_by(result, opponent) %>% 
    mutate(n = n()) %>% 
    ungroup() %>% 
    # sum amount of goals by Japan and opponent
    group_by(result, opponent) %>% 
    summarize(j_g = sum(japan_goals),
              o_g = sum(opp_goals),
              n = n()) %>% 
    ungroup() %>% 
    # spread results over multiple columns
    spread(result, n) %>% 
    # 1. failsafe against no type of result against an opponent
    # 2. sum up counts per opponent
    group_by(opponent) %>% 
    mutate(Win = if(""Win"" %in% names(.)){return(Win)} else{return(0)},
         Draw = if(""Draw"" %in% names(.)){return(Draw)} else{return(0)},
         Loss = if(""Loss"" %in% names(.)){return(Loss)} else{return(0)}) %>% 
    summarize(Win = sum(Win, na.rm = TRUE),
              Draw = sum(Draw, na.rm = TRUE),
              Loss = sum(Loss, na.rm = TRUE),
              `Goals For` = sum(j_g),
              `Goals Against` = sum(o_g))
  
  return(jp_vs)
}
```

```{r, fig.height = 4, fig.width=3}
library(glue)
library(dplyr)
library(tidyr)
library(waffle)
library(extrafont)
loadfonts(device = ""win"")

results_jp_asia <- readRDS(""../data/results_jp_asia.RDS"")


jp_aus <- results_jp_asia %>% 
  japan_versus(opponent == ""Australia"") %>% 
  select(-opponent, Japan = Win, Australia = Loss) %>% 
  gather(key = ""team"", value = ""values"", -`Goals For`, -`Goals Against`) %>% 
  select(-contains(""Goals""))

# Waffle plot!
waffle(
  jp_aus, rows = 4, size = 1, 
  title = glue(""
               Japan vs. Australia: 
               The New 'Asian' Rivalry""),
  colors = c(""red"", ""grey"", ""blue""), 
  use_glyph = ""futbol"", glyph_size = 5,
  legend_pos = ""bottom""
)

```

","2019"
"39",197,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Asian Cup 2019/jpn_saudi.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""January 21, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, ggrepel, stringi, magick, 
               glue, extrafont, rvest, ggtextures, cowplot, ggimage, polite)
```

```{r}
federation_files <- Sys.glob(""../data/federation_affiliations/*"")

df_federations = data.frame(country = NULL, federation = NULL)
for (f in federation_files) {
    federation = basename(f)
    content = read.csv(f, header=FALSE)
    content <- cbind(content,federation=rep(federation, dim(content)[1]))
    df_federations <- rbind(df_federations, content)
}

colnames(df_federations) <- c(""country"", ""federation"")

df_federations <- df_federations %>% 
  mutate(country = as.character(country) %>% str_trim(side = ""both""))
```

Now to load the results data and then join it with the affiliations data.

```{r, message=FALSE}
results_raw <- read_csv(""../data/results.csv"")

results_japan_raw <- results_raw %>% 
  filter(home_team == ""Japan"" | away_team == ""Japan"") %>% 
  rename(venue_country = country, 
         venue_city = city) %>% 
  mutate(match_num = row_number())

# combine with federation affiliations
results_japan_home <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""home_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(home_federation = federation) 

results_japan_away <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""away_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(away_federation = federation)

# combine home-away
results_japan_cleaned <- results_japan_home %>% 
  full_join(results_japan_away)
```

Next I need to edit some of the continents for teams that didn't have a match in the federation affiliation data set, for example, ""South Korea"" is ""Korea Republic"" in the Kaggle data set.

```{r}
results_japan_cleaned <- results_japan_cleaned %>% 
  mutate(
    home_federation = case_when(
      home_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"") ~ ""AFC"",
      home_team == ""USA"" ~ ""Concacaf"",
      home_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ home_federation),
    away_federation = case_when(
      away_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"", ""Taiwan"") ~ ""AFC"",
      away_team == ""USA"" ~ ""Concacaf"",
      away_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ away_federation
    ))
```

Now that it's nice and cleaned up I can reshape it so that the data is set from Japan's perspective.

```{r}
results_jp_asia <- results_japan_cleaned %>% 
  # filter only for Japan games and AFC opponents
  filter(home_team == ""Japan"" | away_team == ""Japan"",
         home_federation == ""AFC"" & away_federation == ""AFC"") %>% 
  select(-contains(""federation""), -contains(""venue""),
         -neutral, -match_num,
         date, home_team, home_score, away_team, away_score, tournament) %>% 
  # reshape columns to Japan vs. opponent
  mutate(
    opponent = case_when(
      away_team != ""Japan"" ~ away_team,
      home_team != ""Japan"" ~ home_team),
    home_away = case_when(
      home_team == ""Japan"" ~ ""home"",
      away_team == ""Japan"" ~ ""away""),
    japan_goals = case_when(
      home_team == ""Japan"" ~ home_score,
      away_team == ""Japan"" ~ away_score),
    opp_goals = case_when(
      home_team != ""Japan"" ~ home_score,
      away_team != ""Japan"" ~ away_score)) %>% 
  # label results from Japan's perspective
  mutate(
    result = case_when(
      japan_goals > opp_goals ~ ""Win"",
      japan_goals < opp_goals ~ ""Loss"",
      japan_goals == opp_goals ~ ""Draw""),
    result = result %>% as_factor() %>% fct_relevel(c(""Win"", ""Draw"", ""Loss""))) %>% 
  select(-contains(""score""), -contains(""team""))
```


```{r}
results_jp_asia %>% filter(opponent == ""Saudi Arabia"") %>% knitr::kable()
```


```{r}
japan_versus <- function(data, ...) {
  # filter 
  filter_vars <- enquos(...)
  
  jp_vs <- data %>% 
    filter(!!!filter_vars) %>% 
    # count results type per opponent
    group_by(result, opponent) %>% 
    mutate(n = n()) %>% 
    ungroup() %>% 
    # sum amount of goals by Japan and opponent
    group_by(result, opponent) %>% 
    summarize(j_g = sum(japan_goals),
              o_g = sum(opp_goals),
              n = n()) %>% 
    ungroup() %>% 
    # spread results over multiple columns
    spread(result, n) %>% 
    # 1. failsafe against no type of result against an opponent
    # 2. sum up counts per opponent
    group_by(opponent) %>% 
    mutate(Win = if(""Win"" %in% names(.)){return(Win)} else{return(0)},
         Draw = if(""Draw"" %in% names(.)){return(Draw)} else{return(0)},
         Loss = if(""Loss"" %in% names(.)){return(Loss)} else{return(0)}) %>% 
    summarize(Win = sum(Win, na.rm = TRUE),
              Draw = sum(Draw, na.rm = TRUE),
              Loss = sum(Loss, na.rm = TRUE),
              `Goals For` = sum(j_g),
              `Goals Against` = sum(o_g))
  
  return(jp_vs)
}
```



```{r}
results_jp_asia %>% 
  japan_versus(opponent == ""Saudi Arabia"") %>% 
  knitr::kable(format = ""html"",
               caption = ""Japan's Record vs. Saudi Arabia"") %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c("" "", ""Result"" = 3, ""Goals"" = 2))
```

```{r}
results_jp_asia %>% 
  japan_versus(opponent == ""Vietnam"") %>% 
  knitr::kable(format = ""html"",
               caption = ""Japan's Record vs. Vietnam"") %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c("" "", ""Result"" = 3, ""Goals"" = 2))
```

","2019"
"40",198,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Asian Cup 2019/visualize_asian_cup_2019.rmd","---
title: ""Untitled""
author: ""RN7""
always_allow_html: yes
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Another year, another big soccer/football tournament! This time it's the top international competition in Asia, the Asian Cup hosted in the U.A.E. I'll be covering (responsible) web-scraping, data wrangling (tidyverse ftw!), and of course, data visualization with `ggplot2`.

Let's get started!

## Packages

```{r message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, ggrepel, stringi, magick, 
               glue, extrafont, rvest, ggtextures, cowplot, ggimage, polite)
# Roboto Condensed font (from hrbrmstrthemes or just Google it)
loadfonts()
```

## Top Goalscorers of the Asian Cup

The first thing I looked at was, ""Who were the top goalscorers in the history of the Asian Cup?""

Here I use the [polite](https://github.com/dmi3kno/polite) package to take a look at the `robots.txt` for the web page and see if it is OK to  web scrape. It's good to make things like this a habit! 

First you pass the URL to the `bow()` function, check that you are indeed allowed to scrape, then use `scrape()` to retrieve data, and the rest is the usual `rvest` web-scraping workflow.

```{r}
topg_url <- ""https://en.wikipedia.org/wiki/AFC_Asian_Cup_records_and_statistics""

session <- bow(topg_url)

ac_top_scorers <- scrape(session) %>%
  html_nodes(""table.wikitable:nth-child(29)"") %>% ## 6/22/2019: it's (36) now and the players have changed...
  html_table() %>% 
  flatten_df() %>% 
  select(-Ref.) %>% 
  set_names(c(""total_goals"", ""player"", ""country""))
```

For brevity, let's only take a look at the top 5 goal scorers. I'll also `mutate()` in a nice image of a soccer ball for the data points on the plot.

```{r}
ac_top_scorers <- ac_top_scorers %>% 
  head(5) %>% 
  mutate(image = ""https://www.emoji.co.uk/files/microsoft-emojis/activity-windows10/8356-soccer-ball.png"")
```

Now it's ready! Slightly different to your standard bar graph here as I use the `geom_isotype_col()` function from `ggtextures` to create a bar of soccer ball images. Compared to other functions in `ggtextures`, `geom_isotype_col()` allows each image to correspond to the value of the variable you are plotting, in this case 1 ball = 1 goal!

```{r top goal scorers plot, fig.width=8, fig.height=6}
ac_top_graph <- ac_top_scorers %>% 
  ggplot(aes(x = reorder(player, total_goals), y = total_goals,
             image = image)) +
  geom_isotype_col(img_width = grid::unit(1, ""native""), img_height = NULL,
    ncol = NA, nrow = 1, hjust = 0, vjust = 0.5) +
  coord_flip() +
  scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12, 14),
                     expand = c(0, 0), 
                     limits = c(0, 15)) +
  ggthemes::theme_solarized() +
  labs(title = ""Top Scorers of the Asian Cup"",
       subtitle = ""Most goals in a single tournament: 8 (Ali Daei, 1996)"",
       y = ""Number of Goals"", x = NULL,
       caption = glue(""
                      Source: Wikipedia
                      By @R_by_Ryo"")) +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 22),
        plot.subtitle = element_text(size = 14),
        axis.text = element_text(size = 14),
        axis.title.x = element_text(size = 16),
        axis.line.y = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.ticks.y = element_blank())

ac_top_graph
```

OK, not bad. However, wouldn't it be nice to add a bit more information for context? Specifically, which country these players came from. So let's add some flags along the y-axis!

There are lots of different ways to do this (like `geom_flag()` from the `ggimage` package) but I ended up doing it the `cowplot` way. I had to tweak the scales a bit as the flags came in different sizes. When you plot, you just insert the image strip into the bar plot with `axis_canvas()` and combine all the parts together with `ggdraw()`!

```{r draw_image, fig.width=8, fig.height=6, fig.align='center'}
axis_image <- axis_canvas(ac_top_graph, axis = 'y') + 
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/c/ca/Flag_of_Iran.svg"", 
             y = 13, scale = 1.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/0/09/Flag_of_South_Korea.svg"", 
             y = 10, scale = 1.7) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/9/9e/Flag_of_Japan.svg"", 
             y = 7, scale = 1.7) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/f/f6/Flag_of_Iraq.svg"", 
             y = 4, scale = 1.6) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/a/aa/Flag_of_Kuwait.svg"", 
             y = 1, scale = 1.2)

ggdraw(insert_yaxis_grob(ac_top_graph, axis_image, position = ""left""))
```

Ideally I wanted the soccer balls to be the official balls from the tournament that the player scored in. However, I couldn't find a nice emoji-fied/icon-ized version and there was also the ""small"" problem in that there was no ""official"" Asian Cup ball until the 2004 tournament in China! You can take a look at the official Asian Cup balls [here](http://football-balls.com/balls/asian-cup).

## Winners of the Asian Cup

We saw that the top goal scorers came from Iran, South Korea, Japan, Iraq, and Kuwait but did their goal scoring exploits lead their nations to glory? Let's find out!

When web-scraping I really like using `flatten_df()` after `html_table()` as I don't have to use the awkward looking `.[[1]]` within my piped workflow.

```{r}
acup_url <- ""https://en.wikipedia.org/wiki/AFC_Asian_Cup""

session <- bow(acup_url)

acup_winners_raw <- scrape(session) %>% 
  html_nodes(""table:nth-child(31)"") %>% 
  html_table() %>% 
  flatten_df()
```

Now I can use the `clean_names()` function to quickly clean up my names (mainly when I can't be bothered to `set_names()` them myself...).

The next steps are splitting up the number of times a team placed between 1st and 3rd and the year that occurred with `separate()`. 

The variants of `mutate()` are then used to tidy the string columns of the data into numeric type.

I use `gather()` so each team will have a row for each of the rank positions (1st-3rd). 

Finally, I arrange the data in a way that the facets will be ordered in the way that I want.

```{r clean winners df, warning=FALSE}
acup_winners_clean <- acup_winners_raw %>% 
  janitor::clean_names() %>% 
  slice(1:8) %>% 
  select(-fourth_place, -semi_finalists, -total_top_four) %>% 
  separate(winners, into = c(""Champions"", ""first_place_year""), 
           sep = "" "", extra = ""merge"") %>% 
  separate(runners_up, into = c(""Runners-up"", ""second_place_year""), 
           sep = "" "", extra = ""merge"") %>% 
  separate(third_place, into = c(""Third Place"", ""third_place_year""), 
           sep = "" "", extra = ""merge"") %>% 
  mutate_all(funs(str_replace_all(., """", ""0""))) %>% 
  mutate_at(vars(contains(""num"")), funs(as.numeric)) %>% 
  mutate(team = if_else(team == ""Israel1"", ""Israel"", team)) %>% 
  gather(key = ""key"", value = ""value"", -team, 
         -first_place_year, -second_place_year, -third_place_year) %>% 
  mutate(key = key %>% 
           fct_relevel(c(""Champions"", ""Runners-up"", ""Third Place""))) %>% 
  arrange(key, value) %>% 
  mutate(team = as_factor(team),
         order = row_number())
```

I plot using facets on the ""key"" variable (containing the rank data) so that we can see how many times each team placed as Champions to Third Place. I also use the `glue()` function here to format the multi-line captions and titles in a neat way.

```{r, fig.width=8, fig.height=6, fig.align='center'}
acup_winners_clean %>% 
  ggplot(aes(value, team, color = key)) +
  geom_point(size = 5) +
  scale_color_manual(values = c(""Champions"" = ""#FFCC33"",
                                ""Runners-up"" = ""#999999"",
                                ""Third Place"" = ""#CC6600""),
                     guide = FALSE) +
  labs(x = ""Number of Occurrence"",
       title = ""Winners & Losers of the Asian Cup!"",
       subtitle = glue(""
                       Ordered by number of Asian Cup(s) won.
                       Four-time Champions, Japan, only won their first in 1992!""),
       caption = glue(""
                      Note: Israel was expelled by the AFC in 1974 while Australia joined the AFC in 2006.
                      Source: Wikipedia
                      By @R_by_Ryo"")) +
  facet_wrap(~key) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 18),
        plot.subtitle = element_text(size = 12),
        axis.title.y = element_blank(),
        axis.title.x = element_text(size = 12),
        axis.text.y = element_text(size = 14),
        axis.text.x = element_text(size = 12),
        plot.caption = element_text(hjust = 0, size = 10),
        panel.border = element_rect(fill = NA, colour = ""grey20""),
        panel.grid.minor.x = element_blank(),
        strip.text = element_text(size = 16)) 
```

## Goals per Game

One new thing I learned very recently, while working on this viz in fact, was using magrittr aliases! 

![](https://twitter.com/Emil_Hvitfeldt/status/1081080919073542144) 

Usually for web scraping I always wind up having to use `.[x]` or `.[[x]]` but now I can just use `extract()` or `extract2()` respectively to do the same thing!

```{r GPG base links}
wiki_url <- ""https://en.wikipedia.org""
session <- bow(wiki_url)
acup_url <- ""https://en.wikipedia.org/wiki/AFC_Asian_Cup""
session_cup <- bow(acup_url)

cup_links <- scrape(session_cup) %>% 
  html_nodes(""br+ i a"") %>% 
  html_attr(""href"") %>% 
  magrittr::extract(-17:-18)

acup_df <- cup_links %>% 
  as_data_frame() %>% 
  mutate(cup = str_remove(value, ""\\/wiki\\/"") %>% str_replace_all(""_"", "" "")) %>% 
  rename(link = value)
```

Another cool thing I found while scraping this data was the `jump_to()` function that allows you to navigate to a new URL. This makes `map()`-ing over multiple URL links from a base URL very easy! Here, the base URL is the AFC Asian Cup Wikipedia page and the function iterates over each of the links to the URL of the respective tournament pages. Another way that I could've done this was to `map()` over the different dates of the tournaments as the Wikipedia page of each edition of the Asian Cup only differed in the ""year"" appended at the beginning of the URL. 

```{r goal info functions, warning=FALSE}
goals_info <- function(x) {
  goal_info <- session %>% 
    jump_to(x) %>% 
    html_nodes("".vcalendar"") %>% 
    html_table(header = FALSE) %>% 
    flatten_df() %>% 
    spread(key = X1, value = X2) %>% 
    select(`Goals scored`) %>% 
    mutate(`Goals scored` = str_remove_all(`Goals scored`, pattern = "".*\\("") %>% 
             str_extract_all(""\\d+\\.*\\d*"") %>% as.numeric)
}

team_num_info <- function(x) {
  team_num_info <- session %>% 
    jump_to(x) %>% 
    html_nodes("".vcalendar"") %>% 
    html_table(header = FALSE) %>% 
    flatten_df() %>% 
    spread(key = X1, value = X2) %>% 
    select(`Teams`) %>% 
    mutate(`Teams` = as.numeric(`Teams`))
}

match_num_info <- function(x) {
  match_num_info <- session %>% 
    jump_to(x) %>% 
    html_nodes("".vcalendar"") %>% 
    html_table(header = FALSE) %>% 
    flatten_df() %>% 
    spread(key = X1, value = X2) %>% 
    janitor::clean_names() %>% 
    select(matches_played) %>% 
    mutate(matches_played = as.numeric(matches_played))
}

# all together:
goals_data <- acup_df %>% 
  mutate(goals_per_game = map(acup_df$link, goals_info) %>% unlist,
         team_num = map(acup_df$link, team_num_info) %>% unlist,
         match_num = map(acup_df$link, match_num_info) %>% unlist)
```

Next, clean it up a bit and add in the number of teams that participated in each tournament.

```{r clean up}
ac_goals_df <- goals_data %>% 
  mutate(label = cup %>% str_extract(""[0-9]+"") %>% str_replace("".."", ""'""),
         team_num = case_when(
           is.na(team_num) ~ 16,
           TRUE ~ team_num
         )) %>% 
  arrange(cup) %>% 
  mutate(label = factor(label, label),
         team_num = c(4, 4, 4, 5, 6, 6, 10, 10, 10, 8, 12, 12, 16, 16, 16, 16))

glimpse(ac_goals_df)
```

Now we make a line graph but with LOTS of `annotate()` code to add in comments, labels, and segments for the labels. At the end I use `geom_emoji()` to add a soccer ball to the plot for each of the data points.

```{r, fig.align='center'}
plot <- ac_goals_df %>% 
  ggplot(aes(x = label, y = goals_per_game, group = 1)) +
  geom_line() +
  scale_y_continuous(limits = c(NA, 5.35),
                     breaks = c(1.5, 2, 2.5, 3, 3.5, 4, 4.5)) +
  labs(x = ""Tournament (Year)"", y = ""Goals per Game"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 12)) +
  annotate(geom = ""label"", x = ""'56"", y = 5.15, family = ""Roboto Condensed"",
           color = ""black"", 
           label = ""Total Number of Games Played:"", hjust = 0) +
  annotate(geom = ""text"", x = ""'60"", y = 4.9, 
           label = ""6"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 1, xend = 3, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'68"", y = 4.9, 
           label = ""10"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 3.8, xend = 4.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'72"", y = 4.9, 
           label = ""13"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 4.8, xend = 5.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'76"", y = 4.9, 
           label = ""10"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 5.8, xend = 6.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'84"", y = 4.9, 
           label = ""24"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 7, xend = 9, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = ""'92"", y = 4.9, 
           label = ""16"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 9.8, xend = 10.2, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 11.5, y = 4.9, 
           label = ""26"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 11, xend = 12, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 14.5, y = 4.9, 
           label = ""32"", family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", x = 13, xend = 16, y = 4.8, yend = 4.8) +
  annotate(geom = ""text"", x = 9, y = 4, family = ""Roboto Condensed"",
           label = glue(""
                        Incredibly low amount of goals in Group B
                        (15 in 10 Games) and in Knock-Out Stages
                        (4 goals in 4, only 1 scored in normal time)"")) +
  annotate(geom = ""segment"", x = 9, xend = 9, y = 1.65, yend = 3.75,
           color = ""red"") +
  ggimage::geom_emoji(aes(image = '26bd'), size = 0.03) 

plot
ggsave(filename = paste0(here::here(""Asian Cup 2019""), ""/gpg_plot.png""), 
       width = 8, height = 7, dpi = 300)
plot <- image_read(paste0(here::here(""Asian Cup 2019""), ""/gpg_plot.png""))
```

However, I'm not finished yet! I wanted to try to make this look a bit more ""official"" so I attempted to add the Asian Cup logo on the top right corner. There are probably alternative ways to how I did it below, especially by using grobs, but I was reminded of [this](https://www.danielphadley.com/ggplot-logo/) blog post by [Daniel Hadley](https://twitter.com/danielphadley) who used the `magick` package to add a footer with a logo onto a `ggplot` object. I've used `magick` before for animations and this was a good chance to try it out for image editing. Compared to Daniel Hadley's example I needed to have the logo on the right corner so I had to find an alternative way of creating a blank canvas with `image_blank()` and then placing everything on top of that with `image_composite()` and `image_append()`.

```{r, fig.align='center'}
logo_raw <- image_read(""https://upload.wikimedia.org/wikipedia/en/a/ad/2019_afc_asian_cup_logo.png"")

logo_proc <- logo_raw %>% image_scale(""600"")

# create blank canvas
a <- image_blank(width = 1000, height = 100, color = ""white"")
# combine with logo image and shift logo to the right
b <- image_composite(image_scale(a, ""x100""), image_scale(logo_proc, ""x75""), 
                     offset = ""+880+25"")
# add in the title text
logo_header <- b %>% 
  image_annotate(text = glue(""Goals per Game Throughout the History of the Asian Cup""),
                 color = ""black"", size = 24, font = ""Roboto Condensed"",
                 location = ""+63+50"", gravity = ""northwest"")

# combine it all together! 
final2_plot <- image_append(image_scale(c(logo_header, plot), ""1000""), stack = TRUE)

# image_write(final2_plot,
#             glue(""{here::here('Asian Cup 2019')}/gpg_plot_final.png""))

final2_plot
```

All in all it took a while to tweak the positions of the text and logo image but for my first try it worked well. There is definitely room for improvement in regards to sizing and scaling though.

Ultimately, I couldn't find much information on why those tournaments in the 80s in particular were such low scoring affairs. I wasn't alive to watch those games on TV nor could I find any illuminating articles or blog posts on the style of Asian football back in the 80s...This was also before Japan really got into soccer so there wasn't anything I could find in Japanese either.

## Japan's record vs. Group D opponents and rivals

Japan is the most successful team in the competition with 4 championships but who are their opponents in the group stages and how have they fared against them? While I'm at it I will also check their records against long-time continental rivals such as Iran, South Korea, Saudi Arabia and more recently, Australia.

The data I'm going to use comes from [Kaggle](https://www.kaggle.com/martj42/international-football-results-from-1872-to-2017) which has all international football results from 1872 to the World Cup final last year. To add in the federation affiliation (UEFA, AFC, etc.) for each of the countries I slightly modified some code from one of the kernels, [""A Journey Through The History of Soccer""](https://www.kaggle.com/phjulien/a-journey-through-the-history-of-soccer/) by PH Julien.

```{r}
federation_files <- Sys.glob(""../data/federation_affiliations/*"")

df_federations = data.frame(country = NULL, federation = NULL)
for (f in federation_files) {
    federation = basename(f)
    content = read.csv(f, header=FALSE)
    content <- cbind(content,federation=rep(federation, dim(content)[1]))
    df_federations <- rbind(df_federations, content)
}

colnames(df_federations) <- c(""country"", ""federation"")

df_federations <- df_federations %>% 
  mutate(country = as.character(country) %>% str_trim(side = ""both""))
```

Now to load the results data and then join it with the affiliations data.

```{r, message=FALSE}
results_raw <- read_csv(""../data/results.csv"")

results_japan_raw <- results_raw %>% 
  filter(home_team == ""Japan"" | away_team == ""Japan"") %>% 
  rename(venue_country = country, 
         venue_city = city) %>% 
  mutate(match_num = row_number())

# combine with federation affiliations
results_japan_home <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""home_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(home_federation = federation) 

results_japan_away <- results_japan_raw %>% 
  left_join(df_federations, 
            by = c(""away_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(away_federation = federation)

# combine home-away
results_japan_cleaned <- results_japan_home %>% 
  full_join(results_japan_away)
```

Next I need to edit some of the continents for teams that didn't have a match in the federation affiliation data set, for example, ""South Korea"" is ""Korea Republic"" in the Kaggle data set.

```{r}
results_japan_cleaned <- results_japan_cleaned %>% 
  mutate(
    home_federation = case_when(
      home_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"") ~ ""AFC"",
      home_team == ""USA"" ~ ""Concacaf"",
      home_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ home_federation),
    away_federation = case_when(
      away_team %in% c(
        ""China"", ""Manchukuo"", ""Burma"", ""Korea Republic"", ""Vietnam Republic"",
        ""Korea DPR"", ""Brunei"", ""Taiwan"") ~ ""AFC"",
      away_team == ""USA"" ~ ""Concacaf"",
      away_team == ""Bosnia-Herzegovina"" ~ ""UEFA"",
      TRUE ~ away_federation
    ))
```

Now that it's nice and cleaned up I can reshape it so that the data is set from Japan's perspective.

```{r}
results_jp_asia <- results_japan_cleaned %>% 
  # filter only for Japan games and AFC opponents
  filter(home_team == ""Japan"" | away_team == ""Japan"",
         home_federation == ""AFC"" & away_federation == ""AFC"") %>% 
  select(-contains(""federation""), -contains(""venue""),
         -neutral, -match_num,
         date, home_team, home_score, away_team, away_score, tournament) %>% 
  # reshape columns to Japan vs. opponent
  mutate(
    opponent = case_when(
      away_team != ""Japan"" ~ away_team,
      home_team != ""Japan"" ~ home_team),
    home_away = case_when(
      home_team == ""Japan"" ~ ""home"",
      away_team == ""Japan"" ~ ""away""),
    japan_goals = case_when(
      home_team == ""Japan"" ~ home_score,
      away_team == ""Japan"" ~ away_score),
    opp_goals = case_when(
      home_team != ""Japan"" ~ home_score,
      away_team != ""Japan"" ~ away_score)) %>% 
  # label results from Japan's perspective
  mutate(
    result = case_when(
      japan_goals > opp_goals ~ ""Win"",
      japan_goals < opp_goals ~ ""Loss"",
      japan_goals == opp_goals ~ ""Draw""),
    result = result %>% as_factor() %>% fct_relevel(c(""Win"", ""Draw"", ""Loss""))) %>% 
  select(-contains(""score""), -contains(""team""))
```

With all that done we can take a look at how Japan have done against certain opponents by using `filter()`.

```{r}
results_jp_asia %>% 
  filter(opponent == ""Jordan"",
         tournament == ""AFC Asian Cup"")
```

Unfortunately, this data set doesn't go into extra-time or penalty wins as Japan's Quarter-Final meeting with Jordan in 2004 ended with Japan securing a route to the semis, 4-3 on penalties! 

I can create a function that'll filter for certain opponents and tournaments and aggregate the results. With the second argument being `...`, `tidyeval` allows me to input any kind of filter condition for an opponent, tournament, etc. The `if else` statement protects against cases where Japan never had that type of result against an opponent and makes sure that a column populated by 0s is created.

```{r}
japan_versus <- function(data, ...) {
  # filter 
  filter_vars <- enquos(...)
  
  jp_vs <- data %>% 
    filter(!!!filter_vars) %>% 
    # count results type per opponent
    group_by(result, opponent) %>% 
    mutate(n = n()) %>% 
    ungroup() %>% 
    # sum amount of goals by Japan and opponent
    group_by(result, opponent) %>% 
    summarize(j_g = sum(japan_goals),
              o_g = sum(opp_goals),
              n = n()) %>% 
    ungroup() %>% 
    # spread results over multiple columns
    spread(result, n) %>% 
    # 1. failsafe against no type of result against an opponent
    # 2. sum up counts per opponent
    group_by(opponent) %>% 
    mutate(Win = if(""Win"" %in% names(.)){return(Win)} else{return(0)},
         Draw = if(""Draw"" %in% names(.)){return(Draw)} else{return(0)},
         Loss = if(""Loss"" %in% names(.)){return(Loss)} else{return(0)}) %>% 
    summarize(Win = sum(Win, na.rm = TRUE),
              Draw = sum(Draw, na.rm = TRUE),
              Loss = sum(Loss, na.rm = TRUE),
              `Goals For` = sum(j_g),
              `Goals Against` = sum(o_g))
  
  return(jp_vs)
}
```

Now let's try it out a bit.

```{r}
japan_versus(data = results_jp_asia, 
             opponent == ""China"")
```

I can put in multiple filter conditions if needed as well.

```{r}
japan_versus(data = results_jp_asia,
             home_away == ""home"",
             opponent %in% c(""Palestine"", ""Vietnam"", ""India""))
```

As you can see Japan has never lost or drawn against India, Palestine, or Vietnam so in the data there wouldn't have been any rows with ""Loss"" in the results column. With the function I created I was able to impute results that didn't exist and fill them in with 0s!

Let's check Japan's performance against our main rivals in the Asian Cup. Here I make the tables look a lot nicer with the options in the `kable` and `kableExtra` packages.

```{r, fig.align='center'}
results_jp_asia %>% 
  japan_versus(opponent %in% c(""Iran"", ""Korea Republic"", ""Saudi Arabia""),
               tournament == ""AFC Asian Cup"") %>% 
  knitr::kable(format = ""html"",
               caption = ""Japan vs. Historic Rivals in the Asian Cup"") %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c("" "", ""Result"" = 3, ""Goals"" = 2))
```

Now let's take a look at how Japan have historically played against the other teams in Group F of this year's Asian Cup.

```{r}
results_jp_asia %>% 
  japan_versus(opponent %in% c(""Oman"", ""Uzbekistan"", ""Turkmenistan"")) %>% 
  knitr::kable(format = ""html"",
               caption = ""Japan's Record vs. Group F Teams"") %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c("" "", ""Result"" = 3, ""Goals"" = 2))
```

We see no rows here for Turkmenistan. This is due to the fact that until just this past week Japan had **never** played against them in a friendly or competitive game!

# Conclusion

Although Japan's first game was quite horrible I'm hoping it'll wake the players and coaches out of their complacency and not underestimate our opponents in the next two games. 

Japan 

South Korea and Iran

thankfully south korea should be on the other side of the bracket and we would also only meet Iran in the semifinals (provided both teams finish top of their respective groups)

Japan could meet Australia in the Quarters but without Aaron Mooy they're a much weaker side as shown in their abject loss to Jordan in their opening match.

even with losing new star Nakajima, the fact that we can replace him with a player of the calibre of Takashi Inui and Hannover regular, Genki Haraguchi, stepping up from the bench shows how much Japanese football has progressed these past 25 years.

It's a changing of the guard for Japan but we've got quality players in Europe as well as some depth too with more young Japanese players headed to Europe from a young age

It was quite awe-inspiring seeing how the number of Japanese players playing for foreign clubs have been steadily increasing since the 1988 Asian Cup squad. Maybe that could be another idea for a visualization?

this tournament should be a first stepping stone for this new generation of players to make a big impact for the next world cup in 2022 so keep your eye out for this bunch of players!","2019"
"41",199,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Bundesliga 2018-2019/player_goal_contribution_matrix.Rmd","---
title: ""Bundesliga""
author: ""RN7""
date: ""5/24/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# pkgs

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

## add_logo

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))
}
```


# Bundesliga

## webscrape soccerway

```{r}
url <- ""https://us.soccerway.com/national/germany/bundesliga/20182019/regular-season/r47657/""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#page_competition_1_block_competition_tables_7_block_competition_league_table_1_table .large-link a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, NA, NA, ""team_name"", ""team_num""), sep = ""/"") %>% 
  mutate(link = glue(""
                     https://us.soccerway.com/teams/germany/{team_name}/{team_num}/squad/""),
         stat_link = glue(""{link %>% str_replace('squad', 'statistics')}""))

# for each team link:

player_name_info <- function(session) {
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#page_team_1_block_team_squad_3-table .name.large-link"") %>% 
    html_text()
}

num_goals_info <- function(session) {

  num_goals_info <- scrape(session) %>% 
    html_nodes("".goals"") %>% 
    html_text()
  
  num_goals_info_clean <- num_goals_info[-1]
}

num_assists_info <- function(session) {

  num_assists_info <- scrape(session) %>% 
    html_nodes("".assists"") %>% 
    html_text()
  
  num_assists_info_clean <- num_assists_info[-1]
}

team_goals_info <- function(session) {
  team_goals_info <- scrape(session) %>% 
    html_nodes(""tr.first:nth-child(6) > td:nth-child(2)"") %>% 
    html_text()
}

# BIG FUNCTION
bundesliga_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  bundesliga_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names) 
  
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
bundesliga_goal_contribution_df_ALL <- map2(.x = team_links_df$link,
                .y = team_links_df$stat_link,
                ~ bundesliga_stats_info(link = .x, statlink = .y))

bundesliga_goal_contribution_df <- bundesliga_goal_contribution_df_ALL %>% 
  set_names(team_links_df$team_name) %>% 
  bind_rows(.id = ""team_name"")

## save
saveRDS(bundesliga_goal_contribution_df, file = glue(""{here::here()}/data/bundesliga_goal_contrib_df_soccerway.RDS""))
```

## clean

```{r}
bundesliga_goal_contribution_clean_df <- bundesliga_goal_contribution_df %>% 
  mutate_at(.vars = c(""goals"", ""assists""), 
            ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(team = team_name %>% str_replace_all(., ""-"", "" "") %>% str_to_title,
         total_goals = as.numeric(team_goals)) %>% 
  group_by(team) %>% 
  mutate(total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         assist_contrib = assists/total_goals) %>% 
  ungroup() %>% 
  select(-team_name, -team_goals)

## save
saveRDS(bundesliga_goal_contribution_clean_df, 
        file = glue(""{here::here()}/data/bundesliga_goal_contrib_clean_df.RDS""))
bundesliga_goal_contribution_clean_df <- readRDS(file = glue(""{here::here()}/data/bundesliga_goal_contrib_clean_df.RDS""))
```

## plot

```{r fig.width = 10, fig.height = 8}  
## Description text
desc_hazard <- ""Hazard FC: With 16 goals and 15 assists Eden Hazard has been involved in the most goals for a team this season.""
desc_vardymurray <- ""Scoring 37.5% and 37.1% of their team's goals, Jamie Vardy and Glen Murray have proven to be talismans for their team yet again!""
desc_fraser <- ""Another fantastic season from Ryan Fraser with 7 goals and 14 assists (one behind league-leader Hazard)""

## PLOT!
bundesliga_goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = bundesliga_goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.225 | assist_contrib < 0.125),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = bundesliga_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.225 | assist_contrib > 0.125),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.225, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.125, color = ""grey20"", alpha = 0.4) +
  geom_text_repel(data = bundesliga_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.225 | assist_contrib > 0.125),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 15, size = 5, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  # geom_mark_circle(aes(filter = name == ""E. Hazard"", label = ""Eden Hazard"",
  #                       description = desc_hazard), 
  #                   label.family = ""Roboto Condensed"", label.fontsize = c(14, 10)) +
  # geom_mark_hull(aes(filter = name %in% c(""G. Murray"", ""J. Vardy""), label = ""Vardy & Murray"",
  #                       description = desc_vardymurray),
  #                   label.buffer = unit(20, ""mm""), label.fontsize = c(14, 10),
  #                   label.family = ""Roboto Condensed"") +
  # geom_mark_circle(aes(filter = name == ""R. Fraser"", label = ""Ryan Fraser"",
  #                       description = desc_fraser),
  #                   label.buffer = unit(9.8, ""mm""), label.fontsize = c(14, 10),
  #                   label.family = ""Roboto Condensed"") +
  scale_x_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.225)) +
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.4)) +
  labs(title = ""Goal Contribution Matrix: Bundesliga (2018-2019 Season)"",
       subtitle = ""Team Goal Involvement as Percentage of Total Club Goals and/or Assists."",
       caption = glue(""
                      Data: soccerway.com
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 18),
        plot.subtitle = element_text(size = 16),
        plot.caption = element_text(size = 10),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        panel.grid.minor.x = element_blank()) -> bundesliga_goal_contribution_matrix

bundesliga_goal_contribution_matrix
```

## save

```{r}
ggsave(plot = bundesliga_goal_contribution_matrix, 
       ""../Bundesliga 2018-2019/output/goal_contribution_matrix_plot_bundesliga.png"",
       height = 9, width = 11)
```

```{r}
plot_logo <- add_logo(
  plot_path = ""../Bundesliga 2018-2019/output/goal_contribution_matrix_plot_bundesliga.png"",
  logo_path = ""https://upload.wikimedia.org/wikipedia/en/d/df/Bundesliga_logo_%282017%29.svg"",
  logo_position = ""top right"",
  logo_scale = 13)

plot_logo
```

```{r}
image_write(image = plot_logo, 
            ""../Bundesliga 2018-2019/output/goal_contribution_matrix_plot_logo_bundesliga.png"")
```
","2018"
"42",200,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Bundesliga 2019-2020/bundesstats.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""10/12/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               understatr,
               rvest, glue, extrafont, ggrepel, magick, ggtext)
loadfonts()
```

# Bundesliga

```{r}
bundesmeta <- get_leagues_meta()
bundesliga1920 <- get_league_teams_stats(""Bundesliga"", 2019)
```

```{r}
bundesliga1920$team_name %>% 
  unique() %>% 
  str_replace_all(., "" "", ""_"")
```


```{r}
bundesliga1920 %>% 
  group_by(team_name) %>% 
  mutate(sumxPts = sum(xpts),
         sumPoints = sum(pts)) %>% 
  ungroup() %>% 
  select(team_name, sumxPts, sumPoints) %>% 
  unique() %>% 
  arrange(desc(sumxPts)) %>% 
  ggplot(aes(sumxPts, sumPoints, group = team_name)) +
  geom_point() +
  geom_text_repel(aes(label = team_name)) +
  geom_abline() +
  theme_minimal()


bundesliga1920 %>% 
  group_by(team_name) %>% 
  mutate(sumxPts = sum(xpts),
         sumPoints = sum(pts),
         games = n(),
         ppg = sumPoints / games) %>% 
  ungroup() %>% 
  select(team_name, ppg) %>% 
  unique() %>% 
  arrange(desc(ppg))

bundesliga1920 %>% 
  group_by(team_name) %>% 
  mutate(sumxPts = sum(xpts),
         sumPoints = sum(pts),
         games = n(),
         ppg = sumPoints / games,
         sumConceded = sum(missed),
         sumxGConceded = sum(npxGA),
         concededxGratio = sumConceded / sumxGConceded) %>% 
  ungroup() %>% 
  select(team_name, sumConceded, sumxGConceded, concededxGratio) %>% 
  unique() %>% 
  ggplot(aes(x = sumxGConceded, y = concededxGratio)) +
  geom_point() +
  geom_label_repel(aes(label = team_name)) +
  scale_x_reverse() +
  scale_y_reverse() + 
  theme_minimal()
```






# Eintracht Frankfurt

```{r}
frankfurtstats <- get_team_players_stats(""Eintracht Frankfurt"", 2018)
```

```{r}
glimpse(frankfurtstats)
```


```{r}
frankfurtstats %>% 
  filter(time >= 900) %>% 
  mutate(shots90 = (shots / time) * 90,
         xGperShot = xG / shots,
         xG90 = (xG/time) * 90) %>% 
  select(player_name, time, shots90, xGperShot, xG90) %>% 
  ggplot(aes(xGperShot, shots90)) +
  geom_point(aes(size = xG90)) +
  geom_text(aes(label = player_name))
```

","2019"
"43",201,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Champions League & Europa League 2019-2020/europa_league_eloRatings.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""9/1/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Packages

```{r}
pacman::p_load(tidyverse, scales, lubridate, 
               ggrepel, glue, extrafont,
               polite, rvest)
loadfonts(quiet = TRUE)
```


# Elo Ratings 8.31.19

```{r}
## Elo Ratings from 8.31.19
elo_ratings_raw <- read.csv(""http://api.clubelo.com/2019-08-31"")
```


# Europa League

## webscrape

```{r}
url <- ""https://en.wikipedia.org/wiki/2019%E2%80%9320_UEFA_Europa_League_group_stage""

session <- bow(url)

EL_teams <- scrape(session) %>% 
  html_nodes("".wikitable th+ td"") %>% 
  html_text() %>% 
  as_tibble() %>% 
  rename(team_name = value) %>% 
  mutate(team_name = team_name %>% trimws())

country_league <- scrape(session) %>% 
  html_nodes(""th+ td .thumbborder"") %>% 
  html_attr(""alt"") %>% 
  as_tibble() %>% 
  rename(country_league = value)

EL_teams_clean <- EL_teams %>% 
  bind_cols(country_league)
```

## clean

```{r}
EL_teams_df <- EL_teams_clean %>% 
  mutate(team_name = team_name %>% 
           iconv(from = ""UTF-8"", to = ""ASCII//TRANSLIT""),
         elo_name = case_when(
           team_name == ""Qarabag"" ~ ""Karabakh Agdam"",
           team_name == ""F91 Dudelange"" ~ ""Dudelange"",
           team_name == ""Copenhagen"" ~ ""FC Kobenhavn"",
           team_name == ""Malmo FF"" ~ ""Malmoe"",
           team_name == ""Krasnodar"" ~ ""FC Krasnodar"",
           team_name == ""Sporting CP"" ~ ""Sporting"",
           team_name == ""PSV Eindhoven"" ~ ""PSV"",
           team_name == ""Eintracht Frankfurt"" ~ ""Frankfurt"",
           team_name == ""Standard Liege"" ~ ""Standard"",
           team_name == ""Vitoria de Guimaraes"" ~ ""Guimaraes"",
           team_name == ""CSKA Moscow"" ~ ""CSKA Moskva"",
           team_name == ""Ludogorets Razgrad"" ~ ""Razgrad"",
           team_name == ""Ferencvaros"" ~ ""Ferencvaros"",
           team_name == ""VfL Wolfsburg"" ~ ""Wolfsburg"",
           team_name == ""KAA Gent"" ~ ""Gent"",
           team_name == ""Saint-Etienne"" ~ ""Saint-Etienne"",
           team_name == ""Oleksandriya"" ~ ""Olexandriya"",
           team_name == ""Borussia Monchengladbach"" ~ ""Gladbach"",
           team_name == ""Istanbul Basaksehir"" ~ ""Bueyueksehir"",
           team_name == ""Wolfsberger AC"" ~ ""Wolfsberg"",
           team_name == ""Besiktas"" ~ ""Besiktas"",
           team_name == ""Wolverhampton Wanderers"" ~ ""Wolves"",
           team_name == ""Manchester United"" ~ ""Man United"",
           team_name == ""Astana"" ~ ""FK Astana"",
           team_name == ""AZ"" ~ ""Alkmaar"",
           TRUE ~ team_name
         )) %>% 
  ## join Club info to Elo data
  left_join(elo_ratings_raw, by = c(""elo_name"" = ""Club"")) %>% 
  janitor::clean_names() %>% 
  select(-level, -from, -to, -elo_name) %>% 
  ## fill out group names per 4 rows
  mutate(group = rep(LETTERS[1:12], each = 4, length.out = 48) %>% 
           as.factor()) %>% 
  ## per group stats
  group_by(group) %>% 
  mutate(avg_elo = mean(elo),
         med_elo = median(elo),
         max_elo = max(elo),
         min_elo = min(elo)) %>% 
  ungroup() %>% 
  ## manually change names
  ## manually spread out the labels
  mutate(
    team_name = case_when(
      team_name == ""Wolverhampton Wanderers"" ~ ""Wolves"",
      team_name == ""PSV Eindhoven"" ~ ""PSV"",
      team_name == ""Borussia Monchengladbach"" ~ ""Gladbach"",
      team_name == ""Sporting CP"" ~ ""Sporting"",
      team_name == ""Vitoria de Guimaraes"" ~ ""Vitoria S.C."",
      TRUE ~ team_name),
    elo_2 = case_when(
      team_name == ""CFR Cluj"" ~ elo - 10,
      team_name == ""Sporting"" ~ elo + 10,
      team_name == ""PSV"" ~ elo - 10,
      team_name == ""Braga"" ~ elo + 10,
      team_name == ""Besiktas"" ~ elo - 10,
      team_name == ""AZ"" ~ elo + 10,
      team_name == ""Partizan"" ~ elo - 5,
      TRUE ~ elo),
    group = forcats::fct_reorder(group, med_elo))
```


## plot

```{r, fig.height = 7, fig.width=15}
EL_teams_df %>% 
  ggplot(aes(x = group, y = elo, group = group)) +
  geom_segment(aes(x = group, xend = group,
                   y = max_elo, yend = min_elo,
                   group = group),
               size = 2.25, color = ""lightgrey"") +
  geom_point(aes(y = med_elo, group = group),
             size = 4.5, color = ""red"") +
  geom_text(aes(y = elo_2, label = team_name), 
            vjust = 0.5,
            size = 4.5, family = ""Roboto Condensed"",
            show.legend = FALSE) +
  geom_curve(aes(x = 12.8, xend = 12.1, 
                 y = 1675, yend = 1675),
             arrow = arrow(length = unit(0.07, ""inch"")), 
             size = 0.5, color = ""black"", curvature = 0.35) +
  geom_text(x = 12.85, y = 1675,
            hjust = 0, color = ""red"",
            family = ""Roboto Condensed"",
            size = 4,
            label = glue::glue(""
                               Median ELO 
                               (per group)"")) +
  scale_x_discrete(expand = expand_scale(add = c(0.5, 1.75))) +
  labs(title = ""Europa League (2019/2020) Elo Ratings"",
       subtitle = ""Ratings as of August 31st, 2019"",
       x = ""Group (Ordered by Median Elo Rating per Group)"", y = ""Elo Rating"",
       caption = ""@R_by_Ryo                                                                                                                                                                                                                                                                            Source: ClubElo.com"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 22),
        plot.subtitle = element_text(size = 18),
        plot.caption = element_text(size = 14, hjust = 0),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14))
```


```{r}
ggsave(filename = here::here(
  ""Champions League & Europa League 2019-2020/outputs/euroleague_eloPlot2.png""),
  width = 15, height = 7)
```



# Champions League

## webscrape

```{r}
url2 <- ""https://en.wikipedia.org/wiki/2019%E2%80%9320_UEFA_Champions_League_group_stage""

session2 <- bow(url2)

CL_teams <- scrape(session2) %>% 
  html_nodes(""h3+ .wikitable .flagicon+ a"") %>% 
  html_text() %>% 
  as_tibble() %>% 
  rename(team_name = value) %>% 
  mutate(team_name = team_name %>% trimws())

country_leagueCL <- scrape(session2) %>% 
  html_nodes(""h3+ .wikitable .thumbborder"") %>% 
  html_attr(""alt"") %>% 
  as_tibble() %>% 
  rename(country_league = value)

CL_teams_clean <- CL_teams %>% 
  bind_cols(country_leagueCL)
```


## clean

```{r}
CL_teams_df <- CL_teams_clean %>% 
  mutate(
    team_name = team_name %>% 
      iconv(from = ""UTF-8"", to = ""ASCII//TRANSLIT""),
    elo_name = case_when(
      team_name == ""Paris Saint-Germain"" ~ ""Paris SG"",
      team_name == ""Club Brugge"" ~ ""Brugge"",
      team_name == ""Bayern Munich"" ~ ""Bayern"",
      team_name == ""Tottenham Hotspur"" ~ ""Tottenham"",
      team_name == ""Olympiacos"" ~ ""Olympiakos"",
      team_name == ""Red Star Belgrade"" ~ ""Crvena Zvezda"",
      team_name == ""Manchester City"" ~ ""Man City"",
      team_name == ""Shakhtar Donetsk"" ~ ""Shakhtar"",
      team_name == ""Atletico Madrid"" ~ ""Atletico"",
      team_name == ""Bayer Leverkusen"" ~ ""Leverkusen"",
      team_name == ""Lokomotiv Moscow"" ~ ""Lok Moskva"",
      team_name == ""Red Bull Salzburg"" ~ ""Salzburg"",
      team_name == ""Borussia Dortmund"" ~ ""Dortmund"",
      team_name == ""Inter Milan"" ~ ""Inter"",
      team_name == ""Slavia Prague"" ~ ""Slavia Praha"",
      team_name == ""Zenit Saint Petersburg"" ~ ""Zenit"",
      TRUE ~ team_name)) %>% 
  ## join Club info to Elo data
  left_join(elo_ratings_raw, by = c(""elo_name"" = ""Club"")) %>% 
  janitor::clean_names() %>% 
  select(-level, -from, -to, -elo_name) %>% 
  ## fill out group names per 4 rows
  mutate(group = rep(LETTERS[1:12], each = 4, length.out = 32) %>% 
           as.factor()) %>% 
  ## per group stats
  group_by(group) %>% 
  mutate(avg_elo = mean(elo),
         med_elo = median(elo),
         max_elo = max(elo),
         min_elo = min(elo)) %>% 
  ungroup() %>% 
  mutate(group = forcats::fct_reorder(group, med_elo),
         elo_2 = case_when(
           team_name == ""RB Leipzig"" ~ elo + 10,
           team_name == ""Benfica"" ~ elo - 10,
           team_name == ""Shakhtar"" ~ elo + 10,
           team_name == ""Atalanta"" ~ elo - 10,
           TRUE ~ elo))
```


## plot

```{r, fig.height = 7, fig.width=15}
CL_teams_df %>% 
  ggplot(aes(x = group, y = elo, group = group)) +
  geom_segment(aes(x = group, xend = group,
                   y = max_elo, yend = min_elo,
                   group = group),
               size = 2.25, color = ""lightgrey"") +
  geom_point(aes(y = med_elo, group = group),
             size = 4.5, color = ""red"") +
  geom_text(aes(y = elo_2, label = team_name), 
            #nudge_y = 10,
            vjust = 0.5,
            size = 4.5, family = ""Roboto Condensed"",
            show.legend = FALSE) +
  geom_curve(aes(x = 8.8, xend = 8.1, 
                 y = 1825, yend = 1825),
             arrow = arrow(length = unit(0.07, ""inch"")), 
             size = 0.5, color = ""black"", curvature = 0.35) +
  geom_text(x = 8.85, y = 1825,
            hjust = 0, color = ""red"",
            family = ""Roboto Condensed"",
            size = 4,
            label = glue::glue(""
                               Median ELO 
                               (per group)"")) +
  scale_x_discrete(expand = expand_scale(add = c(0.5, 1.35))) +
  labs(title = ""Champions League (2019/2020) Elo Ratings"",
       subtitle = ""Ratings as of August 31st, 2019"",
       x = ""Group (Ordered by Median Elo Rating per Group)"", 
       y = ""Elo Rating"",
       caption = ""@R_by_Ryo                                                                                                                                                                                                                                                                            Source: ClubElo.com"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 22),
        plot.subtitle = element_text(size = 18),
        plot.caption = element_text(size = 14, hjust = 0),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14))
```



```{r}
ggsave(filename = here::here(
  ""Champions League & Europa League 2019-2020/outputs/champleague_eloPlot2.png""),
  width = 15, height = 7)
```





```{r}
top3_teams <- CL_teams_df %>% 
  group_by(group) %>% 
  arrange(desc(elo), .by_group = TRUE) %>% 
  mutate(group_rank = row_number()) %>% 
  filter(group_rank != 4) %>% 
  group_by(group) %>% 
  summarize(avg_top3_elo = mean(elo),
            med_top3_elo = median(elo),
            max_top3_elo = max(elo),
            min_top3_elo = min(elo))

CL_top3_df <- CL_teams_df %>% 
  left_join(top3_teams, by = ""group"")
```




```{r, fig.height = 7, fig.width=15}
CL_top3_df %>% 
  mutate(group = forcats::fct_reorder(group, med_top3_elo)) %>% 
  ggplot(aes(x = group, y = elo, group = group)) +
  geom_segment(aes(x = group, xend = group,
                   y = max_top3_elo, yend = min_top3_elo,
                   group = group),
               size = 2.25, color = ""lightgrey"") +
  geom_point(aes(y = med_top3_elo, group = group),
             size = 4.5, color = ""red"") +
  geom_text(aes(y = elo_2, label = team_name), 
            vjust = 0.5,
            size = 4.5, family = ""Roboto Condensed"",
            show.legend = FALSE) +
  geom_segment(aes(x = 8.6, xend = 8.05, 
                 y = 1840, yend = 1875),
             arrow = arrow(length = unit(0.09, ""inch"")), 
             size = 0.5, color = ""black"") +
  geom_text(x = 8.65, y = 1840,
            hjust = 0, color = ""red"",
            family = ""Roboto Condensed"",
            size = 4,
            label = glue::glue(""
                               Median ELO 
                               (per group)"")) +
  scale_x_discrete(expand = expand_scale(add = c(0.5, 1.35))) +
  labs(title = ""Champions League (2019/2020) Elo Ratings"",
       subtitle = ""Ratings as of August 31st, 2019 | Median of Top Three Teams per Group"",
       x = ""Group (Ordered by Median Elo Rating per Group)"", 
       y = ""Elo Rating"",
       caption = ""@R_by_Ryo                                                                                                                                                                                                                                                                            Source: ClubElo.com"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 22),
        plot.subtitle = element_text(size = 18),
        plot.caption = element_text(size = 14, hjust = 0),
        axis.title = element_text(size = 16),
        axis.text = element_text(size = 14))
```


```{r}
ggsave(filename = here::here(
  ""Champions League & Europa League 2019-2020/outputs/champleague_top3_eloPlot.png""),
  width = 15, height = 7)
```














","2019"
"44",202,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Copa America 2019/copa_america2019.rmd","---
title: ""Visualizing the Copa Amrica: Historical Records, Squad Profiles, and Player Profiles with xG statistics!""
always_allow_html: yes
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce, ggtextures, DT, 
               cowplot, rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

Another summer and another edition of the Copa Amrica! Along with the Africa Cup of Nations, Nations League finals, the Women's World Cup, Under-21 European Championship AND the Gold Cup this is yet another soccer-filled season after last year's World Cup and the Asian Cup earlier this year (I also did a blog post on these last two tournaments which you can see [here (World Cup)](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/) and [here (Asian Cup)](https://ryo-n7.github.io/2019-01-11-visualize-asian-cup/)). There is so much football going on at once even I can't keep up, especially with the time difference! To not redo all the previous visualizations with Copa Amrica data I tried to find new sources of data and other forms of visualizations to give some insight into the players and teams competing to be the champion of South America. You can find all the code I used in this blogpost here and you can also find other soccer related data viz in my [soccer_ggplot](https://github.com/Ryo-N7/soccer_ggplots) Github repo. 

The sections will go from a very macro-level view of the __historical records__ of the tournament, to the __squads__ competing, the teams' __match record__ in the Copa Amrica, and finally to a micro-level view of various attacking players using __xG__ statistics.

Vmonos!

## Packages

```{r eval=FALSE, message=FALSE, warning=FALSE}
library(dplyr)        ## data wrangling
library(tidyr)        ## data wrangling
library(purrr)        ## data wrangling and iteration
library(stringr)      ## data wrangling
library(rvest)        ## webscraping
library(polite)       ## webscraping (Github only pkg)
library(ggplot2)      ## plotting
library(scales)       ## plotting scales
library(ggimage)      ## images for flags
library(ggforce)      ## plotting text labels
library(cowplot)      ## plotting grid
library(glue)         ## text
library(ggrepel)      ## plotting text labels
library(magick)       ## plotting
library(DT)           ## tables
library(ggtextures)   ## soccer ball emoji as geom_col()
library(extrafont)    ## fonts: Roboto Condensed

loadfonts()
```

## theme_copaAmerica

I wanted to have all the plots in this blogpost to have a consistent color theme. As the tournament is going to be held in Brazil, I went with a color theme based on its flag with blue, yellow, and green being the primary colors.

```{r}
theme_copaAmerica <- function(
  title.size = 24,
  subtitle.size = 14,
  caption.size = 8,
  axis.text.size = 14,
  axis.text.x.size = 12,
  axis.text.y.size = 12,
  axis.title.size = 16,
  strip.text.size = 18,
  panel.grid.major.x = element_line(size = 0.5, color = ""white""),
  panel.grid.major.y = element_line(size = 0.5, color = ""white""),
  panel.grid.minor.x = element_blank(),
  panel.grid.minor.y = element_blank(),
  axis.ticks = element_line(color = ""white"")) {
  ## Theme:
  theme(text = element_text(family = ""Roboto Condensed"", color = ""white""),
        plot.title = element_text(family = ""Roboto Condensed"", face = ""bold"", 
                                  size = title.size, color = ""yellow""),
        plot.subtitle = element_text(size = subtitle.size),
        plot.caption = element_text(size = caption.size),
        panel.background = element_rect(fill = ""#009b3a""),
        plot.background = element_rect(fill = ""#002776""),
        axis.text = element_text(size = axis.text.size, color = ""white""),
        axis.text.x = element_text(size = axis.text.x.size, color = ""white""),
        axis.text.y = element_text(size = axis.text.y.size, color = ""white""),
        axis.title = element_text(size = axis.title.size),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        panel.grid.major.x = panel.grid.major.x,
        panel.grid.major.y = panel.grid.major.y,
        panel.grid.minor.x = panel.grid.minor.x,
        panel.grid.minor.y = panel.grid.minor.y,
        strip.text = element_text(color = ""yellow"", face = ""bold"", 
                                  size = strip.text.size, 
                                  margin = margin(4.4, 4.4, 4.4, 4.4)),
        strip.background = element_blank(),
        axis.ticks = axis.ticks
        )
}
```

## Top Goal Scorers // Goleadores

For this plot I took the stats from the Spanish version of the Wikipedia page as it had more content. I used `purrr::flatten_df()` to squish the list output into a dataframe then set the names of each column using `purrr::set_names()`.

```{r, eval=FALSE}
url <- ""https://es.wikipedia.org/wiki/Anexo:Estad%C3%ADsticas_de_la_Copa_Am%C3%A9rica""

session <- bow(url)

copa_top_scorers <- scrape(session) %>% 
  html_nodes("".mw-parser-output > table:nth-child(95)"") %>% 
  html_table() %>% 
  flatten_df() %>% 
  set_names(c(""player"", ""country"", ""goals"")) %>% 
  mutate(image = ""https://www.emoji.co.uk/files/microsoft-emojis/activity-windows10/8356-soccer-ball.png"")
```

```{r, eval=FALSE, echo=FALSE}
saveRDS(copa_top_scorers, file = here::here(""data/copa_top_scorers.RDS""))
```

```{r, echo=FALSE}
copa_top_scorers <- readRDS(file = here::here(""data/copa_top_scorers.RDS""))
```

```{r}
glimpse(copa_top_scorers)
```

Like in the Asian Cup blogpost I use [Claus Wilke](https://twitter.com/ClausWilke/)'s [ggtextures](https://github.com/clauswilke/ggtextures) package to use __soccer ball emoji__ as the column image in the plot.

```{r, fig.height = 8, fig.width = 10}
copa_goleadores_raw_plot <- copa_top_scorers %>% 
  head(5) %>% 
  ggplot(aes(x = reorder(player, goals), y = goals,
             image = image)) +
  geom_isotype_col(img_width = grid::unit(1, ""native""), img_height = NULL,
    ncol = NA, nrow = 1, hjust = 0, vjust = 0.5) +
  geom_text(aes(label = goals, family = ""Roboto Condensed"", fontface = ""bold""), 
            size = 7.5, color = ""yellow"",
            nudge_y = 0.5) +
  coord_flip() +
  scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16, 18),
                     expand = c(0, 0), 
                     limits = c(0, 19)) +
  labs(title = ""Top Scorers of the Copa Amrica"",
       subtitle = glue(""
                       Most goals in a single tournament: 9 
                       Humberto Maschio (Argentina), Javier Ambrois (Uruguay), Jair (Brazil)""),
       y = ""Number of Goals"", x = NULL,
       caption = glue(""
                      Source: Wikipedia
                      By @R_by_Ryo"")) +
  theme_copaAmerica(title.size = 26,
                    subtitle.size = 16,
                    caption.size = 12,
                    axis.text.size = 18,
                    axis.title.size = 18,
                    panel.grid.major.y = element_blank(),
                    axis.ticks = element_blank())

## Add flags to y-axis:
axis_image <- axis_canvas(copa_goleadores_raw_plot, axis = 'y') + 
  draw_image(""https://upload.wikimedia.org/wikipedia/en/0/05/Flag_of_Brazil.svg"", 
             y = 16.5, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/1/1a/Flag_of_Argentina.svg"", 
             y = 12.5, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/f/fe/Flag_of_Uruguay.svg"", 
             y = 9, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/d/df/Flag_of_Peru_%28state%29.svg"", 
             y = 5.25, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/0/05/Flag_of_Brazil.svg"", 
             y = 1.5, scale = 1.8)

copa_goleadores_plot <- ggdraw(insert_yaxis_grob(copa_goleadores_raw_plot, axis_image, position = ""left""))
copa_goleadores_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = copa_goleadores_plot, filename = here::here(""Copa America 2019/output/copa_goleadores_plot.png""),
       height = 8, width = 10)
```

Most of these players aren't ones you might recognize. The Copa Amrica used to be held a lot more regularly (and sometimes erratically) until this century so players had a lot more opportunities to score goals. All five of the players you see here played in the 1930s-1950s when there was a tournament every one or two years. Out of currently active players, Peruvian legend Paolo Guerrero has 11 goals along with Eduardo Vargas (from Chile). (Edit: after the Chile - Japan game, Vargas is on 12...) Another player you might recognize that was actually tied with Ademir for 5th place, along with three other players, was Gabriel Batistuta (""Batigol"").

## Winners of the Copa Amrica

After grabbing the data from the Wikipedia page I used a variety of functions to clean and reshape the dataset like `tidyr::separate()` to split the number of occurences and the year.

```{r, warning=FALSE, eval=FALSE}
url <- ""https://es.wikipedia.org/wiki/Anexo:Estad%C3%ADsticas_de_la_Copa_Am%C3%A9rica""

session <- bow(url)

copa_campeones <- scrape(session) %>% 
  html_nodes("".mw-parser-output > table:nth-child(10)"") %>% 
  html_table() %>% 
  flatten_df()

copa_campeones_limpia <- copa_campeones %>% 
  janitor::clean_names() %>% 
  slice(1:8) %>% 
  select(1:4) %>% 
  set_names(c(""team"", ""winners"", ""runners_up"", ""third_place"")) %>% 
  separate(winners, into = c(""Champions"", ""first_place_year""), 
           sep = "" "", extra = ""merge"") %>% 
  separate(runners_up, into = c(""Runners-up"", ""second_place_year""), 
           sep = "" "", extra = ""merge"") %>% 
  separate(third_place, into = c(""Third Place"", ""third_place_year""), 
           sep = "" "", extra = ""merge"") %>% 
  mutate_all(list(~str_replace_all(., """", ""0""))) %>% 
  mutate_at(vars(contains(""num"")), funs(as.numeric)) %>% 
  gather(key = ""key"", value = ""value"", -team, 
         -first_place_year, -second_place_year, -third_place_year) %>% 
  mutate(key = as.factor(key),
         value = as.numeric(value),
         team = team %>% str_replace(., ""[A-Z]{3}"", """") %>% str_trim(.),
         team = case_when(team == ""Brasil"" ~ ""Brazil"",
                          TRUE ~ team)) %>% 
  mutate(key = forcats::fct_relevel(key, 
                                    ""Champions"",
                                    ""Runners-up"",
                                    ""Third Place"")) %>% 
  arrange(key, desc(value)) %>% 
  mutate(team = forcats::as_factor(team),
         order = row_number())
```

```{r, eval=FALSE, echo=FALSE}
saveRDS(copa_campeones_limpia, file = here::here(""data/copa_campeones_clean.RDS""))
```

```{r, echo=FALSE}
copa_campeones_limpia <- readRDS(file = here::here(""data/copa_campeones_clean.RDS""))
```

I also wanted to add flags to this plot but `cowplot::insert_yaxis_grob()` is unfortunately not compatible with facets. I used `stringr::str_wrap()` to format the subtitle nicely while I used `glue::glue()` to avoid having the use '\n' to create a new line for the caption.

```{r, fig.height = 6, fig.width = 8}
copa_ganadores_plot <- copa_campeones_limpia %>% 
  ggplot(aes(value, forcats::fct_rev(team), color = key)) +
  geom_point(size = 10) +        # 10
  geom_text(aes(label = value), 
            size = 5, color = ""black"",    # 5 
            family = ""Roboto Condensed"", fontface = ""bold"") +
  scale_color_manual(values = c(""Champions"" = ""#FFCC33"",
                                ""Runners-up"" = ""#999999"",
                                ""Third Place"" = ""#CC6600""),
                     guide = FALSE) +
  scale_x_continuous(breaks = c(1, 5, 10, 15),
                     labels = c(1, 5, 10, 15),
                     limits = c(-1, 16)) +
  labs(x = ""Number of Occurrence"", y = NULL,
       title = ""Most Successful Teams of the Copa Amrica!"",
       subtitle = str_wrap(""Ordered by number of Copa Amrica(s) won. Argentina missed the chance to leapfrog Uruguay after consecutive final losses in the previous two tournaments!"", width = 80),
       caption = glue(""
                      Source: Wikipedia
                      By @R_by_Ryo"")) +
  facet_wrap(~key) +
  theme_copaAmerica(subtitle.size = 14, 
                    caption.size = 10)

copa_ganadores_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(filename = here::here(""Copa America 2019/output/copa_ganadores_plot.png""),
       height = 6, width = 8)
```

What's surprising to note is that Pele never won a Copa Amrica with Brazil, although he did get Best Player and Top Scorer in the 1959 edition of the tournament. Even more bizarrely Diego Maradona has never won it either! He didn't play in either of the 1991 and 1993 editions where Argentina won their 13th and 14th Copas.

## Copa Amrica Squad Profiles

We just looked at what happened in the past but who are the players competing in the tournament this year? To take a quick look I web-scraped the squads of each of the competing teams from Wikipedia.

I created a list of the `xpath`s for each of squads and using `purrr::map()` I grabbed the data for each participating country. After I got some meta-information about the country name and the group I created a list-column that stores the squad data as a dataframe in its own column. To explode this out I used `tidyr::unnest()` to reshape the entire dataframe to have one row with all the data for each player in every squad.

```{r, eval=FALSE, echo=FALSE}
squad_url <- ""https://en.wikipedia.org/wiki/2019_Copa_Am%C3%A9rica_squads""

session <- bow(squad_url)

xpaths <- 1:12 %>% 
  map(., ~glue(""//*[@id='mw-content-text']/div/table[{.x}]""))

squads_df_raw <- scrape(session) %>% 
  html_node(xpath = '//*[@id=""toc""]') %>%  
  html_text() %>% 
  str_split(""\n"") %>% 
  unlist() %>% 
  tibble::enframe() %>% 
  rename(country = value) %>% 
  filter(str_detect(country, ""^[1-8]\\.""), !str_detect(country, ""Group"")) %>% 
  separate(country, c(""group"", ""delete"", ""country""), sep = c(1, 3)) %>% 
  slice(1:12) %>% 
  mutate(group = LETTERS[as.numeric(group)], 
         country = str_trim(country), 
         xpaths = xpaths,
         squads = map(xpaths, ~ scrape(session) %>% 
                        html_node(xpath = .x) %>% 
                        html_table())) %>% 
  unnest(squads) %>%
  filter(Player != """") %>% 
  mutate(country_league = scrape(session) %>% 
           html_nodes("".nat-fs-player .thumbborder"") %>% 
           html_attr(""alt""))
```

```{r, eval=FALSE, echo=FALSE}
saveRDS(squads_df_raw, file = here::here(""data/copa_america2019_squads_raw.RDS""))
```

```{r, echo=FALSE}
squads_df_raw <- readRDS(file = here::here(""data/copa_america2019_squads_raw.RDS""))
```

To get a clean dataset I use some `stringr::str_*()` functions to properly format the character strings such as the player positions, ages, date of births. 

```{r}
squads_df_clean <- squads_df_raw %>% 
  janitor::clean_names() %>% 
  select(-delete, squad_num = no, 
         position = pos, birth_age = date_of_birth_age) %>% 
  mutate(position = position %>% str_replace_all(., ""[1-9]"", """"),
         birth_age = birth_age %>% str_extract_all(., pattern = ""\\([^()]+\\)"")) %>%   unnest(birth_age) %>% 
  group_by(player) %>% 
  mutate(colnum = seq_along(player)) %>% 
  spread(key = colnum, value = birth_age) %>% 
  ungroup() %>% 
  select(everything(), dob = `1`, age = `2`) %>% 
  mutate(dob = dob %>% str_replace_all(., ""[()]"", """") %>% lubridate::as_date(),
         age = age %>% str_extract(., ""[0-9]+"") %>% as.integer,
         country = forcats::fct_relevel(country, 
                                    ""Brazil"", ""Argentina"", ""Uruguay"", 
                                    ""Peru"", ""Qatar"", ""Chile"",  
                                    ""Venezuela"", ""Paraguay"", ""Japan"", 
                                    ""Bolivia"", ""Colombia"", ""Ecuador"",
                                    ),
         club = case_when(
           club == ""Barcelona"" & country == ""Ecuador"" ~ ""Barcelona (Ecuador)"",
           TRUE ~ club))
```

```{r, eval=FALSE, echo=FALSE}
saveRDS(squads_df_clean, file = here::here(""data/copa_america2019_squads_clean.RDS""))
```

```{r, echo=FALSE}
squads_df_clean <- readRDS(file = here::here(""data/copa_america2019_squads_clean.RDS""))
```

```{r}
glimpse(squads_df_clean)
```

### Age-histogram

Using this data I can plot a bunch of histograms:

```{r, fig.height = 8, fig.width = 8}
age_country_plot <- squads_df_clean %>% 
  group_by(country) %>% 
  mutate(median_age = median(age)) %>% 
  ungroup() %>% 
  ggplot(aes(x = age)) +
  geom_histogram(fill = ""red"", binwidth = 1) +
  geom_vline(aes(xintercept = median_age), size = 1.2) +
  geom_label(aes(x = median_age, y = 8, 
                label = glue::glue(""Median: {median_age}"")),
            nudge_x = 0.5, hjust = 0.1, size = 3,
            family = ""Roboto Condensed"", color = ""black"") +
  labs(title = ""Age Distribution of Copa Amrica squads"",
       subtitle = ""Columns ordered Group A to Group C"",
       x = ""Age"", y = NULL,
       caption = glue::glue(""
                            Source: Wikipedia
                            By: @R_by_Ryo"")) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0),
                     breaks = scales::pretty_breaks()) +
  theme_copaAmerica(title.size = 22,
                    subtitle.size = 14, 
                    caption.size = 8,
                    axis.text.size = 12,
                    axis.title.size = 16,
                    strip.text.size = 18,
                    panel.grid.minor.x = element_line(color = ""white""),
                    panel.grid.minor.y = element_line(color = ""white"")) +
  facet_wrap(~country, ncol = 3)
  
age_country_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = age_country_plot, filename = here::here(""Copa America 2019/output/age_country_plot.png""),
       height = 8, width = 8)
```

In terms of age, Japan have the youngest team with a median of 21, 4 years younger than the next youngest team, Qatar. The rest have a fairly balanced spread of ages from 20 to early-mid 30s with most of the medians hovering around 27 years of age. The reason for Japan's extremely young squad is due to the fact that the full-strength Japan team has played in both the World Cup and the Asian Cup in the past year. Along with the fact that the Tokyo Olympics are next year, it was decided to use the invitation to the Copa Amrica as a trial-by-fire for the young stars of the future. Much like in a real Olympic squad, the team contains three ""overage"" players in World Cup 2010/2014/2018 goalkeeper Eiji Kawashima, Premier League winner Shinji Okazaki, and Getafe playmaker Gaku Shibasaki.

The oldest player will be Brazil captain Dani Alves at 36 with Paraguay's Oscar Cardozo only two weeks younger. On the other hand, the youngest player is Japan's 18-year old prodigy Takefusa Kubo, the ex-Barcelona youth player who only just recently moved to Real Madrid! In light of his transfer a lot of eyes will be on him to see if he can produce some Captain Tsubasa-esque performances for a very inexperienced Japan team gearing up for the Tokyo Olympics!

### Caps histogram

When considering the experience of a squad it's not enough to look at ages but one needs to look at the caps or appearances for the national team as well.

```{r, fig.height = 8, fig.width = 8}
caps_country_plot <- squads_df_clean %>% 
  group_by(country) %>% 
  mutate(median_cap = median(caps)) %>% 
  ungroup() %>% 
  ggplot(aes(x = caps)) +
  geom_histogram(fill = ""red"", binwidth = 5) +
  geom_vline(aes(xintercept = median_cap), size = 1.25) +
  geom_label(aes(x = median_cap, y = 15, 
                label = glue::glue(""Median: {median_cap}"")),
            nudge_x = 0.5, hjust = 0.05, size = 3,
            family = ""Roboto Condensed"", color = ""black"") +
  labs(title = ""Caps (Appearances) by Country"", 
       subtitle = ""Columns ordered Group A to Group C"",
       x = ""Caps"", y = NULL,
       caption = glue::glue(""
                            Source: Wikipedia
                            By: @R_by_Ryo"")) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_copaAmerica(
    title.size = 20,
    subtitle.size = 14, 
    caption.size = 10,
    axis.text.size = 10,
    axis.title.size = 16,
    strip.text.size = 18,
    panel.grid.major.x = element_line(color = ""white"", size = 0.25),
    panel.grid.major.y = element_line(color = ""white"", size = 0.25),
    panel.grid.minor.x = element_line(color = ""white"", size = 0.25),
    panel.grid.minor.y = element_line(color = ""white"", size = 0.25)) +
  facet_wrap(~country, ncol = 3)

caps_country_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = caps_country_plot, filename = here::here(""Copa America 2019/output/caps_country_plot.png""),
       height = 8, width = 8)
```

The majority of Japan's squad have 0 (ZERO) caps, with the aforementioned three ""overage"" players taking up most of the proportion of caps on the team. Bolivia are also taking a untested squad with 8 of their players with 2 caps or less! Chile, Uruguay, and Argentina bring their veterans with multiple players over or around 100 caps. From this data I was surprised that Jefferson Farfan and Paolo Guerrero didn't have 100 caps by now...

The player with the most caps is Lionel Messi (130) followed closely by Diego Godin (126), and Alexis Sanchez (124). On the other hand there are 29 players hopeful of making their first national team appearance at this tournament with the majority (17 players) coming from Japan.

### Goal distribution

Next I looked at the distribution of goals scored by the midfielders and strikers of each team. I found out about using `ggplot2::position_nudge()` for slightly adjusting variables on a discrete scale in similar fashion to the `nudge_y =` and `nudge_x =` arguments most people might be familiar with from other geoms. I also used `ggforce::geom_mark_hull()` to do some labelling.

```{r, fig.height = 6, fig.width = 8}
goals_country_plot <- squads_df_clean %>% 
  filter(position %in% c(""MF"", ""FW"")) %>% 
  group_by(country) %>% 
  mutate(median = median(goals)) %>% 
  ungroup() %>% 
  ggplot(aes(x = goals, y = reorder(country, median))) +
  ggridges::geom_density_ridges(fill = ""red"", color = ""white"", scale = 1.1) +
  geom_point(aes(x = median, y = country), position = position_nudge(y = 0.25),
             color = ""yellow"", size = 3) +
  ggforce::geom_mark_hull(aes(filter = country == ""Argentina"" & goals == 67, label = ""Lionel Messi: 67 goals""),
                          label.buffer = unit(15, ""mm""), label.fontsize = 10, label.fill = ""red"",
                          label.family = ""Roboto Condensed"", label.colour = ""white"",
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""Uruguay"" & goals == 55, label = ""Luis Suarez: 55 goals""),
                          label.buffer = unit(5, ""mm""), label.fontsize = 10, label.fill = ""red"",
                          label.family = ""Roboto Condensed"", label.colour = ""white"",
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""Japan"" & goals == 50, label = ""Shinji Okazaki: 50 goals""),
                          label.buffer = unit(2, ""mm""), label.fontsize = 10, label.fill = ""red"",
                          label.family = ""Roboto Condensed"", label.colour = ""white"",
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""Uruguay"" & goals == 46, label = ""Edinson Cavani: 46 goals""),
                          label.buffer = unit(25, ""mm""), label.fontsize = 10, label.fill = ""red"",
                          label.family = ""Roboto Condensed"", label.colour = ""white"",
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""Chile"" & goals == 41, label = ""Alexis Sanchez: 41 goals""),
                          label.buffer = unit(4, ""mm""), label.fontsize = 10, label.fill = ""red"",
                          label.family = ""Roboto Condensed"", label.colour = ""white"",
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  scale_x_continuous(limits = c(0, 73),
                     expand = c(0.01, 0.01),
                     breaks = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70),
                     labels = c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70)) +
  expand_limits(y = 13.5) +
  labs(title = ""Distribution of Goals Scored by Midfielders and Strikers"",
       subtitle = ""Copa Amrica 2019 squads, Yellow dot = Median goals"",
       x = ""Goals"", y = NULL,
       caption = glue::glue(""
                            Source: Wikipedia
                            Data from prior to start of tournament
                            By: @R_by_Ryo"")) +
  theme_copaAmerica(title.size = 18,
                    subtitle.size = 12, 
                    caption.size = 8,
                    axis.text.size = 14,
                    axis.title.size = 16,
                    strip.text.size = 18) 

goals_country_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = goals_country_plot, filename = here::here(""Copa America 2019/output/goals_country_plot.png""),
       height = 6, width = 8)
```

With a lot of these players being more defensively minded or new players the distribution is heavily skewed but you can see little mounds showing the top goalscorers for each country and see which countries have their goalscorers spread out among multiple players such as Brazil, Qatar, and Peru.

If you know your South American players you can take a good guess at who are the top goal scorers for each nation. For Colombia the two outlying mounds are obviously James Rodriguez and Falcao, for example. Venezuela's top scorer with 22 is Salomon Rondon and for Brazil, if not for his injury, a lonesome mound would have appeared for Neymar with 60 goals!

### Player contribution by league

Now let's check the player contribution to the squads at the Copa Amrica by league. I'm just going to use the country that the league is from for simplicity's sake. Originally I wanted to `left_join()` it with a 'country <> domestic league' table but couldn't find one and the league names itself aren't very meaningful or have awful sponsor names that obfuscate the country of origin even further. 

```{r, fig.height = 7, fig.width = 8}
player_contrib_league_plot <- squads_df_clean %>% 
  group_by(country_league) %>%
  summarize(n = n()) %>%
  ungroup() %>% 
  ggplot(aes(y = n, x = reorder(country_league, n))) +
  geom_col(fill = ""red"") +
  geom_text(aes(label = n, family = ""Roboto Condensed"", fontface = ""bold""), 
            size = 4.5, color = ""yellow"",
            nudge_y = 0.5) +
  coord_flip() +
  scale_y_continuous(labels = c(0, 5, 10, 15, 20, 25),
                     breaks = c(0, 5, 10, 15, 20, 25),
                     limits = c(0, 30),
                     expand = c(0, 0)) +
  labs(title = ""Breakdown of Player Contributions by League"",
       subtitle = glue(""
                       Shown as Country Name 
                       Mexico (Liga MX) contributed 27 players to South American squads""),
       x = ""League (Country name)"", y = ""Number of players"",
       caption = glue::glue(""
                            Source: Wikipedia
                            By: @R_by_Ryo"")) +
  theme_copaAmerica(title.size = 18,
                    subtitle.size = 12,
                    caption.size = 10, 
                    axis.text.size = 14,
                    axis.text.y.size = 11,
                    axis.title.size = 16,
                    panel.grid.major.y = element_blank(),
                    panel.grid.minor.x = element_line(color = ""white""))

player_contrib_league_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = player_contrib_league_plot, filename = here::here(""Copa America 2019/output/player_contrib_league_plot.png""),
       height = 7, width = 8)
```

The best of the best players from South American countries will move on to Europe so the Argentinean league (Superliga Argentina) and the Brazilian league (Brasileiro - Serie A) do not have as many players as you might think and as a consequence, the top leagues of England, Spain, and Italy contribute quite a bit! A lot of the better players but not quite elite South American players might go to Mexico instead of a lower-mid European league. With the growth of the MLS a fair number of players ply their trade there as well.

We can take a more detailed look by creating a table of the proportion of players from each squad coming from either a domestic league or any other league. I had to do a lot of wrangling to get the proper output for the table. After calculating the percentage of domestic players from a country's domestic league I added the full data back in. Then I had to make sure that for each country, the country - domestic league country was the first row in each of the country groups (so Bolivia - Bolivia, Bolivia, China, Japan - Japan, Japan - England, etc.). By doing this I can automatically `tidyr::fill()`-in the rest of the rows of that country with the 'percentage of players from domestic league stat'. 

```{r}
squads_df_clean %>% 
  group_by(country, country_league) %>% 
  summarize(player_from_league = n()) %>% 
  filter(country == country_league) %>% 
  mutate(perc_from_domestic_league = percent(player_from_league / 23, accuracy = 0.1)) %>% 
  right_join(squads_df_clean %>% 
              group_by(country, country_league) %>% 
              summarize(player_from_league = n()) %>% 
              ungroup()) %>% 
  mutate(first = case_when(
    country == country_league ~ 1,
    TRUE ~ 0)) %>% 
  arrange(country, desc(first)) %>% 
  fill(perc_from_domestic_league) %>% 
  group_by(country) %>% 
  mutate(perc_from_league = percent(player_from_league / 23, accuracy = 0.1),
         country_league = glue::glue(""{country_league} - league"")) %>% 
  arrange(desc(player_from_league)) %>% 
  select(Country = country, `League (country name)` = country_league,
         `Number of players from league` = player_from_league,
         `Percentage of players from league` = perc_from_league,
         `Percentage of players from domestic league` = perc_from_domestic_league) %>% 
  head(10) %>% 
  knitr::kable(format = ""html"",
               caption = ""Breakdown of Player Contribution by League"") %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

Three interesting facts I found:

- 30% of players on the Brazil squad play for an English team, most out of any league - squad combination excluding domestic leagues.
- 100% of the Qatar squad play in their domestic league!
- Only one Uruguayan player (4.3%) plays in its domestic league.

### Player contribution by club

In the final plot for this section, I looked at the top 10 clubs contributing the most players to the tournament. I used `arrange(desc(n)) %>% slice()` instead of `top_n()` as there were too many teams tied at 4 players. To set the team names inside the bars I created a midpoint value `midval` that calculated a value half of the number of players contributed so the labels were placed neatly.

```{r fig.height = 6, fig.width = 8}
player_contrib_club_plot <- squads_df_clean %>% 
  group_by(club) %>% 
  summarize(n = n()) %>% 
  mutate(club = club %>% forcats::as_factor() %>% forcats::fct_reorder(n),
         midval = n / 2) %>% 
  arrange(desc(n)) %>% 
  slice(1:15) %>% 
  ggplot(aes(x = club, y = n)) +
  geom_col(fill = ""red"") +
  geom_text(aes(label = n, family = ""Roboto Condensed"", fontface = ""bold""), 
            size = 7.5, color = ""yellow"",
            nudge_y = 0.5) +
  geom_text(aes(y = midval, label = club, 
                family = ""Roboto Condensed"", fontface = ""bold""),
            size = 5, color = ""white"") +
  coord_flip() +
  scale_y_continuous(breaks = scales::pretty_breaks(),
                     expand = c(0, 0),
                     limits = c(0, 10.5)) +
  labs(title = ""Top 15 Clubs contributing the most players to the Copa Amrica"",
       x = ""Club"", y = ""Number of players"",
       caption = ""Source: Wikipedia"") +
  theme_copaAmerica(
    title.size = 18,
    subtitle.size = 12, 
    caption.size = 8,
    axis.text.size = 14,
    axis.title.size = 16,
    strip.text.size = 18,
    panel.grid.major.y = element_blank(),
    panel.grid.minor.x = element_line(color = ""white"")) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

player_contrib_club_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = player_contrib_club_plot, filename = here::here(""Copa America 2019/output/player_contrib_club_plot.png""),
       height = 6, width = 8)
```

With 100% of its players coming from the domestic league it's not surprise that the Qatari team, Al-Sadd, is contributing the most players to the tournament. Tied with another Qatari team, Mexican club America features 7 players yet none of them are Mexicans (2 Argentineans, 2 Colombians, 1 Ecuadorian, 1 Chilean, and 1 Paraguayan). 

At first I thought Barcelona contributed 8 players until I realized the Ecuadorian players were coming from the Ecuadorian team called Barcelona...I had to go all the way back up to the beginning of this section to fix that small peculiarity. As futbol came to South America via European colonists and immigrants a lot of teams took up the names and colors of the teams these Europeans were fond of. Other examples include Liverpool F.C. (Montevideo, Uruguay), Arsenal de Sarandi (Buenos Aires, Argentina), and Club Atletico Juventus (Sao Paulo, Brazil - although they use the colors of Torino F.C.).

If you download the data and type in the code below you can see the entire club-country list.

```{r, eval=FALSE}
squads_df_clean %>% 
    group_by(club, country) %>% 
    summarize(n = n()) %>% View()
```

## Match Records

Now that we got a good look at the composition of the teams, we can take a look at how they've done at every Copa Amrica.

The next code chunk mainly comes from PH Julien and his excellent Kaggle kernel of [""A Journey Through The History of Soccer""](https://www.kaggle.com/phjulien/a-journey-through-the-history-of-soccer/).

```{r, message=FALSE, eval=FALSE}
## grab football federation affiliations data
federation_files <- Sys.glob(""../data/federation_affiliations/*"")

df_federations = data.frame(country = NULL, federation = NULL)
for (f in federation_files) {
    federation = basename(f)
    content = read.csv(f, header=FALSE)
    content <- cbind(content,federation=rep(federation, dim(content)[1]))
    df_federations <- rbind(df_federations, content)
}

colnames(df_federations) <- c(""country"", ""federation"")

df_federations <- df_federations %>% 
  mutate(country = as.character(country) %>% str_trim(side = ""both""))

results_raw <- readr::read_csv(""../data/results.csv"")

results_copa <- results_raw %>% 
  filter(tournament == ""Copa Amrica"") %>% 
  rename(venue_country = country, 
         venue_city = city) %>% 
  mutate(match_num = row_number())

## combine with federation affiliations
results_copa_home <- results_copa %>% 
  left_join(df_federations, 
            by = c(""home_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(home_federation = federation) 

results_copa_away <- results_copa %>% 
  left_join(df_federations, 
            by = c(""away_team"" = ""country"")) %>% 
  mutate(federation = as.character(federation)) %>% 
  rename(away_federation = federation)

## combine home-away
results_copa_cleaned <- results_copa_home %>% 
  full_join(results_copa_away)
```

Unfortunately, this data does not have __penalty__ results as those games are all counted as a draw (as technically that is the actual result). Considering there a lot of cagey knock-out rounds that finish in a penalty shoot-out (including the last two finals...) it is unfortunate but that's just the data you have sometimes. There is a way to web-scrape all the Copa Amrica results and assign Win-Lose to those games that went to penalties but I'll leave that for another time. Also, there is no info on what stage of the tournament the match recorded is in.

```{r, eval=FALSE}
results_copa_cleaned <- results_copa_cleaned %>% 
  mutate(
    home_federation = case_when(
      home_team == ""USA"" ~ ""Concacaf"",
      TRUE ~ home_federation),
    away_federation = case_when(
      away_team == ""USA"" ~ ""Concacaf"",
      TRUE ~ away_federation)) %>% 
  select(-contains(""federation""), -contains(""venue""),
         -neutral, date, home_team, home_score, away_team, away_score, 
         tournament, venue_city)
```

```{r, echo=FALSE, eval=FALSE}
saveRDS(results_copa_cleaned, file = here::here(""data/results_copa_cleaned.RDS""))
```

```{r, echo=FALSE}
results_copa_cleaned <- readRDS(file = here::here(""data/results_copa_cleaned.RDS""))
```

```{r}
glimpse(results_copa_cleaned)
```

Now that it's nice and cleaned up I created a function that reshapes the data so that it's set from a certain team's perspective with the ""team"" argument. You can also set the function to look for only results against a certain opponent by filling in the `versus` argument.

```{r}
copaAmerica_resultados <- function(data, team, versus = NA) {
  
  ## team of interest: ex. 'Brazil'
  team_var <- enquo(team)
  
  todos_partidos <- data %>% 
    ## filter only for results of team of interest
    filter(home_team == !!team_var | away_team == !!team_var) %>% 
    ## reshape columns to team vs. opponent
    mutate(
      opponent = case_when(
        away_team != !!team_var ~ away_team,
        home_team != !!team_var ~ home_team),
      home_away = case_when(
        home_team == !!team_var ~ ""home"",
        away_team == !!team_var ~ ""away""),
      equipo_goals = case_when(
        home_team == !!team_var ~ home_score,
        away_team == !!team_var ~ away_score),
      opp_goals = case_when(
        home_team != !!team_var ~ home_score,
        away_team != !!team_var ~ away_score)) %>% 
    ## label results from team's perspective
    mutate(
      result = case_when(
        equipo_goals > opp_goals ~ ""Win"",
        equipo_goals < opp_goals ~ ""Loss"",
        equipo_goals == opp_goals ~ ""Draw"")) %>% 
    mutate(result = result %>% forcats::as_factor() %>% forcats::fct_relevel(c(""Win"", ""Draw"", ""Loss""))) %>% 
    select(-contains(""score""), -contains(""team""), -match_num) %>% 
    rename(Date = date, Tournament = tournament, `Venue` = venue_city, Opponent = opponent, `Home / Away` = home_away,
           `Goals For` = equipo_goals, `Goals Against` = opp_goals, Result = result)
  
  if (is.na(versus) | is.null(versus)) {
    
    resultados_totalmente <- todos_partidos %>% 
      group_by(Result, Opponent) %>% 
      mutate(n = n()) %>% 
      ungroup() %>% 
      ## sum amount of goals by team and opponent
      group_by(Result, Opponent) %>% 
      summarize(e_g = sum(`Goals For`),
                o_g = sum(`Goals Against`),
                n = n()) %>% 
      ungroup() %>% 
      ## spread results over multiple columns
      spread(Result, n) %>% 
      mutate_if(is.integer, as.numeric)
    
    missing_cols <- c(""Win"", ""Draw"", ""Loss"") %>% 
      map_dfr( ~tibble(!!.x := numeric()))
    
    resultados_totalmente <- resultados_totalmente %>% 
      bind_rows(missing_cols) %>% 
      mutate(Win = if_else(is.na(Win), 0, Win),
             Draw = if_else(is.na(Draw), 0, Draw),
             Loss = if_else(is.na(Loss), 0, Loss)) %>%
      group_by(Opponent) %>% 
      summarize(Win = sum(Win, na.rm = TRUE),
                Draw = sum(Draw, na.rm = TRUE),
                Loss = sum(Loss, na.rm = TRUE),
                `Goals For` = sum(e_g),
                `Goals Against` = sum(o_g))
    
    return(list(resultados_totalmente, todos_partidos))
  } else { 
    ## opponent: ex. 'Argentina'
    todos_partidos <- todos_partidos %>% 
      filter(Opponent == versus)
    
    if (nrow(todos_partidos) == 0) {
     return(glue(""{team} has never played {versus} at the Copa Amrica!"")) 
    } else {
    
    resultados_totalmente <- todos_partidos %>% 
      group_by(Result, Opponent) %>% 
      mutate(n = n()) %>% 
      ungroup() %>% 
      # sum amount of goals by team and opponent
      group_by(Result, Opponent) %>% 
      summarize(e_g = sum(`Goals For`),
                o_g = sum(`Goals Against`),
                n = n()) %>% 
      ungroup() %>% 
      # spread results over multiple columns
      spread(Result, n) %>% 
      mutate_if(is.integer, as.numeric) %>%       
      group_by(Opponent) %>% 
      summarize(Win = sum(Win, na.rm = TRUE),
                Draw = sum(Draw, na.rm = TRUE),
                Loss = sum(Loss, na.rm = TRUE),
                `Goals For` = sum(e_g),
                `Goals Against` = sum(o_g))
    
    return(list(resultados_totalmente, todos_partidos))
    }
  }
}
```

The output is either a dataframe of all the games a team has been involved in as well as the record of the team against other teams in the Copa Amrica or a message saying that the team you picked has never played against the opponent you picked.

### Japan

```{r, warning=FALSE}
copaAmerica_resultados(data = results_copa_cleaned, 
               team = ""Japan"", versus = ""Brazil"")
```

Oh... that's right Japan has never played against Brazil at the Copa...

```{r}
resultados_japon <- copaAmerica_resultados(data = results_copa_cleaned, team = ""Japan"")

resultados_japon[[2]] %>% 
  knitr::kable(format = ""html"",
               caption = ""Japan's record in the Copa Amrica"") %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

Japan's only previous journey to the Copa Amrica was in the 1999 edition where they lost all 3 games. They were invited for the 2011 edition but withdrew due to the Tohoku Earthquake and were replaced by Costa Rica. Japanese football has come a long way since 1999 but with a young squad it will be a uphill battle to get 3 points against any of their Group C opponents, Uruguay, Chile, and Ecuador.

### Colombia

```{r}
resultados_colombia <- copaAmerica_resultados(data = results_copa_cleaned, team = ""Colombia"") 

resultados_colombia[[2]] %>% 
  slice(87:92) %>% 
  knitr::kable(format = ""html"",
               caption = ""Colombia's record in the Copa Amrica"") %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

Despite a recent resurgence of the Colombia national team they have not been able to match the feats of the 2001 side that won the Copa with their best place finish since then coming 3rd in 2004. The 2001 team were not only unbeaten but also did not concede a single goal throughout the tournament!

### Superclasico Sudamericano: Brazil vs. Argentina

```{r}
resultados_de_brazil <- copaAmerica_resultados(data = results_copa_cleaned, 
               team = ""Brazil"", versus = ""Argentina"")

resultados_de_brazil[[1]] %>% 
  knitr::kable(format = ""html"",
               caption = ""Brazil vs. Argentina in the Copa Amrica"") %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

```{r}
resultados_de_brazil[[2]] %>% 
  tail(5) %>% 
  knitr::kable(format = ""html"",
               caption = ""Brazil vs. Argentina in the Copa Amrica"") %>% 
  kableExtra::kable_styling(full_width = FALSE)
```

Brazil does not have a good overall record vs. Argentina but they have not lost against their rivals at the Copa Amrica since the 1993 edition where they lost 5-6 on penalties in the Quarter Finals. The ""draw"" in 1995 was won on penalties while the ""draw"" in 2004 was actually in the final where they won 4-2 on penalties.

What I found odd was that the Copa Amrica seems to have a very low priority to certain countries, especially Brazil who have repeatedly sent their B or C teams to the tournament in favor of sending their best team to other tournaments or resting star players. Funnily enough these understrength Brazilian squads have actually won the entire tournament a few times, most notably in 2007 against a full strength Argentina side containing the likes of Zanetti, Riquelme, Cambiasso, Tevez, a young Messi/Mascherano, Cambiasso, et al!

## Player Profiles

After looking at the history of the competition and the composition of the squads I examined the players and their form coming into the Copa Amrica. In recent years football analytics has really taken off and there have been many strides made in creating more informative statistics to assess players' abilities, the most prominently being the __xG__ statistics. This is the first time I talk about __xG__ in any length/depth so this introduction is as much to solidify my understanding as well as yours!

### What IS xG?

- __xG__: Quantitative measure (between 0 and 1) that assigns a probability that a shot taken will result in a goal based on a variety of variables and is used for evaluating the quality of chances and predicting players' and teams' future performances.

- __xA__: Quantitative measure (between 0 and 1) that assigns a probability that a given pass will result in an assist for a goal based on a variety of variables.

Common variables used in the models that output xG statistics are the distance and angle of a shot, the body part used, rebound, among others. Similar to how you might assess your favorite striker's chances of scoring just as he is lining up to take a shot: Is the shot a header? Is he trying to score from a cross in regular play or a corner kick? Are there a crowd of defenders in front of him or is he one-on-one with the goalkeeper? Etc. You might think __who__ takes a shot would be a genuine factor but in actuality it tells you a lot less about the chances of a goal compared to the location of the shot.

Note that there isn't a SINGLE xG model. You can check out a blog post comparing different people's xG models [here](https://mackayanalytics.nl/2017/06/19/how-accurate-are-xg-models-ii-the-big-chance-dilemma/). People and organizations (from Statsbomb to OptaPro) have their own ideas about what __could__ be the important variables in play and as such it's important to report from which source you got your data from as the stats can differ between models. A few things xG does not factor in are things like goalkeeper performance (someone pulling off incredible saves or letting in a poor shot) and one must also consider the fact that team style of play and the quality of a player's teammates. When judging players based on these stats it is important to be aware of contextual factors like the team they play for, their opponent, and the player's position/role in the team.

From xG and xA more granular statistics such as xGChain and xGBuildup were created to be able to dig a little deeper into who is contributing to chance creation, I'll introduce the latter two a bit later. As the field has grown new statistics have popped up such as [Karun Singh](https://twitter.com/karun1710/)'s ""expected threat"" or xT. You can check out an introduction to xT from [here](https://karun.in/blog/expected-threat.html).

Of course, these statistics only tell a part of the story and are definitenly not the be-all-and-end-all. In the context of this current blog post, these stats only tell the story about how these players did for their club teams this past season rather than for their national team. Even still it gives us a good idea of what kind of form these players are in coming into this tournament.

You might also want to watch these Youtube videos by [TifoFootball](https://www.youtube.com/channel/UCGYYNGmyhZ_kwBF_lqqXdAQ) for a quick primer on [xG](https://www.youtube.com/watch?v=zSaeaFcm1SY) and [xA](https://www.youtube.com/watch?v=1MdlkuzLdj4).

### understat data

For the data I used the website, `understat.com`. Their xG models were created via training a neural network on a dataset consisting of over 100,000 shots using more than 10 different variables. Getting data from `understat` has been made easy by Ewen Henderson's `understatr` package available from [Github](https://github.com/ewenme/understatr) (he's also the guy that made the [ghibli](https://github.com/ewenme/ghibli) color palette!). I tried to pick a wide selection of attacking players but I was also limited by the fact that `understat` only has data for teams/players from six European leagues (Premier League, Bundesliga, Serie A, La Liga, Ligue 1, and Russian Premier League). 

For __Peru__ I would have chosen Paolo Guerrero but as he plays in Brazil now I went with Jefferson Farfan (who hasn't played as many games as the other players used for comparison unfortunately...). For __Chile__ I would pick Eduardo Vargas but he as doesn't play for a team covered by understat I went with Alexis Sanchez, who had a woeful season and only played ~600 minutes despite appearing in ~20 league matches and later added Arturo Vidal. For __Brazil__ I included Neymar initially but since he won't actually be playing I'll keep him for comparison's sake but also include Gabriel Jesus and Roberto Firmino who have been fighting for the starting striker spot. Note that these two aren't the ones replacing Neymar __positionally__. In Neymar's left-wing position I can see David Neres or Phil Coutinho replacing him (Richarlison and Willian mostly play on the right). (Edit: In the first match vs. Bolivia, David Neres started off on the left while Richarlison played on the right, Coutinho played just behind Bobby Firmino)

The other nation's strikers/attacking midfielders don't play for the six European leagues covered by understat or like in Shinji Okazaki's case just did not play as many minutes/games during the season. To get the data I created a list of the player codes and use `purrr::map()` to iterate each through the `understatr::get_player_seasons_stats()` function. 

```{r, eval=FALSE}
player_codes <- c(2097, 2099, 813,   ## Messi, Neymar, Rondon
                  498, 4299, 696,    ## Alexis, Farfan, Falcao
                  3294, 2098, 5543,  ## Cavani, Suarez, G. Jesus
                  482, 1148, 2249,   ## Bobby, Duvan, James
                  1089, 3553, 488,   ## Cuadrado, Di Maria, Coutinho
                  222)               ## Arturo Vidal

understat_data <- player_codes %>% 
  map(., ~ understatr::get_player_seasons_stats(.x)) %>% 
  reduce(bind_rows) %>% 
  select(-player_id, -position, -yellow, -red)
```

```{r, eval=FALSE, echo=FALSE}
saveRDS(understat_data, file = here::here(""data/copa_america_understat.RDS""))
```

```{r, echo=FALSE}
understat_data <- readRDS(file = here::here(""data/copa_america_understat.RDS""))
```

```{r}
glimpse(understat_data)
```

As you can see the data consists of a row for each player and each year (from the 2014/2015 season to the 2018/2019 season). I tried to mitigate the fact that some players played a lot more minutes than others by standardize everything to a 'per 90 minutes' value but this does have its own disadvantages. These include the fact that players who play a lot of minutes (as regular starting members) may not have as high 'per 90' stat even though their production with all these minutes might suggest that they are consistently performing and producing at a high level.

It'll be a bit crowded (kind of like a spilt box of Skittles...) but let's check out the key metrics for all the players at once.

Note: npg = non-penalty goals, npxG = non-penalty goals xG

```{r, fig.height = 6, fig.width = 8}
comparison_data <- understat_data %>% 
  filter(year == 2018) %>% 
  select(-games, -team_name, -year) %>% 
  rename(Shots = shots, KP = key_passes) %>% 
  gather(key = ""key"", value = ""value"", -player_name, -time) %>% 
  mutate(key = forcats::as_factor(key) %>% 
           forcats::fct_relevel(., 
                                ""xG"", ""goals"", ""npxG"", ""npg"", 
                                ""xA"", ""assists"", ""xGChain"", ""xGBuildup"",
                                ""Shots"", ""KP""))

comparison_strikers_plot <- comparison_data %>%
  filter(key != ""Shots"", key != ""KP"",
         key != ""xGBuildup"", key != ""xGChain"") %>% 
  mutate(value = value / time * 90) %>% 
  ggplot(aes(x = key, y = value, fill = player_name)) +
  geom_jitter(shape = 21, size = 5, color = ""black"", width = 0.25, stroke = 1.1) +
  geom_vline(xintercept = 1.5, size = 2) +
  geom_vline(xintercept = 2.5, size = 2) +
  geom_vline(xintercept = 3.5, size = 2) +
  geom_vline(xintercept = 4.5, size = 2) +
  geom_vline(xintercept = 5.5, size = 2) +
  coord_flip() +
  scale_y_continuous(expand = c(0.01, 0.01),
                     limits = c(0, 1.26)) +
  scale_fill_manual(values = pals::glasbey(16), name = ""Player"") +
  labs(title = ""Comparison: Top attackers at the Copa Amrica"",
       subtitle = ""For select group of attacking players with data available from understat.com"",
       x = NULL, y = ""Metric per 90"",
       caption = glue::glue(""
                            data: understat.com
                            2018-2019 Season"")) +
  theme_copaAmerica(title.size = 18,
                    subtitle = 12,
                    panel.grid.minor.x = element_line(color = ""white""))

comparison_strikers_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = comparison_strikers_plot, filename = here::here(""Copa America 2019/output/comparison_strikers_plot.png""),
       height = 5, width = 8)
```

As usual in these types of charts, Messi is leading a lot of the metrics here and showing consistency too with having played the third highest amount of minutes out of the selected players. It's helpful to have the xG/xA stats next to the actual goals/assists as it provides an indication of whether the player in question is scoring shots that he probabilistically should be scoring. When a player's actual goal count is higher than their xG stat this suggests that the player is __""exceeding their xG""__ or that they are scoring from shots that are historically hard to score from. It can be seen as a marker of an elite finisher as they are putting away chances from difficult situations consistently. In terms of assists and xA Alexis Sanchez, who only played about 600 minutes, looks a lot better than in reality due to the aforementioned disadvantage of standardizing everything to a ""per 90 minutes"" value. Normally you would have a cut-off based on a certain __minimum amount of minutes__ but as I mentioned I was rather limited in my choice of players.

A way to take a closer look at xG - Goals and xA - Assists is to use a simple dot plot with a line going through the 45 degree angle. Those below the line are underperforming relative to their xG or xA stat, those over it are overachieving (""exceeding"" their xG/xA stat) while those just on the line are scoring or assisting right around what the model expects the player to be. I use non-penalty xG below as penalties have around ~0.75 xG (give or take a few percentage points depending on the model) and can inflate the stats of those players who take a lot of penalties and score them, especially if they weren't the ones who earned the penalty themselves.

```{r, fig.height = 5, fig.width = 8}
expected_goal_plot <- understat_data %>% 
  filter(year == 2018) %>% 
  select(player_name, time, npxG, xG, goals) %>% 
  mutate_at(c(""npxG"", ""xG"", ""goals""), ~. / time * 90) %>% 
  ggplot(aes(x = npxG, y = goals, fill = player_name)) +
  geom_abline(intercept = 0, slope = 1, color = ""white"", size = 1.1) +
  geom_point(shape = 21, size = 5, color = ""black"", stroke = 1.1) +
  scale_x_continuous(limits = c(0, 1.1),
                     expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 1.3),
                     expand = c(0, 0)) +
  scale_fill_manual(values = pals::glasbey(16), name = ""Player"") +
  labs(title = ""Expected vs. Actual Goals"",
       subtitle = ""For select group of attacking players with data available from understat.com"",
       x = ""Non-penalty xG per 90 minutes"",
       y = ""Goals per 90 minutes"",
       caption = glue::glue(""
                            data: understat.com
                            2018-2019 Season"")) +
  theme_copaAmerica(panel.grid.minor.x = element_line(color = ""white""),
                    panel.grid.minor.y = element_line(color = ""white""),
                    subtitle.size = 11)

expected_goal_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = expected_goal_plot, filename = here::here(""Copa America 2019/output/expected_goal_plot.png""),
       height = 5, width = 8)
```

Gabriel Jesus is quite clearly below the 45 degree line meaning that he has been very poor at finishing chances (and/or incredibly unlucky). After a poor World Cup where he scored 0 goals as a starter, he is really going to have to step up to fill Neymar's goalscoring boots for this tournament. However, his build-up play for City has still been good this past season and he has been scoring for Brazil in the friendlies leading up to the tournament so it's going to be a hard decision for Tite to decide on who starts against Bolivia (edit: Firmino started and contributed an assist while Jesus replaced him in the 65th minute).

```{r, fig.height = 5, fig.width = 8}
expected_assists_plot <- understat_data %>% 
  filter(year == 2018) %>% 
  select(player_name, time, xA, assists) %>% 
  mutate_at(c(""xA"", ""assists""), ~. / time * 90) %>% 
  ggplot(aes(x = xA, y = assists, fill = player_name)) +
  geom_abline(intercept = 0, slope = 1, color = ""white"", size = 1.1) +
  geom_point(shape = 21, size = 5, color = ""black"", stroke = 1.1) +
  labs(title = ""Expected vs. Actual Assists"",
       subtitle = ""For select group of attacking players with data available from understat.com"",
       x = ""xA per 90 minutes"",
       y = ""Assists per 90 minutes"",
       caption = glue::glue(""
                            data: understat.com
                            2018-2019 Season"")) +
  scale_x_continuous(limits = c(0, 0.55),
                     expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 0.55),
                     expand = c(0, 0)) +
  scale_fill_manual(values = pals::glasbey(16), name = ""Player"") +
  theme_copaAmerica(panel.grid.minor.x = element_line(color = ""white""),
                    panel.grid.minor.y = element_line(color = ""white""),
                    subtitle.size = 11)

expected_assists_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = expected_assists_plot, filename = here::here(""Copa America 2019/output/expected_assists_plot.png""),
       height = 5, width = 8)
```

One thing to keep in mind is that xA does not take into account the recipient of the assist pass. Even if the pass given had a high expected assist value the receiving player still might not have the quality to put it away through no fault of the passer. This might explain why most of the players with a higher xA among this group don't have the assists to match. It can also be that these players are also the ones playing a lot more minutes and the volume of chances they create just aren't translating to goals all the time.

### Key Passes, Shots, xGChain, and xGBuildup (per 90)

I separated ""key passes"" and ""shots"" as well as ""xGChain"" and ""xGBuildup"" from the rest as these two sets were on a very different scale.

```{r, fig.height=5, fig.width=7}
kp_shots_plot <- comparison_data %>%
  filter(key == ""Shots"" | key == ""KP"") %>% 
  mutate(value = value / time * 90) %>% 
  ggplot(aes(x = key, y = value, fill = player_name)) +
  geom_jitter(shape = 21, size = 5, color = ""black"", width = 0.25, stroke = 1.1) +
  coord_flip() +
  scale_y_continuous(expand = c(0.01, 0.01),
                     limits = c(0, 6),
                     breaks = c(0, 1, 2, 3, 4, 5, 6),
                     labels = c(0, 1, 2, 3, 4, 5, 6)) +
  scale_fill_manual(values = pals::glasbey(17), name = ""Player"") +
  geom_vline(xintercept = 1.5, size = 2) +
  labs(title = ""Comparison: Stars of the Copa Amrica"",
       subtitle = glue(""
                       KP = Key Passes
                       For select group of attacking players with data available from understat.com""),
       x = NULL, y = ""Metric per 90"",
       caption = glue::glue(""
                            data: understat.com
                            2018-2019 Season"")) +
  theme_copaAmerica(title.size = 18,
                    subtitle.size = 10,
                    panel.grid.minor.x = element_line(color = ""white""))

kp_shots_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = kp_shots_plot, filename = here::here(""Copa America 2019/output/kp_shots_plot.png""),
       height = 5, width = 7)
```

- xGChain: Quantitative measure that is the combined sum of the xG of every possession that ends in a shot that a player is involved in. The same derived value is given to each of the players involved and allows us to credit players for attacking contributions outside of just shots (xG) and assists (xA). 

- xGBuildup: Similar to xGChain but excluding shots and assists. This is in response to xGChain values still being dominated by the xG and xA from shots and assists, respectively. 

```{r, fig.height=5, fig.width=7}
xgbuildup_xgchain_plot <- comparison_data %>%
  filter(key == ""xGBuildup"" | key == ""xGChain"") %>% 
  mutate(value = value / time * 90) %>% 
  ggplot(aes(x = key, y = value, fill = player_name)) +
  geom_jitter(shape = 21, size = 5, color = ""black"", width = 0.25, stroke = 1.1) +
  coord_flip() +
  scale_y_continuous(expand = c(0.01, 0.01),
                     limits = c(0, 1.55),
                     breaks = c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5),
                     labels = c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5)) +
  scale_fill_manual(values = pals::glasbey(17), name = ""Player"") +
  geom_vline(xintercept = 1.5, size = 2) +
  labs(title = ""Comparison: Stars of the Copa Amrica"",
       subtitle = ""For select group of attacking players with data available from understat.com"",
       x = NULL, y = ""Metric per 90"",
       caption = glue::glue(""
                            data: understat.com
                            2018-2019 Season"")) +
  theme_copaAmerica(title.size = 18,
                    subtitle.size = 10,
                    panel.grid.minor.x = element_line(color = ""white""))

xgbuildup_xgchain_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = xgbuildup_xgchain_plot, filename = here::here(""Copa America 2019/output/xgbuildup_xgchain_plot.png""),
       height = 5, width = 7)
```

Although Gabriel Jesus has been poor at finishing his chances as seen in previous graphs, his xGChain and xGBuildup stat makes it clear that he is still contributing to City's attack outside of scoring goals himself (not to mention all the defensive work he does as well).

For example below, the stats are able to clearly differentiate between James, who is more of a playmaker, compared to Falcao and Duvan who are traditional number 9s with his superior xGBuildup, xGChain, and Key Passes values. For a more detailed overview on xGChain and xGBuildup check out Statsbomb's article [here](https://statsbomb.com/2018/08/introducing-xgchain-and-xgbuildup/).

```{r, fig.height=5, fig.width=7}
## keep colors for Colombians consistent with other plots
colombia_pal <- c(""#000033"", ""#005300"", ""#009FFF"", ""#00FFBE"")

comparison_colombia_plot <- comparison_data %>%
  filter(!key %in% c(""xG"", ""goals"", ""npxG"", ""npg"", ""xA"", ""assists""),
         player_name %in% c(""James Rodrguez"", ""Falcao"", ""Duvn Zapata"", ""Juan Cuadrado"")) %>% 
  mutate(value = value / time * 90) %>% 
  ggplot(aes(x = key, y = value, fill = player_name)) +
  geom_point(shape = 21, size = 5, color = ""black"", stroke = 1.1) +
  geom_vline(xintercept = 1.5, size = 2) +
  geom_vline(xintercept = 2.5, size = 2) +
  geom_vline(xintercept = 3.5, size = 2) +
  coord_flip() +
  scale_y_continuous(expand = c(0.05, 0.05),
                     breaks = c(0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4),
                     labels = c(0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4)) +
  scale_fill_manual(values = colombia_pal, name = ""Player"") +
  labs(title = ""Comparison: Stars of Colombia"",
       subtitle = ""KP: Key Passes"",
       x = NULL, y = ""Metric per 90"",
       caption = glue::glue(""
                            data: understat.com
                            2018-2019 Season"")) +
  theme_copaAmerica(title.size = 20,
                    subtitle.size = 12,
                    panel.grid.minor.x = element_line(color = ""white""))

comparison_colombia_plot
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = comparison_colombia_plot, filename = here::here(""Copa America 2019/output/comparison_colombia_plot.png""),
       height = 5, width = 7)
```

There are lots of different ways to visualize this data, most famously the radar charts created by [Statsbomb](http://statsbomb.com/). Using the data you can also compare and evaluate players in many different ways and using `understatr` package you could add a few more players like Paulo Dybala, Miguel Almiron, and more! I could probably do a whole other article using just this data but I'll leave it here for now.

## Conclusion

Throughout this blog post I talked about some of the historical records, squad compositions, match records, and finally the player profiles of attacking players at this summer's Copa Amrica. Using the power of R it is really easy to webscrape and visualize data in a way that is informative and aesthetically pleasing. I wanted to finish this before the tournament started but other life things got in the way as well as the fact that the amount of content ballooned out of control (especially the xG section) so I had to cut down a lot. 

It's been fun reading the articles on the Copa Amrica website and seeing how far my ""intermediate-but-very-out-of-practice""-level of Spanish can get me to understand the content, here is one that I particularly liked reading: [14 Estadisticas de la Copa Amrica](https://copaamerica.com/es/noticias/a-14-dias-del-inicio-de-la-copa-14-estadisticas-de-la-copa-america). With so many tournaments going on right now (and with the African Cup of Nations starting in a few days) a lot of the news media is spread thin right now but there are still some quality articles out there to read about the Copa, like [this article](https://www.bbc.com/sport/football/48600098) from BBC's South American football expert, Tim Vickery.

After the first round of games, a few points of discussion:

- After an extremely lacklustre performance vs. Colombia, how does Argentina bounce back? What tactical changes need to be made?

- Qatar impressed against Paraguay but can they pull off a major upset vs. Colombia?

- How will Japan line-up against Uruguay after a losing by a scoreline that didn't really do their performance justice? How will manager Moriyasu balance experience vs. youth, will he start with veteran Okazaki after Ueda's numerous misses vs. Chile?

- Can Brazil earn a early ticket to the next round vs. Venezuela after a clinical but not excellent performance vs. Bolivia? Will they be able to keep up their streak of winning the Copa every time they have hosted it?

Thanks for reading and...

Buena suerte a todos equipos!","2019"
"45",203,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Copa America 2019/copa_extras.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""6/15/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


https://copaamerica.com/es/noticias/a-14-dias-del-inicio-de-la-copa-14-estadisticas-de-la-copa-america

fixture calendar: https://copaamerica.com/static/CA2019-calendar-ESP-1-d78531672f9b0a782f78f96f57acb21c.png

Colores:

https://i.ytimg.com/vi/ByYw8EyMr1E/maxresdefault.jpg

```{r}
#142052 darknavy
#7CAE51 light grassy green
#3E632F dark green
#FEDB45 yellow gold
#31359D purple
#245D98 lightblue
#012488 deep blue
#4B9213 med green
```


host nation performance
- first game results

guest nation performance >>> USA 3rd Place in 2016... also hosts though...

time-difference

how far does each team have to travel??
- hypothetical scenarios all the way to the final: Brazil, Argentina, Japan??
- grab names of stadiums then `geocode()`
- brazil training in teresopolis near Rio before the tournament...

- which leagues have contributed most players? boring bar chart
-- which team
-- percentage of players coming from each own nation's team?

- avg. age per position? per team?

- squad numbers and position?

top performers >>> understat   (only for top 5 leagues...)
-->> percentile rank of select players in similar position?
- Sh90, KP90, xG, xG90, xA, xA90, xGChain90, xGBuildup90

gt tables: green/yellow/red  ABOVE+BELOW league avg. (at least 30 appearances)
create radar charts?

```{r, fig.height = 5, fig.width = 8}
age_position_plot <- squads_df_clean %>% 
  group_by(position) %>% 
  mutate(median = median(age)) %>% 
  ungroup() %>% 
  ggplot(aes(x = age)) +
  geom_histogram(fill = ""red"", binwidth = 1) +
  geom_vline(aes(xintercept = median), size = 1.2) +
  labs(x = ""Age"", y = NULL) +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  theme_copaAmerica(title.size = 24,
                    subtitle.size = 14, 
                    caption.size = 8,
                    axis.text.size = 14,
                    axis.title.size = 16,
                    strip.text.size = 18,
                    panel.grid.minor.x = element_line(color = ""white""),
                    panel.grid.minor.y = element_line(color = ""white"")) +
  facet_wrap(~position)

age_position_plot
```


## Team Profiles

soccerway

### Argentina

```{r}

```

probable line-up? >>> most common since world cup?
Goals + assists

### Brazil

```{r}
url <- ""https://us.soccerway.com/teams/brazil/brazil/349/matches/""

session <- bow(url)

matches_links <- scrape(session) %>% 
  html_nodes("".score a"") %>% 
  html_attr(""href"") %>% 
  tail(9)

matches_link_df <- matches_links %>% 
  tibble::enframe(name = NULL, value = ""link"") %>% 
  mutate(link = glue::glue(""https://us.soccerway.com{link}""))

one_url <- ""https://us.soccerway.com/matches/2018/10/16/world/friendlies/argentina/brazil/2916264/""

## starting eleven

bow(one_url) %>% 
  scrape() %>% 
  html_nodes("".right .large-link"") %>% 
  html_text()

bow(one_url) %>% 
  scrape() %>% 
  html_nodes("".left .large-link"") %>% 
  html_text()

## home team - away team
## goal scorers
## result
```

probable line-up?
Goals + assists

- regex shenanigans...

```{r}

```









### Lionel Messi

```{r}
messi_data_raw <- understatr::get_player_seasons_stats(2097)

messi_data_clean <- messi_data_raw %>% 
  filter(year == 2018) %>% 
  select(-player_id, -year, -team_name, 
         -position, -yellow, -red)
```

### Luis Suarez 


```{r}
suarez_data_raw <- understatr::get_player_seasons_stats(2098)

glimpse(suarez_data_raw)

suarez_data_clean <- suarez_data_raw %>% 
  filter(year == 2018) %>% 
  select(-player_id, -year, -team_name, 
         -position, -yellow, -red)
```


```{r}
comparison_data <- bind_rows(messi_data_clean, suarez_data_clean) %>% 
  select(-games, -time) %>% 
  gather(key = ""key"", value = ""value"", -player_name) %>% 
  mutate(key = forcats::as_factor(key) %>% 
           forcats::fct_relevel(., 
                                ""xG"", ""goals"", ""xA"", ""assists""))

comparison_data %>%
  ggplot(aes(x = key, y = value, color = player_name)) +
  geom_point(size = 2) +
  coord_flip() +
  labs(title = ""Comparison: Messi vs. Suarez"") +
  theme_copaAmerica() +
  theme(legend.position = ""none"")
```

of course when you have a lot of players or players with similar stats then it becomes harder to see and that's where the radar chart can be more appropriate.


```{r}
data <- bind_rows(messi_data_clean, suarez_data_clean) %>% 
  select(-games, -time) %>% 
  #mutate_at(vars(-player_name), rescale) %>% 
  select(1:6) 

Attributes = colnames(data)
AttNo = length(Attributes)


circleFun <- function(center = c(0,0),diameter = 1, npoints = 100){
    r = diameter / 2
    tt <- seq(0,2*pi,length.out = npoints)
    xx <- center[1] + r * cos(tt)
    yy <- center[2] + r * sin(tt)
    return(data.frame(x = xx, y = yy))
}

circle1 <- circleFun(c(0,0),200,npoints = 100)
circle2 <- circleFun(c(0,0),150,npoints = 100)
circle3 <- circleFun(c(0,0),100,npoints = 100)
circle4 <- circleFun(c(0,0),50,npoints = 100)




angle_spilt <- (2*pi) / (AttNo)
angle_spilt_seq <- seq(0,(2*pi),angle_spilt)

# empty dataframes to catch results 
LineData <- data.frame(x = numeric, y = numeric, stringsAsFactors = F)
TitlePositioning <- data.frame(title = character, x = numeric, y = numeric, stringsAsFactors = F)

## create plot background construction data  
for (i in 1:NCOL(data)) {
  angle_multiplier <- if(i < NCOL(data)){i}else{1}
  radians_for_segment <- angle_spilt_seq[i]

  x <- 100 * cos(radians_for_segment)
  y <- 100 * sin(radians_for_segment)
  temp <- data.frame(x = x, y = y, stringsAsFactors = F)
  LineData <- rbind(temp, LineData)
  
  x <- 112 * cos(radians_for_segment)
  y <- 112 * sin(radians_for_segment)
  title <- colnames(data)[i]
  temp <- data.frame(title = title, x = x, y = y, stringsAsFactors = F)
  TitlePositioning <- rbind(temp, TitlePositioning)
}

## create the value labellings data 
values <- c(25,50,75)
radian_for_values <- angle_spilt / 2
x <- values * cos(radian_for_values)
y <- values * sin(radian_for_values)
ValuePositioning <- data.frame(values = values, x = x, y = y, stringsAsFactors = F)

## Add the origin values for the lines 
LineData$x2 <- 0
LineData$y2 <- 0

# empty dataframe to catch result 
polydata <- data.frame(player = character, value = numeric, 
                       radians = numeric, 
                       x = numeric, y = numeric, stringsAsFactors = F)

## create polygon data for the players 
for (i in 1:NCOL(data)) {
  
  for (p in 1:NROW(data)) {
    
  player2calc <- data[p,]
  angle_multiplier <- if(i < NCOL(data)){i}else{1}
  radians_for_segment <- angle_spilt_seq[i]
  x <- player2calc[i] * cos(radians_for_segment)
  y <- player2calc[i] * sin(radians_for_segment)
  player <- rownames(data)[p]
  temp <- data.frame(player = player, value = player2calc[i], 
                     radians = radians_for_segment, x = x, y = y, 
                     stringsAsFactors = F)
  polydata <- rbind(temp, polydata)
  }
}


#e data up into player 1 and 2
playersDB <- unique(polydata$player)
player1 <- polydata[which(polydata$player == playersDB[1]),]
player2 <- polydata[which(polydata$player == playersDB[2]),]

## create the title string for player 1
Player1_title <- gsub('([[:upper:]])', ' \\1', playersDB[1])
Player1_title <- trimws(Player1_title)

## Create Title Strings for Player 2
Player2_title <- gsub('([[:upper:]])', ' \\1', playersDB[2])
Player2_title <- trimws(Player2_title)

require(ggplot2)


## Add the radar background
ggplot() + xlim(c(-120, 120)) + ylim(c(-120, 150)) + 
## Add circles
geom_polygon(data = circle1, aes(x=x,y=y),fill = ""#F0F0F0"", colour = ""#969696"") + geom_polygon(data = circle2, aes(x=x,y=y),fill = ""#FFFFFF"", colour = ""#d9d9d9"") + geom_polygon(data = circle3, aes(x=x,y=y),fill = ""#F0F0F0"", colour = ""#d9d9d9"") + geom_polygon(data = circle4, aes(x=x,y=y),fill = ""#FFFFFF"", colour = ""#d9d9d9"") +
## Change the theme to void 
theme_void() +
## Add the segment lines and attribute/value titles 
geom_segment(data=LineData, aes(x = LineData$x, y = LineData$y, xend = LineData$x2, yend = LineData$y2),colour = ""#d9d9d9"", linetype = ""dashed"") + 
annotate(""text"", x = TitlePositioning$x , y = TitlePositioning$y, label = TitlePositioning$title, size= 2.5) +  
annotate(""text"", x = ValuePositioning$x , y = ValuePositioning$y, label = ValuePositioning$values, size= 2.5, colour = ""#969696"") +
## Add player 1 data 
geom_polygon(data = player1, aes(x=x,y=y),fill = ""#A30845"", colour = ""#A30845"", alpha = 0.3) + geom_point(data = player1, aes(x = x, y = y),size=0.3, colour= ""#A30845"") + 
## Add Chart Title
annotate(""text"", x = -110 , y = 130, label = Player1_title, size= 5, colour = ""#A30845"", family = ""Helvetica"", fontface = ""bold"", hjust = 0) + 
annotate(""text"", x = 110 , y = 130, label = ""FIFA 18 Data"", size= 4, colour = ""#969696"", family = ""Helvetica"", fontface = ""bold"", hjust = 1) +
## Add the player 2 polygon and data points
geom_polygon(data = player2, aes(x=x,y=y),fill = ""#00B20B"", colour = ""#00B20B"", alpha = 0.3) +
geom_point(data = player2, aes(x = x, y = y),size=0.3, colour= ""#00B20B"") +
## Add the titles for player 2
annotate(""text"", x = -110 , y = 116, label = Player2_title, size= 5, colour = ""#00B20B"", family = ""Helvetica"", fontface = ""bold"", hjust = 0) + 
annotate(""text"", x = -110 , y = 123 , label = ""vrs"", size= 3, colour = ""#969696"", family = ""Helvetica"", hjust = 0)
```





### Brazil's Number 9

```{r}
comparison_data %>% 
  filter(player_name %in% c(""Roberto Firmino"", ""Gabriel Jesus"")) %>% 
  mutate(value = value / time * 90)
  
```



```{r, fig.height = 5, fig.width = 8, warning=FALSE, message=FALSE}
colores <- c(""Roberto Firmino"" = ""red"",
             ""Gabriel Jesus"" = ""lightblue"")

comparison_data %>%
  filter(key != ""shots"" | key != ""key_passes"") %>% 
  filter(player_name %in% c(""Roberto Firmino"", ""Gabriel Jesus"")) %>% 
  #mutate(value = value / time * 90) %>% 
  ggplot(aes(x = key, y = value, fill = player_name)) +
  geom_jitter(shape = 21, size = 5, color = ""black"", width = 0.25, show.legend = FALSE, stroke = 1.1) +
  coord_flip() +
  scale_y_continuous(expand = c(0.05, 0.05)) +
  scale_fill_manual(values = colores, name = ""Player"") +
  labs(title = ""Comparison: Brazil's Number 9s"",
       x = NULL, y = ""Metric"") +
  theme_copaAmerica(title.size = 14,
                    panel.grid.minor.x = element_line(color = ""white"")) -> comparison_value

comparison_data %>%
  filter(key != ""shots"" | key != ""key_passes"") %>% 
  filter(player_name %in% c(""Roberto Firmino"", ""Gabriel Jesus"")) %>% 
  mutate(value = value / time * 90) %>% 
  ggplot(aes(x = key, y = value, fill = player_name)) +
  geom_jitter(shape = 21, size = 5, color = ""black"", width = 0.25, show.legend = FALSE, stroke = 1.1) +
  coord_flip() +
  scale_y_continuous(expand = c(0.05, 0.05)) +
  scale_fill_manual(values = colores, name = ""Player"") +
  labs(title = ""Comparison: Brazil's Number 9s"",
       x = NULL, y = ""Metric per 90"",
       caption = glue::glue(""data: understat.com"")) +
  theme_copaAmerica(title.size = 14,
                    panel.grid.minor.x = element_line(color = ""white"")) -> comparison_per90

plot_grid(comparison_value, comparison_per90, ncol = 2)
```

```{r, eval=FALSE, echo=FALSE}
ggsave(plot = player_contrib_club_plot, filename = here::here(""Copa America 2019/output/player_contrib_club_plot.png""),
       height = 6, width = 8)
```


","2019"
"46",204,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Eredivisie 2018-2019/player_goal_contribution_matrix.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""5/25/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# pkgs

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

## add_logo

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))
}
```

# Eredivisie

https://us.soccerway.com/national/france/ligue-1/20182019/regular-season/r48044/


## webscrape soccerway

```{r}
url <- ""https://us.soccerway.com/national/netherlands/eredivisie/20182019/regular-season/r47971/""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#page_competition_1_block_competition_tables_7_block_competition_league_table_1_table .large-link a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, NA, NA, ""team_name"", ""team_num""), sep = ""/"") %>% 
  mutate(link = glue(""
                     https://us.soccerway.com/teams/netherlands/{team_name}/{team_num}/squad/""),
         stat_link = glue(""{link %>% str_replace('squad', 'statistics')}""))

# for each team link:

player_name_info <- function(session) {
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#page_team_1_block_team_squad_3-table .name.large-link"") %>% 
    html_text()
}

num_goals_info <- function(session) {

  num_goals_info <- scrape(session) %>% 
    html_nodes("".goals"") %>% 
    html_text()
  
  num_goals_info_clean <- num_goals_info[-1]
}

num_assists_info <- function(session) {

  num_assists_info <- scrape(session) %>% 
    html_nodes("".assists"") %>% 
    html_text()
  
  num_assists_info_clean <- num_assists_info[-1]
}

team_goals_info <- function(session) {
  team_goals_info <- scrape(session) %>% 
    html_nodes(""tr.first:nth-child(6) > td:nth-child(2)"") %>% 
    html_text()
}

# BIG FUNCTION
eredivisie_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  eredivisie_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names) 
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
eredivisie_goal_contribution_df_ALL <- map2(.x = team_links_df$link,
                .y = team_links_df$stat_link,
                ~ eredivisie_stats_info(link = .x, statlink = .y))

eredivisie_goal_contribution_df <- eredivisie_goal_contribution_df_ALL %>% 
  set_names(team_links_df$team_name) %>% 
  bind_rows(.id = ""team_name"")

## save
saveRDS(eredivisie_goal_contribution_df, file = glue(""{here::here()}/data/eredivisie_goal_contrib_df_soccerway.RDS""))
```

## clean

```{r}
eredivisie_goal_contribution_clean_df <- eredivisie_goal_contribution_df %>% 
  mutate_at(.vars = c(""goals"", ""assists""), 
            ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(team = team_name %>% str_replace_all(., ""-"", "" "") %>% str_to_title,
         total_goals = as.numeric(team_goals)) %>% 
  group_by(team) %>% 
  mutate(total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         assist_contrib = assists/total_goals) %>% 
  ungroup() %>% 
  select(-team_name, -team_goals)

## save
saveRDS(eredivisie_goal_contribution_clean_df, 
        file = glue(""{here::here()}/data/eredivisie_goal_contrib_clean_df.RDS""))
eredivisie_goal_contribution_clean_df <- readRDS(file = glue(""{here::here()}/data/eredivisie_goal_contrib_clean_df.RDS""))
```

## plot

- 
-
-

```{r fig.width = 10, fig.height = 8}  
## Description text
## Iago Aspas
desc_aspas <- ""With 20 Goals from 12.47 xG, Iago Aspas greatly exceeded his xG as he heroically saved Celta Vigo from relegation yet again!""

## Jony   xA90 of 0.29 (tied 3rd highest, minimum 30 games)
desc_jony <- ""With 10 assists amounting to 34% of Alavs' xA, Jony had his career-best season as he helped Alavs contend for a European place.""

## Messi
desc_goat <- ""With total contribution nearly double of the next best, 36 Goals from a xG of 26, etc. Messi led almost every metric in La Liga this season!""

## PLOT!
eredivisie_goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = eredivisie_goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.2 | assist_contrib < 0.125),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = eredivisie_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.2 | assist_contrib > 0.125),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.2, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.125, color = ""grey20"", alpha = 0.4) +
  geom_text_repel(data = eredivisie_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.2 | assist_contrib > 0.125,
                           !name %in% c(""Iago Aspas"", ""L. Messi"", 
                                        ""Jony"", ""Pablo Sarabia"")),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 15, size = 4, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  # geom_mark_circle(aes(filter = name == ""L. Messi"", 
  #                      label = ""Lionel Messi: GOAT"",
  #                       description = desc_goat),
  #                   label.family = ""Roboto Condensed"", label.fontsize = c(16, 12)) +
  # geom_mark_circle(aes(filter = name == ""Iago Aspas"", 
  #                    label = ""Iago Aspas: The Hero of Vigo"",
  #                       description = desc_aspas),
  #                   label.buffer = unit(10, ""mm""), label.fontsize = c(16, 12),
  #                   label.family = ""Roboto Condensed"") +
  # geom_mark_circle(aes(filter = name == ""Jony"", 
  #                      label = ""Jony: El Glorioso"", 
  #                      description = desc_jony),
  #                  label.buffer = unit(5, ""mm""), label.fontsize = c(16, 12),
  #                  label.family = ""Roboto Condensed"") +
  scale_x_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.3)) +
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.5)) +
  labs(title = ""Goal Contribution Matrix: Eredivisie (2018-2019 Season)"",
       subtitle = ""Goal Involvement (Goals and/or Assists) as Percentage of Total Club Goals"",
       caption = glue(""
                      Data: soccerway.com & understat.com
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 20),
        plot.subtitle = element_text(size = 16),
        plot.caption = element_text(size = 10),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        panel.grid.minor.x = element_blank()) -> eredivisie_goal_contribution_matrix

eredivisie_goal_contribution_matrix
```

## save

```{r}
ggsave(plot = eredivisie_goal_contribution_matrix, 
       ""../Eredivisie 2018-2019/output/goal_contribution_matrix_plot_eredivisie.png"",
       height = 9, width = 11)
```

```{r}
plot_logo <- add_logo(
  plot_path = ""../Eredivisie 2018-2019/output/goal_contribution_matrix_plot_eredivisie.png"",
  logo_path = ""https://upload.wikimedia.org/wikipedia/commons/0/0f/Eredivisie_nieuw_logo_2017-.svg"",
  logo_position = ""top right"",
  logo_scale = 10)

plot_logo
```

```{r}
image_write(image = plot_logo, 
            ""../Eredivisie 2018-2019/output/goal_contribution_matrix_plot_logo_eredivisie.png"")
```
","2018"
"47",205,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","J-League 2018/j_league.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""December 25, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, ggrepel, glue, extrafont)
loadfonts()
```

```{r}
Sys.setlocale(""LC_ALL"", ""English_United States.932"")
```


```{r}
url <- ""http://www.football-lab.jp/summary/team_ranking/j1/?year=2018&data=chance""
# CSS Selector: #ccsTable1

jleague_chances_raw <- url %>% 
  read_html() %>% 
  html_nodes(""#ccsTable1"") %>% 
  html_table() %>% 
  flatten_df()

```




```{r}
jleague_chances_clean <- jleague_chances_raw %>% 
  set_names(""img"", ""team"", 
            ""avg_attacks"", ""rank_1"", ""avg_shots"", ""rank_2"", 
            ""avg_chance_creation"", ""rank_3"", ""avg_goals"", ""rank_4"", 
            ""shots_per_goal"", ""rank_5"") %>% 
  select(-contains(""rank""), -img) %>% 
  mutate(team = as_factor(team)) %>% 
  mutate_if(is.character, funs(str_remove(., ""%"") %>% as.numeric))

jleague_chances_clean %>% glimpse()
```


```{r}
jleague_chances_clean %>% 
  ggplot(aes(shots_per_goal, avg_chance_creation, color = team)) +
  geom_point() +
  theme_minimal()
```

","2018"
"48",206,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","J-League 2018/j_league_avg_age_value.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""August 25, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Avg. Value vs. Avg. Age

- also look at % of foreign players
- Iniesta, Torres, Podolski?
- 


## Packages

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, rvest, glue, extrafont, ggrepel)
loadfonts()
# library(rvest)
# library(polite)
# library(dplyr)
# library(tidyr)
# library(purrr)
# library(ggplot2)
# library(scales)
# library(ggimage)
# library(stringr)
# library(glue)
```

## 2018 season

```{r}
#\31 022
# //*[@id=""yw1""]/table/tbody/tr[1]/td[1]/a/img
# //*[@id=""yw1""]/table/tbody/tr[1]/td[1]/a/img
# //*[@id=""828""]
# #\38 28
# #yw1 > table > tbody > tr:nth-child(1) > td.zentriert.no-border-rechts > a > img
team_name <- scrape(session) %>% 
  html_nodes(xpath = ""//*[@id='yw1']/table/tbody/tr/td/a/img"") %>% 
  html_attr(""alt"")
```



```{r}
url <- ""https://www.transfermarkt.com/j-league-division-1/startseite/wettbewerb/JAP1/saison_id/2017""

session <- bow(url)

# grab team name from img instead
team_name <- scrape(session) %>% 
  html_nodes(""#yw1 > table > tbody > tr > td.zentriert.no-border-rechts > a > img"") %>% 
  html_attr(""alt"")

avg_age <- scrape(session) %>% 
  html_nodes(""tbody .hide-for-pad:nth-child(5)"") %>% 
  html_text()

avg_value <- scrape(session) %>% 
  html_nodes(""tbody .rechts+ .hide-for-pad"") %>% 
  html_text()

team_img <- scrape(session) %>% 
  html_nodes(""#yw1 > table > tbody > tr > td.zentriert.no-border-rechts > a > img"") %>% 
  html_attr(""src"")
```



```{r}
resultados <- list(team_name, avg_age, avg_value, team_img)

col_name <- c(""team"", ""avg_age"", ""avg_value"", ""img"")

j_league_2018_age_value_raw <- resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name)

j_league_2018_age_value <- j_league_2018_age_value_raw %>% 
  mutate(avg_age = avg_age %>% str_replace_all("","", ""."") %>% as.numeric(),
         avg_value = avg_value %>% 
           str_replace_all(""Th. \200"", ""000"") %>% 
           str_replace("" "", """") %>% 
           as.numeric(),
         img = img %>% str_replace(""/tiny/"", ""/head/"")) %>% 
# Googled Euro-to-Yen exchange rate: 1 Euro = 129.39 Yen (8.25.18)
  mutate(avg_value = (avg_value * 129.39) %>% round(digits = 0),
         avg_value = avg_value / 10000) %>% 
  # fix Kobe manually:
  mutate(avg_value = case_when(
    team == ""Vissel Kobe"" ~ 1020000,
    TRUE ~ avg_value
  )) %>% 
  mutate(avg_value = case_when(
    team == ""Vissel Kobe"" ~ (avg_value * 129.39)/10000,
    TRUE ~ avg_value
  )) %>% 
  mutate(team = case_when(
    team == ""Hokkaido Consadole Sapporo"" ~ ""Consadole Sapporo"",
    TRUE ~ team
  ))

j_league_2018_age_value %>% glimpse()

saveRDS(j_league_2018_age_value, ""../data/j_league_2018_age_value.RDS"")
```


## tategaki funs
```{r}
tategaki <- function(x){
  x <- chartr(""?"", ""?"", x) # ??????
  x <- strsplit(split="""", x)
  sapply(x, paste, collapse=""\n"")
}

tategaki_alt <- function(x){
  x <- stringr::str_replace_all(x, ""?"", ""?"") # ??????
  stringr::str_wrap(x, width = 1)
}
```



```{r fig.height=8, fig.width=10}
j_league_2018_age_value %>% 
  ggplot(aes(x = avg_age, y = avg_value)) +
  geom_image(aes(image = img), size = 0.065) +
  #geom_point(color = ""darkgreen"", size = 6) +
  #geom_label_repel(aes(label = team), size = 3) +
  scale_x_continuous(breaks = c(23, 24, 25, 26, 27, 28),
                     labels = c(23, 24, 25, 26, 27, 28),
                     limits = c(22.5, 28) ) +
  scale_y_continuous(#labels = comma,
                     breaks = c(2000, 4000, 6000, 8000, 10000, 12000, 14000),
                     labels = c(2000, 4000, 6000, 8000, 10000, 12000, 14000) %>% comma) +
  labs(title = ""J??? 2018: ????????????? vs. ????"",
       subtitle = """",
       caption = glue(""
                      ???:transfermarkt.com
                      By: @R_by_Ryo""),
       x = ""????"",
       y = tategaki_alt(""???????? (??)"")) +
  theme_minimal() +
  theme(text = element_text(family = ""IPAexGothic""),
        axis.title.y = element_text(angle = 0, vjust= 0.5)) -> jleague_2018

ggsave(filename = ""j_league_2018_age_value_plot.png"", height = 6, width = 8)
```


```{r fig.width = 20}

x <- seq(3, 9, by = 3)

j_league_2018_age_value %>%
  mutate(x = rep(1:6, each = 3), y = rep(1:3, 6)) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_image(aes(image = img), size = 0.08) +
  geom_text(aes(label = team), 
            family = ""Roboto Condensed"",
            nudge_y = -0.5, size = 3.5) +
  lims(x = c(0, 6.15), y = c(-0.15, 3.15)) +
  theme_void() -> jleague_icon_legend

library(patchwork)
 
jleague_2018 + jleague_icon_legend + plot_layout(ncol = 2, width = c(1, 1.5))
```

- probably scale using magick instead???

Percentage of total value by foreign players?


```{r}
team_links <- scrape(session) %>% 
  html_nodes(""#yw1 > table > tbody > tr > td.zentriert.no-border-rechts > a"") %>% 
  html_attr(""href"")

player_name <- scrape(session) %>% 
  html_nodes() %>% 
  html_attr()


team_links[1]

session_cz <- bow(glue(""{url}{team_links[1]}""))
session_cz <- bow(""https://www.transfermarkt.com/cerezo-osaka/startseite/verein/1022/saison_id/2017"")
# grab name from photo element instead
result_name <- scrape(session_cz) %>% 
  html_nodes("".bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

# grab nationality
result_nationality <- scrape(session_cz) %>% 
  html_nodes(""#yw1 .flaggenrahmen"") %>% 
  html_attr(""title"")

# grab minutes played in league
result_value <- scrape(session_cz) %>% 
  html_nodes("".rechts.hauptlink"") %>% 
  html_text()


```


## 2019 season


```{r}
url <- ""https://www.transfermarkt.com/j-league-division-1/startseite/wettbewerb/JAP1/saison_id/2018""

session <- bow(url)

# grab team name from img instead
team_name <- scrape(session) %>% 
  html_nodes(""#yw1 > table > tbody > tr > td.zentriert.no-border-rechts > a > img"") %>% 
  html_attr(""alt"")

avg_age <- scrape(session) %>% 
  html_nodes(""tbody .hide-for-pad:nth-child(5)"") %>% 
  html_text()

avg_value <- scrape(session) %>% 
  html_nodes(""tbody .rechts+ .hide-for-pad"") %>% 
  html_text()

team_img <- scrape(session) %>% 
  html_nodes(""#yw1 > table > tbody > tr > td.zentriert.no-border-rechts > a > img"") %>% 
  html_attr(""src"")
```



```{r}
resultados <- list(team_name, avg_age, avg_value, team_img)

col_name <- c(""team"", ""avg_age"", ""avg_value"", ""img"")

j_league_2019_age_value_raw <- resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name)

j_league_2019_age_value <- j_league_2019_age_value_raw %>% 
  mutate(avg_age = avg_age %>% str_replace_all("","", ""."") %>% as.numeric(),
         avg_value = avg_value %>% 
           str_replace_all(""Th. \200"", ""000"") %>% 
           str_replace("" "", """") %>% 
           as.numeric(),
         img = img %>% str_replace(""/tiny/"", ""/head/"")) %>% 
# Googled Euro-to-Yen exchange rate: 1 Euro = 126.4 Yen (3.7.19)
  mutate(avg_value = (avg_value * 126.4) %>% round(digits = 0),
         avg_value = avg_value / 10000) %>% 
  mutate(team = case_when(
    team == ""Hokkaido Consadole Sapporo"" ~ ""Consadole Sapporo"",
    TRUE ~ team
  ))

saveRDS(j_league_2019_age_value, ""../data/j_league_2019_age_value.RDS"")
```

```{r fig.height=8, fig.width=10}
j_league_2019_age_value %>%
  ggplot(aes(x = avg_age, y = avg_value)) +
  #geom_label_repel(aes(label = team), vjust = -1.25, size = 3) +
  #geom_label(aes(label = team), vjust = -1.25, size = 2.5) +
  geom_image(aes(image = img), size = 0.065) +
  geom_label_repel(aes(label = team), vjust = -1.15, size = 3, segment.color = NA) +
  scale_x_continuous(breaks = pretty_breaks(5),
                     limits = c(24, 29) ) +
  scale_y_continuous(breaks = c(2000, 4000, 6000, 8000, 10000, 12000, 14000),
                     labels = c(2000, 4000, 6000, 8000, 10000, 12000, 14000) %>% comma,
                     limits = c(3000, 14250)) +
  labs(title = ""J??? 2019: ????????????? vs. ????"",
       subtitle = """",
       caption = glue(""
                      ???:transfermarkt.com
                      By: @R_by_Ryo""),
       x = ""????"",
       y = tategaki_alt(""???????? (??)"")) +
  theme_minimal() +
  theme(text = element_text(family = ""IPAexGothic""),
        axis.title.y = element_text(angle = 0, vjust= 0.5))

ggsave(filename = ""j_league_2019_age_value_plot.png"", height = 6, width = 8)
```

- side-by-side plot
- underneath == comparison difference in teams >>> leave out promoted/relegated? (have as separate)
- Urawa buys Ewerton, Fabricio, Sugimoto (free) which raises avg. player prices considerably
- Kawasaki Frontale >>> Leandro Damiao, Kazuya Yamamura
- Vissel Kobe >>> David VIlla, Sergi Samp,er Iniesta, H. Yamaguchi, Daigo Nishi but also many younger/low value players promoted or return from loan

gt table of differences between 2018 >>> 2019

```{r}

```

","2018"
"49",207,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","J-League 2018/jleague_age_utility.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""March 9, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# MAIN QUESTIONS
- is squad reaching its peak years?
- how much youth is used by teams?
- changes/trends over seasons? overall transfer strategies? (highlight NEW players on plot?)


# R related problems

- how to scale up?
-- instead of copy-paste same code, can use purrr BUT each team needs some manual fixing of names and other small little edits ...
- create function that only needs new team {name}, and insert {primay color} and {secondary color}
-- this can be easily done... 
- introduce semi-transparent grey lines at 50% and Age == 25??

# Packages
```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, rvest, 
               glue, extrafont, ggrepel, magick, ggforce)
loadfonts()
```

# functions

## add_logo functions

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}
```

## tategaki function

```{r}
tategaki <- function(x){
  x <- chartr(""?"", ""?"", x) # ??????
  x <- strsplit(split="""", x)
  sapply(x, paste, collapse=""\n"")
}

tategaki_alt <- function(x){
  x <- stringr::str_replace_all(x, ""?"", ""?"") # ??????
  stringr::str_wrap(x, width = 1)
}
```


# Vissel Kobe

## scrape
```{r}
session <- bow(""https://www.transfermarkt.com/vissel-kobe/leistungsdaten/verein/3958/plus/0?reldata=JAP1%262017"")

print(session)
# ""The path is scrapable for this user-agent"": OK, looks like we are good to go!

# scraping tranfermarkt is a nightmare...
# scrape each col individually then combine later...

# grab name from photo element instead
result_name <- scrape(session) %>% 
  html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

# grab age
result_age <- scrape(session) %>% 
  html_nodes("".posrela+ .zentriert"") %>% 
  html_text()

# grab minutes played in league
result_mins <- scrape(session) %>% 
  html_nodes(""td.rechts"") %>% 
  html_text()
```

## clean

```{r}
# place each vector into list

resultados <- list(result_name, result_age, result_mins)

col_name <- c(""name"", ""age"", ""minutes"")

# then reduce(cbind) to combine them, set names to cols 
resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name) -> results_comb

# NOICE.gif
glimpse(results_comb)

# fix ""strings"" into proper formats, calculate % of minutes appeared
kobe_minutes <- results_comb %>% 
  
  mutate(age = as.numeric(age),
         minutes = minutes %>% 
           str_replace(""\\."", """") %>% 
           str_replace(""'"", """") %>% 
           as.numeric(),
         min_perc = (minutes / 3060) %>% round(digits = 3)) %>% 
  
  filter(!is.na(minutes)) %>% 
  
  separate(name, into = c(""first_name"", ""last_name""), by = "" "") %>%
  # manually fix somes names
  mutate(last_name = case_when(
    first_name == ""Wellington"" ~ ""Wellington"", 
    first_name == ""Seung"" ~ ""S.G. Kim"",
    first_name == ""Leandro"" ~ ""Leandro"",
    first_name == ""Woo"" ~ ""W.Y. Jung"",
    TRUE ~ last_name
  )) %>% 
  
  arrange(desc(min_perc))

# rectanglular highlight for players in their prime:
rect_df <- data.frame(
  xmin = 26, xmax = 31,
  ymin = -Inf, ymax = Inf
)

glimpse(kobe_minutes)
```



## plot

```{r fig.height=6, fig.width=8}
kobe_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_vline(xintercept = 25, alpha = 0.4, color = ""grey20"") +
  geom_hline(yintercept = 0.5, alpha = 0.4, color = ""grey20"") +
  geom_mark_rect(aes(filter = age >= 26 & age <= 31), 
                 description = ""?????*"", con.cap = 0,
                 color = NA, fill = ""firebrick1"", alpha = 0.5) + 
  #geom_point(color = ""firebrick1"", size = 2.5) +
  geom_point(color = ""darkred"", size = 2.5) +
  geom_text_repel(
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""??"", 
    y = tategaki_alt(""????(%)""),  
    title = ""???????: ??-????????"",
    subtitle = ""J-League 2018 Season (100% = 3060?)"",
    caption = glue(""
                   ???: transfermarkt.com
                   *??
                   ?: @R_by_Ryo""))  +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    plot.title = element_text(color = ""darkred"", size = 16, face = ""bold""),
    plot.subtitle = element_text(size = 14),
    axis.title.y = element_text(angle = 0, vjust= 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    panel.border = element_rect(color = ""darkred"", size = 1.25)) -> kobe_plot
```

```{r}
ggsave(plot = kobe_plot, ""../J-League 2018/output/kobe_plot.png"",
       height = 6, width = 8)
```



```{r}
plot_logo <- add_logo(plot_path = ""../J-League 2018/output/kobe_plot.png"",
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/8/87/VisselKobe.png"",
                      logo_position = ""top right"",
                      logo_scale = 20)

plot_logo
```

```{r}
image_write(image = plot_logo, ""../J-League 2018/output/kobe_logo_plot.png"")
```

### english version

```{r fig.height=6, fig.width=8}
kobe_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_vline(xintercept = 25, alpha = 0.4, color = ""grey20"") +
  geom_hline(yintercept = 0.5, alpha = 0.4, color = ""grey20"") +
  geom_mark_rect(aes(filter = age >= 26 & age <= 31), 
                 description = ""Prime Age*"", con.cap = 0,
                 color = NA, fill = ""firebrick1"", alpha = 0.5) + 
  geom_point(color = ""darkred"", size = 2.5) +
  geom_text_repel(
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""Current Age (As of March 30, 2019)"", 
    y = ""% of Minutes Played"",  
    title = ""Vissel Kobe: Age-Utility Matrix"",
    subtitle = ""J-League 2018 Season (100% = 3060 minutes)"",
    caption = glue(""
                   Data: transfermarkt.com
                   *Subjective
                   Created by: @R_by_Ryo""))  +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    plot.title = element_text(color = ""darkred"", size = 16, face = ""bold""),
    plot.subtitle = element_text(size = 14),
    #axis.title.y = element_text(angle = 0, vjust= 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    panel.border = element_rect(color = ""darkred"", size = 1.25)) -> kobe_plot_eng
```

```{r}
ggsave(plot = kobe_plot_eng, ""../J-League 2018/output/kobe_plotENG.png"",
       height = 6, width = 8)
```

```{r}
plot_logo <- add_logo(plot_path = ""../J-League 2018/output/kobe_plotENG.png"",
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/8/87/VisselKobe.png"",
                      logo_position = ""top right"",
                      logo_scale = 20)

plot_logo
```

```{r}
image_write(image = plot_logo, ""../J-League 2018/output/kobe_logo_plotENG.png"")
```


# FC Tokyo
## scrape Tokyo

```{r}
session <- bow(""https://www.transfermarkt.com/fc-tokyo/leistungsdaten/verein/6631/plus/0?reldata=JAP1%262017"")

print(session)
# ""The path is scrapable for this user-agent"": OK, looks like we are good to go!

# scraping tranfermarkt is a nightmare...
# scrape each col individually then combine later...

# grab name from photo element instead
result_name <- scrape(session) %>% 
  html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

# grab age
result_age <- scrape(session) %>% 
  html_nodes("".posrela+ .zentriert"") %>% 
  html_text()

# grab minutes played in league
result_mins <- scrape(session) %>% 
  html_nodes(""td.rechts"") %>% 
  html_text()
```

## clean tokyo

```{r}
# place each vector into list

resultados <- list(result_name, result_age, result_mins)

col_name <- c(""name"", ""age"", ""minutes"")

# then reduce(cbind) to combine them, set names to cols 
resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name) -> results_comb

# NOICE.gif
glimpse(results_comb)

# fix ""strings"" into proper formats, calculate % of minutes appeared
tokyo_minutes <- results_comb %>% 
  
  mutate(age = as.numeric(age),
         minutes = minutes %>% 
           str_replace(""\\."", """") %>% 
           str_replace(""'"", """") %>% 
           as.numeric(),
         min_perc = (minutes / 3060) %>% round(digits = 3)) %>% 
  
  filter(!is.na(minutes)) %>% 
  
  separate(name, into = c(""first_name"", ""last_name""), by = "" "") %>%
  # manually fix somes names
  mutate(last_name = case_when(
    first_name == ""Lins"" ~ ""Lins"",
    first_name == ""Hyeon"" ~ ""H.S. Jang"",
    TRUE ~ last_name)) %>%
  
  arrange(desc(min_perc))

# rectanglular highlight for players in their prime:
rect_df <- data.frame(
  xmin = 26, xmax = 31,
  ymin = -Inf, ymax = Inf
)

glimpse(tokyo_minutes)
```

## plot Tokyo

```{r fig.height=6, fig.width=8}
tokyo_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_vline(xintercept = 25, alpha = 0.4, color = ""grey20"") +
  geom_hline(yintercept = 0.5, alpha = 0.4, color = ""grey20"") +
  geom_mark_rect(aes(filter = age >= 26 & age <= 31), 
                 description = ""?????*"", con.cap = 0,
                 color = NA, fill = ""#271672"", alpha = 0.5) + 
  geom_point(color = ""#DD2220"", size = 2.5) +
  geom_text_repel(
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""??"", 
    y = tategaki_alt(""????(%)""),  
    title = ""FC??: ??-????????"",
    subtitle = ""J-League 2018 Season (100% = 3060?)"",
    caption = glue(""
                   ???: transfermarkt.com
                   *??
                   ?: @R_by_Ryo"")) +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    panel.border = element_rect(color = ""#271672"", size = 1.25),
    plot.title = element_text(color = ""#271672"", size = 16, face = ""bold""),
    plot.subtitle = element_text(color = ""#DD2220"", size = 14),
    axis.title.y = element_text(angle = 0, vjust= 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)) -> fctokyo_plot
```

```{r}
ggsave(plot = fctokyo_plot, ""../J-League 2018/output/fctokyo_plot.png"",
       height = 6, width = 8)
```



```{r}
plot_logo <- add_logo(plot_path = ""../J-League 2018/output/fctokyo_plot.png"",
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/4/45/FCTokyo.png"",
                      logo_position = ""top right"",
                      logo_scale = 18)

plot_logo
```

```{r}
image_write(image = plot_logo, ""../J-League 2018/output/fctokyo_logo_plot.png"")
```



# Shonan Bellmare 2019

## scrape

```{r}
# https://www.transfermarkt.com/shonan-bellmare/leistungsdaten/verein/8457/plus/0?reldata=JAP1%262018
session <- bow(""https://www.transfermarkt.com/shonan-bellmare/leistungsdaten/verein/8457/plus/0?reldata=JAP1%262018"")

print(session)
# ""The path is scrapable for this user-agent"": OK, looks like we are good to go!

# scraping tranfermarkt is a nightmare...
# scrape each col individually then combine later...

# grab name from photo element instead
result_name <- scrape(session) %>% 
  html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

# grab age
result_age <- scrape(session) %>% 
  html_nodes("".posrela+ .zentriert"") %>% 
  html_text()

# grab minutes played in league
result_mins <- scrape(session) %>% 
  html_nodes(""td.rechts"") %>% 
  html_text()
```


## clean

- NEED TO UPDATE AFTER EVERYMATCH DAY (ex. 3 Matches = 270 min >>> 4 Matches = 360 Min)

```{r}
# place each vector into list

resultados <- list(result_name, result_age, result_mins)

col_name <- c(""name"", ""age"", ""minutes"")

# then reduce(cbind) to combine them, set names to cols 
resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name) -> results_comb

# NOICE.gif
glimpse(results_comb)

# fix ""strings"" into proper formats, calculate % of minutes appeared
shonan_minutes <- results_comb %>% 
  
  mutate(age = as.numeric(age),
         minutes = minutes %>% 
           str_replace(""\\."", """") %>% 
           str_replace(""'"", """") %>% 
           as.numeric(),
         min_perc = (minutes / 360) %>% round(digits = 3)) %>% 
  
  filter(!is.na(minutes)) %>% 
  
  separate(name, into = c(""first_name"", ""last_name""), by = "" "") %>%
  ## manually fix somes names
  mutate(last_name = case_when(
    first_name == ""Freire"" ~ ""Freire"",
    TRUE ~ last_name)) %>%
  
  arrange(desc(min_perc))

# rectanglular highlight for players in their prime:
rect_df <- data.frame(
  xmin = 26, xmax = 31,
  ymin = -Inf, ymax = Inf
)

glimpse(shonan_minutes)
```


## plot


```{r fig.height=6, fig.width=8}
shonan_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_vline(xintercept = 25, alpha = 0.4, color = ""grey20"") +
  geom_hline(yintercept = 0.5, alpha = 0.4, color = ""grey20"") +
  # geom_rect(
  #   data = rect_df, inherit.aes = FALSE,
  #   aes(xmin = xmin, xmax = xmax, 
  #       ymin = ymin, ymax = ymax),
  #   alpha = 0.5,
  #   fill = ""#67B356"") +
  geom_mark_rect(aes(filter = age >= 26 & age <= 31), 
                 description = ""?????*"", con.cap = 0,
                 color = NA, fill = ""#67B356"", alpha = 0.5, size = 0.01) +
  geom_point(color = ""#103C95"", size = 2.5) +
  geom_text_repel(
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1.05), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""?? (3?22?2019?)"", 
    y = tategaki_alt(""????(%)""), 
    title = ""???????: ??-????????"",
    subtitle = ""J-League 2019 Season (4?: 100% = 360?)"",
    caption = glue(""
                   ???: transfermarkt.com
                   *??
                   ?: @R_by_Ryo"")) +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    #panel.grid.minor.y = element_blank(),
    panel.border = element_rect(color = ""#67B356"", size = 1.25),
    plot.title = element_text(color = ""#67B356"", size = 16, face = ""bold""),
    plot.subtitle = element_text(color = ""#103C95"", size = 14),
    axis.title.y = element_text(angle = 0, vjust= 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)) -> shonan_plot
```




```{r}
ggsave(plot = shonan_plot, ""../J-League 2018/output/shonan_plot.png"",
       height = 6, width = 8)
```



```{r}
plot_logo <- add_logo(plot_path = ""../J-League 2018/output/shonan_plot.png"",
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/2/2c/ShonanBellmare.png"",
                      logo_position = ""top right"",
                      logo_scale = 20)

plot_logo
```

```{r}
image_write(image = plot_logo, ""../J-League 2018/output/shonan_logo_plot.png"")
```



# Shimizu S-Pulse

## scrape

```{r}
# https://www.transfermarkt.com/shonan-bellmare/leistungsdaten/verein/8457/plus/0?reldata=JAP1%262018
session <- bow(""https://www.transfermarkt.com/shimizu-s-pulse/leistungsdaten/verein/1062/plus/0?reldata=JAP1%262017"")

print(session)
# ""The path is scrapable for this user-agent"": OK, looks like we are good to go!

# scraping tranfermarkt is a nightmare...
# scrape each col individually then combine later...

# grab name from photo element instead
result_name <- scrape(session) %>% 
  html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

# grab age
result_age <- scrape(session) %>% 
  html_nodes("".posrela+ .zentriert"") %>% 
  html_text()

# grab minutes played in league
result_mins <- scrape(session) %>% 
  html_nodes(""td.rechts"") %>% 
  html_text()
```


## clean

- NEED TO UPDATE AFTER EVERYMATCH DAY (ex. 3 Matches = 270 min >>> 4 Matches = 360 Min)

```{r}
# place each vector into list

resultados <- list(result_name, result_age, result_mins)

col_name <- c(""name"", ""age"", ""minutes"")

# then reduce(cbind) to combine them, set names to cols 
resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name) -> results_comb

# NOICE.gif
glimpse(results_comb)

# fix ""strings"" into proper formats, calculate % of minutes appeared
shimizu_minutes <- results_comb %>% 
  
  mutate(age = as.numeric(age),
         minutes = minutes %>% 
           str_replace(""\\."", """") %>% 
           str_replace(""'"", """") %>% 
           as.numeric(),
         min_perc = (minutes / 3060) %>% round(digits = 3)) %>% 
  
  filter(!is.na(minutes)) %>% 
  
  separate(name, into = c(""first_name"", ""last_name""), by = "" "") %>%
  ## manually fix somes names
  mutate(last_name = case_when(
    first_name == ""Freire"" ~ ""Freire"",
    first_name == ""Crislan"" ~ ""Crislan"",
    first_name == ""Douglas"" ~ ""Douglas"",
    first_name == ""Seok"" ~ ""S.H. Hwang"",
    TRUE ~ last_name)) %>%
  
  arrange(desc(min_perc))

# rectanglular highlight for players in their prime:
rect_df <- data.frame(
  xmin = 26, xmax = 31,
  ymin = -Inf, ymax = Inf
)

glimpse(shimizu_minutes)
```


## plot
- lighter blue: #0D6BA5
- lightish blue: #0569AE
- orange: #F29900

```{r fig.height=6, fig.width=8}
shimizu_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_vline(xintercept = 25, alpha = 0.4, color = ""grey20"") +
  geom_hline(yintercept = 0.5, alpha = 0.4, color = ""grey20"") +
  geom_mark_rect(aes(filter = age >= 26 & age <= 31), 
                 description = ""?????*"", con.cap = 0,
                 color = NA, fill = ""#F29900"", alpha = 0.5, size = 0.01) +
  geom_point(color = ""#0569AE"", size = 2.5) +
  geom_text_repel(
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1.05), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""?? (3?22?2019?)"", 
    y = tategaki_alt(""????(%)""), 
    title = ""???????: ??-????????"",
    subtitle = ""J-League 2018 Season (100% = 3060?)"",
    caption = glue(""
                   *??
                   ???: transfermarkt.com
                   ?: @R_by_Ryo"")) +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    panel.border = element_rect(color = ""#F29900"", size = 1.25),
    plot.title = element_text(color = ""#F29900"", size = 16, face = ""bold""),
    plot.subtitle = element_text(color = ""#0569AE"", size = 14),
    axis.title.y = element_text(angle = 0, vjust= 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)) -> shimizu_plot
```




```{r}
ggsave(plot = shimizu_plot, ""../J-League 2018/output/shimizu_plot.png"",
       height = 6, width = 8)
```



```{r}
plot_logo <- add_logo(plot_path = ""../J-League 2018/output/shimizu_plot.png"",
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/4/4c/ShimizuS-Pulse.png"",
                      logo_position = ""top right"",
                      logo_scale = 20)

plot_logo
```

```{r}
image_write(image = plot_logo, ""../J-League 2018/output/shimizu_logo_plot.png"")
```

### english version


```{r fig.height=6, fig.width=8}
shimizu_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_vline(xintercept = 25, alpha = 0.4, color = ""grey20"") +
  geom_hline(yintercept = 0.5, alpha = 0.4, color = ""grey20"") +
  geom_mark_rect(aes(filter = age >= 26 & age <= 31), 
                 description = ""Prime Age*"", con.cap = 0,
                 color = NA, fill = ""#F29900"", alpha = 0.5, size = 0.01) +
  geom_point(color = ""#0569AE"", size = 2.5) +
  geom_text_repel(
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1.05), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""Current Age (As of March 30, 2019)"", 
    y = ""% of Minutes Played"", 
    title = ""Shimizu S-Pulse: Age-Utility Matrix"",
    subtitle = ""J-League 2018 Season (100% = 3060 minutes)"",
    caption = glue(""
                   *Subjective
                   Data: transfermarkt.com
                   Created by: @R_by_Ryo"")) +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    panel.border = element_rect(color = ""#F29900"", size = 1.25),
    plot.title = element_text(color = ""#F29900"", size = 16, face = ""bold""),
    plot.subtitle = element_text(color = ""#0569AE"", size = 14),
    #axis.title.y = element_text(angle = 0, vjust= 0.5),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)) -> shimizu_plot_eng
```




```{r}
ggsave(plot = shimizu_plot_eng, ""../J-League 2018/output/shimizu_plotENG.png"",
       height = 6, width = 8)
```



```{r}
plot_logo <- add_logo(plot_path = ""../J-League 2018/output/shimizu_plotENG.png"",
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/4/4c/ShimizuS-Pulse.png"",
                      logo_position = ""top right"",
                      logo_scale = 20)

plot_logo
```

```{r}
image_write(image = plot_logo, ""../J-League 2018/output/shimizu_logo_plotENG.png"")
```
","2018"
"50",208,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","J-League 2018/player_goal_contribution_matrix.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""March 19, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# % team goal involvement (????????)

- inspiration: https://www.reddit.com/r/soccer/comments/b2wdfn/oc_which_players_are_most_involved_in_their_teams/
- first try with FC Tokyo
- then scale it up for all teams
- do 2018 season as only a few games into 2019 season...


# pkgs

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, 
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

# just FC Tokyo

## scrape

```{r}
url <- ""https://www.transfermarkt.com/fc-tokyo/leistungsdaten/verein/6631/reldata/JAP1%262017/plus/1""

# .items
# .items > tbody:nth-child(2)
session <- bow(url)

# fctokyo_table <- scrape(session) %>% 
#   html_nodes("".items > tbody:nth-child(2)"") %>% flatten()
#   magrittr::extract(2)
#   html_table(fill = TRUE) %>% 
#   flatten_df()
  #magrittr::extract(1)
  
# tr.odd:nth-child(1) > td:nth-child(7)
  
player_name <- scrape(session) %>% 
  html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 
  
num_goals <- scrape(session) %>% 
  html_nodes(""td:nth-child(7)"") %>% 
  html_text()

num_assists <- scrape(session) %>% 
  html_nodes(""td:nth-child(8)"") %>% 
  html_text()


resultados <- list(player_name, num_goals, num_assists)
col_names <- c(""name"", ""goals"", ""assists"")
```

## clean/tidy

```{r}
fctokyo_results <- resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_names)

fctokyo_df <- fctokyo_results %>% 
  mutate_at(.vars = c(""goals"", ""assists""), ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(total_goals = sum(goals),
         total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         assist_contrib = assists/total_goals)

```

## plot

```{r}
fctokyo_plot <- fctokyo_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point() +
  scale_x_continuous(labels = percent) +
  scale_y_continuous(labels = percent) +
  labs(title = ""Team Goal Involvement as Percentage of Total Club Goals"",
       subtitle = ""J-League 2018 Season"",
       caption = glue(""
                      Data: transfermarkt
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal()

ggsave(plot = fctokyo_plot, filename = ""../J-League 2018/fctokyo_plot.png"")
```

## add_logo

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}
```

## tategaki function

```{r}
tategaki <- function(x){
  x <- chartr(""?"", ""?"", x) # ??????
  x <- strsplit(split="""", x)
  sapply(x, paste, collapse=""\n"")
}

tategaki_alt <- function(x){
  x <- stringr::str_replace_all(x, ""?"", ""?"") # ??????
  stringr::str_wrap(x, width = 1)
}
```


```{r}
logo_path <- ""https://tmssl.akamaized.net//images/logo/normal/jap1.png?lm=1546692506""

add_logo(plot_path = glue(""{here::here()}/J-League 2018/fctokyo_plot.png""),
         logo_path = logo_path, logo_position = ""top right"")
```




# all teams 

## scrape

```{r}
# #yw1 > table:nth-child(2) > tbody:nth-child(3) > tr:nth-child(1) > td:nth-child(2) > a:nth-child(1)

url <- ""https://www.transfermarkt.com/j1-league/startseite/wettbewerb/JAP1/plus/?saison_id=2017""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#yw1 > table > tbody > tr > td.zentriert.no-border-rechts > a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, ""team_name"", NA, NA, ""team_num"", NA, NA), sep = ""/"") %>% 
  mutate(link = glue(""https://www.transfermarkt.com/{team_name}/leistungsdaten/verein/{team_num}/reldata/JAP1%262017/plus/1""))

# for each team link:

player_name_info <- function(link) {
  
  session <- bow(link)
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 
  
}

num_goals_info <- function(link) {
  
  session <- bow(link)
  
  num_goals_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(7)"") %>% 
    html_text()
}

num_assists_info <- function(link) {
  
  session <- bow(link)
  
  num_assists_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(8)"") %>% 
    html_text()
}

# BIG FUNCTION

jleague_stats_info <- function(link) {
  
  session <- bow(link)
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

  num_goals_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(7)"") %>% 
    html_text()

  num_assists_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(8)"") %>% 
    html_text()
  
  resultados <- list(player_name_info, num_goals_info, num_assists_info)
  col_names <- c(""name"", ""goals"", ""assists"") 
  
  jleague_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names)
  
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
goal_contribution_df_ALL <- map2(.x = team_links_df$link, 
                             .y = team_links_df$team_name,
                             ~ jleague_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df <- goal_contribution_df_ALL %>% 
  reduce(rbind)

## save
saveRDS(goal_contribution_df, file = glue(""{here::here()}/data/goal_contrib_df.RDS""))
```

### piece-wise

```{r}
# break scraping into groups of 4-5 teams, then combine:
goal_contribution_df1 <- map2(.x = team_links_df$link[1:3], 
                             .y = team_links_df$team_name[1:3],
                             ~ jleague_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df2 <- map2(.x = team_links_df$link[4:8], 
                             .y = team_links_df$team_name[4:8],
                             ~ jleague_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df3 <- map2(.x = team_links_df$link[9:13], 
                             .y = team_links_df$team_name[9:13],
                             ~ jleague_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df4 <- map2(.x = team_links_df$link[14:18], 
                             .y = team_links_df$team_name[14:18],
                             ~ jleague_stats_info(link = .x) %>% mutate(team = .y))

a1 <- goal_contribution_df1 %>% reduce(rbind)
a2 <- goal_contribution_df2 %>% reduce(rbind)
a3 <- goal_contribution_df3 %>% reduce(rbind)
a4 <- goal_contribution_df4 %>% reduce(rbind)


resultados_grande <- list(a1, a2, a3, a4)

goal_contribution_df <- resultados_grande %>% 
  reduce(rbind)

## save
saveRDS(goal_contribution_df, file = glue(""{here::here()}/data/goal_contrib_df.RDS""))
goal_contribution_df <- readRDS(file = glue(""{here::here()}/data/goal_contrib_df.RDS""))
```

```{r Miscellaneous}
goal_contribution_df1 <- map2(.x = team_links_df$link[1:3], 
                              .y = team_links_df$team_name[1:3],
                              ~ jleague_stats_info(link = .x) %>% 
                                set_names(., nm = seq_along(.y)))
# goal_contribution_df <- map(team_links_df$link[1:3], ~ jleague_stats_info) %>% 
#   set_names(team_links_df$team_name[1:3])

# YES
the_big_data <- team_links_df[1:3,] %>% 
  ## map each team URL link to the data-getting function
  mutate(data = map(team_links_df$link[1:3], ~ jleague_stats_info(.x))) %>% 
  ## set names of each data list to team name
  mutate(data = data %>% set_names(team_links_df$team_name[1:3]))

the_big_data2$data$`vissel-kobe`$goals

# clean/tidy each team data list-column
the_big_data2 %>% 
  mutate(data = map(data, ~ .x %>% 
                      mutate_at(.vars = c(""goals"", ""assists""), 
                                ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
                      mutate(total_goals = sum(goals),
                             total_assists = sum(assists),
                             goal_contrib = goals/total_goals,
                             assist_contrib = assists/total_goals))) -> big_data3

big_data3$data
```


- mutate in team name into DATA itself
- take out all the data >>> bind_rows into single df
- `mutate()` in similar way inside list >>> separate out and save each as separate dataframe
- make ggplot function >>> inputs: colors, team name in title

## clean

```{r}
goal_contribution_clean_df <- goal_contribution_df %>% 
  mutate_at(.vars = c(""goals"", ""assists""), 
            ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(team = team %>% str_replace_all(., ""-"", "" "") %>% str_to_title) %>% 
  group_by(team) %>% 
  mutate(total_goals = sum(goals),
         total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         assist_contrib = assists/total_goals) %>% 
  ungroup()

## save
saveRDS(goal_contribution_clean_df, 
        file = glue(""{here::here()}/data/goal_contrib_clean_df.RDS""))
goal_contribution_clean_df <- readRDS(file = glue(""{here::here()}/data/goal_contrib_clean_df.RDS""))
```

```{r}
goal_contribution_clean_df %>% 
  ggplot(aes(goal_contrib)) +
  geom_histogram()

goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib)) +
  geom_histogram()

goal_contribution_clean_df %>% 
  summarize(mean_goals = mean(total_goals),
            mean_assists = mean(total_assists),
            median_goals_contrib = median(goal_contrib),
            median_assists_contrib = median(assist_contrib))

goal_contribution_clean_df %>% 
  summarize(iqr_goals = quantile(goal_contrib)[4],
         iqr_assists = quantile(assist_contrib)[4])

goal_contribution_clean_df %>% 
  ggplot(aes(goal_contrib)) +
  geom_histogram() +
  geom_vline(xintercept = quantile(goal_contribution_clean_df$goal_contrib)[4])
```

- numbers mostly 0s (defenders, goalkeepers, etc.) >>> positive skew
- median == 0!
- mean will be very low

## plot

```{r fig.width = 10, fig.height = 8}  
goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.25 | assist_contrib < 0.15),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.25 | assist_contrib > 0.15),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.25, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.15, color = ""grey20"", alpha = 0.4) +
  # gghighlight::gghighlight(goal_contrib > 0.25 | assist_contrib > 0.15,
  #                          label_key = name, 
  #                          label_params = list(size = 3.5)) +
  geom_text_repel(data = goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.25 | assist_contrib > 0.15),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 7, size = 5, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  scale_x_continuous(labels = percent_format(accuracy = 1), 
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.3)) +
  scale_y_continuous(labels = percent_format(accuracy = 1), 
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.5)) +
  labs(title = ""Team Goal Involvement as Percentage of Total Club Goals"",
       subtitle = ""J.League 2018 Season"",
       caption = glue(""
                      Data: transfermarkt.com
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 20),
        plot.subtitle = element_text(size = 18),
        plot.caption = element_text(size = 8),
        axis.title = element_text(size = 15),
        axis.text = element_text(size = 14),
        panel.grid.minor.x = element_blank()) -> goal_contribution_matrix
```

- gghighlight with geom_text_repel() instead??? PR?
- contribution score: goals + assist / 2 ?
- in Japanese: ?????


```{r fig.width = 10, fig.height = 8}  
goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.25 | assist_contrib < 0.15),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.25 | assist_contrib > 0.15),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.25, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.15, color = ""grey20"", alpha = 0.4) +
  geom_text_repel(data = goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.25 | assist_contrib > 0.15),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 7, size = 5, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  scale_x_continuous(labels = percent_format(accuracy = 1), 
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.3)) +
  scale_y_continuous(labels = percent_format(accuracy = 1), 
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.5)) +
  labs(title = ""????? (?????????????)"",
       subtitle = ""J.League 2018 ????"",
       caption = glue(""
                      ???: transfermarkt.com
                      ?: @R_by_Ryo""),
       x = ""??????"",
       y = tategaki_alt(""?????"")) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 20),
        plot.subtitle = element_text(size = 18),
        plot.caption = element_text(size = 8),
        axis.title = element_text(size = 15),
        axis.title.y = element_text(angle = 0, vjust= 0.5),
        axis.text = element_text(size = 14),
        panel.grid.minor.x = element_blank()) -> goal_contribution_matrix_jp
```



```{r}
ggsave(plot = goal_contribution_matrix_jp, 
       ""../J-League 2018/output/goal_contribution_matrix_plot_jp.png"",
       height = 8, width = 10)
```



```{r}
plot_logo <- add_logo(
  plot_path = ""../J-League 2018/output/goal_contribution_matrix_plot_jp.png"",
  logo_path = ""https://upload.wikimedia.org/wikipedia/en/3/31/J.League_%28local%29.png"",
  logo_position = ""top right"",
  logo_scale = 18)

plot_logo
```

```{r}
image_write(image = plot_logo, 
            ""../J-League 2018/output/goal_contribution_matrix_plot_jp_logo.png"")
```
","2018"
"51",209,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","J-League 2018/player_turnover.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""February 24, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r}
pacman::p_load(tidyverse, rvest, polite, scales)
```



## player data

```{r}
# div.box:nth-child(3) > div:nth-child(3) > table:nth-child(1) > tbody:nth-child(2) > tr:nth-child(1) > td:nth-child(15)

# div.box:nth-child(3) > div:nth-child(3) > table:nth-child(1) > tbody:nth-child(2) > tr:nth-child(1)

## player minutes from player page
# .box:th-child(3) .rechts

## player URL from team page
```

","2018"
"52",210,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","J-League 2019/goal_minutes.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""10/19/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Packages

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick, ggtext)
loadfonts()
```


```{r}
url <- ""https://data.j-league.or.jp/SFMS02/?match_card_id=21513""

session <- bow(url)

url %>% 
  read_html() %>% 
  html_nodes("".score-board-pk-b > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  purrr::flatten_df() %>% 
  View()


url %>% 
  read_html() %>% 
  html_nodes(""td.right-area > table:nth-child(1)"") %>% #html_text() %>% View()
  html_table(fill = TRUE) %>% 
  purrr::flatten_df() %>% 
  View()

thingy22 <- url %>% 
  read_html() %>% 
  html_nodes(""td.left-area > table:nth-child(1)"") 


thingy <- url %>% 
  read_html() %>% 
  html_nodes(""td.right-area > table:nth-child(1)"")   

if (length(xml_contents(thingy)) == 0) {
  thingy <- tibble(name = """",
                   minute = """")
}

if (length(xml_contents(thingy22)) == 0) {
  thingy22 <- tibble(name = """",
                   minute = """")
}

thingy22 %>% 
  html_table(fill = TRUE) %>% 
  purrr::flatten_df() %>% # %>% View()
  rename(name = X1, minute = X2)



"".score-board-pk-b > table:nth-child(1) > tbody:nth-child(1) > tr:nth-child(1)""
""td.right-area > table:nth-child(1)""
""td.right-area""
```


LEFT == HOME
RIGHT == AWAY


```{r}
url %>% 
  read_html() %>% 
  html_nodes("".score-board-b > table:nth-child(1)"") %>% 
  html_text() %>% View()
  .[[1]] %>% 
  html_table(fill = TRUE)
```

or just grab score from starting page



","2019"
"53",214,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","La Liga 2018-2019/player_goal_contribution_matrix.Rmd","---
title: ""La Liga""
author: ""RN7""
date: ""5/24/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# pkgs

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

## add_logo

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))
}
```


# La Liga

## webscrape soccerway

```{r}
url <- ""https://us.soccerway.com/national/spain/primera-division/20182019/regular-season/r47983/""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#page_competition_1_block_competition_tables_7_block_competition_league_table_1_table .large-link a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, NA, NA, ""team_name"", ""team_num""), sep = ""/"") %>% 
  mutate(link = glue(""
                     https://us.soccerway.com/teams/spain/{team_name}/{team_num}/squad/""),
         stat_link = glue(""{link %>% str_replace('squad', 'statistics')}""))

# for each team link:

player_name_info <- function(session) {
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#page_team_1_block_team_squad_3-table .name.large-link"") %>% 
    html_text()
}

num_goals_info <- function(session) {

  num_goals_info <- scrape(session) %>% 
    html_nodes("".goals"") %>% 
    html_text()
  
  num_goals_info_clean <- num_goals_info[-1]
}

num_assists_info <- function(session) {

  num_assists_info <- scrape(session) %>% 
    html_nodes("".assists"") %>% 
    html_text()
  
  num_assists_info_clean <- num_assists_info[-1]
}

team_goals_info <- function(session) {
  team_goals_info <- scrape(session) %>% 
    html_nodes(""tr.first:nth-child(6) > td:nth-child(2)"") %>% 
    html_text()
}

# BIG FUNCTION
laliga_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  laliga_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names)
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
laliga_goal_contribution_df_ALL <- map2(.x = team_links_df$link,
                .y = team_links_df$stat_link,
                ~ laliga_stats_info(link = .x, statlink = .y))

laliga_goal_contribution_df <- laliga_goal_contribution_df_ALL %>% 
  set_names(team_links_df$team_name) %>% 
  bind_rows(.id = ""team_name"")

## save
saveRDS(laliga_goal_contribution_df, file = glue(""{here::here()}/data/laliga_goal_contrib_df_soccerway.RDS""))
```

## clean

```{r}
laliga_goal_contribution_clean_df <- laliga_goal_contribution_df %>% 
  mutate_at(.vars = c(""goals"", ""assists""), 
            ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(team = team_name %>% str_replace_all(., ""-"", "" "") %>% str_to_title,
         total_goals = as.numeric(team_goals)) %>% 
  group_by(team) %>% 
  mutate(total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         ## as/tot_goals because looking at perspective of contrib to goals.
         ## Will be an underestimation as not all goals have assists.
         ## a.k.a. not looking at % of club assists assisted but % of club goals assisted
         assist_contrib = assists/total_goals) %>% 
  ungroup() %>% 
  select(-team_name, -team_goals)

## save
saveRDS(laliga_goal_contribution_clean_df, 
        file = glue(""{here::here()}/data/laliga_goal_contrib_clean_df.RDS""))
laliga_goal_contribution_clean_df <- readRDS(file = glue(""{here::here()}/data/laliga_goal_contrib_clean_df.RDS""))
```

## plot

- Aspas exceeds his xG (again) to save Celta Vigo from relegation (again)!
-
-

```{r fig.width = 10, fig.height = 8}  
## Description text
## Iago Aspas
desc_aspas <- ""With 20 Goals from 12.47 xG, Iago Aspas greatly exceeded his xG as he heroically saved Celta Vigo from relegation yet again!""

## Jony   xA90 of 0.29 (tied 3rd highest, minimum 30 games)
desc_jony <- ""With 10 assists amounting to 34% of Alavs' xA, Jony had his career-best season as he helped Alavs contend for a European place.""

## Messi
desc_goat <- ""With total contribution nearly double of the next best, 36 Goals from a xG of 26, etc. Messi led almost every metric in La Liga this season!""

## PLOT!
laliga_goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = laliga_goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.225 | assist_contrib < 0.125),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = laliga_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.225 | assist_contrib > 0.125),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.225, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.125, color = ""grey20"", alpha = 0.4) +
  geom_text_repel(data = laliga_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.225 | assist_contrib > 0.125,
                           !name %in% c(""Iago Aspas"", ""L. Messi"", 
                                        ""Jony"", ""Pablo Sarabia"")),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 15, size = 4, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  geom_text(data = laliga_goal_contribution_clean_df %>%
              filter(name == ""Pablo Sarabia""),
            aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""),
            size = 4,
            nudge_x = -0.02, nudge_y = 0) +
  geom_mark_circle(aes(filter = name == ""L. Messi"", 
                       label = ""Lionel Messi: GOAT"",
                        description = desc_goat),
                    label.family = ""Roboto Condensed"", label.fontsize = c(16, 12)) +
  geom_mark_circle(aes(filter = name == ""Iago Aspas"", 
                     label = ""Iago Aspas: The Hero of Vigo"",
                        description = desc_aspas),
                    label.buffer = unit(10, ""mm""), label.fontsize = c(16, 12),
                    label.family = ""Roboto Condensed"") +
  geom_mark_circle(aes(filter = name == ""Jony"", 
                       label = ""Jony: El Glorioso"", 
                       description = desc_jony),
                   label.buffer = unit(5, ""mm""), label.fontsize = c(16, 12),
                   label.family = ""Roboto Condensed"") +
  scale_x_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.33)) +
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.55)) +
  labs(title = ""Goal Contribution Graph: La Liga (2018-2019 Season)"",
       subtitle = ""Goal Involvement (Goals and/or Assists) as Percentage of Total Club Goals"",
       caption = glue(""
                      Data: soccerway.com & understat.com
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 20),
        plot.subtitle = element_text(size = 16),
        plot.caption = element_text(size = 10),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        panel.grid.minor.x = element_blank()) -> laliga_goal_contribution_matrix

laliga_goal_contribution_matrix
```

## save

```{r}
ggsave(plot = laliga_goal_contribution_matrix, 
       ""../La Liga 2018-2019/output/goal_contribution_matrix_plot_laliga.png"",
       height = 8, width = 10)
```

```{r}
plot_logo <- add_logo(
  plot_path = ""../La Liga 2018-2019/output/goal_contribution_matrix_plot_laliga.png"",
  logo_path = ""https://i.imgur.com/hBltz33.png"",
  logo_position = ""top right"",
  logo_scale = 6)

plot_logo
```

```{r}
image_write(image = plot_logo, 
            ""../La Liga 2018-2019/output/goal_contribution_matrix_plot_logo_laliga.png"")
```
","2018"
"54",215,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Ligue 1 2018-2019/player_goal_contribution_matrix.rmd","---
title: ""Ligue 1""
author: ""RN7""
date: ""5/25/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# pkgs

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

## add_logo

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))
}
```

# Ligue 1

https://us.soccerway.com/national/france/ligue-1/20182019/regular-season/r48044/


## webscrape soccerway

```{r}
url <- ""https://us.soccerway.com/national/france/ligue-1/20182019/regular-season/r48044/""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#page_competition_1_block_competition_tables_7_block_competition_league_table_1_table .large-link a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, NA, NA, ""team_name"", ""team_num""), sep = ""/"") %>% 
  mutate(link = glue(""
                     https://us.soccerway.com/teams/france/{team_name}/{team_num}/squad/""),
         stat_link = glue(""{link %>% str_replace('squad', 'statistics')}""))

# for each team link:

player_name_info <- function(session) {
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#page_team_1_block_team_squad_3-table .name.large-link"") %>% 
    html_text()
}

num_goals_info <- function(session) {

  num_goals_info <- scrape(session) %>% 
    html_nodes("".goals"") %>% 
    html_text()
  
  num_goals_info_clean <- num_goals_info[-1]
}

num_assists_info <- function(session) {

  num_assists_info <- scrape(session) %>% 
    html_nodes("".assists"") %>% 
    html_text()
  
  num_assists_info_clean <- num_assists_info[-1]
}

team_goals_info <- function(session) {
  team_goals_info <- scrape(session) %>% 
    html_nodes(""tr.first:nth-child(6) > td:nth-child(2)"") %>% 
    html_text()
}

# BIG FUNCTION
ligueUn_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  ligueUn_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names) 
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
ligueUn_goal_contribution_df_ALL <- map2(.x = team_links_df$link,
                .y = team_links_df$stat_link,
                ~ ligueUn_stats_info(link = .x, statlink = .y))

ligueUn_goal_contribution_df <- ligueUn_goal_contribution_df_ALL %>% 
  set_names(team_links_df$team_name) %>% 
  bind_rows(.id = ""team_name"")

## save
saveRDS(ligueUn_goal_contribution_df, file = glue(""{here::here()}/data/ligueUn_goal_contrib_df_soccerway.RDS""))
```

## clean

```{r}
ligueUn_goal_contribution_clean_df <- ligueUn_goal_contribution_df %>% 
  mutate_at(.vars = c(""goals"", ""assists""), 
            ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(team = team_name %>% str_replace_all(., ""-"", "" "") %>% str_to_title,
         total_goals = as.numeric(team_goals)) %>% 
  group_by(team) %>% 
  mutate(total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         assist_contrib = assists/total_goals) %>% 
  ungroup() %>% 
  select(-team_name, -team_goals)

## save
saveRDS(ligueUn_goal_contribution_clean_df, 
        file = glue(""{here::here()}/data/ligueUn_goal_contrib_clean_df.RDS""))
ligueUn_goal_contribution_clean_df <- readRDS(file = glue(""{here::here()}/data/ligueUn_goal_contrib_clean_df.RDS""))
```

## plot

- 
-
-

```{r fig.width = 10, fig.height = 8}  
## Description text
## Iago Aspas
desc_aspas <- ""With 20 Goals from 12.47 xG, Iago Aspas greatly exceeded his xG as he heroically saved Celta Vigo from relegation yet again!""

## Jony   xA90 of 0.29 (tied 3rd highest, minimum 30 games)
desc_jony <- ""With 10 assists amounting to 34% of Alavs' xA, Jony had his career-best season as he helped Alavs contend for a European place.""

## Messi
desc_goat <- ""With total contribution nearly double of the next best, 36 Goals from a xG of 26, etc. Messi led almost every metric in La Liga this season!""

## PLOT!
ligueUn_goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = ligueUn_goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.2 | assist_contrib < 0.125),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = ligueUn_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.2 | assist_contrib > 0.125),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.2, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.125, color = ""grey20"", alpha = 0.4) +
  geom_text_repel(data = ligueUn_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.2 | assist_contrib > 0.125,
                           !name %in% c(""Iago Aspas"", ""L. Messi"", 
                                        ""Jony"", ""Pablo Sarabia"")),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 15, size = 4, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  # geom_mark_circle(aes(filter = name == ""L. Messi"", 
  #                      label = ""Lionel Messi: GOAT"",
  #                       description = desc_goat),
  #                   label.family = ""Roboto Condensed"", label.fontsize = c(16, 12)) +
  # geom_mark_circle(aes(filter = name == ""Iago Aspas"", 
  #                    label = ""Iago Aspas: The Hero of Vigo"",
  #                       description = desc_aspas),
  #                   label.buffer = unit(10, ""mm""), label.fontsize = c(16, 12),
  #                   label.family = ""Roboto Condensed"") +
  # geom_mark_circle(aes(filter = name == ""Jony"", 
  #                      label = ""Jony: El Glorioso"", 
  #                      description = desc_jony),
  #                  label.buffer = unit(5, ""mm""), label.fontsize = c(16, 12),
  #                  label.family = ""Roboto Condensed"") +
  scale_x_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.33)) +
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.55)) +
  labs(title = ""Goal Contribution Matrix: La Liga (2018-2019 Season)"",
       subtitle = ""Goal Involvement (Goals and/or Assists) as Percentage of Total Club Goals"",
       caption = glue(""
                      Data: soccerway.com & understat.com
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 20),
        plot.subtitle = element_text(size = 16),
        plot.caption = element_text(size = 10),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        panel.grid.minor.x = element_blank()) -> ligueUn_goal_contribution_matrix

ligueUn_goal_contribution_matrix
```

## save

```{r}
ggsave(plot = ligueUn_goal_contribution_matrix, 
       ""../Ligue 1 2018-2019/output/goal_contribution_matrix_plot_ligueUn.png"",
       height = 9, width = 11)
```

```{r}
plot_logo <- add_logo(
  plot_path = ""../Ligue 1 2018-2019/output/goal_contribution_matrix_plot_ligueUn.png"",
  logo_path = ""http://worldsoccertalk.com/wp-content/uploads/2016/08/ligue-un-logo-horizontal-600x186.png"",
  logo_position = ""top right"",
  logo_scale = 6)

plot_logo
```

```{r}
image_write(image = plot_logo, 
            ""../Ligue 1 2018-2019/output/goal_contribution_matrix_plot_logo_ligueUn.png"")
```
","2018"
"55",222,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/LFC_ELO_Ratings.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""December 20, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages

```{r message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, ggrepel, 
               glue, extrafont, grid, gridExtra, ggtext)
loadfonts(quiet = TRUE)

```





```{r}
lfc_elo_raw <- read.csv(""data/liverpool"")

lfc_elo_clean <- lfc_elo_raw %>% 
  janitor::clean_names() %>% 
  mutate(from = as.Date(from), 
         to = as.Date(to))

lfc_elo_clean %>% 
  filter(from >= ""2015-10-08"") %>% 
  ggplot(aes(x = from, y = elo)) +
  geom_line() +
  theme_minimal()

lfc_elo_clean %>% 
  filter(from >= ""2016-05-18"") 

# LFC dates
# Europa League Final 5.19 ranking day after

# Klopp
# Mainz: 2003-2004 Promotion to Bundesliga
# Dortmund: 2010-2011, 2011-2012 Bundesliga champions
# 2013 Champions League Final
# LFC: October 2015 
# End of first full season
# 2018 Champions League Final

```

# ELO data

```{r}
lfc_elo_raw <- read_csv(""http://api.clubelo.com/liverpool"")
dortmund_elo_raw <- read_csv(""http://api.clubelo.com/Dortmund"")
mainz_elo_raw <- read_csv(""http://api.clubelo.com/Mainz"")

mainz_elo_clean <- mainz_elo_raw %>% 
  filter(between(From, as.Date(""2001-02-28""), as.Date(""2008-05-19"")))

dortmund_elo_clean <- dortmund_elo_raw %>% 
  filter(between(From, as.Date(""2008-08-15""), as.Date(""2015-05-24"")))

lfc_elo_clean <- lfc_elo_raw %>% 
  filter(From >= as.Date(""2015-10-05""))

klopp <- lfc_elo_clean %>% 
  bind_rows(dortmund_elo_clean, mainz_elo_clean) %>% 
  mutate(Club = as_factor(Club))
```

# Annotations

```{r}
# Klopp
# Mainz: 2003-2004 Promotion to Bundesliga    2004-05-24
# Dortmund: 2010-2011   2011-05-14
        #   2011-2012 Bundesliga champions   2012-05-05
# 2013 Champions League Final 2013-05-25
# LFC: October 2015     2015-10-08
# Europa League Final 2016-05-18
# 2018 Champions League Final  2018-05-26

annotations_df <- data.frame(
  date = as.Date(c(""2004-05-24"", ""2011-05-15"", ""2012-05-05"", 
                   ""2013-05-25"", ""2016-05-18"", ""2018-05-26"")),
  lab_pos = as.Date(c(""2004-05-24"", ""2009-09-01"", ""2009-09-01"",
                      ""2013-05-01"", ""2016-01-01"", ""2017-10-01"")),
  y = c(1700, 1920, 1970, 2020, 1970, 2020),
  text = c(""Promotion to Bundesliga ('03-'04)"", 
           ""Bundesliga Champions ('10-'11)"", 
           ""Bundesliga Champions ('11-'12)"",
           ""2013 Champions League Final"",
           ""2016 Europa League Final"",
           ""2018 Champions League Final"")
)

#library(teamcolors)

cols <- c(""Liverpool"" = ""#D00027"", ""Dortmund"" = ""#FFE500"", ""Mainz"" = ""#C4122E"")

```

# Plot

```{r klopp chart, fig.height = 8, fig.width=11}
klopp %>% 
  ggplot() +
  geom_line(aes(From, y = Elo, color = Club)) +
  scale_x_date(breaks = pretty_breaks(10)) +
  scale_y_continuous(limits = c(1430, 2100), position = ""right"") +
  scale_color_manual(values = cols, guide = FALSE) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 25),
        plot.subtitle = element_text(size = 15),
        plot.caption = element_text(size = 12),
        axis.title = element_text(size = 18),
        axis.text = element_text(size = 15)) +
  labs(x = NULL, y = ""Club Elo Rating"", 
       title = ""Jrgen Klopp's Managerial History"",
       subtitle = glue(""
                       After learning the managerial ropes at Mainz, Klopp has given both Dortmund
                       and Liverpool the adrenaline shot needed to climb back to the top!""), 
       caption = glue(""
                      @R_by_Ryo
                      Source: clubelo.com"")) +
  # Connecting segments:
  annotate(geom = ""segment"", 
           x = as.Date(""2004-05-24""), xend = as.Date(""2004-05-24""),
           y = 1541.472, yend = 1700) +
  annotate(geom = ""segment"", 
           x = as.Date(""2011-05-14""), xend = as.Date(""2010-01-01""),
           y = 1844.078, yend = 1920) +
  annotate(geom = ""segment"", 
           x = as.Date(""2012-05-05""), xend = as.Date(""2011-12-01""),
           y = 1912.054, yend = 1970) +
  annotate(geom = ""segment"", 
           x = as.Date(""2013-05-01""), xend = as.Date(""2013-05-01""),
           y = 1945.104, yend = 2020) +
  annotate(geom = ""segment"", 
           x = as.Date(""2016-05-18""), xend = as.Date(""2016-03-01""),
           y = 1800.110, yend = 1970) +
  annotate(geom = ""segment"", 
           x = as.Date(""2018-05-26""), xend = as.Date(""2017-10-01""),
           y = 1913.713, yend = 2020) +
  # achievements text:
  geom_label(data = annotations_df, 
            aes(x = lab_pos, y = y, label = text),
            family = ""Roboto Condensed"", size = 4.5) +
  # Team names + bars:
  annotate(geom = ""segment"", 
           x = as.Date(""2001-02-28""), xend = as.Date(""2008-06-30""),
           y = 2050, yend = 2050, color = ""#C4122E"") +
  annotate(geom = ""text"", 
           x = as.Date(""2004-10-29""), y = 2080, 
           label = ""Mainz"", family = ""Roboto Condensed"", 
           color = ""#C4122E"", size = 8) +
  annotate(geom = ""segment"", 
           x = as.Date(""2008-07-18""), xend = as.Date(""2015-06-30""),
           y = 2050, yend = 2050) +
  annotate(geom = ""text"", 
           x = as.Date(""2012-01-08""), y = 2080, 
           label = ""Borussia Dortmund"", family = ""Roboto Condensed"",
           size = 8) +
  annotate(geom = ""segment"", 
           x = as.Date(""2015-10-08""), xend = as.Date(""2018-12-30""),
           y = 2050, yend = 2050, color = ""#D00027"") +
  annotate(geom = ""text"", 
           x = as.Date(""2017-05-19""), y = 2080, 
           label = ""Liverpool"", family = ""Roboto Condensed"", 
           color = ""#D00027"", size = 8)
```

After learning the managerial ropes at Mainz, Klopp has given both Dortmund and Liverpool the adrenaline shot needed to climb back toward the top!




```{r fig.height = 8, fig.width=11}
title_grobbo <- textGrob(""Jrgen Klopp's Managerial History"",
                  gp = gpar(fontsize = 25, 
                            fontface = ""bold.italic"",
                            fontfamily = ""Roboto Condensed""))

subtitle <- c(""After learning the managerial ropes at "", ""Mainz"", "", Klopp has given both "", 
              ""Dortmund "", ""and "", ""Liverpool "", 
              ""the adrenaline shot needed to climb back to the top!"")

colors <- c(""black"", ""#C4122E"", ""black"", ""#FFE500"", ""black"", ""#D00027"", ""black"")

subtitle_grobbo <- tableGrob(t(subtitle),
                          theme = ttheme_minimal(padding = unit(c(0, 2), ""mm""),
                                                 base_colour = colors,
                                                 base_size = 15,
                                                 base_face = ""bold"",
                                                 base_family = ""Roboto Condensed""))

plot <- klopp %>% 
  ggplot() +
  geom_line(aes(From, y = Elo, color = Club)) +
  scale_x_date(breaks = pretty_breaks(10)) +
  scale_y_continuous(limits = c(1430, 2100), position = ""right"") +
  scale_color_manual(values = cols, guide = FALSE) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 25),
        plot.subtitle = element_text(size = 15),
        plot.caption = element_text(size = 12),
        axis.title = element_text(size = 18),
        axis.text = element_text(size = 15)) +
  labs(x = NULL, y = ""Club Elo Rating"", 
       caption = glue(""
                      @R_by_Ryo
                      Source: clubelo.com"")) +
  # Connecting segments:
  annotate(geom = ""segment"", 
           x = as.Date(""2004-05-24""), xend = as.Date(""2004-05-24""),
           y = 1541.472, yend = 1700) +
  annotate(geom = ""segment"", 
           x = as.Date(""2011-05-14""), xend = as.Date(""2010-01-01""),
           y = 1844.078, yend = 1920) +
  annotate(geom = ""segment"", 
           x = as.Date(""2012-05-05""), xend = as.Date(""2011-12-01""),
           y = 1912.054, yend = 1970) +
  annotate(geom = ""segment"", 
           x = as.Date(""2013-05-01""), xend = as.Date(""2013-05-01""),
           y = 1945.104, yend = 2020) +
  annotate(geom = ""segment"", 
           x = as.Date(""2016-05-18""), xend = as.Date(""2016-03-01""),
           y = 1800.110, yend = 1970) +
  annotate(geom = ""segment"", 
           x = as.Date(""2018-05-26""), xend = as.Date(""2017-10-01""),
           y = 1913.713, yend = 2020) +
  # achievements text:
  geom_label(data = annotations_df, 
            aes(x = lab_pos, y = y, label = text),
            family = ""Roboto Condensed"", size = 4.5) +
  # Team names + bars:
  annotate(geom = ""segment"", 
           x = as.Date(""2001-02-28""), xend = as.Date(""2008-06-30""),
           y = 2050, yend = 2050, color = ""#C4122E"") +
  annotate(geom = ""text"", 
           x = as.Date(""2004-10-29""), y = 2080, 
           label = ""Mainz"", family = ""Roboto Condensed"", 
           color = ""#C4122E"", size = 8) +
  annotate(geom = ""segment"", 
           x = as.Date(""2008-07-18""), xend = as.Date(""2015-06-30""),
           y = 2050, yend = 2050) +
  annotate(geom = ""text"", 
           x = as.Date(""2012-01-08""), y = 2080, 
           label = ""Borussia Dortmund"", family = ""Roboto Condensed"",
           size = 8) +
  annotate(geom = ""segment"", 
           x = as.Date(""2015-10-08""), xend = as.Date(""2018-12-30""),
           y = 2050, yend = 2050, color = ""#D00027"") +
  annotate(geom = ""text"", 
           x = as.Date(""2017-05-19""), y = 2080, 
           label = ""Liverpool"", family = ""Roboto Condensed"", 
           color = ""#D00027"", size = 8)


grid.arrange(title_grobbo,
             subtitle_grobbo,
             plot,
             heights = c(10, 8, 100))
```


# ggtext version



```{r message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, ggrepel, 
               glue, extrafont, grid, gridExtra, ggtext)
loadfonts(quiet = TRUE)
```


```{r}
lfc_elo_raw <- read_csv(""http://api.clubelo.com/liverpool"")
dortmund_elo_raw <- read_csv(""http://api.clubelo.com/Dortmund"")
mainz_elo_raw <- read_csv(""http://api.clubelo.com/Mainz"")

mainz_elo_clean <- mainz_elo_raw %>% 
  filter(between(From, as.Date(""2001-02-28""), as.Date(""2008-05-19"")))

dortmund_elo_clean <- dortmund_elo_raw %>% 
  filter(between(From, as.Date(""2008-08-15""), as.Date(""2015-05-24"")))

lfc_elo_clean <- lfc_elo_raw %>% 
  filter(From >= as.Date(""2015-10-05""))

klopp <- lfc_elo_clean %>% 
  bind_rows(dortmund_elo_clean, mainz_elo_clean) %>% 
  mutate(Club = as_factor(Club))
```

```{r}
# Klopp
# Mainz: 2003-2004 Promotion to Bundesliga    2004-05-24
# Dortmund: 2010-2011   2011-05-14
        #   2011-2012 Bundesliga champions   2012-05-05
# 2013 Champions League Final 2013-05-25
# LFC: October 2015     2015-10-08
# Europa League Final 2016-05-18
# 2018 Champions League Final  2018-05-26

annotations_df <- data.frame(
  date = as.Date(c(""2004-05-24"", ""2011-05-15"", ""2012-05-05"", 
                   ""2013-05-25"", ""2016-05-18"", ""2018-05-26"",
                   ""2019-06-01"")),
  lab_pos = as.Date(c(""2004-05-24"", ""2009-09-01"", ""2009-09-01"",
                      ""2009-11-01"", ""2016-01-01"", ""2015-08-01"",
                      ""2017-01-01"")),
  y = c(1700, 1920, 1970, 2030, 1950, 2020, 2080),
  text = c(""Promotion to Bundesliga ('03-'04)"", 
           ""Bundesliga Champions ('10-'11)"", 
           ""Bundesliga Champions ('11-'12)"",
           ""2013 Champions League Final"",
           ""2016 Europa League Final"",
           ""2018 Champions League Final"",
           ""2019 Champions League Final"")
)

#library(teamcolors)

cols <- c(""Liverpool"" = ""#D00027"", ""Dortmund"" = ""#FFE500"", ""Mainz"" = ""#C4122E"")

```


```{r klopp chart, fig.height = 8, fig.width=11}
klopp %>% 
  ggplot() +
  geom_line(aes(From, y = Elo, color = Club),
            size = 1.5) +
  scale_x_date(breaks = pretty_breaks(10)) +
  scale_y_continuous(limits = c(1430, 2200), position = ""right"") +
  scale_color_manual(values = cols, guide = FALSE) +
  labs(x = NULL, y = ""Club Elo Rating"", 
       title = ""Jrgen Klopp's Managerial History (2001-2019)"",
       subtitle = ""After learning the managerial ropes at <b style='color:#C4122E'>Mainz</b>, Klopp has given both <b style='color:#FFE500'>Dortmund</b> and <b style='color:#D00027'>Liverpool</b> the adrenaline shot <br>needed to climb back to the top. As of the latest data (Oct. 9th, 2019), <b style='color:#D00027'>Liverpool</b> are ranked first out of all teams in Europe!"",        
       caption = glue(""
                      @R_by_Ryo
                      Source: clubelo.com"")) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 25),
        #plot.subtitle = element_text(size = 15),
        plot.subtitle = element_markdown(size = 15),
        plot.caption = element_text(size = 12),
        axis.title = element_text(size = 18),
        axis.text = element_text(size = 15)) +
  # Connecting segments:
  annotate(geom = ""segment"", 
           x = as.Date(""2004-05-24""), xend = as.Date(""2004-05-24""),
           y = 1541.472, yend = 1700) +
  annotate(geom = ""segment"", 
           x = as.Date(""2011-05-14""), xend = as.Date(""2010-01-01""),
           y = 1844.078, yend = 1920) +
  annotate(geom = ""segment"", 
           x = as.Date(""2012-05-05""), xend = as.Date(""2011-12-01""),
           y = 1912.054, yend = 1970) +
  ## CL Final
  annotate(geom = ""segment"", 
           x = as.Date(""2013-05-01""), xend = as.Date(""2011-11-01""),
           y = 1945.104, yend = 2020) +
  annotate(geom = ""segment"", 
           x = as.Date(""2016-05-18""), xend = as.Date(""2016-03-01""),
           y = 1800.110, yend = 1950) +
  annotate(geom = ""segment"", 
           x = as.Date(""2018-05-26""), xend = as.Date(""2017-10-01""),
           y = 1913.713, yend = 2020) +
  annotate(geom = ""segment"", 
           x = as.Date(""2019-06-01""), xend = as.Date(""2019-01-01""),
           y = 2043.473, yend = 2080) +
  # achievements text:
  geom_label(data = annotations_df, 
            aes(x = lab_pos, y = y, label = text),
            family = ""Roboto Condensed"", size = 4.5) +
  # Team names + bars:
  ## Mainz
  annotate(geom = ""segment"", 
           x = as.Date(""2001-02-28""), xend = as.Date(""2008-06-30""),
           y = 2150, yend = 2150, color = ""#C4122E"") +
  annotate(geom = ""text"", 
           x = as.Date(""2004-10-29""), y = 2180, 
           label = ""Mainz"", family = ""Roboto Condensed"", 
           color = ""#C4122E"", size = 8) +
  ## Dortmund
  annotate(geom = ""segment"", 
           x = as.Date(""2008-07-18""), xend = as.Date(""2015-06-30""),
           y = 2150, yend = 2150) +
  annotate(geom = ""text"", 
           x = as.Date(""2012-01-08""), y = 2180, 
           label = ""Borussia Dortmund"", family = ""Roboto Condensed"",
           size = 8) +
  ## Liverpool
  annotate(geom = ""segment"", 
           x = as.Date(""2015-10-08""), xend = as.Date(""2019-12-30""),
           y = 2150, yend = 2150, color = ""#D00027"") +
  annotate(geom = ""text"", 
           x = as.Date(""2017-11-18""), y = 2180, 
           label = ""Liverpool"", family = ""Roboto Condensed"", 
           color = ""#D00027"", size = 8)
```


```{r}
ggsave(filename = here::here(""Premier League 2018-2019/output/klopp_manager_history2.png""),
       height = 8, width = 11)
```



## Liverpool

```{r}
annotations_lfcdf <- data.frame(
  date = as.Date(c(""2015-10-08"", ""2016-02-28"", ""2016-05-05"", 
                   ""2017-05-21"", ""2018-01-01"", ""2018-05-26"",
                   ""2019-06-01"")),
  lab_pos = as.Date(c(""2015-11-01"", ""2016-02-20"", ""2016-05-05"",
                      ""2017-05-21"", ""2018-01-01"", ""2018-05-26"", 
                      ""2019-06-01"")),
  y = c(1700, 1920, 1970, 2030, 1970, 2020, 2100),
  text = c(""Jrgen Klopp becomes Manager of LFC"", 
           ""League Cup Final (Loss)"", 
           ""Europa League Final (Loss)"",
           ""Qualification to Champions League"",
           ""Van Dijk signs for LFC"",
           ""2018 Champions League Final (Loss)"",
           ""2019 Champions League Final (Win)"")
)
```



```{r klopp-liv-chart, fig.height = 8, fig.width=11}
klopp %>% 
  filter(Club == ""Liverpool"") %>% 
  ggplot() +
  geom_line(aes(From, y = Elo), size = 2, color = ""#D00027"") +
  scale_x_date(breaks = pretty_breaks(10)) +
  scale_y_continuous(limits = c(1430, 2200), position = ""right"") +
  labs(x = NULL, y = ""Club Elo Rating"", 
       title = ""From Doubters to Believers: 4 Years of Klopp at Liverpool FC"",
       subtitle = ""After <i style='color:#D00027'>Liverpool</i> the adrenaline shot <br>needed to climb back to the top!"",        caption = glue(""
                      @R_by_Ryo
                      Source: clubelo.com"")) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_text(size = 25),
        #plot.subtitle = element_text(size = 15),
        plot.subtitle = element_markdown(size = 15),
        plot.caption = element_text(size = 12),
        axis.title = element_text(size = 18),
        axis.text = element_text(size = 15),
        legend.position = ""none"") +
    # achievements text:
  geom_label_repel(data = annotations_lfcdf, 
            aes(x = date, y = y, label = text),
            family = ""Roboto Condensed"", size = 4.5,
            min.segment.length = 0)
```














## bump chart for 2018

```{r}

```

","2018"
"56",223,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/LFC_goals_timeframe.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""November 24, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r message=FALSE}
library(tidyverse)
library(extrafont)
loadfonts()
```



```{r}
liv_goals <- data.frame(
  goals_for = c(7, 9, 7),
  goals_against = c(1, 0, 4),
  GD = c(6, 9, 3),
  time_frame = c(""0-30th Minute"", ""31-60th Minute"", ""61-90th Minute"")
)
```

```{r}
liv_goals %>% 
  ggplot(aes(time_frame)) +
  geom_linerange(aes(ymin = goals_against, ymax = goals_for), color = ""grey"", size = 2) +
  geom_point(aes(y = goals_for), shape = 21, 
             color = ""black"", fill = ""red"", size = 3.5) +
  geom_point(aes(y = goals_against), shape = 21, 
             color = ""black"", fill = ""black"", size = 3.5) +
  scale_y_continuous(breaks = scales::pretty_breaks(), limits = c(0, 10),
                     name = ""Goals"") +
  annotate(geom = ""label"", x = 1.05, y = 7, hjust = 0, label = ""Goals For"") +
  annotate(geom = ""label"", x = 1.05, y = 1, hjust = 0, label = ""Goals Against"") +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        #plot.background = element_rect(color = ""red""),
        #panel.background = element_rect(fill = ""red""),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        text = element_text(family = ""Roboto Condensed""))
```






```{r}
library(rvest)

url <- ""https://en.wikipedia.org/wiki/2017%E2%80%9318_Liverpool_F.C._season""

liv_raw <- url %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(1)"") %>% 
  html_table() %>% 
  flatten_df() %>% 
  mutate(Season = ""2017-2018"")

url2 <- ""https://en.wikipedia.org/wiki/2016%E2%80%9317_Liverpool_F.C._season""

liv_raw2 <- url2 %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(1)"") %>% 
  html_table() %>% 
  flatten_df() %>% 
  mutate(Season = ""2016-2017"")

url3 <- ""https://en.wikipedia.org/wiki/2015%E2%80%9316_Liverpool_F.C._season""

liv_raw3 <- url3 %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(1)"") %>% 
  html_table() %>% 
  flatten_df() %>% 
  mutate(Season = ""2015-2016"")

liv_clean <- function(data = data) {data %>% 
  gather(key = ""Match"", value = ""stat"", -Matchday, -Season) %>% 
  spread(Matchday, stat) %>% 
  mutate(Match = Match %>% as.numeric) %>% 
  rename(""Home-Away"" = ""Ground"") %>% 
  arrange(Match) %>% 
  mutate(Points = case_when(
    Result == ""W"" ~ 3,
    Result == ""L"" ~ 0,
    Result == ""D"" ~ 1
  )) %>% 
  mutate(CP = cumsum(Points)) }

liv_list <- list(liv_raw, liv_raw2, liv_raw3)

liv_all <- liv_list %>% map(~ liv_clean(data = .)) %>% 
  reduce(rbind) %>% 
  mutate(Position = as.numeric(Position))

```

```{r}
library(gganimate)
library(ggtextures)

# Isotope?
liv_all %>% 
  mutate(image = ""https://vectors.pro/wp-content/uploads/2018/04/liverpool-fc-football-club-logo-vector.png"") %>% 
  ggplot(aes(x = Season, y = CP, image = image)) +
  geom_isotype_col(position = ""identity"") +
  #geom_col(position = ""identity"") +
  theme_minimal() +
  transition_states(Match, transition_length = 1.5, state_length = 5) +
  labs(title = ""Matchday {closest_state}"")

```


```{r}
col <- c(`2015-2016` = ""#fc9272"", `2016-2017` = ""#ef3b2c"", `2017-2018` = ""#a50f15"")

liv_all %>% 
  ggplot(aes(x = Match, y = Position, group = Season, color = Season)) +
  geom_path(show.legend = FALSE) +
  geom_point(show.legend = FALSE) +
  scale_x_continuous(breaks = c(1, 5, 10, 15, 20, 25, 30, 35, 38), 
                     labels = c(1, 5, 10, 15, 20, 25, 30, 35, 38)) +
  scale_y_reverse(breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13), 
                  labels = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13),
                  sec.axis = sec_axis(~ .)) +
  scale_color_manual(values = col) +
  theme_minimal() +
  theme(panel.grid.minor.y = element_blank(),
        text = element_text(family = ""Roboto Condensed""))

```

","2018"
"57",224,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/Premier_League_Center_of_Gravity.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""December 8, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

- English Premier League version of https://www.chadbixby.com/2018/09/06/2018-09-06-the-nfl-nba-mlb-s-center-of-gravity/


## packages

```{r}
pacman::p_load(rvest, dplyr, tidyr, ggplot2, purrr, ggmap, scales, stringr)
```

## web-scrape

```{r}
url <- ""https://en.wikipedia.org/wiki/List_of_English_football_champions""

# css selector: table.wikitable:nth-child(17)
# table.wikitable:nth-child(15)

eng_champ_raw <- url %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(15)"") %>% 
  html_table() %>% 
  flatten_df()

eng_champ_clean <- eng_champ_raw %>% 
  janitor::clean_names() %>% 
  select(year, champions_number_of_titles) %>% 
  transmute(year = year,
            champions = gsub(""[0-9]|\\(|\\)|\\[|\\]"", """", 
                             champions_number_of_titles) %>% trimws()) %>% 
  slice(c(-24, -45))

eng_PL_champ_raw <- url %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(17)"") %>% 
  html_table() %>% 
  flatten_df()

eng_PL_champ_clean <- eng_PL_champ_raw %>% 
  janitor::clean_names() %>% 
  select(year, champions_number_of_titles) %>% 
  transmute(year = year,
            champions = gsub(""[0-9]|\\(|\\)|\\[|\\]"", """", 
                             champions_number_of_titles) %>% trimws())

eng_champions_df <- eng_champ_clean %>% 
  bind_rows(eng_PL_champ_clean)

# eng_champ_clean %>% 
#   mutate(geo = geocode(champions, source = ""dsk""))
# some are more specific than others due to geocode() not getting the right 
# location even trying different addresses
# most are... close enough
# eng_champions_df$champions %>% unique()

eng_champ_location <- eng_champions_df %>% 
  mutate(location_name = case_when(
    champions == ""Manchester United"" ~ ""Manchester, England"",
    champions == ""Blackburn Rovers"" ~ ""Blackburn, England"",
    champions == ""Arsenal"" ~ ""Holloway, England"",
    champions == ""Chelsea"" ~ ""Chelsea, London, UK"",
    champions == ""Manchester City"" ~ ""etihad stadium, england"",
    champions == ""Leicester City"" ~ ""Leicester, England"",
    champions == ""Sunderland"" ~ ""sunderland, england"",
    champions == ""Aston Villa"" ~ ""aston, england"",
    champions == ""Sheffield United"" ~ ""bramall lane, england"",
    champions %in% c(""The Wednesday"", ""Sheffield Wednesday"") ~ ""hillsborough, england"",
    champions == ""Liverpool"" ~ ""anfield, england"",
    champions == ""Newcastle United"" ~ ""newcastle upon tyne, england"",
    champions == ""Everton"" ~ ""everton, england"",
    champions == ""West Bromwich Albion"" ~ ""west bromwich, england"",
    champions == ""Burnley"" ~ ""burnley, england"",
    champions == ""Huddersfield Town"" ~ ""huddersfield, england"",
    champions == ""Portsmouth"" ~ ""portsmouth, england"",
    champions == ""Tottenham Hotspur"" ~ ""tottenham, london, england"",
    champions == ""Wolverhampton Wanderers"" ~ ""wolverhampton, england"",
    champions == ""Leeds United"" ~ ""leeds, england"",
    champions == ""Derby County"" ~ ""derby, england"",
    champions == ""Nottingham Forest"" ~ ""nottingham, england"",
    champions == ""Ipswich Town"" ~ ""ipswich, england""
  )) %>% 
  mutate_geocode(location_name, source = ""dsk"")

saveRDS(object = eng_champ_location, ""../data/eng_champ_location.RDS"")
```

## Center of gravity

```{r}
# from https://www.chadbixby.com/2018/09/06/2018-09-06-the-eng_champ_location-nba-mlb-s-center-of-gravity/

find_center <- function(df){
  
  df2 <- df %>%
    mutate(rad_lon = lon*pi/180, rad_lat = lat*pi/180) %>% 
    mutate(X = cos(rad_lat) * cos(rad_lon)) %>%
    mutate(Y = cos(rad_lat) * sin(rad_lon)) %>%
    mutate(Z = sin(rad_lat)) %>%
    summarise(X = mean(X), Y = mean(Y), Z = mean(Z)) %>% #find mean
    mutate(Lon = atan2(Y, X), Hyp = sqrt(X * X + Y * Y), Lat = atan2(Z, Hyp)) %>%  
    select(Lon, Lat) %>%
    mutate(Lon = Lon*180/pi, Lat = Lat*180/pi)
  
  # Lon <- df2$Lon
  # Lat <- df2$Lat
  
  return(df2)
}

find_center2 <- function(df, lon, lat){
  
  df2 <- df %>%
    mutate(rad_lon = lon*pi/180, rad_lat = lat*pi/180) %>% 
    mutate(X = cos(rad_lat) * cos(rad_lon)) %>%
    mutate(Y = cos(rad_lat) * sin(rad_lon)) %>%
    mutate(Z = sin(rad_lat)) %>%
    summarise(X = mean(X), Y = mean(Y), Z = mean(Z)) %>% #find mean
    mutate(Lon = atan2(Y, X), Hyp = sqrt(X * X + Y * Y), Lat = atan2(Z, Hyp)) %>%  
    select(Lon, Lat) %>%
    mutate(Lon = Lon*180/pi, Lat = Lat*180/pi)
  
  # Lon <- df2$Lon
  # Lat <- df2$Lat
  
  return(df2)
}



pl_center <- find_center(eng_champ_location)
pl_center


map(1:nrow(eng_champ_location) ~ 
      eng_champ_location %>% 
      mutate(lon_center = find_center()))

eng_champ_location %>% 
  rowwise() %>% 
  mutate(cen_lon = find_center(.)) %>% View()

eng_champ_location %>% 
  purrrlyr::by_row(..f = find_center, .to = ""coords"", .collate = ""list"") %>% 
  View()


center_shift <- eng_champ_location %>% 
  rowwise() %>% 
  find_center()

eng_champ_location %>% 
  bind_cols(center_shift)

eng_champ_location %>% 
  mutate(id = row_number()) %>% 
  tibbletime::rollify(.f = find_center(.), window = 2)
  
rolling_center <- tibbletime::rollify(.f = find_center, window = 2)
rolling_center2 <- tibbletime::rollify(.f = find_center2, window = 2)

eng_champ_location %>% 
  mutate(cen = rolling_center2(.))


# for loop...

for (i in 1:nrow(eng_champ_location)) {
  eng_champ_location$lon_center[i] <- find_center(eng_champ_location[1:i,])[[1]]
  eng_champ_location$lat_center[i] <- find_center(eng_champ_location[1:i,])[[2]]
}

```



## map

```{r}
UK <- map_data(map = ""world"", region = ""UK"") # changed map to ""world""

ggplot(data = UK, aes(x = long, y = lat, group = group)) + 
  geom_polygon() +
  coord_map(xlim = c(-4, 2), ylim = c(50, 57)) +
  geom_path(data = eng_champ_location, 
            aes(x = lon_center, y = lat_center, group = 1, color = year), 
            show.legend = FALSE) +
  geom_point(data = eng_champ_location, 
            aes(x = lon, y = lat, group = 1))
```

nowhere near as interesting as MLB/NBA/NFL one! haha","2018"
"58",225,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/appearances_season_players.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""10/10/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Appearances over Season: Split between Managers

## packages

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick, ggtext)
loadfonts()
```

# 2018-2019


## squad info

- Squad details 

```{r}
url <- ""https://www.transfermarkt.com/liverpool-fc/leistungsdaten/verein/31/reldata/GB1%262018/plus/1""

session <- bow(url)

squad_table_raw <- scrape(session) %>% 
  html_nodes("".hauptlink > div > span > a"") %>% 
  html_attr(""href"")

squad_table_clean <- squad_table_raw %>% 
  enframe() %>% 
  select(-name) %>% 
  distinct() %>% 
  separate(value, into = c(""1"", ""2"", '3', '4', '5'), sep = ""\\/"") %>% 
  select(player_name = 2, id_num = 5)

## add links
squad_table_df <- squad_table_clean %>% 
  mutate(link = glue::glue(""https://www.transfermarkt.com/{player_name}/leistungsdatendetails/spieler/{id_num}/saison/2018/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1"")) %>% 
  ## remove Karius, Bogdan, Kelleher, Grabara, Hoever, CR56, 
  ## Grujic, C. Jones, I. C-D, H. Wilson, Solanke, Ings, 
  ## 
  slice(-3, -4, -5, -6, -15, -16, -22, -25, -26, -32, -33, -34,
        -36, -37, -38)

glimpse(squad_table_df)
```

Know # of players >> Check when webscrape

```{r}
saveRDS(squad_table_df, file = here::here(""data/squad_LFC_18_19_df.RDS""))
squad_table_df <- readRDS(file = here::here(""data/squad_LFC_18_19_df.RDS""))
```

## base dates

- use someone like Migs who played/in squad of every single game:

```{r}
base_url <- ""https://www.transfermarkt.com/alisson/leistungsdatendetails/spieler/50219/saison/2018/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session <- bow(base_url)

base_raw <- scrape(session) %>% 
  html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  slice(-n())

base_dates <- base_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  ## make sure minutes == 0 for BASE
  ## add empty FALSE injury col
  mutate(date = lubridate::mdy(date),
         minutes = 0,
         injury = FALSE) %>% 
  ## set sub_in, sub_out = 0
  mutate(sub_in = """",
         sub_out = 0) %>% 
  ## set goals/assists = 0
  mutate(goal = 0,
         assist = 0) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
```

Check that row == 38


```{r}
saveRDS(base_dates, file = here::here(""data/base_LFC_18_19_dates_df.RDS""))
base_dates <- readRDS(file = here::here(""data/base_LFC_18_19_dates_df.RDS""))
```


## get_appearances() function

```{r}
get_appearances <- function(link) {
  
  session <- bow(link)
  
  appearances_raw <- scrape(session) %>% 
    html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
    html_table(fill = TRUE) %>% 
    .[[1]] %>% 
    #magrittr::extract2(1) %>% 
    janitor::clean_names() %>% 
    slice(-n())
  
  appearances_clean <- appearances_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  mutate(date = lubridate::mdy(date),
         minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes),
         minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                           minutes, ""0"") %>% as.numeric()) %>% 
  ## injury + suspension
  mutate(sub_in =  
           if_else(str_detect(sub_in, ""'""), 
                   str_replace_all(sub_in, ""'"", """"), sub_in),
         sub_in = case_when(
    str_detect(sub_in, ""^[0-9]+$"") == TRUE ~ """",
    TRUE ~ sub_in)) %>% 
  ## handle cases of suspension too, otherwise == FALSE
  mutate(injury = case_when(
    sub_in %in% c(""on the bench"", ""Not in squad"", ""With 2nd team"",
                  ""special leave"", ""doping ban"", """") ~ FALSE,
    TRUE ~ TRUE)) %>% 
  ## fix sub_out
  mutate(sub_out =  
           if_else(str_detect(sub_out, ""'""), 
                   str_replace_all(sub_out, ""'"", """"), sub_out),
         sub_out = if_else(str_detect(sub_out, ""^[0-9]+$""),
                           sub_out, ""0"") %>% as.numeric()) %>% 
  ## fix goals/assists
  mutate(goal = if_else(str_detect(goal, ""^[0-9]+$""),
                           goal, ""0"") %>% as.numeric(),
         assist = if_else(str_detect(assist, ""^[0-9]+$""),
                           assist, ""0"") %>% as.numeric()) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
  
  ## deal with no match rows:
  ## basically using base df, anti_join on dates and 
  ## insert info for rows where missing
  add_df <- base_dates %>% 
    anti_join(appearances_clean, by = c(""date""))
  
  ## combine missing data with existing
  appearances_clean <- appearances_clean %>% 
    full_join(add_df) %>% 
    arrange(date)
}
```

## iterate over

```{r}
appearances_df_raw <- map2(.x = squad_table_df$link,
                           .y = squad_table_df$player_name,
                           ~ get_appearances(link = .x) %>% 
                             mutate(name = .y))
```

Check # of squad members == element of list

```{r}
length(appearances_df_raw) == 24
```


```{r}
saveRDS(appearances_df_raw, 
        file = glue(""{here::here()}/data/appearances_df_raw_LFC_18_19.RDS""))
appearances_df_raw <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_raw_LFC_18_19.RDS""))
```


# clean

```{r}
appearances_df_LFC_18_19 <- appearances_df_raw %>% 
  reduce(bind_rows) %>% 
  group_by(name) %>% 
  mutate(match_num = row_number()) %>% 
  mutate(end = seq(from = 90, to = 3420, by = 90),
         start = lag(end, default = 0),
         dur = if_else(minutes == 90, start, end - minutes)) %>% 
  ## for sub-outs
  mutate(end = case_when(
    sub_out != 0 ~ start + sub_out,
    TRUE ~ end),
    dur = case_when(
      sub_out != 0 ~ start,
      TRUE ~ dur)) %>% 
  ## change times for injury == TRUE
  mutate(dur = case_when(
    injury == TRUE ~ start,
    TRUE ~ dur)) %>% 
  ungroup() %>% 
  mutate(name = str_replace_all(name, ""-"", "" "") %>% str_to_title(),
         position = case_when(row_number() %in% 1:76 ~ ""GK"",
                              row_number() %in% 77:380 ~ ""DF"",
                              row_number() %in% 381:646 ~ ""MF"",
                              row_number() %in% 647:874 ~ ""ST""),
         position = as_factor(position) %>% 
           fct_relevel(""GK"", ""DF"", ""MF"", ""ST""),
         name = as_factor(name)) %>% 
  arrange(position, name) %>% 
  mutate(id = row_number(),
         name = fct_reorder(name, id))
```



```{r}
## save
saveRDS(appearances_df_LFC_18_19, 
        file = glue(""{here::here()}/data/appearances_df_LFC_18_19.RDS""))
appearances_df_LFC_18_19 <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_LFC_18_19.RDS""))
```


# plot

## plot aux

```{r}
divide_lines <- tibble(yint = seq(0.5, 23.5, by = 1))

verticolo <- tibble(verts_start = seq(0, 3420, by = 90),
                    verts_end = seq(0, 3420, by = 90),
                    y_low = 0.5,
                    y_high = 23.5)
```

## all player

```{r, fig.height=9, fig.width=12, message=FALSE}
appearances_df_LFC_18_19 %>% 
  ggplot(aes(x = dur, 
             y = name, yend = name)) + 
  ## fit
    geom_segment(data = appearances_df_LFC_18_19 %>% 
                 filter(injury == FALSE),
               aes(xend = end,
                   group = match_num),
               size = 3.5, color = ""darkgreen"") +
  ## injury + suspension
  geom_segment(data = appearances_df_LFC_18_19 %>% 
                 filter(injury == TRUE),
               aes(xend = end, 
                   group = match_num),
               size = 3.5, color = ""black"") +
  geom_segment(data = verticolo, 
               aes(x = verts_start, xend = verts_end, 
                   y = y_low, yend = y_high)) +
  ## Dividers
  geom_hline(data = divide_lines, aes(yintercept = yint),
             size = 0.5) +
  scale_x_continuous(breaks = seq(45, 3420, 90),
                     labels = seq(1, 38, 1),
                     expand = c(0, 0)) +
  expand_limits(y = c(0.1, 26)) +
  ## Kloppo
  annotate(geom = ""segment"", 
           x = 1710, xend = 1710,
           y = 24, yend = 24.5,
           color = ""black"", size = 1) +
  annotate(geom = ""label"", size = 5,
           label = ""Jrgen Klopp (W: 30 D: 7 L: 1)"",
           x = 1710, y = 25, family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", 
           x = 7, xend = 3415,
           y = 24, yend = 24,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 7, xend = 7,
           y = 23.7, yend = 24.3,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 3415, xend = 3415,
           y = 23.7, yend = 24.3,
           color = ""black"", size = 1) +
  labs(title = ""Player Minutes | <b style='color:#D00027'>Liverpool FC</b> | Season 2018-2019"",
       subtitle = glue(""
                       Players Ordered by Position (ST, MF, DF, GK)
                       Black = Injury or Suspension""),
       x = ""Minutes Played per Game Week"", y = """",
       caption = glue::glue(""
                            Data: transfermarkt.com
                            By: @R_by_Ryo"")) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        axis.title = element_text(size = 14),
        axis.text.x = element_text(color = ""black"", size = 11),
        axis.text.y = element_text(color = ""black"", size = 10),
        panel.grid = element_blank(),
        plot.title = element_markdown(size = 20),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 12))
```

```{r}
ggsave(filename = here::here(""Premier League 2018-2019/output/player_minutes_LFC_18_19.png""),
       height = 9, width = 12)
```

## add logo

```{r}
# add logo with Magick using Thomas Mock's custom function
# check out the explanation in his blog post: https://themockup.netlify.com/posts/2019-01-09-add-a-logo-to-your-plot/
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}

# add_logo and save
plot_logo <- add_logo(plot_path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_18_19.png""),
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/thumb/0/0c/Liverpool_FC.svg/800px-Liverpool_FC.svg.png"",
                      logo_position = ""top right"",
                      logo_scale = 18)

image_write(image = plot_logo, 
            path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_18_19_logo.png""))
```


# -----------------------------------------------------

# 2019-2020 


## squad info

- Squad details 

```{r}
url <- ""https://www.transfermarkt.com/liverpool-fc/leistungsdaten/verein/31/reldata/GB1%262019/plus/1""

session <- bow(url)

squad_table_raw <- scrape(session) %>% 
  html_nodes("".hauptlink > div > span > a"") %>% 
  html_attr(""href"")

squad_table_clean <- squad_table_raw %>% 
  enframe() %>% 
  select(-name) %>% 
  distinct() %>% 
  separate(value, into = c(""1"", ""2"", '3', '4', '5'), sep = ""\\/"") %>% 
  select(player_name = 2, id_num = 5)

## add links
squad_table_df <- squad_table_clean %>% 
  mutate(link = glue::glue(""https://www.transfermarkt.com/{player_name}/leistungsdatendetails/spieler/{id_num}/saison/2019/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1"")) %>% 
  ## remove Kelleher, Lonergan, Hoever, CR56, 
  ## Grujic, C. Jones, I. C-D, H. Wilson, Solanke, Ings, 
  ## 
  slice(-3, -4, -12)

glimpse(squad_table_df)
```

Know # of players >> Check when webscrape

```{r}
saveRDS(squad_table_df, file = here::here(""data/squad_LFC_19_20_df.RDS""))
squad_table_df <- readRDS(file = here::here(""data/squad_LFC_19_20_df.RDS""))
```

## base dates

- use someone like Migs who played/in squad of every single game:

```{r}
base_url <- ""https://www.transfermarkt.com/virgil-van-dijk/leistungsdatendetails/spieler/139208/saison/2019/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session <- bow(base_url)

base_raw <- scrape(session) %>% 
  html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  slice(-n())

base_dates <- base_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  ## make sure minutes == 0 for BASE
  ## add empty FALSE injury col
  mutate(date = lubridate::mdy(date),
         minutes = 0,
         injury = FALSE) %>% 
  ## set sub_in, sub_out = 0
  mutate(sub_in = """",
         sub_out = 0) %>% 
  ## set goals/assists = 0
  mutate(goal = 0,
         assist = 0) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
```

Check that row == 8

```{r}
nrow(base_dates) == 8
```



```{r}
saveRDS(base_dates, file = here::here(""data/base_LFC_19_20_dates_df.RDS""))
base_dates <- readRDS(file = here::here(""data/base_LFC_19_20_dates_df.RDS""))
```


## get_appearances() function

```{r}
get_appearances <- function(link) {
  
  session <- bow(link)
  
  appearances_raw <- scrape(session) %>% 
    html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
    html_table(fill = TRUE) %>% 
    .[[1]] %>% 
    #magrittr::extract2(1) %>% 
    janitor::clean_names() %>% 
    slice(-n())
  
  appearances_clean <- appearances_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  mutate(date = lubridate::mdy(date),
         minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes),
         minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                           minutes, ""0"") %>% as.numeric()) %>% 
  ## injury + suspension
  mutate(sub_in =  
           if_else(str_detect(sub_in, ""'""), 
                   str_replace_all(sub_in, ""'"", """"), sub_in),
         sub_in = case_when(
    str_detect(sub_in, ""^[0-9]+$"") == TRUE ~ """",
    TRUE ~ sub_in)) %>% 
  ## handle cases of suspension too, otherwise == FALSE
  mutate(injury = case_when(
    sub_in %in% c(""on the bench"", ""Not in squad"", ""With 2nd team"",
                  ""special leave"", ""doping ban"", """") ~ FALSE,
    TRUE ~ TRUE)) %>% 
  ## fix sub_out
  mutate(sub_out =  
           if_else(str_detect(sub_out, ""'""), 
                   str_replace_all(sub_out, ""'"", """"), sub_out),
         sub_out = if_else(str_detect(sub_out, ""^[0-9]+$""),
                           sub_out, ""0"") %>% as.numeric()) %>% 
  ## fix goals/assists
  mutate(goal = if_else(str_detect(goal, ""^[0-9]+$""),
                           goal, ""0"") %>% as.numeric(),
         assist = if_else(str_detect(assist, ""^[0-9]+$""),
                           assist, ""0"") %>% as.numeric()) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
  
  ## deal with no match rows:
  ## basically using base df, anti_join on dates and 
  ## insert info for rows where missing
  add_df <- base_dates %>% 
    anti_join(appearances_clean, by = c(""date""))
  
  ## combine missing data with existing
  appearances_clean <- appearances_clean %>% 
    full_join(add_df) %>% 
    arrange(date)
}
```

## iterate over

```{r}
appearances_df_raw <- map2(.x = squad_table_df$link,
                           .y = squad_table_df$player_name,
                           ~ get_appearances(link = .x) %>% 
                             mutate(name = .y))
```

Check # of squad members == element of list

```{r}
length(appearances_df_raw) == 23
```


```{r}
saveRDS(appearances_df_raw, 
        file = glue(""{here::here()}/data/appearances_df_raw_LFC_19_20.RDS""))
appearances_df_raw <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_raw_LFC_19_20.RDS""))
```


# clean

```{r}
appearances_df_LFC_19_20 <- appearances_df_raw %>% 
  reduce(bind_rows) %>% 
  group_by(name) %>% 
  mutate(match_num = row_number()) %>% 
  mutate(end = seq(from = 90, to = 720, by = 90),
         start = lag(end, default = 0),
         dur = if_else(minutes == 90, start, end - minutes)) %>% 
  ## for sub-outs
  mutate(end = case_when(
    sub_out != 0 ~ start + sub_out,
    TRUE ~ end),
    dur = case_when(
      sub_out != 0 ~ start,
      TRUE ~ dur)) %>% 
  ## change times for injury == TRUE
  mutate(dur = case_when(
    injury == TRUE ~ start,
    TRUE ~ dur)) %>% 
  ungroup() %>% 
  mutate(name = str_replace_all(name, ""-"", "" "") %>% str_to_title(),
         position = case_when(row_number() %in% 1:16 ~ ""GK"",
                              row_number() %in% 17:72 ~ ""DF"",
                              row_number() %in% 73:128 ~ ""MF"",
                              row_number() %in% 129:184 ~ ""ST""),
         position = as_factor(position) %>% 
           fct_relevel(""GK"", ""DF"", ""MF"", ""ST""),
         name = as_factor(name)) %>% 
  arrange(position, name) %>% 
  mutate(id = row_number(),
         name = fct_reorder(name, id))
```



```{r}
## save
saveRDS(appearances_df_LFC_19_20, 
        file = glue(""{here::here()}/data/appearances_df_LFC_19_20.RDS""))
appearances_df_LFC_19_20 <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_LFC_19_20.RDS""))
```


# plot

## plot aux

```{r}
divide_lines <- tibble(yint = seq(0.5, 23.5, by = 1))

verticolo <- tibble(verts_start = seq(0, 720, by = 90),
                    verts_end = seq(0, 720, by = 90),
                    y_low = 0.5,
                    y_high = 23.5)
```

## all player

```{r, fig.height=9, fig.width=12, message=FALSE}
appearances_df_LFC_19_20 %>% 
  ggplot(aes(x = dur, 
             y = name, yend = name)) + 
  geom_segment(data = appearances_df_LFC_19_20,
               aes(xend = end,
                   group = match_num, color = injury),
               size = 3.5) +
  scale_color_manual(values = c(""darkgreen"", ""red""),
                     guide = FALSE) +
  geom_segment(data = verticolo, 
               aes(x = verts_start, xend = verts_end, 
                   y = y_low, yend = y_high)) +
  ## Dividers
  geom_hline(data = divide_lines, aes(yintercept = yint),
             size = 0.5) +
  scale_x_continuous(breaks = seq(45, 720, 90),
                     labels = seq(1, 8, 1),
                     expand = c(0, 0)) +
  expand_limits(y = c(0.1, 26)) +
  ## Kloppo
  annotate(geom = ""segment"", 
           x = 360, xend = 360,
           y = 24, yend = 24.8,
           color = ""black"", size = 1) +
  annotate(geom = ""label"", size = 5,
           label = ""Jrgen Klopp (W: 8 D: 0 L: 0)"",
           x = 360, y = 25, family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", 
           x = 1, xend = 719,
           y = 24, yend = 24,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 1, xend = 1,
           y = 23.7, yend = 24.3,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 719, xend = 719,
           y = 23.7, yend = 24.3,
           color = ""black"", size = 1) +
  labs(title = ""Player Minutes | <b style='color:#D00027'>Liverpool FC</b> | Season 2019-2020"",
       subtitle = glue(""
                       Players Ordered by Position (ST, MF, DF, GK)
                       Black = Injury or Suspension""),
       x = ""Minutes Played per Game Week"", y = """",
       caption = glue::glue(""
                            Data: transfermarkt.com
                            By: @R_by_Ryo"")) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        axis.title = element_text(size = 14),
        axis.text.x = element_text(color = ""black"", size = 11),
        axis.text.y = element_text(color = ""black"", size = 10),
        panel.grid = element_blank(),
        plot.title = element_markdown(size = 20),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 12))
```

```{r}
ggsave(filename = here::here(""Premier League 2018-2019/output/player_minutes_LFC_19_20.png""),
       height = 9, width = 12)
```

## add logo

```{r}
# add logo with Magick using Thomas Mock's custom function
# check out the explanation in his blog post: https://themockup.netlify.com/posts/2019-01-09-add-a-logo-to-your-plot/
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}

# add_logo and save
plot_logo <- add_logo(plot_path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_19_20.png""),
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/thumb/0/0c/Liverpool_FC.svg/800px-Liverpool_FC.svg.png"",
                      logo_position = ""top right"",
                      logo_scale = 18)

image_write(image = plot_logo, 
            path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_19_20_logo.png""))
```




","2018"
"59",226,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/appearances_season_split_manager.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""6/23/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Appearances over Season: Split between Managers

## packages

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

- from squad details
-- grab each player name + id num
-- iterate to scrape their appearances table for entire season
-- try to grab the icons for injuries??

# 2010-2011: webscrape

## squad info

- Squad details for 2010-2011 season

```{r}
url <- ""https://www.transfermarkt.com/liverpool-fc/leistungsdaten/verein/31/reldata/GB1%262010/plus/1""

session <- bow(url)

squad_table_raw <- scrape(session) %>% 
  html_nodes("".hauptlink > div > span > a"") %>% 
  html_attr(""href"")

squad_table_clean <- squad_table_raw %>% 
  enframe() %>% 
  select(-name) %>% 
  distinct() %>% 
  separate(value, into = c(""1"", ""2"", '3', '4', '5'), sep = ""\\/"") %>% 
  select(player_name = 2, id_num = 5)

## add links
squad_table_df <- squad_table_clean %>% 
  mutate(link = glue::glue(""https://www.transfermarkt.com/{player_name}/leistungsdatendetails/spieler/{id_num}/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1"")) %>% 
  ## remove Amoo, tom ince, Dalla Valle
  slice(-31, -38, -41)

glimpse(squad_table_df)
```

## base dates

- use someone like Skrtel who played/in squad of every single game:

```{r}
base_url <- ""https://www.transfermarkt.com/martin-skrtel/leistungsdatendetails/spieler/24180/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session <- bow(base_url)

base_raw <- scrape(session) %>% 
  html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  slice(-n())

base_dates <- base_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  ## make sure minutes == 0 for BASE
  mutate(date = lubridate::mdy(date),
         minutes = 0) %>% 
  ## set sub_in, sub_out = 0
  mutate(sub_in = 0,
         sub_out = 0) %>% 
  ## set goals/assists = 0
  mutate(goal = 0,
         assist = 0) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))

saveRDS(base_dates, file = here::here(""data/base_LFC_10_11_dates_df.RDS""))
base_dates <- readRDS(file = here::here(""data/base_LFC_10_11_dates_df.RDS""))
```


## get_appearances() function

```{r}
get_appearances <- function(link) {
  
  session <- bow(link)
  
  appearances_raw <- scrape(session) %>% 
    html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
    html_table(fill = TRUE) %>% 
    .[[1]] %>% 
    #magrittr::extract2(1) %>% 
    janitor::clean_names() %>% 
    slice(-n())
  
  appearances_clean <- appearances_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  ## fix minutes
  ## mutate_at(), mutate_if()...
  mutate(date = lubridate::mdy(date),
         minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes),
         minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                           minutes, ""0"") %>% as.numeric()) %>% 
  ## fix sub_in, sub_out
  mutate(sub_in =  
           if_else(str_detect(sub_in, ""'""), 
                   str_replace_all(sub_in, ""'"", """"), sub_in),
         sub_in = if_else(str_detect(sub_in, ""^[0-9]+$""),
                           sub_in, ""0"") %>% as.numeric(),
         sub_out =  
           if_else(str_detect(sub_out, ""'""), 
                   str_replace_all(sub_out, ""'"", """"), sub_out),
         sub_out = if_else(str_detect(sub_out, ""^[0-9]+$""),
                           sub_out, ""0"") %>% as.numeric()) %>% 
  ## fix goals/assists
  mutate(goal = if_else(str_detect(goal, ""^[0-9]+$""),
                           goal, ""0"") %>% as.numeric(),
         assist = if_else(str_detect(assist, ""^[0-9]+$""),
                           assist, ""0"") %>% as.numeric()) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
  
  ## deal with no match rows:
  ## basically using base df, anti_join on dates and 
  ## insert info for rows where missing
  add_df <- base_dates %>% 
    anti_join(appearances_clean, by = c(""date""))
  
  ## combine missing data with existing
  appearances_clean <- appearances_clean %>% 
    full_join(add_df) %>% 
    arrange(date)
}
```

## iterate over

```{r, message=FALSE}
appearances_df_raw <- map2(.x = squad_table_df$link,
                           .y = squad_table_df$player_name,
                           ~ get_appearances(link = .x) %>% 
                             mutate(name = .y))

saveRDS(appearances_df_raw, 
        file = glue(""{here::here()}/data/appearances_df_raw_LFC_10_11.RDS""))
appearances_df_raw <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_raw_LFC_10_11.RDS""))
```




```{r}
appearances_df_LFC_10_11 <- appearances_df_raw %>% 
  reduce(bind_rows) %>% 
  group_by(name) %>% 
  mutate(match_num = row_number()) %>% 
  mutate(end = seq(from = 90, to = 3420, by = 90),
         start = lag(end, default = 0),
         dur = if_else(minutes == 90, start, end - minutes)) %>% 
  ## for sub-outs
  mutate(end = case_when(
    sub_out != 0 ~ start + sub_out,
    TRUE ~ end),
    dur = case_when(
      sub_out != 0 ~ start,
      TRUE ~ dur)) %>% 
  ungroup() %>% 
  ## fix Joe Cole manually, didn't consider expulsion due to red cards
  ## there's probably a few others but I'll do that another time...
  mutate(end = case_when(
    name == ""joe-cole"" & match_num == 1 ~ dur,
    TRUE ~ end),
    dur = case_when(
      name == ""joe-cole"" & match_num == 1 ~ 0,
    TRUE ~ dur
    )) %>% 
  ## fix names and label positions
  mutate(name = str_replace_all(name, ""-"", "" "") %>% str_to_title(),
         position = case_when(row_number() %in% 1:190 ~ ""GK"",
                              row_number() %in% 191:760 ~ ""DF"",
                              row_number() %in% 761:1102 ~ ""MF"",
                              row_number() %in% 1103:1482 ~ ""ST""),
         position = as_factor(position) %>% 
           fct_relevel(""GK"", ""DF"", ""MF"", ""ST""),
         name = as_factor(name)) %>% 
  arrange(position, name)

## save
saveRDS(appearances_df_LFC_10_11, 
        file = glue(""{here::here()}/data/appearances_df_LFC_10_11.RDS""))
appearances_df_LFC_10_11 <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_LFC_10_11.RDS""))
```

## plot

```{r}
glimpse(appearances_df_LFC_10_11)
```


```{r}
## check that each player has data for 38 games...
appearances_df_LFC_10_11 %>% 
  group_by(name) %>% 
  summarize(num = n())
```

```{r}
lucas_df <- appearances_df_LFC_10_11 %>% 
  filter(name == ""Lucas Leiva"")

lucas_df %>% 
  mutate(end = seq(from = 90, to = 3420, by = 90),
         start = lag(end, default = 0)) %>% 
  mutate(dur = if_else(minutes == 90, start, end - minutes)) %>% 
  View()

spearo_df <- appearances_df_LFC_10_11 %>% 
  filter(name == ""Jay Spearing"")

spearo_df %>% 
  mutate(end = seq(from = 90, to = 3420, by = 90),
         start = lag(end, default = 0)) %>% 
  mutate(dur = if_else(minutes == 90, start, end - minutes)) %>% 
  View()
```

## plot aux

```{r}
divide_lines <- tibble(yint = seq(0.5, 39.5, by = 1))

verticolo <- tibble(verts_start = seq(0, 3420, by = 90),
                    verts_end = seq(0, 3420, by = 90),
                    y_low = 0.5,
                    y_high = 39.5)
```


```{r}
appearances_df_LFC_10_11 %>% 
  mutate(position = case_when(row_number() %in% 1:190 ~ ""GK"",
                              row_number() %in% 191:760 ~ ""DF"",
                              row_number() %in% 761:1102 ~ ""MF"",
                              row_number() %in% 1103:1482 ~ ""ST"")) %>% 
  View()
```


```{r}
appearances_df_LFC_10_11 %>% 
  mutate(position = as_factor(position) %>% 
           fct_relevel(""GK"", ""DF"", ""MF"", ""ST"")) %>% 
  glimpse()
```


## raul

- if ""sub_out"" then end == start + sub_out and dur == start

```{r, fig.height=9, fig.width=12}
appearances_df_LFC_10_11 %>% 
  filter(name == ""Raul Meireles"") %>% 
  ggplot() + 
  geom_segment(aes(x = dur, xend = end, 
                   y = name, yend = name, group = match_num), 
               size = 3, color = ""darkred"") +
  # geom_vline(xintercept = 0,
  #            size = 0.5) +
  geom_vline(xintercept = 1710, color = ""green"",
             size = 0.5) +
  geom_segment(data = verticolo, 
               aes(x = verts_start, xend = verts_end, 
                   y = y_low, yend = y_high)) +
  # geom_vline(data = verticolo, aes(xintercept = verts),
  #            size = 0.5) +
  # geom_hline(data = divide_lines, aes(yintercept = yint),
  #            size = 0.5) +
  scale_x_continuous(breaks = seq(45, 3420, 90),
                     labels = seq(1, 38, 1),
                     expand = c(0, 0)) +
  #scale_y_discrete(expand = c(0.1, 0)) +
  annotate(geom = ""label"", label = ""Roy Hodgson"",
           x = 800, y = 42, family = ""Roboto Condensed"") +
  annotate(geom = ""label"", label = ""Kenny Dalglish"",
           x = 2800, y = 42, family = ""Roboto Condensed"") +
  labs(title = ""Player Minutes"",
       subtitle = ""Liverpool FC | Season 2010-2011"",
       x = ""Minutes Played per Game Week"", y = """",
       caption = glue::glue(""
                            Data: transfermarkt.com
                            By: @R_by_Ryo"")) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        #panel.grid.minor.x = element_line(color = ""black"", size = 0.25),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank())
```



## all players

```{r, fig.height=9, fig.width=12}
appearances_df_LFC_10_11 %>% 
  ggplot(aes(x = dur, xend = end, 
             y = name, 
             yend = name)) + 
  ## Woy
  geom_segment(data = appearances_df_LFC_10_11 %>% filter(match_num < 21),
               aes(group = match_num),
               size = 3, color = ""darkred"") +
  ## King Kenny
  geom_segment(data = appearances_df_LFC_10_11 %>% filter(match_num >= 21),
               aes(group = match_num),
               size = 3, color = ""darkgreen"") +
  geom_segment(data = verticolo, 
               aes(x = verts_start, xend = verts_end, 
                   y = y_low, yend = y_high)) +
  ## Dividers
  geom_segment(x = 1800, xend = 1800,
               y = 0.5, yend = 39.5, 
               color = ""darkgrey"", size = 1.1) +
  geom_hline(data = divide_lines, aes(yintercept = yint),
             size = 0.5) +
  scale_x_continuous(breaks = seq(45, 3420, 90),
                     labels = seq(1, 38, 1),
                     expand = c(0, 0)) +
  expand_limits(y = c(0.1, 43)) +
  ## Woy
  annotate(geom = ""segment"", 
           x = 945, xend = 945,
           y = 40, yend = 40.5,
           color = ""black"", size = 1) +
  annotate(geom = ""label"", 
           label = ""Roy Hodgson (W: 7 D: 4 L: 9)"",
           x = 945, y = 41, family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", 
           x = 7, xend = 1790,
           y = 40, yend = 40,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 7, xend = 7,
           y = 39.7, yend = 40.3,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 1790, xend = 1790,
           y = 39.7, yend = 40.3,
           color = ""black"", size = 1) +
  ## King Kenny
  annotate(geom = ""segment"", 
           x = 2655, xend = 2655,
           y = 40, yend = 40.5,
           color = ""black"", size = 1) +
  annotate(geom = ""label"", 
           label = ""Kenny Dalglish (W: 10 D: 3 L: 5)"",
           x = 2655, y = 41, family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", 
           x = 1810, xend = 3410,
           y = 40, yend = 40,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 1810, xend = 1810,
           y = 39.7, yend = 40.3,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 3410, xend = 3410,
           y = 39.7, yend = 40.3,
           color = ""black"", size = 1) +
  labs(title = ""Player Minutes | Liverpool FC | Season 2010-2011"",
       subtitle = ""Players Ordered by Position (ST, MF, DF, GK)"",
       x = ""Minutes Played per Game Week"", y = """",
       caption = glue::glue(""
                            Data: transfermarkt.com
                            By: @R_by_Ryo"")) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        axis.title = element_text(size = 14),
        axis.text.x = element_text(color = ""black"", size = 11),
        axis.text.y = element_text(color = ""black"", size = 10),
        panel.grid = element_blank(),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 16),
        plot.caption = element_text(size = 12))
```

```{r}
ggsave(filename = here::here(""Premier League 2018-2019/output/player_minutes_LFC_10_11.png""),
       height = 9, width = 12)
```


## add logo

```{r}
# add logo with Magick using Thomas Mock's custom function
# check out the explanation in his blog post: https://themockup.netlify.com/posts/2019-01-09-add-a-logo-to-your-plot/
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}

# add_logo and save
plot_logo <- add_logo(plot_path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_10_11.png""),
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/thumb/0/0c/Liverpool_FC.svg/800px-Liverpool_FC.svg.png"",
                      logo_position = ""top right"",
                      logo_scale = 18)

image_write(image = plot_logo, path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_10_11_logo.png""))
```








# 2015-2016: webscrape


## squad info

- Squad details 

```{r}
url <- ""https://www.transfermarkt.com/liverpool-fc/leistungsdaten/verein/31/reldata/GB1%262015/plus/1""

session <- bow(url)

squad_table_raw <- scrape(session) %>% 
  html_nodes("".hauptlink > div > span > a"") %>% 
  html_attr(""href"")

squad_table_clean <- squad_table_raw %>% 
  enframe() %>% 
  select(-name) %>% 
  distinct() %>% 
  separate(value, into = c(""1"", ""2"", '3', '4', '5'), sep = ""\\/"") %>% 
  select(player_name = 2, id_num = 5)

## add links
squad_table_df <- squad_table_clean %>% 
  mutate(link = glue::glue(""https://www.transfermarkt.com/{player_name}/leistungsdatendetails/spieler/{id_num}/saison/2015/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1"")) %>% 
  ## remove Kent, J-C, Masterson, Cleary, Maguire, Wisdom, Fulton, Vigoroux
  slice(-43, -30, -22, -21, -18, -12, -5, -4)

glimpse(squad_table_df)
```

## base dates

- use someone like Migs who played/in squad of every single game:

```{r}
base_url <- ""https://www.transfermarkt.com/simon-mignolet/leistungsdatendetails/spieler/50219/saison/2015/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session <- bow(base_url)

base_raw <- scrape(session) %>% 
  html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  slice(-n())

base_dates <- base_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  ## make sure minutes == 0 for BASE
  ## add empty FALSE injury col
  mutate(date = lubridate::mdy(date),
         minutes = 0,
         injury = FALSE) %>% 
  ## set sub_in, sub_out = 0
  mutate(sub_in = """",
         sub_out = 0) %>% 
  ## set goals/assists = 0
  mutate(goal = 0,
         assist = 0) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
```

```{r}
saveRDS(base_dates, file = here::here(""data/base_LFC_15_16_dates_df.RDS""))
base_dates <- readRDS(file = here::here(""data/base_LFC_15_16_dates_df.RDS""))
```


## get_appearances() function

```{r}
get_appearances <- function(link) {
  
  session <- bow(link)
  
  appearances_raw <- scrape(session) %>% 
    html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
    html_table(fill = TRUE) %>% 
    .[[1]] %>% 
    #magrittr::extract2(1) %>% 
    janitor::clean_names() %>% 
    slice(-n())
  
  appearances_clean <- appearances_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  mutate(date = lubridate::mdy(date),
         minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes),
         minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                           minutes, ""0"") %>% as.numeric()) %>% 
  ## injury + suspension
  mutate(sub_in =  
           if_else(str_detect(sub_in, ""'""), 
                   str_replace_all(sub_in, ""'"", """"), sub_in),
         sub_in = case_when(
    str_detect(sub_in, ""^[0-9]+$"") == TRUE ~ """",
    TRUE ~ sub_in)) %>% 
  ## handle cases of suspension too, otherwise == FALSE
  mutate(injury = case_when(
    sub_in %in% c(""on the bench"", ""Not in squad"", ""With 2nd team"",
                  ""special leave"", ""doping ban"", """") ~ FALSE,
    TRUE ~ TRUE)) %>% 
  ## fix sub_out
  mutate(sub_out =  
           if_else(str_detect(sub_out, ""'""), 
                   str_replace_all(sub_out, ""'"", """"), sub_out),
         sub_out = if_else(str_detect(sub_out, ""^[0-9]+$""),
                           sub_out, ""0"") %>% as.numeric()) %>% 
  ## fix goals/assists
  mutate(goal = if_else(str_detect(goal, ""^[0-9]+$""),
                           goal, ""0"") %>% as.numeric(),
         assist = if_else(str_detect(assist, ""^[0-9]+$""),
                           assist, ""0"") %>% as.numeric()) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
  
  ## deal with no match rows:
  ## basically using base df, anti_join on dates and 
  ## insert info for rows where missing
  add_df <- base_dates %>% 
    anti_join(appearances_clean, by = c(""date""))
  
  ## combine missing data with existing
  appearances_clean <- appearances_clean %>% 
    full_join(add_df) %>% 
    arrange(date)
}
```

## iterate over

```{r}
appearances_df_raw <- map2(.x = squad_table_df$link,
                           .y = squad_table_df$player_name,
                           ~ get_appearances(link = .x) %>% 
                             mutate(name = .y))
```


```{r}
saveRDS(appearances_df_raw, 
        file = glue(""{here::here()}/data/appearances_df_raw_LFC_15_16.RDS""))
appearances_df_raw <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_raw_LFC_15_16.RDS""))
```


```{r}
appearances_df_LFC_15_16 <- appearances_df_raw %>% 
  reduce(bind_rows) %>% 
  group_by(name) %>% 
  mutate(match_num = row_number()) %>% 
  mutate(end = seq(from = 90, to = 3420, by = 90),
         start = lag(end, default = 0),
         dur = if_else(minutes == 90, start, end - minutes)) %>% 
  ## for sub-outs
  mutate(end = case_when(
    sub_out != 0 ~ start + sub_out,
    TRUE ~ end),
    dur = case_when(
      sub_out != 0 ~ start,
      TRUE ~ dur)) %>% 
  ## change times for injury == TRUE
  mutate(dur = case_when(
    injury == TRUE ~ start,
    TRUE ~ dur)) %>% 
  ungroup() %>% 
  mutate(name = str_replace_all(name, ""-"", "" "") %>% str_to_title(),
         position = case_when(row_number() %in% 1:114 ~ ""GK"",
                              row_number() %in% 115:608 ~ ""DF"",
                              row_number() %in% 609:1026 ~ ""MF"",
                              row_number() %in% 1027:1368 ~ ""ST""),
         position = as_factor(position) %>% 
           fct_relevel(""GK"", ""DF"", ""MF"", ""ST""),
         name = as_factor(name)) %>% 
  arrange(position, name)

## save
saveRDS(appearances_df_LFC_15_16, 
        file = glue(""{here::here()}/data/appearances_df_LFC_15_16.RDS""))
appearances_df_LFC_15_16 <- readRDS(
  file = glue(""{here::here()}/data/appearances_df_LFC_15_16.RDS""))
```


## plot

## plot aux

```{r}
divide_lines <- tibble(yint = seq(0.5, 36.5, by = 1))

verticolo <- tibble(verts_start = seq(0, 3420, by = 90),
                    verts_end = seq(0, 3420, by = 90),
                    y_low = 0.5,
                    y_high = 36.5)
```


## all player

```{r, fig.height=9, fig.width=12, message=FALSE}
appearances_df_LFC_15_16 %>% 
  
  mutate(name = reorder_within(name, name, position)) %>% 
  
  ggplot() + 
  ## injury + suspension
  geom_segment(data = appearances_df_LFC_15_16 %>% filter(injury == TRUE),
               aes(x = dur, y = name,
                   xend = end, yend = name, group = match_num),
               size = 3.5, color = ""black"") +
  ## Brendao
  geom_segment(data = appearances_df_LFC_15_16 %>% 
                 filter(match_num < 9 & injury == FALSE),
               aes(x = dur, y = name,
                   xend = end, yend = name, group = match_num),
               size = 3.5, color = ""darkred"") +
  ## Kloppo
  geom_segment(data = appearances_df_LFC_15_16 %>% 
                 filter(match_num >= 9 & injury == FALSE),
               aes(x = dur, y = name,
                   xend = end, yend = name, group = match_num),
               size = 3.5, color = ""darkgreen"") +
  geom_segment(data = verticolo, 
               aes(x = verts_start, xend = verts_end, 
                   y = y_low, yend = y_high)) +
  ## Dividers
  geom_segment(x = 720, xend = 720,
               y = 0.5, yend = 36.5, 
               color = ""darkgrey"", size = 1.1) +
  geom_hline(data = divide_lines, aes(yintercept = yint),
             size = 0.5) +
  scale_x_continuous(breaks = seq(45, 3420, 90),
                     labels = seq(1, 38, 1),
                     expand = c(0, 0)) +
  expand_limits(y = c(0.1, 40)) +
  ## Brendao
  annotate(geom = ""segment"", 
           x = 360, xend = 360,
           y = 37, yend = 37.5,
           color = ""black"", size = 1) +
  annotate(geom = ""label"", size = 4,
           label = ""Brendan Rodgers (W: 3 D: 3 L: 2)"",
           x = 360, y = 38, family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", 
           x = 7, xend = 710,
           y = 37, yend = 37,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 7, xend = 7,
           y = 36.7, yend = 37.3,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 710, xend = 710,
           y = 36.7, yend = 37.3,
           color = ""black"", size = 1) +
  ## Kloppo
  annotate(geom = ""segment"", 
           x = 2065, xend = 2065,
           y = 37, yend = 37.5,
           color = ""black"", size = 1) +
  annotate(geom = ""label"", size = 4,
           label = ""Jrgen Klopp (W: 13 D: 9 L: 8)"",
           x = 2065, y = 38, family = ""Roboto Condensed"") +
  annotate(geom = ""segment"", 
           x = 730, xend = 3410,
           y = 37, yend = 37,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 730, xend = 730,
           y = 36.7, yend = 37.3,
           color = ""black"", size = 1) +
  annotate(geom = ""segment"", 
           x = 3410, xend = 3410,
           y = 36.7, yend = 37.3,
           color = ""black"", size = 1) +
  labs(title = ""Player Minutes | Liverpool FC | Season 2015-2016"",
       subtitle = glue(""
                       Players Ordered by Position (ST, MF, DF, GK)
                       Black = Injury or Suspension""),
       x = ""Minutes Played per Game Week"", y = """",
       caption = glue::glue(""
                            Data: transfermarkt.com
                            By: @R_by_Ryo"")) +
  facet_wrap(~position) +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        axis.title = element_text(size = 14),
        axis.text.x = element_text(color = ""black"", size = 11),
        axis.text.y = element_text(color = ""black"", size = 10),
        panel.grid = element_blank(),
        plot.title = element_text(size = 20),
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 12))
```

```{r}
ggsave(filename = here::here(""Premier League 2018-2019/output/player_minutes_LFC_15_16.png""),
       height = 9, width = 12)
```

## add logo

```{r}
# add logo with Magick using Thomas Mock's custom function
# check out the explanation in his blog post: https://themockup.netlify.com/posts/2019-01-09-add-a-logo-to-your-plot/
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}

# add_logo and save
plot_logo <- add_logo(plot_path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_15_16.png""),
                      logo_path = ""https://upload.wikimedia.org/wikipedia/en/thumb/0/0c/Liverpool_FC.svg/800px-Liverpool_FC.svg.png"",
                      logo_position = ""top right"",
                      logo_scale = 18)

image_write(image = plot_logo, path = here::here(""Premier League 2018-2019/output/player_minutes_LFC_15_16_logo.png""))
```

























# stuff that didnt work etc.


```{r}
## Squad details for 2010-2011 season
url <- ""https://www.transfermarkt.com/liverpool-fc/leistungsdaten/verein/31/reldata/GB1%262010/plus/1""

session <- bow(url)

squad_table_raw <- scrape(session) %>% 
  html_nodes("".hauptlink > div > span > a"") %>% 
  html_attr(""href"")

squad_table_clean <- squad_table_raw %>% 
  enframe() %>% 
  select(-name) %>% 
  distinct() %>% 
  separate(value, into = c(""1"", ""2"", '3', '4', '5'), sep = ""\\/"") %>% 
  select(player_name = 2, id_num = 5)

glimpse(squad_table_clean)
```

```{r}
squad_table_df <- squad_table_clean %>% 
  mutate(link = glue::glue(""https://www.transfermarkt.com/{player_name}/leistungsdatendetails/spieler/{id_num}/plus/0/saison/2010/wettbewerb/GB1/verein/31""))
```

## big function

```{r}
get_appearances <- function(link) {
  
  session <- bow(link)
  
  appearances_raw <- scrape(session) %>% 
    html_nodes(""thead+ tbody td"") %>% 
    html_text() %>% 
    enframe()
  
  appearances_clean <- appearances_raw %>% 
    select(-name) %>% 
    mutate(var = if_else(value %>% str_detect(""\\\r""), 
                         ""match_num"", ""minutes"")) %>% 
    mutate(thingy = case_when(
      var == ""match_num"" ~ value,
      TRUE ~ """"),
      thingy = as.numeric(thingy)) %>% 
    fill(thingy) %>% 
    group_by(thingy) %>% 
    slice(c(1, n())) %>% 
    filter(var == ""minutes"") %>% 
    select(match_number = thingy, minutes = value, -var) %>% 
    mutate(minutes =  
             if_else(str_detect(minutes, ""'""), 
                     str_replace_all(minutes, ""'"", """"), minutes)) %>% 
    mutate(minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                             minutes, ""0"") %>% as.numeric())
  
  ## deal with no match rows:
  empty_df <- tibble(match_number = c(1:38), minutes = rep(0, 38))
  
  
  add_df <- empty_df %>% 
    anti_join(appearances_clean, by = c(""match_number"", ""minutes""))
  
  appearances_clean <- add_df %>% 
    full_join(appearances_clean) %>% 
    arrange(match_number) %>% 
    distinct()
}
```


```{r}
appearances_df_raw <- map2(.x = squad_table_df$link[32:34],
                           .y = squad_table_df$player_name[32:34],
                           ~ get_appearances(link = .x) %>% 
                             mutate(name = .y))

appearances_df_LFC_10_11 <- appearances_df_raw %>% 
  reduce(bind_rows)

## save
saveRDS(appearances_df, file = glue(""{here::here()}/data/appearances_df_LFC_10_11.RDS""))
```







```{r}
appearances_url <- ""https://www.transfermarkt.com/martin-skrtel/leistungsdatendetails/spieler/3109/plus/0/saison/2010/wettbewerb/GB1/verein/31""

appearances_url <- glue::glue(""https://www.transfermarkt.com/{player_name}/leistungsdatendetails/spieler/{id_num}/plus/0/saison/2010/wettbewerb/GB1/verein/31"")

appearances_url <- ""https://www.transfermarkt.com/steven-gerrard/leistungsdatendetails/spieler/3109/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0""


session <- bow(appearances_url)

dates_raw <- scrape(session) %>% 
  html_nodes("".responsive-table td.zentriert:nth-child(2)"") %>% 
  html_text()

venue_raw <- scrape(session) %>% 
  html_nodes("".zentriert.hauptlink"") %>% 
  html_text()

result_raw <- scrape(session) %>% 
  html_nodes("".ergebnis-link span"") %>% 
  html_text() %>% 
  trimws()

goal_raw <- scrape(session) %>% 
  html_nodes("".zentriert.hauptlink"") %>% 
  html_text()

assist_raw <- scrape(session) %>% 
  html_nodes("".responsive-table td.zentriert:nth-child(1) , thead+ tbody .rechts"") %>% 
  html_text()

minutes_raw <- scrape(session) %>% 
  html_nodes(""thead+ tbody .rechts"") %>% 
  html_text()



alles_raw <- scrape(session) %>% 
  html_nodes("".responsive-table thead+ tbody td"") %>% 
  html_text()
  html_table(fill = TRUE)
  
  
alles2_raw <- scrape(session) %>% 
  html_nodes("".responsive-table tbody td"") %>% 
  html_text()

alles2_raw %>% 
  enframe() %>% 
  select(-name) %>% 
  slice(-1:-8) %>% 
  mutate(match = if_else(value %>% str_detect(""\\\r""), TRUE, FALSE)) %>%
  mutate(thingy = case_when(
    match == TRUE ~ value,
    TRUE ~ """"
  )) %>% 
  group_by(match, thingy) %>%
  fill(thingy) %>%
  View()
```

.responsive-table td.zentriert:nth-child(1) , thead+ tbody .rechts

tfoot .zentriert+ .rechts , .responsive-table .zentriert+ .hauptlink , .img-vat~ .responsive-table th , thead+ tbody .rechts , .responsive-table thead+ tbody .zentriert

## stevie G

```{r}
asdf_url <- ""https://www.transfermarkt.com/steven-gerrard/leistungsdatendetails/spieler/3109/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session <- bow(asdf_url)

appearances_raw <- scrape(session) %>% 
  html_nodes(""thead+ tbody td"") %>% 
  html_text() %>% 
  enframe()
  
  
appearances_clean <- appearances_raw %>% 
  select(-name) %>% 
  mutate(var = if_else(value %>% str_detect(""\\\r""), 
                         ""match_num"", ""minutes"")) %>% 
  mutate(thingy = case_when(
    var == ""match_num"" ~ value,
    TRUE ~ """"),
    thingy = as.numeric(thingy)) %>% 
  fill(thingy) %>% 
  group_by(thingy) %>% 
  slice(c(1, n())) %>% 
  filter(var == ""minutes"") %>% 
  select(match_number = thingy, minutes = value, -var) %>% 
  mutate(minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes)) %>% 
  mutate(minutes = if_else(str_detect(minutes, ""[0-9]""),
                           minutes, ""0"") %>% as.numeric())
```

## skrtel

```{r}
asdf_url2 <- ""https://www.transfermarkt.com/martin-skrtel/leistungsdatendetails/spieler/24180/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session2 <- bow(asdf_url2)

appearances_raw2 <- scrape(session2) %>% 
  html_nodes(""thead+ tbody td"") %>% 
  html_text() %>% 
  enframe() %>% 
  select(-name)

appearances_clean2 <- appearances_raw2 %>% 
  mutate(var = if_else(value %>% str_detect(""\\\r""), 
                         ""match_num"", ""minutes"")) %>% 
  mutate(thingy = case_when(
    var == ""match_num"" ~ value,
    TRUE ~ """") ,
    thingy = as.numeric(thingy)
    ) %>% 
  fill(thingy) %>% #View()
  group_by(thingy) %>% 
  slice(c(1, n())) %>% #View()
  filter(var == ""minutes"") %>% 
  select(match_number = thingy, minutes = value, -var) %>% 
  mutate(minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes)) %>% 
  mutate(minutes = if_else(str_detect(minutes, ""[0-9]""),
                           minutes, ""0"") %>% as.numeric())
```

```{r}
asdf_url3 <- ""https://www.transfermarkt.com/martin-skrtel/leistungsdatendetails/spieler/24180/plus/0/saison/2010/wettbewerb/GB1/verein/31""

session3 <- bow(asdf_url3)

base_raw <- scrape(session3) %>% 
  html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  slice(-n())

base_dates <- base_raw %>% 
  select(date, opponent = vs_2)
```



## gulacsi

```{r}
asdf_url3 <- ""https://www.transfermarkt.com/peter-gulacsi/leistungsdatendetails/spieler/57071/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session3 <- bow(asdf_url3)

appearances_raw3 <- scrape(session3) %>% 
  html_nodes(""thead+ tbody td"") %>% 
  html_text() %>% 
  enframe() %>% 
  select(-name)

appearances_clean3 <- appearances_raw3 %>% 
  mutate(var = if_else(value %>% str_detect(""\\\r""), 
                         ""match_num"", ""minutes"")) %>% #View()
  mutate(thingy = case_when(
    var == ""match_num"" ~ value,
    TRUE ~ """") ,
    thingy = as.numeric(thingy)
    ) %>% 
  fill(thingy) %>% #View()
  group_by(thingy) %>% 
  slice(c(1, n())) %>% 
  filter(var == ""minutes"") %>% 
  select(match_number = thingy, minutes = value, -var) %>% 
  mutate(minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes)) %>% 
  mutate(minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                           minutes, ""0"") %>% as.numeric())
```

IF number in match_number 1-38 is missing THEN create ROW with missing num and minutes == 0!


```{r}
appearances_clean3b <- appearances_raw3 %>% 
  mutate(var = if_else(value %>% str_detect(""\\\r""), 
                         ""match_num"", ""minutes"")) %>% #View()
  mutate(thingy = case_when(
    var == ""match_num"" ~ value,
    TRUE ~ """") ,
    thingy = as.numeric(thingy)
    ) %>% 
  fill(thingy) 

empty_df <- tibble(match_number = c(1:38), minutes = rep(0, 38))


add_df <- empty_df %>% #select(match_number) %>% 
  anti_join(appearances_clean3, by = c(""match_number"", ""minutes""))

add_df %>% 
  bind_rows(appearances_clean3) %>% 
  arrange(match_number) %>% 
  distinct()

appearances_clean3 %>% 
  full_join(add_df) %>% 
  arrange(match_number) %>% 
  distinct()



```


## torres
""https://www.transfermarkt.com/fernando-torres/leistungsdatendetails/spieler/7767/plus/0/saison/2010/wettbewerb/GB1/verein/31""
div.responsive-table:nth-child(3) > table:nth-child(1)

```{r}
asdf_url3 <- ""https://www.transfermarkt.com/fernando-torres/leistungsdatendetails/spieler/7767/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session3 <- bow(asdf_url3)

appearances_raw3 <- scrape(session3) %>% 
  html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  slice(-n())

appearances_clean3 <- appearances_raw3 %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
 ## fix minutes
  mutate(date = lubridate::mdy(date),
         minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes),
         minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                           minutes, ""0"") %>% as.numeric()) %>% 
  ## fix sub_in, sub_out
  mutate(sub_in =  
           if_else(str_detect(sub_in, ""'""), 
                   str_replace_all(sub_in, ""'"", """"), sub_in),
         sub_in = if_else(str_detect(sub_in, ""^[0-9]+$""),
                           sub_in, ""0"") %>% as.numeric(),
         sub_out =  
           if_else(str_detect(sub_out, ""'""), 
                   str_replace_all(sub_out, ""'"", """"), sub_out),
         sub_out = if_else(str_detect(sub_out, ""^[0-9]+$""),
                           sub_out, ""0"") %>% as.numeric()) %>% 
  ## fix goals/assists
  mutate(goal = if_else(str_detect(goal, ""^[0-9]+$""),
                           goal, ""0"") %>% as.numeric(),
         assist = if_else(str_detect(assist, ""^[0-9]+$""),
                           assist, ""0"") %>% as.numeric()) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))
```

""https://www.transfermarkt.com/martin-skrtel/leistungsdatendetails/spieler/24180/plus/0/saison/2010/wettbewerb/GB1/verein/31""

https://www.transfermarkt.com/martin-skrtel/leistungsdatendetails/spieler/24180/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1

```{r}
##### base_dates
asdf_url3 <- ""https://www.transfermarkt.com/martin-skrtel/leistungsdatendetails/spieler/24180/saison/2010/verein/31/liga/0/wettbewerb/GB1/pos/0/trainer_id/0/plus/1""

session3 <- bow(asdf_url3)

base_raw <- scrape(session3) %>% 
  html_nodes(""div.responsive-table:nth-child(3) > table:nth-child(1)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  slice(-n())

base_dates <- base_raw %>% 
  select(date, home = home_team_2, away = away_team_2,
         result, goal = x, assist = x_2,
         sub_in = x_7, sub_out = x_8, minutes = x_9) %>% 
  ## make sure minutes == 0 for BASE
  mutate(date = lubridate::mdy(date),
         minutes = 0) %>% 
  ## set sub_in, sub_out = 0
  mutate(sub_in = 0,
         sub_out = 0) %>% 
  ## set goals/assists = 0
  mutate(goal = 0,
         assist = 0) %>% 
  ## separate result
  separate(result, into = c(""home_goal"", ""away_goal""), 
           sep = "":"", convert = TRUE) %>% 
  ## home - away and rank
  mutate(home_rank = home %>% str_extract(""[0-9]+"") %>% as.numeric,
         away_rank = away %>% str_extract(""[0-9]+"") %>% as.numeric,
         home = home %>% str_remove_all(""\\(.*\\)""),
         away = away %>% str_remove_all(""\\(.*\\)""))

base_dates

add_df <- base_dates %>% 
  anti_join(appearances_clean3, by = c(""date""))
  
appearances_clean3 %>% 
  full_join(add_df) %>% 
  arrange(date)
```



```{r}
# base_dates %>% 
#   separate(date, into = c(""month"", ""day"", ""year""), sep = ""\\/"") %>% 
#   mutate(year = paste0(""20"", year)) %>% 
#   mutate(month = str_pad(month, width = 2, pad = ""0""),
#          day = str_pad(day, width = 2, pad = ""0"")) %>% 
#   unite(date, sep = ""-"") %>% 
#   mutate(date = lubridate::mdy(date))

# add_df %>% 
#   bind_rows(appearances_clean3) %>% 
#   arrange(date) %>% 
#   distinct()
  
```






```{r}
appearances_clean3 <- appearances_raw3 %>% 
  mutate(var = if_else(value %>% str_detect(""\\/""), 
                         ""match_num"", ""minutes"")) %>% #View()
  mutate(thingy = case_when(
    var == ""match_num"" ~ value,
    TRUE ~ """") #,
    #thingy = as.numeric(thingy)
    ) %>% 
  group_by(thingy) %>% 
  mutate(rank = 1:length(var))
  filter(var == ""minutes"") %>% 
  select(match_number = thingy, minutes = value, -var) %>% 
  mutate(minutes =  
           if_else(str_detect(minutes, ""'""), 
                   str_replace_all(minutes, ""'"", """"), minutes)) %>% 
  mutate(minutes = if_else(str_detect(minutes, ""^[0-9]+$""),
                           minutes, ""0"") %>% as.numeric())



empty_df <- tibble(match_number = c(1:38), minutes = rep(0, 38))


add_df <- empty_df %>% #select(match_number) %>% 
  anti_join(appearances_clean3, by = c(""match_number""))

add_df %>% 
  bind_rows(appearances_clean3) %>% 
  arrange(match_number) %>% 
  distinct()

appearances_clean3 %>% 
  full_join(add_df) %>% 
  arrange(match_number) %>% 
  distinct()
```


```{r}
scrape(session3) %>% 
  html_nodes("".responsive-table td"") %>% 
  html_table()
```






```{r}
assist_raw <- scrape(session) %>% 
  html_nodes("".responsive-table td.zentriert:nth-child(1) , thead+ tbody .rechts"") %>% 
  html_text()


assist_raw %>% 
  enframe() %>%
  select(-name) %>% 
  mutate(minute_val = if_else(str_detect(value, ""'""), TRUE, FALSE)) %>% 
  View()
```







```{r}
team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, ""team_name"", NA, NA, ""team_num"", NA, NA), sep = ""/"") %>% 
  mutate(link = glue(""https://www.transfermarkt.com/{team_name}/leistungsdaten/verein/{team_num}/reldata/GB1%262018/plus/1""))

# for each team link:

player_name_info <- function(link) {
  
  session <- bow(link)
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 
  
}

num_goals_info <- function(link) {
  
  session <- bow(link)
  
  num_goals_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(7)"") %>% 
    html_text()
}

num_assists_info <- function(link) {
  
  session <- bow(link)
  
  num_assists_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(8)"") %>% 
    html_text()
}

# BIG FUNCTION
premier_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  laliga_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names)
}
```


```{r}
appearances_df_LFC_10_11 %>% 
  group_by(name) %>% 
  mutate(cumsum = zoo::rollsum(minutes, 1))
  mutate(cumsum = cumsum(minutes))
```


```{r}
appearances_df_LFC_10_11 %>% 
  group_by(name) %>% 
  ggplot(aes(x = name, y = match_num)) +
  geom_col() +
  coord_flip()
```



```{r}

```




- ordeno los jugadores...by position >>> GK > DF > MF > ST
- find sub-in + sub-out times and minus from end/start 
- add manager annotate pointers
- limit vertical lines >> use geom_segment instead

example:

```{r}
Lines <- read.table(textConnection(""Begin End EventID
01.01.2000 01.05.2000 1
03.04.1998 03.09.1999 1
12.03.2014 16.07.2014 2
12.12.2003 03.06.2004 3
21.06.1993 14.12.1993 2
27.02.1995 15.03.1995 3
14.06.2002 15.06.2002 2
""), sep="" "", header=TRUE)

Lines$Begin <- as.Date(Lines$Begin, ""%d.%m.%Y"")
Lines$End <- as.Date(Lines$End, ""%d.%m.%Y"")
Lines$EventID <- as.factor(Lines$EventID)
Lines$Sep <- as.factor(1:length(Lines$Begin))

glimpse(Lines)

p <- ggplot(data = Lines) + 
     geom_segment(aes(x = Begin, xend = End, 
                      y = EventID, yend = EventID, group = Sep), 
                  size = 12)
p
```



","2018"
"60",227,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/epl_wages.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""November 2, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r message=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(purrr)
library(ggplot2)
```



```{r cars}
epl_wages_raw <- read.csv(""https://raw.githubusercontent.com/ft-interactive/baseline/master/eplWages.csv"")
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
epl_wages_lfc <- epl_wages_raw %>% 
  filter(club == ""Liverpool"") %>% 
  mutate(season = season %>% str_replace_all(""(.{4})(.*)"", ""\\1-\\2""))

y_labs <- epl_wages_lfc$season

epl_wages_lfc_plot <- epl_wages_raw %>% 
  filter(club == ""Liverpool"") %>% 
  mutate(season = season %>% str_replace_all(""(.{4})(.*)"", ""\\1""))

df <- seq.Date(from = as.Date(""1992-08-01""), 
                         to = as.Date(""2017-07-01""), 
                         by = ""month"")

df %>% as_data_frame() %>% 
  mutate(date = format(value, ""%m/%d""),
         year = format(value, ""%Y"")) %>% 
  group_by(year) %>% 
  mutate(season = case_when(
    date >= ""08-01"" ~ year,
    date <= ""07-01"" ~ glue::glue(""{year - 1}"")
  ))
  
  
  
  mutate(season = case_when(
    value %in% seq(as.Date(""1992-08-01""), as.Date(""1993-06-01""), by = ""month"") ~ ""1992/1993"",
    TRUE ~ NA
  ))

```




```{r}
epl_wages_lfc %>% 
  ggplot(aes(x = season, y = wages)) +
  geom_rect(aes(xmin = season, xmax = season), 
            ymin = -Inf, ymax = Inf, fill = ""red"") +
  geom_point()
  
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
","2018"
"61",228,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/liverpool_age_utility.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""August 2, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Liverpool FC Age-Utility Graph


```{r}
library(rvest)
library(polite)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(purrr)
library(stringr)
library(ggrepel)
library(glue)
library(extrafont)
#loadfonts()
```

```{r}
# #NONEOFTHISWORKS
# CSS Selector .items
# .items > tbody:nth-child(2)
# .responsive-table
# .items > tbody:nth-child(2)
# #yw1
# //*[(@id = ""yw1"")]//td
# //*[@id=""yw1""]/table/tbody
# tr.odd:nth-child(3) > td:nth-child(2) > table:nth-child(1) > tbody:nth-child(1) > tr:nth-child(1) > td:nth-child(2) > div:nth-child(1) > span:nth-child(1) > a:nth-child(1)

result <- scrape(session) %>% 
  html_nodes(xpath = '//*[@id=""yw1""]/table') %>% 
  .[[1]] %>% 
  html_table(fill = TRUE, header = FALSE)

result_name <- scrape(session) %>% 
  html_nodes(""#yw1 .spielprofil_tooltip"") %>% 
  html_attr(""title"") 
```



```{r}
# first time using ""polite"" package for responsible web scraping!
session <- bow(""https://www.transfermarkt.com/liverpool-fc/leistungsdaten/verein/31/reldata/GB1%262017/plus/1"")

print(session)
# ""The path is scrapable for this user-agent"": OK, looks like we are good to go!

# scraping tranfermarkt is a nightmare...
# scrape each col individually then combine later...

# grab name from photo element instead
result_name <- scrape(session) %>% 
  html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

# grab age
result_age <- scrape(session) %>% 
  html_nodes("".posrela+ .zentriert"") %>% 
  html_text()

# grab minutes played in league
result_mins <- scrape(session) %>% 
  html_nodes(""td.rechts"") %>% 
  html_text()

```


# tidy data

```{r}
# place each vector into list

resultados <- list(result_name, result_age, result_mins)

col_name <- c(""name"", ""age"", ""minutes"")

# then reduce(cbind) to combine them, set names to cols 
resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name) -> results_comb

# NOICE.gif
glimpse(results_comb)

age_plus_one <- c(""Lovren"", ""Van Dijk"", ""Moreno"", ""Ings"")

# fix ""strings"" into proper formats, calculate % of minutes appeared
lfc_minutes <- results_comb %>% 
  
  mutate(age = as.numeric(age),
         minutes = minutes %>% 
           str_replace(""\\."", """") %>% 
           str_replace(""'"", """") %>% 
           as.numeric(),
         min_perc = (minutes / 3420) %>% round(digits = 3)) %>% 
  
  filter(!is.na(minutes)) %>% 
  
  separate(name, into = c(""first_name"", ""last_name""), by = "" "") %>% 
  
  # manually fix some names
  mutate(
    last_name = case_when(                        
      first_name == ""Trent"" ~ ""Alexander-Arnold"",   
      first_name == ""Virgil"" ~ ""Van Dijk"",
      first_name == ""Alex"" ~ ""Oxlade-Chamberlain"",
      TRUE ~ last_name),
    age = age + 1) %>%    # do CURRENT age instead for plot 2.0
  
  mutate(
    age = case_when(
      last_name %in% age_plus_one ~ age + 1,
      TRUE ~ age)
    ) %>% 
  
  # can't be arsed to scrape them individually so manually add the new lads
  add_row(
    first_name = "" "",
    last_name = ""Alisson"",
    age = 25,
    minutes = 3330,
    min_perc = 0.974
  ) %>% 
  add_row(
    first_name = "" "",
    last_name = ""Fabinho"",
    age = 24,
    minutes = 3060,
    min_perc = 0.895
  ) %>% 
  add_row(
    first_name = ""Naby"",
    last_name = ""Keita"",
    age = 23,
    minutes = 1966,
    min_perc = 0.642
  ) %>% 
  add_row(
    first_name = ""Xherdan"",
    last_name = ""Shaqiri"",
    age = 26,
    minutes = 3049,
    min_perc = 0.892
  ) %>% 
  
  # create identifier for new vs. old player for labelling purposes
  mutate(
    new_player = case_when(
      last_name %in% c(""Alisson"", ""Fabinho"", ""Keita"", ""Shaqiri"") ~ TRUE,
      TRUE ~ FALSE)) %>% 
  
  arrange(desc(min_perc))

# rectanglular highlight for players in their prime:
rect_df <- data.frame(
  xmin = 24, xmax = 30,
  ymin = -Inf, ymax = Inf
)

# annotations data frame:
# NOTE: Origi got 9 minutes in before he was loaned out to Wolfsburg
# NOTE: Woody only got 6 minutes, he would've probably played more if not for injury...
# NOTE: Naby, Alisson, Fabinho all use minutes from their respective league games
# Encouraging to see Liverpool buying players in their prime AND regulars in their previous teams
# Arguably our entire best Starting XI are going to be in their prime coming into this season!

```


```{r}
# theme_liverpool(): based on theme_bw() with red tinges  ... work-in-progress ...

theme_liverpool <- theme(
  
  text =              element_text(family = ""Georgia""),
  axis.line =         theme_blank(),
  axis.text.x =       theme_text(size = base_size * 0.8 , lineheight = 0.9, vjust = 1),
  axis.text.y =       theme_text(size = base_size * 0.8, lineheight = 0.9, hjust = 1),
  axis.ticks =        theme_segment(colour = ""black"", size = 0.2),
  axis.title.x =      theme_text(size = base_size, vjust = 1),
  axis.title.y =      theme_text(size = base_size, angle = 90, vjust = 0.5),
  axis.ticks.length = unit(0.3, ""lines""),
  axis.ticks.margin = unit(0.5, ""lines""),
  
  legend.background = theme_rect(colour=NA), 
  legend.key =        theme_rect(colour = ""grey80""),
  legend.key.size =   unit(1.2, ""lines""),
  legend.text =       theme_text(size = base_size * 0.8),
  legend.title =      theme_text(size = base_size * 0.8, face = ""bold"", hjust = 0),
  legend.position =   ""right"",
  
  panel.background =  theme_rect(fill = ""white"", colour = NA), 
  panel.border =      theme_rect(fill = NA, colour=""grey50""), 
  panel.grid.major =  theme_line(colour = ""grey90"", size = 0.2),
  panel.grid.minor =  theme_line(colour = ""grey98"", size = 0.5),
  panel.margin =      unit(0.25, ""lines""),
  
  strip.background =  theme_rect(fill = ""grey80"", colour = ""grey50""), 
  strip.text.x =      theme_text(size = base_size * 0.8),
  strip.text.y =      theme_text(size = base_size * 0.8, angle = -90),
  
  plot.background =   theme_rect(colour = NA),
  plot.title =        theme_text(size = base_size * 1.2),
  plot.margin =       unit(c(1, 1, 0.5, 0.5), ""lines"")
  
)

```



```{r fig.height=6, fig.width=8}
lfc_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_rect(
    data = rect_df, inherit.aes = FALSE,
    aes(xmin = xmin, xmax = xmax, 
        ymin = ymin, ymax = ymax),
    alpha = 0.3,
    fill = ""firebrick1"") +
  geom_point(color = ""red"", size = 2.5) +
  geom_text_repel(
    data = lfc_minutes %>% filter(!new_player == TRUE),
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  geom_text_repel(
    data = lfc_minutes %>% filter(new_player == TRUE),
    aes(label = last_name, family = ""Roboto Condensed"", fontface = ""bold""), 
    size = 4, nudge_x = 0.5, nudge_y = 0.02,
    seed = 8) +
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""Current Age (As of Aug. 5th, 2018)"", y = ""% of Minutes Played"", 
    title = ""Liverpool FC: Age-Utility Matrix"",
    subtitle = ""Premier League 17/18 (Summer 2018 transfers in bold, departed players left in for comparison)"",
    caption = ""Data from transfermarkt.com\nInspired by @FinerMargins\nBy @R_by_Ryo"") +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    panel.grid.minor.y = element_blank()) +
  geom_label(
    aes(x = 20.5, y = 0.87, 
        hjust = 0.5, 
        label = glue(""
          Encouraging to see Liverpool buying players both in 
          their prime and regulars in their previous teams. 
          Our entire best 'Starting XI' are going to be 
          in their prime this season!
          ""), 
        family = ""Roboto Condensed""),
    size = 3.5)

```

























","2018"
"62",229,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/liverpoolfc_goals.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""August 12, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(ggsoccer)
library(gganimate)
library(ggplot2)
library(dplyr)
library(scales)
library(ggimage)
```


```{r}
empty_dat <- data.frame(x = 1, y = 1)

data_df <- data.frame(
  
  time = c(1, 2, 3, 4, 5, 6, 7, 8),
  
  x = c(62.5,  66.5,   70.5,   73.5,   75.5, 92.5, 95.5, 101),
  y = c(  70,    67,     60,     57,     43,   29, 54,   54),
  
  lab1 = ""#8"",
  x1 = c(61.5, 65.5, 69.5, 72.5, 74.4, 77.5, 84.5, 87.5),
  y1 = c(70,     67,   60,   57,   43,   40, 45, 45),
  
  lab2 = ""#3"",
  x2 = c(61.5, 70.5, 75.5, 81.5, 83.5, 90.5, 90.5, 90.5),
  y2 = c(17,     18,   19,   20,   23,   27,   27, 30),
  
  lab3 = ""#11"",
  x3 = c(67, 79, 81, 83.4, 85, 88, 94, 95),
  y3 = c(85, 79, 70, 65,   58, 54, 54, 54),
  
  lab4 = ""#10"",
  x4 = c(72, 77, 78, 80, 83.5, 85, 87, 87),
  y4 = c(38, 43, 45, 47, 47, 47, 47,   47)
  
)

ggplot(data_df, aes(x = x, y = y)) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(60, 105),
             ylim = c(-1, 101)) +
  geom_label(aes(x = x1, y = y1, label = lab1)) +
  geom_label(aes(x = x2, y = y2, label = lab2)) +
  geom_label(aes(x = x3, y = y3, label = lab3)) +
  geom_label(aes(x = x4, y = y4, label = lab4)) +
  ggimage::geom_emoji(
    aes(x = x, y = y),
    image = ""26bd"", size = 0.035) + 
  transition_states(states = time, 
                    transition_length = 0.25, state_length = 0.001, 
                    wrap = FALSE) +
  ease_aes(""linear"")
  
```



```{r}  
ggplot(data_df, aes(x = x, y = y)) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(60, 105),
             ylim = c(-1, 101)) +
  geom_point(aes(x = 72, y = 38)) +
  geom_point(aes(x = 77, y = 43)) +
  geom_point(aes(x = 78, y = 45)) +
  geom_point(aes(x = 80, y = 48)) +
  geom_point(aes(x = 85.5, y = 48)) +
  geom_point(aes(x = 87, y = 48)) +
  # robbo
  geom_point(aes(x = 61.5, y = 17), color = ""red"") +
  geom_point(aes(x = 68.5, y = 18), color = ""red"") +
  geom_point(aes(x = 74.5, y = 19), color = ""red"") +
  geom_point(aes(x = 81.5, y = 20), color = ""red"") +
  geom_point(aes(x = 90.5, y = 27), color = ""red"") +
  geom_point() +
  geom_point() +
  geom_point()


```






```{r}

ball_data <- data.frame(
  
  # SHOW Trent's beautiful through-pass?
  
  # 1: forward run (slight diagonal left)   center toward penalty box arc
  
  # 2: touch out wide left
  
  # 3: drift left 
  
  # 4. >>> PASS       (how to code in the slight pause?)
  
  # 5: Robbo first time cross in
  
  # 6: Mo tap-in
  
)


lfc_players <- data.frame(
  
  # Trent
  lx1,
  ly1,
  
  # Naby
  lx2,
  ly2,
  
  # Robbo
  lx3,
  ly3,
  
  # Mo
  lx4,
  ly4,
  
  # Sadio
  lx5,
  ly5,
  
  # Hamez
  lx6,
  ly6,
  
  # Bobby
  lx7,
  ly7,
  
  

)

whfc_players <- data.frame(
  
  # Rice
  wx1,
  wy1,
  # Noble
  wx2,
  wy2,
  
  # Fredericks
  wx3,
  wy3,
  
  # Ogbonna
  wx4,
  wy4,
  
  # Balbuena
  wx5,
  wy5,
  
  # Masuaku
  wx6,
  wy6,
  
  # Fabianski
  wx7,
  wy7
)


```







```{r}
ggplot(empty_dat, aes(x = x, y = y)) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(
    xlim = c(40, 112),
    ylim = c(-1, 101)) 


ggplot(empty_dat, aes(x = x, y = y)) +
  annotate_pitch() +
  theme_pitch() +
  coord_cartesian(
    xlim = c(50, 105),
    ylim = c(-1, 101)) 

```





","2018"
"63",230,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/north_west_derby.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""December 16, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r message=FALSE}
pacman::p_load(tidyverse, rvest, scales, extrafont, glue, lubridate)

loadfonts()
```






```{r}
# #mw-content-text > div > div:nth-child(74) > table
# #mw-content-text > div > div:nth-child(75) > table
# #mw-content-text > div > div:nth-child(89) > table

# .vevent:nth-child(89) td , .vevent:nth-child(88) td , .vevent:nth-child(87) td , .vevent:nth-child(86) td , .vevent:nth-child(85) td , .vevent:nth-child(84) td , .vevent:nth-child(83) td , .vevent:nth-child(82) td , .vevent:nth-child(81) td , .vevent:nth-child(80) td , .vevent:nth-child(79) td , .vevent:nth-child(78) td , .vevent:nth-child(77) td , .vevent:nth-child(76) td , .vevent:nth-child(75) td , .vevent:nth-child(74) td


library(rvest)

url <- ""https://en.wikipedia.org/wiki/201819_Liverpool_F.C._season""

liv_raw <- url %>% 
  read_html() %>% 
  html_nodes() %>% 
  html_text() %>% 
  flatten_df()

```



```{r}
# For
# 0-30     12345678
# 31-60    123456789-
# 61-90    123456789-123456

# Against
# 0-30     1
# 31-60    1
# 61-90    1234

# mu
# For
# 0-30     1234567
# 31-60    123456789
# 61-90    123456789-

# Against
# 0-30     123456789-1
# 31-60    123456
# 61-90    123456789

lfc_mufc_goals <- data.frame(
  goals_for =     c(8, 10, 16, 7, 9, 10),
  goals_against = c(1, 1,   4, 11, 6, 9),
  GD =            c(7, 9,  12, -4, 3, 1),
  time_frame = c(""0-30th Minute"", ""31-60th Minute"", ""61-90th Minute""),
  team = c(""LFC"", ""LFC"", ""LFC"", ""MUFC"", ""MUFC"", ""MUFC"")
)
```



```{r}
lfc_mufc_goals %>% 
  filter(team == ""LFC"") %>% 
  ggplot(aes(time_frame)) +
  geom_linerange(aes(ymin = goals_against, ymax = goals_for), color = ""grey"", size = 2) +
  geom_point(aes(y = goals_for), shape = 21, 
             color = ""black"", fill = ""red"", size = 3.5) +
  geom_point(aes(y = goals_against), shape = 21, 
             color = ""black"", fill = ""black"", size = 3.5) +
  scale_y_continuous(breaks = scales::pretty_breaks(), limits = c(0, 18),
                     name = ""Goals"") +
  annotate(geom = ""label"", x = 1.05, y = 8, hjust = 0, label = ""Goals For"") +
  annotate(geom = ""label"", x = 1.05, y = 2, hjust = 0, label = ""Goals Against"") +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        #plot.background = element_rect(color = ""red""),
        #panel.background = element_rect(fill = ""red""),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        text = element_text(family = ""Roboto Condensed""))
```

# facet

```{r}
lfc_mufc_goals %>% 
  mutate(goals_against = goals_against * -1) %>% 
  ggplot(aes(y = time_frame)) +
  geom_segment(aes(x = 0, xend = goals_for, yend = time_frame)) +
  geom_point(aes(x = goals_for), shape = 21, 
             color = ""black"", fill = ""red"", size = 3.5) +
  geom_segment(aes(x = 0, xend = goals_against, yend = time_frame)) +
  geom_point(aes(x = goals_against), shape = 21, 
             color = ""black"", fill = ""black"", size = 3.5) +
  scale_x_continuous(breaks = scales::pretty_breaks(), limits = c(-5, 20),
                     name = ""Goals"") +
  geom_vline(xintercept = 0) +
  scale_y_discrete(limits = rev(levels(lfc_mufc_goals$time_frame))) +
  annotate(geom = ""label"", x = 6.5, y = 3.4, hjust = 0, label = ""Goals For"") +
  annotate(geom = ""label"", x = -5, y = 3.4, hjust = 0, label = ""Goals Against"") +
  labs(x = ""Goals"", y = """",
       title = ""When In A Match Have Liverpool Scored/Conceded?"",
       subtitle = ""Lots of excitement (on both ends of the pitch) late in the game!"",
       caption = glue(""
                      by @R_By_Ryo
                      Source: Wikipedia"")) +
  theme_minimal() +
  theme(panel.grid.minor.y = element_blank(),
        axis.text = element_text(size = 12),
        title = element_text(size = 15),
        text = element_text(family = ""Roboto Condensed"")) +
  facet_wrap(~ team, scales = ""free"")
```



# double-sided lolipop

```{r}
lfc_mufc_goals %>% 
  filter(team == ""LFC"") %>% 
  mutate(goals_against = goals_against * -1) %>% 
  ggplot(aes(y = time_frame)) +
  geom_segment(aes(x = 0, xend = goals_for, yend = time_frame)) +
  geom_point(aes(x = goals_for), shape = 21, 
             color = ""black"", fill = ""red"", size = 3.5) +
  geom_segment(aes(x = 0, xend = goals_against, yend = time_frame)) +
  geom_point(aes(x = goals_against), shape = 21, 
             color = ""black"", fill = ""black"", size = 3.5) +
  scale_x_continuous(breaks = scales::pretty_breaks(), limits = c(-5, 20),
                     name = ""Goals"") +
  geom_vline(xintercept = 0) +
  scale_y_discrete(limits = rev(levels(lfc_mufc_goals$time_frame))) +
  annotate(geom = ""label"", x = 6.5, y = 3.4, hjust = 0, label = ""Goals For"") +
  annotate(geom = ""label"", x = -5, y = 3.4, hjust = 0, label = ""Goals Against"") +
  labs(x = ""Goals"", y = """",
       title = ""When In A Match Have Liverpool Scored/Conceded?"",
       subtitle = ""Lots of excitement (on both ends of the pitch) late in the game!"",
       caption = glue(""
                      by @R_By_Ryo
                      Source: Wikipedia"")) +
  theme_minimal() +
  theme(panel.grid.minor.y = element_blank(),
        axis.text = element_text(size = 12),
        title = element_text(size = 15),
        text = element_text(family = ""Roboto Condensed""))
```



```{r fig.width=10, fig.height=5}
lfc_mufc_goals %>% 
  filter(team == ""MUFC"") %>% 
  mutate(goals_against = goals_against * -1) %>% 
  ggplot(aes(y = time_frame)) +
  geom_segment(aes(x = 0, xend = goals_for, yend = time_frame)) +
  geom_point(aes(x = goals_for), shape = 21, 
             color = ""black"", fill = ""red"", size = 3.5) +
  geom_segment(aes(x = 0, xend = goals_against, yend = time_frame)) +
  geom_point(aes(x = goals_against), shape = 21, 
             color = ""black"", fill = ""black"", size = 3.5) +
  scale_x_continuous(breaks = scales::pretty_breaks(), limits = c(-12, 12),
                     name = ""Goals"") +
  geom_vline(xintercept = 0) +
  scale_y_discrete(limits = rev(levels(lfc_mufc_goals$time_frame))) +
  annotate(geom = ""label"", x = 6, y = 3.4, hjust = 0, label = ""Goals For"") +
  annotate(geom = ""label"", x = -10, y = 3.4, hjust = 0, label = ""Goals Against"") +
  labs(x = ""Goals"", y = """",
       title = ""When In A Match Have Manchester United Scored/Conceded?"",
       caption = glue(""
                      by @R_By_Ryo
                      Source: Wikipedia"")) +
  theme_minimal() +
  theme(panel.grid.minor.y = element_blank(),
        axis.text = element_text(size = 12),
        title = element_text(size = 15),
        text = element_text(family = ""Roboto Condensed""))
```


## Waffle chart

```{r}
library(waffle)
library(extrafont)
loadfonts(device = ""win"")

NW_Derby <- c(`Liverpool FC (55)` = 55, 
              `Draw (46)` = 46, 
              `Manchester United (68)` = 68)
# ""soccer-ball-o""

options(device = ""pdf"")

waf <- waffle(
  NW_Derby, rows = 6, size = 1, 
  title = ""North West Derby (1895-2018)"",
  colors = c(""red"", ""grey"", ""black""), 
  use_glyph = ""futbol"", glyph_size = 5,
  legend_pos = ""bottom""
)

ggsave(""NW_derby_waffle"", device = ""pdf"")

waffle(
  NW_Derby, rows = 6, size = 1, 
  title = ""North West Derby (1895-2018)"",
  colors = c(""red"", ""grey"", ""black""), 
  use_glyph = ""flag"", glyph_size = 5,
  legend_pos = ""bottom""
)

ggsave(plot = waf, ""NW_derby_waffle"", device = ""pdf"")
```


```{r}
tibble(
  team = c(""Liverpool FC"", ""Draw"", ""Man. Utd""),
  values = c(55, 46, 68)
) -> liv_man

ggplot(liv_man, aes(fill = team, values = values)) +
  geom_waffle(color = ""white"", size=1.125, n_rows = 6) +
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  ggthemes::scale_fill_tableau(name=NULL) +
  coord_equal() +
  hrbrthemes::theme_ipsum_rc(grid="""") +
  theme_enhance_waffle() +
  labs(title = ""The North West Derby"")


tibble(
  parts = factor(rep(month.abb[1:3], 3), levels=month.abb[1:3]),
  values = c(10, 20, 30, 6, 14, 40, 30, 20, 10),
  fct = c(rep(""Thing 1"", 3), rep(""Thing 2"", 3), rep(""Thing 3"", 3))
) -> xdf

ggplot(xdf, aes(fill=parts, values=values)) +
  geom_waffle(color = ""white"", size = 1.125, n_rows = 6) +
  facet_wrap(~fct, ncol=1) +
  scale_x_discrete(expand=c(0,0)) +
  scale_y_discrete(expand=c(0,0)) +
  ggthemes::scale_fill_tableau(name=NULL) +
  coord_equal() +
  labs(
    title = ""Faceted Waffle Geoms""
  ) +
  hrbrthemes::theme_ipsum_rc(grid="""") +
  theme_enhance_waffle()
```



## Klopp vs. Mourinho

```{r}
# LFC: table.wikitable:nth-child(3)
# MUFC: table.wikitable:nth-child(6)
# W D L from LIVERPOOL's perspective

url <- ""https://en.wikipedia.org/wiki/Liverpool_F.C.Manchester_United_F.C._rivalry""

liv_results_raw <- url %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(3)"") %>% 
  html_table() %>% 
  flatten_df()

liv_results_clean <- liv_results_raw %>% 
  separate(Score, into = c(""LFC"", ""MUFC""), sep = """") %>% # copy-paste the double-dash...
  mutate(result = case_when(
    LFC > MUFC ~ ""win"",
    LFC < MUFC ~ ""loss"",
    LFC == MUFC ~ ""draw""
  ))

mu_results_raw <- url %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(6)"") %>% 
  html_table() %>% 
  flatten_df()

mu_results_clean <- mu_results_raw %>% 
  separate(Score, into = c(""MUFC"", ""LFC""), sep = """") %>% # copy-paste the double-dash...
  mutate(result = case_when(
    LFC > MUFC ~ ""win"",
    LFC < MUFC ~ ""loss"",
    LFC == MUFC ~ ""draw""
  ))

liv_mu_results_df <- liv_results_clean %>% 
  bind_rows(mu_results_clean) %>% 
  mutate(Date = dmy(Date),
         result = as_factor(result),
         result = fct_relevel(result, c(""win"", ""draw"", ""loss""))) %>% 
  arrange(Date)


# PLOT

liv_mu_results_df %>% 
  mutate(result = fct_rev(result)) %>% 
  ggplot(aes(x = Date, y = result, group = 1)) +
  geom_rect(aes(xmin = as.Date(""1895-10-12""), xmax = as.Date(""2018-12-16"")), 
            ymin = 2.5, ymax = Inf,
            fill = ""red"") +
  scale_fill_manual(values = alpha(""red"", 0.2)) +
  geom_path() +
  geom_point() +
  theme_minimal()

# OR vertical color bars for W/D/L ??

liv_mu_results_df %>% 
  filter(Date >= as.Date(""2016-01-07"")) %>% 
  mutate(result = fct_rev(result)) %>% 
  ggplot(aes(x = Date, y = result, group = 1)) +
  geom_rect(aes(xmin = result, xmax = result), 
            ymin = -Inf, ymax = Inf,
            fill = ""red"") +
  scale_fill_manual(values = alpha(""red"", 0.2)) +
  geom_path() +
  geom_point() +
  theme_minimal()
```

","2018"
"64",231,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2018-2019/player_goal_contribution_matrix.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""5/17/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# pkgs

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

## add_logo

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))
}
```

# Premier League

## webscrape tranksfermartk

```{r}
url <- ""https://www.transfermarkt.com/premier-league/startseite/wettbewerb/GB1/plus/?saison_d=2018""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#yw1 > table > tbody > tr > td.zentriert.no-border-rechts > a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, ""team_name"", NA, NA, ""team_num"", NA, NA), sep = ""/"") %>% 
  mutate(link = glue(""https://www.transfermarkt.com/{team_name}/leistungsdaten/verein/{team_num}/reldata/GB1%262018/plus/1""))

# for each team link:

player_name_info <- function(link) {
  
  session <- bow(link)
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 
  
}

num_goals_info <- function(link) {
  
  session <- bow(link)
  
  num_goals_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(7)"") %>% 
    html_text()
}

num_assists_info <- function(link) {
  
  session <- bow(link)
  
  num_assists_info <- scrape(session) %>% 
    html_nodes(""td:nth-child(8)"") %>% 
    html_text()
}

# BIG FUNCTION
premier_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  laliga_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names)
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
goal_contribution_df_ALL <- map2(.x = team_links_df$link, 
                             .y = team_links_df$team_name,
                             ~ premier_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df <- goal_contribution_df_ALL %>% 
  reduce(rbind)

## save
saveRDS(goal_contribution_df, file = glue(""{here::here()}/data/epl_goal_contrib_df.RDS""))
```

### piece-wise

```{r}
# break scraping into groups of 4-5 teams, then combine:
goal_contribution_df1 <- map2(.x = team_links_df$link[1:3], 
                             .y = team_links_df$team_name[1:3],
                             ~ premier_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df2 <- map2(.x = team_links_df$link[4:8], 
                             .y = team_links_df$team_name[4:8],
                             ~ premier_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df3 <- map2(.x = team_links_df$link[9:13], 
                             .y = team_links_df$team_name[9:13],
                             ~ premier_stats_info(link = .x) %>% mutate(team = .y))

goal_contribution_df4 <- map2(.x = team_links_df$link[14:18], 
                             .y = team_links_df$team_name[14:18],
                             ~ premier_stats_info(link = .x) %>% mutate(team = .y))

a1 <- goal_contribution_df1 %>% reduce(rbind)
a2 <- goal_contribution_df2 %>% reduce(rbind)
a3 <- goal_contribution_df3 %>% reduce(rbind)
a4 <- goal_contribution_df4 %>% reduce(rbind)


resultados_grande <- list(a1, a2, a3, a4)

goal_contribution_df <- resultados_grande %>% 
  reduce(rbind)

## save
saveRDS(goal_contribution_df, file = glue(""{here::here()}/data/epl_goal_contrib_df.RDS""))
goal_contribution_df <- readRDS(file = glue(""{here::here()}/data/epl_goal_contrib_df.RDS""))
```

## webscrape soccerway

```{r}
url <- ""https://us.soccerway.com/national/england/premier-league/20182019/regular-season/r48730/""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#page_competition_1_block_competition_tables_7_block_competition_league_table_1_table .large-link a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, NA, NA, ""team_name"", ""team_num""), sep = ""/"") %>% 
  mutate(link = glue(""
                     https://us.soccerway.com/teams/spain/{team_name}/{team_num}/squad/""),
         stat_link = glue(""{link %>% str_replace('squad', 'statistics')}""))

# for each team link:

player_name_info <- function(session) {
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#page_team_1_block_team_squad_3-table .name.large-link"") %>% 
    html_text()
}

num_goals_info <- function(session) {

  num_goals_info <- scrape(session) %>% 
    html_nodes("".goals"") %>% 
    html_text()
  
  num_goals_info_clean <- num_goals_info[-1]
}

num_assists_info <- function(session) {

  num_assists_info <- scrape(session) %>% 
    html_nodes("".assists"") %>% 
    html_text()
  
  num_assists_info_clean <- num_assists_info[-1]
}

team_goals_info <- function(session) {
  team_goals_info <- scrape(session) %>% 
    html_nodes(""tr.first:nth-child(6) > td:nth-child(2)"") %>% 
    html_text()
}

# BIG FUNCTION
epl_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  epl_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names)
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
epl_goal_contribution_df_ALL <- map2(.x = team_links_df$link,
                .y = team_links_df$stat_link,
                ~ epl_stats_info(link = .x, statlink = .y))

epl_goal_contribution_df <- epl_goal_contribution_df_ALL %>% 
  set_names(team_links_df$team_name) %>% 
  bind_rows(.id = ""team_name"")


# goal_contribution_df_ALL <- map2(.x = team_links_df$link, 
#                              .y = team_links_df$team_name,
#                              ~ premier_stats_info(link = .x) %>% mutate(team = .y))
# 
# goal_contribution_df <- goal_contribution_df_ALL %>% 
#   reduce(rbind)

## save
saveRDS(epl_goal_contribution_df, file = glue(""{here::here()}/data/epl_goal_contrib_df_soccerway.RDS""))
goal_contribution_df <- readRDS(file = glue(""{here::here()}/data/epl_goal_contrib_df_soccerway.RDS""))
```

### piece-wise

```{r}
# break scraping into groups of 4-5 teams, then combine:
# goal_contribution_df1 <- map2(.x = team_links_df$link[1:3], 
#                              .y = team_links_df$team_name[1:3],
#                              ~ premier_stats_info(link = .x) %>% mutate(team = .y))
# 
# goal_contribution_df2 <- map2(.x = team_links_df$link[4:8], 
#                              .y = team_links_df$team_name[4:8],
#                              ~ premier_stats_info(link = .x) %>% mutate(team = .y))
# 
# goal_contribution_df3 <- map2(.x = team_links_df$link[9:13], 
#                              .y = team_links_df$team_name[9:13],
#                              ~ premier_stats_info(link = .x) %>% mutate(team = .y))
# 
# goal_contribution_df4 <- map2(.x = team_links_df$link[14:18], 
#                              .y = team_links_df$team_name[14:18],
#                              ~ premier_stats_info(link = .x) %>% mutate(team = .y))
# 
# a1 <- goal_contribution_df1 %>% reduce(rbind)
# a2 <- goal_contribution_df2 %>% reduce(rbind)
# a3 <- goal_contribution_df3 %>% reduce(rbind)
# a4 <- goal_contribution_df4 %>% reduce(rbind)
# 
# 
# resultados_grande <- list(a1, a2, a3, a4)
# 
# goal_contribution_df <- resultados_grande %>% 
#   reduce(rbind)
# 
# ## save
# saveRDS(goal_contribution_df, file = glue(""{here::here()}/data/epl_goal_contrib_df_soccerway.RDS""))
# goal_contribution_df <- readRDS(file = glue(""{here::here()}/data/epl_goal_contrib_df_soccerway.RDS""))
```

## clean

```{r}
goal_contribution_clean_df <- goal_contribution_df %>% 
  mutate_at(.vars = c(""goals"", ""assists""), 
            ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(team = team_name %>% str_replace_all(., ""-"", "" "") %>% str_to_title,
         total_goals = as.numeric(team_goals)) %>% 
  group_by(team) %>% 
  mutate(total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         ## as/tot_goals because looking at perspective of contrib to goals.
         ## Will be an underestimation as not all goals have assists.
         ## a.k.a. not looking at % of club assists assisted but % of club goals assisted
         assist_contrib = assists/total_goals) %>% 
  ungroup() %>% 
  select(-team_name, -team_goals)

## save
saveRDS(goal_contribution_clean_df, 
        file = glue(""{here::here()}/data/epl_goal_contrib_clean_df.RDS""))
goal_contribution_clean_df <- readRDS(file = glue(""{here::here()}/data/epl_goal_contrib_clean_df.RDS""))
```

## plot

- original: goal = 0.25, assist = 0.15
- 2: goal = 0.225, assist = 0.125
- 3: goal = 0.2, assist = 0.1

```{r fig.width = 10, fig.height = 8}  
## Description text
desc_hazard <- ""Hazard FC: With 16 goals and 15 assists Eden Hazard has been involved in the most goals for a team this season.""
desc_vardymurray <- ""Scoring 37.5% and 37.1% of their team's goals, Jamie Vardy and Glen Murray have proven to be talismans for their team yet again!""
desc_fraser <- ""Another fantastic season from Ryan Fraser with 7 goals and 14 assists (one behind league-leader Hazard)""

## PLOT!
goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.2 | assist_contrib < 0.1),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.2 | assist_contrib > 0.1),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.2, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.1, color = ""grey20"", alpha = 0.4) +
  geom_text_repel(data = goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.2 | assist_contrib > 0.1, 
                           !name %in% c(""E. Hazard"", ""R. Fraser"", ""J. Vardy"", ""G. Murray"")),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 15, size = 4, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  geom_mark_circle(aes(filter = name == ""E. Hazard"", label = ""Eden Hazard"",
                        description = desc_hazard), 
                    label.family = ""Roboto Condensed"", label.fontsize = c(14, 12)) +
  geom_mark_hull(aes(filter = name %in% c(""G. Murray"", ""J. Vardy""), label = ""Vardy & Murray"",
                        description = desc_vardymurray),
                    label.buffer = unit(10, ""mm""), label.fontsize = c(14, 11),
                    label.family = ""Roboto Condensed"") +
  geom_mark_hull(aes(filter = name == ""R. Fraser"", label = ""Ryan Fraser"",
                        description = desc_fraser), concavity = 1,
                    label.buffer = unit(0.5, ""mm""), label.fontsize = c(14, 12),
                    label.family = ""Roboto Condensed"") +
  scale_x_continuous(labels = percent_format(accuracy = 1), 
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.3)) +
  scale_y_continuous(labels = percent_format(accuracy = 1), 
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.5)) +
  labs(title = ""Goal Contribution Matrix: Premier League (2018-2019 Season)"", 
       subtitle = ""Goal Involvement (Goals and/or Assists) as Percentage of Total Club Goals"",
       caption = glue(""
                      Data: soccerway.com
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 18),
        plot.subtitle = element_text(size = 16),
        plot.caption = element_text(size = 10),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        panel.grid.minor.x = element_blank()) -> goal_contribution_matrix

goal_contribution_matrix
```

## save

```{r}
ggsave(plot = goal_contribution_matrix, 
       ""../Premier League 2018-2019/output/goal_contribution_matrix_plot_epl4.png"",
       height = 9, width = 11)
```

```{r}
plot_logo4 <- add_logo(
  plot_path = ""../Premier League 2018-2019/output/goal_contribution_matrix_plot_epl4.png"",
  logo_path = ""https://upload.wikimedia.org/wikipedia/en/f/f2/Premier_League_Logo.svg"",
  logo_position = ""top right"",
  logo_scale = 8)

plot_logo2
```

```{r}
image_write(image = plot_logo4, 
            ""../Premier League 2018-2019/output/goal_contribution_matrix_plot_logo4.png"")
```

","2018"
"65",232,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2019-2020/epl_scoring_stats.Rmd","---
title: ""Untitled""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               understatr,
               jsonlite, xml2, qdapRegex, stringi, stringr,
               rvest, glue, extrafont, ggrepel, magick, ggtext)
loadfonts(quiet = TRUE)
```


# understat aux functions

```{r}
get_script <- function(x) {
  as.character(html_nodes(x, ""script""))
}

# subset data element of html page
get_data_element <- function(x, element_name) {
  stri_unescape_unicode(str_subset(x, element_name))
}

# fix json element for parsing
fix_json <- function(x) {
  str_subset(
    unlist(
      rm_square(
        x, extract = TRUE, include.markers = TRUE
      )
    ),
    ""\\[\\]"", negate = TRUE
  )
}

# get player name part of html page
get_player_name <- function(x) {

  player_name <- html_nodes(x, "".header-wrapper:first-child"")
  trimws(html_text(player_name))
}
```


# Data

## base data

```{r}
EPL2019 <- get_league_teams_stats(""EPL"", ""2019"")

glimpse(EPL2019)

EPL2019_teams <- EPL2019 %>% 
  select(team_name) %>% unique() %>% pull() %>% 
  str_replace_all("" "", ""_"")

glimpse(EPL2019_teams)
```


```{r}
get_team_shots_data <- function(team_name) {
  
  url <- glue::glue(""https://understat.com/team/{team_name}/2019"")
  
  team_page <- polite::bow(url)
  
  team_data <- polite::scrape(team_page) %>% 
    get_script()
  
  team_situation_data <- get_data_element(team_data, ""statisticsData"") %>% 
    str_replace(., ""\\{\""situation\"""",  ""[\\{\""situation\"""") %>% 
    str_replace(., ""\\}'\\)"", ""\\}]'\\)"") %>% 
    fix_json() %>% 
    fromJSON()
  
  ## stats by theme
  
  situation_df <- team_situation_data %>% 
    .[[1]] %>% 
    unlist() %>% 
    enframe()
  
  formation_df <- team_situation_data %>% 
    .[[2]] %>% 
    unlist() %>% 
    enframe()
  
  gamestate_df <- team_situation_data %>% 
    .[[3]] %>% 
    unlist() %>% 
    enframe()
  
  minutes_df <- team_situation_data %>% 
    .[[4]] %>% 
    unlist() %>% 
    enframe()
  
  zone_df <- team_situation_data %>% 
    .[[5]] %>% 
    unlist() %>% 
    enframe()
  
  speed_df <- team_situation_data %>% 
    .[[6]] %>% 
    unlist() %>% 
    enframe()
  
  shot_df <- team_situation_data %>% 
    .[[7]] %>% 
    unlist() %>% 
    enframe() 
  
  data_df <- list(situation_df, formation_df, gamestate_df, 
                  minutes_df, zone_df, speed_df, shot_df)
  
  print(paste(team_name, "" done!""))
  
  return(data_df)
}
```

# EPL all teams

```{r}
EPL_shots_data_df_raw <- map(EPL2019_teams, 
                             ~get_team_shots_data(team_name = .x)) %>% 
  set_names(EPL2019_teams)
```

```{r}
saveRDS(EPL_shots_data_df_raw, 
        file = here::here(""data/EPL_shots_data_df_raw.RDS""))
```

```{r}
EPL_shots_data_df_raw <- readRDS(
  file = here::here(""data/EPL_shots_data_df_raw.RDS""))
```




## game state


```{r}
EPL_gamestate_data_df <- EPL_shots_data_df_raw %>% 
  ## pick out 3rd data frame which is game states
  map(3) %>% 
  bind_rows(.id = ""team_name"") %>% 
  mutate(name = str_replace(name, ""Goal diff "", """"),
         name = str_replace(name, ""against."", ""against_"")) %>% 
  separate(name, c(""game_state"", ""metric""), 
           sep = ""\\."", extra = ""merge"") %>% 
  filter(metric != ""stat"") %>% 
  mutate(state = case_when(
    game_state == ""0"" ~ ""Drawing"",
    game_state %in% c(""> +1"", ""+1"") ~ ""Winning"",
    game_state %in% c(""-1"", ""< -1"") ~ ""Losing"",
    TRUE ~ NA_character_
  )) %>% 
  filter(metric == ""time"") %>% 
  select(-game_state, -metric) %>% 
  mutate(value = as.numeric(value)) %>% 
  group_by(state, team_name) %>% 
  summarize(value = sum(value)) %>% 
  ungroup() %>% 
  group_by(team_name) %>% 
  mutate(total = sum(value)) %>% 
  ungroup() %>% 
  group_by(state, team_name) %>% 
  mutate(percentage = value / total) %>% 
  ungroup() %>% 
  arrange(team_name) %>% 
  mutate(team_name = str_replace(team_name, ""_"", "" ""),
         team_name = as_factor(team_name),
         state = as_factor(state),
         state = fct_relevel(state, ""Losing"", ""Drawing"", ""Winning""),
         percentage = percentage * 100)

glimpse(EPL_gamestate_data_df)
```

```{r}
result_vals <- c(""Winning"" = ""darkgreen"", ""Drawing"" = ""grey"", ""Losing"" = ""red"")

EPL_gamestate_df_clean <- EPL_gamestate_data_df %>% 
  pivot_wider(names_from = ""state"", values_from = ""percentage"") %>% 
  mutate(Winning = if_else(is.na(Winning), 0, Winning),
         Drawing = if_else(is.na(Drawing), 0, Drawing),
         Losing = if_else(is.na(Losing), 0, Losing)) %>% 
  group_by(team_name) %>% 
  summarize_all(sum) %>% 
  ungroup() %>% 
  mutate(equals = Winning + Drawing + Losing) %>% 
  select(-equals, -value, -total) %>% 
  mutate(win_half = Winning / 2,
         draw_half =(  (Winning + Drawing) - Winning  )  / 2 + (Winning),
         lose_half = ( (Winning + Drawing + Losing) - (Winning + Drawing) )  / 2 + (Winning + Drawing)) %>% 
  mutate(team_name = fct_relevel(team_name, team_winning_order),
         team_name = fct_rev(team_name)) %>% 
  # mutate(Winning = round(Winning, digits = 1),
  #        Drawing = round(Drawing, digits = 1),
  #        Losing = round(Losing, digits = 1)) %>% 
  mutate(equals = Winning + Drawing + Losing) 

ars <- c(43.95393, 22.45681, 	33.58925)
sum(ars)

largeRem2(ars)
pcVec <- ars
```


```{r}
ggplot(EPL_gamestate_df_clean,
       aes(x = team_name, xend = team_name)) + 
  geom_segment(aes(y = 0, yend = Winning, 
                   color = ""Winning""), 
               size = 4) +
  geom_segment(aes(y = Winning, yend = Winning + Drawing, 
                   color = ""Drawing""), 
               size = 4) +
  geom_segment(aes(y = Winning + Drawing, yend = Winning + Drawing + Losing, 
                   color = ""Losing""), 
               size = 4) +
  geom_text(aes(y = win_half, label = Winning)) +
  scale_color_manual(values = result_vals, name = ""Game State"",
                    breaks = c(""Winning"", ""Drawing"", ""Losing""),
                    labels = c(""Winning"", ""Drawing"", ""Losing"")) +
  scale_y_continuous(expand = c(0, 0)) +
  labs(title = ""Percentage of Time Spent:"") +
  coord_flip() +
  theme_minimal() +
  theme(text = element_text(family = ""Titillium Web""),
        axis.title = element_blank(),
        axis.text.x = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        axis.ticks.y = element_line(color = ""black""),
        axis.ticks.length.y = unit(0.25, ""cm""),
        legend.position = ""top"")
```






```{r}
EPL_gamestate_data_df %>% 
  pivot_wider(names_from = ""state"", values_from = ""percentage"") %>% 
  mutate(team_name = fct_reorder(team_name, Winning)) %>% 
  filter(!is.na(Winning)) %>% 
  select(-Drawing, -Losing) %>% 
  arrange(desc(Winning)) %>% 
  select(team_name) %>% pull() %>% as.character() -> team_winning_order

```


```{r}
result_vals <- c(""Winning"" = ""darkgreen"", ""Drawing"" = ""grey"", ""Losing"" = ""red"")


EPL_gamestate_data_df %>% 
  mutate(team_name = fct_relevel(team_name, team_winning_order),
         team_name = fct_rev(team_name)) %>% 
  ggplot(aes(x = team_name, y = percentage, 
             fill = state)) + 
  geom_col() +
  scale_fill_manual(values = result_vals, 
                    breaks = c(""Winning"", ""Drawing"", ""Losing""),
                    labels = c(""Winning"", ""Drawing"", ""Losing"")) +
  coord_flip() +
  theme_minimal()
```






## by minutes (4)

```{r}
EPL_minutes_df <- EPL_shots_data_df_raw %>% 
  ## pick out 4th data frame which is minutes
  map(4) %>% 
  bind_rows(.id = ""team_name"")

EPL_minutes_df_clean <- EPL_minutes_df %>% 
  mutate(name = str_replace(name, ""against."", ""against_""),
         team_name = str_replace(team_name, ""_"", "" ""),
         team_name = as_factor(team_name)) %>% 
  separate(name, c(""timing"", ""metric""), 
           sep = ""\\."", extra = ""merge"") %>% 
  #select(-timing) %>% 
  filter(metric != ""stat"") %>% 
  pivot_wider(names_from = ""metric"", values_from = ""value"") %>% 
  mutate_at(vars(-team_name, -timing), as.numeric) %>% 
  mutate(xGperShot = xG / shots,
         xGAperShot = against_xG / against_shots)

glimpse(EPL_minutes_df_clean)
```

### shots per game

```{r}
EPL_minutes_df_clean %>% 
  mutate(shots = shots / 11,
         against_shots = against_shots / 11) %>% 
  ggplot(aes(x = timing)) +
  geom_point(aes(y = shots), color = ""darkgreen"") +
  geom_line(aes(y = shots, group = 1), color = ""darkgreen"") +
  geom_point(aes(y = against_shots), color = ""red"") +
  geom_line(aes(y = against_shots, group = 1), color = ""red"") +
  labs(x = ""Minutes"", y = ""Shots per Game"") +
  theme_minimal() +
  facet_wrap(~ team_name)
```


### xG per shot

```{r}
EPL_minutes_df_clean %>% 
  ggplot(aes(x = timing)) +
  geom_point(aes(y = xGperShot), color = ""darkgreen"") +
  geom_line(aes(y = xGperShot, group = 1), color = ""darkgreen"") +
  geom_point(aes(y = xGAperShot), color = ""red"") +
  geom_line(aes(y = xGAperShot, group = 1), color = ""red"") +
  labs(x = ""Minutes"", y = ""Expected Goals (per shot)"") +
  theme_minimal() +
  facet_wrap(~team_name)
```





```{r}
EPL_minutes_df_clean %>% 
  mutate(goalsperGame = goals / 11,
         against_goalsperGame = against_goals / 11) %>% 
  ggplot(aes(x = timing)) +
  # actual
  geom_point(aes(y = goalsperGame), color = ""darkgreen"") +
  geom_line(aes(y = goalsperGame, group = 1), color = ""darkgreen"") +
  geom_point(aes(y = against_goalsperGame), color = ""darkred"") +
  geom_line(aes(y = against_goalsperGame, group = 1), color = ""darkred"") +
  ## xG
  geom_point(aes(y = xGperShot), color = ""green"") +
  geom_line(aes(y = xGperShot, group = 1), color = ""green"") +
  geom_point(aes(y = xGAperShot), color = ""red"") +
  geom_line(aes(y = xGAperShot, group = 1), color = ""red"") +
  labs(x = ""Minutes"", y = ""Goals per Game | xG per Shot"") +
  theme_minimal() +
  facet_wrap(~team_name)
```

waaayyy tooo messsyyyyyyy

maybe just do FOR and AGAINST separately?

or do xG Goal difference?

do goal per shot?

### for

```{r}
EPL_minutes_df_clean %>% 
  mutate(goalsperGame = goals / 11,
         against_goalsperGame = against_goals / 11) %>% 
  ggplot(aes(x = timing)) +
  # actual
  geom_point(aes(y = goalsperGame), color = ""darkgreen"") +
  geom_line(aes(y = goalsperGame, group = 1), color = ""darkgreen"") +
  ## xG
  geom_point(aes(y = xGperShot), color = ""green"") +
  geom_line(aes(y = xGperShot, group = 1), color = ""green"") +
  labs(x = ""Minutes"", y = ""Goals per Game | xG per Shot"") +
  theme_minimal() +
  facet_wrap(~team_name)
```

Leicester/Chelsea/City/LFC all vastly scoring more than expected given the quality of their chances >>> elite/on-form strikers (Vardy, Tammy, Fab-3, etc.)

city pepper opponent with many shots of middling quality but with elite players they have they are bound to score a couple eventually

burnley able to get a lot of goals late on in games despite xG staying relatively stable throughout the course of the game

### against

```{r}
EPL_minutes_df_clean %>% 
    mutate(goalsperGame = goals / 11,
         against_goalsperGame = against_goals / 11) %>% 
  ggplot(aes(x = timing)) +
  # actual
  geom_point(aes(y = against_goalsperGame), color = ""darkred"") +
  geom_line(aes(y = against_goalsperGame, group = 1), color = ""darkred"") +
  ## xG
  geom_point(aes(y = xGAperShot), color = ""red"") +
  geom_line(aes(y = xGAperShot, group = 1), color = ""red"") +
  labs(x = ""Minutes"", y = ""Goals per Game | xG per Shot"") +
  theme_minimal() +
  facet_wrap(~team_name)
```

As seen vs. LFC, Villa giving up goals late in the game! Defensive efforts == exhausting and dam breaks late on?

LFC leaking goals late game despite only allowing poor quality chances...


### goal difference

```{r}
EPL_minutes_df_clean %>% 
  mutate(xGD = xG - against_xG,
         GD = goals - against_goals) %>% 
  ggplot(aes(x = timing)) +
  # actual
  geom_point(aes(y = GD), color = ""black"") +
  geom_line(aes(y = GD, group = 1), color = ""black"") +
  ## xG
  geom_point(aes(y = xGD), color = ""gray"") +
  geom_line(aes(y = xGD, group = 1), color = ""gray"") +
  geom_hline(yintercept = 0, color = ""red"") +
  labs(x = ""Minutes"", y = ""Goal Difference | xGD"") +
  theme_minimal() +
  facet_wrap(~team_name)
```

As seen from other viz, LFC start slow then hit their peak near halftime and slow down as the game ends


Chelsea giving up lots of late goals... Lampard's young Chelsea not closing games well + tire from unrefined pressing system?

Man. United seem to have bursts of energy, mainly peaking in the middle of either half...


as seen in previous viz, Burnley dig themselves in a hole in first half but usually manage to claw their way back near the end of the game.

Newcastle do worse over time until they wake up in the final ~15 minutes...


Everton unlucky (?) in that they give up goals with low xG late on in the game, costing them points...


goal-contribution matrix for TIME-INTERVALS?



# Liverpool





```{r}
url <- ""https://understat.com/team/Liverpool/2019""

team_page <- polite::bow(url)

team_data <- polite::scrape(team_page) %>% 
  get_script()

team_situation_data <- get_data_element(team_data, ""statisticsData"") %>% 
  str_replace(., ""\\{\""situation\"""",  ""[\\{\""situation\"""") %>% 
  str_replace(., ""\\}'\\)"", ""\\}]'\\)"") %>% 
  fix_json() %>% 
  fromJSON()
```




## situation (1)

```{r}
situation_df <- team_situation_data %>% 
  .[[1]] %>% 
  unlist() %>% 
  enframe()

situation_df_clean <- situation_df %>% 
  mutate(name = str_replace(name, ""against."", ""against_"")) %>% 
  separate(name, c(""situation"", ""metric""), 
           sep = ""\\."", extra = ""merge"")
```

```{r}
situation_df_clean %>% 
  ggplot(aes(x = situation, y = value)) +
  geom_segment(aes(xend = situation,
                   y = 0, yend = value)) +
  geom_point(color = ""red"", size = 2.5) + 
  theme_minimal() +
  facet_wrap(""metric"", scales = ""free_y"")
```




## formation (2)

```{r}
formation_df <- team_situation_data %>% 
  .[[2]] %>% 
  unlist() %>% 
  enframe()
```


## game state (3)

```{r}
gamestate_df <- team_situation_data %>% 
  .[3] %>% 
  unlist() %>% 
  enframe()

gamestate_df_clean <- gamestate_df %>% 
  mutate(name = str_replace(name, ""gameState.Goal diff "", """"),
         name = str_replace(name, ""against."", ""against_"")) %>% 
  separate(name, c(""game_state"", ""metric""), 
           sep = ""\\."", extra = ""merge"") %>% 
  filter(metric != ""stat"")

glimpse(gamestate_df_clean)
```

https://experimental361.com/2019/10/08/game-states-8-oct-2019/

```{r}
game_state_clean <- gamestate_df_clean %>% 
  filter(metric == ""time"") %>% 
  mutate(state = case_when(
    game_state == ""0"" ~ ""Drawing"",
    game_state %in% c(""> +1"", ""+1"") ~ ""Winning"",
    game_state %in% c(""-1"", "">-1"") ~ ""Losing"",
    TRUE ~ NA_character_
  )) %>% 
  select(-game_state, -metric) %>% 
  mutate(value = as.numeric(value)) %>% 
  group_by(state) %>% 
  summarize(value = sum(value)) %>% 
  ungroup() %>% 
  mutate(team_name = ""Liverpool"",
         total = sum(value),
         percentage = value / total)

glimpse(game_state_clean)
```


```{r}
ggplot(game_state_clean,
       aes(x = team_name, y = percentage, fill = as.factor(state))) + 
  geom_col()
```



## by minutes (4)

```{r}
minutes_df <- team_situation_data %>% 
  .[4] %>% 
  unlist() %>% 
  enframe()

minutes_df_clean <- minutes_df %>% 
  mutate(name = str_replace(name, ""against."", ""against-"")) %>% 
  separate(name, c(""timing"", ""minutes"", ""metric""), 
           sep = ""\\."", extra = ""merge"") %>% 
  select(-timing) %>% 
  filter(metric != ""stat"") %>% 
  pivot_wider(names_from = ""metric"", values_from = ""value"") %>% 
  mutate_at(vars(-minutes), as.numeric) %>% 
  mutate(xGperShot = xG / shots,
         xGAperShot = `against-xG` / `against-shots`)

glimpse(minutes_df_clean)
```

## shot zone (5)

```{r}
zone_df <- team_situation_data %>% 
  .[[5]] %>% 
  unlist() %>% 
  enframe()

zone_df_clean <- zone_df %>% 
  mutate(name = str_replace(name, ""against."", ""against-"")) %>% 
  separate(name, c(""zone"", ""metric""), 
           sep = ""\\."", extra = ""merge"") %>% 
  filter(metric != ""stat"") %>% 
  mutate(value = as.numeric(value))
```

```{r}
zone_df_clean %>% 
  ggplot(aes(x = zone, y = value)) +
  geom_segment(aes(xend = zone,
                   y = 0, yend = value)) +
  geom_point(color = ""red"", size = 2.5) + 
  theme_minimal() +
  facet_wrap(""metric"", scales = ""free_y"")
```

## attack speed (6)


## shot result (7)

```{r}
shot_df <- team_situation_data %>% 
  .[[7]] %>% 
  unlist() %>% 
  enframe() 

shot_df_clean <- shot_df %>% 
  mutate(name = str_replace(name, ""against."", ""against-"")) %>% 
  separate(name, c(""result"", ""metric""), 
           sep = ""\\."", extra = ""merge"") %>% 
  filter(metric != ""stat"") %>% 
  mutate(value = as.numeric(value))
```

```{r}
shot_df_clean %>% 
  ggplot(aes(x = result, y = value)) +
  geom_segment(aes(xend = result,
                   y = 0, yend = value)) +
  geom_point(color = ""red"", size = 2.5) + 
  theme_minimal() +
  facet_wrap(""metric"", scales = ""free_y"")
```




# Plots

```{r}
minutes_df_clean %>% 
  pivot_longer(-minutes, names_to = ""metric"", values_to = ""value"") %>% 
  ggplot(aes(x = minutes, y = value)) + 
  geom_point(color = ""red"", size = 2.5) + 
  geom_line(aes(group = metric)) +
  theme_minimal() +
  facet_wrap(""metric"", scales = ""free_y"")
```


```{r}
minutes_df_clean %>% 
  filter(metric == ""shots"" |
         metric == ""against-shots"") %>% 
  ggplot() + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""shots""),
             aes(x = minutes, y = value),
             color = ""blue"", size = 2.5) + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""against-shots""),
             aes(x = minutes, y = value),
             color = ""red"", size = 2.5) + 
  geom_line(aes(x = minutes, y = value, group = metric)) +
  labs(title = ""Shots/Shots Against by Time"") +
  theme_minimal()
```




```{r}
minutes_df_clean %>% 
  filter(metric == ""xG"" |
         metric == ""against-xG"") %>% 
  ggplot() + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""xG""),
             aes(x = minutes, y = value),
             color = ""blue"", size = 2.5) + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""against-xG""),
             aes(x = minutes, y = value),
             color = ""red"", size = 2.5) + 
  geom_line(aes(x = minutes, y = value, group = metric)) +
  labs(title = ""xG/xGA by Time"") +
  theme_minimal()
```

per shot is probably more informative


```{r}
minutes_df_clean %>% 
  mutate(shots = shots / 11,
         `against-shots` = `against-shots` / 11) %>% 
  ggplot(aes(x = minutes)) +
  geom_point(aes(y = shots), color = ""darkgreen"") +
  geom_line(aes(y = shots, group = 1), color = ""darkgreen"") +
  geom_point(aes(y = `against-shots`), color = ""red"") +
  geom_line(aes(y = `against-shots`, group = 1), color = ""red"") +
  labs(x = ""Minutes"", y = ""Shots per Game"") +
  theme_minimal()
```


```{r}
minutes_df_clean %>% 
  ggplot(aes(x = minutes)) +
  geom_point(aes(y = xGperShot), color = ""darkgreen"") +
  geom_line(aes(y = xGperShot, group = 1), color = ""darkgreen"") +
  geom_point(aes(y = xGAperShot), color = ""red"") +
  geom_line(aes(y = xGAperShot, group = 1), color = ""red"") +
  labs(x = ""Minutes"", y = ""Expected Goals (per shot)"") +
  theme_minimal()
```

LFC finish each half very strongly!

LFC shut down opponents in 2nd half

```{r}
minutes_df_clean %>% 
  mutate(goals = goals / 11,
         `against-goals` = `against-goals` / 11) %>% 
  ggplot(aes(x = minutes)) +
  # actual
  geom_point(aes(y = goals), color = ""darkgreen"") +
  geom_line(aes(y = goals, group = 1), color = ""darkgreen"") +
  geom_point(aes(y = `against-goals`), color = ""darkred"") +
  geom_line(aes(y = `against-goals`, group = 1), color = ""darkred"") +
  ## xG
  geom_point(aes(y = xGperShot), color = ""green"") +
  geom_line(aes(y = xGperShot, group = 1), color = ""green"") +
  geom_point(aes(y = xGAperShot), color = ""red"") +
  geom_line(aes(y = xGAperShot, group = 1), color = ""red"") +
  labs(x = ""Minutes"", y = ""Goals per Game | xG per Game"") +
  theme_minimal()
```

","2019"
"66",233,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2019-2020/liverpool_age_utility.rmd","---
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Liverpool FC Age-Utility Graph


```{r}
# pacman::p_load()
library(rvest)
library(polite)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(purrr)
library(stringr)
library(ggrepel)
library(glue)
library(extrafont)
loadfonts(quiet = TRUE)
```

## web-scrape

```{r}
session <- bow(""https://www.transfermarkt.com/liverpool-fc/leistungsdaten/verein/31/reldata/GB1%262018/plus/1"")

print(session)
# ""The path is scrapable for this user-agent"": OK, looks like we are good to go!

# grab name from photo element instead
result_name <- scrape(session) %>% 
  html_nodes(""#yw1 .bilderrahmen-fixed"") %>% 
  html_attr(""title"") 

# grab age
result_age <- scrape(session) %>% 
  html_nodes("".posrela+ .zentriert"") %>% 
  html_text()

# grab minutes played in league
result_mins <- scrape(session) %>% 
  html_nodes(""td.rechts"") %>% 
  html_text()

```


### combine scraped data

```{r}
# place each vector into list

resultados <- list(result_name, result_age, result_mins)

col_name <- c(""name"", ""age"", ""minutes"")

# then reduce(cbind) to combine them, set names to cols 
results_comb <- resultados %>% 
  reduce(cbind) %>% 
  as_tibble() %>% 
  set_names(col_name)

# NOICE.gif
glimpse(results_comb)
```

## clean data

### fix ages via Wikipedia squad page

```{r}
wiki_url <- ""https://en.wikipedia.org/wiki/201920_Liverpool_F.C._season""

wiki_session <- bow(wiki_url)

wiki_age <- scrape(wiki_session) %>% 
  html_nodes(""table.wikitable:nth-child(6)"") %>% 
  html_table(fill = TRUE) %>% 
  flatten_df()



```


### more cleaning

```{r}
age_plus_one <- c(""Lovren"", ""Van Dijk"", ""Moreno"", ""Ings"")

# fix ""strings"" into proper formats, calculate % of minutes appeared
lfc_minutes <- results_comb %>% 
  
  mutate(age = as.numeric(age),
         minutes = minutes %>% 
           str_replace(""\\."", """") %>% 
           str_replace(""'"", """") %>% 
           as.numeric(),
         min_perc = (minutes / 3420) %>% round(digits = 3)) %>% 
  
  filter(!is.na(minutes)) %>% 
  
  separate(name, into = c(""first_name"", ""last_name""), sep = "" "") %>% 
  
  # manually fix some names
  mutate(
    last_name = case_when(                        
      first_name == ""Trent"" ~ ""Alexander-Arnold"",   
      first_name == ""Virgil"" ~ ""Van Dijk"",
      first_name == ""Alex"" ~ ""Oxlade-Chamberlain"",
      TRUE ~ last_name),
    age = age + 1) %>%    # do CURRENT age instead for plot 2.0
  
  mutate(
    age = case_when(
      last_name %in% age_plus_one ~ age + 1,
      TRUE ~ age)
    ) %>% 
  arrange(desc(min_perc))

# rectanglular highlight for players in their prime:
rect_df <- data.frame(
  xmin = 25, xmax = 30,
  ymin = -Inf, ymax = Inf
)
```




## plotting

```{r fig.height=6, fig.width=8}
lfc_minutes %>% 
  ggplot(aes(x = age, y = min_perc)) +
  geom_rect(
    data = rect_df, inherit.aes = FALSE,
    aes(xmin = xmin, xmax = xmax, 
        ymin = ymin, ymax = ymax),
    alpha = 0.3,
    fill = ""firebrick1"") +
  geom_point(color = ""red"", size = 2.5) +
  geom_text_repel(
    aes(label = last_name, family = ""Roboto Condensed""),
    nudge_x = 0.5,
    seed = 6) + 
  scale_y_continuous(
    expand = c(0.01, 0),
    limits = c(0, 1), 
    labels = percent_format()) +
  scale_x_continuous(
    breaks = pretty_breaks(n = 10)) +
  labs(
    x = ""Current Age (As of Aug. --th, 2019)"", y = ""% of Minutes Played"", 
    title = ""Liverpool FC: Age-Utility Matrix"",
    subtitle = ""Premier League 18/19 (Summer 2019 transfers in bold, departed players left in for comparison)"",
    caption = glue::glue(""
                         Data: transfermarkt.com
                         By: @R_by_Ryo"")) +
  theme_bw() +
  theme(
    text = element_text(family = ""Roboto Condensed""),
    panel.grid.minor.y = element_blank()) +
  geom_label(
    aes(x = 20.5, y = 0.87, 
        hjust = 0.5, 
        label = glue(""
          Encouraging to see Liverpool buying players both in 
          their prime and regulars in their previous teams. 
          Our entire best 'Starting XI' are going to be 
          in their prime this season!
          ""), 
        family = ""Roboto Condensed""),
    size = 3.5)

```

























","2019"
"67",234,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2019-2020/liverpool_understat.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""8/27/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Package

```{r}
pacman::p_load(dplyr, tidyr, stringr, stringi, purrr,
               tibble, rvest, polite, lubridate,
               ggplot2, jsonlite, xml2, qdapRegex,
               ggtext, extrafont, ggrepel, ggforce,
               understatr, ggsoccer,
               grid, gridExtra)
loadfonts(quiet = TRUE)
```


## Shots data

```{r}
bobby_shots <- get_player_shots(482)
```

IMG size: Width = 878, Height = 542
Pitch size: 
- Width:20 >   pitch < 20
- Height: 20 from Top > pitch 

x == y (from bottom to up)

y == x (from right to left)

ex. ShotOnPost, Header, Minute 60, xG = 0.1485... (Mainz vs. Hoff) 2014

x: 0.987	y: 0.382	

is actually:
y: 98.7% from BOTTOM  (542 * 0.987)   534.954
x: 38.2% from RIGHT   (878 * 0.382)   335.396

BUT from LEFT so need to...

x: 878 - 335.396 == 542.604
y: 534.954


total HEIGHT: 542 * 2 == 1084

box width 685-192 == 493

box length 245 - 21 == 224

pen spot: 171 - 21 == 150

goal width: 488 - 389 == 99

six length: 94 - 21 == 73
six width: 562 - 315 == 247
```{r, fig.height=8, fig.width=10}
pitch_custom <- list(
  length = 1084,
  width = 878,
  penalty_box_length = 224,
  penalty_box_width = 493,
  six_yard_box_length = 73,
  six_yard_box_width = 247,
  penalty_spot_distance = 150,
  goal_width = 99,
  origin_x = 0,
  origin_y = 0
)

df <- data.frame(x = 1042.604, y = 534.604)

ggplot(df) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 878/1084) +
  coord_flip(xlim = c(550, 1085),
              ylim = c(-1, 880)) +
  geom_point(aes(x = x, y = y), shape = 21,
             fill = ""red"",
             colour = ""red"", size = 5) +
  geom_point(x = 1080, y = 850)


ggplot(df) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 878/1284) +
  geom_point(x = 0, y = 0) +
  geom_point(x = 600, y = 878)
```



```{r}
shots <- data.frame(x = c(90, 85, 82, 78, 83, 74, 94, 91),
                    y = c(43, 40, 52, 56, 44, 71, 60, 54))

ggplot(shots) +
  annotate_pitch(colour = ""white"",
                 fill   = ""chartreuse4"",
                 limits = FALSE) +
  geom_point(aes(x = x, y = 100 - y),
             colour = ""yellow"", 
             size = 4) +
  theme_pitch() +
  theme(plot.background = element_rect(fill = ""chartreuse4""),
        title = element_text(colour = ""white"")) +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  ggtitle(""Simple shotmap"",
          ""ggsoccer example"")
```

```{r}
player_url <- str_glue(""{home_url}/player/{player_id}"")

# read player page
player_page <- read_html(player_url)

# locate script tags
player_data <- get_script(player_page)

# isolate player data
player_data <- get_data_element(player_data, ""shotsData"")

# pick out JSON string
player_data <- fix_json(player_data)

# parse JSON
player_data <- fromJSON(player_data)
```



## understat utility funs

```{r}
get_script <- function(x) {
  as.character(html_nodes(x, ""script""))
}

# subset data element of html page
get_data_element <- function(x, element_name) {
  stri_unescape_unicode(str_subset(x, element_name))
}

# fix json element for parsing
fix_json <- function(x) {
  str_subset(
    unlist(
      rm_square(
        x, extract = TRUE, include.markers = TRUE
      )
    ),
    ""\\[\\]"", negate = TRUE
  )
}

# get player name part of html page
get_player_name <- function(x) {

  player_name <- html_nodes(x, "".header-wrapper:first-child"")
  trimws(html_text(player_name))
}
```

## base vars

```{r}
home_url <- ""https://understat.com""
player_id <- 482
```


# Match Summary Stats

```{r}
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

team_stats <- polite::scrape(match_page) %>% 
  html_nodes(""div.scheme-block:nth-child(4)"") %>% 
  html_text() %>% 
  str_remove_all(., ""CHANCES"") %>% 
  str_remove_all(., ""([0-9]{2,}%)"") %>% 
  str_replace_all(., ""SHOTS ON TARGET"", ""ON-TARGET"") %>% #trimws() %>% 
  str_squish() %>% 
  read.table(text = ., header = FALSE, sep = "" "",
             col.names = c(""var_name"", ""home"", ""away"")) %>% 
  t() %>% 
  tibble::as_tibble() %>% 
  janitor::row_to_names(row_number = 1) %>% 
  mutate_at(vars(-TEAMS), ~ as.numeric(.))

home_stats <- team_stats[1,]

away_stats <- team_stats[2,]

team_stats
```

# Liv-Nor


```{r}
home_url <- ""https://understat.com""
match_id <- 11643
```

```{r}
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

match_data <- polite::scrape(match_page) %>% 
  get_script()

match_shots_data <- get_data_element(match_data, ""shotsData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_shots_data <- fix_json(match_shots_data)

# Home: Liverpool
liv_shots_data <- fromJSON(match_shots_data[1])

## add 'team_name' with home team name from 'h_team' var
liv_shots_data$team_name <- liv_shots_data$h_team


# Away: Arsenal
nor_shots_data <- fromJSON(match_shots_data[2])

## add 'team_name' with away team name from 'a_team' var
nor_shots_data$team_name <- nor_shots_data$a_team
```


```{r}
match_shots_data_clean <- liv_shots_data %>% 
  full_join(nor_shots_data) %>% 
  select(-id, -h_team, -a_team,
         -h_goals, -a_goals) %>% 
  mutate_at(vars(minute, xG, X, Y, 
                 player_id, match_id, season), ~ as.numeric(.)) %>% 
  mutate(team_name = forcats::as_factor(team_name),
         xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         result = case_when(
           result == ""SavedShot"" ~ ""Saved Shot"",
           result == ""BlockedShot"" ~ ""Blocked Shot"",
           result == ""MissedShots"" ~ ""Missed Shot"",
           result == ""ShotOnPost"" ~ ""On Post"",
           result == ""OwnGoal"" ~ ""Own Goal"",
           TRUE ~ result),
         situation = case_when(
           situation == ""OpenPlay"" ~ ""Open Play"", 
           situation == ""FromCorner"" ~ ""From Corner"",
           situation == ""DirectFreekick"" ~ ""From Free Kick"",
           TRUE ~ situation),
         lastAction = case_when(
           lastAction == ""BallRecovery"" ~ ""Ball Recovery"",
           lastAction == ""BallTouch"" ~ ""Ball Touch"",
           lastAction == ""LayOff"" ~ ""Lay Off"",
           lastAction == ""TakeOn"" ~ ""Take On"",
           TRUE ~ lastAction),
         shotType = case_when(
           shotType == ""LeftFoot"" ~ ""Left Foot"",
           shotType == ""RightFoot"" ~ ""Right Foot"",
           TRUE ~ shotType)) %>% 
  separate(player, into = c(""firstname"", ""player""), 
           sep = ""\\s"", extra = ""merge"") %>% 
  ## players like Fabinho listed without Tavares last name
  mutate(player = if_else(is.na(player), firstname, player))

last_min <- match_shots_data_clean$minute %>% unique() %>% last()
minute <- c(0:last_min)
team_name <- c(""Liverpool"", ""Norwich"")

livnor_rollsumxG <- match_shots_data_clean %>% 
  full_join(crossing(minute, team_name)) %>% 
  arrange(minute) %>% 
  group_by(team_name) %>% 
  mutate(xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         rollsum = lag(cumsum(xG))) %>% 
  ungroup() %>% 
  mutate(player_label = case_when(
    result == ""Goal"" ~ glue::glue(""{player}: {xG %>% round(digits = 2)} xG""),
    result == ""Own Goal"" ~ glue::glue(""{player} (Own Goal): {xG %>% round(digits = 2)} xG""),
    TRUE ~ """"),
    ## 
    rollsum_goal = rollsum + xG,
    minute_goal = minute + 1)
```


## accumulated xG plot

```{r, fig.height=6, fig.width=10}
cumsum_xG_plot <- livnor_rollsumxG %>% 
  ggplot(aes(x = minute_goal, y = rollsum_goal, 
             color = team_name, group = team_name)) +
  geom_line(size = 2.5) +
  geom_label_repel(data = livnor_rollsumxG %>% 
                     filter(result %in% c(""Goal"", ""Own Goal"")),
                   aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name, label = player_label),
                   nudge_x = -10, nudge_y = 0.35,
                   show.legend = FALSE) +
  geom_point(data = livnor_rollsumxG %>% 
               filter(result %in% c(""Goal"", ""Own Goal"")),
             aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name),
             size = 5, shape = 21, fill = ""white"", stroke = 1.25,
             show.legend = FALSE) +
  scale_x_continuous(breaks = c(seq(0, 90, by = 5), 91),
                     labels = c(seq(0, 40, by = 5), ""HT"", 
                                seq(50, 85, by = 5),"""", ""FT""),
                     expand = c(0.01, 0),
                     limits = c(0, 91)) +
  scale_y_continuous(limits = c(0, 3),
                     sec.axis = sec_axis(~ ., breaks = team_stats$xG)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Norwich"" = ""#00a650""),
    breaks = c(""Liverpool"", ""Norwich""),
    labels = c(""<b style ='color:#d00027'>Liverpool</b>"",
               ""<b style='color: #00a650'>Norwich</b>"")) +
  labs(title = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}: {home_stats$GOALS} </b><b style ='color:#d00027; font-size: 20'>({home_stats$xPTS} xPTs)</b><br> <b style='color: #00a650'>{away_stats$TEAMS}: {away_stats$GOALS} </b><b style='color: #00a650; font-size: 20'>({away_stats$xPTS} xPTs)</b>""),
       subtitle = ""August 9, 2019 (Matchday 1)"",
       x = NULL,
       y = ""Expected Goals"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_markdown(size = 40, 
                                      family = ""Roboto Condensed""),
        plot.subtitle = element_text(size = 18, 
                                     family = ""Roboto Condensed"",
                                     color = ""grey20""),
        axis.title = element_text(size = 18, color = ""grey20""),
        axis.text = element_text(size = 16, face = ""bold""),
        panel.grid.minor.x = element_blank(),
        legend.text = element_markdown(size = 14),
        legend.position = c(0.2, 0.95),
        legend.direction = ""horizontal"",
        legend.title = element_blank())

cumsum_xG_plot
```


# Sot-Liv

can't use black or white because of shot map...
use black outline for all and swap to white for only black color teams?
don't want to use outlandish 3rd colors unless aboslutely necessary

```{r}
home_url <- ""https://understat.com""
match_id <- 11658
```

```{r}
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

match_data <- polite::scrape(match_page) %>% 
  get_script()

match_shots_data <- get_data_element(match_data, ""shotsData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_shots_data <- fix_json(match_shots_data)

# Home: Southampton
sot_shots_data <- fromJSON(match_shots_data[1])

## add 'team_name' with home team name from 'h_team' var
sot_shots_data$team_name <- sot_shots_data$h_team

# Away: Liverpool
liv_shots_data <- fromJSON(match_shots_data[2])

## add 'team_name' with away team name from 'a_team' var
liv_shots_data$team_name <- liv_shots_data$a_team
```

```{r}
match_shots_data_clean <- liv_shots_data %>% 
  full_join(sot_shots_data) %>% 
  select(-id, -h_team, -a_team,
         -h_goals, -a_goals) %>% 
  mutate_at(vars(minute, xG, X, Y, 
                 player_id, match_id, season), ~ as.numeric(.)) %>% 
  mutate(team_name = forcats::as_factor(team_name),
         xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         result = case_when(
           result == ""SavedShot"" ~ ""Saved Shot"",
           result == ""BlockedShot"" ~ ""Blocked Shot"",
           result == ""MissedShots"" ~ ""Missed Shot"",
           result == ""ShotOnPost"" ~ ""On Post"",
           result == ""OwnGoal"" ~ ""Own Goal"",
           TRUE ~ result),
         situation = case_when(
           situation == ""OpenPlay"" ~ ""Open Play"", 
           situation == ""FromCorner"" ~ ""From Corner"",
           situation == ""DirectFreekick"" ~ ""From Free Kick"",
           TRUE ~ situation),
         lastAction = case_when(
           lastAction == ""BallRecovery"" ~ ""Ball Recovery"",
           lastAction == ""BallTouch"" ~ ""Ball Touch"",
           lastAction == ""LayOff"" ~ ""Lay Off"",
           lastAction == ""TakeOn"" ~ ""Take On"",
           TRUE ~ lastAction),
         shotType = case_when(
           shotType == ""LeftFoot"" ~ ""Left Foot"",
           shotType == ""RightFoot"" ~ ""Right Foot"",
           TRUE ~ shotType)) %>% 
  separate(player, into = c(""firstname"", ""player""), 
           sep = ""\\s"", extra = ""merge"") %>% 
  ## players like Fabinho listed without Tavares last name
  mutate(player = if_else(is.na(player), firstname, player))

last_min <- match_shots_data_clean$minute %>% unique() %>% last()
minute <- c(0:last_min)
team_name <- c(""Southampton"", ""Liverpool"")

livsot_rollsumxG <- match_shots_data_clean %>% 
  full_join(crossing(minute, team_name)) %>% 
  arrange(minute) %>% 
  group_by(team_name) %>% 
  mutate(xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         rollsum = lag(cumsum(xG))) %>% 
  ungroup() %>% 
  mutate(player_label = case_when(
    result == ""Goal"" ~ glue::glue(""{player}: {xG %>% round(digits = 2)} xG""),
    TRUE ~ """"),
    ## 
    rollsum_goal = rollsum + xG,
    minute_goal = minute + 1)
```


## accumulated xG plot

```{r, fig.height=6, fig.width=10}
cumsum_xG_plot <- livsot_rollsumxG %>% 
  ggplot(aes(x = minute_goal, y = rollsum_goal, 
             color = team_name, group = team_name)) +
  geom_line(size = 2.5) +
  geom_label_repel(data = livsot_rollsumxG %>% filter(result == ""Goal""),
                   aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name, label = player_label),
                   nudge_x = -10, nudge_y = 0.35,
                   show.legend = FALSE) +
  geom_point(data = livsot_rollsumxG %>% filter(result == ""Goal""),
             aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name),
             size = 5, shape = 21, fill = ""white"", stroke = 1.25,
             show.legend = FALSE) +
  scale_x_continuous(breaks = c(seq(0, 90, by = 5), 91),
                     labels = c(seq(0, 40, by = 5), ""HT"", 
                                seq(50, 85, by = 5),"""", ""FT""),
                     expand = c(0.01, 0),
                     limits = c(0, 91)) +
  scale_y_continuous(limits = c(0, 3),
                     sec.axis = sec_axis(~ ., breaks = team_stats$xG)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#000000"",
               ""Southampton"" = ""#ed1a3b""),
    breaks = c(""Liverpool"", ""Southampton""),
    labels = c(""<b style ='color:#000000'>Liverpool</b>"",
               ""<b style='color: #ed1a3b'>Southampton</b>"")) +
  labs(title = glue::glue(""<b style ='color:#ed1a3b'>{home_stats$TEAMS}: {home_stats$GOALS} </b><b style ='color:#ed1a3b; font-size: 20'>({home_stats$xPTS} xPTs)</b><br> <b style='color: #000000'>{away_stats$TEAMS}: {away_stats$GOALS} </b><b style='color: #000000; font-size: 20'>({away_stats$xPTS} xPTs)</b>""),
       subtitle = ""August 17, 2019 (Matchday 2)"",
       x = NULL,
       y = ""Expected Goals"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_markdown(size = 40, 
                                      family = ""Roboto Condensed""),
        plot.subtitle = element_text(size = 18, 
                                     family = ""Roboto Condensed"",
                                     color = ""grey20""),
        axis.title = element_text(size = 18, color = ""grey20""),
        axis.text = element_text(size = 16, face = ""bold""),
        panel.grid.minor.x = element_blank(),
        legend.text = element_markdown(size = 14),
        legend.position = c(0.2, 0.95),
        legend.direction = ""horizontal"",
        legend.title = element_blank())

cumsum_xG_plot
```





# Liv-Ars

```{r}
match_id <- 11670
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

match_data <- polite::scrape(match_page) %>% 
  get_script()

match_shots_data <- get_data_element(match_data, ""shotsData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_shots_data <- fix_json(match_shots_data)

# Home: Liverpool
liv_shots_data <- fromJSON(match_shots_data[1])

## add 'team_name' with home team name from 'h_team' var
liv_shots_data$team_name <- liv_shots_data$h_team


# Away: Arsenal
ars_shots_data <- fromJSON(match_shots_data[2])

## add 'team_name' with away team name from 'a_team' var
ars_shots_data$team_name <- ars_shots_data$a_team
```

```{r}
match_shots_data_clean <- liv_shots_data %>% 
  full_join(ars_shots_data) %>% 
  select(-id, -h_team, -a_team,
         -h_goals, -a_goals) %>% 
  mutate_at(vars(minute, xG, X, Y, 
                 player_id, match_id, season), ~ as.numeric(.)) %>% 
  mutate(team_name = forcats::as_factor(team_name),
         xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         result = case_when(
           result == ""SavedShot"" ~ ""Saved Shot"",
           result == ""BlockedShot"" ~ ""Blocked Shot"",
           result == ""MissedShots"" ~ ""Missed Shot"",
           result == ""ShotOnPost"" ~ ""On Post"",
           result == ""OwnGoal"" ~ ""Own Goal"",
           TRUE ~ result),
         situation = case_when(
           situation == ""OpenPlay"" ~ ""Open Play"", 
           situation == ""FromCorner"" ~ ""From Corner"",
           situation == ""DirectFreekick"" ~ ""From Free Kick"",
           TRUE ~ situation),
         lastAction = case_when(
           lastAction == ""BallRecovery"" ~ ""Ball Recovery"",
           lastAction == ""BallTouch"" ~ ""Ball Touch"",
           lastAction == ""LayOff"" ~ ""Lay Off"",
           lastAction == ""TakeOn"" ~ ""Take On"",
           TRUE ~ lastAction),
         shotType = case_when(
           shotType == ""LeftFoot"" ~ ""Left Foot"",
           shotType == ""RightFoot"" ~ ""Right Foot"",
           TRUE ~ shotType)) %>% 
  separate(player, into = c(""firstname"", ""player""), 
           sep = ""\\s"", extra = ""merge"") %>% 
  ## players like Fabinho listed without Tavares last name
  mutate(player = if_else(is.na(player), firstname, player))

last_min <- match_shots_data_clean$minute %>% unique() %>% last()
minute <- c(0:last_min)
team_name <- c(""Liverpool"", ""Arsenal"")
# crossing(minute, team_name)

livars_rollsumxG <- match_shots_data_clean %>% 
  full_join(crossing(minute, team_name)) %>% 
  arrange(minute) %>% 
  group_by(team_name) %>% 
  mutate(xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         rollsum = lag(cumsum(xG))) %>% 
  ungroup() %>% 
  mutate(player_label = case_when(
    result == ""Goal"" ~ glue::glue(""{player}: {xG %>% round(digits = 2)} xG""),
    TRUE ~ """"),
    ## 
    rollsum_goal = rollsum + xG,
    minute_goal = minute + 1)
```


## accumulated xG plot

```{r, fig.height=6, fig.width=10}
cumsum_xG_plot <- livars_rollsumxG %>% 
  ggplot(aes(x = minute_goal, y = rollsum_goal, 
             color = team_name, group = team_name)) +
  geom_line(size = 2.5) +
  geom_label_repel(data = livars_rollsumxG %>% filter(result == ""Goal""),
                   aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name, label = player_label),
                   nudge_x = -10, nudge_y = 0.35,
                   show.legend = FALSE) +
  geom_point(data = livars_rollsumxG %>% filter(result == ""Goal""),
             aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name),
             size = 5, shape = 21, fill = ""white"", stroke = 1.25,
             show.legend = FALSE) +
  scale_x_continuous(breaks = c(seq(0, 90, by = 5), 94),
                     labels = c(seq(0, 40, by = 5), ""HT"", 
                                seq(50, 90, by = 5), ""FT""),
                     expand = c(0.01, 0),
                     limits = c(0, 94)) +
  scale_y_continuous(limits = c(0, 3),
                     sec.axis = sec_axis(~ ., breaks = team_stats$xG)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Arsenal"" = ""#063672""),
    breaks = c(""Liverpool"", ""Arsenal""),
    labels = c(""<b style ='color:#d00027'>Liverpool</b>"",
               ""<b style='color: #063672'>Arsenal</b>"")) +
  labs(title = glue::glue(
    ""<b style ='color:{home_stats$home_team_color}'>{home_stats$TEAMS}: {home_stats$GOALS} </b><b style ='color:{home_stats$home_team_color}; font-size: 20'>({home_stats$xPTS} xPTs)</b><br> <b style='color:{away_stats$away_team_color}'>{away_stats$TEAMS}: {away_stats$GOALS} </b><b style='color:{away_stats$away_team_color}; font-size: 20'>({away_stats$xPTS} xPTs)</b>""),
       subtitle = glue::glue(""{match_date} (Matchday {matchday_num})""),
       x = NULL,
       y = ""Expected Goals"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_markdown(size = 40, 
                                      family = ""Roboto Condensed""),
        plot.subtitle = element_text(size = 18, 
                                     family = ""Roboto Condensed"",
                                     color = ""grey20""),
        axis.title = element_text(size = 18, color = ""grey20""),
        axis.text = element_text(size = 16, face = ""bold""),
        panel.grid.minor.x = element_blank(),
        legend.text = element_markdown(size = 14),
        legend.position = c(0.2, 0.95),
        legend.direction = ""horizontal"",
        legend.title = element_blank())

cumsum_xG_plot
```


# Burn-Liv

```{r}
match_id <- 11680

match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

match_data <- polite::scrape(match_page) %>% 
  get_script()

match_shots_data <- get_data_element(match_data, ""shotsData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_shots_data <- fix_json(match_shots_data)

# Home: Burnley
burn_shots_data <- fromJSON(match_shots_data[1])

## add 'team_name' with home team name from 'h_team' var
burn_shots_data$team_name <- burn_shots_data$h_team


# Away: LFC
liv_shots_data <- fromJSON(match_shots_data[2])

## add 'team_name' with away team name from 'a_team' var
liv_shots_data$team_name <- liv_shots_data$a_team
```

```{r}
match_shots_data_clean <- liv_shots_data %>% 
  full_join(burn_shots_data) %>% 
  select(-id, -h_team, -a_team,
         -h_goals, -a_goals) %>% 
  mutate_at(vars(minute, xG, X, Y, 
                 player_id, match_id, season), ~ as.numeric(.)) %>% 
  mutate(team_name = forcats::as_factor(team_name),
         xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         result = case_when(
           result == ""SavedShot"" ~ ""Saved Shot"",
           result == ""BlockedShot"" ~ ""Blocked Shot"",
           result == ""MissedShots"" ~ ""Missed Shot"",
           result == ""ShotOnPost"" ~ ""On Post"",
           result == ""OwnGoal"" ~ ""Own Goal"",
           TRUE ~ result),
         situation = case_when(
           situation == ""OpenPlay"" ~ ""Open Play"", 
           situation == ""FromCorner"" ~ ""From Corner"",
           situation == ""DirectFreekick"" ~ ""From Free Kick"",
           TRUE ~ situation),
         lastAction = case_when(
           lastAction == ""BallRecovery"" ~ ""Ball Recovery"",
           lastAction == ""BallTouch"" ~ ""Ball Touch"",
           lastAction == ""LayOff"" ~ ""Lay Off"",
           lastAction == ""TakeOn"" ~ ""Take On"",
           TRUE ~ lastAction),
         shotType = case_when(
           shotType == ""LeftFoot"" ~ ""Left Foot"",
           shotType == ""RightFoot"" ~ ""Right Foot"",
           TRUE ~ shotType)) %>% 
  arrange(minute) %>% 
  separate(player, into = c(""firstname"", ""player""), 
           sep = ""\\s"", extra = ""merge"") %>% 
  ## players like Fabinho listed without Tavares last name
  mutate(player = if_else(is.na(player), firstname, player))

last_min <- match_shots_data_clean$minute %>% unique() %>% last()
if (last_min < 90) {
  last_min <- 90
}

minute <- c(0:last_min)
team_name <- c(""Liverpool"", ""Burnley"")
# crossing(minute, team_name)

livars_rollsumxG <- match_shots_data_clean %>% 
  full_join(crossing(minute, team_name)) %>% 
  arrange(minute) %>% 
  group_by(team_name) %>% 
  mutate(xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         rollsum = lag(cumsum(xG))) %>% 
  ungroup() %>% 
  mutate(player_label = case_when(
    result == ""Goal"" ~ glue::glue(""{player}: {xG %>% round(digits = 2)} xG""),
    result == ""Own Goal"" ~ glue::glue(""{player} (Own Goal): {xG %>% round(digits = 2)} xG""),
    TRUE ~ """"),
    # xG = case_when(
    #        result == ""OwnGoal"" ~ rollsum,
    #        TRUE ~ xG
    #      ),
    ## 
    rollsum_goal = rollsum + xG,
    minute_goal = minute + 1)
```


## accumulated xG plot

place xPoints instead of current points in title...

```{r, fig.height=6, fig.width=10}
cumsum_xG_plot <- livars_rollsumxG %>% 
  ggplot(aes(x = minute_goal, y = rollsum_goal, 
             color = team_name, group = team_name)) +
  geom_line(size = 2.5) +
  geom_label_repel(data = livars_rollsumxG %>% filter(result == ""Goal""),
                   aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name, label = player_label),
                   nudge_x = -10, nudge_y = 0.35,
                   size = 5, show.legend = FALSE) +
  geom_label_repel(data = livars_rollsumxG %>% filter(result == ""Own Goal""),
                   aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name, label = player_label),
                   nudge_x = -10, nudge_y = 0.35,
                   size = 5, show.legend = FALSE) +
  geom_point(data = livars_rollsumxG %>% 
               filter(result %in% c(""Goal"", ""Own Goal"")),
             aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name),
             size = 5, shape = 21, fill = ""white"", stroke = 1.25,
             show.legend = FALSE) +
  ## if extratime or last min is < 93/94 then just skip 90 min label
  scale_x_continuous(breaks = c(seq(0, 90, by = 5), 92),
                     labels = c(seq(0, 40, by = 5), ""HT"", 
                                seq(50, 85, by = 5), """", ""FT""),
                     expand = c(0.01, 0),
                     limits = c(0, 92)) +
  scale_y_continuous(limits = c(0, 1.75),
                     sec.axis = sec_axis(~ ., breaks = team_stats$xG)) +
  scale_color_manual(
    values = c(""Burnley"" = ""#6C1D45"",
               ""Liverpool"" = ""#d00027""),
    breaks = c(""Burnley"", ""Liverpool""),
    labels = c(""<b style='color: #6C1D45'>Burnley</b>"",
               ""<b style ='color:#d00027'>Liverpool</b>"")) +
  labs(title = glue::glue(""<b style ='color:#6C1D45'>{home_stats$TEAMS}: {home_stats$GOALS} </b><b style ='color:#6C1D45; font-size: 20'>({home_stats$xPTS} xPTs)</b><br> <b style='color: #d00027'>{away_stats$TEAMS}: {away_stats$GOALS} </b><b style='color: #d00027; font-size: 20'>({away_stats$xPTS} xPTs)</b>""),
       subtitle = ""August 31, 2019 (Matchday 4)"",
       x = NULL,
       y = ""Expected Goals"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_markdown(size = 40, 
                                      family = ""Roboto Condensed""),
        plot.subtitle = element_text(size = 18, 
                                     family = ""Roboto Condensed"",
                                     color = ""grey20""),
        axis.title = element_text(size = 18, color = ""grey20""),
        axis.text = element_text(size = 16, face = ""bold""),
        panel.grid.minor.x = element_blank(),
        legend.text = element_markdown(size = 18),
        legend.position = c(0.2, 0.95),
        legend.direction = ""horizontal"",
        legend.title = element_blank())

cumsum_xG_plot
```


# Liv-New

## Match Summary Stats

```{r}
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

team_stats <- polite::scrape(match_page) %>% 
  html_nodes(""div.scheme-block:nth-child(4)"") %>% 
  html_text() %>% 
  str_remove_all(., ""CHANCES"") %>% 
  str_remove_all(., ""([0-9]{2,}%)"") %>% 
  str_replace_all(., ""SHOTS ON TARGET"", ""ON-TARGET"") %>% 
  str_replace_all(., ""Newcastle United"", ""Newcastle-United"") %>% 
  str_squish() %>% 
  read.table(text = ., header = FALSE, sep = "" "",
             col.names = c(""var_name"", ""home"", ""away"")) %>% 
  t() %>% 
  tibble::as_tibble() %>% 
  janitor::row_to_names(row_number = 1) %>% 
  mutate_at(vars(-TEAMS), ~ as.numeric(.))

home_stats <- team_stats[1,]

away_stats <- team_stats[2,]
away_stats$TEAMS <- ""Newcastle United""

team_stats

## set to red vs. blue as DEFAULT
home_stats$home_team_color <- ""#d00027""
away_stats$away_team_color <- ""#000000""
```

```{r}
match_id <- 11683

match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

match_data <- polite::scrape(match_page) %>% 
  get_script()

match_shots_data <- get_data_element(match_data, ""shotsData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_shots_data <- fix_json(match_shots_data)

# Home: Burnley
liv_shots_data <- fromJSON(match_shots_data[1])

## add 'team_name' with home team name from 'h_team' var
liv_shots_data$team_name <- liv_shots_data$h_team


# Away: LFC
new_shots_data <- fromJSON(match_shots_data[2])

## add 'team_name' with away team name from 'a_team' var
new_shots_data$team_name <- new_shots_data$a_team

## Match date
match_date <- scrape(match_page) %>% 
  html_nodes("".breadcrumb > li:nth-child(3)"") %>% 
  html_text()
```

```{r}
match_shots_data_clean <- liv_shots_data %>% 
  full_join(new_shots_data) %>% 
  select(-id, -h_team, -a_team,
         -h_goals, -a_goals) %>% 
  mutate_at(vars(minute, xG, X, Y, 
                 player_id, match_id, season), ~ as.numeric(.)) %>% 
  mutate(team_name = forcats::as_factor(team_name),
         xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         result = case_when(
           result == ""SavedShot"" ~ ""Saved Shot"",
           result == ""BlockedShot"" ~ ""Blocked Shot"",
           result == ""MissedShots"" ~ ""Missed Shot"",
           result == ""ShotOnPost"" ~ ""On Post"",
           result == ""OwnGoal"" ~ ""Own Goal"",
           TRUE ~ result),
         situation = case_when(
           situation == ""OpenPlay"" ~ ""Open Play"", 
           situation == ""FromCorner"" ~ ""From Corner"",
           situation == ""DirectFreekick"" ~ ""From Free Kick"",
           TRUE ~ situation),
         lastAction = case_when(
           lastAction == ""BallRecovery"" ~ ""Ball Recovery"",
           lastAction == ""BallTouch"" ~ ""Ball Touch"",
           lastAction == ""LayOff"" ~ ""Lay Off"",
           lastAction == ""TakeOn"" ~ ""Take On"",
           TRUE ~ lastAction),
         shotType = case_when(
           shotType == ""LeftFoot"" ~ ""Left Foot"",
           shotType == ""RightFoot"" ~ ""Right Foot"",
           TRUE ~ shotType)) %>% 
  arrange(minute) %>% 
  separate(player, into = c(""firstname"", ""player""), 
           sep = ""\\s"", extra = ""merge"") %>% 
  ## players like Fabinho listed without Tavares last name
  mutate(player = if_else(is.na(player), firstname, player))

last_min <- match_shots_data_clean$minute %>% unique() %>% last()
if (last_min < 90) {
  last_min <- 90
}

minute <- c(0:last_min)
team_name <- c(""Liverpool"", ""Newcastle United"")
# crossing(minute, team_name)

livnew_rollsumxG <- match_shots_data_clean %>% 
  full_join(crossing(minute, team_name)) %>% 
  arrange(minute) %>% 
  group_by(team_name) %>% 
  mutate(xG = if_else(is.na(xG), 0, xG) %>% round(digits = 2),
         rollsum = lag(cumsum(xG))) %>% 
  ungroup() %>% 
  mutate(player_label = case_when(
    result == ""Goal"" ~ glue::glue(""{player}: {xG %>% round(digits = 2)} xG""),
    result == ""Own Goal"" ~ glue::glue(""{player} (Own Goal): {xG %>% round(digits = 2)} xG""),
    TRUE ~ """"),
    # xG = case_when(
    #        result == ""OwnGoal"" ~ rollsum,
    #        TRUE ~ xG
    #      ),
    ## 
    rollsum_goal = rollsum + xG,
    minute_goal = minute + 1)
```

## accumulated xG plot

```{r, fig.height=6, fig.width=10}
cumsum_xG_plot <- livnew_rollsumxG %>% 
  ggplot(aes(x = minute_goal, y = rollsum_goal, 
             color = team_name, group = team_name)) +
  geom_line(size = 2.5) +
  geom_label_repel(data = livnew_rollsumxG %>% filter(result == ""Goal""),
                   aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name, label = player_label),
                   nudge_x = -10, nudge_y = 0.35,
                   size = 5, show.legend = FALSE) +
  geom_label_repel(data = livnew_rollsumxG %>% filter(result == ""Own Goal""),
                   aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name, label = player_label),
                   nudge_x = -10, nudge_y = 0.35,
                   size = 5, show.legend = FALSE) +
  geom_point(data = livnew_rollsumxG %>% 
               filter(result %in% c(""Goal"", ""Own Goal"")),
             aes(x = minute_goal, y = rollsum_goal, 
                       color = team_name),
             size = 5, shape = 21, fill = ""white"", stroke = 1.25,
             show.legend = FALSE) +
  ## if extratime or last min is < 93/94 then just skip 90 min label
  scale_x_continuous(breaks = c(seq(0, 90, by = 5), 90),
                     labels = c(seq(0, 40, by = 5), ""HT"", 
                                seq(50, 85, by = 5), """", ""FT""),
                     expand = c(0.01, 0),
                     limits = c(0, 90)) +
  scale_y_continuous(limits = c(0, 4),
                     sec.axis = sec_axis(~ ., breaks = team_stats$xG)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Newcastle United"" = ""#000000""),
    breaks = c(""Liverpool"", ""Newcastle United""),
    labels = c(""<b style ='color:#d00027'>Liverpool</b>"",
               ""<b style='color: #000000'>Newcastle United</b>"")) +
  labs(title = glue::glue(
    ""<b style ='color:{home_stats$home_team_color}'>{home_stats$TEAMS}: {home_stats$GOALS} </b><b style ='color:{home_stats$home_team_color}; font-size: 20'>({home_stats$xPTS} xPTs)</b><br> <b style='color:{away_stats$away_team_color}'>{away_stats$TEAMS}: {away_stats$GOALS} </b><b style='color:{away_stats$away_team_color}; font-size: 20'>({away_stats$xPTS} xPTs)</b>""),
       subtitle = glue::glue(""{match_date} (Matchday {matchday_num})""),
       x = NULL,
       y = ""Expected Goals"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        plot.title = element_markdown(size = 40,
                                      family = ""Roboto Condensed""),
        plot.subtitle = element_markdown(size = 18, 
                                     family = ""Roboto Condensed"",
                                     color = ""grey20""),
        axis.title = element_text(size = 18, color = ""grey20""),
        axis.text = element_text(size = 16, face = ""bold""),
        panel.grid.minor.x = element_blank(),
        legend.text = element_markdown(size = 18),
        legend.position = c(0.2, 0.95),
        legend.direction = ""horizontal"",
        legend.title = element_blank()
        )

cumsum_xG_plot
```

# xG Pitch Plot

not perfect but eh, serviceable!

```{r, fig.height=8, fig.width=10}
pitch_custom <- list(
  length = 587,
  width = 373,
  penalty_box_length = 101,
  penalty_box_width = 211,
  six_yard_box_length = 31,
  six_yard_box_width = 111,
  penalty_spot_distance = 66,
  goal_width = 45,
  origin_x = 0,
  origin_y = 0
)
```

```{r, fig.height=8, fig.width=10}
df <- data.frame(x = 570, y = 190)

ggplot(df) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  geom_point(aes(x = x, y = y), 
             colour = ""red"", size = 2) +
  geom_point(x = 0, y = 0, 
             colour = ""red"", size = 2) +
  geom_point(x = 0, y = 219, 
             colour = ""red"", size = 2) +
  geom_point(x = 524, y = 186.5, 
             colour = ""blue"", size = 2) 

```

```{r}
pitch_custom2 <- list(
  length = 100,
  width = 100,
  penalty_box_length = 17,
  penalty_box_width = 58,
  six_yard_box_length = 6,
  six_yard_box_width = 26.4,
  penalty_spot_distance = 11,
  goal_width = 7.3,
  origin_x = 0,
  origin_y = 0
)
```

```{r, fig.height=8, fig.width=10}
liv_shots_data %>% 
  mutate_at(vars(X, Y, xG), ~ as.numeric(.)) %>% 
  mutate(x = X * 100,
         y = Y * 100) %>% 
  select(minute, player, result, X, x, Y, y, xG) %>% 
  ggplot() +
  annotate_pitch(dimensions = pitch_custom2) +
  theme_pitch(aspect_ratio = 800/1000) + 
  geom_point(aes(x = x, y = y, size = xG), 
             colour = ""red"", show.legend = FALSE)
```




## Liv - Ars xG plot (HOME)

```{r}
liv_shots_df <- liv_shots_data %>% 
  mutate_at(vars(X, Y, xG), ~ as.numeric(.)) %>% 
  mutate(x = X * 587,
         y = Y * 373) %>% 
  select(minute, player, result, X, x, Y, y, xG)


ggplot(liv_shots_df) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  geom_point(aes(x = x, y = y, size = xG,
                 color = result), 
             show.legend = FALSE)
```


## Ars - Liv xG plot (AWAY)

```{r}
ars_shots_df <- ars_shots_data %>% 
  mutate_at(vars(X, Y, xG), ~ as.numeric(.)) %>% 
  mutate(x = 587 - (X * 587),
         y = 373 - (Y * 373)) %>% 
  select(minute, player, result, X, x, Y, y, xG)


ggplot(ars_shots_df) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  geom_point(aes(x = x, y = y, size = xG), 
             colour = ""blue"", show.legend = FALSE)
```


# Match xG Plot

```{r}
match_shots_data_clean <- match_shots_data_clean %>% 
  mutate(x = case_when(
    h_a == ""a"" ~ 587 - (X * 587),
    h_a == ""h"" ~ X * 587,
    TRUE ~ 0),
    y = case_when(
      h_a == ""a"" ~ 373 - (Y * 373),
      h_a == ""h"" ~ Y * 373,
      TRUE ~ 0)) %>% 
  select(minute, player, team_name, 
         result, X, x, Y, y, xG) %>% 
  mutate(shot_label = glue::glue(""({minute}') {player} - {result}: {xG}""),
         result = forcats::as_factor(result)) %>% 
  mutate(result = forcats::fct_relevel(result, ""Goal"", ""On Post"",
                                       ""Saved Shot"", ""Blocked Shot"", 
                                       ""Missed Shots"", ""Own Goal"")) 
```


```{r}
match_shots_data_clean <- match_shots_data_clean %>% 
  mutate(x = case_when(
    h_a == ""a"" ~ 100 - (X * 100),
    h_a == ""h"" ~ X * 100,
    TRUE ~ 0),
    y = case_when(
      h_a == ""a"" ~ 100 - (Y * 100),
      h_a == ""h"" ~ Y * 100,
      TRUE ~ 0)) %>% 
  select(minute, player, team_name, 
         result, X, x, Y, y, xG) %>% 
  mutate(shot_label = glue::glue(""({minute}') {player} - {result}: {xG}""),
         result = forcats::as_factor(result)) %>% 
  mutate(result = forcats::fct_relevel(result, ""Goal"", ""On Post"",
                                       ""Saved Shot"", ""Blocked Shot"", 
                                       ""Missed Shots"", ""Own Goal"")) 
```




number the annotations
- label crhnoloogically in subtitle/title ggtext style

add team_stats in title?

## Liverpool Arsenal

```{r, fig.height=8, fig.width=10}
shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             size = xG, group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed"")) +
  labs(title = glue::glue(""
                          <b style ='color:#d00027'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#063672'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(color = team_name), show.legend = FALSE) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = team_name), 
      color = ""black"", stroke = 2.5,
      show.legend = FALSE, shape = 21) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Arsenal"" = ""#063672""),
    breaks = c(""Liverpool"", ""Arsenal""),
    labels = c(""<b style ='color:#d00027'>Liverpool</b>"",
               ""<b style='color: #063672'>Arsenal</b>""),
    guide = FALSE) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#063672'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))
  # geom_text_repel(data = match_shots_data_clean %>% 
  #     filter(result == ""Goal""),
  #     aes(label = shot_label), size = 4) +
  # geom_mark_circle(
  #   data = match_shots_data_clean %>% 
  #     filter(result == ""Goal"", player == ""Mohamed Salah"", minute == 48),
  #   aes(x = x, y = y, label = shot_label), 
  #   color = ""black"", size = 1) +
  # geom_mark_circle(
  #   data = match_shots_data_clean %>% 
  #     filter(result == ""Goal"", player == ""Joel Matip""),
  #   aes(x = x, y = y, label = shot_label), 
  #   color = ""black"", size = 1) +
  # geom_mark_circle(
  #   data = match_shots_data_clean %>% 
  #     filter(result == ""Goal"", player == ""Mohamed Salah"", minute == 58),
  #   aes(x = x, y = y, label = shot_label), 
  #   color = ""black"", size = 1) +
  # geom_mark_circle(
  #   data = match_shots_data_clean %>% 
  #     filter(result == ""Goal"", player == ""Lucas Torreira""),
  #   aes(x = x, y = y, label = shot_label), 
  #   color = ""black"", size = 1)

shotxG_map
```


```{r}
# cowplot::plot_grid(cumsum_xG_plot, shotxG_map,
#                    ncol = 1, align = ""hv"", axis = ""l"")
library(grid)
library(gtable)

png(filename = here::here(""Premier League 2019-2020/output/livars_plot.png""), 
    width = 1200, height = 1600, res = 144, bg = ""white"")

one <- ggplotGrob(cumsum_xG_plot)
two <- ggplotGrob(shotxG_map)

gg <- rbind(one, two, size = ""last"")
gg$widths <- unit.pmax(one$widths, two$widths)

grid.newpage()
grid.draw(gg)
dev.off()
```

```{r, fig.width=8, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livars-circlePlotONLY.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(shotxG_map)
dev.off()
```

### shapes for result

```{r, fig.height=8, fig.width=10}
shape_vals <- c(""Goal"" = ""circle filled"",
                ""Saved Shot"" = ""square filled"",
                ""Blocked Shot"" = ""diamond filled"",
                ""Missed Shot"" = ""triangle filled"")

shotxGShape_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             size = xG, group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#d00027'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#063672'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(fill = team_name, shape = result),
             color = ""black"") +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(fill = team_name, shape = result), 
      stroke = 2.5, color = ""black"",
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_shape_manual(values = shape_vals, 
                     name = ""Result"",
                     guide = guide_legend(override.aes = list(size = 5))) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_fill_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Arsenal"" = ""#063672""),
    guide = FALSE) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#063672'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxGShape_map
```

```{r, fig.width=8, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livars-shapesplot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```

```{r, fig.width=8, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livars-shapePlotONLY.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(shotxGShape_map)
dev.off()
```

### colors for result

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""#a6d96a"",
               ""Blocked Shot"" = ""#fdae61"",
               ""Missed Shot"" = ""#d7191c"")

fill_cols2 <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""orange"",
               ""Blocked Shot"" = ""grey"",
               ""Missed Shot"" = ""black"",
               ""Own Goal"" = ""#d7191c"",
               ""Shot On Post"" = ""dodgerblue"")

fill_cols3 <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""#a6d96a"",
               ""Blocked Shot"" = ""#fdae61"",
               ""Missed Shot"" = ""#d7191c"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#d00027'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#063672'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(size = xG, 
                 color = result),
             stroke = 1.5) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = result,
          size = xG), 
      stroke = 1.5,
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(values = fill_cols2, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#063672'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```



```{r, fig.width=800, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livars_shotresult_plot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```

```{r, fig.width=8, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livars-colorPlotONLY.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(shotxG_map)
dev.off()
```


### size AND alpha for xG >>> only alpha for xG

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""#a6d96a"",
               ""Blocked Shot"" = ""#fdae61"",
               ""Missed Shot"" = ""#d7191c"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#d00027'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#063672'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(alpha = xG, 
                 fill = result), size = 4,
             color = ""black"", shape = 21, stroke = 1.5) +
  scale_alpha(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_fill_manual(values = fill_cols, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#063672'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```


```{r, fig.width=8, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livars-alphaPlotONLY.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(shotxG_map)
dev.off()
```


## Burnley - Liverpool


xG per shot?
total xG?

```{r}
format(round(away_stats$xG/away_stats$SHOTS, 3))

round(away_stats$xG/away_stats$SHOTS, 2)

away_stats$xG/away_stats$SHOTS %>% round(2)
```

### original

```{r, fig.height=8, fig.width=10}
shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             size = xG, group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  labs(title = glue::glue(""
                          <b style ='color:#6C1D45'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#d00027'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(color = team_name), show.legend = FALSE) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = team_name), 
      color = ""black"", stroke = 2.5,
      show.legend = FALSE, shape = 21) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""OwnGoal""),
      aes(color = team_name), 
      color = ""black"", stroke = 2.5,
      show.legend = FALSE, shape = 21) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Burnley"" = ""#6C1D45""),
    breaks = c(""Liverpool"", ""Burnley""),
    labels = c(""<b style ='color:#d00027'>Liverpool</b>"",
               ""<b style='color: #6C1D45'>Burnley</b>""),
    guide = FALSE) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0))

shotxG_map
```

```{r}
# cowplot::plot_grid(cumsum_xG_plot, shotxG_map,
#                    ncol = 1, align = ""hv"", axis = ""l"")
library(grid)
library(gtable)

png(filename = here::here(""Premier League 2019-2020/output/burnliv_plot2.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

one <- ggplotGrob(cumsum_xG_plot)
two <- ggplotGrob(shotxG_map)

gg <- rbind(one, two, size = ""first"")
#gg$widths <- unit.pmax(one$widths, two$widths)
#gg$heights <- unit.pmax(one$heights, two$heights)

grid.newpage()
grid.draw(gg)
dev.off()
```


```{r, fig.width=800, fig.height = 10}
library(gridExtra)

png(filename = here::here(""Premier League 2019-2020/output/burnliv_plot3.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```


### shapes for result

```{r, fig.height=8, fig.width=10}
shape_vals <- c(""Goal"" = ""circle filled"",
                ""OwnGoal"" = ""asterisk"",
                ""Saved Shot"" = ""square filled"",
                ""Blocked Shot"" = ""diamond filled"",
                ""Missed Shot"" = ""triangle filled"")

shotxGShape_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             size = xG, group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#6C1D45'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#d00027'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(fill = team_name, shape = result),
             color = ""black"") +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(fill = team_name, shape = result), 
      stroke = 2.5, color = ""black"",
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_shape_manual(values = shape_vals, 
                     name = ""Result"",
                     guide = guide_legend(override.aes = list(size = 5))) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_fill_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Burnley"" = ""#6C1D45""),
    guide = FALSE) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#6C1D45'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxGShape_map
```

```{r, fig.width=800, fig.height = 10}
library(gridExtra)

png(filename = here::here(""Premier League 2019-2020/output/burnliv_shotresultplot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxGShape_map)
dev.off()
```

### colors for result

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols2 <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""orange"",
               ""Blocked Shot"" = ""grey"",
               ""Missed Shot"" = ""black"",
               ""Own Goal"" = ""#d7191c"",
               ""Shot On Post"" = ""dodgerblue"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#6C1D45'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#d00027'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(size = xG, 
                 color = result),
             stroke = 1.5) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = result,
          size = xG), 
      stroke = 1.5,
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(values = fill_cols2, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#6C1D45'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```

```{r, fig.width=800, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/burnliv_shotresult_plot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```

### size AND alpha for xG >>> only alpha for xG

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""#a6d96a"",
               ""Blocked Shot"" = ""#fdae61"",
               ""Missed Shot"" = ""#d7191c"",
               ""OwnGoal"" = ""darkred"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#6C1D45'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#d00027'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(alpha = xG, 
                 fill = result), size = 4,
             color = ""black"", shape = 21, stroke = 1.5) +
  scale_alpha(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_fill_manual(values = fill_cols, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#6C1D45'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```


```{r, fig.width=800, fig.height = 10}
library(gridExtra)

png(filename = here::here(""Premier League 2019-2020/output/burnliv_shotresultAlphaplot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```










## Liverpool - Norwich

### original

```{r, fig.height=8, fig.width=10}
shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             size = xG, group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0)) +
  labs(title = glue::glue(""
                          <b style ='color:#d00027'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#00a650'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(color = team_name), show.legend = FALSE) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = team_name), 
      color = ""black"", stroke = 2.5,
      show.legend = FALSE, shape = 21) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""OwnGoal""),
      aes(color = team_name), 
      color = ""black"", stroke = 2.5,
      show.legend = FALSE, shape = 21) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#d00027"",
               ""Norwich"" = ""#00a650""),
    breaks = c(""Liverpool"", ""Norwich""),
    labels = c(""<b style ='color:#d00027'>Liverpool</b>"",
               ""<b style='color: #00a650'>Norwich</b>""),
    guide = FALSE) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#00a650'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```


```{r, fig.width=800, fig.height = 10}
library(grid)
library(gridExtra)

png(filename = here::here(""Premier League 2019-2020/output/livnor_shotresultplot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```


### colors for result

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols2 <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""orange"",
               ""Blocked Shot"" = ""grey"",
               ""Missed Shot"" = ""black"",
               ""Own Goal"" = ""#d7191c"",
               ""On Post"" = ""dodgerblue"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#d00027'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#00a650'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(size = xG, 
                 color = result),
             stroke = 1.5) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = result,
          size = xG), 
      stroke = 1.5,
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(values = fill_cols2, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#00a650'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```



```{r, fig.width=800, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livnor_shotresult_plot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols2 <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""orange"",
               ""Blocked Shot"" = ""grey"",
               ""Missed Shot"" = ""black"",
               ""Own Goal"" = ""#d7191c"",
               ""On Post"" = ""dodgerblue"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom2) +
  theme_pitch(aspect_ratio = 900/1100) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#d00027'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#00a650'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(size = xG, 
                 color = result),
             stroke = 1.5) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = result,
          size = xG), 
      stroke = 1.5,
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(values = fill_cols2, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 75.25, y = 10, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#d00027'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 25.75, y = 10, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#00a650'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```


## Southampton - Liverpool


```{r, fig.height=8, fig.width=10}
shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             size = xG, group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  labs(title = glue::glue(""
                          <b style ='color:#ed1a3b'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#000000'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(color = team_name), show.legend = FALSE) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = team_name), 
      color = ""black"", stroke = 2.5,
      show.legend = FALSE, shape = 21) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""OwnGoal""),
      aes(color = team_name), 
      color = ""black"", stroke = 2.5,
      show.legend = FALSE, shape = 21) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(
    values = c(""Liverpool"" = ""#000000"",
               ""Southampton"" = ""#ed1a3b""),
    breaks = c(""Liverpool"", ""Southampton""),
    labels = c(""<b style ='color:#000000'>Liverpool</b>"",
               ""<b style='color:#ed1a3b'>Southampton</b>""),
    guide = FALSE) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0))

shotxG_map
```

```{r, fig.width=800, fig.height = 10}
library(grid)
library(gridExtra)

png(filename = here::here(""Premier League 2019-2020/output/sotliv_plot1.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```

### alpha = xG

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""#a6d96a"",
               ""Blocked Shot"" = ""#fdae61"",
               ""Missed Shot"" = ""#d7191c"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             size = xG, group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#ed1a3b'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#000000'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(alpha = xG, 
                 fill = result), size = 4,
             color = ""black"", shape = 21, stroke = 1.5) +
  scale_alpha(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_fill_manual(values = fill_cols, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#ed1a3b'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#000000'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```



```{r, fig.width=800, fig.height = 10}
library(grid)
library(gridExtra)

png(filename = here::here(""Premier League 2019-2020/output/sotliv_shotresultplot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```


### colors for result

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols2 <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""orange"",
               ""Blocked Shot"" = ""grey"",
               ""Missed Shot"" = ""black"",
               ""Own Goal"" = ""#d7191c"",
               ""Shot On Post"" = ""dodgerblue"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:#ed1a3b'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:#000000'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(size = xG, 
                 color = result),
             stroke = 1.5) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = result,
          size = xG), 
      stroke = 1.5,
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(values = fill_cols2, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#ed1a3b'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 10,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:#000000'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```



```{r, fig.width=8, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/sotliv_shotresult_plot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```



## Liverpool - Newcastle




### colors for result

```{r, fig.height=8, fig.width=10}
# http://colorbrewer2.org/#type=diverging&scheme=RdYlGn&n=4
fill_cols2 <- c(""Goal"" = ""#1a9641"",
               ""Saved Shot"" = ""orange"",
               ""Blocked Shot"" = ""grey"",
               ""Missed Shot"" = ""black"",
               ""Own Goal"" = ""#d7191c"",
               ""On Post"" = ""#004CFF"")

shotxG_map <- match_shots_data_clean %>% 
  ggplot(aes(x = x, y = y, 
             group = team_name)) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 373/587) +
  theme(plot.title = element_markdown(family = ""Roboto Condensed"", 
                                      size = 20, hjust = 0.5),
        plot.caption = element_text(family = ""Roboto Condensed"",
                                    size = 14, hjust = 0),
        text = element_markdown(family = ""Roboto Condensed""),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12),
        legend.key = element_blank(),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"") +
  labs(title = glue::glue(""
                          <b style ='color:{home_stats$home_team_color}'>{home_stats$TEAMS}</b> | Shots: {home_stats$SHOTS} | On Target: {home_stats$`ON-TARGET`} | xG per Shot: {round(home_stats$xG/home_stats$SHOTS, 2)}<br>
                          <b style='color:{away_stats$away_team_color}'>{away_stats$TEAMS}</b> | Shots: {away_stats$SHOTS} | On Target: {away_stats$`ON-TARGET`} | xG per Shot: {round(away_stats$xG/away_stats$SHOTS, 2)}""),
       caption = "" @R_by_Ryo                                                                                                                                                             Data: understat.com"") +
  geom_point(aes(size = xG, 
                 color = result),
             stroke = 1.5) +
  geom_point(data = match_shots_data_clean %>% 
      filter(result == ""Goal""),
      aes(color = result,
          size = xG), 
      stroke = 1.5,
      show.legend = FALSE) +
  scale_size(guide = FALSE) +
  scale_x_continuous(expand = c(0.01, 0)) +
  scale_color_manual(values = fill_cols2, name = ""Result"",
                    guide = guide_legend(override.aes = list(size = 4.55))) +
  ## Home
  geom_rich_text(x = 440.25, y = 50, 
            color = ""grey20"", size = 8,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:{home_stats$home_team_color}'>{home_stats$TEAMS}</b>: {home_stats$xG} xG"")) +
  ## Away
  geom_rich_text(x = 146.75, y = 50, 
            color = ""grey20"", size = 8,
            fill = NA, label.color = NA,
            label = glue::glue(""<b style ='color:{away_stats$away_team_color}'>{away_stats$TEAMS}</b>: {away_stats$xG} xG""))

shotxG_map
```



```{r, fig.width=800, fig.height = 10}
png(filename = here::here(""Premier League 2019-2020/output/livnew_shotresult_plot.png""), 
    width = 1600, height = 2000, res = 144, bg = ""white"")

grid.newpage()
grid.arrange(cumsum_xG_plot, shotxG_map)
dev.off()
```












# roster data

```{r}
match_squad_data <- get_data_element(match_data, ""rostersData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_squad_data <- fix_json(match_squad_data)

# Home: Liverpool
liv_squad_data <- fromJSON(match_squad_data[1])

## add 'team_name' with home team name from 'h_team' var

# Away: Arsenal
ars_squad_data <- fromJSON(match_squad_data[2])

## add 'team_name' with away team name from 'a_team' var
```



# Season Matches


```{r}
team_name <- ""Liverpool""
season <- 2018
season_url <- stringr::str_glue(""{home_url}/team/{team_name}/{season}"")

season_url %>% 
  read_html() %>% 
  html_nodes(xpath = '//*[contains(concat( "" "", @class, "" "" ), concat( "" "", ""match-info"", "" "" ))]')


  html_nodes(""match-info"") %>% 
  html_attr(""href"")

```


```{r}
liv <- get_team_meta(""Liverpool"")

liv
```



```{r}
season_url %>% 
  read_html() %>% 
  html_nodes(""div.calendar-date-container"")


season_url %>% 
  read_html() %>% 
  html_nodes(""a"")

""div.calendar-date-container:nth-child(5) > div:nth-child(2) > div:nth-child(1) > a:nth-child(1)""


""div.calendar-date-container:nth-child(5) > div:nth-child(2) > div:nth-child(1) > a:nth-child(1)""
```


```{r}
season_url %>% 
  read_html() %>% 
  print(width = 50000000)
```

","2019"
"68",235,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2019-2020/premier_league_website_data.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""8/24/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse,
               rvest, polite, lubridate)

library(tidyverse)
```




```{r}
url <- ""https://www.premierleague.com/clubs/10/Liverpool/results?se=210""

.tabbedContent > div:nth-child(1) > div:nth-child(5) > section:nth-child(1)
div.fixtures__matches-list:nth-child(3) > ul:nth-child(2) > li:nth-child(1)


session <- bow(url)

prem_df_raw <- scrape(session) %>% 
  html_nodes("".tabbedContent"") %>% 
  html_text()


prem_df_raw <- scrape(session) %>% 
  html_nodes("".shortname"") %>% 
  html_text()

```




```{r}
library(understatr)

bobby_shots <- get_player_shots(482)
```

IMG size: Width = 878, Height = 542
Pitch size: 
- Width:20 >   pitch < 20
- Height: 20 from Top > pitch 

x == y (from bottom to up)

y == x (from right to left)

ex. ShotOnPost, Header, Minute 60, xG = 0.1485... (Mainz vs. Hoff) 2014

x: 0.987	y: 0.382	

is actually:
y: 98.7% from BOTTOM  (542 * 0.987)   534.954
x: 38.2% from RIGHT   (878 * 0.382)   335.396

BUT from LEFT so need to...

x: 878 - 335.396 == 542.604
y: 534.954


total HEIGHT: 542 * 2 == 1084

box width 685-192 == 493

box length 245 - 21 == 224

pen spot: 171 - 21 == 150

goal width: 488 - 389 == 99

six length: 94 - 21 == 73
six width: 562 - 315 == 247
```{r, fig.height=8, fig.width=10}
library(ggsoccer)
library(ggplot2)

pitch_custom <- list(
  length = 1084,
  width = 878,
  penalty_box_length = 224,
  penalty_box_width = 493,
  six_yard_box_length = 73,
  six_yard_box_width = 247,
  penalty_spot_distance = 150,
  goal_width = 99,
  origin_x = 0,
  origin_y = 0
)

df <- data.frame(x = 1042.604, y = 534.604)

ggplot(df) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 878/1084) +
  coord_flip(xlim = c(550, 1085),
              ylim = c(-1, 880)) +
  geom_point(aes(x = x, y = y), shape = 21,
             fill = ""red"",
             colour = ""red"", size = 5) +
  geom_point(x = 1080, y = 850)


ggplot(df) +
  annotate_pitch(dimensions = pitch_custom) +
  theme_pitch(aspect_ratio = 878/1284) +
  geom_point(x = 0, y = 0) +
  geom_point(x = 600, y = 878)
```



```{r}
shots <- data.frame(x = c(90, 85, 82, 78, 83, 74, 94, 91),
                    y = c(43, 40, 52, 56, 44, 71, 60, 54))

ggplot(shots) +
  annotate_pitch(colour = ""white"",
                 fill   = ""chartreuse4"",
                 limits = FALSE) +
  geom_point(aes(x = x, y = 100 - y),
             colour = ""yellow"", 
             size = 4) +
  theme_pitch() +
  theme(plot.background = element_rect(fill = ""chartreuse4""),
        title = element_text(colour = ""white"")) +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  ggtitle(""Simple shotmap"",
          ""ggsoccer example"")
```



```{r}
library(stringi)
library(jsonlite)
library(stringr)
library(xml2)
library(qdapRegex)
```



```{r}
get_script <- function(x) {
  as.character(html_nodes(x, ""script""))
}

# subset data element of html page
get_data_element <- function(x, element_name) {
  stri_unescape_unicode(str_subset(x, element_name))
}

# fix json element for parsing
fix_json <- function(x) {
  str_subset(
    unlist(
      rm_square(
        x, extract = TRUE, include.markers = TRUE
      )
    ),
    ""\\[\\]"", negate = TRUE
  )
}

# get player name part of html page
get_player_name <- function(x) {

  player_name <- html_nodes(x, "".header-wrapper:first-child"")
  trimws(html_text(player_name))
}
```





```{r}
home_url <- ""https://understat.com""
match_id <- 11670
player_id <- 482
```



```{r}
player_url <- str_glue(""{home_url}/player/{player_id}"")

# read player page
player_page <- read_html(player_url)

# locate script tags
player_data <- get_script(player_page)

# isolate player data
player_data <- get_data_element(player_data, ""shotsData"")

# pick out JSON string
player_data <- fix_json(player_data)

# parse JSON
player_data <- fromJSON(player_data)
```


## xG data

```{r}
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- read_html(match_url)

match_data <- get_script(match_page)

match_shots_data <- get_data_element(match_data, ""shotsData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_shots_data <- fix_json(match_shots_data)

# Home: Liverpool
liv_shots_data <- fromJSON(match_shots_data[1])

## add 'team_name' with home team name from 'h_team' var

# Away: Arsenal
ars_shots_data <- fromJSON(match_shots_data[2])

## add 'team_name' with away team name from 'a_team' var
```


## roster data

```{r}
match_squad_data <- get_data_element(match_data, ""rostersData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_squad_data <- fix_json(match_squad_data)

# Home: Liverpool
liv_squad_data <- fromJSON(match_squad_data[1])

## add 'team_name' with home team name from 'h_team' var

# Away: Arsenal
ars_squad_data <- fromJSON(match_squad_data[2])

## add 'team_name' with away team name from 'a_team' var
```






## Match Summary Stats

```{r}
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- read_html(match_url)

team_stats <- match_page %>% 
  html_nodes(""div.scheme-block:nth-child(4)"") %>% 
  html_text() %>% 
  str_remove_all(., ""CHANCES"") %>% 
  str_remove_all(., ""([0-9]{2,}%)"") %>% 
  str_replace_all(., ""SHOTS ON TARGET"", ""ON-TARGET"") %>% #trimws() %>% 
  str_squish() %>% 
  read.table(text = ., header = FALSE, sep = "" "",
             col.names = c(""var_name"", ""home"", ""away"")) %>% 
  t() %>% 
  tibble::as_tibble() %>% 
  janitor::row_to_names(row_number = 1)
  
  
  # rownames_to_column() %>% 
  # gather(key = var, value = thing, -rowname) %>% 
  # spread(rowname, thing)
  # 
  # 
  # t() %>% 
  # 
  # tibble::as_tibble()
  # tidyr::pivot_longer(names_to = )
```




```{r}
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- read_html(match_url)

team_stats <- match_page %>% 
  html_nodes(""div.scheme-block:nth-child(4)"") %>% 
  html_text()
#match-rosters > table:nth-child(3) #match-rosters > table:nth-child(3)
#match-rosters > table:nth-child(3) > tbody:nth-child(2)


stats_string <- team_stats %>% str_squish()
#  str_remove_all(., ""\\n|\\t"")
  # str_replace_all(., ""\\n|\\t"", "" "") %>%
  # str_squish()

stats_string %>% 
  str_remove_all(., ""CHANCES"") %>% 
  str_remove_all(., ""([0-9]{2,}%)"") %>% 
  str_replace_all(., ""SHOTS ON TARGET"", ""ON-TARGET"") %>% 
  str_squish() %>% 
  read.table(text = ., header = FALSE, sep = "" "", 
             col.names = c(""TEAMS"", ""GOALS"", ""xG"",
                           ""SHOTS"", ""ON-TARGET"", ""DEEP"",
                           ""PPDA"", ""xPTS""))
  

team_stats %>%
  str_squish() %>% 
  str_remove_all(., ""CHANCES"") %>% 
  str_remove_all(., ""([0-9]{2,}%)"") %>% 
  str_replace_all(., ""SHOTS ON TARGET"", ""ON-TARGET"") %>% 
  str_squish() %>% 
  read.table(text = ., header = FALSE, sep = "" "",
             col.names = c(""var_name"", ""home"", ""away""))




  
asdf <- stats_string %>% 
  str_remove_all(., ""CHANCES"") %>% 
  str_remove_all(., ""([0-9]{2,}%)"") %>% 
  str_replace_all(., ""SHOTS ON TARGET"", ""ON-TARGET"") %>% 
  str_squish()

asdf %>% strsplit(split = "" "")


  
stats_string %>% 
  read.table(text = ., header = FALSE, sep = "" "",
             col.names = c(""TEAMS"", ""CHANCES"", ""GOALS"", ""xG"",
                           ""SHOTS"", ""SHOTS ON TARGET"", ""DEEP"",
                           ""PPDA"", ""xPTS""))


all <- match_page %>% 
  html_nodes(""div.scheme-block:nth-child(4)"") %>% 
  .[[1]]

print(all, width = 50000)
print(team_stats, width = 50000)
print(stats_string, width = 50000)

asdf
```






```{r}
xml <- all %>% xml_find_all()
```














```{r}
library(XML)

all2 <- xmlTreeParse(all, asText = TRUE, useInternalNodes = TRUE)

m <- xpathSApply(all, ""//div[@class = 'scheme-block is-hide'"", function(node) {
  list(p = xmlValue(node[[""progress-title""]]))
})
```











```{r}
do.call(rbind, lapply(all, function(x) {
  title <- tryCatch(xml_text(xml_node(x, ""div.progress-title"")))
  
  value <- tryCatch(xml_text(xml_node(x, ""div.progress-home progress-over"")))
  
  data.frame(title, value, stringsAsFactors = FALSE)
}))
```

","2019"
"69",236,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Premier League 2019-2020/premierleague1920.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""10/15/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               understatr,
               jsonlite, xml2, qdapRegex, stringi, stringr,
               rvest, glue, extrafont, ggrepel, magick, ggtext)
loadfonts(quiet = TRUE)
```

# Premier League

```{r}
premierleague1920 <- get_league_teams_stats(""EPL"", 2018)
```

```{r}
premierleagueklopp_raw <- map(c(2015:2019), 
                          ~ get_league_teams_stats(""EPL"", .x)) %>% bind_rows()

premierleagueklopp_clean <- premierleagueklopp_raw %>% 
  bind_rows() %>% 
  filter(team_name == ""Liverpool"") %>% 
  mutate(game_num = row_number(),
         manager = case_when(
    game_num %in% c(1:8) ~ ""Brendan Rodgers"",
    TRUE ~ ""Jrgen Klopp"")) %>% 
  mutate(rollxpts = rolling_sum(xpts),
         rollxG = rolling_sum(xG),
         rollxGA = rolling_sum(xGA),
         sumpts = cumsum(pts),
         sumxpts = cumsum(xpts),
         season = glue(""{year}-{year+1}"")) %>% 
  group_by(season) %>% 
  mutate(match_num = row_number()) %>% 
  ungroup() %>% 
  select(game_num, season, match_num, manager,
         h_a, result, xG, scored, rollxG, 
         xGA, rollxGA, missed, 
         pts, xpts, sumpts, sumxpts, rollxpts)
```

```{r}
saveRDS(premierleagueklopp_raw,
        here::here(""data/premierleague_1516_1920_results.RDS""))

saveRDS(premierleagueklopp_clean, 
        here::here(""data/premierleague_klopp_results.RDS""))
```

```{r}
premierleagueklopp_raw <- readRDS(here::here(""data/premierleague_1516_1920_results.RDS""))

premierleagueklopp_clean <- readRDS(here::here(""data/premierleague_klopp_results.RDS""))
```


```{r}
rolling_sum <- tibbletime::rollify(.f = mean, window = 5)

lfc1920 <- premierleague1920 %>% 
  filter(team_name == ""Liverpool"") %>% 
  mutate(rollxpts = rolling_sum(xpts),
         rollxG = rolling_sum(xG),
         rollxGA = rolling_sum(xGA),
         sumpts = cumsum(pts),
         sumxpts = cumsum(xpts),
         game_num = row_number(),
         season = glue(""{year}-{year+1}"")) %>% 
  select(game_num, season, h_a, result, xG, scored, rollxG, xGA, rollxGA,
         missed, pts, xpts, 
         sumpts, sumxpts, rollxpts)

glimpse(lfc1920)
```



```{r}
premierleagueklopp_clean %>% 
  ggplot(aes(game_num, rollxpts)) +
  geom_line() +
  theme_minimal()

premierleagueklopp_clean %>% 
  ggplot(aes(game_num, xG)) +
  geom_line() +
  theme_minimal()

premierleagueklopp_clean %>% 
  ggplot(aes(game_num, rollxGA)) +
  geom_line() +
  theme_minimal()
```




```{r}
coef(lm(rollxG ~ game_num, data = premierleagueklopp_clean))
coef(lm(rollxGA ~ game_num, data = premierleagueklopp_clean))

premierleagueklopp_clean %>% 
  ggplot(aes(game_num)) +
  geom_line(aes(y = rollxG, color = ""rollxG""), size = 1.25) +
  geom_line(aes(y = rollxGA, color = ""rollxGA""), size = 1.25) +
  geom_abline(intercept = 1.448527732, slope = 0.004819968,
              color = ""darkgreen"") +
  geom_abline(intercept = 1.071953995, slope = -0.001729413,
              color = ""red"") +
  scale_x_continuous(limits = c(0, NA),
                     expand = c(0, 0),
                     breaks = c(1, 38, 39, 76, 77, 114),
                     labels = c(""1"", ""38"", ""1"", ""38"", ""1"", ""38"")) +
  scale_y_continuous(breaks = scales::pretty_breaks()) +
  scale_color_manual(values = c(""rollxG"" = ""darkgreen"", 
                                ""rollxGA"" = ""red""),
                     labels = c(""Rolling xG"", ""Rolling xGA""),
                     name = """") +
  labs(title = ""Five-Game Rolling xG & xGA from 2015/2016 Season to Present"",
       subtitle = """",
       caption = """",
       x = ""Games from Beginning of 2015/2016 Season"",
       y = ""Expected Goals"") +
  theme_minimal() +
  theme(legend.position = c(0.125, 0.95))
```

- divide by season along x-axis, labels in middle of season with `YEAR/YEAR`
- vertical line separate seasons as well


Goal difference <> xG difference

```{r}
rolling_mean <- tibbletime::rollify(.f = mean, window = 5)


plklopp_clean <- premierleagueklopp_clean %>% 
  mutate(GD = scored - missed, 
         xGD = xG - xGA) %>% 
  mutate(rollGD = rolling_mean(GD),
         rollxGD = rolling_mean(xGD))

premierleagueklopp_xg <- plklopp_clean %>% 
  filter(rollxGD >= rollGD)

premierleagueklopp_gd <- plklopp_clean %>% 
  filter(rollGD >= rollxGD)


ggplot(plklopp_clean,
       aes(x = game_num)) +
  geom_line(aes(y = rollGD), color = ""green"") +
  geom_line(aes(y = rollxGD), color = ""blue"") +
  geom_ribbon(data = premierleagueklopp_xg, 
              aes(ymin = rollxGD, ymax = rollGD), fill = ""blue"") +
  geom_hline(yintercept = 0, size = 1.5)
```




## Aston Villa

```{r}
get_script <- function(x) {
  as.character(html_nodes(x, ""script""))
}

# subset data element of html page
get_data_element <- function(x, element_name) {
  stri_unescape_unicode(str_subset(x, element_name))
}

# fix json element for parsing
fix_json <- function(x) {
  str_subset(
    unlist(
      rm_square(
        x, extract = TRUE, include.markers = TRUE
      )
    ),
    ""\\[\\]"", negate = TRUE
  )
}

fix_json2 <- function(x) {
  str_subset(
    unlist(
      rm_curly(
        x, extract = TRUE, include.markers = TRUE
      )
    ),
    ""\\[\\]"", negate = TRUE
  )
}


# get player name part of html page
get_player_name <- function(x) {

  player_name <- html_nodes(x, "".header-wrapper:first-child"")
  trimws(html_text(player_name))
}
```

```{r}
url <- ""https://understat.com/team/Liverpool/2019""

team_page <- polite::bow(url)

team_data <- polite::scrape(team_page) %>% 
  get_script()

team_situation_data <- get_data_element(team_data, ""statisticsData"")




team_situation_data <- fix_json2(team_situation_data)

paste(team_situation_data, collapse = ""}'"", sep = "","") -> team_situa11

paste0(""["", team_situa11, ""]"") %>% fromJSON()

team_situation_data_df <- fromJSON(team_situation_data)

fromJSON(team_situation_data, flatten = TRUE)

team_situation_datafixed <- str_subset(unlist(rm_square(team_situation_data, include.markers = TRUE, extract = TRUE)), ""\\[\\]"", negate = TRUE)

team_situation_data_df <- fromJSON(team_situation_datafixed)


team_situation_data2 <- get_data_element(team_data, ""datesData"")

team_situation_data2 <- fix_json(team_situation_data2)

team_player_data <- fromJSON(team_situation_data2)
```




```{r}
home_url <- ""https://understat.com""
match_id <- 11643
match_url <- stringr::str_glue(""{home_url}/match/{match_id}"")

match_page <- polite::bow(match_url)

match_data <- polite::scrape(match_page) %>% 
  get_script()

match_shots_data <- get_data_element(match_data, ""shotsData"")

#msd <- jsonlite::stream_in(match_shots_data)

match_shots_data2 <- fix_json(match_shots_data)

# Home: Liverpool
liv_shots_data <- fromJSON(match_shots_data2[1])
```








```{r}
url <- ""https://understat.com/team/Liverpool/2019""

team_page <- polite::bow(url)

team_data <- polite::scrape(team_page) %>% 
  html_nodes(""#team-statistics > table:nth-child(3) > tbody:nth-child(2)"") %>% 
  html_table()
```


## game state

```{r}
url <- ""https://understat.com/team/Liverpool/2019""

team_page <- polite::bow(url)

team_data <- polite::scrape(team_page) %>% 
  get_script()

team_situation_data <- get_data_element(team_data, ""statisticsData"")

team_situation_data %>% 
  str_replace(., ""\\{\""situation\"""",  ""[\\{\""situation\"""") %>% 
  str_replace(., ""\\}'\\)"", ""\\}]'\\)"") %>% 
  fix_json() %>% 
  fromJSON() %>% #purrr::flatten() 
  .[3] %>% 
  unlist() %>% 
  enframe() -> gamestate_df

gamestate_df %>% 
  mutate(name2 = str_replace(name, ""([^0-9]*)"", """"),
         name3 = str_replace(name, ""\\..*?\\."", """"),
         name4 = str_replace(name, ""([^\\+<>-]*)"", """"))
```

## by minutes

```{r}
team_situation_data %>% 
  str_replace(., ""\\{\""situation\"""",  ""[\\{\""situation\"""") %>% 
  str_replace(., ""\\}'\\)"", ""\\}]'\\)"") %>% 
  fix_json() %>% 
  fromJSON() %>% #purrr::flatten() 
  .[4] %>% 
  unlist() %>% 
  enframe() -> minutes_df


minutes_df_clean <- minutes_df %>% 
  mutate(name = str_replace(name, ""against."", ""against-"")) %>% 
  separate(name, c(""timing"", ""minutes"", ""metric""), sep = ""\\."", extra = ""merge"") %>% 
  select(-timing) %>% 
  filter(metric != ""stat"")

glimpse(minutes_df_clean)
```

```{r}
minutes_df_clean %>% 
  #filter(metric == ""shots"") %>% 
  ggplot(aes(x = minutes, y = value)) + 
  geom_point(color = ""red"", size = 2.5) + 
  geom_line(aes(group = metric)) +
  theme_minimal() +
  facet_wrap(""metric"", scales = ""free_y"")
```


```{r}
minutes_df_clean %>% 
  filter(metric == ""shots"" |
         metric == ""against-shots"") %>% 
  ggplot() + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""shots""),
             aes(x = minutes, y = value),
             color = ""blue"", size = 2.5) + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""against-shots""),
             aes(x = minutes, y = value),
             color = ""red"", size = 2.5) + 
  geom_line(aes(x = minutes, y = value, group = metric)) +
  labs(title = ""Shots/Shots Against by Time"") +
  theme_minimal()
```




```{r}
minutes_df_clean %>% 
  filter(metric == ""xG"" |
         metric == ""against-xG"") %>% 
  ggplot() + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""xG""),
             aes(x = minutes, y = value),
             color = ""blue"", size = 2.5) + 
  geom_point(data = minutes_df_clean %>% 
               filter(metric == ""against-xG""),
             aes(x = minutes, y = value),
             color = ""red"", size = 2.5) + 
  geom_line(aes(x = minutes, y = value, group = metric)) +
  labs(title = ""xG/xGA by Time"") +
  theme_minimal()
```

per shot is probably more informative









```{r}
url <- ""https://understat.com/team/Liverpool/2019""

team_page <- polite::bow(url)

team_data <- polite::scrape(team_page) %>% 
  get_script()

team_situation_data <- get_data_element(team_data, ""statisticsData"")

## save 
write_json(team_situation_data, path = here::here(""data/team_situation_data.json""))

## edit in notepad++ [ and ] so begininig/end look like: '[{\""     \""}]'

team_thingy <- read_json(path = here::here(""data/team_situation_data.json"")) %>% unlist()

team_thingy2 <- fix_json(team_thingy)

team_thingy_DF <- fromJSON(team_thingy2)


team_thingy_DF %>% 
  select(contains(""situation"")) %>% 
  unlist() %>% 
  enframe() %>% 
  mutate(name = str_replace(name, ""situation."", """"),
         perGame = value / 11)
```

","2019"
"70",237,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Serie A 2018-2019/player_goal_contribution_matrix.Rmd","---
title: ""Serie A""
author: ""RN7""
date: ""5/24/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# pkgs

```{r, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce,
               rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```

## add_logo

```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))
}
```

# Serie A

## webscrape soccerway

```{r}
url <- ""https://us.soccerway.com/national/italy/serie-a/20182019/regular-season/r48235/""

session <- bow(url)

team_links <- scrape(session) %>% 
  html_nodes(""#page_competition_1_block_competition_tables_7_block_competition_league_table_1_table .large-link a"") %>% 
  html_attr(""href"")

team_links_df <- team_links %>% 
  enframe(name = NULL) %>% 
  separate(value, c(NA, NA, NA, ""team_name"", ""team_num""), sep = ""/"") %>% 
  mutate(link = glue(""
                     https://us.soccerway.com/teams/italy/{team_name}/{team_num}/squad/""),
         stat_link = glue(""{link %>% str_replace('squad', 'statistics')}""))

# for each team link:

player_name_info <- function(session) {
  
  player_name_info <- scrape(session) %>% 
    html_nodes(""#page_team_1_block_team_squad_3-table .name.large-link"") %>% 
    html_text()
}

num_goals_info <- function(session) {

  num_goals_info <- scrape(session) %>% 
    html_nodes("".goals"") %>% 
    html_text()
  
  num_goals_info_clean <- num_goals_info[-1]
}

num_assists_info <- function(session) {

  num_assists_info <- scrape(session) %>% 
    html_nodes("".assists"") %>% 
    html_text()
  
  num_assists_info_clean <- num_assists_info[-1]
}

team_goals_info <- function(session) {
  team_goals_info <- scrape(session) %>% 
    html_nodes(""tr.first:nth-child(6) > td:nth-child(2)"") %>% 
    html_text()
}

# BIG FUNCTION
serieA_stats_info <- function(link, statlink) {
  
  session <- bow(link)
  session2 <- bow(statlink)
  
  player_name <- player_name_info(session = session)

  num_goals <- num_goals_info(session = session)

  num_assists <- num_assists_info(session = session)
  
  team_goals <- team_goals_info(session = session2)
  
  resultados <- list(player_name, num_goals, num_assists, team_goals)
  col_names <- c(""name"", ""goals"", ""assists"", ""team_goals"") 
  
  serieA_stats <- resultados %>% 
    reduce(cbind) %>% 
    as_tibble() %>% 
    set_names(col_names) 
}
```

### all at once

```{r}
# ALL 18 TEAMS AT ONCE, WILL TAKE A WHILE:
serieA_goal_contribution_df_ALL <- map2(.x = team_links_df$link,
                .y = team_links_df$stat_link,
                ~ serieA_stats_info(link = .x, statlink = .y))

serieA_goal_contribution_df <- serieA_goal_contribution_df_ALL %>% 
  set_names(team_links_df$team_name) %>% 
  bind_rows(.id = ""team_name"")

## save
saveRDS(serieA_goal_contribution_df, file = glue(""{here::here()}/data/serieA_goal_contrib_df_soccerway.RDS""))
```

## clean

```{r}
serieA_goal_contribution_clean_df <- serieA_goal_contribution_df %>% 
  mutate_at(.vars = c(""goals"", ""assists""), 
            ~str_replace(., ""-"", ""0"") %>% as.numeric) %>% 
  mutate(team = team_name %>% str_replace_all(., ""-"", "" "") %>% str_to_title,
         total_goals = as.numeric(team_goals)) %>% 
  group_by(team) %>% 
  mutate(total_assists = sum(assists),
         goal_contrib = goals/total_goals,
         ## as/tot_goals because looking at perspective of contrib to goals.
         ## Will be an underestimation as not all goals have assists.
         ## a.k.a. not looking at % of club assists assisted but % of club goals assisted
         assist_contrib = assists/total_goals) %>% 
  ungroup() %>% 
  select(-team_name, -team_goals)

## save
saveRDS(serieA_goal_contribution_clean_df, 
        file = glue(""{here::here()}/data/serieA_goal_contrib_clean_df.RDS""))
serieA_goal_contribution_clean_df <- readRDS(file = glue(""{here::here()}/data/serieA_goal_contrib_clean_df.RDS""))
```

## plot

- 
-
-

```{r fig.width = 10, fig.height = 8}  
## Description text
## Fabio Quagliarella: The Old Fox in the Box
## 34% from penalties (9/26)
desc_quagliarella <- ""With only 1 of his 26 goals coming from outside the box, Quagliarella maintained Sampdoria's   stability    in midtable position   ...""

## Jony   xA90 of 0.29 (tied 3rd highest, minimum 30 games)
desc_jony <- ""With 10 assists amounting to 34% of Alavs' xA, Jony had his career-best season as he helped Alavs contend for a European place.""

## Messi
desc_goat <- ""With total contribution nearly double of the next best, 36 Goals from a xG of 26, etc. Messi led almost every metric in La Liga this season!""

## PLOT!
serieA_goal_contribution_clean_df %>% 
  ggplot(aes(assist_contrib, goal_contrib)) +
  geom_point(data = serieA_goal_contribution_clean_df %>%
                    filter(goal_contrib < 0.15 | assist_contrib < 0.125),
             color = ""grey20"", size = 4, alpha = 0.2) +
  geom_point(data = serieA_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.15 | assist_contrib > 0.125),
             color = ""red"", size = 4) +
  geom_hline(yintercept = 0.15, color = ""grey20"", alpha = 0.4) +
  geom_vline(xintercept = 0.125, color = ""grey20"", alpha = 0.4) +
  geom_text_repel(data = serieA_goal_contribution_clean_df %>%
                    filter(goal_contrib > 0.15 | assist_contrib > 0.125,
                           !name %in% c(""Iago Aspas"", ""L. Messi"", 
                                        ""Jony"", ""Pablo Sarabia"")),
                  aes(label = name, family = ""Roboto Condensed"", fontface = ""bold""), 
                  seed = 15, size = 4, 
                  min.segment.length = 0, segment.color = ""red"",
                  point.padding = 0.5) +
  geom_mark_circle(aes(filter = name == ""L. Messi"", 
                       label = ""Lionel Messi: GOAT"",
                        description = desc_goat),
                    label.family = ""Roboto Condensed"", label.fontsize = c(16, 12)) +
  geom_mark_circle(aes(filter = name == ""Iago Aspas"", 
                     label = ""Iago Aspas: The Hero of Vigo"",
                        description = desc_aspas),
                    label.buffer = unit(10, ""mm""), label.fontsize = c(16, 12),
                    label.family = ""Roboto Condensed"") +
  geom_mark_circle(aes(filter = name == ""Jony"", 
                       label = ""Jony: El Glorioso"", 
                       description = desc_jony),
                   label.buffer = unit(5, ""mm""), label.fontsize = c(16, 12),
                   label.family = ""Roboto Condensed"") +
  scale_x_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3),
                     limits = c(0, 0.33)) +
  scale_y_continuous(labels = percent_format(accuracy = 1),
                     breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),
                     limits = c(0, 0.55)) +
  labs(title = ""Goal Contribution Matrix: Serie A (2018-2019 Season)"",
       subtitle = ""Goal Involvement (Goals and/or Assists) as Percentage of Total Club Goals"",
       caption = glue(""
                      Data: soccerway.com & understat.com
                      By: @R_by_Ryo""),
       x = ""Percentage of Club Goals Assisted"",
       y = ""Percentage of Club Goals Scored"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        title = element_text(size = 20),
        plot.subtitle = element_text(size = 16),
        plot.caption = element_text(size = 10),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        panel.grid.minor.x = element_blank()) -> serieA_goal_contribution_matrix

serieA_goal_contribution_matrix
```


## save

```{r}
ggsave(plot = serieA_goal_contribution_matrix, 
       ""../Serie A 2018-2019/output/goal_contribution_matrix_plot_serieA.png"",
       height = 8, width = 10)
```

```{r}
plot_logo <- add_logo(
  plot_path = ""../Serie A 2018-2019/output/goal_contribution_matrix_plot_serieA.png"",
  logo_path = ""https://upload.wikimedia.org/wikipedia/en/0/02/Serie_A_logo_%282018%29.png"",
  logo_position = ""top right"",
  logo_scale = 6)

plot_logo
```

```{r}
image_write(image = plot_logo, 
            ""../Serie A 2018-2019/output/goal_contribution_matrix_plot_logo_serieA.png"")
```
","2018"
"71",238,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Women's World Cup 2019/pass_sonars.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""6/20/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r message=FALSE}
library(soccermatics)
library(StatsBombR)
library(tidyverse)
library(ggsoccer)
```




```{r}
comps <- FreeCompetitions()

WC_Matches <- FreeMatches(43)

JPN_Matches <- WC_Matches %>% filter(home_team.home_team_id == 778 | away_team.away_team_id == 778)

jp_sen <- get.matchFree(JPN_Matches[1, ])

# need to clean player.name column due to non-ASCII characters
jp_col <- readRDS(file = ""../data/jp_col.RDS"")
jp_sen <- readRDS(file = ""../data/jp_sen.RDS"")
jp_pol <- readRDS(file = ""../data/jp_pol.RDS"")
jp_bel <- readRDS(file = ""../data/jp_bel.RDS"")
br_cr <- readRDS(file = ""../data/br_cr.RDS"")

# get all StatsBomb data
allinfo <- function(df) {
  lapply(1:nrow(df), function(i) {
    temp <- get.matchFree(df[i,])
    Sys.sleep(runif(1, 1, 2)) #be courteous!
    temp <- cleanlocations(temp)
    temp <- goalkeeperinfo(temp)
    temp <- shotinfo(temp)
    temp <- defensiveinfo(temp)
    return(temp)
  }) %>% 
    plyr::rbind.fill()
}

jp <- allinfo(jp_sen)


```





```{r}
comps
```

```{r}
comps %>% 
  filter(competition_id == 72)


all_free <- StatsBombFreeEvents(MatchesDF = 22961)

StatsBombR:::MatchesDF


wwc_matches <- FreeMatches(Competitions = 72)

jp_sco_id <- wwc_matches %>% filter(match_id == 22961)

jp_sco_raw <- get.matchFree(Match = jp_sco_id)

glimpse(jp_sco_raw)
```



```{r}
round.angle <- 15

jp_sco_pass_raw <- jp_sco_raw %>% 
  filter(type.name == ""Pass"",
         possession_team.name == ""Japan Women's"",
         !play_pattern.name %in% c(""From Corner"", ""From Free Kick"",
                                   ""From Throw In"")) %>% 
  mutate(angle_round = round(pass.angle * 180 / pi / round.angle) *
           round.angle)



sonar_df <- jp_sco_pass_raw %>% 
  add_count(player.name, team.name, name = ""pass_n"") %>% 
  add_count(player.name, team.name, angle_round, name = ""angle_n"") %>% 
  group_by(player.name, team.name) %>% 
  mutate(max_n = max(angle_n),
         angle_norm = angle_n / max_n) %>% 
  ungroup() %>% 
  group_by(angle_round, player.name, team.name, pass_n) %>% 
  summarize(angle_norm = mean(angle_norm),
            distance = mean(pass.length),
            distance = if_else(distance > 30, 30, distance))
  
```




```{r}
jugadores <- unique(sonar_df$player.name)
```



```{r}

sonar_df %>% 
  filter(player.name == jugadores[14]) %>% 
  ggplot() + 
  geom_bar(aes(x = angle_round, y = angle_norm, fill = distance),
           stat = ""identity"") +
  scale_y_continuous(limits = c(0, 1))+
  scale_x_continuous(breaks = seq(-180, 180, by = 90), 
                     limits = c(-180, 180)) +
  coord_polar(start = pi, direction = 1) +
  #RColorBrewer::brewer.pal.info
  colorspace::scale_fill_continuous_sequential(palette = ""Blues"", rev = TRUE) +
  # viridis::scale_fill_viridis(""Distance (yards)"", limits = c(0, 30),
  #                    na.value = ""#FDE725FF"") +
  labs(x = '', y = '', title = jugadores[14]) +
  theme_void()+
  theme(plot.title = element_text(hjust = 0.5),
        #legend.position = ""none"", #uncomment to remove colorbar
        plot.background = element_rect(fill = ""transparent"", colour = NA),
        panel.background = element_rect(fill = ""transparent"", colour = NA))
```


```{r}
createPitch <- function(xmax=115, ymax=80, grass_colour=""white"", line_colour=""gray"", background_colour=""white"", goal_colour=""gray"", data=NULL, halfPitch=FALSE){
  
  GoalWidth <- 8
  penspot <- 12
  boxedgeW <- 44
  boxedgeL <- 18
  box6yardW <- 20
  box6yardL <- 6
  corner_d=3
  centreCirle_d <- 20
  
  # The 18 Yard Box
  TheBoxWidth <- c(((ymax / 2) + (boxedgeW / 2)),((ymax / 2) - (boxedgeW / 2)))
  TheBoxHeight <- c(boxedgeL,xmax-boxedgeL)
  GoalPosts <- c(((ymax / 2) + (GoalWidth / 2)),((ymax / 2) - (GoalWidth / 2)))
  
  # The 6 Yard Box
  box6yardWidth <- c(((ymax / 2) + (box6yardW / 2)),((ymax / 2) - (box6yardW / 2)))
  box6yardHeight <- c(box6yardL,xmax-box6yardL)
  
  ## define the circle function
  circleFun <- function(center = c(0,0),diameter = 1, npoints = 100){
    r = diameter / 2
    tt <- seq(0,2*pi,length.out = npoints)
    xx <- center[1] + r * cos(tt)
    yy <- center[2] + r * sin(tt)
    return(data.frame(x = xx, y = yy))
  }
  
  #### create leftD arc ####
  Dleft <- circleFun(c((penspot),(ymax/2)),centreCirle_d,npoints = 1000)
  ## remove part that is in the box
  Dleft <- Dleft[which(Dleft$x >= (boxedgeL)),]
  
  ## create rightD arc  ####
  Dright <- circleFun(c((xmax-(penspot)),(ymax/2)),centreCirle_d,npoints = 1000)
  ## remove part that is in the box
  Dright <- Dright[which(Dright$x <= (xmax-(boxedgeL))),]
  
  #### create center circle ####
  center_circle <- circleFun(c((xmax/2),(ymax/2)),centreCirle_d,npoints = 2000)
  
  
  if (halfPitch==FALSE){
    xmin=0
    ymin=0
    
    ## create corner flag radius ####
    TopLeftCorner <- circleFun(c(xmin,ymax),corner_d,npoints = 1000)
    TopLeftCorner <- TopLeftCorner[which(TopLeftCorner$x > (xmin)),]
    TopLeftCorner <- TopLeftCorner[which(TopLeftCorner$y < (ymax)),]
    TopRightCorner <- circleFun(c(xmax,ymax),corner_d,npoints = 1000)
    TopRightCorner <- TopRightCorner[which(TopRightCorner$x < (xmax)),]
    TopRightCorner <- TopRightCorner[which(TopRightCorner$y < (ymax)),]
    
    BottomLeftCorner <- circleFun(c(xmin,ymin),corner_d,npoints = 1000)
    BottomLeftCorner <- BottomLeftCorner[which(BottomLeftCorner$x > (xmin)),]
    BottomLeftCorner <- BottomLeftCorner[which(BottomLeftCorner$y > (ymin)),]
    
    BottomRightCorner <- circleFun(c(xmax,ymin),corner_d,npoints = 1000)
    BottomRightCorner <- BottomRightCorner[which(BottomRightCorner$x < (xmax)),]
    BottomRightCorner <- BottomRightCorner[which(BottomRightCorner$y > (ymin)),]
    
    
    
    ggplot(data=data) + #xlim(c(ymin,ymax)) + ylim(c(xmin,xmax)) +
      # add the theme 
      #theme_blankPitch() +
      # add the base rectangle of the pitch 
      geom_rect(aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), fill = grass_colour, colour = line_colour)+

      # add the 18 yard box Left
      geom_rect(aes(xmin=0, xmax=TheBoxHeight[1], ymin=TheBoxWidth[1], ymax=TheBoxWidth[2]), fill = grass_colour, colour = line_colour) + 
      # add the 18 yard box Right
      geom_rect(aes(xmin=TheBoxHeight[2], xmax=xmax, ymin=TheBoxWidth[1], ymax=TheBoxWidth[2]), fill = grass_colour, colour = line_colour) +
      # add the six yard box Left
      geom_rect(aes(xmin=0, xmax=box6yardHeight[1], ymin=box6yardWidth[1], ymax=box6yardWidth[2]), fill = grass_colour, colour = line_colour)  +
      # add the six yard box Right
      geom_rect(aes(xmin=box6yardHeight[2], xmax=xmax, ymin=box6yardWidth[1], ymax=box6yardWidth[2]), fill = grass_colour, colour = line_colour)  + 
      # Add half way line 
      geom_segment(aes(x = xmax/2, y = ymin, xend = xmax/2, yend = ymax),colour = line_colour) +
      # add left D 
      geom_path(data=Dleft, aes(x=x,y=y), colour = line_colour) + 
      # add Right D 
      geom_path(data=Dright, aes(x=x,y=y), colour = line_colour) +
      # add centre circle 
      geom_path(data=center_circle, aes(x=x,y=y), colour = line_colour) +
      
      # add penalty spot left 
      geom_point(aes(x = penspot , y = ymax/2), colour = line_colour) + 
      # add penalty spot right
      geom_point(aes(x = (xmax-(penspot)) , y = ymax/2), colour = line_colour) + 
      # add centre spot 
      geom_point(aes(x = (xmax/2) , y = ymax/2), colour = line_colour) +
      # add Corner Flag corners
      geom_path(data=TopLeftCorner, aes(x=x,y=y), colour = line_colour) +
      geom_path(data=TopRightCorner, aes(x=x,y=y), colour = line_colour) +
      geom_path(data=BottomLeftCorner, aes(x=x,y=y), colour = line_colour) +
      geom_path(data=BottomRightCorner, aes(x=x,y=y), colour = line_colour) +
      geom_segment(aes(x = xmin-0.2, y = GoalPosts[1], xend = xmin-0.2, yend = GoalPosts[2]),colour = goal_colour, size = 1) +
      # add the goal right
      geom_segment(aes(x = xmax+0.2, y = GoalPosts[1], xend = xmax+0.2, yend = GoalPosts[2]),colour = goal_colour, size = 1) +
      
      coord_fixed() +
      theme(rect = element_blank(),#, #remove additional ggplot2 features: lines, axis, etc...
            line = element_blank(), 
            #legend.position = ""none"",
            axis.title.y = element_blank(),
            axis.title.x = element_blank(),
            axis.text.x = element_blank(),
            axis.text.y = element_blank())
}
  
  else{
    xmin=(xmax/2)
    ymin=0
    center_circle = center_circle[which(center_circle$x>=xmin),]
    
    ## create corner flag radius ####
    BottomRightCorner <- circleFun(c(xmax,ymin),corner_d,npoints = 1000)
    BottomRightCorner <- BottomRightCorner[which(BottomRightCorner$x < (xmax)),]
    BottomRightCorner <- BottomRightCorner[which(BottomRightCorner$y > (ymin)),]
    TopRightCorner <- circleFun(c(xmax,ymax),corner_d,npoints = 1000)
    TopRightCorner <- TopRightCorner[which(TopRightCorner$x < (xmax)),]
    TopRightCorner <- TopRightCorner[which(TopRightCorner$y < (ymax)),]
    
    ggplot(data=data) + #xlim(c(ymin,ymax)) + ylim(c(xmin,xmax)) +
      # add the theme 
      #theme_blankPitch() +
      # add the base rectangle of the pitch 
      geom_rect(aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), fill = grass_colour, colour = line_colour)+ 
      # add the 18 yard box offensive
      geom_rect(aes(xmin=TheBoxHeight[2], xmax=xmax, ymin=TheBoxWidth[1], ymax=TheBoxWidth[2]), fill = grass_colour, colour = line_colour)+ 
      # add the six yard box offensive
      geom_rect(aes(xmin=box6yardHeight[2], xmax=xmax, ymin=box6yardWidth[1], ymax=box6yardWidth[2]), fill = grass_colour, colour = line_colour)+  
      # add the arc circle 
      geom_path(data=Dright, aes(x=x,y=y), colour = line_colour)+
      #add center arc
      geom_path(data=center_circle, aes(x=x,y=y), colour = line_colour)+
      # add penalty spot 
      
      geom_point(aes(x = (xmax-(penspot)) , y = ymax/2), colour = line_colour) +
      # add centre spot 
      geom_point(aes(x = (xmax/2) , y = ymax/2), colour = line_colour) +
      #geom_point(aes(x = CentreSpot , y = penSpotOff), colour = line_colour) +
      # add Corner Flag corners
      geom_path(data=BottomRightCorner, aes(x=x,y=y), colour = line_colour) +
      geom_path(data=TopRightCorner, aes(x=x,y=y), colour = line_colour) +

      
      # add the goal right
      geom_segment(aes(x = xmax+0.2, y = GoalPosts[1], xend = xmax+0.2, yend = GoalPosts[2]),colour = goal_colour, size = 1) +
      # add the goal offensive
      
    
    coord_fixed() +
      theme(rect = element_blank(), #remove additional ggplot2 features: lines, axis, etc...
            line = element_blank(), 
            #legend.position = ""none"",
            axis.title.y = element_blank(), 
            axis.title.x = element_blank(),
            axis.text.x = element_blank(),
            axis.text.y = element_blank())
  }
  
  
  
}
```


```{r}
#Plotting on top of a field by a team's formation
#The trick is to save each players PassSonar as a grob into a list. Then using
#annotation_custom() each PassSonar is placed in the correct position on the pitch
#It takes some trial and error to get the PassSonars into the correct position

text_color=""black""
background_color=""white""
radar.size=27
ymax=80
xmax=120

team.select=""Japan Women's""
match.select=22961

game.lineup = jp_sco_raw %>% 
  filter(team.name == team.select, type.name == 'Starting XI', 
         match_id == match.select)

game.players = game.lineup$tactics.lineup[[1]][[""player.name""]]
team.formation = game.lineup$tactics.formation
#game.lineup$tactics.lineup[[1]][[""position.name""]]  #uncomment to view positions to help place into correct locations of field

player.plots <- list()

for (i in 1:length(game.players)){
  
  plot.data <- sonar_df %>% 
    filter(team.name == team.select & 
             player.name == game.players[i])
  
  player.plots[[i]] <- ggplot(plot.data) + 
    geom_bar(aes(x = angle_round, y = angle_norm, fill = distance), 
             stat=""identity"") +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(breaks = seq(-180, 180, by = 90), 
                       limits = c(-180, 180)) +
    coord_polar(start = pi, direction = 1) +
    viridis::scale_fill_viridis(""Distance (yards)"", 
                                limits = c(0, 30), na.value = ""#FDE725FF"") +
    labs(x = '', y = '', title = plot.data$player.name[1]) +
    theme_void() +
    theme(plot.title = element_text(hjust = 0.5, color = text_color),
          plot.background = element_rect(fill = ""transparent"", colour = NA),
          panel.background = element_rect(fill = ""transparent"", colour = NA),
          legend.position = ""none"")
  
  player.plots[[i]] <- ggplotGrob(player.plots[[i]])
  
  if (i == length(game.players)){
    colorbar <- ggplot(plot.data) + 
      geom_bar(aes(x = angle_round, y = angle_norm, fill = distance), 
               stat = ""identity"") +
      scale_y_continuous(limits = c(0, 0)) +
      viridis::scale_fill_viridis("""", limits = c(0, 30), 
                                  na.value = ""#FDE725FF"")+
      labs(x = '', y = '')+
      theme_void()+
      theme(legend.position = ""bottom"",
            plot.background = element_rect(fill = ""transparent"", colour = NA),
            panel.background = element_rect(fill = ""transparent"", colour = NA))
    
    colorbar <- ggplotGrob(colorbar)
  }
}

#this is a 4-4-2 example. Use similar methods for other formations

if (team.formation == 442){
  team.formation <- '4-4-2'
  
  back.line <- 20
  mid.line <- 48
  forward.line <- 77
  
  p <- createPitch(grass_colour = background_color, 
                   goal_colour = text_colour, 
                   line_colour = text.color) + 
    coord_flip(ylim = c(0, 80))+
    theme(aspect.ratio = 120 / 80, 
          plot.title = element_text(size = 18, 
                                    hjust = 0.5, vjust = -2, 
                                    color = text.color),
          plot.background = element_rect(fill = background_color, colour = NA),
          panel.background = element_rect(fill = background_color, colour = NA)) +
    annotation_custom(grob = player.plots[[1]], 
                      xmin = -9, xmax = -9 + radar.size, 
                      ymax = ymax / 2 + radar.size / 2 - 1.5,
                      y= ymax / 2 - radar.size / 2 - 1.5) + #GK
    annotation_custom(grob = player.plots[[2]], 
                      xmin = back.line+3, xmax = back.line + 3 + radar.size, 
                      ymax = ymax + 1, y = ymax - radar.size + 1) + #RB
    annotation_custom(grob = player.plots[[5]], 
                      xmin = back.line + 3, xmax = back.line + 3 + radar.size,
                      ymax= -3 + radar.size, y = -3) + #LB
    annotation_custom(grob = player.plots[[4]], 
                      xmin = back.line, xmax= back.line + radar.size,
                      ymax = ymax / 2 - 23.5 + radar.size, y = ymax / 2 - 23.5) + #LCB
    annotation_custom(grob = player.plots[[3]], 
                      xmin = back.line, xmax = back.line + radar.size,
                      ymax = ymax / 2 - 6 + radar.size, y = ymax / 2 - 6) + #RCB
    annotation_custom(grob = player.plots[[7]], 
                      xmin = mid.line, xmax = mid.line + radar.size,
                      ymax = ymax / 2 - 23.5 + radar.size, y = ymax / 2 - 23.5) + #LCM
    annotation_custom(grob = player.plots[[6]], 
                      xmin = mid.line, xmax = mid.line + radar.size,
                      ymax = ymax / 2 - 6 + radar.size, y = ymax / 2 - 6) + #RCM
    annotation_custom(grob = player.plots[[10]], 
                      xmin = forward.line, xmax = forward.line + radar.size,
                      ymax = ymax / 2 - 3 + radar.size, y = ymax / 2 - 3) + #RF
    annotation_custom(grob = player.plots[[11]], 
                      xmin = forward.line, xmax = forward.line + radar.size,
                      ymax = ymax / 2 - 26 + radar.size, y = ymax / 2 - 26) + #LF
    annotation_custom(grob = player.plots[[8]], 
                      xmin = mid.line + 5, xmax = mid.line + 5 + radar.size, 
                      ymax = ymax + 1, y = ymax - radar.size + 1) + #RM
    annotation_custom(grob = player.plots[[9]], 
                      xmin = mid.line + 5, xmax = mid.line + 5 + radar.size, 
                      ymax = -3 + radar.size, y = -3) + #LM
    annotation_custom(grob = colorbar, xmin = 3, xmax = 7, 
                      ymin = 1, ymax = 18)+
    annotate(""text"", label = ""concept:@etmckinley\ndata:@StatsBomb"", 
             x = 6, y = 79, hjust = 1, vjust = 1,
             size = 3.75, color = text.color) +
    annotate(""text"", label = ""Mean Pass Distance (Yards)"", 
             x = 9, y = 3, hjust = 0, 
             size = 3, color = text.color) +
    annotate(""text"", 
             label = 'Bar length = normalized pass angle frequency; Bar color = mean pass distance', 
             color = text.color, 
             x = -2, y = 79, 
             hjust = 1, size = 3)+
    annotate(""text"", 
             label = paste0('Starting Formation: ', team.formation), 
             color = text.color, 
             x = -2, y = 0, 
             hjust = 0, size = 5, fontface = ""bold"") +
    annotate(""text"", 
             label = paste0('PassSonar: ', team.select), 
             color = text.color, 
             x = 121.5, y = 0, hjust = 0, size = 9, fontface = ""bold"") +
    guides(fill = guide_colourbar())
  
}
```



```{r}
  team.formation <- '4-4-2'
  
  back.line <- 20
  mid.line <- 48
  forward.line <- 77


 plot.data <- sonar_df %>% 
    filter(team.name == team.select & 
             player.name == game.players[4])
  
  player.plots <- ggplot(plot.data) + 
    geom_bar(aes(x = angle_round, y = angle_norm, fill = distance), 
             stat=""identity"") +
    scale_y_continuous(limits = c(0, 1)) +
    scale_x_continuous(breaks = seq(-180, 180, by = 90), 
                       limits = c(-180, 180)) +
    coord_polar(start = pi, direction = 1) +
    viridis::scale_fill_viridis(""Distance (yards)"", 
                                limits = c(0, 30), na.value = ""#FDE725FF"") +
    labs(x = '', y = '', title = plot.data$player.name[4]) +
    theme_void() +
    theme(plot.title = element_text(hjust = 0.5, color = text_color),
          plot.background = element_rect(fill = ""transparent"", colour = NA),
          panel.background = element_rect(fill = ""transparent"", colour = NA),
          legend.position = ""none"")
  
  grobbo <- ggplotGrob(player.plots)
```



```{r, fig.height=6, fig.width=4}
ggplot() +
  annotate_pitch(dimensions = pitch_statsbomb) +
  theme_pitch() +
  coord_flip(xlim = c(0, 130),
             ylim = c(0, 80)) +
  theme(aspect.ratio = 120 / 80, 
          plot.title = element_text(size = 18, 
                                    hjust = 0.5, vjust = -2, 
                                    color = ""black"")) +
  annotation_custom(grob = grobbo, 
                      xmin = back.line+3, xmax = back.line + 3 + radar.size, 
                      ymax = ymax + 1, y = ymax - radar.size + 1)
```

","2019"
"72",239,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Women's World Cup 2019/tidytuesday.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""7/9/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## pkgs

```{r, message=FALSE, warning=FALSE}
library(dplyr)        ## data wrangling
library(tidyr)        ## data wrangling
library(purrr)        ## data wrangling and iteration
library(stringr)      ## data wrangling
library(rvest)        ## webscraping
library(polite)       ## webscraping (Github only pkg)
library(ggplot2)      ## plotting
library(scales)       ## plotting scales
library(ggimage)      ## images for flags
library(ggforce)      ## plotting text labels
library(cowplot)      ## plotting grid
library(glue)         ## text
library(ggrepel)      ## plotting text labels
library(magick)       ## plotting
library(ggtextures)   ## soccer ball emoji as geom_col()
library(extrafont)    ## fonts: Roboto Condensed

loadfonts()
```

## WWC theme


```{r}
theme_womenWorldCup <- function(
  title.size = 24,
  subtitle.size = 14,
  caption.size = 8,
  axis.text.size = 14,
  axis.text.x.size = 12,
  axis.text.y.size = 12,
  axis.title.size = 16,
  strip.text.size = 18,
  panel.grid.major.x = element_line(size = 0.5, color = ""black""),
  panel.grid.major.y = element_line(size = 0.5, color = ""black""),
  panel.grid.minor.x = element_blank(),
  panel.grid.minor.y = element_blank(),
  axis.ticks = element_line(color = ""black"")) {
  ## Theme:
  theme(text = element_text(family = ""Roboto Condensed"", color = ""white""),
        plot.title = element_text(family = ""Roboto Condensed"", face = ""bold"", 
                                  size = title.size, color = ""yellow""),
        plot.subtitle = element_text(size = subtitle.size),
        plot.caption = element_text(size = caption.size),
        panel.background = element_rect(fill = ""#009b3a""), # red green
        plot.background = element_rect(fill = ""#002776""),
        axis.text = element_text(size = axis.text.size, color = ""white""),
        axis.text.x = element_text(size = axis.text.x.size, color = ""white""),
        axis.text.y = element_text(size = axis.text.y.size, color = ""white""),
        axis.title = element_text(size = axis.title.size),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        panel.grid.major.x = panel.grid.major.x,
        panel.grid.major.y = panel.grid.major.y,
        panel.grid.minor.x = panel.grid.minor.x,
        panel.grid.minor.y = panel.grid.minor.y,
        strip.text = element_text(color = ""yellow"", face = ""bold"", 
                                  size = strip.text.size, 
                                  margin = margin(4.4, 4.4, 4.4, 4.4)),
        strip.background = element_blank(),
        axis.ticks = axis.ticks
        )
}
```




## ONLY 2019 edition

```{r}
wwc_2019_top_goleadores <- data.frame(
  player = c(""Ellen White"", ""Alex Morgan"", ""Megan Rapinoe"", 
           ""Sam Kerr"", ""Marta"", ""Wendie Renard""),
  goals = c(6, 6, 6, 5, 4, 4),
  image = ""https://www.emoji.co.uk/files/microsoft-emojis/activity-windows10/8356-soccer-ball.png""
)
```




```{r, fig.height = 12, fig.width = 14}
wwc_2019_top_goleadores_raw_plot <- wwc_2019_top_goleadores %>% 
  ggplot(aes(x = reorder(player, goals), y = goals,
             image = image)) +
  geom_isotype_col(img_width = grid::unit(1, ""native""), 
                   img_height = NULL, ncol = NA, nrow = 1, 
                   hjust = 0, vjust = 0.5) +
  geom_text(aes(label = goals, 
                family = ""Roboto Condensed"", fontface = ""bold""), 
            size = 11.5, color = ""yellow"",
            nudge_y = 0.5) +
  coord_flip() +
  scale_y_continuous(breaks = c(0, 2, 4, 6),
                     expand = c(0, 0.1), 
                     limits = c(0, 7.5)) +
  labs(title = ""Top Scorers of the 2019 Women's World Cup"",
       subtitle = str_wrap(""
                       Third time there has been a tie for top goalscorer 
                       and the first time that there has been a three way tie!
                       Other ties include: 2015 (Carli Lloyd & Celia Sasic 
                       with 5 goals) & 1999 (Sun Wen & Sissi with 7 goals)"", 
                       width = 80),
       y = ""Number of Goals"", x = NULL,
       caption = glue(""
                      Source: Wikipedia
                      By @R_by_Ryo"")) +
  theme_womenWorldCup(title.size = 32,
                    subtitle.size = 22,
                    caption.size = 16,
                    axis.text.x.size = 24,
                    axis.text.y.size = 24,
                    axis.title.size = 22,
                    panel.grid.major.x = element_line(size = 0.5, color = ""white""),
                    panel.grid.major.y = element_blank(),
                    axis.ticks = element_blank())

## Add flags to y-axis:
axis_image <- axis_canvas(wwc_2019_top_goleadores_raw_plot, axis = 'y') + 
  draw_image(""https://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg"", 
             y = 6.3, scale = 0.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/b/be/Flag_of_England.svg"", 
             y = 5, scale = 0.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg"", 
             y = 3.75, scale = 0.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/8/88/Flag_of_Australia_%28converted%29.svg"", 
             y = 2.55, scale = 0.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/c/c3/Flag_of_France.svg"", 
             y = 1.35, scale = 0.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/0/05/Flag_of_Brazil.svg"", 
             y = 0.1, scale = 0.8) 

wwc_2019_top_goleadores_plot <- ggdraw(insert_yaxis_grob(
  wwc_2019_top_goleadores_raw_plot, 
  axis_image, position = ""left""))

wwc_2019_top_goleadores_plot
```

```{r}
ggsave(filename = here::here(""Women's World Cup 2019/output/wwc2019_top_scorers.png""),
       height = 12, width = 14)
```



## ALL Women's World Cups



```{r}
url <- ""https://en.wikipedia.org/wiki/List_of_FIFA_Women%27s_World_Cup_goalscorers""

session <- bow(url)

wwc_top_scorers <- scrape(session) %>% 
  html_nodes(""table.wikitable:nth-child(8)"") %>% 
  html_table() %>% 
  flatten_df() %>% 
  set_names(c(""rank"", ""player"", ""country"", ""goals"", 
              ""matches"", ""goal_avg"", ""tournaments_played"")) %>% 
  mutate(image = ""https://www.emoji.co.uk/files/microsoft-emojis/activity-windows10/8356-soccer-ball.png"")
```


```{r, fig.height = 10, fig.width = 12}
wwc_top_scorers_raw_plot <- wwc_top_scorers %>% 
  head(5) %>% 
  ggplot(aes(x = reorder(player, goals), y = goals,
             image = image)) +
  geom_isotype_col(img_width = grid::unit(1, ""native""), 
                   img_height = NULL, ncol = NA, nrow = 1, 
                   hjust = 0, vjust = 0.5) +
  geom_text(aes(label = goals, 
                family = ""Roboto Condensed"", fontface = ""bold""), 
            size = 9.5, color = ""yellow"",
            nudge_y = 0.5) +
  coord_flip() +
  scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10, 12, 14, 16, 18),
                     expand = c(0, 0), 
                     limits = c(0, 20)) +
  labs(title = ""Top Scorers of the Women's World Cup (1991-2019)"",
       subtitle = glue(""
                       Most goals in a single tournament: 10 
                       Michelle Akers (1991)""),
       y = ""Number of Goals"", x = NULL,
       caption = glue(""
                      Source: Wikipedia
                      By @R_by_Ryo"")) +
  theme_womenWorldCup(title.size = 28,
                    subtitle.size = 20,
                    caption.size = 16,
                    axis.text.x.size = 24,
                    axis.text.y.size = 24,
                    axis.title.size = 18,
                    panel.grid.major.x = element_line(size = 0.5, color = ""white""),
                    panel.grid.major.y = element_blank(),
                    axis.ticks = element_blank())

## Add flags to y-axis:
axis_image <- axis_canvas(wwc_top_scorers_raw_plot, axis = 'y') + 
  draw_image(""https://upload.wikimedia.org/wikipedia/en/0/05/Flag_of_Brazil.svg"", 
             y = 17, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/b/ba/Flag_of_Germany.svg"", 
             y = 13.25, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg"", 
             y = 9.3, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg"", 
             y = 5.35, scale = 1.8) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/f/fa/Flag_of_the_People%27s_Republic_of_China.svg"", 
             y = 1.6, scale = 1.8)

wwc_top_scorers_plot <- ggdraw(insert_yaxis_grob(
  wwc_top_scorers_raw_plot, 
  axis_image, position = ""left""))

wwc_top_scorers_plot
```


```{r}
ggsave(filename = here::here(""Women's World Cup 2019/output/wwc_top_scorers.png""),
       height = 10, width = 12)
```


## Statsbomb



```{r, message=FALSE}
library(soccermatics)
library(StatsBombR)
```



```{r}
comps <- FreeCompetitions()
comps %>% 
  filter(competition_id == 72)

StatsBombR:::MatchesDF

all_free <- StatsBombFreeEvents(MatchesDF = 22961)

wwc_matches <- FreeMatches(Competitions = 72)

wwc_final_id <- wwc_matches %>% filter(match_id == 69321)

wwc_final_raw <- get.matchFree(Match = wwc_final_id)

glimpse(wwc_final_raw)
```

```{r}
saveRDS(wwc_final_raw, file = here::here(""data/wwc_final_raw.RDS""))

wwc_final_raw <- readRDS(file = here::here(""data/wwc_final_raw.RDS""))
```



```{r}
# get all StatsBomb data
allinfo <- function(df) {
  lapply(1:nrow(df), function(i) {
    temp <- get.matchFree(df[i,])
    Sys.sleep(runif(1, 1, 2)) #be courteous!
    temp <- cleanlocations(temp)
    temp <- goalkeeperinfo(temp)
    temp <- shotinfo(temp)
    temp <- defensiveinfo(temp)
    return(temp)
  }) %>% 
    plyr::rbind.fill()
}
```


```{r}
wwc_final_df <- allinfo(wwc_final_raw)

wwc_final_df %>% cleanlocations() %>% glimpse()
```



```{r}
# Pass map (to first substitution)
wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""Netherlands Women's"") %>% 
  soccerPassmap(theme = ""light"")

# Pass map (to first substitution)
wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""United States Women's"") %>% 
  soccerPassmap(theme = ""light"")

# Pass Heatmap
wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""United States Women's"", type.name == ""Pass"") %>% 
  soccerHeatmap(x = ""location.x"", y = ""location.y"")
```

Netherlands focus on passing centrally through their star midfield trio

Not many balls were able to come through to Miedema and Beerensteyn up top


```{r}
# Defensive pressure Heatmap
wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""United States Women's"", type.name == ""Pressure"") %>% 
  soccerHeatmap(x = ""location.x"", y = ""location.y"",
                title = ""US Women's Defensive Pressure vs. The Netherlands"") 

wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""Netherlands Women's"", type.name == ""Pressure"") %>% 
  soccerHeatmap(x = ""location.x"", y = ""location.y"",
                title = ""The Netherlands Women's Defensive Pressure vs. USA"") 
```


## PASS MAP (Complete + Incomplete)

### USA 


```{r, fig.height=10, fig.width=16}
d3 <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(type.name == ""Pass"" & team.name == ""United States Women's"") %>% 
  mutate(pass.outcome = as.factor(if_else(is.na(pass.outcome.name), 
                                          ""Complete"", ""Incomplete"")))

pass_map_neth <- soccerPitch(arrow = ""r"",
            title = ""USA W (vs. Netherlands W)"", 
            subtitle = ""Pass map"") +
  geom_segment(data = d3, aes(x = location.x, xend = pass.end_location.x, 
                              y = location.y, yend = pass.end_location.y, 
                              col = pass.outcome), alpha = 0.75) +
  geom_point(data = d3, aes(x = location.x, y = location.y, 
                            col = pass.outcome), alpha = 0.5) +
  scale_color_manual(values = c(""blue"", ""red""), name = ""Outcome"") +
  theme(text = element_text(family = ""Roboto Condensed""),
        legend.position = ""bottom"")

# Pass map (to first substitution)
usa_passmap <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""United States Women's"") %>% 
  soccerPassmap(theme = ""light"")



pass_map_text <- ggplot() +
  annotate(geom = ""text"", family = ""Roboto Condensed"",
           label = str_wrap(""USA use the wide areas to attack but most of their crosses into the box were unsucessful. Their big chances (especially after the first goal was scored) came from the times they were able to break through the previously packed Dutch midfield which started to leave gaps as they pushed up to create an equalizer."",
                            width = 50), size = 6,
           x = 1, y = 1) +
  theme_void()

library(patchwork)

usa_passmap / (pass_map_neth + pass_map_text)


pass_map_neth + pass_map_text - usa_passmap + plot_layout(ncol = 1)
```

### Netherlands


```{r, fig.height=10, fig.width=16}
d4 <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(type.name == ""Pass"" & team.name == ""Netherlands Women's"") %>% 
  mutate(pass.outcome = as.factor(if_else(is.na(pass.outcome.name), 
                                          ""Complete"", ""Incomplete"")))

pass_map_ned <- soccerPitch(arrow = ""r"",
            title = ""Netherlands W (vs. USA W)"", 
            subtitle = ""Pass map"") +
  geom_segment(data = d4, aes(x = location.x, xend = pass.end_location.x, 
                              y = location.y, yend = pass.end_location.y, 
                              col = pass.outcome), alpha = 0.75) +
  geom_point(data = d4, aes(x = location.x, y = location.y, 
                            col = pass.outcome), alpha = 0.5) +
  scale_color_manual(values = c(""blue"", ""red""), name = ""Outcome"") +
  theme(text = element_text(family = ""Roboto Condensed""),
        legend.position = ""bottom"")

# Pass map (to first substitution)
holland_passmap <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""Netherlands Women's"") %>% 
  soccerPassmap(theme = ""light"")



pass_map_text_ned <- ggplot() +
  annotate(geom = ""text"", family = ""Roboto Condensed"",
           label = str_wrap(""The Dutch cycled possession around their midfield three but could not find the creativity to play vertical passes centrally to star Striker Miedema or Berensteyn. Even when they did it was when they dropped very deep into midfield. The Dutch did not complete ANY passes in the USA's 18-yard box!"",
                            width = 50), size = 6,
           x = 1, y = 1) +
  theme_void()

library(patchwork)

usa_passmap / (pass_map_neth + pass_map_text)


pass_map_ned + pass_map_text_ned - holland_passmap + plot_layout(ncol = 1)
```






```{r}
wwc_final_raw %>% select(type.name) %>% unique()

wwc_final_raw %>% select(player.name) %>% unique()
```

```{r}
wwc_final_raw %>% 
  filter(player.name == ""Anouk Dekker"", type.name == ""Clearance"") %>% 
  count()


wwc_final_raw %>% 
  filter(player.name == ""Anouk Dekker"", type.name == ""Duel"") %>% 
  count()



wwc_final_raw %>% 
  filter(player.name == ""Stephanie van der Gragt"", type.name == ""Duel"") %>% 
  count()
```




```{r}
wwc_final_raw %>% 
  allclean() %>% 
  cleanlocations() %>% 
  freezeframeinfo()
```

","2019"
"73",240,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","Women's World Cup 2019/tidytuesday_statsbomb.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""7/10/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Statsbomb



```{r, message=FALSE}
library(soccermatics) ## soccermatics viz package
library(StatsBombR)   ## statsbomb R package to grab free statsbomb data!
library(dplyr)        ## data wrangling
library(tidyr)        ## data wrangling
library(purrr)        ## data wrangling and iteration
library(stringr)      ## data wrangling
library(rvest)        ## webscraping
library(polite)       ## webscraping (Github only pkg)
library(ggplot2)      ## plotting
library(scales)       ## plotting scales
library(ggimage)      ## images for flags
library(ggforce)      ## plotting text labels
library(cowplot)      ## plotting grid
library(glue)         ## text
library(ggrepel)      ## plotting text labels
library(magick)       ## plotting
library(ggtextures)   ## soccer ball emoji as geom_col()
library(extrafont)    ## fonts: Roboto Condensed

loadfonts()
```



```{r}
comps <- FreeCompetitions()
comps %>% 
  filter(competition_id == 72)

StatsBombR:::MatchesDF

all_free <- StatsBombFreeEvents(MatchesDF = 22961)

wwc_matches <- FreeMatches(Competitions = 72)

wwc_final_id <- wwc_matches %>% filter(match_id == 69321)

wwc_final_raw <- get.matchFree(Match = wwc_final_id)

glimpse(wwc_final_raw)
```

```{r}
saveRDS(wwc_final_raw, file = here::here(""data/wwc_final_raw.RDS""))

wwc_final_raw <- readRDS(file = here::here(""data/wwc_final_raw.RDS""))
```




## PASS MAP (Complete + Incomplete)

### USA 


```{r, fig.height=10, fig.width=16}
d3 <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(type.name == ""Pass"" & team.name == ""United States Women's"") %>% 
  mutate(pass.outcome = as.factor(if_else(is.na(pass.outcome.name), 
                                          ""Complete"", ""Incomplete"")))

pass_map_neth <- soccerPitch(arrow = ""r"",
            title = ""USA W (vs. Netherlands W)"", 
            subtitle = ""Pass map"") +
  geom_segment(data = d3, aes(x = location.x, xend = pass.end_location.x, 
                              y = location.y, yend = pass.end_location.y, 
                              col = pass.outcome), alpha = 0.75) +
  geom_point(data = d3, aes(x = location.x, y = location.y, 
                            col = pass.outcome), alpha = 0.5) +
  scale_color_manual(values = c(""blue"", ""red""), name = ""Outcome"") +
  theme(text = element_text(family = ""Roboto Condensed""),
        legend.position = ""bottom"")

# Pass map (to first substitution)
usa_passmap <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""United States Women's"") %>% 
  soccerPassmap(theme = ""light"")



pass_map_text <- ggplot() +
  annotate(geom = ""text"", family = ""Roboto Condensed"",
           label = str_wrap(""USA use the wide areas to attack but most of their crosses into the box were unsucessful. Their big chances (especially after the first goal was scored) came from the times they were able to break through the previously packed Dutch midfield which started to leave gaps as they pushed up to create an equalizer."",
                            width = 50), size = 6,
           x = 1, y = 1) +
  theme_void()

library(patchwork)

usa_passmap / (pass_map_neth + pass_map_text)


pass_map_neth + pass_map_text - usa_passmap + plot_layout(ncol = 1)
```

```{r}
ggsave(filename = here::here(""Women's World Cup 2019/output/usa_passmap.png""),
       height = 10, width = 16)
```


### Netherlands


```{r, fig.height=10, fig.width=16}
d4 <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(type.name == ""Pass"" & team.name == ""Netherlands Women's"") %>% 
  mutate(pass.outcome = as.factor(if_else(is.na(pass.outcome.name), 
                                          ""Complete"", ""Incomplete"")))

pass_map_ned <- soccerPitch(arrow = ""r"",
            title = ""Netherlands W (vs. USA W)"", 
            subtitle = ""Pass map"") +
  geom_segment(data = d4, aes(x = location.x, xend = pass.end_location.x, 
                              y = location.y, yend = pass.end_location.y, 
                              col = pass.outcome), alpha = 0.75) +
  geom_point(data = d4, aes(x = location.x, y = location.y, 
                            col = pass.outcome), alpha = 0.5) +
  scale_color_manual(values = c(""blue"", ""red""), name = ""Outcome"") +
  theme(text = element_text(family = ""Roboto Condensed""),
        legend.position = ""bottom"")

# Pass map (to first substitution)
holland_passmap <- wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(team.name == ""Netherlands Women's"") %>% 
  soccerPassmap(theme = ""light"")



pass_map_text_ned <- ggplot() +
  annotate(geom = ""text"", family = ""Roboto Condensed"",
           label = str_wrap(""The Dutch cycled possession around their midfield three but could not find the creativity to play vertical passes centrally to star Striker Miedema or Berensteyn. Even when they did it was when they dropped very deep into midfield. The Dutch did not complete ANY passes in the USA's 18-yard box!"",
                            width = 50), size = 6,
           x = 1, y = 1) +
  theme_void()

library(patchwork)

usa_passmap / (pass_map_neth + pass_map_text)


pass_map_ned + pass_map_text_ned - holland_passmap + plot_layout(ncol = 1)
```


```{r}
ggsave(filename = here::here(""Women's World Cup 2019/output/ned_passmap.png""),
       height = 10, width = 16)
```








```{r}
wwc_final_raw %>% 
  cleanlocations() %>% 
  soccerTransform(method = ""statsbomb"") %>% 
  filter(type.name == ""Pass"" & team.name == ""Netherlands Women's"") %>% View()
  soccerPositionMap(id = ""player.name"", x = ""location.x"", y = ""location.y"", 
                    fill1 = ""blue"", grass = T,
                    arrow = ""r"", 
                    title = ""Netherlands W (vs. USA W)"", 
                    subtitle = ""Average pass position (1' - )"")
```

","2019"
"74",241,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/blog posts/soccer_plots_part1.rmd","---
title: ""Visualize the World Cup with R! Part 1: Recreating Goals with ggsoccer and ggplot2""
author: ""RN7""
date: ""June 27, 2018""
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

After posting a couple of my World Cup viz on [Twitter](https://twitter.com/R_by_Ryo), I thought I'll collate some of them into a blog post. This will be __Part 1__ of a series as the World Cup goes on and I keep improving my viz skills throughout the tournament. I will also explain how I made improvements in each new plot, practice makes perfect!

Let's look at some of the packages I will use!

```{r packages, eval=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)   # plotting on top of ggsoccer 
library(ggsoccer)  # create soccer pitch overlay
library(dplyr)     # data manipulation
library(purrr)     # create multiple dataframes for tweenr
library(tweenr)    # build frames for animation
library(gganimate) # animate plots
library(extrafont) # insert custom fonts into plots
library(ggimage)   # insert images and emoji into plots
```

The important package here is the `ggsoccer` package made by Ben Torvaney, check out the GitHub repo [here](https://github.com/Torvaney/ggsoccer).

Showing is better than telling in this instance so let's take a look at the pitch:

```{r half-pitch template}
library(ggplot2)
library(ggsoccer)

data <- data.frame(x = 1, y = 1)

ggplot(data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101))
```

Basically, `annotate_pitch()` creates the markings for the soccer field such as the center circle, 18-yard box, penalty spot, etc. while `theme_pitch()` erases the extraneous axes and background from the default ggplot style. By using the limits arguments in `coord_flip()`, we can focus on a certain area of the pitch and orient it in a way that we want, as I want to recreate goals I'm going to show only one half of the field and orient the view to face the goal. With this as the base, we can now input positional data and then use a combination of `geom_segment()` and `geom_curve()` to show the path of the ball and the players!

The only problem with doing this is manually creating the data points. This is more a problem of access to the data rather than availability as sports analytics firms, most notably Opta, generate a huge amount of data for every player in every match, however it is not easy for a regular guy like me to buy it. 

Some people have managed to create some nice [heatmaps](https://twitter.com/neilcharles_uk/status/1009181021965778945) by scraping _WhoScored.com_ and other sites (that create their viz from purchased data from Opta) with __RSelenium__ or some other JS scrapers but that was a bit out of my expertise so I resorted to creating the coordinate positions by hand. Thankfully, due to the plotting system in `ggsoccer` and `ggplot2`, it's very easy to figure out the positions on the soccer field plot and with a little bit of practice it doesn't take too much time.

To save space I don't show the data frames with the coordinate points and labelling data for all of the graphics, however you can find all of them [here](https://github.com/Ryo-N7/soccer_ggplots) in the GitHub repo!

### Gazinsky Scores The First Goal!

```{r gazinsky data, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
# loadfonts()

#                              2   1  
pass_data <- data.frame(x = c( 84, 82),
                        y = c(  6, 32),
                        x2 = c(77, 84),
                        y2 = c(13, 8))

#            corner kick + golovin cross
curve_data <- data.frame(x = c(100, 76),
                         y = c(0, 19),
                         x2 = c(94, 94),
                         y2 = c(35, 60))

# Saudi failed clearance, Gazinsky header
ball_data <- data.frame(x = c(94, 94),
                        y = c(35, 60),
                        x2 = c(82, 99.2),
                        y2 = c(33.5, 47.5))

# soccer ball image
goal_img <- data.frame(x = 100,
                       y = 47) %>% 
  mutate(image = ""https://d30y9cdsu7xlg0.cloudfront.net/png/43563-200.png"")

# golovin + zhirkov movement
movement_data <- data.frame(x = c(83, 98),
                           y = c(24.25, 2),
                           x2 = c(77, 88),
                           y2 = c(21, 6))

label_data <- data.frame(
  x = c(94, 83, 75, 98, 84),
  y = c(60, 23, 11,  0,  6),
  label = c(""Gazinsky"", ""Golovin"", ""Golovin"", ""Zhirkov"", ""Zhirkov""),
  hjust = c(-0.1, -0.05, -0.1,  0.5,  0.5),
  vjust = c( 0.5,  0.5,   0.5, -0.3, -0.3)
)

```

```{r gazinsky plot}

ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() + 
  theme(text = element_text(family = ""Trebuchet MS"")) +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(aes(x = x, y = y, xend = x2, yend = y2),
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(data = ball_data,
               aes(x = x, y = y, xend = x2, yend = y2), 
               linetype = ""dashed"", size = 0.85,
               color = c(""black"", ""red"")) +
  geom_segment(data = movement_data,
               aes(x = x, y = y, xend = x2, yend = y2), 
               linetype = ""dashed"", size = 1.2,
               color = ""darkgreen"") +
  geom_curve(data = curve_data, 
             aes(x = x, y = y, xend = x2, yend = y2), 
             curvature = 0.25, 
             arrow = arrow(length = unit(0.25, ""cm""),
                           type = ""closed"")) +
  geom_image(data = goal_img,
             aes(x = x, y = y,
                 image = image), 
             size = 0.035) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  geom_label(data = label_data,
    aes(x = x, y = y, 
        label = label,
        hjust = hjust,
        vjust = vjust)) +
  annotate(""text"", x = 69, y = 65, family = ""Trebuchet MS"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"")

```

Not bad for a first try. Let's take a closer look at how I plotted the soccer ball image into the plot.

```{r ball img, eval=FALSE}
goal_img <- data.frame(x = 100,
                       y = 47) %>% 
  mutate(image = ""https://d30y9cdsu7xlg0.cloudfront.net/png/43563-200.png"")

## ggplot2 code ##
geom_image(data = goal_img,
             aes(x = x, y = y,
                 image = image), 
             size = 0.035)
## ggplot2 code ##

```

I used the `ggimage` package to be able to create a geom layer for an image. I created a column called `image` in a dataframe with the URL link to the soccer ball image I wanted and then in the `geom_image()` function I specified it in the `image` argument. 

## Cristiano's Hattrick!

In my excitement after seeing __Portugal vs. Spain__, a candidate for match of the tournament for the group stages if not for the whole tournament, I drew up Cristiano Ronaldo's hattrick!

```{r Cristiano data, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(ggsoccer)
library(extrafont)
library(emoGG)
library(ggimage)
# loadfonts()
# Official WC 2018 Font: ""Dusha""
# http://fifa2018wiki.com/fifa-2018-font-typeface-download-dusha-font-ttf/509/

# look up soccer ball emoji:
# emoji_search(""soccer"")  # ""26bd""

goals_data <- data.frame(x = c(88, 80, 71),
                         y = c(50, 48, 54),
                         label = c(1, 2, 3))

curve_data <- data.frame(x = c(88, 71), y = c(50, 54),
                         xend = c(100, 100), yend = c(54, 54))

annotation_data <- data.frame(
  hjust = c(0.5, 0.5, 0.5, 0, 0, 0),
  label = c(""Portugal             (3) vs. Spain            (3)"",
            ""Cristiano's Hattrick (4', 44', 88')"",
            ""by Ryo Nakagawara (@R_by_Ryo)"",
            ""1. Fouled by Nacho in the box,\nCristiano confidently strokes the ball\ninto the right corner from the spot."",
            ""2. Guedes lays it off to Cristiano whose\nstrong shot is uncharacteristically\nfumbled by De Gea into the net."",
            ""In the final minutes of the game,\nCristiano wins a freekick against Pique\nand curls it beautifully over the wall.""),
  x = c(110, 105, 53, 76, 66, 66), 
  y = c(30, 20, 85, 5, 5, 55)
)

flag_data <- data.frame(
  image = c(""PT"", ""ES""),
  x = c(110, 110),
  y = c(19.1, 50.3)
)

```

```{r Cristiano plot, fig.height=5, fig.width=8}

ggplot(goals_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5""),
        legend.position = ""none"") +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_segment(x = 80, y = 48, 
               xend = 97, yend = 48) +  # 2nd 
  geom_segment(x = 97, y = 48, 
               xend = 100, yend = 45.5,
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +        # degea fumble
  geom_curve(data = curve_data,
             aes(x = x, y = y, 
                 xend = xend, yend = yend),     # FREEKICK
             curvature = 0.3, 
             arrow = arrow(length = unit(0.25, ""cm""), type = ""closed"")) +
  geom_text(data = annotation_data,
            family = ""Dusha V5"", 
            aes(x = x, y = y,
                hjust = hjust, label = label), 
            size = c(6.5, 4.5, 3, 3.5, 3.5, 3.5)) +
  geom_flag(data = flag_data,
            aes(x = x, y = y,
                image = image), size = c(0.08, 0.08)) +       # Portugal + Spain Flag
  ggimage::geom_emoji(aes(x = 105, 
                 y = c(45, 50, 55)),
             image = ""26bd"", size = 0.035) +
  geom_point(aes(x = x, y = y), 
             shape = 21, size = 7, color = ""black"", fill = ""white"") +
  geom_text(aes(x = x, y = y, label = label, family = ""Dusha V5""))

```

Compared to the first plot, I increased the x-axis limit so that we could place our `geom_text()` annotations and flag images together without having to use grobs. This also meant that we put the plot title and subtitle in the `geom_text()` rather than in the `labs()` function, which let all the text/label data be organized in one dataframe, `annotation_data`. 

```{r, eval=FALSE}
annotation_data <- data.frame(
  hjust = c(0.5, 0.5, 0.5, 0, 0, 0),
  label = c(""Portugal             (3) vs. Spain            (3)"",
            ""Cristiano's Hattrick (4', 44', 88')"",
            ""by Ryo Nakagawara (@R_by_Ryo)"",
            ""1. Fouled by Nacho in the box,\nCristiano confidently strokes the ball\ninto the right corner from the spot."",
            ""2. Guedes lays it off to Cristiano whose\nstrong shot is uncharacteristically\nfumbled by De Gea into the net."",
            ""In the final minutes of the game,\nCristiano wins a freekick against Pique\nand curls it beautifully over the wall.""),
  x = c(110, 105, 53, 76, 66, 66), 
  y = c(30, 20, 85, 5, 5, 55)
)
```

Overall, it's a slightly hacky solution to include a lot of blank spaces between the country name and the score to put the flags in between them, but I don't know of any geoms that can incorporate both text and images at the same time so the hacky solution will do!

To show the flags I use the `geom_flag()` function from the `ggimage` package. The function requires you to pass a two-digit ISO code in the __image__ argument for the flags of the countries you want. You can find the ISO codes for countries with a quick google search, Portugal is __""PT""__ and Spain is __""ES""__.

```{r geom_flag, eval=FALSE}

flag_data <- data.frame(
  image = c(""PT"", ""ES""),
  x = c(110, 110),
  y = c(19.1, 50.1)
)

## ggplot2 code ##
geom_flag(data = flag_data,
          aes(x = x, y = y,
              image = image, size = size))  
## ggplot2 code ##

```

Some other options to do this include using the `ggflags` package or if you don't like the flags used in `geom_flag()`, pass an image of a flag of your choosing to `geom_image()`.

There is actually a better way to search for the ISO codes which I will show later!

This time, instead of the soccer ball image, I used the `emoji_search()` function from the `emoGG` package to find a soccer ball emoji. Then I can use either emoGG or ggimage's `geom_emoji()` function to insert it into my ggplot!

```{r emoji, warning=FALSE, message=FALSE}
library(emoGG)
library(ggimage)

emoji_search(""soccer"") # ""26bd""

```

```{r geom_emoji, eval=FALSE}
## ggplot2 code ##
ggimage::geom_emoji(aes(x = 105, 
                        y = c(45, 50, 55)),
                    image = ""26bd"", size = 0.035)
## ggplot2 code ##
```

From now on, instead of the soccer ball image in the first graphic, I will be using the emoji version!

The official World Cup font, _""Dusha""_, was created by a Portugese design agency back in 2014 and has been used in all official World Cup prints and graphics. Some of the letters may look a bit squished but overall I quite like it, so I wanted to incorporate it in my plots. To do so you need to download the `.TTF` file from [here](http://fifa2018wiki.com/fifa-2018-font-typeface-download-dusha-font-ttf/509/), then right-click and install it. Now, we need to make sure R can use it, this can be done by using the `extrafont` package!

```{r extrafont, eval=FALSE}
font_import()  # import font files in your computer

font_install() # install any new font files added to your computer

loadfonts()    # run every new session once!

fonts()        # to check out what fonts are ready for use in R!
```

For more details check out the package __README__ [here](https://cran.r-project.org/web/packages/extrafont/README.html). Again, remember to run `loadfont()` everytime you open up a new session!

## Osako's Winner vs. Colombia

I wasn't expecting much from Japan's World Cup journey this time around due to our poor performances in the friendlies (besides the Paraguay game) and the fact that we changed our manager in April! However, with a historic win (our first against South American opposition in the World Cup), I couldn't resist making another R graphic:

```{r Osako winner data, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(extrafont)
library(ggimage)
library(countrycode)

cornerkick_data <- data.frame(x = 99, y = 0.3,
                              x2 = 94, y2 = 47)

osako_gol <- data.frame(x = 94, y = 49,
                        x2 = 100, y2 = 55.5)

player_label <- data.frame(x = c(92, 99), 
                           y = c(49, 2))

annotation_data <- data.frame(
  x = c(110, 105, 70, 92, 53), 
  y = c(30, 30, 45, 81, 85),
  hjust = c(0.5, 0.5, 0.5, 0.5, 0.5),
  label = c(""Japan             (2) vs. Colombia             (1)"",
            ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
            ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
            ""Bonus: Ospina looking confused and\ndoing a lil' two-step-or-god-knows-what."",
            ""by Ryo Nakagawara (@R_by_Ryo)"")
)

flag_data <- data.frame(
  x = c(110, 110),
  y = c(13, 53),
  team = c(""japan"", ""colombia"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)

wc_logo <- data.frame(x = 107,
                       y = 85) %>% 
  mutate(image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")

```

```{r Osako winner plot, fig.width=7, fig.height=5, warning=FALSE, message=FALSE}

ggplot(osako_gol) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5""),
        plot.margin=grid::unit(c(0,0,0,0), ""mm"")) +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_curve(data = cornerkick_data,
             aes(x = x, y = y, xend = x2, yend = y2),
             curvature = -0.15, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(aes(x = x, y = y, xend = x2, yend = y2),
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_label(data = player_label, 
             aes(x = x, y = y),
             label = c(""Osako"", ""Honda""), family = ""Dusha V5"") +
  geom_point(aes(x = 98, y = 50), size = 3, color = ""green"") +
  geom_text(aes(x = 99.7, y = 50), size = 5, label = ""???"", family = ""Dusha V5"") +
  geom_text(data = annotation_data,
            family = ""Dusha V5"", 
            aes(x = x, y = y,
                hjust = hjust, label = label), 
            size = c(6.5, 4.5, 4, 3.5, 3)) +
  ggimage::geom_flag(data = flag_data,
                     aes(x = x, y = y,
                         image = image),       
                     size = c(0.08, 0.08)) +
  ggimage::geom_emoji(aes(x = 95, 
                          y = 50),
             image = ""26bd"", size = 0.035) +
  geom_image(data = wc_logo,
             aes(x = x, y = y,
                 image = image), size = 0.17)

```

I could have used the `annotate()` function to add the little comment about Ospina being stuck in no-man's-land but I prefer to have all of my text in a single dataframe. Like before, I again had to expand the x-axis limits in the `coord_flip()`. This is also so we can insert the World Cup image on the top right without using grobs/Magick and such. To grab that World Cup logo, we do the same things as we did when we added the soccer ball image in the first plot with `ggimage`.

For finding the ISO codes to input for the `geom_flag()` function we can do one better than previous attempts by using the `countrycode` package to find ISO codes without having to manually search online!

By passing country names into `countrycode()` function and labelling them as __""country.name""__ in the __origin__ argument, the function will know that the input is the regular name for a country. Then you specify the output such as __""iso2c""__ for the two-digit ISO codes such as in our case, __""wb""__ for World Bank codes, __""eurostat.name""__ for country names in the Eurostat database and so on...!

```{r ISO flag, warning=FALSE, message=FALSE}
library(countrycode)

flag_data <- data.frame(
  x = c(110, 110),
  y = c(13, 53),
  team = c(""japan"", ""colombia"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)

glimpse(flag_data)

```

Although the ISO codes are pretty intuitive for countries like Japan and Colombia, when you're dealing with lots of countries like at the World Cup or the Olympics, having a reproducible workflow for this is very helpful! 

In a future part (not necessarily the next part), I want to animate some of these goal graphics using the great `gganimate` and `tweenr` packages. I've been slowly working my way through them in the past week so here is a preview:

I'll only show a `gganimate` version of Gazinsky's goal for now as I'm still figuring out how to interpolate multiple moving objects (the ball and the players) as well as making the green movement lines disappear after the player finished moving. 

```{r gazinsky animate, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
library(gganimate)
library(tweenr)
# loadfonts()

# data
pass_data <- data.frame(
  x = c(100, 94, 82, 82.5,  84, 76.5, 75.5, 94, 99.2),       # pass balls
  y = c(0,   35, 31, 22,     8, 13, 19, 60, 47.5),
  label = ""ball movement"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

golovin_movement <- data.frame(
  x = c(78, 80, 80, 80, 75, 74, 73, 73, 73),
  y = c(30, 30, 27, 25,  10, 9, 15, 15, 15),
  label = ""Golovin"",
  time = c(1, 2, 3,  4,  5,  6,  7,  8,  9)
)

zhirkov_movement <- data.frame(
  x = c(98, 90, 84, 84, 84, 84, 84, 84, 84),
  y = c( 0,  2,  2,  2,  2,  2,  2,  2,  2),
  label = ""Zhirkov"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

gazinsky_movement <- data.frame(
  x = c(91.5),
  y = c(69),
  label = ""Gazinsky"",
  time = c(6, 7, 8, 9)
)

# segment golovin should only appear 4-5
# segment zhirkov should only appear 1-3
segment_data <- data.frame(
  x = c(77.5, 98),
  y = c(22, 2),
  xend = c(75, 84),
  yend = c(15, 3),
  linetype = c(""dashed"", ""dashed""),
  color = c(""darkgreen"", ""darkgreen""),
  size = c(1.2, 1.25)
)

saudi_data <- data.frame(
  x = c(95),
  y = c(35)
)

# animate

ani <- ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(data = segment_data, 
               aes(x = x, y = y, 
                   xend = xend, yend = yend),
               size = segment_data$size,
               color = segment_data$color,
               linetype = c(""dashed"", ""dashed"")) +
  geom_label(
    data = golovin_movement,
    aes(x = x, y = y,
        frame = time,
        label = label)) +
  geom_label(
    data = zhirkov_movement,
    aes(x = x, y = y,
        frame = time,
        label = label)) +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        frame = time,
        label = label)) +
  geom_point(
    data = saudi_data,
    aes(x = x, y = y),
    color = ""darkgreen"",
    size = 5) +
  ggimage::geom_emoji(
    aes(x = x, y = y, 
        frame = time), 
    image = ""26bd"", 
    size = 0.035) +
  theme(text = element_text(family = ""Dusha V5"")) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"")

gganimate(ani, ""gazi_goal.gif"", title_frame = FALSE)

```

For Osako's goal, here's a preview of the `tweenr` version. Working on this was much easier as I had made it so that the only moving bit to interpolate was the path of the ball.

```{r osako tween, echo=FALSE, warning=FALSE, message=FALSE}
library(purrr)
library(tweenr)


ball_data <- data.frame(x = c(99, 94, 100),
                        y = c(0.3, 47, 55.5))

ball_list <- map(seq(nrow(ball_data)),
                      ~ ball_data[c(seq(.x), rep(.x, nrow(ball_data) - .x)), ])
  
osako_tween <- ball_list %>% 
  tween_states(tweenlength = 1.5, statelength = 0.01, ease = ""quadratic-out"", nframes = 50)

os_t <- osako_tween %>% group_by(.frame) %>% slice(3)
# take only changed 3rd value (1 and 2 of each frame are just copies of ball point origin coords)

g2 <- ggplot(os_t) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_label(data = player_label, 
             aes(x = x, y = y),
             label = c(""Osako"", ""Honda""), family = ""Dusha V5"") +
  geom_point(aes(x = 98, y = 50), size = 3, color = ""green"") +
  annotate(geom = ""text"", family = ""Dusha V5"", 
           hjust = c(0.5, 0.5, 0.5, 0.5),
           size = c(6.5, 4.5, 4, 3),
           label = c(""Japan             (2) vs. Colombia             (1)"",
                     ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
                     ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
                     ""by Ryo Nakagawara (@R_by_Ryo)""),
           x = c(110, 105, 70, 53), 
           y = c(30, 30, 45, 85)) +
  ggimage::geom_emoji(aes(x = x, 
                          y = y,
                          frame = .frame),
             image = ""26bd"", size = 0.035) +
  ggimage::geom_flag(aes(image = ""JP""),       # Japan Flag
            x = 110, y = 13, size = 0.08) +
  ggimage::geom_flag(aes(image = ""CO""),       # Colombia Flag
            x = 110, y = 53, size = 0.08) +
  geom_image(data = wc_logo,
             aes(x = x, y = y,
                 image = image), size = 0.17) +
  theme(plot.margin=grid::unit(c(0,0,0,0), ""mm""))

gganimate(g2, 
          ani.width = 800, ani.height = 500, 
          interval = 0.01,
          ""osako_goal.gif"") 

```

I've been playing around a lot with the different easing functions using [this](https://easings.net/) website as a reference but it still doesn't feel 100% right... For this one I used __""quadratic-out""__. I want to make sure that the ball doesn't completely come to a full stop when it reaches Osako but most keep doing that. 

These goals are just from the first week of the World Cup and if I had the time I would do more as there have been some fantastic individual and team goals so far! 

With the Group Stages done, I am looking forward to an even more exciting Knockout Stage, good luck to all of your favorite teams! 

And hopefully no own goals:

[Sommer's bad luck](https://www.youtube.com/watch?v=Fjh16v8UffU)

Or other mishaps:

![lol](https://gfycat.com/PitifulSeparateAlpineroadguidetigerbeetle)

Part 2 will be coming soon!

","2018"
"75",242,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/blog posts/soccer_plots_part2.rmd","---
title: ""World Cup Drama: Visualizing Changes in the Group Table During the Final Matchday""
author: ""RN7""
date: ""June 27, 2018""
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is __Part 2__ of my World Cup Data Viz Series (See Part 1 [here](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/))! I was originally planning for my animated goals to be Part 2 but that will have to wait for now. In this blog post I'll be showing you the visualizations I made for how the group table changed throughout the final matchday that I've been posting on [Twitter](https://twitter.com/R_by_Ryo). 

I thought I'll go through the entire code to use as a reference and as a sounding board for creating some kind of function/package for these graphs in the future!

Besides the code I will go through some of the design/ggplot2 choices I made as well.

Here's an example using __Group H__:

```{r echo = FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
#loadfonts()  run once per new session!

group_h <- data.frame(

  time =      c( 1, 2, 3, 4),
  japan =   c(   1, 3, 2, 2),
  senegal =   c( 2, 1, 3, 3),
  colombia =   c(3, 2, 1, 1),
  poland = c(    4, 4, 4, 4)
  
)

group_h <- group_h %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team)) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""japan"", ""senegal"", ""colombia"", ""poland""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""59'"", ""74'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 4, 4, 4, 4),
  y = c(3, 1, 1, 2, 3, 4),
  score = c(""0-1"", ""1-0"", 
            ""1-0"", ""0-1"", ""0-1"", ""1-0"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""Japan"", ""Senegal"", ""Colombia"", ""Poland"")
)

goals_labs <- data.frame(
  x = c(2, 3),
  y = c(3, 1),
  scorers = c(""Bednarek (Poland)"", ""Mina"")
)

points_labs <- data.frame(
  x = c(4.8, 4.8, 4.8, 4.8),
  y = c(1, 2, 3, 4),
  points = c(""6 pts."", ""4 pts."", ""4 pts."", ""3 pts."")
)

## PLOT

ggplot(
  group_h,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 6) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 6) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.25, size = 4) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    size = 5) +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:4,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.6, 5)) +
  labs(
    title = ""Group H Table Throughout The Last Matchday"",
    subtitle = ""Japan vs. Poland & Senegal vs. Colombia"",
    caption = ""by @R_By_Ryo"") +
  theme_minimal() +
  theme(
    text = element_text(family = ""Dusha V5"", size = 18),
    axis.title = element_blank(),
    legend.position = ""none"",
    panel.grid = element_blank())

```

Below you can take a look at the graphics I made for each Group:

[Group A](https://i.imgur.com/s5reY7g.png) | [Group B](https://i.imgur.com/4L8BHqE.png) | [Group C](https://i.imgur.com/tUDR8oF.png) | [Group D](https://i.imgur.com/BYT1E2P.png)
------------|-------------|-------------|------------
[__Group E__](https://i.imgur.com/svW9wEg.png) | [__Group F__](https://i.imgur.com/AQUE8B0.png) | [__Group G__](https://i.imgur.com/ikYlshs.png) | [__Group H__](https://i.imgur.com/HKAsin8.png)

In my opinion, Group D was probably the most exciting so let's work through that one as the example!

Let's take a look at the packages I'll be using:

```{r warning=FALSE, message=FALSE}
library(dplyr)        # the usual data cleaning
library(tidyr)        # the usual data tidying
library(forcats)      # dealing with factor data
library(ggplot2)      # plotting
library(ggimage)      # adding images and flags into the plots
library(countrycode)  # easy way to access ISO codes
library(extrafont)    # inserting custom fonts into the plots
# loadfonts()  run once per new session!

```

## Base dataframe

The most important part of the plot is the dataframe that houses each team's ranking during the final 90 minutes, there is a new column in the graph each time the ranking changes due to a goal or yellow/red card. You can take a look at the tie-breakers [here](https://www.fifa.com/worldcup/news/tie-breakers-for-russia-2018-groups).

```{r initial df}
group_d <- data.frame(

  time =      c(1, 2, 3, 4, 5, 6, 7),
  croatia =   c(1, 1, 1, 1, 1, 1, 1),
  nigeria =   c(2, 3, 2, 2, 2, 3, 3),
  iceland =   c(3, 4, 3, 4, 3, 4, 4),
  argentina = c(4, 2, 4, 3, 4, 2, 2)
  
)

```

This format is very easy to create but it is not a great format to use as an input for `ggplot2`, therefore we need to use `gather()` to collect the data into key-value pairs. The `key` variable is `team` and the `value` variable we want to create is `position` for what rank each team is in at each specific `time` column.

```{r spread() + ISO codes}

group_d <- group_d %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""croatia"", ""nigeria"", ""argentina"", ""iceland""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

glimpse(group_d)

```

As previously mentioned in [Part 1](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/) you can use the `countrycode()` function from the `countrycode` package to easily extract the __ISO__ codes needed for the `geom_flag()` function when it comes to plotting.

## Label dataframes

Now let's take a look at all the different label dataframes:

The `country_labs` just has the name of the four teams in the group and their position in the first column, ""0'"".

```{r country labs}
country_labs <- data.frame(
  x = c(rep(1, 4)),
  y = c(rep(1:4, 1)),
  country = c(""Croatia"", ""Nigeria"", ""Iceland"", ""Argentina"")
)

```

The x-axis variable `time` is numbered from `1:n` in the main dataframe, so it is necessary to provide the correct minute labels here. The two constants here are the ""0'"" mark and the ""Full Time"" mark. The labels for the y-axis variable, ""position"", are self-explanatory.

```{r axis labels}

x_labs <- c(""0'"", ""14'"", ""51'"", ""53'"", ""76'"", ""86'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

```

Next are the labels for when a goal changes the rank of the teams in the table. The only constant here is that the each team will have the final score of their game labelled in the last column, __""Full Time""__. A thing to note is that as teams can move depending on goals scored by other teams, it is important to make sure you are putting the labels in the right place. In Group D, Iceland was in 3rd but when Croatia scored against them they moved down to 4th. Therefore, I placed the score label under Iceland's flag with the opponent's score on the right side ( _0-1_ instead of _1-0_) to show that they conceded and placed Croatia's goalscorer underneath the previous label. Any goals that didn't change the rankings are listed under each team in the ""Full Time"" column.

```{r score + goal labs}
score_labs <- data.frame(
  x = c(2, 3, 4, 5, 6, 
        7, 7, 7, 7),    # always have score labels for every team at FULL TIME
  y = c(2, 2, 4, 3, 2, 
        1, 2, 3, 4),
  score = c(""1-0"", ""1-1"", ""0-1"", ""1-1"", ""2-1"", 
            ""2-1"", ""2-1"", ""1-2"", ""1-2"")          # Full Time scores
)

goals_labs <- data.frame(
  x = c(2, 3, 4, 5, 6, 7),
  y = c(2, 2, 4, 3, 2, 1),
  scorers = c(
    ""Messi"", ""Moses (pen.)"", ""(Croatia)\nBadelj"", 
    ""G. Sigurdsson (pen.)"", ""Rojo"", ""Perisic (90')"")
)

```

Finally, the points dataframe: The total amount of points each team earned after all group games have finished. 

```{r points labs}
points_labs <- data.frame(
  x = c(rep(max(group_d$time), 4)),
  y = c(rep(1:4, 1)),
  points = c(""9 pts."", ""4 pts."", ""3 pts."", ""1 pts."")
)

```

I made things slightly easier on myself by using the `rep()` function a lot. This is done so that it guards against any typos I make when creating the individual dataframes. Now, I only have to make changes to the initial base dataframe's `positions` column and the other dataframes will expand/contract as needed. When this happens I will of course need to add or subtract a label as necessary but this saves me time from individually deleting a series of `x/y` coordinate numbers. I can only do this for columns which have a series of `positions` that are strictly set, like how in the `country_labs` dataframe there are only ever going to be `1, 2, 3, 4` y-axis ticks. For the `points_labs` dataframe, I use `rep()` with `max()` as the points label positions are only ever going to be found in the last `time` column, or in other words, the largest number in the `time` row in the initial base dataframe.

These dataframes are consistent across all the groups with the number of columns expanding or contracting depending on the number of goals AND if they cause any changes in the ranking. I am thinking up of a way to easily transform all of these into some neat little package but for now this ""template"" of sorts will do...

## Custom `theme()`

Before we start plotting, we can set some custom `theme()` defaults:

```{r theme()}

theme_matchday <- theme_minimal() +
  theme(
    text = element_text(family = ""Dusha V5"", size = 18),
    axis.title = element_blank(),
    axis.text = element_text(color = ""grey30""),
    legend.position = ""none"",
    panel.grid = element_blank())

```


## Plot with `ggplot2`

Pretty standard `ggplot2` code was used for these graphics. The only one you may be unfamiliar with is the `geom_flag()` function from the `ggimage` package to insert pictures of the country's flags as the data points. With the x,y coordinate positions of each `geom_text()` defined in the dataframes, all it takes is to use the various `nudge_*()` arguments to set the labels above or below the flag data points in their respective places. `scale_y_reverse()` is used to flip the y-axis ticks so that they go 1 to 4 from top to bottom.


```{r fig.width=8, fig.height=5}

# NOTE: Argentina in 4th at start due to more yellow cards in tie-breaker vs. Iceland.

ggplot(group_d, aes(time, position)) +
  geom_line(
    aes(group = team), 
    linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.38, size = 3.5) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    nudge_x = 0.8,
    size = 5,
    color = ""grey30"") + # match color with the other axes labels!
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:7,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.5, 8.1)) +
  labs(
    title = ""Group D Table Throughout The Last Matchday"",
    subtitle = ""Nigeria vs. Argentina & Iceland vs. Croatia"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

```


## Visualization design and problem solving with ggplot2

Here I'll make some notes on what I thought about making these graphs as well as some comments on visualization design.

One thing that I always had to keep in mind while creating the initial ""base"" dataframe was that not __ALL__ the goals scored caused a change in the group table. This meant that I needed to be constantly thinking backwards as to how the group table changed before/after a goal was scored. In addition, it was difficult to keep in mind the different [tie-breakers](https://www.fifa.com/worldcup/news/tie-breakers-for-russia-2018-groups) (goal difference, head-to-head score, yellow/red cards, etc.) involved between the teams at every different event point in the games. Thankfully (though not from a match quality point of view), some group tables were already completely decided by Matchday 2 and required very little cognitive effort on my part, like Groups __A__, __C__, and __E__.

The __key__ point of these graphs were to emphasize the __movement__ of _teams_ in the group table as a result of certain events. Therefore, I had to be wary of not introducing too much detail into the plots so I could direct the viewer's focus on the flags rather than the labels. 

Along that line of reasoning, I at first was thinking about having the goal scorer text be inside `geom_label()` instead of `geom_text()` but I ultimately didn't as I thought it would obscure the dotted movement lines too much, especially since some of the player names and the ""pens."" or ""o.g."" would take up a lot of space.

I also originally had the total group points in a darker black but I figured it made the graph look lopsided. I changed all the surrounding axis text to be a uniform __""grey30""__ so that the axis labels would visually ""surround"" the plot and direct focus towards the flags inside. 

A possible point of confusion is that it can be hard to tell which teams are playing which in the final matchday. Without a clear label it can be confusing as a goal in one game may not affect the teams in that match but can completely change the rankings of the teams in the other game! In the end, the best I could do was to include the matchups in the __subtitle__ of the plot but I'm still thinking about whether there's a more effective method.

The most difficult part of this whole process of making a graph for each group was the problem of iteration. Each group had different amounts of goals or rank-changing events as well as more aesthetic things such as the length of the country names and goal scorer names that made tweaking each plot individually a necessity. It would have saved me a lot of time if I could have turned this into a package somehow but with all the moving pieces of this puzzle and how they are interconnected with eachother I wasn't able to for now. 

These were very fun to make and I plan to make some more for next season's _Champions League_ groups as well as for the _Asian Cup_ in January of 2019 and maybe even for the _Asian Games_ next month! So creating a package may be something I turn my full attention to once this World Cup is over! On a positive note, I'm very thankful that there were no blowouts on the final matchday as fitting in the goal scorer labels would've been an absolute nightmare!

See you in Part 3!
","2018"
"76",243,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/blog posts/soccer_plots_part3.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""July 24, 2018""
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

__Animating__ the Goals of the World Cup: Comparing the __old__ vs. __new__ `gganimate` and `tweenr` API!

Welcome to **Part 3** of my series on ""Visualizing the World Cup with R""! This is the culmination of this mini project that I've been working on throughout the World Cup. In addition, from having listened to **Thomas Pedersen's** excellent [keynote](https://www.youtube.com/watch?v=21ZWDrTukEs) at __UseR! 2018__ in Brisbane on the **NEW** gganimate and tweenr API, I am taking advantage of the fortuitous timing to also compare the APIs using the goals as the examples!

I've had finished these animations a couple of weeks ago but didn't make them available until I presented at the [TokyoR](https://twitter.com/TokyoRCommunity) MeetUp last week! **Hadley Wickham** and **Joe Rickert** were the special guests and with the amount of speakers and attendees it felt more like a mini-conference than a regular meetup, if you're ever in Tokyo come join us for some R&R...and R! You can check out a recording of my talk on [YouTube](https://www.youtube.com/watch?v=tNncHFd5dVo).

Let's get started!

## Coordinate position data

Since this series started, several people have asked me where I got the data. I thought I made it quite clear in [Part 1](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/) but I will reiterate in the next few paragraphs.

I get a lot of my data science/visualization news from Twitter which has made a weird comeback by providing a platform for certain communities like `#rstats` (never thought I'll be creating a Twitter account in 2017!). Therefore, I've been able to come across some wonderful visualizations for the World Cup by **The Financial Times**, **FiveThirtyEight**, and a host of other people. As you can see from a great example of World Cup penalties by the **BBC** below, data is provided by sports analytics companies, primarily **Opta**!

<center>
<img src=""https://ichef.bbci.co.uk/onesport/cps/624/cpsprodpb/79E6/production/_102260213_1_penalties_scored_640-nc.png"" style=""height: 300px"" />
</center>

Great! But can an average joe like me just waltz in, slap down a fiver, and say ""GIMME THE DATA""? Well, unfortunately no, it costs quite a lot! This isn't really a knock on Opta or other sports analytics companies since FIFA or the FAs of respective nations didn't do this kind of stuff, the free market stepped in to fill the gap. Still, I'm 100% sure I am not the only one who wishes this kind of data was free though, well besides some datasets of varying quality you see on Kaggle (but none of those are as granular as the stuff Opta provides anyway).

So, envious of those who have the financial backing to procure such data and some mild annoyance at others online who didn't really bother sharing exactly how they got their data or even what tools they used, I started thinking of ways that I could get the data for myself.

One possible way was to use **RSelenium** or other JavaScript web scrapers on soccer analytics websites and their cool dashboards, like [WhoScored.com](https://www.whoscored.com/). However, since I wouldn't have been able to master these tools before the World Cup ended (during which whatever I end up creating would be most relevant), I decided that I'll create the coordinate data positions myself!

<center>
<img src=""https://i.imgur.com/Hn9X0GC.gif"" style=""width: 400px"" />
</center>


With the plotting system in [ggsoccer](https://github.com/Torvaney/ggsoccer) and `ggplot2` it's really not that hard to figure out the positions on the soccer field plot, as you can see in the picture below:

```{r example field, eval=FALSE, fig.width=9, fig.height=6}
ggplot(point_data) +
  annotate_pitch() +
  theme_pitch(aspect_ratio = NULL) +
  coord_flip() +
  geom_point(
    aes(x = x, y = y), 
    size = 1.5) +
  geom_text(
    aes(x = x, y = y,
        label = label),
    vjust = 1.5, color = ""red"")
```

<center>
<img src=""https://i.imgur.com/ejgbOFg.png"" style=""width: 500px"" />
</center>

There's also a way to make the coordinates be in **120x80** format (which is much more intuitive) and you can do that by adding the `*_scale` arguments inside the `annotate_pitch()` function. However, I only realized this after I had embedded the coordinate positions for the **100x100** plot in my head so that's what I kept going with.

There is also the **""Soccer event logger""** [here](https://github.com/Torvaney/elm-soccer-tracker) (incidentally also by [Ben Torvaney](https://twitter.com/Torvaney)) which allows you to mouse-click specific points on the field and then download a `.csv` file of the coordinate positions you clicked. This might be easier but personally I like to experiment within the R environment and take notes/ideas in RMarkdown as I do so, it definitely is an option for others though.

... and that's how [Part 1](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/) was born! But I wasn't going to stop there, soccer is a moving - flowing game, static images are OK but it just doesn't capture the **FEEL** of the sport. So this is where `gganimate` and `tweenr` came in!

Out of all the World Cup stuff I've animated so far, by far the most complicated was [Gazinsky's goal](https://www.youtube.com/watch?v=mE79PUhe1_8) in the opening game. This is because I not only have to track the ball movement but the movement of multiple players as well. So most of the **comparison** aspect of the APIs will be done with this goal.

Let's take a look at the packages that I'll be using:

```{r packages, message=FALSE, warning=FALSE}
library(ggplot2)    # general plotting base
library(dplyr)      # data manipulation/tidying
library(ggsoccer)   # draw soccer field plot
library(ggimage)    # add soccer ball emoji + flags
library(extrafont)  # incorporate Dusha font into plots
library(gganimate)  # animate goal plots
library(tweenr)     # create in-between frames for data
library(purrr)      # for creating a list of dataframes for tweenr
library(countrycode)# for finding ISO codes for geom_flag()
# loadfonts()         run once every new session
```

## Gazinsky's first goal:

Let's first look at the set of dataframes with the coordinate data points necessary for this to work:

```{r gazinsky data}
pass_data <- data.frame(
  x = c(100, 94, 82, 82.5,  84, 76.5, 75.5, 94, 99.2),     
  y = c(0,   35, 31, 22,     8, 13, 19, 60, 47.5),
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

golovin_movement <- data.frame(
  x = c(78, 80, 80, 80, 75.5, 74.5, 73.5, 73, 73),  
  y = c(30, 30, 27, 25,   10,    9, 15, 15, 15),
  label = ""Golovin"",
  time = c(1, 2, 3,  4,  5,  6,  7,  8,  9)
)

zhirkov_movement <- data.frame(
  x = c(98, 90, 84, 84, 84, 84, 84, 84, 84),
  y = c( 0,  2,  2,  2,  2,  2,  2,  2,  2),
  label = ""Zhirkov"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

gazinsky_movement <- data.frame(
  x = c(0, 0, 0, 0, NA, 92,   92,   92,   92),
  y = c(0, 0, 0, 0, NA, 66.8, 66.8, 66.8, 66.8),
  label = ""Gazinsky"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

# ONLY in static + gganimate versions
segment_data <- data.frame(
  x = c(77.5, 98),
  y = c(22, 2),
  xend = c(75, 84),
  yend = c(15, 3),
  linetype = c(""dashed"", ""dashed""),
  color = c(""black"", ""black""),
  size = c(1.2, 1.25)
)

# saudi defender
saudi_data <- data.frame(
  x = c(95, 95, 90, 87, 84, 80, 79, 79, 79),
  y = c(35, 35, 35, 32, 28, 25, 24, 25, 26),
  label = ""M. Al-Breik"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

### soccer ball
ball_data <- tribble(
  ~x,  ~y, ~time,
  100,   0,   1,
  94,   35,   2,
  82,   31,   3,
  82.5, 25,   4,
  84,    6,   5, 
  77,   13,   6,
  76,   19,   7,
  94,   60,   8,
  99.2, 47.5, 9
  
) 

```

If you're manually creating these, you could also use `tribble()` instead of a `dataframe()`. It takes up a bit more space, as you can see in `ball_data`, but it is probably more readable for when you're sharing the code (like creating a reprex on SO or RStudio Community).

And here is the `ggplot` code for the `gganimate` version (no tween frames)!

**Note**: You need to be careful about the ordering of the `ggplot` elements. You need to make sure the soccer ball emoji code is near the end, after the labels, so that the player name labels don't cover the soccer ball as it's moving around!

```{r gazinsky old gganimate, eval=FALSE}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(
    xlim = c(49, 101),
    ylim = c(-1, 101)) +
  geom_segment(
    data = segment_data, 
    aes(x = x, y = y, 
        xend = xend, yend = yend),
    size = segment_data$size,
    color = segment_data$color,
    linetype = c(""dashed"", ""dashed"")) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(data = zhirkov_movement,
    aes(x = x, y = y,
        frame = time,
        label = label),
    color = ""red"") +
  geom_label(data = golovin_movement,
    aes(x = x, y = y,
        frame = time,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  ggimage::geom_emoji(
    data = ball_data,
    aes(x = x, y = y, frame = time),   
    image = ""26bd"", size = 0.035) +
  ggtitle(
    label = ""Russia (5) vs. (0) Saudi Arabia"", 
    subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(
    ""text"", x = 69, y = 65, family = ""Dusha V5"",
    label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5""))

```

<center>
<img src=""https://i.imgur.com/V9drm0I.gif"" />
</center>


Now let's check out how we would do it with the in-between frames added in using `tweenr`!

The important bit with the old API was that you had to create a list of dataframes of the different states of your data. In this case, it is a dataframe for each observation of the data or to put it more simply, the ""time"" variable (a dataframe of coordinate positions for time = 1, time = 2, etc.). This is done with `pmap()` with `dataframe()` being passed to the `.f` argument.

With this list of dataframes created, we can pass it into `tween_states()` function to create the in-between frames to connect each of the dataframes in the list. Take note of the arguments in `tweent_states()` as they'll show up again in the new API later.

```{r old tweenr, eval=FALSE}
### soccer ball
b_list <- ball_data %>% pmap(data.frame)

ball_tween <- b_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

### Golovin
golovin_movement_list <- golovin_movement %>% pmap(data.frame)
  
golovin_tween <- golovin_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

golovin_tween <- golovin_tween %>% mutate(label = ""Golovin"")

### Zhirkov
zhirkov_movement_list <- zhirkov_movement %>% pmap(data.frame)
  
zhirkov_tween <- zhirkov_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

zhirkov_tween <- zhirkov_tween %>% mutate(label = ""Zhirkov"")
```

Now with these newly created tween dataframes, we pass them into our `ggplot` code as before and specify the `frame` argument with the newly created "".frame"" variable.

```{r gazinsky old tweenr, eval=FALSE}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(data = zhirkov_tween,
    aes(x = x, y = y,
        frame = .frame,
        label = label),
    color = ""red"") +
  geom_label(data = golovin_tween,
    aes(x = x, y = y,
        frame = .frame,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  ggimage::geom_emoji(
    data = ball_tween,
    aes(x = x, y = y, frame = .frame),   
    image = ""26bd"", size = 0.035) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5""))
```

<center>
<img src=""https://i.imgur.com/GQYSJSH.gif"" />
</center>


Looks good. Now let's check out how things changed with the new API!

## __New__ gganimate & tweenr

Once again, let's start by looking at just animating across the ""time"" variable without creating in-between frames.

```{r gazinsky NEW gganimate, warning=FALSE, fig.width=8, fig.height=6, fig.align='center'}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(
    data = segment_data, 
    aes(x = x, y = y, 
        xend = xend, yend = yend),
    size = segment_data$size,
    color = segment_data$color,
    linetype = c(""dashed"", ""dashed"")) +
  geom_label(
    data = zhirkov_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = golovin_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") + 
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  ggimage::geom_emoji(
    data = ball_data,
    aes(x = x, y = y),   
    image = ""26bd"", size = 0.035) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  # new gganimate code:
  transition_manual(time)

```

It's quite nice that I don't have to specify `frame = some_time_variable` in every geom that I want animated now!

However, you can see that like in the old gganimate code the new `transition_manual()` function just speeds through the specified ""time"" variable without actually creating in-between frames. Let's use the other `transition_*()` functions to specify the tween frames and set the animation speed.

Here I will use `transition_states()` with ""time"" being the column I pass to the `states` argument. Instead of having to create a "".frame"" column with the `tween_states()` function I can just pass the ""time"" variable into the `transition_states()` function and it will tween the frames for you in addition to the `ggplot` code! The `transition_length` argument is the same as the `tween_length` argument from the old `tween_states()` function and `state_length` argument is the same here too.

Unlike in the version I showed in my presentation, I added Mohammed Al-Breik's movement as well. I felt it was a bit silly (and unfair) to show him just standing there after his headed clearance!

```{r gazinsky NEW tweenr, warning=FALSE, fig.width=8, fig.height=6, fig.align='center'}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(
    data = zhirkov_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = golovin_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  enter_grow(fade = TRUE) +
  ggimage::geom_emoji(
    data = ball_data,
    aes(x = x, y = y),   
    image = ""26bd"", size = 0.035) +
  ggtitle(
    label = ""Russia (5) vs. (0) Saudi Arabia"", 
    subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(
    ""text"", x = 69, y = 65, family = ""Dusha V5"",
    label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5"")) +
  # new gganimate code:
  transition_states(
    time, 
    transition_length = 0.5, 
    state_length = 0.0001,
    wrap = FALSE) +
  ease_aes(""linear"")

```

Now you may be wondering why I didn't use the more logical choice, the `transition_time()` function here so let me explain.

I manually created the timing of the coordinate data so naturally, the transitions would be slightly off compared to real data. This goal animation was split into 9 ""time"" values for each important bit of the play that I thought would transition well when connected with eachother. Then I ran it through `gganimate` to see if it flowed well and once I was satisfied, I let `tweenr` fill in the blanks between each ""time"" value.

With the new API however, using `transition_time()` function wouldn't allow me to control transition length and state length like with `transition_states()`! Try running the code above with `transition_time(time = time)` instead and you'll see what I mean.

If I had real data and the proper timing values in the ""time"" column that seamlessly worked with the coordinate data points it would have then been appropriate to use `transition_time()`. Some examples of these kind of data sets include the gapminder data set used in the package README which used the ""year"" variable or the data set in the cool NBA animation by James Curley seen [here](https://rpubs.com/jalapic/nbaplaybyplay) that had very granular data recording the coordinate positions and the exact times.

A cool new thing that you can play around with in the **new** gganimate are the different enter/exit animations! However, I couldn't really get it to work for Gazinsky's label... In the `mtcars` example on the gganimate GitHub Repo, the boxplots disappeared when there was no data for the specific combination of variables but I can't seem to properly set up the Gazinsky label dataframe correctly to implement it.

Ideally, I want Gazinsky's label to only show up from `time = 6` onwards. I tried filling the coordinate positions for `time = 1` to `time = 5` with **NAs** or **0s** but it didn't seem trigger the effect ... when I tried with ""x = 0, y = 0"" in `time = 5`, the player label zipped in from the bottom of the screen to the penalty box at `time = 6` and it was unintentionally very funny!

Any help here will be greatly appreciated!

## Osako's goal vs. Colombia

Japan faced a tough opponent in Colombia, even with the man-advantage early on, in our opening game of the World Cup. Even with our passing tiring out the tenacious Colombians we were finding it hard to find a breakthrough. In came Keisuke Honda, who within minutes of his arrival, delivered a beautiful cross from a corner kick for Osako to head home!

This goal was a lot easier to animate and to be honest this was the first one I was able to actually get working a few weeks ago! This was mainly because the ball movement was the only thing I really had to worry about.

```{r osako data, warning=FALSE}
cornerkick_data <- data.frame(
  x = 99, y = 0.3,
  x2 = 94, y2 = 47)

osako_gol <- data.frame(
  x = 94, y = 49,
  x2 = 100, y2 = 55.5)

ball_data <- data.frame(
  x = c(99, 94, 100),
  y = c(0.3, 47, 55.5),
  time = c(1, 2, 3))

player_label <- data.frame(
  x = c(92, 99), 
  y = c(49, 2),
  label = c(""Osako"", ""Honda""))

wc_logo <- data.frame(
  x = 107,
  y = 85) %>% 
  mutate(
    image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")

flag_data <- data.frame(
  x = c(110, 110),
  y = c( 13, 53),
  team = c(""japan"", ""colombia"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)
```

For this animation, I used one of the many easing functions available in `tweenr`, `quadratic-out`, to get the speed of the ball from a corner kick just about right. You can refer to [this](https://easings.net/) awesome website to check out most of the different easing functions you can use in `ease_aes()`!

```{r osako NEW tweenr, warning=FALSE, fig.height = 5, fig.width = 7, fig.align='center'}
ggplot(ball_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(
    text = element_text(family = ""Dusha V5""),
    plot.margin=grid::unit(c(0,0,0,0), ""mm"")) +
  coord_flip(
    xlim = c(55, 112),
    ylim = c(-1, 101)) +
  geom_label(
    data = player_label, 
    aes(x = x, y = y,
        label = label),
    family = ""Dusha V5"") +
  geom_point(
    aes(x = 98, y = 50), size = 3, color = ""green"") +
  annotate(
    geom = ""text"", family = ""Dusha V5"", 
    hjust = c(0.5, 0.5, 0.5, 0.5),
    size = c(6.5, 4.5, 5, 3),
    label = c(""Japan             (2) vs. Colombia             (1)"",
              ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
              ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
              ""by Ryo Nakagawara (@R_by_Ryo)""),
    x = c(110, 105, 70, 53), 
    y = c(30, 30, 47, 85)) +
  ggimage::geom_emoji(              # soccer ball emoji
    aes(x = x, 
        y = y),
    image = ""26bd"", size = 0.035) +
  ggimage::geom_flag(               # Japan + Colombia flag
    data = flag_data,
    aes(x = x, y = y,
        image = image),       
    size = c(0.08, 0.08)) +
  geom_image(                       # World Cup logo
    data = wc_logo,     
    aes(x = x, y = y,
        image = image), size = 0.17) +
  # new gganimate code:
  transition_states(
    time, 
    transition_length = 0.5, 
    state_length = 0.0001,
    wrap = FALSE) +
  ease_aes(""quadratic-out"")
```

As you can see it's quite easy and fun to make these! I am hoping to make more in the future, especially when the new season begins!

A small note on the flags: I used a bit of a hacky solution to get them into the title but both Ben and Hadley recommended I use the [emo::ji()](https://github.com/hadley/emo) package which allows you to insert emoji into RMarkdown and inline. So that's something I'll be looking into in the near future!

## Japan's Offside Trap vs. Senegal!

For the final animation, I tried to recreate something you don't see everyday - an offside trap!

<center>
<img src=""https://media.giphy.com/media/lk0TFUdop2JTW/giphy.gif"" style=""width: 400px"" />
</center>

```{r offside data}
# PLAYERS
# JAPAN: x, y (blue)     Senegal: x2, y2  (lightgreen)
trap_data <- data.frame(
  
  time = c(1, 2, 3, 4, 5),
  
  # ball trajectory
  x = c(70, 70, 70, 87, 95),       
  y = c(85, 85, 85, 52, 33),
  
  # offside line bar
  #xo =    c(83, 81.2, 79, 77.5, 70),
  xoend = c(83.8, 81.8, 79, 78.5, 71),
  
  yo =    c( 5,  5,  5,  5, 5),
  yoend = c(95, 95, 95, 95, 95),
  
  # players: japan
  jx  = c(83, 81, 77, 75, 70),
  jy  = c(rep(65, 5)),
  
  jx2 = c(83, 81.8, 78.5, 77, 70),
  jy2 = c(rep(60.5, 5)),
  
  jx3 = c(83, 81, 76.5, 75, 71),
  jy3 = c(rep(55, 5)),
  
  jx4 = c(83, 81.2, 76.3, 75, 70),
  jy4 = c(rep(52, 5)),
  
  jx5 = c(82.8, 81, 77, 74, 70),
  jy5 = c(rep(49, 5)),
  
  jx6 = c(83, 81.8, 77, 74, 70),
  jy6 = c(rep(45, 5)),

  jx7 = c(83.8, 81, 79, 77.5, 70),
  jy7 = c(rep(40, 5)),
  
  # players: senegal
  sx = c(83, 84, 84, 84, 84),
  sy = c(rep(33, 5)),
  
  sx2 = c(83, 85, 87, 92, 95),
  sy2 = c(38, 37, 35, 34, 33),
  
  sx3 = c(83, 84, 84, 83, 83),
  sy3 = c(rep(41, 5)),
  
  sx4 = c(83, 84, 83, 78, 78),
  sy4 = c(rep(45, 5)),
  
  sx5 = c(83, 84, 87, 88, 89),
  sy5 = c(rep(52, 5)),
  
  sx6 = c(83, 85, 84, 84, 83),
  sy6 = c(rep(69, 5))
)

# flags
flag_data <- data.frame(
  x = c( 48, 93),
  y = c(107, 107),
  team = c(""japan"", ""senegal"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)

# extra players:
goalkeeper_data <- data.frame(
  x = c(98),
  y = c(50)
)

senegal_data <- data.frame(
  x = c(55, 55, 68.5),
  y = c(50, 60, 87)
)
```

In the code below, take note of the ""wrap"" option in `transition_states()`. You can set it to false if you don't want the last state to transition back to the first state (default == TRUE).

```{r tweenr offside NEW, warning=FALSE, fig.height=10, fig.width=9, fig.align='center'}
ggplot(trap_data) +
  annotate_pitch() +
  theme_pitch(aspect_ratio = NULL) +
  coord_fixed(
    xlim = c(30, 101),
    ylim = c(-5, 131)) +
  # offside line
  geom_segment(aes(x = xoend, y = yo, 
                   xend = xoend, yend = yoend), 
               color = ""black"", size = 1.3) +
  # japan
  geom_point(aes(x = jx, y = jy), size = 4, color = ""blue"") +
  geom_point(aes(x = jx2, y = jy2), size = 4, color = ""blue"") +
  geom_point(aes(x = jx3, y = jy3), size = 4, color = ""blue"") +
  geom_point(aes(x = jx4, y = jy4), size = 4, color = ""blue"") +
  geom_point(aes(x = jx5, y = jy5), size = 4, color = ""blue"") +
  geom_point(aes(x = jx6, y = jy6), size = 4, color = ""blue"") +
  geom_point(aes(x = jx7, y = jy7), size = 4, color = ""blue"") +
  # senegal
  geom_point(aes(x = sx, y = sy), size = 4, color = ""green"") +
  geom_point(aes(x = sx2, y = sy2), size = 4, color = ""green"") +
  geom_point(aes(x = sx3, y = sy3), size = 4, color = ""green"") +
  geom_point(aes(x = sx4, y = sy4), size = 4, color = ""green"") +
  geom_point(aes(x = sx5, y = sy5), size = 4, color = ""green"") +
  geom_point(aes(x = sx6, y = sy6), size = 4, color = ""green"") +
  
  # free kick spot (reference)
  geom_point(aes(x = 70, y = 85), color = ""blue"", size = 1.2) +
  # goalkeeper
  geom_point(
    data = goalkeeper_data,
    aes(x = x, y = y), size = 4, color = ""blue"") +
  # senegal defenders
  geom_point(
    data = senegal_data,
    aes(x = x, y = y), size = 4, color = ""green"") +
  annotate(
    geom = ""text"", family = ""Dusha V5"", 
    hjust = c(0, 0),
    size = c(6, 6.5),
    label = c(""Japan          (2) vs. Senegal         (2)"",
              ""The Perfect Offside Trap""),
    x = c(30,  30), 
    y = c(107, 115)) +
  ggimage::geom_flag(
    data = flag_data,
    aes(x = x, y = y,
        image = image),       
    size = c(0.07, 0.07)) +
  ggimage::geom_emoji(
    aes(x = x, y = y),
    image = ""26bd"", size = 0.035) +
  # NEW gganimate code
  transition_states(
    states = time, 
    transition_length = 0.2, 
    state_length = 0.00000001,
    wrap = FALSE) +
  ease_aes(""linear"")

```

So against the height advantage and physicality of Senegal, the thinking behind Japan's strategy was...

```{r meme, eval=FALSE}
library(memery)
img <- (""https://imgflip.com/s/meme/Roll-Safe-Think-About-It.jpg"")

meme_labs <- c(""you can't lose the aerial battle"", ""if you set an offside trap"")

meme(img, meme_labs, ""offside_meme.png"")

```

<center>
<img src=""https://i.imgur.com/B9Vauq0.jpg"" style=""height: 300px"" />
</center>


Jokes and memes aside, let's take a few minutes to reflect on the new API.

## Personal thoughts:

The best thing about the new API is without a doubt, no more intermediary steps between tweening the data and plotting. As long as you have some kind of ""time"" variable you don't have to manually go and create the list of dataframe for each state yourself as `transition_*()` functions does it all for you in the `ggplot` code!

The `ease_aes()` also allows you to specify the easing function of the transitions within the `ggplot` code as well. From ""linear"" to ""quartic"" to ""elastic"" along with modifiers such as ""in"", ""out"", ""in-out"" you have a lot to choose from to satisfy your animation needs. Thomas did mention in his keynote that he wants a better name for this, so any suggestions? Maybe something like `ease_tween()`, `easing_fun()`, `ease_trans()`, `ease_transitions()`?

With everything streamlined so that you can add in the animation code seamlessly with `ggplot` grammar I feel you can read the entirety of the code better. As in, you don't have to refer back to a separate chunk of code that showed how you created the tween frames. The transition to a ""grammar of animation"" is truly in motion!

## New options in gganimate and tweenr!

Now I'll talk about a few other new things that I didn't have a chance to show this time around.

There are a host of different `enter_*()` and `exit_*()` functions to choose from to show how data appear and disappear throughout the duration of your animation. Some of the built-in effects that are available include, `*_fade()`, `*_grow()`, `*_shrink()` with extra arguments like `early` that change whether the data appears or disappears at the beginning of the transition or at the end.

With the old API, since you had to create the frames yourself with `tween_states()`, you got a dataframe output with the expanded tween-frames that you could view at your leisure. Now with the tweening done in the `ggplot` code you might think that you can't explicitly access them, but this is where the `frame_vars()` function comes in! Using this function you can access metadata about each of the frames rendered in your latest animation:

```{r frame_vars example}
frames_data <- frame_vars(animation = last_animation())

glimpse(frames_data)

```

The ""frame\_source"" column shows you where each individual frame image is saved so you can copy them, re-animate them with `magick` instead, anything you want!

Panning and zooming across different states in the animation is another new concept introduced in the new `gganimate` with the series of `view_*()` functions like `view_zoom()` and `view_step()`. Within these you can use arguments like `pause_length` to specify the length of the zoomed view and `step_length` to specify the length of the transition between view points. I didn't implement them in these GIFs because I had already used the `coord_*()` functions to focus on certain areas of the pitch and the events I was animating needed a wide perspective of the field. This may come into play in future goal or play-by-play animations where I'm recreating a neat bit of build-up play from a full field view then zoom in on the off-the-ball movement of a certain player, so definitely a set of functions to keep an eye on!

Finally, in previous versions you used the `gganimate()` function to save the animation on your computer but now that is done with `anim_save()`. The README on GitHub has a very clear explanation on this so take a look under the ""Where is my animation?"" section [here](https://github.com/thomasp85/gganimate#where-is-my-animation).

There's still much to learn from the new API and I'm sure there will still be more changes/fixes to come before the first CRAN release but this was a great step in the right direction. I will eagerly await the next release!
","2018"
"77",244,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/blog posts/soccer_plots_part3_DS+.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""July 24, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

__Animating__ the Goals of the World Cup: Comparing the __old__ vs. __new__ `gganimate` and `tweenr` API!

Welcome to **Part 3** of my series on ""Visualizing the World Cup with R""! This is the culmination of this mini project that I've been working on throughout the World Cup. In addition, from having listened to **Thomas Pedersen's** excellent [keynote](https://www.youtube.com/watch?v=21ZWDrTukEs) at __UseR! 2018__ in Brisbane on the **NEW** gganimate and tweenr API, I am taking advantage of the fortuitous timing to also compare the APIs using the goals as the examples!

I've had finished these animations a couple of weeks ago but didn't make them available until I presented at the [TokyoR](https://twitter.com/TokyoRCommunity) MeetUp last week! **Hadley Wickham** and **Joe Rickert** were the special guests and with the amount of speakers and attendees it felt more like a mini-conference than a regular meetup, if you're ever in Tokyo come join us for some R&R...and R! You can check out a recording of my talk on [YouTube](https://www.youtube.com/watch?v=tNncHFd5dVo).
<center>
| [Part 1](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/) | [Part 2](https://ryo-n7.github.io/2018-07-05-visualize-worldcup-part-2/) | [Part 3](https://ryo-n7.github.io/2018-07-24-visualize-worldcup-part-3/) |
</center>
Let's get started!

## Coordinate position data

Since this series started, several people have asked me where I got the data. I thought I made it quite clear in [Part 1](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/) but I will reiterate in the next few paragraphs.

I get a lot of my data science/visualization news from Twitter which has made a weird comeback by providing a platform for certain communities like `#rstats` (never thought I'll be creating a Twitter account in 2017!). Therefore, I've been able to come across some wonderful visualizations for the World Cup by **The Financial Times**, **FiveThirtyEight**, and a host of other people. As you can see from a great example of World Cup penalties by the **BBC** below, data is provided by sports analytics companies, primarily **Opta**!

<center>
<img src=""https://ichef.bbci.co.uk/onesport/cps/624/cpsprodpb/79E6/production/_102260213_1_penalties_scored_640-nc.png"" style=""height: 300px"" />
</center>

Great! But can an average joe like me just waltz in, slap down a fiver, and say ""GIMME THE DATA""? Well, unfortunately no, it costs quite a lot! This isn't really a knock on Opta or other sports analytics companies since FIFA or the FAs of respective nations didn't do this kind of stuff, the free market stepped in to fill the gap. Still, I'm 100% sure I am not the only one who wishes this kind of data was free though, well besides some datasets of varying quality you see on Kaggle (but none of those are as granular as the stuff Opta provides anyway).

So, envious of those who have the financial backing to procure such data and some mild annoyance at others online who didn't really bother sharing exactly how they got their data or even what tools they used, I started thinking of ways that I could get the data for myself.

One possible way was to use **RSelenium** or other JavaScript web scrapers on soccer analytics websites and their cool dashboards, like [WhoScored.com](https://www.whoscored.com/). However, since I wouldn't have been able to master these tools before the World Cup ended (during which whatever I end up creating would be most relevant), I decided that I'll create the coordinate data positions myself!

<center>
<img src=""https://i.imgur.com/Hn9X0GC.gif"" style=""width: 400px"" />
</center>


With the plotting system in [ggsoccer](https://github.com/Torvaney/ggsoccer) and `ggplot2` it's really not that hard to figure out the positions on the soccer field plot, as you can see in the picture below:

```{r example field, eval=FALSE, fig.width=9, fig.height=6}
ggplot(point_data) +
  annotate_pitch() +
  theme_pitch(aspect_ratio = NULL) +
  coord_flip() +
  geom_point(
    aes(x = x, y = y), 
    size = 1.5) +
  geom_text(
    aes(x = x, y = y,
        label = label),
    vjust = 1.5, color = ""red"")
```

<center>
<img src=""https://i.imgur.com/ejgbOFg.png"" style=""width: 500px"" />
</center>

There's also a way to make the coordinates be in **120x80** format (which is much more intuitive) and you can do that by adding the `*_scale` arguments inside the `annotate_pitch()` function. However, I only realized this after I had embedded the coordinate positions for the **100x100** plot in my head so that's what I kept going with.

There is also the **""Soccer event logger""** [here](https://github.com/Torvaney/elm-soccer-tracker) (incidentally also by [Ben Torvaney](https://twitter.com/Torvaney)) which allows you to mouse-click specific points on the field and then download a `.csv` file of the coordinate positions you clicked. This might be easier but personally I like to experiment within the R environment and take notes/ideas in RMarkdown as I do so, it definitely is an option for others though.

... and that's how [Part 1](https://ryo-n7.github.io/2018-06-29-visualize-worldcup/) was born! But I wasn't going to stop there, soccer is a moving - flowing game, static images are OK but it just doesn't capture the **FEEL** of the sport. So this is where `gganimate` and `tweenr` came in!

Out of all the World Cup stuff I've animated so far, by far the most complicated was [Gazinsky's goal](https://www.youtube.com/watch?v=mE79PUhe1_8) in the opening game. This is because I not only have to track the ball movement but the movement of multiple players as well. So most of the **comparison** aspect of the APIs will be done with this goal.

Let's take a look at the packages that I'll be using:

```{r packages, message=FALSE, warning=FALSE}
library(ggplot2)    # general plotting base
library(dplyr)      # data manipulation/tidying
library(ggsoccer)   # draw soccer field plot
library(ggimage)    # add soccer ball emoji + flags
library(extrafont)  # incorporate Dusha font into plots
library(gganimate)  # animate goal plots
library(tweenr)     # create in-between frames for data
library(purrr)      # for creating a list of dataframes for tweenr
library(countrycode)# for finding ISO codes for geom_flag()
# loadfonts()         run once every new session
```

## Gazinsky's first goal:

Let's first look at the set of dataframes with the coordinate data points necessary for this to work:

```{r gazinsky data}
pass_data <- data.frame(
  x = c(100, 94, 82, 82.5,  84, 76.5, 75.5, 94, 99.2),     
  y = c(0,   35, 31, 22,     8, 13, 19, 60, 47.5),
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

golovin_movement <- data.frame(
  x = c(78, 80, 80, 80, 75.5, 74.5, 73.5, 73, 73),  
  y = c(30, 30, 27, 25,   10,    9, 15, 15, 15),
  label = ""Golovin"",
  time = c(1, 2, 3,  4,  5,  6,  7,  8,  9)
)

zhirkov_movement <- data.frame(
  x = c(98, 90, 84, 84, 84, 84, 84, 84, 84),
  y = c( 0,  2,  2,  2,  2,  2,  2,  2,  2),
  label = ""Zhirkov"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

gazinsky_movement <- data.frame(
  x = c(0, 0, 0, 0, NA, 92,   92,   92,   92),
  y = c(0, 0, 0, 0, NA, 66.8, 66.8, 66.8, 66.8),
  label = ""Gazinsky"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

# ONLY in static + gganimate versions
segment_data <- data.frame(
  x = c(77.5, 98),
  y = c(22, 2),
  xend = c(75, 84),
  yend = c(15, 3),
  linetype = c(""dashed"", ""dashed""),
  color = c(""black"", ""black""),
  size = c(1.2, 1.25)
)

# saudi defender
saudi_data <- data.frame(
  x = c(95, 95, 90, 87, 84, 80, 79, 79, 79),
  y = c(35, 35, 35, 32, 28, 25, 24, 25, 26),
  label = ""M. Al-Breik"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

### soccer ball
ball_data <- tribble(
  ~x,  ~y, ~time,
  100,   0,   1,
  94,   35,   2,
  82,   31,   3,
  82.5, 25,   4,
  84,    6,   5, 
  77,   13,   6,
  76,   19,   7,
  94,   60,   8,
  99.2, 47.5, 9
  
) 

```

If you're manually creating these, you could also use `tribble()` instead of a `dataframe()`. It takes up a bit more space, as you can see in `ball_data`, but it is probably more readable for when you're sharing the code (like creating a reprex on SO or RStudio Community).

And here is the `ggplot` code for the `gganimate` version (no tween frames)!

**Note**: You need to be careful about the ordering of the `ggplot` elements. You need to make sure the soccer ball emoji code is near the end, after the labels, so that the player name labels don't cover the soccer ball as it's moving around!

```{r gazinsky old gganimate, eval=FALSE}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(
    xlim = c(49, 101),
    ylim = c(-1, 101)) +
  geom_segment(
    data = segment_data, 
    aes(x = x, y = y, 
        xend = xend, yend = yend),
    size = segment_data$size,
    color = segment_data$color,
    linetype = c(""dashed"", ""dashed"")) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(data = zhirkov_movement,
    aes(x = x, y = y,
        frame = time,
        label = label),
    color = ""red"") +
  geom_label(data = golovin_movement,
    aes(x = x, y = y,
        frame = time,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  ggimage::geom_emoji(
    data = ball_data,
    aes(x = x, y = y, frame = time),   
    image = ""26bd"", size = 0.035) +
  ggtitle(
    label = ""Russia (5) vs. (0) Saudi Arabia"", 
    subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(
    ""text"", x = 69, y = 65, family = ""Dusha V5"",
    label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5""))

```

<center>
<img src=""https://i.imgur.com/V9drm0I.gif"" />
</center>


Now let's check out how we would do it with the in-between frames added in using `tweenr`!

The important bit with the old API was that you had to create a list of dataframes of the different states of your data. In this case, it is a dataframe for each observation of the data or to put it more simply, the ""time"" variable (a dataframe of coordinate positions for time = 1, time = 2, etc.). This is done with `pmap()` with `dataframe()` being passed to the `.f` argument.

With this list of dataframes created, we can pass it into `tween_states()` function to create the in-between frames to connect each of the dataframes in the list. Take note of the arguments in `tweent_states()` as they'll show up again in the new API later.

```{r old tweenr, eval=FALSE}
### soccer ball
b_list <- ball_data %>% pmap(data.frame)

ball_tween <- b_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

### Golovin
golovin_movement_list <- golovin_movement %>% pmap(data.frame)
  
golovin_tween <- golovin_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

golovin_tween <- golovin_tween %>% mutate(label = ""Golovin"")

### Zhirkov
zhirkov_movement_list <- zhirkov_movement %>% pmap(data.frame)
  
zhirkov_tween <- zhirkov_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

zhirkov_tween <- zhirkov_tween %>% mutate(label = ""Zhirkov"")
```

Now with these newly created tween dataframes, we pass them into our `ggplot` code as before and specify the `frame` argument with the newly created "".frame"" variable.

```{r gazinsky old tweenr, eval=FALSE}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(data = zhirkov_tween,
    aes(x = x, y = y,
        frame = .frame,
        label = label),
    color = ""red"") +
  geom_label(data = golovin_tween,
    aes(x = x, y = y,
        frame = .frame,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  ggimage::geom_emoji(
    data = ball_tween,
    aes(x = x, y = y, frame = .frame),   
    image = ""26bd"", size = 0.035) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5""))
```

<center>
<img src=""https://i.imgur.com/GQYSJSH.gif"" />
</center>


Looks good. Now let's check out how things changed with the new API!

## __New__ gganimate & tweenr

Once again, let's start by looking at just animating across the ""time"" variable without creating in-between frames. (**NOTE**: 2 weeks after I first posted this article, the most recent changes in gganimate made the animation using `transition_time()` not run.)

```{r gazinsky NEW gganimate, eval=FALSE,warning=FALSE, fig.width=8, fig.height=6, fig.align='center'}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_label(
    data = zhirkov_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = golovin_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") + 
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  ggimage::geom_emoji(
    data = ball_data,
    aes(x = x, y = y),   
    image = ""26bd"", size = 0.035) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  # new gganimate code:
  transition_manual(frames = time)

```

<center>
<img src=""https://i.imgur.com/iMKnDb2.gif"" />
</center>

It's quite nice that I don't have to specify `frame = some_time_variable` in every geom that I want animated now!

However, you can see that like in the old gganimate code the new `transition_manual()` function just speeds through the specified ""time"" variable without actually creating in-between frames. Let's use the other `transition_*()` functions to specify the tween frames and set the animation speed.

Here I will use `transition_states()` with ""time"" being the column I pass to the `states` argument. Instead of having to create a "".frame"" column with the `tween_states()` function I can just pass the ""time"" variable into the `transition_states()` function and it will tween the frames for you in addition to the `ggplot` code! The `transition_length` argument is the same as the `tween_length` argument from the old `tween_states()` function and `state_length` argument is the same here too.

Unlike in the version I showed in my presentation, I added Mohammed Al-Breik's movement as well. I felt it was a bit silly (and unfair) to show him just standing there after his headed clearance!

```{r gazinsky NEW tweenr, eval=FALSE, warning=FALSE, fig.width=8, fig.height=6, fig.align='center'}
ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(
    data = zhirkov_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = golovin_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  enter_grow(fade = TRUE) +
  ggimage::geom_emoji(
    data = ball_data,
    aes(x = x, y = y),   
    image = ""26bd"", size = 0.035) +
  ggtitle(
    label = ""Russia (5) vs. (0) Saudi Arabia"", 
    subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(
    ""text"", x = 69, y = 65, family = ""Dusha V5"",
    label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5"")) +
  # new gganimate code:
  transition_states(
    time, 
    transition_length = 0.5, 
    state_length = 0.0001,
    wrap = FALSE) +
  ease_aes(""linear"")

anim_save(filename = ""gazin_new_tweenr.gif"")

```

<center>
<img src=""https://i.imgur.com/YD9myCo.gif"" />
</center>

Now you may be wondering why I didn't use the more logical choice, the `transition_time()` function here so let me explain.

I manually created the timing of the coordinate data so naturally, the transitions would be slightly off compared to real data. This goal animation was split into 9 ""time"" values for each important bit of the play that I thought would transition well when connected with eachother. Then I ran it through `gganimate` to see if it flowed well and once I was satisfied, I let `tweenr` fill in the blanks between each ""time"" value.

With the new API however, using `transition_time()` function wouldn't allow me to control transition length and state length like with `transition_states()`! Try running the code above with `transition_time(time = time)` instead and you'll see what I mean.

If I had real data and the proper timing values in the ""time"" column that seamlessly worked with the coordinate data points it would have then been appropriate to use `transition_time()`. Some examples of these kind of data sets include the gapminder data set used in the package README which used the ""year"" variable or the data set in the cool NBA animation by James Curley seen [here](https://rpubs.com/jalapic/nbaplaybyplay) that had very granular data recording the coordinate positions and the exact times.

A cool new thing that you can play around with in the **new** gganimate are the different enter/exit animations! However, I couldn't really get it to work for Gazinsky's label... In the `mtcars` example on the gganimate GitHub Repo, the boxplots disappeared when there was no data for the specific combination of variables but I can't seem to properly set up the Gazinsky label dataframe correctly to implement it.

Ideally, I want Gazinsky's label to only show up from `time = 6` onwards. I tried filling the coordinate positions for `time = 1` to `time = 5` with **NAs** or **0s** but it didn't seem trigger the effect ... when I tried with ""x = 0, y = 0"" in `time = 5`, the player label zipped in from the bottom of the screen to the penalty box at `time = 6` and it was unintentionally very funny!

Any help here will be greatly appreciated!

## Osako's goal vs. Colombia

Japan faced a tough opponent in Colombia, even with the man-advantage early on, in our opening game of the World Cup. Even with our passing tiring out the tenacious Colombians we were finding it hard to find a breakthrough. In came Keisuke Honda, who within minutes of his arrival, delivered a beautiful cross from a corner kick for Osako to head home!

This goal was a lot easier to animate and to be honest this was the first one I was able to actually get working a few weeks ago! This was mainly because the ball movement was the only thing I really had to worry about.

```{r osako data, warning=FALSE}
cornerkick_data <- data.frame(
  x = 99, y = 0.3,
  x2 = 94, y2 = 47)

osako_gol <- data.frame(
  x = 94, y = 49,
  x2 = 100, y2 = 55.5)

ball_data <- data.frame(
  x = c(99, 94, 100),
  y = c(0.3, 47, 55.5),
  time = c(1, 2, 3))

player_label <- data.frame(
  x = c(92, 99), 
  y = c(49, 2),
  label = c(""Osako"", ""Honda""))

wc_logo <- data.frame(
  x = 107,
  y = 85) %>% 
  mutate(
    image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")

flag_data <- data.frame(
  x = c(110, 110),
  y = c( 13, 53),
  team = c(""japan"", ""colombia"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)
```

For this animation, I used one of the many easing functions available in `tweenr`, `quadratic-out`, to get the speed of the ball from a corner kick just about right. You can refer to [this](https://easings.net/) awesome website to check out most of the different easing functions you can use in `ease_aes()`!

```{r osako NEW tweenr, eval=FALSE, warning=FALSE, fig.height = 5, fig.width = 7, fig.align='center'}
ggplot(ball_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(
    text = element_text(family = ""Dusha V5""),
    plot.margin=grid::unit(c(0,0,0,0), ""mm"")) +
  coord_flip(
    xlim = c(55, 112),
    ylim = c(-1, 101)) +
  geom_label(
    data = player_label, 
    aes(x = x, y = y,
        label = label),
    family = ""Dusha V5"") +
  geom_point(
    aes(x = 98, y = 50), size = 3, color = ""green"") +
  annotate(
    geom = ""text"", family = ""Dusha V5"", 
    hjust = c(0.5, 0.5, 0.5, 0.5),
    size = c(6.5, 4.5, 5, 3),
    label = c(""Japan             (2) vs. Colombia             (1)"",
              ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
              ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
              ""by Ryo Nakagawara (@R_by_Ryo)""),
    x = c(110, 105, 70, 53), 
    y = c(30, 30, 47, 85)) +
  ggimage::geom_emoji(              # soccer ball emoji
    aes(x = x, 
        y = y),
    image = ""26bd"", size = 0.035) +
  ggimage::geom_flag(               # Japan + Colombia flag
    data = flag_data,
    aes(x = x, y = y,
        image = image),       
    size = c(0.08, 0.08)) +
  geom_image(                       # World Cup logo
    data = wc_logo,     
    aes(x = x, y = y,
        image = image), size = 0.17) +
  # new gganimate code:
  transition_states(
    time, 
    transition_length = 0.5, 
    state_length = 0.0001,
    wrap = FALSE) +
  ease_aes(""quadratic-out"")
```

<center>
<img src=""https://i.imgur.com/HsWC2u3.gif"" />
</center>

As you can see it's quite easy and fun to make these! I am hoping to make more in the future, especially when the new season begins!

A small note on the flags: I used a bit of a hacky solution to get them into the title but both Ben and Hadley recommended I use the [emo::ji()](https://github.com/hadley/emo) package which allows you to insert emoji into RMarkdown and inline. So that's something I'll be looking into in the near future!

## Japan's Offside Trap vs. Senegal!

For the final animation, I tried to recreate something you don't see everyday - an offside trap!

<center>
<img src=""https://media.giphy.com/media/lk0TFUdop2JTW/giphy.gif"" style=""width: 400px"" />
</center>

```{r offside data}
# PLAYERS
# JAPAN: x, y (blue)     Senegal: x2, y2  (lightgreen)
trap_data <- data.frame(
  
  time = c(1, 2, 3, 4, 5),
  
  # ball trajectory
  x = c(70, 70, 70, 87, 95),       
  y = c(85, 85, 85, 52, 33),
  
  # offside line bar
  #xo =    c(83, 81.2, 79, 77.5, 70),
  xoend = c(83.8, 81.8, 79, 78.5, 71),
  
  yo =    c( 5,  5,  5,  5, 5),
  yoend = c(95, 95, 95, 95, 95),
  
  # players: japan
  jx  = c(83, 81, 77, 75, 70),
  jy  = c(rep(65, 5)),
  
  jx2 = c(83, 81.8, 78.5, 77, 70),
  jy2 = c(rep(60.5, 5)),
  
  jx3 = c(83, 81, 76.5, 75, 71),
  jy3 = c(rep(55, 5)),
  
  jx4 = c(83, 81.2, 76.3, 75, 70),
  jy4 = c(rep(52, 5)),
  
  jx5 = c(82.8, 81, 77, 74, 70),
  jy5 = c(rep(49, 5)),
  
  jx6 = c(83, 81.8, 77, 74, 70),
  jy6 = c(rep(45, 5)),

  jx7 = c(83.8, 81, 79, 77.5, 70),
  jy7 = c(rep(40, 5)),
  
  # players: senegal
  sx = c(83, 84, 84, 84, 84),
  sy = c(rep(33, 5)),
  
  sx2 = c(83, 85, 87, 92, 95),
  sy2 = c(38, 37, 35, 34, 33),
  
  sx3 = c(83, 84, 84, 83, 83),
  sy3 = c(rep(41, 5)),
  
  sx4 = c(83, 84, 83, 78, 78),
  sy4 = c(rep(45, 5)),
  
  sx5 = c(83, 84, 87, 88, 89),
  sy5 = c(rep(52, 5)),
  
  sx6 = c(83, 85, 84, 84, 83),
  sy6 = c(rep(69, 5))
)

# flags
flag_data <- data.frame(
  x = c( 48, 93),
  y = c(107, 107),
  team = c(""japan"", ""senegal"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)

# extra players:
goalkeeper_data <- data.frame(
  x = c(98),
  y = c(50)
)

senegal_data <- data.frame(
  x = c(55, 55, 68.5),
  y = c(50, 60, 87)
)
```

In the code below, take note of the ""wrap"" option in `transition_states()`. You can set it to false if you don't want the last state to transition back to the first state (default == TRUE).

```{r tweenr offside NEW, eval = FALSE, warning=FALSE, fig.height=10, fig.width=9, fig.align='center'}
ggplot(trap_data) +
  annotate_pitch() +
  theme_pitch(aspect_ratio = NULL) +
  coord_fixed(
    xlim = c(30, 101),
    ylim = c(-5, 131)) +
  # offside line
  geom_segment(aes(x = xoend, y = yo, 
                   xend = xoend, yend = yoend), 
               color = ""black"", size = 1.3) +
  # japan
  geom_point(aes(x = jx, y = jy), size = 4, color = ""blue"") +
  geom_point(aes(x = jx2, y = jy2), size = 4, color = ""blue"") +
  geom_point(aes(x = jx3, y = jy3), size = 4, color = ""blue"") +
  geom_point(aes(x = jx4, y = jy4), size = 4, color = ""blue"") +
  geom_point(aes(x = jx5, y = jy5), size = 4, color = ""blue"") +
  geom_point(aes(x = jx6, y = jy6), size = 4, color = ""blue"") +
  geom_point(aes(x = jx7, y = jy7), size = 4, color = ""blue"") +
  # senegal
  geom_point(aes(x = sx, y = sy), size = 4, color = ""green"") +
  geom_point(aes(x = sx2, y = sy2), size = 4, color = ""green"") +
  geom_point(aes(x = sx3, y = sy3), size = 4, color = ""green"") +
  geom_point(aes(x = sx4, y = sy4), size = 4, color = ""green"") +
  geom_point(aes(x = sx5, y = sy5), size = 4, color = ""green"") +
  geom_point(aes(x = sx6, y = sy6), size = 4, color = ""green"") +
  
  # free kick spot (reference)
  geom_point(aes(x = 70, y = 85), color = ""blue"", size = 1.2) +
  # goalkeeper
  geom_point(
    data = goalkeeper_data,
    aes(x = x, y = y), size = 4, color = ""blue"") +
  # senegal defenders
  geom_point(
    data = senegal_data,
    aes(x = x, y = y), size = 4, color = ""green"") +
  annotate(
    geom = ""text"", family = ""Dusha V5"", 
    hjust = c(0, 0),
    size = c(6, 6.5),
    label = c(""Japan          (2) vs. Senegal         (2)"",
              ""The Perfect Offside Trap""),
    x = c(30,  30), 
    y = c(107, 115)) +
  ggimage::geom_flag(
    data = flag_data,
    aes(x = x, y = y,
        image = image),       
    size = c(0.07, 0.07)) +
  ggimage::geom_emoji(
    aes(x = x, y = y),
    image = ""26bd"", size = 0.035) +
  # NEW gganimate code
  transition_states(
    states = time, 
    transition_length = 0.2, 
    state_length = 0.00000001,
    wrap = FALSE) +
  ease_aes(""linear"")

```

<center>
<img src=""https://i.imgur.com/5C0tbsN.gif"" />
</center>

So against the height advantage and physicality of Senegal, the thinking behind Japan's strategy was...

```{r meme, eval=FALSE}
library(memery)
img <- (""https://imgflip.com/s/meme/Roll-Safe-Think-About-It.jpg"")

meme_labs <- c(""you can't lose the aerial battle"", ""if you set an offside trap"")

meme(img, meme_labs, ""offside_meme.png"")

```

<center>
<img src=""https://i.imgur.com/B9Vauq0.jpg"" style=""height: 300px"" />
</center>


Jokes and memes aside, let's take a few minutes to reflect on the new API.

## Personal thoughts:

The best thing about the new API is without a doubt, no more intermediary steps between tweening the data and plotting. As long as you have some kind of ""time"" variable you don't have to manually go and create the list of dataframe for each state yourself as `transition_*()` functions does it all for you in the `ggplot` code!

The `ease_aes()` also allows you to specify the easing function of the transitions within the `ggplot` code as well. From ""linear"" to ""quartic"" to ""elastic"" along with modifiers such as ""in"", ""out"", ""in-out"" you have a lot to choose from to satisfy your animation needs. Thomas did mention in his keynote that he wants a better name for this, so any suggestions? Maybe something like `ease_tween()`, `easing_fun()`, `ease_trans()`, `ease_transitions()`?

With everything streamlined so that you can add in the animation code seamlessly with `ggplot` grammar I feel you can read the entirety of the code better. As in, you don't have to refer back to a separate chunk of code that showed how you created the tween frames. The transition to a ""grammar of animation"" is truly in motion!

## New options in gganimate and tweenr!

Now I'll talk about a few other new things that I didn't have a chance to show this time around.

There are a host of different `enter_*()` and `exit_*()` functions to choose from to show how data appear and disappear throughout the duration of your animation. Some of the built-in effects that are available include, `*_fade()`, `*_grow()`, `*_shrink()` with extra arguments like `early` that change whether the data appears or disappears at the beginning of the transition or at the end.

With the old API, since you had to create the frames yourself with `tween_states()`, you got a dataframe output with the expanded tween-frames that you could view at your leisure. Now with the tweening done in the `ggplot` code you might think that you can't explicitly access them, but this is where the `frame_vars()` function comes in! Using this function you can access metadata about each of the frames rendered in your latest animation:

```{r frame_vars example, eval=FALSE}
frames_data <- frame_vars(animation = last_animation())

```

<center>
<img src=""https://i.imgur.com/FyluQu6.jpg"" style=""height: 300px"" />
</center>

The ""frame\_source"" column shows you where each individual frame image is saved so you can copy them, re-animate them with `magick` instead, anything you want!

Panning and zooming across different states in the animation is another new concept introduced in the new `gganimate` with the series of `view_*()` functions like `view_zoom()` and `view_step()`. Within these you can use arguments like `pause_length` to specify the length of the zoomed view and `step_length` to specify the length of the transition between view points. I didn't implement them in these GIFs because I had already used the `coord_*()` functions to focus on certain areas of the pitch and the events I was animating needed a wide perspective of the field. This may come into play in future goal or play-by-play animations where I'm recreating a neat bit of build-up play from a full field view then zoom in on the off-the-ball movement of a certain player, so definitely a set of functions to keep an eye on!

Finally, in previous versions you used the `gganimate()` function to save the animation on your computer but now that is done with `anim_save()`. The README on GitHub has a very clear explanation on this so take a look under the ""Where is my animation?"" section [here](https://github.com/thomasp85/gganimate#where-is-my-animation).

There's still much to learn from the new API and I'm sure there will still be more changes/fixes to come before the first CRAN release but this was a great step in the right direction. I will eagerly await the next release!
","2018"
"78",245,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/ggsoccer_graphs.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 15, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(tidyverse)
library(ggsoccer)
library(ggimage)
library(extrafont)
# loadfonts()

#                              2   1  
pass_data <- data.frame(x = c( 84, 82),
                        y = c(  6, 32),
                        x2 = c(77, 84),
                        y2 = c(13, 8))

#                            corner kick
curve_data <- data.frame(x = c(100),
                         y = c(0),
                         x2 = c(94),
                         y2 = c(35))
# golovin cross
cross_data <- data.frame(x = 76,
                         y = 19,
                         x2 = 94,
                         y2 = 60)

# Saudi failed clearance 
clearance_data <- data.frame(x = c(94),
                             y = c(35),
                             x2 = c(82),
                             y2 = c(33.5))

# Gazinski header
goal_data <- data.frame(x = c(94),
                        y = c(60),
                        x2 = c(99.2),
                        y2 = c(47.5))

# soccer ball image
goal_img <- data.frame(x = 100,
                       y = 47) %>% 
  mutate(image = ""https://d30y9cdsu7xlg0.cloudfront.net/png/43563-200.png"")

# golovin movement
golovin_data <- data.frame(x = c(83),
                           y = c(24.25),
                           x2 = c(77),
                           y2 = c(21))

# zhirkov movement 
zhirkov_data <- data.frame(x = 98,
                           y = 2,
                           x2 = 88,
                           y2 = 6)

g <- ggplot(pass_data) +
  annotate_pitch() +
  geom_segment(aes(x = x, y = y, xend = x2, yend = y2),
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(data = clearance_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", size = 0.85) +
  geom_segment(data = goal_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", color = ""red"", size = 0.85) +
  geom_segment(data = golovin_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", color = ""darkgreen"", size = 1.2) +
  geom_segment(data = zhirkov_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", color = ""darkgreen"", size = 1.25) +
  geom_curve(data = curve_data, 
             aes(x = x, y = y, xend = x2, yend = y2), 
             curvature = 0.25, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_curve(data = cross_data, 
             aes(x = x, y = y, xend = x2, yend = y2), 
             curvature = 0.25, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_image(data = goal_img,
             aes(x = x, y = y,
                 image = image), size = 0.035) +
  theme_pitch() + 
  theme(text = element_text(family = ""Trebuchet MS"")) +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  geom_label(aes(x = 94, y = 60, label = ""Gazinsky""), hjust = -0.1) +
  geom_label(aes(x = 83, y = 23, label = ""Golovin""), hjust = -0.05) +
  geom_label(aes(x = 75, y = 11, label = ""Golovin""), hjust = -0.1) +
  geom_label(aes(x = 98, y = 0, label = ""Zhirkov""), vjust = -0.3) +
  geom_label(aes(x = 84, y = 6, label = ""Zhirkov""), vjust = -0.3) +
  annotate(""text"", x = 69, y = 65, family = ""Trebuchet MS"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"")

ggsave(g, filename = ""gazinsky_goal.png"")

```




## Cristiano Ronaldo hattrick


```{r}
library(ggplot2)
library(ggsoccer)
library(extrafont)
library(emoGG)
library(ggimage)
# loadfonts()
# Official WC 2018 Font: ""Dusha""
# http://fifa2018wiki.com/fifa-2018-font-typeface-download-dusha-font-ttf/509/

emoji_search(""soccer"")  # ""26bd""

goals_data <- data.frame(x = c(88, 80, 71),
                         y = c(50, 48, 54))

cr <- ggplot(goals_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_curve(x = 88, y = 50, 
             xend = 100, yend = 54,     # Penaldo
             curvature = 0.3, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(x = 80, y = 48, 
               xend = 97, yend = 48) +  # 2nd 
  geom_segment(x = 97, y = 48, 
               xend = 100, yend = 45.5,
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +        # degea fumble
  geom_curve(x = 71, y = 54, 
             xend = 100, yend = 54,     # FREEKICK
             curvature = 0.3, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  annotate(geom = ""text"", family = ""Dusha V5"", hjust = c(0.5, 0.5, 0.5, 0, 0, 0),
           size = c(6.5, 4.5, 3, 3.5, 3.5, 3.5),
           label = c(""Portugal             (3) vs. Spain             (3)"",
                     ""Cristiano's Hattrick (4', 44', 88')"",
                     ""by Ryo Nakagawara (@R_by_Ryo)"",
                     ""1. Fouled by Nacho in the box,\nCristiano confidently strokes the ball\ninto the right corner from the spot."",
                     ""2. Guedes lays it off to Cristiano whose\nstrong shot is uncharacteristically\nfumbled by De Gea into the net."",
                     ""In the final minutes of the game,\nCristiano wins a freekick against Pique\nand curls it beautifully over the wall.""),
           x = c(110, 105, 53, 76, 66, 66), 
           y = c(30, 20, 85, 5, 5, 55)) +
  ggimage::geom_flag(aes(image = ""PT""),       # Portugal Flag
            x = 110, y = 19.1, size = 0.08) +
  ggimage::geom_flag(aes(image = ""ES""),       # Spain Flag
            x = 110, y = 51.1, size = 0.08) +
  ggimage::geom_emoji(aes(x = 105, 
                          y = c(45, 50, 55)),
             image = ""26bd"", size = 0.035) +
  geom_point(aes(x = x, y = y), 
             shape = 21, size = 7, color = ""black"", fill = ""white"") +
  geom_text(aes(x = x, y = y, label = c(1, 2, 3)), family = ""Dusha V5"")

ggsave(cr, filename = ""cr_hattrick.png"")

```


""1. Fouled by Nacho in the box, Cristiano confidently strokes the ball into the right corner from the spot.""

""2. Guedes lays it off to Cristiano who's strong shot is uncharacteristically fumbled by De Gea into the net.""

""3. In the final minutes of the game, Cristiano wins a freekick against Pique and curls it beautifully over the wall.""


### OSAKO GOL GOL GOL

```{r}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(extrafont)
library(emoGG)
library(ggimage)


cornerkick_data <- data.frame(x = 99, y = 0.3,
                              x2 = 94, y2 = 47)

osako_gol <- data.frame(x = 94, y = 49,
                        x2 = 100, y2 = 55.5)

player_label <- data.frame(x = c(92, 99), 
                           y = c(49, 2))

wc_logo <- data.frame(x = 107,
                       y = 85) %>% 
  mutate(image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")


g <- ggplot(osako_gol) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_curve(data = cornerkick_data,
             aes(x = x, y = y, xend = x2, yend = y2),
             curvature = -0.15, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(aes(x = x, y = y, xend = x2, yend = y2),
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_label(data = player_label, 
             aes(x = x, y = y),
             label = c(""Osako"", ""Honda""), family = ""Dusha V5"") +
  geom_point(aes(x = 98, y = 50), size = 3, color = ""green"") +
  geom_text(aes(x = 99.7, y = 50), size = 5, label = ""???"", family = ""Dusha V5"") +
  annotate(geom = ""text"", family = ""Dusha V5"", 
           hjust = c(0.5, 0.5, 0.5, 0, 0.5),
           size = c(6.5, 4.5, 4, 3.5, 3),
           label = c(""Japan             (2) vs. Colombia             (1)"",
                     ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
                     ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
                     ""Bonus: Ospina looking confused and doing\na lil' two-step-or-god-knows-what."",
                     ""by Ryo Nakagawara (@R_by_Ryo)""),
           x = c(110, 105, 70, 92, 53), 
           y = c(30, 30, 45, 65, 85)) +
  ggimage::geom_flag(aes(image = ""JP""),       # Japan Flag
            x = 110, y = 13, size = 0.08) +
  ggimage::geom_flag(aes(image = ""CO""),       # Colombia Flag
            x = 110, y = 53, size = 0.08) +
  ggimage::geom_emoji(aes(x = 95, 
                          y = 50),
             image = ""26bd"", size = 0.035) +
  geom_image(data = wc_logo,                  # World Cup Logo
             aes(x = x, y = y,
                 image = image), size = 0.17)
  
ggsave(g, filename = ""osako_winner.png"")

```




## Shots on Target  // Off Target

```{r}

```



## Formation and line-ups

make function for set formations 
- all you need to do is pass player names and formation string (""3-5-2"", ""4-4-2"", etc.)
- later version: player icon with uniform (like in Wikipedia)


```{r}

```














how to get rid of margins????


```{r}
s <- ggplot(pass_data) +
  annotate_pitch() +
  geom_segment(aes(x = x, y = y, xend = x2, yend = y2),
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(data = clearance_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", size = 0.85) +
  geom_segment(data = goal_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", color = ""red"", size = 0.85) +
  geom_segment(data = golovin_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", color = ""darkgreen"", size = 1.2) +
  geom_segment(data = zhirkov_data,
               aes(x = x, y = y, xend = x2, yend = y2
                   ), linetype = ""dashed"", color = ""darkgreen"", size = 1.25) +
  geom_curve(data = curve_data, 
             aes(x = x, y = y, xend = x2, yend = y2), 
             curvature = 0.25, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_image(data = goal_img,
             aes(x = x, y = y,
                 image = image), size = 0.035) +
  theme_pitch() +
  theme(plot.margin = unit(c(0, 0, 0, 0), ""mm"")) +
  coord_flip()


ggsave(s, filename = ""s.png"")



```


","2018"
"79",246,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/group_table_final_matchday.rmd","---
title: ""final matchday group""
author: ""RN7""
date: ""June 27, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## matchday theme()

```{r theme()}

theme_matchday <- theme_minimal() +
  theme(
    text = element_text(family = ""Dusha V5"", size = 18),
    axis.title = element_blank(),
    axis.text = element_text(color = ""grey30""),
    legend.position = ""none"",
    panel.grid = element_blank())

```




## Group A Standings throughout Final Matchday!

```{r fig.width=7, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
# loadfonts()  run once per new session!

group_a <- data.frame(

  time =         c(1, 2, 3, 4),
  russia =       c(1, 2, 2, 2),
  uruguay =      c(2, 1, 1, 1),
  egypt =        c(3, 3, 4, 4),
  saudi_arabia = c(4, 4, 3, 3)
  
)

group_a <- group_a %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = recode_factor(team, ""saudi_arabia"" = ""saudi arabia"")) %>% 
  mutate(team = fct_relevel(team, 
                            ""russia"", ""uruguay"", ""egypt"", ""saudi arabia""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""10'"", ""90 + 5'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 4, 4, 4, 4),
  y = c(1, 3, 1, 2, 3, 4),
  score = c(""1-0"", ""2-1"", ""3-0"", ""0-3"", ""2-1"", ""1-2"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""Russia"", ""Uruguay"", ""Egypt"", ""Saudi Arabia"")
)

goals_labs <- data.frame(
  x = c(2, 3, 4, 4, 4),
  y = c(1, 3, 1, 3, 4),
  scorers = c(""Suarez (10')"", ""Al-Dawsari (90+5')"",
              ""Cheryshev o.g. (23')\nCavani (90')"",
              ""Al-Faraj pen. (45+6')"",
              ""Salah (22')"")
)

points_labs <- data.frame(
  x = c(rep(max(group_a$time), 4)),
  y = c(rep(1:4, 1)),
  points = c(""9 pts."", ""6 pts."", ""3 pts."", ""0 pts."")
)


## plot

groupA <- ggplot(
  group_a,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.1) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.25, size = 5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.25, size = 5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.3, size = 3.5) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    nudge_x = 0.6,
    size = 5,
    color = ""grey30"") +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.5, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:4,
    labels = x_labs,
    limits = c(0.7, 4.8)) +
  labs(
    title = ""Group A Table Throughout The Last Matchday"",
    subtitle = ""Uruguay vs. Russia & Saudi Arabia vs. Egypt"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

ggsave(groupA, filename = ""groupA_table.png"", width = 7, height = 5)
```




## Group B Standings during Final Match Day!

```{r fig.width=10, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
# loadfonts()  run once per new session!

group_b <- data.frame(

  time = c(1, 2, 3, 4, 5, 6, 7, 8),
  spain = c(1, 2, 1, 2, 2, 2, 1, 1),
  portugal = c(2, 1, 2, 1, 1, 1, 2, 2),
  iran = c(3, 3, 3, 3, 4, 3, 3, 3),
  morocco = c(4, 4, 4, 4, 3, 4, 4, 4)
  
)

group_b <- group_b %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""spain"", ""portugal"", ""iran"", ""morocco""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""14'"", ""19'"", ""45'"", ""81'"", ""90 + 1'"", ""90 + 3'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 4, 5, 6, 7, 8, 8, 8, 8),
  y = c(2, 1, 1, 3, 4, 2, 1, 2, 3, 4),
  score = c(""0-1"", ""1-1"", ""1-0"", ""2-1"", ""2-2"", ""1-1"",
            ""2-2"", ""1-1"", ""1-1"", ""2-2"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""Spain"", ""Portugal"", ""Iran"", ""Morocco"")
)

goals_labs <- data.frame(
  x = c(2, 3, 4, 5, 6, 7),
  y = c(1, 1, 1, 3, 4, 2),
  scorers = c(
    ""Boutaib (14')\n(Morocco)"",
    ""Isco (19')"",
    ""Quaresma (45')"",
    ""En-Nesyri (81')"",
    ""Aspas (90+1')\n(Spain)"",
    ""Ansarifard pen. (90+3')\n(Iran)""
    )
)

points_labs <- data.frame(
  x = c(rep(max(group_b$time), 4)),
  y = c(rep(1:4, 1)),
  points = c(""5 pts."", ""5 pts."", ""4 pts."", ""1 pts."")
)

## PLOT

groupB <- ggplot(
  group_b,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.08) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.25, size = 6) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.25, size = 5.5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.3, size = 3.5) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    nudge_x = 0.8,
    size = 5,
    color = ""grey30"") +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.5, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:8,
    labels = x_labs,
    limits = c(0.9, 9)) +
  labs(
    title = ""Group B Table Throughout The Last Matchday"",
    subtitle = ""Iran vs. Portugal & Spain vs. Morocco"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

ggsave(groupB, filename = ""groupB_table.png"", width = 10, height = 5)
```

how to emphasize IRAN vs. PORTUGAL and SPAIN sv. MOROCCO   ???

place scorer name below flags?


## Group C Standings During Final Matchday!

```{r fig.width=7, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
# loadfonts()  run once per new session!

group_c <- data.frame(

  time =      c(1, 2, 3),
  france =    c(1, 1, 1),
  denmark =   c(2, 2, 2),
  australia = c(3, 4, 4),
  peru =      c(4, 3, 3)
  
)

group_c <- group_c %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""france"", ""denmark"", ""australia"", ""peru""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""18'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 3, 3, 3),
  y = c(3, 1, 2, 3, 4),
  score = c(""1-0"", ""0-0"", ""0-0"", ""2-0"", ""0-2"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""France"", ""Denmark"", ""Australia"", ""Peru"")
)

goals_labs <- data.frame(
  x = c(2, 3),
  y = c(3, 3),
  scorers = c(""Carillo (18')"", ""Guerrero (50')"")
)

points_labs <- data.frame(
  x = c(3.4, 3.4, 3.4, 3.4),
  y = c(1, 2, 3, 4),
  points = c(""7 pts."", ""5 pts."", ""3 pts."", ""1 pts."")
)

## PLOT

groupC <- ggplot(
  group_c,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.3, size = 4) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    size = 5,
    color = ""grey30"") +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.5, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:3,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.7, 3.6)) +
  labs(
    title = ""Group C Table Throughout The Last Matchday"",
    subtitle = ""Denmark vs. France & Australia vs. Peru"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

ggsave(groupC, filename = ""groupC_table.png"", width = 7, height = 5)
```


## Group D Standings During Final Matchday!

NOTE: Argentina in 4th at start due to more yellow cards in tie-breaker vs. Iceland.


```{r NOT WORK}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
# loadfonts()  run once per new session!

group_d <- data.frame(

  time =      c(1, 2, 3, 4, 5, 6, 7),
  croatia =   c(1, 1, 1, 1, 1, 1, 1),
  nigeria =   c(2, 3, 2, 2, 2, 3, 3),
  iceland =   c(3, 4, 3, 4, 3, 4, 4),
  argentina = c(4, 2, 4, 3, 4, 2, 2)
  
)

group_d <- group_d %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""croatia"", ""nigeria"", ""argentina"", ""iceland""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))


group_d %>% 
  mutate(
    xscore = c(2, 3, 4, 5, 6, 7, 7, 7, 7),
    yscore = c(2, 2, 4, 3, 2, 1, 2, 3, 4),
    score = c(""1-0"", ""1-1"", ""0-1"", ""1-1"", ""2-1"", 
            ""2-1"", ""2-1"", ""1-2"", ""1-2""),
    
    xcountry= c(1, 1, 1, 1),
    ycountry = c(1, 2, 3, 4),
    country = c(""Croatia"", ""Nigeria"", ""Iceland"", ""Argentina""),
    
    xgoal = c(2, 3, 4, 5, 6, 7),
    ygoal = c(2, 2, 4, 3, 2, 1),
    scorers = c(""Messi"", ""Moses (pen.)"", ""(Croatia)\nBadelj"", 
              ""G. Sigurdsson (pen.)"", ""Rojo"", ""Perisic (90')""),
    
    xpoint = c(7.8, 7.8, 7.8, 7.8),
    ypoint = c(1, 2, 3, 4),
    points = c(""9 pts."", ""4 pts."", ""3 pts."", ""1 pts."")
  )

x_labs <- c(""0'"", ""14'"", ""51'"", ""53'"", ""76'"", ""86'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")


ggplot(
  group_d,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11,
    color = ""black"") +
  geom_text(
    aes(x = c(xcountry, xscore), y = c(ycountry, yscore), 
        label = c(country, score),
        family = ""Dusha V5""),
    nudge_y = c(0.3, 0.3), size = c(6, 6)) +
  geom_text(
    aes(x = xscore, y = yscore, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 6) +
  geom_text(
    aes(x = xgoal, y = ygoal, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.38, size = 4) +
  geom_text(
    aes(x = xpoint, y = ypoint, 
        label = points,
        family = ""Dusha V5""),
    size = 5) +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:7,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.4, 8.3)) +
  labs(
    title = ""Group D Table Throughout The Last Matchday"",
    subtitle = ""Nigeria vs. Argentina & Iceland vs. Croatia"",
    caption = ""by @R_By_Ryo"") +
  theme_minimal() +
  theme(
    text = element_text(family = ""Dusha V5"", size = 18),
    axis.title = element_blank(),
    legend.position = ""none"",
    panel.grid = element_blank())


```



```{r fig.width=8, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
# loadfonts()  run once per new session!

group_d <- data.frame(

  time =      c(1, 2, 3, 4, 5, 6, 7),
  croatia =   c(1, 1, 1, 1, 1, 1, 1),
  nigeria =   c(2, 3, 2, 2, 2, 3, 3),
  iceland =   c(3, 4, 3, 4, 3, 4, 4),
  argentina = c(4, 2, 4, 3, 4, 2, 2)
  
)

group_d <- group_d %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""croatia"", ""nigeria"", ""argentina"", ""iceland""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""14'"", ""51'"", ""53'"", ""76'"", ""86'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

country_labs <- data.frame(
  x = c(rep(1, 4)),
  y = c(rep(1:4, 1)),
  country = c(""Croatia"", ""Nigeria"", ""Iceland"", ""Argentina"")
)

score_labs <- data.frame(
  x = c(2, 3, 4, 5, 6, 
        7, 7, 7, 7),    # always have score labels for every team at FULL TIME
  y = c(2, 2, 4, 3, 2, 
        1, 2, 3, 4),
  score = c(""1-0"", ""1-1"", ""0-1"", ""1-1"", ""2-1"", 
            ""2-1"", ""2-1"", ""1-2"", ""1-2"")          # Full Time scores
)

goals_labs <- data.frame(
  x = c(2, 3, 4, 5, 6, 7),
  y = c(2, 2, 4, 3, 2, 1),
  scorers = c(
    ""Messi"", ""Moses (pen.)"", ""(Croatia)\nBadelj"", 
    ""G. Sigurdsson (pen.)"", ""Rojo"", ""Perisic (90')"")
)

points_labs <- data.frame(
  x = c(rep(max(group_d$time), 4)),
  y = c(rep(1:4, 1)),
  points = c(""9 pts."", ""4 pts."", ""3 pts."", ""1 pts."")
)

## PLOT
# size 0.11, color does NOT put borders around flags...
groupD <- ggplot(group_d, aes(time, position)) +
  geom_line(
    aes(group = team), 
    linetype = ""dotted"",
    size = 1.1) +
  geom_flag(
    aes(image = flag,
        by = ""height""),
    size = 0.1) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.38, size = 3.5) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    nudge_x = 0.8,
    size = 5,
    color = ""grey30"") + # match color with the other axes labels!
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:7,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.5, 8.1)) +
  labs(
    title = ""Group D Table Throughout The Last Matchday"",
    subtitle = ""Nigeria vs. Argentina & Iceland vs. Croatia"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday +
  theme(plot.background = element_rect(fill = 'lightgrey'))

ggsave(groupD, filename = ""groupD_table.png"", width = 8, height = 5)
```

## Group E Standings During Final Matchday!

```{r fig.width=7, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
#loadfonts()  run once per new session!

group_e <- data.frame(

  time =        c(  1, 2, 3, 4),
  brazil =     c(   1, 2, 1, 1),
  switzerland = c(  2, 1, 2, 2),
  serbia =     c(   3, 3, 3, 3),
  costa_rica = c(   4, 4, 4, 4)
  
)

group_e <- group_e %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = recode_factor(team, ""costa_rica"" = ""costa rica"")) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""brazil"", ""switzerland"", ""serbia"", ""costa rica""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""31'"", ""36'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 4, 4, 4, 4),
  y = c(1, 1, 1, 2, 3, 4),
  score = c(""1-0"", ""1-0"", ""2-0"", ""2-2"", 
            ""0-2"", ""2-2"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""Brazil"", ""Switzerland"", ""Serbia"", ""Costa Rica"")
)

goals_labs <- data.frame(
  x = c(2, 3, 4, 4, 4),
  y = c(1, 1, 4, 1, 2),
  scorers = c(""Dzemaili"", ""Paulinho"", 
              ""Waston (56')\nSommer o.g. (90+3')"", ""Thiago Silva (68')"", ""Drmic (88')"")
)

points_labs <- data.frame(
  x = c(4.5, 4.5, 4.5, 4.5),
  y = c(1, 2, 3, 4),
  points = c(""7 pts."", ""5 pts."", ""3 pts."", ""1 pts."")
)

## PLOT

groupE <- ggplot(
  group_e,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.1) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.33, size = 5.5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.35, size = 4) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    size = 5,
    color = ""grey30"") +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:4,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.6, 4.8)) +
  labs(
    title = ""Group E Table Throughout The Last Matchday"",
    subtitle = ""Serbia vs. Brazil & Switzerland vs. Costa Rica"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

ggsave(groupE, filename = ""groupE_table.png"", height = 5, width = 7)

```


## Group F Standings During Final Matchday!

```{r fig.width=8, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
#loadfonts()  run once per new session!

group_f <- data.frame(

  time =      c(  1, 2, 3, 4, 5),
  mexico =   c(   1, 1, 2, 2, 2),
  germany =   c(  2, 3, 3, 4, 4),
  sweden =   c(   3, 2, 1, 1, 1),
  south_korea = c(4, 4, 4, 3, 3)
  
)

group_f <- group_f %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = recode_factor(team, ""south_korea"" = ""south korea"")) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""mexico"", ""germany"", ""sweden"", ""south korea""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""50'"", ""60'"", ""90+3'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 4, 5, 5, 5, 5),
  y = c(2, 1, 3, 1, 2, 3, 4),
  score = c(""1-0"", ""2-0"", ""1-0"", 
            ""3-0"", ""0-3"", ""2-0"", ""0-2"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""Mexico"", ""Germany"", ""Sweden"", ""South Korea"")
)

goals_labs <- data.frame(
  x = c(2, 3, 4, 5, 5),
  y = c(2, 1, 3, 1, 3),
  scorers = c(""Augustinsson"", ""Granqvist (pen.)"", ""Kim Y-G"", 
              ""Alvarez o.g. (74')"", ""Son H-M (90+6')"")
)

points_labs <- data.frame(
  x = c(5.6, 5.6, 5.6, 5.6),
  y = c(1, 2, 3, 4),
  points = c(""6 pts."", ""6 pts."", ""3 pts."", ""3 pts."")
)

## PLOT

groupF <- ggplot(
  group_f,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.25, size = 3.5) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    size = 5,
    color = ""grey30"") +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:5,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.6, 5.8)) +
  labs(
    title = ""Group F Table Throughout The Last Matchday"",
    subtitle = ""South Korea vs. Germany & Mexico vs. Sweden"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

ggsave(groupF, filename = ""groupF_table.png"", width = 8, height = 5)
```


## Group G Standings During Final Matchday!

```{r fig.width=7, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
#loadfonts()  run once per new session!

group_g <- data.frame(

  time =      c(1, 2, 3, 4),
  england =   c(1, 1, 2, 2),
  belgium =   c(2, 2, 1, 1),
  tunisia =   c(3, 4, 3, 3),
  panama =    c(4, 3, 4, 4)
  
)

group_g <- group_g %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team)) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""england"", ""belgium"", ""tunisia"", ""panama""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""33'"", ""51'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 3, 4, 4, 4, 4),
  y = c(3, 3, 1, 1, 2, 3, 4),
  score = c(""1-0"", ""1-1"", ""1-0"", 
            ""1-0"", ""0-1"", ""2-1"", ""1-2"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""England"", ""Belgium"", ""Tunisia"", ""Panama"")
)

goals_labs <- data.frame(
  x = c(2, 3, 3, 4),
  y = c(3, 1, 3, 3),
  scorers = c(""Meria o.g."", ""Januzaj"", ""F. Ben Youssef"", ""Khazri ('66)"")
)

points_labs <- data.frame(
  x = c(4.6, 4.6, 4.6, 4.6),
  y = c(1, 2, 3, 4),
  points = c(""9 pts."", ""6 pts."", ""3 pts."", ""0 pts."")
)

england <- data.frame(
  x = c(1, 2, 3, 4),
  y = c(1, 1, 2, 2),
  image = ""https://upload.wikimedia.org/wikipedia/en/thumb/b/be/Flag_of_England.svg/1280px-Flag_of_England.svg.png""
)

## PLOT

groupG <- ggplot(
  group_g,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11) +
  ggimage::geom_image(
    data = england,
    aes(x = x, y = y,
      image = image), 
    size = 0.13) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.37, size = 5.5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.33, size = 5.5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.3, size = 3.5) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    size = 5,
    color = ""grey30"") +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.4),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:4,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.6, 5)) +
  labs(
    title = ""Group G Table Throughout The Last Matchday"",
    subtitle = ""England vs. Belgium & Panama vs. Tunisia"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

ggsave(groupG, filename = ""groupG_table.png"", height = 5, width = 7)
```



## Group H Standings During Final Matchday!



```{r fig.width=7, fig.height=5}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
#loadfonts()  run once per new session!

group_h <- data.frame(

  time =      c( 1, 2, 3, 4),
  japan =   c(   1, 3, 2, 2),
  senegal =   c( 2, 1, 3, 3),
  colombia =   c(3, 2, 1, 1),
  poland = c(    4, 4, 4, 4)
  
)

group_h <- group_h %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team)) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""japan"", ""senegal"", ""colombia"", ""poland""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))

x_labs <- c(""0'"", ""59'"", ""74'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")

score_labs <- data.frame(
  x = c(2, 3, 4, 4, 4, 4),
  y = c(3, 1, 1, 2, 3, 4),
  score = c(""0-1"", ""1-0"", 
            ""1-0"", ""0-1"", ""0-1"", ""1-0"")
)

country_labs <- data.frame(
  x = c(1, 1, 1, 1),
  y = c(1, 2, 3, 4),
  country = c(""Japan"", ""Senegal"", ""Colombia"", ""Poland"")
)

goals_labs <- data.frame(
  x = c(2, 3),
  y = c(3, 1),
  scorers = c(""Bednarek (Poland)"", ""Mina"")
)

points_labs <- data.frame(
  x = c(4.5, 4.5, 4.5, 4.5),
  y = c(1, 2, 3, 4),
  points = c(""6 pts."", ""4 pts."", ""4 pts."", ""3 pts."")
)

## PLOT

groupH <- ggplot(
  group_h,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11) +
  geom_text(
    data = country_labs,
    aes(x = x, y = y, 
        label = country,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = score_labs,
    aes(x = x, y = y, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 5.5) +
  geom_text(
    data = goals_labs,
    aes(x = x, y = y, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.25, size = 3.5) +
  geom_text(
    data = points_labs,
    aes(x = x, y = y, 
        label = points,
        family = ""Dusha V5""),
    size = 5,
    color = ""grey30"") +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:4,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.7, 4.8)) +
  labs(
    title = ""Group H Table Throughout The Last Matchday"",
    subtitle = ""Japan vs. Poland & Senegal vs. Colombia"",
    caption = ""by @R_By_Ryo"") +
  theme_matchday

ggsave(groupH, filename = ""groupH_table.png"", width = 7, height = 5)
```

----------------------------------------------------------------------------------



### not work!

```{r NOT WORK}
library(dplyr)
library(ggplot2)
library(ggimage)
library(countrycode)
library(tidyr)
library(forcats)
library(extrafont)
# loadfonts()  run once per new session!

group_d <- data.frame(

  time =      c(1, 2, 3, 4, 5, 6, 7),
  croatia =   c(1, 1, 1, 1, 1, 1, 1),
  nigeria =   c(2, 3, 2, 2, 2, 3, 3),
  iceland =   c(3, 4, 3, 4, 3, 4, 4),
  argentina = c(4, 2, 4, 3, 4, 2, 2)
  
)

group_d <- group_d %>% 
  gather(team, position, -time) %>% 
  mutate(team = as.factor(team),
         team = fct_relevel(team, 
                            ""croatia"", ""nigeria"", ""argentina"", ""iceland""),
         flag = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c""))


group_d %>% 
  mutate(
    xscore = c(2, 3, 4, 5, 6, 7, 7, 7, 7),
    yscore = c(2, 2, 4, 3, 2, 1, 2, 3, 4),
    score = c(""1-0"", ""1-1"", ""0-1"", ""1-1"", ""2-1"", 
            ""2-1"", ""2-1"", ""1-2"", ""1-2""),
    
    xcountry= c(1, 1, 1, 1),
    ycountry = c(1, 2, 3, 4),
    country = c(""Croatia"", ""Nigeria"", ""Iceland"", ""Argentina""),
    
    xgoal = c(2, 3, 4, 5, 6, 7),
    ygoal = c(2, 2, 4, 3, 2, 1),
    scorers = c(""Messi"", ""Moses (pen.)"", ""(Croatia)\nBadelj"", 
              ""G. Sigurdsson (pen.)"", ""Rojo"", ""Perisic (90')""),
    
    xpoint = c(7.8, 7.8, 7.8, 7.8),
    ypoint = c(1, 2, 3, 4),
    points = c(""9 pts."", ""4 pts."", ""3 pts."", ""1 pts."")
  )

x_labs <- c(""0'"", ""14'"", ""51'"", ""53'"", ""76'"", ""86'"", ""Full Time"")
y_labs <- c(""1st"", ""2nd"", ""3rd"", ""4th"")


ggplot(
  group_d,
  aes(time, position)) +
  geom_line(
    aes(group = team), linetype = ""dotted"") +
  geom_flag(
    aes(image = flag), 
    size = 0.11) +
  geom_text(
    aes(x = c(xcountry, xscore), y = c(ycountry, yscore), 
        label = c(country, score),
        family = ""Dusha V5""),
    nudge_y = c(0.3, 0.3), size = c(6, 6)) +
  geom_text(
    aes(x = xscore, y = yscore, 
        label = score,
        family = ""Dusha V5""),
    nudge_y = 0.3, size = 6) +
  geom_text(
    aes(x = xgoal, y = ygoal, 
        label = scorers,
        family = ""Dusha V5""),
    nudge_y = -0.38, size = 4) +
  geom_text(
    aes(x = xpoint, y = ypoint, 
        label = points,
        family = ""Dusha V5""),
    size = 5) +
  scale_y_reverse(
    expand = c(0, 0), 
    limits = c(4.8, 0.6),
    breaks = 1:4,
    labels = y_labs) +
  scale_x_continuous(
    position = ""top"", 
    breaks = 1:7,
    labels = x_labs,
    expand = c(0, 0),
    limits = c(0.4, 8.3)) +
  labs(
    title = ""Group D Table Throughout The Last Matchday"",
    subtitle = ""Nigeria vs. Argentina & Iceland vs. Croatia"",
    caption = ""by @R_By_Ryo"") +
  theme_minimal() +
  theme_matchday()


```","2018"
"80",247,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/historical_kits.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 24, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Uniform animation
https://guyabel.com/post/football-kits/

ex. Liverpool 


```{r}
library(rvest)
library(dplyr)
library(purrr)
library(stringr)
library(magick)

url <- ""http://www.historicalkits.co.uk/Liverpool/Liverpool.htm""

#kits
#div.float:nth-child(2)
#div.float:nth-child(3) > img:nth-child(2)
#div.float:nth-child(2)
#div.float:nth-child(2) > img:nth-child(2)
#div.float:nth-child(67)
#div.float:nth-child(2) > img:nth-child(2)
#div.float:nth-child(2) > img:nth-child(2)
#.float p , .float img
#/html/body/div[2]/div[4]/div[2]/div[2]/div[3]/img
#div.float:nth-child(4) > img:nth-child(1)
#html body div#master div#bodywrap div#maincol div.content div.float img

url %>% 
  read_html() %>% 
  html_nodes("".float p , .float img"") %>% 
  html_attr(""src"")


url %>% 
  read_html() %>% 
  html_nodes("".float img"") %>% 
  html_attr(""src"")

url %>% 
  read_html() %>% 
  html_nodes("".float p , .float img"") %>% 
  html_text() %>% 
  c(., NA) %>% 
  .[-1]



scrape_img_url <- function(html){
  html %>%
    html_nodes("".float p , .float img"") %>%
    html_attr(""src"") %>%
    tbl_df() %>%
    set_names(""img_url"") %>%
    mutate(label = html %>% 
             html_nodes("".float p , .float img"") %>%
             html_text() %>%
             c(., NA) %>%
             .[-1])
}


d1 <- read_html(""http://www.historicalkits.co.uk/Liverpool/Liverpool.htm"") %>%
  scrape_img_url() %>%
  filter(str_detect(string = img_url, pattern = ""/Liverpool""),
         !str_detect(string = img_url, pattern = ""unknown"")) %>%
  mutate(
    label = str_replace_all(string = label,
                            pattern = ""[:alpha:]|\\s"", 
                            replacement = """")
  )
# some wrong labels... 



# 2000s

d2 <- d1 %>% 
  slice(46:58)

# download img
kits <- d2 %>% 
  mutate(img_url = paste0(""http://www.historicalkits.co.uk"", img_url)) %>% 
  select(img_url) %>% 
  map(image_read) %>% 
  set_names(""img"")

# morph

kits_ani <- image_morph(c(kits$img[1], kits$img[1]), frames = 4)
kits_ani



seq_along(kits$img)
2:length(kits$img)

seq_along(kits$img) - 1

# save vector of seq_along() 
# map image_morph with vectors of kits$img

kits_len <- seq_along(kits$img)

2:length(kits$img)


kits %>% 
  map(kits_len, function(x) image_morph(.$img - 1, .$img), frame = 5)


for (i in 2:length(kits$img)) {
  
  kits_morph0 <- image_morph(c(kits$img[i - 1], kits$img[i]), frames = 4)
  
  kits_morph1 <- image_morph(c(kits$img[i], kits$img[i]), frames = 4)
  
  kits_ani <- c(kits_ani, kits_morph0)
  
  kits_ani <- c(kits_ani, kits_morph1)
  
}

# animation

kits_ani %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""liv_2000s.gif"")

```


## Japan World Cup uniforms

- example with just japan uniforms

```{r}
library(magick)

japan_kits <- list.files(path = ""./japan_kits/"", pattern = ""*.gif"", full.names = TRUE) %>% 
  map(image_read) %>% 
  image_join()

# no join
japan_kits2 <- list.files(path = ""./japan_kits/"", pattern = ""*.gif"", full.names = TRUE) %>% 
  map(image_read) 

japan_kits2 <- japan_kits2 %>% set_names(rep(""img"", 6))

japan_kits <- list(img = japan_kits) # turn into list with ""img"" as name
# subset [1] to [6] in this. so can image_morph() call each and previous

japan_seq2 <- seq_along(japan_kits2)


#
japan_ani <- image_morph(c(japan_kits$img[1], japan_kits$img[1]), frame = 10)

kits_morph_j0 <- 2:6 %>% 
  map(~ image_morph(c(japan_kits$img[.x-1], japan_kits$img[.x]), frames = 10)) %>% 
  image_join()

kits_morph_j1 <- 2:6 %>% 
  map(~ image_morph(c(japan_kits$img[.x], japan_kits$img[.x]), frames = 10)) %>% 
  image_join()

jkits_ani <- c(japan_ani, kits_morph_j0)
# jkits_ani <- c(jkits_ani, kits_morph_j1)  #  need to integrate PAUSE with morph anims

jkits_ani %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_kit.gif"")

```



## Combine kits for every match sid-by-side

- Read in uniforms (kit_read() function)
- Stitch them up with respective opponent uniforms
- add labels + increase border size
- Loop through image_morph()
- Find LAST frame of previous and FIRST frame of current
- image_morph() those two frames for smooth transition between last game of World Cup and first game of next World Cup!
- repeat to 2018

```{r kit_read fun}
kit_read <- function(path) {
  
  japan_kits <- list.files(path = path, pattern = ""*.gif"", full.names = TRUE) %>% 
    map(image_read) %>% 
    image_join()  
  
  return(japan_kits)
  
}
```


```{r 1998}
library(magick)
library(dplyr)
library(purrr)
library(extrafont)
#loadfonts()
source(""../scripts/kit_read().r"")
# 1998 WC

japan_kits_1998 <- kit_read(path = ""../japan_kits/1998/"")

kit_labels_1998 <- data_frame(
  label = c(""Japan (0) vs. (1) Argentina"", ""Japan (0) vs. (1) Croatia"", ""Japan (1) vs. (2) Jamaica"")
)

wc_label_1998 <- ""World Cup: 1998 (France)""

j_arg <- japan_kits_1998[c(4, 1)] %>% image_append()  # vs. Argentina
j_cro <- japan_kits_1998[c(4, 2)] %>% image_append()  # vs. Croatia
j_jam <- japan_kits_1998[c(4, 3)] %>% image_append()  # vs. Jamaica

j_kits_1998 <- c(j_arg, j_cro, j_jam)
# make into function?

kit_list_1998 <-list(img = j_kits_1998)

# for loop
for (i in seq_along(kit_list_1998$img)) {
  
  kit_list_1998$img[i] <- kit_list_1998$img[i] %>% 
    image_border(geometry = ""25x60"", color = ""white"") %>% 
    image_annotate(text = kit_labels_1998$label[i], 
                   gravity = ""south"",
                   location = ""+0+325"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(text = wc_label_1998,
                   gravity = ""south"",
                   location = ""+0+350"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(
      text = ""Images are Copyright of Historical\nFootball Kits and reproduced by\nkind permission."",
      gravity = ""south""
    )
}


# guy abel code for include PAUSE
jkits_ani_1998 <- image_morph(c(kit_list_1998$img[1], kit_list_1998$img[1]), frames = 8)

for(i in 2:length(kit_list_1998$img)){
  kits_morph0 <- image_morph(c(kit_list_1998$img[i-1], kit_list_1998$img[i]), frames = 4)
  
  kits_morph1 <- image_morph(c(kit_list_1998$img[i], kit_list_1998$img[i]), frames = 8)
  
  jkits_ani_1998 <- c(jkits_ani_1998, kits_morph0)
  
  jkits_ani_1998 <- c(jkits_ani_1998, kits_morph1)
}

# animate!
jkits_ani_1998 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_versus_kit_1998.gif"")

```




```{r map() 1998}
j_kits %>% 
  image_border(geometry = ""10x60"", color = ""white"") %>% 
  image_annotate(text = ""world cup 1998"", 
                 gravity = ""south"", location = ""+0+300"",
                 font = ""Trebuchet MS"", size = 30)

# image_morph each of the match img

japan_ani <- image_morph(c(kit_list$img[1], kit_list$img[1]), frame = 10)

2:length(kit_list$img) %>% 
  map(~ image_morph(c(kit_list$img[.x-1], kit_list$img[.x]), frames = 10)) %>% 
  image_join()

kits_morph_j0 <- 2:3 %>% 
  map(~ image_morph(c(kit_list$img[.x-1], kit_list$img[.x]), frames = 10)) %>% 
  image_join()

kits_morph_j1 <- 2:3 %>% 
  map(~ image_morph(c(kit_list$img[.x], kit_list$img[.x]), frames = 10)) %>% 
  image_join()

jkits_ani <- c(japan_ani, kits_morph_j0)
jkits_ani <- c(jkits_ani, kits_morph_j1)  #  need to integrate PAUSE with morph anims

## as function?

```




```{r 2002}
# 2002 World Cup
library(magick)
library(dplyr)
library(purrr)
library(extrafont)
#loadfonts()
source(""../scripts/kit_read().r"")

japan_kits_2002 <- kit_read(path = ""../japan_kits/2002/"")

kit_labels_2002 <- data_frame(
  label = c(""Japan (2) vs. (2) Belgium"", ""Japan (1) vs. (0) Russia"", ""Japan (2) vs. (0) Tunisia"", ""Japan (0) vs. (1) Turkey"")
)

wc_label_2002 <- ""World Cup: 2002 (Korea/Japan)""

# 2 is Japan Away, 3 is Japan Home
# 1 = belgium, 4 = russia, 5 = tunisia, 6 = Turkey
j_bel <- japan_kits_2002[c(2, 1)] %>% image_append()  # vs. Belgium
j_rus <- japan_kits_2002[c(3, 4)] %>% image_append()  # vs. Russia
j_tun <- japan_kits_2002[c(3, 5)] %>% image_append()  # vs. Tunisia
j_tur <- japan_kits_2002[c(3, 6)] %>% image_append()  # vs. Turkey

j_kits_2002 <- c(j_bel, j_rus, j_tun, j_tur)
# make into function?

kit_list_2002 <-list(img = j_kits_2002)

for (i in seq_along(kit_list_2002$img)) {
  
  kit_list_2002$img[i] <- kit_list_2002$img[i] %>% 
    image_border(geometry = ""25x60"", color = ""white"") %>% 
    image_annotate(text = kit_labels_2002$label[i], 
                   gravity = ""south"",
                   location = ""+0+325"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(text = wc_label_2002,
                   gravity = ""south"",
                   location = ""+0+350"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(
      text = ""Images are Copyright of Historical\nFootball Kits and reproduced by\nkind permission."",
      gravity = ""south""
    )
}

# guy abel code for include PAUSE
jkits_ani_2002 <- image_morph(c(kit_list_2002$img[1], kit_list_2002$img[1]), frames = 8)

for(i in 2:length(kit_list_2002$img)){
  kits_morph0 <- image_morph(c(kit_list_2002$img[i-1], kit_list_2002$img[i]), frames = 4)
  
  kits_morph1 <- image_morph(c(kit_list_2002$img[i], kit_list_2002$img[i]), frames = 8)
  
  jkits_ani_2002 <- c(jkits_ani_2002, kits_morph0)
  
  jkits_ani_2002 <- c(jkits_ani_2002, kits_morph1)
}

jkits_ani_2002 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_versus_kit_2002.gif"")

# connect 1998 and 2002

jkits_ani_ALL <- c(jkits_ani_1998, jkits_ani_2002)

jkits_ani_ALL <-list(img = jkits_ani_ALL)

# frame 42 is the transition from 2998 to 2006
jkits_ani_ALL_ch <- image_morph(c(jkits_ani_ALL$img[42], jkits_ani_ALL$img[43]), frames = 8)

jj <- append(jkits_ani_ALL$img, jkits_ani_ALL_ch, 42)

jj %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_TEST_history.gif"")

```

```{r map() 2002}
# image_morph each of the match img

japan_ani_2002 <- image_morph(c(kit_list_2002$img[1], kit_list_2002$img[1]), frame = 10)

kits_morph_j0 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2002$img[.x-1], kit_list_2002$img[.x]), frames = 10)) %>% 
  image_join()

kits_morph_j1 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2002$img[.x], kit_list_2002$img[.x]), frames = 10)) %>% 
  image_join()

jkits_ani_2002 <- c(japan_ani_2002, kits_morph_j0)
#jkits_ani <- c(jkits_ani, kits_morph_j1)  #  need to integrate PAUSE with morph anims

## as function?

```


```{r 2006}
# 2006 World Cup
library(magick)
library(dplyr)
library(purrr)
library(extrafont)
#loadfonts()
source(""../scripts/kit_read().r"")

japan_kits_2006 <- kit_read(path = ""../japan_kits/2006/"")

kit_labels_2006 <- data_frame(
  label = c(""Japan (1) vs. (3) Australia"", ""Japan (0) vs. (0) Croatia"", ""Japan (1) vs. (4) Brazil"")
)

wc_label_2006 <- ""World Cup: 2006 (Germany)""

# 5 is Japan Away, 4 is Japan Home
# 1 = aus, 2 = bra, 3 = cro
j_aus <- japan_kits_2006[c(5, 1)] %>% image_append()  # vs. Australia
j_cro <- japan_kits_2006[c(4, 3)] %>% image_append()  # vs. Croatia
j_bra <- japan_kits_2006[c(4, 2)] %>% image_append()  # vs. Brazil

j_kits_2006 <- c(j_aus, j_cro, j_bra)
# make into function?

kit_list_2006 <-list(img = j_kits_2006)

for (i in seq_along(kit_list_2006$img)) {
  
  kit_list_2006$img[i] <- kit_list_2006$img[i] %>% 
    image_border(geometry = ""25x60"", color = ""white"") %>% 
    image_annotate(text = kit_labels_2006$label[i], 
                   gravity = ""south"",
                   location = ""+0+325"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(text = wc_label_2006,
                   gravity = ""south"",
                   location = ""+0+350"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(
      text = ""Images are Copyright of Historical\nFootball Kits and reproduced by\nkind permission."",
      gravity = ""south""
    )
}

# guy abel code for include PAUSE
jkits_ani_2006 <- image_morph(c(kit_list_2006$img[1], kit_list_2006$img[1]), frames = 8)

for(i in 2:length(kit_list_2006$img)){
  kits_morph0 <- image_morph(c(kit_list_2006$img[i-1], kit_list_2006$img[i]), frames = 4)
  
  kits_morph1 <- image_morph(c(kit_list_2006$img[i], kit_list_2006$img[i]), frames = 8)
  
  jkits_ani_2006 <- c(jkits_ani_2006, kits_morph0)
  
  jkits_ani_2006 <- c(jkits_ani_2006, kits_morph1)
}

jkits_ani_2006 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_versus_kit_2006.gif"")

# connect 1998/2002 to 2006

jkits_ani_ALL <- c(jj, jkits_ani_2006)

jkits_ani_ALL <-list(img = jkits_ani_ALL)

# 110 >>> 111
jkits_ani_ALL_ch <- image_morph(c(jkits_ani_ALL$img[110], jkits_ani_ALL$img[111]), frames = 8)

jj2 <- append(jkits_ani_ALL$img, jkits_ani_ALL_ch, 110)

jj2 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_TEST2_history.gif"")

```



```{r map() 2006}
# image_morph each of the match img

japan_ani_2006 <- image_morph(c(kit_list_2006$img[1], kit_list_2006$img[1]), frame = 10)

kits_morph_j0 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2006$img[.x-1], kit_list_2006$img[.x]), frames = 10)) %>% 
  image_join()

kits_morph_j1 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2006$img[.x], kit_list_2006$img[.x]), frames = 10)) %>% 
  image_join()

jkits_ani_2006 <- c(japan_ani_2006, kits_morph_j0)
#jkits_ani <- c(jkits_ani, kits_morph_j1)  #  need to integrate PAUSE with morph anims

## as function?





```



```{r 2010}
# 2010 World Cup
library(magick)
library(dplyr)
library(purrr)
library(extrafont)
#loadfonts()
source(""../scripts/kit_read().r"")

japan_kits_2010 <- kit_read(path = ""../japan_kits/2010/"")

kit_labels_2010 <- data_frame(
  label = c(""Japan (1) vs. (0) Cameroon"", ""Japan (0) vs. (1) Netherlands"", ""Japan (3) vs. (1) Denmark"", ""Japan (0) vs. (1 PK) Paraguay"")
)

wc_label_2010 <- ""World Cup: 2010 (South Africa)""

# 3 is Japan Away, 4 is Japan Home (blue shorts), 5 is Japan Home (white shorts), 
# 1 = cam, 2 = den, 6 = ned, par = 7
j_cam <- japan_kits_2010[c(5, 1)] %>% image_append()  # vs. Cameroon
j_ned <- japan_kits_2010[c(3, 6)] %>% image_append()  # vs. Netherlands
j_den <- japan_kits_2010[c(4, 2)] %>% image_append()  # vs. Denmark
j_par <- japan_kits_2010[c(4, 7)] %>% image_append()  # vs. Paraguay

j_kits_2010 <- c(j_cam, j_ned, j_den, j_par)

kit_list_2010 <-list(img = j_kits_2010)

# loop over to add annotations
for (i in seq_along(kit_list_2010$img)) {
  
  kit_list_2010$img[i] <- kit_list_2010$img[i] %>% 
    image_border(geometry = ""25x60"", color = ""white"") %>% 
    image_annotate(text = kit_labels_2010$label[i], 
                   gravity = ""south"",
                   location = ""+0+325"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(text = wc_label_2010,
                   gravity = ""south"",
                   location = ""+0+350"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(
      text = ""Images are Copyright of Historical\nFootball Kits and reproduced by\nkind permission."",
      gravity = ""south""
    )
}

# guy abel code for include PAUSE
jkits_ani_2010 <- image_morph(c(kit_list_2010$img[1], kit_list_2010$img[1]), frames = 8)

for(i in 2:length(kit_list_2010$img)){
  kits_morph0 <- image_morph(c(kit_list_2010$img[i-1], kit_list_2010$img[i]), frames = 4)
  
  kits_morph1 <- image_morph(c(kit_list_2010$img[i], kit_list_2010$img[i]), frames = 8)
  
  jkits_ani_2010 <- c(jkits_ani_2010, kits_morph0)
  
  jkits_ani_2010 <- c(jkits_ani_2010, kits_morph1)
}

jkits_ani_2010 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_versus_kit_2010.gif"")

# connect 1998/2002/2006 to 2010

jkits_ani_ALL <- c(jj2, jkits_ani_2010)

jkits_ani_ALL <-list(img = jkits_ani_ALL)

# 162 >>> 163
jkits_ani_ALL_ch <- image_morph(c(jkits_ani_ALL$img[162], jkits_ani_ALL$img[163]), frames = 8)

jj3 <- append(jkits_ani_ALL$img, jkits_ani_ALL_ch, 162)

jj3 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_TEST3_history.gif"")

```



```{r map() 2010}
# image_morph each of the match img

japan_ani_2010 <- image_morph(c(kit_list_2010$img[1], kit_list_2010$img[1]), frame = 10)
japan_ani_2010_2 <- image_morph(c(kit_list_2010$img[2], kit_list_2010$img[2]), frame = 10)
japan_ani_2010_3 <- image_morph(c(kit_list_2010$img[3], kit_list_2010$img[3]), frame = 10)

kits_morph_j0 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2010$img[.x-1], kit_list_2010$img[.x]), frames = 10)) %>% 
  image_join()

kits_morph_j1 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2010$img[.x], kit_list_2010$img[.x]), frames = 10)) %>% 
  image_join()

jkits_ani_2010 <- c(japan_ani_2010, kits_morph_j0)
#jkits_ani <- c(jkits_ani, kits_morph_j1)  #  need to integrate PAUSE with morph anims

## as function?

```


```{r 2014}
# 2014 World Cup
library(magick)
library(dplyr)
library(purrr)
library(extrafont)
#loadfonts()
source(""../scripts/kit_read().r"")

japan_kits_2014 <- kit_read(path = ""../japan_kits/2014/"")

kit_labels_2014 <- data_frame(
  label = c(""Japan (1) vs. (2) Ivory Coast"", ""Japan (0) vs. (0) Greece"", ""Japan (1) vs. (4) Colombia"")
)

wc_label_2014 <- ""World Cup: 2014 (Brazil)""

# 4 is is Japan Home
# 1 = col, 2 = gre, 3 = civ
j_civ <- japan_kits_2014[c(4, 3)] %>% image_append()  # vs. Cote d'Ivoire
j_gre <- japan_kits_2014[c(4, 2)] %>% image_append()  # vs. Greece
j_col <- japan_kits_2014[c(4, 1)] %>% image_append()  # vs. Colombia

j_kits_2014 <- c(j_civ, j_gre, j_col)

kit_list_2014 <-list(img = j_kits_2014)

# loop over to add annotations
for (i in seq_along(kit_list_2014$img)) {
  
  kit_list_2014$img[i] <- kit_list_2014$img[i] %>% 
    image_border(geometry = ""25x60"", color = ""white"") %>% 
    image_annotate(text = kit_labels_2014$label[i], 
                   gravity = ""south"",
                   location = ""+0+325"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(text = wc_label_2014,
                   gravity = ""south"",
                   location = ""+0+350"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(
      text = ""Images are Copyright of Historical\nFootball Kits and reproduced by\nkind permission."",
      gravity = ""south""
    )
}

# guy abel code for include PAUSE
jkits_ani_2014 <- image_morph(c(kit_list_2014$img[1], kit_list_2014$img[1]), frames = 8)

for(i in 2:length(kit_list_2014$img)){
  kits_morph0 <- image_morph(c(kit_list_2014$img[i-1], kit_list_2014$img[i]), frames = 4)
  
  kits_morph1 <- image_morph(c(kit_list_2014$img[i], kit_list_2014$img[i]), frames = 8)
  
  jkits_ani_2014 <- c(jkits_ani_2014, kits_morph0)
  
  jkits_ani_2014 <- c(jkits_ani_2014, kits_morph1)
}


jkits_ani_2014 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_versus_kit_2014.gif"")

# connect 1998/2002/2006/2010 to 2014

jkits_ani_ALL <- c(jj3, jkits_ani_2014)

jkits_ani_ALL <-list(img = jkits_ani_ALL)

# 110 >>> 111
jkits_ani_ALL_ch <- image_morph(c(jkits_ani_ALL$img[230], jkits_ani_ALL$img[231]), frames = 8)

jj4 <- append(jkits_ani_ALL$img, jkits_ani_ALL_ch, 230)

jj4 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_TEST4_history.gif"")

```




```{r map() 2014}
# image_morph each of the match img

japan_ani_2014 <- image_morph(c(kit_list_2014$img[1], kit_list_2014$img[1]), frame = 10)

kits_morph_j0 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2014$img[.x-1], kit_list_2014$img[.x]), frames = 10)) %>% 
  image_join()

kits_morph_j1 <- 2:3 %>% 
  map(~ image_morph(c(kit_list_2010$img[.x], kit_list_2010$img[.x]), frames = 10)) %>% 
  image_join()

jkits_ani_2014 <- c(japan_ani_2014, kits_morph_j0)
#jkits_ani <- c(jkits_ani, kits_morph_j1)  #  need to integrate PAUSE with morph anims

```


```{r 2018}
# 2018 World Cup
library(magick)
library(dplyr)
library(purrr)
library(extrafont)
#loadfonts()
source(""../scripts/kit_read().r"")

japan_kits_2018 <- kit_read(path = ""../japan_kits/2018/"")

kit_labels_2018 <- data_frame(
  label = c(""Japan (2) vs. (1) Colombia"", ""Japan (2) vs. (2) Senegal"", ""Japan (0) vs. (1) Poland"", ""Japan (2) vs. (3) Belgium"")
)

wc_label_2018 <- ""World Cup: 2018 (Russia)""

# 3 is Japan Home
# 2 = col, 4 = pol, 5 = sen, bel = 1
j_col <- japan_kits_2018[c(3, 2)] %>% image_append()  # vs. Colombia
j_sen <- japan_kits_2018[c(3, 5)] %>% image_append()  # vs. Senegal
j_pol <- japan_kits_2018[c(3, 4)] %>% image_append()  # vs. Poland
j_bel <- japan_kits_2018[c(3, 1)] %>% image_append()  # vs. Belgium

j_kits_2018 <- c(j_col, j_sen, j_pol, j_bel)

kit_list_2018 <-list(img = j_kits_2018)

# loop over to add annotations
for (i in seq_along(kit_list_2018$img)) {
  
  kit_list_2018$img[i] <- kit_list_2018$img[i] %>% 
    image_border(geometry = ""25x60"", color = ""white"") %>% 
    image_annotate(text = kit_labels_2018$label[i], 
                   gravity = ""south"",
                   location = ""+0+325"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(text = wc_label_2018,
                   gravity = ""south"",
                   location = ""+0+350"",
                   font = ""Trebuchet MS"",
                   size = 25) %>% 
    image_annotate(
      text = ""Images are Copyright of Historical\nFootball Kits and reproduced by\nkind permission."",
      gravity = ""south""
    )
}

# guy abel code for include PAUSE
jkits_ani_2018 <- image_morph(c(kit_list_2018$img[1], kit_list_2018$img[1]), frames = 8)

for(i in 2:length(kit_list_2018$img)){
  kits_morph0 <- image_morph(c(kit_list_2018$img[i-1], kit_list_2018$img[i]), frames = 4)
  
  kits_morph1 <- image_morph(c(kit_list_2018$img[i], kit_list_2018$img[i]), frames = 8)
  
  jkits_ani_2018 <- c(jkits_ani_2018, kits_morph0)
  
  jkits_ani_2018 <- c(jkits_ani_2018, kits_morph1)
}

jkits_ani_2018 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_versus_kit_2018.gif"")

# connect 1998/2002/2006/2010 to 2014

jkits_ani_ALL <- c(jj4, jkits_ani_2018)

jkits_ani_ALL <-list(img = jkits_ani_ALL)

# 110 >>> 111
jkits_ani_ALL_ch <- image_morph(c(jkits_ani_ALL$img[282], jkits_ani_ALL$img[283]), frames = 8)

jj5 <- append(jkits_ani_ALL$img, jkits_ani_ALL_ch, 282)

jj5 %>% 
  image_animate(fps = 10) %>% 
  image_write(path = ""japan_TEST5_history.gif"")

```


","2018"
"81",248,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/joyplot_goals.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 30, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown


ggjoy plots    minutes goal scored across Group Stages


- webscrape: use SelectorGadget this time...! click on the elements you want to scrape, copy CSS Selector into html_nodes(), pass html_text or html_table and save! 
- reshape: everything in one row of column ""value"", take regex ""^Group"" make them new cols, group them up underneath each Group name col 
- tidy: grab minutes text, clean out apostrophe/player name/(o.g.), separate on '+' fill in 0 for non extra time goals then mutate() then sum() ??? 

what COLOR? 

different color scheme for different group?

check out scico , pomographical, hrbrthemes, wes anderson palettes



```{r}
library(rvest)
library(dplyr)

url <- ""https://ja.wikipedia.org/wiki/2018_FIFA???????""

url %>% 
  read_html() %>% 
  html_nodes(""tr+ tr span"") %>% 
  html_text()


#### actual

url <- ""https://en.wikipedia.org/wiki/2018_FIFA_World_Cup""

group_goals <- url %>% 
  read_html() %>% 
  html_nodes(""#Group_A , #Group_B , #Group_C , #Group_D , #Group_E , #Group_F , #Group_G , #Group_H,  .plainlist small"") %>% 
  html_text() %>% 
  as_tibble()

# write.csv(group_goals, ""group_goals.csv"", row.names = FALSE)

""#Group_A , #Group_B , #Group_C , #Group_D , #Group_E , #Group_F , #Group_G , #Group_H, .plainlist small""
```


```{r clean}
library(dplyr)
library(tidyr)
library(stringr)
library(purrr)

group_goals_raw <- read.csv(""group_goals.csv"", stringsAsFactors = FALSE)

group_goals <- group_goals_raw %>% 
  mutate(name = if_else(startsWith(value, ""Group""), value, NA_character_)) %>% 
  fill(name) %>% 
  filter(value != name)

group_goals %>% 
  mutate(value = str_replace_all(value, ""'"", """")) %>% 
  mutate(value = str_replace_all(value, ""\\(([^)]+)\\)"", """")) %>% 
  separate(value, into = c(""minute"", ""extra""), sep = ""\\+"") %>% 
  mutate(minute = as.numeric(minute),
         extra = as.numeric(extra))
  
  mutate(sum = if_else(!is.na(extra), ))


```

```{r}
group_goals %>% 
  mutate(value = str_replace_all(value, ""'"", """")) %>% 
  mutate(value = str_replace_all(value, ""\\(([^)]+)\\)"", """"))
```




```{r joyplot}
library(ggridges)


```






















```{r attempt true}
library(dplyr)
library(tidyr)
library(stringr)
library(tibble)
library(purrr)
library(purrrlyr)

group_goals <- read.csv(""group_goals.csv"", stringsAsFactors = FALSE)

group_goals <- group_goals %>% rownames_to_column()

group_name <- group_goals %>% select(value) %>% str_extract_all(""Group [A-Z]"") %>% as_vector()

goal_length <- group_goals %>% 
  filter(value %in% group_name) %>% 
  mutate(
    rowpos = as.numeric(rowname)) %>% 
  select(-rowname) %>% 
  rownames_to_column() %>% 
  mutate(
    goal_start = rowpos + 1, 
    goal_end = lead(rowpos) - 1,
    goal_end = case_when(
      is.na(goal_end) ~ 130,  # manually set 130 (nrow(group_goals))
      TRUE ~ goal_end
    )) %>% 
  select(-rowpos, -rowname)

1:8 # vector of 1 for each group A-H
group_goals # object to map the slice() through


goal_start
goal_end

group_goals %>% 
  slice(goal_length$goal_start[1]:goal_length$goal_end[1]) %>% 
  mutate(groupname = ""Group A"")

group_goals %>% 
  slice(goal_length$goal_start[2]:goal_length$goal_end[2]) %>% 
  mutate(groupname = ""Group B"")

group_goals %>% 
  slice(goal_length$goal_start[3]:goal_length$goal_end[3])


goal_start_vec <- goal_length$goal_start
goal_end_vec <- goal_length$goal_end

group_goals %>% 
  map(., ~slice(goal_start_vec:goal_end_vec))

group_goals %>% 
  map(., ~slice(goal_start_vec:goal_end_vec))

```

```{r reproducible}
# i have webscraped some data taht shows numerical times for a few groups. below is a small sample of what it looks like:
library(tibble)

df <- tribble(
  ~value,
  ""group a"",
  1,
  12,
  56,
  17,
  24,
  ""group b"",
  23,
  1,
  5,
  ""group c"",
  76,
  55,
  89,
  2,
  20,
  ""group d"",
  50,
  23,
  44,
  39
  
)

# what i want to end up with is as follows:   
tribble(
  ~value, ~name,
  1,     ""group a"",
  12,    ""group a"",
  56,    ""group a"",
  17,    ""group a"",
  24,    ""group a"",
  23,    ""group b"",
  1,     ""group c"",
  5,     ""group c""
  # and so on....
)

# below are my attempts to tidy this data:

df_rows <- df %>% rownames_to_column()

groups <- df_rows %>% select(value) %>% str_extract_all(""group [a-z]"") %>% as_vector()

# find the rows where data for certain group begins and ends:
df_length <- df_rows %>% 
  filter(value %in% groups) %>% 
  mutate(
    rowpos = as.numeric(rowname)) %>% 
  select(-rowname) %>% 
  rownames_to_column() %>% 
  mutate(
    group_start = rowpos + 1, 
    group_end = lead(rowpos) - 1,
    group_end = case_when(
      is.na(group_end) ~ 21,  # manually fill in the 'end row position' for the last group...
      TRUE ~ group_end
    )) %>% 
  select(-rowpos, -rowname)

# Now, I have the row number for where the data for a specific group starts and ends. Along with the original df with rownames as well.
# How to mutate() in the group names for the rows specified in ""groups"".

# This can be done by:
df_rows %>% 
  slice(df_length$group_start[1]:df_length$group_end[1]) %>% 
  mutate(groupname = ""Group A"")

df_rows %>% 
  slice(goal_length$goal_start[2]:goal_length$goal_end[2]) %>% 
  mutate(groupname = ""Group B"")

# and then i can just rbind() each to get the solution that i showed above but not very efficient... i have many groups!

# Use map() or for loops to iterate for EACH group??   below are my attempts but they don't work...

for (i in seq_along(goal_length$value)) {
  
  ggoals[i] <- group_goals %>% 
    slice(goal_length$goal_start[i]:goal_length$goal_end[i]) %>% 
    mutate(group = paste0(""Group"", goal_length$value[i]))
  
}

1:8 %>% 
  map2(.x, group_goals, 
       ~ slice(goal_length$goal_end[.x]:goal_length$goal_end[.x]))
```





## Solution

```{r solution}
library(tibble)

df <- tribble(
  ~value,
  ""group a"",
  1,
  12,
  56,
  17,
  24,
  ""group b"",
  23,
  1,
  5,
  ""group c"",
  76,
  55,
  89,
  2,
  20,
  ""group d"",
  50,
  23,
  44,
  39
  
)


glimpse(df)

library(tidyverse)

df %>% 
  mutate(name = if_else(startsWith(value, ""group""), value, NA_character_)) %>% 
  fill(name) %>% 
  filter(value != name)


# alt

group_rows <- which(startsWith(df$value, ""group""))
group_labels <- df$value[group_rows]
group_start <- group_rows + 1
group_end <- c(group_rows[-1] - 1, length(df$value))



```





```{r attempt 1}

for (i in seq_along(goal_length$value)) {
  
  ggoals[i] <- group_goals %>% 
    slice(goal_length$goal_start[i]:goal_length$goal_end[i]) %>% 
    mutate(group = paste0(""Group"", goal_length$value[i]))
  
}


g_rows <- goal_length %>% unite(group_row, goal_start, goal_end, sep = "":"")

goal_length %>% spread(value, goal_start, goal_end)

group_goals %>% 
  slice_rows(.cols = g_rows$group_row)

group_goals %>% 
  map(1:8, ~slice(goal_length$goal_end[.x]:goal_length$goal_end[.x]))


by_slice()


1:8 %>% 
  map2(.x, group_goals, 
       ~ slice(goal_length$goal_end[.x]:goal_length$goal_end[.x]))


goalthing <- list()


for (i in seq_along(1:8)) {
  
  goalthing[i] <- group_goals %>% 
    slice(goal_length$goal_end[i]:goal_length$goal_end[i])
  
}

group_goals %>% 
  slice()


```

","2018"
"82",249,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/presentation.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 22, 2018""
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Introduction
## 
- hi, how's it going? my name is ryo nakagawara and i'm going to be talking about visualizing the world cup with R

## 1
- just a little bit about me, my background is mainly in the social sciences, specifically in psychology and economics
- and currently i work for ACDI/VOCA, which is an international development NGO
- my main intersts are soccer or football - i lived in both england and america so i swap between both terms which well, annoys everyone equally

## 2
- anyways, the agenda for today is...
- that i'm going to be talking about these 4 different types of visualizations
- this talk isn't going to be as serious as previous talks, so sit back, relax because...

## 3
""Now this is where the fun begins!"" gif

## 4
- so quick summary: the world cup is divided into 2 stages, the group stage and then the knock-out rounds
- there are 8 groups of 4 teams each, and each team plays the other once, and the top 2 teams based on 3 points for a win, 1 point for a draw, and 0 points for a loss go through!
- As you can see this is how Group D unfolded throughout the last 90 minutes of gameplay. 
- last important bit, the last 2 games of the group happen simultaneously to avoid teams colluding with eachother to go through to the next round.

- On the left, you see how the teams were ranked at the start then on the right, how the teams were at the final whistle.

- Argentina, bottom of the group at the start but still with a fighting chance to finish 2nd, absolutely needed to win
- and many Argentine prayers were answered when Messi scored in the 14th minute. 
- However, they crashed down to last place when Moses equalized but eventually made it through to the knock-out stages from a goal by Marcos Rojo!

- These graphs really capture the drama of the group stages with the hopes and dreams of the teams and their respective nations on the line!
- So let me explain in some of the most interesting bits of the code used to create these!

## 5
- the geom_flag() function that shows the wonderful flags require two-digit ISO codes as input!
- now, i can google the codes everytime and look through a list but that's annoying!
- so what's the solution? `countrycode` package! 
- all you need to do is: input the name of the countries and specify that in `origin` argument, `country.name`
- specify that you want the output to be `ISO2C` or other types in the `destination` argument
- et VOILA!
- the countrycode() function can take a lot of different inputs, ""country names in german"", ""3 digit ISO code"", ""eurostat"", ""imf""
- so basically you can do the reverse of what I just did >>> it's a very useful package!

- Next, I want to show you...

## 6
- how I displayed the text in the official world cup font, DUSHA!
- I thought having the text be in regular font was kinda boring, 
- and having seen a lot of the marketed graphics and merchandise I found and downloaded the .TFF files
- and installed them!
- Then, with the `extrafont` package, I was able to use them in R!
- Admittedly, some letters look a bit squished and are hard to see. But, overall it brings a little flavor into the titles and annotations in the plots!

## 7
- To create these I had to make a lot of labels in a lot of dataframes...

## 8
- But soon I was able to create a template of sorts, a set of label dataframes with the same general structure which I could just pass different country names, goal scorers, minute times into...

## 9
- If i had more time, i really want to brainstorm HOW to turn this into a package, but for now this ""template"" or sorts will have to do...! 
- the most difficult part of making these was that it was tough to keep track of how teams were ranked both beforean event happened and how things changed
- i did these AFTER the matches finished, so i had to do a lot of backtracking and figuring out which teams were ranked where, at a number of specific times, across 2 different games.

- Going back to the actual plots... 

## 10
we can see that some groups are full of excitement!! 
- Iran just needed one more goal after scoring in the 93rd minute, to leapfrog Portugal and take 2nd place! It was a really exciting end to the game!

## 11
- others... like Group C... were not! after matchday 2, France was 100% through, Denmark just needed to draw their game. 
- But even here, Australia could still have qualified if Denmark lost and they had won!

That's part of the fun, you never really know what's going to happen!

Now let's go on to...

## 12
- Recreating the goals of the World Cup!

- For doing these, I primarily used the `ggsoccer` package by Ben Torvaney which is used with `ggplot2` to draw a soccer field / football pitch in R!
- Basically, `annotate_pitch()` creates the markings for the soccer field such as the center circle, 18-yard box, penalty spot, etc. while `theme_pitch()` erases the extraneous axes and background stuff from the default ggplot style.
- By using the limits arguments in the different `coord_*()` functions, like coord_fixed , coord_cartesian ... here I used `coord_flip()` 
- so that I can focus on a certain area of the pitch and orient it in a way that I want.

## 13 
- So, I'm sure you are all wondering, where did I find the data points for the players, the ball, etc.?
- Well, those that are soccer fans know about sports analytics companies, most notably Opta, that generate a huge amount of data for every player for every match, but the thing is it's not easy for a regular guy like me to buy it!

- If you've been following the World Cup on Twitter you might have seen some great viz by the Financial Times, FiveThirtyEight, the BBC, etc. who got data from Opta, there was also this other guy that scraped a data dashboard from a soccer data website (that in fact, create their viz from purchased data from Opta) with __RSelenium__ or some other JS scrapers.
- but I could do neither of those things so I resorted to creating the coordinate positions by hand. 

## 14
- Thankfully, due to the plotting system in `ggsoccer` and `ggplot2`, it's very easy to figure out the positions on the soccer field plot and with a little bit of practice it doesn't take too much time.

Here is a small part of what some of the dataframes look like with all the coordinate points stored for different parts of the plot.

## 15
and here's an example of the ggplot2 code:
- after creating the soccer field layout i then plot a lot of segments and curves using the respective geoms to plot out the movement of the players and the ball!

## 16
- so here was my first try, Gazinsky scoring the first goal of the World Cup!

## 17
- and here is another, Cristiano scoring a hat trick in what was probably one of the games of the tournament!

## 18
- So, I wanted to talk about how I got the flags into the title for this previous plot.
- I basically put a lot of spaces between the country name and the score in the annotation code, and then I specified the coordinates for the flags to appear in that empty space in the title!
- Yes! It's okay, you can laugh. It is a terrible hack but it works!

## 19
- and for all the Japanese people in the audience, I also recreated Osako's winner against Colombia!


OK... now these are cool but soccer is a moving - flowing game! It's not enough to just show static images, it just doesn't capture the feel of the sport!
So, the next step was to try and animate these images using gganimate and tweenr!

## 21
here is the gganimate version of Gazinsky's goal...

- basically you have to add some kind of time variable in your data that keeps track of the WHEN of your data points.
- then you have to specify that time variable in the `frame` argument of the geom you want animated
- but as you saw, the animation was very choppy and it didn't really look like soccer at all
- we can do better than this by making everything run... smooother!

- and this is where tweenr comes in. 

## 23
For those of you that aren't familiar, tweenr allows you to interpolate data between different states and specify other aspects like the easing of the transition. 

## 24
Now let's check out Osako's goal vs. colombia!


and here's another one
## 25 
Japan's offside trap against Senegal!

against the height and physicality of Senegal, Japan's strategy was basically ...

## 26
- you can't lose the aerial battle, if you set an offside trap!

and yes, this internet meme was created in R too! ... 


Anyways, let's get back on topic...

the LAST thing I wanted to show you was ...

## 27
- animating national team uniforms!

- about a month ago, Guy Abel created this really cool blog post on animating soccer uniforms with R
- what he did was that he downloaded uniforms from a website and then used the `magick` package to animate the transitions
- the thing that got to me was, that to use all these uniform graphics Guy used this website called `historicalkits.co.uk`  which is a website I've been using since I was a little kid, so when I saw the blog post I was like
- HEY - WHY DIDNT I THINK OF DOING THIS??

## 28
- so with the help of Guy's awesome code I went to work, and obviously I didn't want to copy exactly what he did but instead with Japan's uniforms
- so I went ahead and combined Japan's uniforms with those of their opponents in each of the games, in each of the world cups
- to create a historical slideshow showing all of Japan's World Cup games!

## 29
20~30 seconds?

So I want to finish up by some comments on making these...

## 30
- There is definintly room for improvement for these, but I already put a lot of work during my free time, 
- free time which was already limited by the fact that most of it was spent actually watching and enjoying the games!
- even still it was a a great way to challenge my R skills in so many different ways
- and i think if you want to get better at R, you should test yourself by working on topics and subjects that you truly love

## 31
all right, that's all from me so thank you for listening!
and i hope that maybe i've got some of you interested in soccer!

unfortunately, after the final tonight, you're going to have to wait another 4 years for the next one!!

","2018"
"83",250,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/soccer_plots_part4.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""July 18, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```











## Shots on Goal: On + Off Target

```{r shots on goal}

```


## Formation and line-ups

make function for set formations 
- all you need to do is pass player names and formation string (""3-5-2"", ""4-4-2"", etc.)
- later version: player icon with uniform (like in Wikipedia)

```{r formations}

```



## VAR Decisions

```{r var }

```







","2018"
"84",251,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/worldcup_goal_plots.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 20, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Recreate & Animate Your Favorite World Cup Goals!




## example points


```{r echo=FALSE, fig.width=8, fig.height=5}
library(ggsoccer)
library(ggplot2)

point_data <- data.frame(x = c( 100, 83, 100, 83, 88.5, 100,  83, 83, 100, 100),
                         y = c(   0, 21,  21, 38, 50,    50,  62, 80,  80, 100),
                         label = c(""100, 0"", ""83, 21"", ""100, 21"", ""83, 38"", ""88.5, 50"", 
                                   ""100, 50"", ""83, 62"", ""83, 80"", ""100, 80"", ""100, 100""))

field <- ggplot(point_data) +
  annotate_pitch() +
  theme_pitch(aspect_ratio = NULL) +
  coord_flip() +
  geom_point(aes(x = x, y = y), size = 1.5) +
  geom_text(aes(x= x, y = y,
                label = label),
            vjust = 1.5, color = ""red"")
ggsave(field, filename = ""field.png"", width = 8, height = 5)
```





## Gazinsky: First Goal!

```{r first goal, fig.height=6, fig.width=8}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
# loadfonts()

#                              2   1  
pass_data <- data.frame(x = c( 84, 82, 94),
                        y = c(  6, 32, 35),
                        x2 = c(77, 84, 83),
                        y2 = c(13, 8 , 32.5))

#                            corner kick + golovin cross
curve_data <- data.frame(x = c(100, 76),
                         y = c(0, 19),
                         x2 = c(94, 94),
                         y2 = c(35, 60))

# Gazinsky header
ball_data <- data.frame(x = c(94),
                        y = c(60),
                        x2 = c(99.2),
                        y2 = c(47.5))

# soccer ball image
goal_img <- data.frame(x = 100,
                       y = 47) %>% 
  mutate(image = ""https://d30y9cdsu7xlg0.cloudfront.net/png/43563-200.png"")

# golovin + zhirkov movement
movement_data <- data.frame(x = c(83, 98),
                           y = c(24.25, 2),
                           x2 = c(77, 88),
                           y2 = c(21, 6))

saudi_data <- data.frame(
  x = c(96.5),
  y = c(35),
  label = ""M. Al-Breik""
)

g <- ggplot(pass_data) +
  annotate_pitch() +
  geom_segment(aes(x = x, y = y, xend = x2, yend = y2),
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(data = ball_data,
               aes(x = x, y = y, xend = x2, yend = y2), 
               linetype = ""dashed"", size = 0.85,
               color = ""red"") +
  geom_segment(data = movement_data,
               aes(x = x, y = y, xend = x2, yend = y2), 
               linetype = ""dashed"", size = 1.2,
               color = ""black"") +
  geom_curve(data = curve_data, 
             aes(x = x, y = y, xend = x2, yend = y2), 
             curvature = 0.25, 
             arrow = arrow(length = unit(0.25, ""cm""),
                           type = ""closed"")) +
  geom_image(data = goal_img,
             aes(x = x, y = y,
                 image = image), 
             size = 0.035) +
  theme_pitch() + 
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  geom_label(aes(x = 94, y = 60, 
                 label = ""Gazinsky""), 
             hjust = -0.1, color = ""red"", family = ""Dusha V5"") +
  geom_label(aes(x = 83, y = 23, 
                 label = ""Golovin""), 
             hjust = -0.05, color = ""red"", family = ""Dusha V5"") +
  geom_label(aes(x = 75, y = 11, 
                 label = ""Golovin""), 
             hjust = -0.1, color = ""red"", family = ""Dusha V5"") +
  geom_label(aes(x = 98, y = 0, 
                 label = ""Zhirkov""), 
             vjust = -0.3, color = ""red"", family = ""Dusha V5"") +
  geom_label(aes(x = 84, y = 6, 
                 label = ""Zhirkov""), 
             vjust = -0.3, color = ""red"", family = ""Dusha V5"") +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"", family = ""Dusha V5"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"")

ggsave(g, filename = ""gazinsky_goal.png"", height = 6, width = 8)
```



### Gazinsky animate


```{r complete gazinsky gganimate, fig.width=8, fig.height=6}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
library(gganimate)
# loadfonts()

# data
pass_data <- data.frame(
  x = c(100, 94, 82, 82.5,  84, 76.5, 75.5, 94, 99.2),       # pass balls
  y = c(0,   35, 31, 22,     8, 13, 19, 60, 47.5),
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

golovin_movement <- data.frame(
  x = c(78, 80, 80, 80, 75.5, 74.5, 73.5, 73, 73),   #75, 74, 73
  y = c(30, 30, 27, 25,   10,    9, 15, 15, 15),
  label = ""Golovin"",
  time = c(1, 2, 3,  4,  5,  6,  7,  8,  9)
)

zhirkov_movement <- data.frame(
  x = c(98, 90, 84, 84, 84, 84, 84, 84, 84),
  y = c( 0,  2,  2,  2,  2,  2,  2,  2,  2),
  label = ""Zhirkov"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

gazinsky_movement <- data.frame(
  x = c(92),
  y = c(66.8),
  label = ""Gazinsky"",
  time = c(6, 7, 8, 9)
)

# segment golovin should only appear 4-5?
# segment zhirkov should only appear 1-3?
segment_data <- data.frame(
  x = c(77.5, 98),
  y = c(22, 2),
  xend = c(75, 84),
  yend = c(15, 3),
  linetype = c(""dashed"", ""dashed""),
  color = c(""black"", ""black""),
  size = c(1.2, 1.25)
)

saudi_data <- data.frame(
  x = c(95),
  y = c(35),
  label = ""M. Al-Breik""
)

### soccer ball
ball_data <- tribble(
  ~x,  ~y, ~time,
  100,   0,   1,
  94,   35,   2,
  82,   31,   3,
  82.5, 25,   4,
  84,    6,   5, 
  77,   13,   6,
  76,   19,   7,
  94,   60,   8,
  99.2, 47.5, 9,
  
) 


gazin_ani <- ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(data = segment_data, 
               aes(x = x, y = y, 
                   xend = xend, yend = yend),
               size = segment_data$size,
               color = segment_data$color,
               linetype = c(""dashed"", ""dashed"")) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(data = zhirkov_movement,
    aes(x = x, y = y,
        frame = time,
        label = label),
    color = ""red"") +
  geom_label(data = golovin_movement,
    aes(x = x, y = y,
        frame = time,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  ggimage::geom_emoji(
    data = ball_data,
    aes(x = x, y = y, frame = time),   
    image = ""26bd"", size = 0.035) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5""))

gganimate(gazin_ani, 
          width = 8, height = 6, 
          title_frame = FALSE,  
          ""gazin_ggani_final.gif"")


```




```{r complete gazinskiy tweenr, fig.width=8, fig.height=6}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
library(gganimate)
library(tweenr)
library(purrr)
# loadfonts()

# data
pass_data <- data.frame(
  x = c(100, 94, 82, 82.5,  84, 76.5, 75.5, 94, 99.2),       # pass balls
  y = c(0,   35, 31, 22,     8, 13, 19, 60, 47.5),
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

golovin_movement <- data.frame(
  x = c(78, 80, 80, 80, 75.5, 74.5, 73.5, 73, 73),   #75, 74, 73
  y = c(30, 30, 27, 25,   10,    9, 15, 15, 15),
  label = ""Golovin"",
  time = c(1, 2, 3,  4,  5,  6,  7,  8,  9)
)

zhirkov_movement <- data.frame(
  x = c(98, 90, 84, 84, 84, 84, 84, 84, 84),
  y = c( 0,  2,  2,  2,  2,  2,  2,  2,  2),
  label = ""Zhirkov"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

gazinsky_movement <- data.frame(
  x = c(92),
  y = c(66.8),
  label = ""Gazinsky"",
  time = c(6, 7, 8, 9)
)

# saudi defender
saudi_data <- data.frame(
  x = c(95),
  y = c(35),
  label = ""M. Al-Breik""
)

### soccer ball
ball_data <- tribble(
  ~x,  ~y, ~time,
  100,   0,   1,
  94,   35,   2,
  82,   31,   3,
  82.5, 25,   4,
  84,    6,   5, 
  77,   13,   6,
  76,   19,   7,
  94,   60,   8,
  99.2, 47.5, 9,
  
) 

### ball movement
b_list <- ball_data %>% pmap(data.frame)

ball_tween <- b_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

### Golovin

golovin_movement_list <- golovin_movement %>% pmap(data.frame)
  
golovin_tween <- golovin_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

golovin_tween <- golovin_tween %>% mutate(label = ""Golovin"")

### Zhirkov
zhirkov_movement_list <- zhirkov_movement %>% pmap(data.frame)
  
zhirkov_tween <- zhirkov_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

zhirkov_tween <- zhirkov_tween %>% mutate(label = ""Zhirkov"")

### PLOT

gazin_move <- ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_label(
    data = saudi_data,
    aes(x = x, y = y,
        label = label),
    color = ""darkgreen"") +
  geom_label(data = zhirkov_tween,
    aes(x = x, y = y,
        frame = .frame,
        label = label),
    color = ""red"") +
  geom_label(data = golovin_tween,
    aes(x = x, y = y,
        frame = .frame,
        label = label),
    color = ""red"") +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label),
    color = ""red"") +
  ggimage::geom_emoji(
    data = ball_tween,
    aes(x = x, y = y, frame = .frame),   
    image = ""26bd"", size = 0.035) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"") +
  theme(text = element_text(family = ""Dusha V5""))

gganimate(gazin_move, 
          width = 8, height = 6, 
          title_frame = FALSE, interval = 0.25, 
          ""gazinsky_goal_final.gif"")

gganimate(gazin_move, 
          width = 8, height = 6, 
          title_frame = FALSE, interval = 0.25, 
          ""gazin_move.mp4"")

```









## Cristiano Hat Trick

NOTE: you need to play around with the margins in `theme()` and the `width` or `height` arguments in `ggsave()` to remove the extraneous white space that appears.

```{r cristiano hat trick, fig.height=5, fig.width=7}
library(ggplot2)
library(ggsoccer)
library(extrafont)
library(emoGG)
library(ggimage)
# loadfonts()
# Official WC 2018 Font: ""Dusha""
# http://fifa2018wiki.com/fifa-2018-font-typeface-download-dusha-font-ttf/509/

emoji_search(""soccer"")  # ""26bd""

goals_data <- data.frame(x = c(88, 80, 71),
                         y = c(50, 48, 54),
                         label = c(1, 2, 3))

curve_data <- data.frame(x = c(88, 71), y = c(50, 54),
                         xend = c(100, 100), yend = c(54, 54))

annotation_data <- data.frame(
  hjust = c(0.5, 0.5, 0.5, 0, 0, 0),
  label = c(""Portugal             (3) vs. Spain             (3)"",
            ""Cristiano's Hattrick (4', 44', 88')"",
            ""by Ryo Nakagawara (@R_by_Ryo)"",
            ""1. Fouled by Nacho in the box,\nCristiano confidently strokes the ball\ninto the right corner from the spot."",
            ""2. Guedes lays it off to Cristiano whose\nstrong shot is uncharacteristically\nfumbled by De Gea into the net."",
            ""In the final minutes of the game,\nCristiano wins a freekick against Pique\nand curls it beautifully over the wall.""),
  x = c(110, 105, 53, 76, 66, 66), 
  y = c(30, 20, 85, 5, 5, 55)
)

flag_data <- data.frame(
  image = c(""PT"", ""ES""),
  x = c(110, 110),
  y = c(19.1, 51.1)
)

# PLOT

cr <- ggplot(goals_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5""),
        legend.position = ""none"") +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_segment(x = 80, y = 48, 
               xend = 97, yend = 48) +  # 2nd 
  geom_segment(x = 97, y = 48, 
               xend = 100, yend = 45.5,
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +        # degea fumble
  geom_curve(data = curve_data,
             aes(x = x, y = y, 
                 xend = xend, yend = yend),     # FREEKICK
             curvature = 0.3, 
             arrow = arrow(length = unit(0.25, ""cm""), type = ""closed"")) +
  geom_text(data = annotation_data,
            family = ""Dusha V5"", 
            aes(x = x, y = y,
                hjust = hjust, label = label),
            size = c(6.5, 4.5, 3, 3.5, 3.5, 3.5)) +
  geom_flag(data = flag_data,
            aes(x = x, y = y,
                image = image), size = c(0.08, 0.08)) +       # Portugal + Spain Flag
  ggimage::geom_emoji(aes(x = 105, 
                 y = c(45, 50, 55)),
             image = ""26bd"", size = 0.035) +
  geom_point(aes(x = x, y = y), 
             shape = 21, size = 7, color = ""black"", fill = ""white"") +
  geom_text(aes(x = x, y = y, label = label, family = ""Dusha V5""))

ggsave(cr, filename = ""cr_hattrick.png"", height = 5, width = 7)
```


## Osako's Winner against Colombia!


```{r osako winner, fig.height = 5, fig.width = 7}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(extrafont)
library(ggimage)


cornerkick_data <- data.frame(x = 99, y = 0.3,
                              x2 = 94, y2 = 47)

osako_gol <- data.frame(x = 94, y = 49,
                        x2 = 100, y2 = 55.5)

player_label <- data.frame(x = c(92, 99), 
                           y = c(49, 2))

wc_logo <- data.frame(x = 107,
                       y = 85) %>% 
  mutate(image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")


g <- ggplot(osako_gol) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_curve(data = cornerkick_data,
             aes(x = x, y = y, xend = x2, yend = y2),
             curvature = -0.15, 
             arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_segment(aes(x = x, y = y, xend = x2, yend = y2),
               arrow = arrow(length = unit(0.25, ""cm""),
                             type = ""closed"")) +
  geom_label(data = player_label, 
             aes(x = x, y = y),
             label = c(""Osako"", ""Honda""), family = ""Dusha V5"") +
  geom_point(aes(x = 98, y = 50), size = 3, color = ""green"") +
  geom_text(aes(x = 99.7, y = 50), size = 5, label = ""???"", family = ""Dusha V5"") +
  annotate(geom = ""text"", family = ""Dusha V5"", 
           hjust = c(0.5, 0.5, 0.5, 0.5, 0.5),
           size = c(6.5, 4.5, 4, 3.5, 3),
           label = c(""Japan             (2) vs. Colombia             (1)"",
                     ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
                     ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
                     ""Bonus: Ospina looking confused and\ndoing a lil' two-step-or-god-knows-what."",
                     ""by Ryo Nakagawara (@R_by_Ryo)""),
           x = c(110, 105, 70, 92, 53), 
           y = c(30, 30, 45, 81, 85)) +
  ggimage::geom_flag(aes(image = ""JP""),       # Japan Flag
            x = 110, y = 13, size = 0.08) +
  ggimage::geom_flag(aes(image = ""CO""),       # Colombia Flag
            x = 110, y = 53, size = 0.08) +
  ggimage::geom_emoji(aes(x = 95, 
                          y = 50),
             image = ""26bd"", size = 0.035) +
  geom_image(data = wc_logo,
             aes(x = x, y = y,
                 image = image), size = 0.17) +
  theme(plot.margin=grid::unit(c(0,0,0,0), ""mm""))
  
ggsave(g, filename = ""osako_winner.png"", height = 5, width = 7)
```

## Animated version:

```{r osako anim}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(extrafont)
library(emoGG)
library(ggimage)
library(gganimate)


ball_data <- data.frame(x = c(99, 94, 100),
                        y = c(0.3, 47, 55.5),
                        time = c(1, 2, 3))

player_label <- data.frame(x = c(92, 97), 
                           y = c(48, 0))

wc_logo <- data.frame(x = 107,
                       y = 85) %>% 
  mutate(image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")


g <- ggplot(ball_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_label(data = player_label, 
             aes(x = x, y = y),
             label = c(""Osako"", ""Honda""), family = ""Dusha V5"") +
  geom_point(aes(x = 98, y = 50), size = 3, color = ""green"") +
  geom_text(aes(x = 99.7, y = 50), size = 5, label = ""???"", family = ""Dusha V5"") +
  annotate(geom = ""text"", family = ""Dusha V5"", 
           hjust = c(0.5, 0.5, 0.5, 0.5, 0.5),
           size = c(6.5, 4.5, 4, 3.5, 3),
           label = c(""Japan             (2) vs. Colombia             (1)"",
                     ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
                     ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
                     ""Bonus: Ospina looking confused and\ndoing a lil' two-step-or-god-knows-what."",
                     ""by Ryo Nakagawara (@R_by_Ryo)""),
           x = c(110, 105, 70, 92, 53), 
           y = c(30, 30, 45, 81, 85)) +
  ggimage::geom_flag(aes(image = ""JP""),       # Japan Flag
            x = 110, y = 13, size = 0.08) +
  ggimage::geom_flag(aes(image = ""CO""),       # Colombia Flag
            x = 110, y = 53, size = 0.08) +
  ggimage::geom_emoji(aes(x = x, 
                          y = y,
                          frame = time),
             image = ""26bd"", size = 0.035) +
  geom_image(data = wc_logo,
             aes(x = x, y = y,
                 image = image), size = 0.17) +
  theme(plot.margin=grid::unit(c(0,0,0,0), ""mm""))

g

gganimate(g, ""osako_ani.gif"") 

```

```{r osako tween, fig.height = 5, fig.width = 7}
# TWEEN
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(extrafont)
library(emoGG)
library(ggimage)
library(gganimate)
library(purrr)
library(tweenr)

player_label <- data.frame(x = c(92, 97), 
                           y = c(48, 0))

wc_logo <- data.frame(x = 107,
                       y = 85) %>% 
  mutate(image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")

# tweenr the ball movement data
ball_data <- data.frame(x = c(99, 94, 100),
                        y = c(0.3, 47, 55.5))

ball_list <- ball_data %>% pmap(data.frame)
  
osako_tween <- ball_list %>% 
  tween_states(tweenlength = 1.5, statelength = 0.01, ease = ""quadratic-out"", nframes = 50)

g2 <- ggplot(osako_tween) +
  annotate_pitch() +
  theme_pitch() +
  theme(text = element_text(family = ""Dusha V5"")) +
  coord_flip(xlim = c(55, 112),
             ylim = c(-1, 101)) +
  geom_label(data = player_label, 
             aes(x = x, y = y),
             label = c(""Osako"", ""Honda""), family = ""Dusha V5"") +
  geom_point(aes(x = 98, y = 50), size = 3, color = ""green"") +
  annotate(geom = ""text"", family = ""Dusha V5"", 
           hjust = c(0.5, 0.5, 0.5, 0.5),
           size = c(6.5, 4.5, 5, 3),
           label = c(""Japan             (2) vs. Colombia             (1)"",
                     ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
                     ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
                     ""by Ryo Nakagawara (@R_by_Ryo)""),
           x = c(110, 105, 70, 53), 
           y = c(30, 30, 47, 85)) +
  ggimage::geom_emoji(aes(x = x, 
                          y = y,
                          frame = .frame),
             image = ""26bd"", size = 0.035) +
  ggimage::geom_flag(aes(image = ""JP""),       # Japan Flag
            x = 110, y = 13, size = 0.08) +
  ggimage::geom_flag(aes(image = ""CO""),       # Colombia Flag
            x = 110, y = 53, size = 0.08) +
  geom_image(data = wc_logo,
             aes(x = x, y = y,
                 image = image), size = 0.17) +
  theme(plot.margin=grid::unit(c(0,0,0,0), ""mm""))

g2

gganimate(g2, 
          ani.width = 800, ani.height = 500, 
          interval = 0.5,
          ""osako_tween.gif"") 

gganimate(g2, title_frame = FALSE,
          width = 700, height = 500, 
          interval = 0.01,
          ""osako_tween_final.gif"") 

```

## Japan's Offside Trap!

```{r offside data, fig.height=6, fig.width=4}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
library(gganimate)
library(tweenr)
library(purrr)
library(countrycode)
# library(StatsBombR)
# loadfonts()

# flags
flag_data <- data.frame(
  x = c( 48, 87),
  y = c(107, 107),
  team = c(""japan"", ""senegal"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)

# PLAYERS
# JAPAN: x, y (blue)     Senegal: x2, y2  (lightgreen)
# push 2, 3 frames up above box >>> add 5, 6 as frames??
trap_data <- data.frame(
  
  time = c(1, 2, 3, 4, 5),
  
  # ball trajectory
  x = c(70, 70, 70, 87, 95),       # pass balls
  y = c(85, 85, 85, 52, 33),
  
  # offside bar
  #xo =    c(83, 81.2, 79, 77.5, 70),
  xoend = c(83.8, 81.8, 79, 78.5, 71),
  
  yo =    c( 5,  5,  5,  5, 5),
  yoend = c(95, 95, 95, 95, 95),
  
  # players: japan
  jx  = c(83, 81, 77, 75, 70),
  jy  = c(rep(65, 5)),
  
  jx2 = c(83, 81.8, 78.5, 77, 70),
  jy2 = c(rep(60.5, 5)),
  
  jx3 = c(83, 81, 76.5, 75, 71),
  jy3 = c(rep(55, 5)),
  
  jx4 = c(83, 81.2, 76.3, 75, 70),
  jy4 = c(rep(52, 5)),
  
  jx5 = c(82.8, 81, 77, 74, 70),
  jy5 = c(rep(49, 5)),
  
  jx6 = c(83, 81.8, 77, 74, 70),
  jy6 = c(rep(45, 5)),

  jx7 = c(83.8, 81, 79, 77.5, 70),
  jy7 = c(rep(40, 5)),
  
  # players: senegal
  sx = c(83, 84, 84, 84, 84),
  sy = c(rep(33, 5)),
  
  sx2 = c(83, 85, 87, 92, 95),
  sy2 = c(38, 37, 35, 34, 33),
  
  sx3 = c(83, 84, 84, 83, 83),
  sy3 = c(rep(41, 5)),
  
  sx4 = c(83, 84, 83, 78, 78),
  sy4 = c(rep(45, 5)),
  
  sx5 = c(83, 84, 87, 88, 89),
  sy5 = c(rep(52, 5)),
  
  sx6 = c(83, 85, 84, 84, 83),
  sy6 = c(rep(69, 5))
)

# fix focus field issue with coord_fixed() + aspect_ratio = NULL in theme_pitch()
g <- ggplot(trap_data) +
  annotate_pitch() +
  theme_pitch(aspect_ratio = NULL) +
  coord_fixed(xlim = c(30, 101),
       ylim = c(-5, 131)) +
  # offside line
  geom_segment(aes(x = xoend, y = yo, 
                   xend = xoend, yend = yoend,
                   frame = time), 
               color = ""black"", size = 1.3) +
  # start at 83      just use geom_segment instead
  # japan
  geom_point(aes(x = jx, y = jy, frame = time), size = 4, color = ""blue"") +
  geom_point(aes(x = jx2, y = jy2, frame = time), size = 4, color = ""blue"") +
  geom_point(aes(x = jx3, y = jy3, frame = time), size = 4, color = ""blue"") +
  geom_point(aes(x = jx4, y = jy4, frame = time), size = 4, color = ""blue"") +
  geom_point(aes(x = jx5, y = jy5, frame = time), size = 4, color = ""blue"") +
  geom_point(aes(x = jx6, y = jy6, frame = time), size = 4, color = ""blue"") +
  geom_point(aes(x = jx7, y = jy7, frame = time), size = 4, color = ""blue"") +
  # senegal
  geom_point(aes(x = sx, y = sy, frame = time), size = 4, color = ""green"") +
  geom_point(aes(x = sx2, y = sy2, frame = time), size = 4, color = ""green"") +
  geom_point(aes(x = sx3, y = sy3, frame = time), size = 4, color = ""green"") +
  geom_point(aes(x = sx4, y = sy4, frame = time), size = 4, color = ""green"") +
  geom_point(aes(x = sx5, y = sy5, frame = time), size = 4, color = ""green"") +
  geom_point(aes(x = sx6, y = sy6, frame = time), size = 4, color = ""green"") +
  
  # free kick spot (reference)
  geom_point(aes(x = 70, y = 85), color = ""blue"", size = 1.2) +
  annotate(geom = ""text"", family = ""Dusha V5"", 
           hjust = c(0, 0, 0, 0.5),
           size = c(4.5, 3, 5.5, 3),
           label = c(""Japan             (2) vs. Senegal             (2)"",
                     ""Mane (11'), Inui (33'), Wague (71'), Honda (78')"",
                     ""The Perfect Offside Trap"",
                     ""by Ryo Nakagawara\n(@R_by_Ryo)""),
           x = c(30, 30, 30, 94), 
           y = c(117, 108, 125, -3)) +
  ggimage::geom_flag(data = flag_data,
                     aes(x = x, y = y,
                         image = image),       
                     size = c(0.08, 0.08)) +
  ggimage::geom_emoji(aes(x = x, y = y, 
                          frame = time),
                      image = ""26bd"", size = 0.035)

g


```

```{r offside gganimate, fig.height=6, fig.width=4}
# vline for offside line
# x1 Ja, x2 Sen
# sligh twiggle before kick? 
# goalkeeper position

gganimate(g, ""g_ani.gif"")

```


```{r tweenr offside final, fig.height=10, fig.width=8}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
library(gganimate)
library(tweenr)
library(purrr)
library(countrycode)
# library(StatsBombR)
# loadfonts()

# PLAYERS
# JAPAN: x, y (blue)     Senegal: x2, y2  (lightgreen)
trap_data <- data.frame(
  
  time = c(1, 2, 3, 4, 5),
  
  # ball trajectory
  x = c(70, 70, 70, 87, 95),       # pass balls
  y = c(85, 85, 85, 52, 33),
  
  # offside bar
  #xo =    c(83, 81.2, 79, 77.5, 70),
  xoend = c(83.8, 81.8, 79, 78.5, 71),
  
  yo =    c( 5,  5,  5,  5, 5),
  yoend = c(95, 95, 95, 95, 95),
  
  # players: japan
  jx  = c(83, 81, 77, 75, 70),
  jy  = c(rep(65, 5)),
  
  jx2 = c(83, 81.8, 78.5, 77, 70),
  jy2 = c(rep(60.5, 5)),
  
  jx3 = c(83, 81, 76.5, 75, 71),
  jy3 = c(rep(55, 5)),
  
  jx4 = c(83, 81.2, 76.3, 75, 70),
  jy4 = c(rep(52, 5)),
  
  jx5 = c(82.8, 81, 77, 74, 70),
  jy5 = c(rep(49, 5)),
  
  jx6 = c(83, 81.8, 77, 74, 70),
  jy6 = c(rep(45, 5)),

  jx7 = c(83.8, 81, 79, 77.5, 70),
  jy7 = c(rep(40, 5)),
  
  # players: senegal
  sx = c(83, 84, 84, 84, 84),
  sy = c(rep(33, 5)),
  
  sx2 = c(83, 85, 87, 92, 95),
  sy2 = c(38, 37, 35, 34, 33),
  
  sx3 = c(83, 84, 84, 83, 83),
  sy3 = c(rep(41, 5)),
  
  sx4 = c(83, 84, 83, 78, 78),
  sy4 = c(rep(45, 5)),
  
  sx5 = c(83, 84, 87, 88, 89),
  sy5 = c(rep(52, 5)),
  
  sx6 = c(83, 85, 84, 84, 83),
  sy6 = c(rep(69, 5))
)


# flags
flag_data <- data.frame(
  x = c( 42, 72),
  y = c(107, 107),
  team = c(""japan"", ""senegal"")
  ) %>% 
  mutate(
    image = team %>% 
           countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)

# extra players:
goalkeeper_data <- data.frame(
  
  x = c(98),
  y = c(50)
  
)

senegal_data <- data.frame(
  
  x = c(55, 55, 68.5),
  y = c(50, 60, 87)
  
)



# create list of dfs
offside_list <- trap_data %>% pmap(data.frame)
  
# tweenr
offside_tween <- offside_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 50)

# PLOT

g2 <- ggplot(offside_tween) +
  annotate_pitch() +
  theme_pitch(aspect_ratio = NULL) +
  coord_fixed(xlim = c(30, 101),
              ylim = c(-5, 117)) +
  # offside line
  geom_segment(aes(x = xoend, y = yo, 
                   xend = xoend, yend = yoend,
                   frame = .frame), 
               color = ""black"", size = 1.3) +
  # start at 83      just use geom_segment instead
  # japan
  geom_point(aes(x = jx, y = jy, frame = .frame), size = 4, color = ""blue"") +
  geom_point(aes(x = jx2, y = jy2, frame = .frame), size = 4, color = ""blue"") +
  geom_point(aes(x = jx3, y = jy3, frame = .frame), size = 4, color = ""blue"") +
  geom_point(aes(x = jx4, y = jy4, frame = .frame), size = 4, color = ""blue"") +
  geom_point(aes(x = jx5, y = jy5, frame = .frame), size = 4, color = ""blue"") +
  geom_point(aes(x = jx6, y = jy6, frame = .frame), size = 4, color = ""blue"") +
  geom_point(aes(x = jx7, y = jy7, frame = .frame), size = 4, color = ""blue"") +
  # senegal
  geom_point(aes(x = sx, y = sy, frame = .frame), size = 4, color = ""green"") +
  geom_point(aes(x = sx2, y = sy2, frame = .frame), size = 4, color = ""green"") +
  geom_point(aes(x = sx3, y = sy3, frame = .frame), size = 4, color = ""green"") +
  geom_point(aes(x = sx4, y = sy4, frame = .frame), size = 4, color = ""green"") +
  geom_point(aes(x = sx5, y = sy5, frame = .frame), size = 4, color = ""green"") +
  geom_point(aes(x = sx6, y = sy6, frame = .frame), size = 4, color = ""green"") +
  
  # free kick spot (reference)
  geom_point(aes(x = 70, y = 85), color = ""black"", size = 1.2) +
  # goalkeeper
  geom_point(data = goalkeeper_data,
             aes(x = x, y = y), size = 4, color = ""blue"") +
  # senegal defenders
  geom_point(data = senegal_data,
             aes(x = x, y = y), size = 4, color = ""green"") +
  annotate(
    geom = ""text"", family = ""Dusha V5"", 
    hjust = c(0, 0, 0.5),
    size = c(6, 6.5, 3),
    label = c(""Japan             (2) vs. Senegal             (2)"",
              ""The Perfect Offside Trap"",
              ""by Ryo Nakagawara\n(@R_by_Ryo)""),
    x = c(30,  30, 94), 
    y = c(107, 115, -3)) +
  ggimage::geom_flag(data = flag_data,
                     aes(x = c(48, 90), y = c(107, 107),
                         image = image),       
                     size = c(0.07, 0.07)) +
  ggimage::geom_emoji(aes(x = x, y = y, 
                          frame = .frame),
                      image = ""26bd"", size = 0.035)

gganimate(g2, 
          interval = 0.001, height = 10, width = 8,
          ""offside_final.gif"", 
          title_frame = FALSE) 

```






+ the meme generator with R

```{r meme}
library(memery)
img <- (""https://imgflip.com/s/meme/Roll-Safe-Think-About-It.jpg"")

meme_labs <- c(""you can't lose the aerial battle"", ""if you set an offside trap"")

meme(img, meme_labs, ""offside_meme.png"")

```

","2018"
"85",252,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/worldcup_goal_plots_DRAFT.rmd","---
title: ""worldcup_goal_plots_DRAFT""
author: ""RN7""
date: ""July 13, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Gazinsky ani data}
library(ggplot2)
library(dplyr)
library(ggsoccer)
library(ggimage)
library(extrafont)
library(gganimate)
library(tweenr)
# loadfonts()

# data
pass_data <- data.frame(
  x = c(100, 94, 82, 82.5,  84, 76.5, 75.5, 94, 99.2),       # pass balls
  y = c(0,   35, 31, 22,     8, 13, 19, 60, 47.5),
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9))

golovin_movement <- data.frame(
  x = c(78, 80, 80, 80, 75.5, 74.5, 73.5, 73, 73),   #75, 74, 73
  y = c(30, 30, 27, 25,   10,    9, 15, 15, 15),
  label = ""Golovin"",
  time = c(1, 2, 3,  4,  5,  6,  7,  8,  9)
)

zhirkov_movement <- data.frame(
  x = c(98, 90, 84, 84, 84, 84, 84, 84, 84),
  y = c( 0,  2,  2,  2,  2,  2,  2,  2,  2),
  label = ""Zhirkov"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

gazinsky_movement <- data.frame(
  x = c(90.8),
  y = c(69),
  label = ""Gazinsky"",
  time = c(6, 7, 8, 9)
)

# segment golovin should only appear 4-5
# segment zhirkov should only appear 1-3
segment_data <- data.frame(
  x = c(77.5, 98),
  y = c(22, 2),
  xend = c(75, 84),
  yend = c(15, 3),
  linetype = c(""dashed"", ""dashed""),
  color = c(""darkgreen"", ""darkgreen""),
  size = c(1.2, 1.25)
)

saudi_data <- data.frame(
  x = c(95),
  y = c(35)
)

data <- tribble(
  ~x,  ~y,  ~label, ~time,
  100,  0,  ""ball"",     1,
   98,  0, ""Golovin"",   1,
   98,  0, ""Zhirkov"",   1,
   94, 35, ""ball"",      2,
   80, 30, ""Golovin"",   2,
   90,  2, ""Zhirkov"",   2,
   82, 31, ""ball"",      3,
   80, 25, ""Golovin"",   3,
   82,  3, ""Zhirkov"",   3, 
   82.5, 25, ""ball"",    4,
   80, 20, ""Golovin"",   4, 
   82,  3, ""Zhirkov"",   4,
   84,  6, ""ball"",      5, 
   75, 10, ""Golovin"",   5,
   82,  3, ""Zhirkov"",   5, 
   77, 13, ""ball"",      6,
   74,  9, ""Golovin"",   6,
   82,  3, ""Zhirkov"",   6,
   76, 19, ""ball"",      7,
   73, 15, ""Golovin"",   7,
   82,  3, ""Zhirkov"",   7,
   94, 60, ""ball"",      8,
   73, 20, ""Golovin"",   8,
   82,  3, ""Zhirkov"",   8,
   99.2, 47.5, ""ball"",  9,
   73, 20, ""Golovin"",   9,
   82,  3, ""Zhirkov"",   9
  
)

# arrange by time!
# instead of string label, give numerical ID value? but the IDs themselves will get ""interpolated"".... wtf

data2 <- data %>% select(-label)


data3 <- tribble(
  ~x,  ~y,  ~label, ~time,
  100,  0,  ""ball"",     1,
   94, 35, ""ball"",      2,
   82, 31, ""ball"",      3,
   82.5, 25, ""ball"",    4,
   84,  6, ""ball"",      5, 
   77, 13, ""ball"",      6,
   76, 19, ""ball"",      7,
   94, 60, ""ball"",      8,
   99.2, 47.5, ""ball"",  9,

) %>% select(-label)



```

##### remove ALL player label and their coordinate data
##### have label data move separately in their own tweened' dataframe


```{r Gazinsky ani plot}
ani <- ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(data = segment_data, 
               aes(x = x, y = y, 
                   xend = xend, yend = yend),
               size = segment_data$size,
               color = segment_data$color,
               linetype = c(""dashed"", ""dashed"")) +
  geom_label(
    data = golovin_movement,
    aes(x = x, y = y,
        frame = time,
        label = label)) +
  geom_label(
    data = zhirkov_movement,
    aes(x = x, y = y,
        frame = time,
        label = label)) +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        frame = time,
        label = label)) +
  geom_point(
    data = saudi_data,
    aes(x = x, y = y),
    color = ""darkgreen"",
    size = 5) +
  ggimage::geom_emoji(
    aes(x = x, y = y, 
        frame = time), 
    image = ""26bd"", 
    size = 0.035) +
  theme(text = element_text(family = ""Dusha V5"")) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"")

gganimate(ani, ""ani.gif"")  # use frame to check positionings...

```

```{r Gazinsky tween data}
library(purrr)

# all tween
data_list <- map(seq(nrow(data)),
                      ~ data[c(seq(.x), rep(.x, nrow(data) - .x)), ])
  
data_tween <- data_list %>% 
  tween_states(tweenlength = 2, statelength = 1.25, ease = ""linear"", nframes = 200)    
# Error in col2rgb(d) : invalid color name 'ball'
# can't recognize non-numeric data >>> SO question + issue opened but unanswered
# probably solved in the new API!


# try withoutlabels col
data_list <- map(seq(nrow(data2)),
                      ~ data2[c(seq(.x), rep(.x, nrow(data2) - .x)), ])
  
data_tween <- data_list %>% 
  tween_states(tweenlength = 2, statelength = 1.25, ease = ""linear"", nframes = 200)

data_t <- data_tween %>% group_by(.frame) %>% slice(27)

# data3
data_list <- map(seq(nrow(data3)),
                      ~ data3[c(seq(.x), rep(.x, nrow(data3) - .x)), ])
  
data_tween <- data_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

data_t <- data_tween %>% group_by(.frame) %>% slice(9)


# plot

gazinsky_goal <- data_t %>% # change depending on whatever df i wantto try...
  ggplot() +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(data = segment_data, 
               aes(x = x, y = y, 
                   xend = xend, yend = yend),
               size = segment_data$size,
               color = segment_data$color,
               linetype = c(""dashed"", ""dashed"")) +
  geom_point(
    data = saudi_data,
    aes(x = x, y = y),
    color = ""darkgreen"",
    size = 5) +
  ggimage::geom_emoji(
    aes(x = x, y = y, frame = .frame),    # change frame to .frame or it'll still move by time only -_-
    image = ""26bd"", size = 0.035) +
  geom_label(data = golo_t,
    aes(x = x, y = y,
        frame = .frame,
        label = label)) +
  theme(text = element_text(family = ""Dusha V5"")) +
  ggtitle(label = ""Russia (5) vs. (0) Saudi Arabia"", 
          subtitle = ""First goal, Yuri Gazinsky (12th Minute)"") +
  labs(caption = ""By Ryo Nakagawara (@R_by_Ryo)"") +
  annotate(""text"", x = 69, y = 65, family = ""Dusha V5"",
           label = ""After a poor corner kick clearance\n from Saudi Arabia, Golovin picks up the loose ball, \n exchanges a give-and-go pass with Zhirkov\n before finding Gazinsky with a beautiful cross!"")
  
  

# left in the label data so the ball moves to those points as wel... not good.

gganimate(gazinsky_goal, 
          ani.width = 800, ani.height = 500, 
          interval = 0.25, 
          ""gazinsky_goal.gif"")

# with data3, data_tween as input: leaves a trail of ball emoji behind at every point... (without the slice() part...)

gganimate(gazinsky_goal, 
          ani.width = 800, ani.height = 500, 
          interval = 0.25, 
          ""gg_gazinsky.gif"")

# with golovin label movement AND ball movement?

gganimate(gazinsky_goal, 
          ani.width = 800, ani.height = 500, 
          interval = 0.25, 
          ""gg_ball_label.gif"")

```

- try with tween_elements() again........

```{r Gazinsky movement tweenr}
golovin_movement_list <- map(seq(nrow(golovin_movement)),
                      ~golovin_movement[c(seq(.x), rep(.x, nrow(golovin_movement) - .x)), ])
  
golovin_tween <- golovin_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

golo_t <- golovin_tween %>% group_by(.frame) %>% slice(9)

golovin_move <- ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(data = segment_data, 
               aes(x = x, y = y, 
                   xend = xend, yend = yend),
               size = segment_data$size,
               color = segment_data$color,
               linetype = c(""dashed"", ""dashed"")) +
  geom_label(data = golo_t,
    aes(x = x, y = y,
        frame = .frame,
        label = label)) +
  ggimage::geom_emoji(
    aes(x = x, y = y, frame = time), 
    image = ""26bd"", size = 0.035)

gganimate(golovin_move, 
          ani.width = 800, ani.height = 500, 
          title_frame = FALSE, interval = 0.25, 
          ""golovin_move.gif"")
```



```{r zhirkov movement}

zhirkov_movement <- data.frame(
  x = c(98, 90, 84, 84, 84, 84, 84, 84, 84),
  y = c( 0,  2,  2,  2,  2,  2,  2,  2,  2),
  label = ""Zhirkov"",
  time = c(1, 2, 3, 4, 5, 6, 7, 8, 9)
)

zhirkov_movement_list <- map(seq(nrow(zhirkov_movement)),
                      ~zhirkov_movement[c(seq(.x), rep(.x, nrow(zhirkov_movement) - .x)), ])
  
zhirkov_tween <- zhirkov_movement_list %>% 
  tween_states(tweenlength = 0.5, statelength = 0.00000001, ease = ""linear"", nframes = 75)

zhir_t <- zhirkov_tween %>% group_by(.frame) %>% slice(9)

zhirkov_move <- ggplot(pass_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_flip(xlim = c(49, 101),
             ylim = c(-1, 101)) +
  geom_segment(data = segment_data, 
               aes(x = x, y = y, 
                   xend = xend, yend = yend),
               size = segment_data$size,
               color = segment_data$color,
               linetype = c(""dashed"", ""dashed"")) +
  geom_label(data = zhir_t,
    aes(x = x, y = y,
        frame = .frame,
        label = label)) +
  geom_label(data = golo_t,
    aes(x = x, y = y,
        frame = .frame,
        label = label)) +
  geom_label(
    data = gazinsky_movement,
    aes(x = x, y = y,
        label = label)) +
  ggimage::geom_emoji(
    data = data_t,
    aes(x = x, y = y, frame = .frame),    # change frame to .frame or it'll still move by time only -_-
    image = ""26bd"", size = 0.035)

gganimate(zhirkov_move, 
          ani.width = 800, ani.height = 500, 
          title_frame = FALSE, interval = 0.25, 
          ""zhirkov_move.gif"")

```



PR for formations function?

Try more advanced soccer play-by-play animations?

Recreate famous World Cup goals of the past? (Maradona vs. England?)
```{r}
#<center>
#![](https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png)
#</center>
```



```{r other offside}

ggplot(offside_data) +
  annotate_pitch() +
  theme_pitch() +
  lims(x = c(-1, 101),
       y = c(-1, 101))

ggplot(offside_data) +
  annotate_pitch() +
  theme_pitch() +
  coord_cartesian(xlim = c(60, 101),
                  ylim = c(-1, 101))



create_StatsBomb_ShotMap <- function(grass_colour, line_colour, background_colour, goal_colour){
  
  theme_blankPitch = function(size=12) { 
    theme(
      #axis.line=element_blank(), 
      axis.text.x=element_blank(), 
      axis.text.y=element_blank(), 
      #axis.ticks.y=element_text(size=size),
      #   axis.ticks=element_blank(),
      axis.ticks.length=unit(0, ""lines""), 
      #axis.ticks.margin=unit(0, ""lines""), 
      axis.title.x=element_blank(), 
      axis.title.y=element_blank(), 
      legend.background=element_rect(fill=background_colour, colour=NA), 
      legend.key=element_rect(colour=background_colour,fill=background_colour), 
      legend.key.size=unit(1.2, ""lines""), 
      legend.text=element_text(size=size), 
      legend.title=element_text(size=size, face=""bold"",hjust=0),
      strip.background = element_rect(colour = background_colour, fill = background_colour, size = .5),
      panel.background=element_rect(fill=background_colour,colour=background_colour), 
      #       panel.border=element_blank(), 
      panel.grid.major=element_blank(), 
      panel.grid.minor=element_blank(), 
      panel.spacing=element_blank(), 
      plot.background=element_blank(), 
      plot.margin=unit(c(0, 0, 0, 0), ""lines""), 
      plot.title=element_text(size=size*1.2), 
      strip.text.y=element_text(colour=background_colour,size=size,angle=270),
      strip.text.x=element_text(size=size*1))}
  
    ymin <- 60 # minimum width
    ymax <- 120 # maximum width
    xmin <- 0 # minimum length
    xmax <- 80 # maximum length
    
    # Defining features along the length
    boxEdgeOff <- 102
    sixYardOff <- 114
    penSpotOff <- 108
    halfwayline <- 60
    
    # Defining features along the width
    boxEdgeLeft <- 18
    boxEdgeRight <- 62
    sixYardLeft <- 30 
    sixYardRight <- 50
    goalPostLeft <- 36
    goalPostRight <- 44
    CentreSpot <- 40   
    
    # other dimensions
    centreCirle_d <- 20   
  
  ## define the circle function
  circleFun <- function(center = c(0,0),diameter = 1, npoints = 100){
    r = diameter / 2
    tt <- seq(0,2*pi,length.out = npoints)
    xx <- center[1] + r * cos(tt)
    yy <- center[2] + r * sin(tt)
    return(data.frame(x = xx, y = yy))
  }

  #### create leftD arc ####
  dArc <- circleFun(c((40),(penSpotOff)),centreCirle_d,npoints = 1000)
  ## remove part that is in the box
  dArc <- dArc[which(dArc$y <= (boxEdgeOff)),]
    
    ## initiate the plot, set some boundries to the plot
  p <- ggplot() + xlim(c(ymin,ymax)) + ylim(c(xmin,xmax)) +
  # add the theme 
  theme_blankPitch() +
  # add the base rectangle of the pitch 
  geom_rect(aes(xmin=ymin, xmax=ymax, ymin=xmin, ymax=xmax), fill = grass_colour, colour = line_colour) +
  # add the 18 yard box offensive
  geom_rect(aes(xmin=boxEdgeLeft, xmax=boxEdgeRight, ymin=boxEdgeOff, ymax=xmax), fill = grass_colour, colour = line_colour) +
  # add the six yard box offensive
  geom_rect(aes(xmin=sixYardLeft, xmax=sixYardRight, ymin=sixYardOff, ymax=xmax), fill = grass_colour, colour = line_colour) +
  # add the arc circle 
  geom_path(data=dArc, aes(x=x,y=y), colour = line_colour) +
  # add penalty spot 
  geom_point(aes(x = CentreSpot , y = penSpotOff), colour = line_colour) +
     # add the goal offensive
  geom_segment(aes(x = goalPostLeft, y = xmax, xend = goalPostRight, yend = xmax),colour = goal_colour, size = 1)
  
  return(p)

}

p <- create_StatsBomb_ShotMap(""#538032"", ""#ffffff"", ""#538032"", ""#000000"")

p +
  coord_flip()
  geom_point(aes(x = c(70, 30), 
                 y = c(80, 100)))



```

","2018"
"86",253,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/RMarkdown/worldcup_ideas.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 23, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

- home field / continent advantage? 



- players playing abroad %
- top % leagues

- avg. caps per position :: where rely on young? where rely on old?
- differences across teams / confederations?
----- world cup winners characteristics???  by confederation / club teams

- world cup uniforms/logo animation
- Japan vs. OPPONENT side-by-side >>> by each world cup
- have title above with world cup date + match + score(?)
- need to combine images to be side-by-side, then morph each combined image from one-to-next!


ggjoy plot for goals scored >>> which minute of game?


- rtweet worldcup???

6/30-7/1
japanese version part 1 NEED TO START
joyplot goals    IN PROGRESS
post Group A-H   DONE
uniform gifs     IN PROGRESS


create functions for GROUP Standings charts... possible????
- lots of moving parts needed...


- fifa world cup audience report
","2018"
"87",254,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/anim_save_try.r","library(ggplot2)    # general plotting base
library(dplyr)      # data manipulation/tidying
library(ggsoccer)   # draw soccer field plot
library(ggimage)    # add soccer ball emoji + flags
library(extrafont)  # incorporate Dusha font into plots
library(gganimate)  # animate goal plots
library(tweenr)     # create in-between frames for data
library(purrr)      # for creating a list of dataframes for tweenr
library(countrycode)



### DATAFRAMES

cornerkick_data <- data.frame(
  x = 99, y = 0.3,
  x2 = 94, y2 = 47)

osako_gol <- data.frame(
  x = 94, y = 49,
  x2 = 100, y2 = 55.5)

ball_data <- data.frame(
  x = c(99, 94, 100),
  y = c(0.3, 47, 55.5),
  time = c(1, 2, 3))

player_label <- data.frame(
  x = c(92, 99), 
  y = c(49, 2),
  label = c(""Osako"", ""Honda""))

wc_logo <- data.frame(
  x = 107,
  y = 85) %>% 
  mutate(
    image = ""https://upload.wikimedia.org/wikipedia/en/thumb/6/67/2018_FIFA_World_Cup.svg/1200px-2018_FIFA_World_Cup.svg.png"")

flag_data <- data.frame(
  x = c(110, 110),
  y = c( 13, 53),
  team = c(""japan"", ""colombia"")
) %>% 
  mutate(
    image = team %>% 
      countrycode(., origin = ""country.name"", destination = ""iso2c"")
  ) %>% 
  select(-team)




### PLOTTING




ganim <- ggplot(ball_data) +
  annotate_pitch() +
  theme_pitch() +
  theme(
    text = element_text(family = ""Dusha V5""),
    plot.margin=grid::unit(c(0,0,0,0), ""mm"")) +
  coord_flip(
    xlim = c(55, 112),
    ylim = c(-1, 101)) +
  geom_label(
    data = player_label, 
    aes(x = x, y = y,
        label = label),
    family = ""Dusha V5"") +
  geom_point(
    aes(x = 98, y = 50), size = 3, color = ""green"") +
  annotate(
    geom = ""text"", family = ""Dusha V5"", 
    hjust = c(0.5, 0.5, 0.5, 0.5),
    size = c(6.5, 4.5, 5, 3),
    label = c(""Japan             (2) vs. Colombia             (1)"",
              ""Kagawa (PEN 6'), Quintero (39'), Osako (73')"",
              ""Japan press their man advantage, substitute Honda\ndelivers a delicious corner kick for Osako to (somehow) tower over\nColombia's defense and flick a header into the far corner!"",
              ""by Ryo Nakagawara (@R_by_Ryo)""),
    x = c(110, 105, 70, 53), 
    y = c(30, 30, 47, 85)) +
  ggimage::geom_emoji(              # soccer ball emoji
    aes(x = x, 
        y = y),
    image = ""26bd"", size = 0.035) +
  ggimage::geom_flag(               # Japan + Colombia flag
    data = flag_data,
    aes(x = x, y = y,
        image = image),       
    size = c(0.08, 0.08)) +
  geom_image(                       # World Cup logo
    data = wc_logo,     
    aes(x = x, y = y,
        image = image), size = 0.17) +
  # new gganimate code:
  transition_states(
    time, 
    transition_length = 0.5, 
    state_length = 0.0001,
    wrap = FALSE) +
  ease_aes(""quadratic-out"")



anim_save(ganim)


","2018"
"88",255,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/other articles/world_cup_BBC_charts.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 11, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(tidyverse)
library(scales)
library(scales)
library(ggthemes)
library(ggflags)
library(ggimage)


wc_top_scorers <- tribble(
  ~player, ~goals, ~country, ~code,
  
  ""Klose"", 16, ""Germany"", ""DE"",
  ""Ronaldo"", 15, ""Brazil"", ""BR"",
  ""G. Mueller"", 14, ""Germany"", ""DE"",
  ""Fontaine"", 13, ""France"", ""FR"", 
  ""Pele"", 12, ""Brazil"", ""BR"",
  ""Kocsis"", 11, ""Hungary"", ""HU"",
  ""Klinsmann"", 11, ""Germany"", ""DE"",
  ""Rahn"", 10, ""Germany"", ""DE"",
  ""Cubillas"", 10, ""Peru"", ""PE"",
  ""Lineker"", 10, ""England"", ""GB"",
  ""Batistuta"", 10, ""Argentina"", ""AR"",
  ""T. Mueller"", 10, ""Germany"", ""DE""
  
)

glimpse(wc_top_scorers)


ggplot(wc_top_scorers, 
       aes(reorder(player, goals), goals)) +
  geom_col(alpha = 0.9, fill = ""white"") +
  geom_flag(y = -2, aes(image = code)) +
  geom_point(shape = 21, color = ""black"", fill = ""white"", stroke = 3, size = 4) +
  coord_flip() +
  expand_limits(y = -2) +
  #geom_text() +
  theme_minimal()

```

- find flags >>> in ggflag or geom_flag NO england, only UK...
- find ball pics
- annotate for '78-94
- flag on axis :: Done
- geom_text number of goals
- custom legend
- how to make ball for EACH point?? >>> multiple one-row waffle charts???



```{r}
library(ggimage) # 2 letter ISO codes

f <- system.file(""extdata/medals.txt"", package=""ggimage"")
medals <- read.table(f, header=TRUE)
p <- ggplot(medals, aes(Country, count)) + geom_col(aes(fill = medal), width = .8)

p + geom_flag(y = -2, aes(image = code)) +
    coord_flip() + 
    expand_limits(y = -2)  +
    scale_fill_manual(values = c(""Gold"" = ""gold"", ""Bronze"" = ""#cd7f32"", ""Silver"" = ""#C0C0C0""))

```







```{r}
wc_top <- tribble(
  ~player, ~goals, ~country, ~code,
  
  ""Klose"", 1, ""Germany"", ""DE"",
  ""Klose"", 2, ""Germany"", ""DE"",
  ""Klose"", 3, ""Germany"", ""DE"",
  ""Klose"", 4, ""Germany"", ""DE"",
  ""Klose"", 5, ""Germany"", ""DE"",
  ""Klose"", 6, ""Germany"", ""DE"",
  ""Klose"", 7, ""Germany"", ""DE"",
  ""Klose"", 8, ""Germany"", ""DE"",
  ""Fontaine"", 13, ""France"", ""FR"", 
  ""Pele"", 12, ""Brazil"", ""BR"",
  ""Kocsis"", 11, ""Hungary"", ""HU"",
  ""Klinsmann"", 11, ""Germany"", ""DE"",
  ""Rahn"", 10, ""Germany"", ""DE"",
  ""Cubillas"", 10, ""Peru"", ""PE"",
  ""Lineker"", 10, ""England"", ""GB"",
  ""Batistuta"", 10, ""Argentina"", ""AR"",
  ""T. Mueller"", 10, ""Germany"", ""DE""
  
)

ggplot(wc_top, 
       aes(reorder(player, goals), goals)) +
  geom_col(alpha = 0.9, fill = ""white"") +
  geom_point(shape = 21, color = ""black"", fill = ""white"", stroke = 1.5, size = 3.5) +
  coord_flip() +
  expand_limits(y = -2) +
  #geom_text() +
  theme_minimal()



```














","2018"
"89",256,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/other articles/worldcup_player_data.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 26, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Download World Cup player data

https://rviews.rstudio.com/2018/06/14/player-data-for-the-2018-fifa-world-cup/


## From PDF

```{r}
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(ggplot2)
library(lubridate)
library(cowplot)
library(tabulizer)

url <- ""https://github.com/davidkane9/wc18/raw/master/fifa_player_list_1.pdf""
out <- extract_tables(url, output = ""data.frame"")


```

32 element list, one df for each team!

```{r}
pdf_data <- out %>% 
  bind_rows() %>% 
  as_tibble()

glimpse(pdf_data)

pdf_data <- pdf_data %>% 
  
  janitor::clean_names() %>% 
  
  rename(number = x,
         position = pos,
         name = fifa_popular_name) %>% 
  
  mutate(
    team = case_when(
    team == ""Korea Republic"" ~ ""South Korea"",
    team == ""IR Iran"" ~ ""Iran"",
    TRUE ~ team
  )) %>% 
  
  mutate(
    birth_date = dmy(birth_date),
    league = str_sub(club, -4, -2),
    club = str_sub(club, end = -7),
    age = interval(birth_date, ""2018-06-14"") / years(1)
  )

# check out the str_sub() function
pdf_data %>% 
  janitor::clean_names() %>% 
  select(team, fifa_popular_name, club) %>% 
  mutate(league = str_sub(club,    # take string from 4 spaces from end to 2 spaces from end!
                          start = -4, end = -2),
         club = str_sub(club, end = -7)) # take string from 7 spaces from end only

```

check for errors with `stopifnot()` function!

```{r}

stopifnot(length(unique(pdf_data$Team)) == 32) # 32 teams in total

pdf_data %>% 
  select(team) %>% 
  unique() %>% 
  count()


stopifnot(all(range(table(pdf_data$Team)) == 23)) # 23 players per team

pdf_data %>% 
  select(Team) %>% 
  table() %>% 
  range() %>% 
  all(23) # TRUE!

pdf_data %>% 
  filter(position == ""GK"") %>% 
  group_by(team) %>% 
  tally() %>% 
  filter(n != 3) %>% 
  nrow() == 0         # all teams have 3 GKs

pdf_data %>% 
  select(position) %>% 
  filter(position %in% c(""GK"", ""DF"", ""MF"", ""FW"")) %>% 
  unique() # each player assigned to valid position



```



## From Wikipedia data

```{r}
library(rvest)

html <- read_html(""https://en.wikipedia.org/wiki/2018_FIFA_World_Cup_squads"")

country <- html %>% 
  html_nodes("".mw-parser-output > h3"") %>% 
  html_text() %>% 
  as_tibble() %>% 
  slice(1:32)

number <- html %>% 
  html_nodes(""td:nth-child(1)"") %>% 
  html_text() %>% 
  as.numeric() %>% 
  na.omit() %>% 
  .[1:736]

name <- html %>% 
  html_nodes(""th:nth-child(3)"") %>% 
  html_text() %>% 
  as_tibble() %>% 
  filter(!str_detect(value, ""Player"")) %>% 
  mutate(value = str_remove_all(value, ""\\(captain\\)"")) %>% 
  slice(1:736)

caps <- html %>% 
  html_nodes(""td:nth-child(5)"") %>% 
  html_text() %>% 
  as.numeric() %>% 
  .[1:736]

wiki_data <- tibble(
  
  number = number,
  name = name$value,
  team = rep(country$value, each = 23),
  caps = caps
  
)

wc_player_data <- pdf_data %>% 
  select(-name) %>% 
  left_join(wiki_data, by = c(""team"", ""number""))

#write.csv(wc_player_data, ""data/wc_player_data.csv"")

```































","2018"
"90",257,"https://github.com/Ryo-N7/soccer_ggplots","Ryo-N7","soccer_ggplots","World Cup 2018/scripts/kit_read().r","kit_read <- function(path) {
  
  japan_kits <- list.files(path = path, pattern = ""*.gif"", full.names = TRUE) %>% 
    map(image_read) %>% 
    image_join()  
  
  return(japan_kits)
  
}","2018"
"91",258,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","2019_week_10/women_employment.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""March 9, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Packages


```{r, warning=FALSE, message=FALSE}
pacman::p_load(tidyverse, rvest, polite, scales, lubridate, extrafont)
loadfonts()
```

# data load

```{r}
jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")
```

# clean

```{r}
glimpse(jobs_gender)
```

```{r}
skimr::skim_to_wide(jobs_gender) %>% knitr::kable()
```

```{r}
jobs_gender %>% View()
```

```{r}
jobs_gender %>% 
  ggplot(aes(log(total_earnings_male), log(total_earnings_female), color = major_category)) +
  geom_point()

jobs_gender %>% 
  select(major_category, year, percent_female) %>% 
  mutate(percent_male = (100 - percent_female) %>% round(digits = 1)) %>% 
  rename(male = percent_male, female = percent_female) %>% 
  filter(year == 2016) %>% 
  group_by(major_category) %>% 
  mutate(diff = male - female) %>% 
  gather(""gender"", value = ""percentage"", -year, -major_category, - diff) %>% 
  group_by(major_category, gender) %>% 
  summarise(perc = mean(percentage),
            diff = mean(diff)) %>% 
  ungroup() %>% 
  mutate(major_category = major_category %>% as_factor() %>% fct_reorder(diff)) %>% 
  ggplot(aes(x = perc, y = major_category, color = gender)) +
  geom_point() + 
  geom_segment(aes(xend = perc, yend = major_category)) +
  theme_minimal()
```




```{r}
jobs_gender %>% 
  select(major_category, year, percent_female) %>% 
  mutate(percent_male = (100 - percent_female) %>% round(digits = 1)) %>% 
  rename(male = percent_male, female = percent_female) %>% 
  group_by(major_category) %>% 
  mutate(diff = male - female) %>% 
  gather(""gender"", value = ""percentage"", -year, -major_category, - diff) %>% 
  group_by(major_category, gender, year) %>% 
  summarise(perc = mean(percentage),
            diff = mean(diff)) %>% 
  ggplot(aes(x = year, y = diff, group = major_category, color = major_category)) +
  geom_line()
```

","2019"
"92",259,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","2019_week_3/space_flight.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""January 17, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r, message=FALSE}
pacman::p_load(tidyverse, scales, lubridate, gghighlight, ggbeeswarm,
               extrafont, glue, magick)
loadfonts()
```


```{r}
launches_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")

agencies_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/agencies.csv"")


```




```{r}
launches_raw %>% glimpse()
agencies_raw %>% glimpse()

launches_raw %>% 
  glimpse()

launches_raw %>% 
  filter(state_code == ""J"") %>% 
  mutate(success = if_else(category == ""O"", TRUE, FALSE)) %>% 
  arrange(launch_year) %>% 
  select(launch_year, type, state_code, agency_type, success) %>% 
  group_by(launch_year, agency_type, type, success) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(launch_year, n, fill = success)) +
  geom_col() +
  gghighlight(agency_type == ""private"") + theme_minimal()
  facet_wrap(~agency_type, ncol = 1) +
  theme_minimal()

```




```{r}
launches_raw %>% 
  filter(state_code == ""J"") %>% 
  ggplot(aes(launch_year)) +
  geom_area(stat = ""bin"", fill = ""red"", bins = 50) +
  scale_x_continuous(breaks = scales::pretty_breaks(20),
                     limits = c(1960, 2018),
                     expand = c(0, 0)) +
  theme_minimal() + 
  theme(panel.grid.minor.x = element_blank()) +
  geom_text(aes(x = 1960, y = 3, hjust = 0,
           label = ""1963: Establishment of the National Aerospace Laboratory (NAL)""),
           size = 2) +
  annotate(geom = ""segment"")
```





```{r}
launches_raw %>% 
  filter(state_code == ""J"") %>% 
  group_by(launch_year, type) %>% 
  count() %>% 
  #add_count(state_code) %>% 
  ggplot(aes(x = launch_year, y = n, fill = type)) +
  geom_col() +
  theme_minimal()

```





```{r}
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", 
                              ""bottom right"", ""bottom left"", ""bottom center"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    # add bottom center position!
    } else if (logo_position == ""bottom center"") {
      x_pos = plot_width / 2
      y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}
```


```{r}
launches_jp_type <- launches_raw %>% 
  filter(state_code == ""J"") %>% 
  add_count(type) %>% 
  mutate(agency_type = as_factor(agency_type) %>% 
           fct_recode(Private = ""private"", State = ""state""),
         type = as_factor(type),
         type = fct_reorder(.f = type, .x = launch_date, 
                            .fun = min)) %>% 
  mutate(success = if_else(category == ""O"", ""Success"", ""Failure"") %>% as_factor())

cols <- c(""Private"" = ""red"", ""State"" = ""grey"")
cols <- c(""Success"" = ""grey"", ""Failure"" = ""red"")

launches_jp_type %>% 
  ggplot(aes(launch_year, fct_rev(type), color = success)) +
  geom_beeswarm(groupOnX = FALSE, cex = 1.5) +
  scale_color_manual(values = cols, name = ""Launch Result"") +
  scale_x_continuous(breaks = scales::pretty_breaks(20)) +
  theme_minimal() +
  theme(panel.grid.minor.x = element_blank(),
        text = element_text(family = ""Roboto Condensed""),
        legend.position = ""bottom"") +
  geom_rect(xmin = 1965, xmax = 2020, fill = NA, color = ""black"",
            ymin = 3.4, ymax = 7.6, alpha = 0.2) +
  labs(title = ""Timeline of Japan's Space Vehicles"",
       subtitle = glue(""
                       The H-IIA (operated by Mitsubishi Heavy Industries) has been a reliable vehicle for the 
                       Japan Aerospace Exploration Agency (JAXA) throughout this century.""), 
       x = NULL,
       y = ""Launch System Type"",
       caption = ""
       Source: FiveThirtyEight
       By @R_by_Ryo"") +
  annotate(geom = ""text"", 
           label = glue(""
                        Only 1 of 40 launches of this type have failed.""),
           x = 1967, y = 5.5, hjust = 0, family = ""Roboto Condensed"")

# save plot
ggsave(glue(""../2019_week_3/jp_space_vehicles_plot.png""))
#plot <- image_read(""../2019_week_3/jp_space_vehicles_plot.png"")
```

```{r}
add_logo(plot_path = ""../2019_week_3/jp_space_vehicles_plot.png"",
         logo_path = ""https://upload.wikimedia.org/wikipedia/en/d/d6/Mitsubishi_Heavy_Industries_%28logo%29.svg"",
         logo_position = ""bottom left"",
         logo_scale = 5)

ggsave(""../2019_week_3/jp_vehicles_logo_plot.png"")

add_logo(plot_path = ""../2019_week_3/jp_space_vehicles_plot.png"",
         logo_path = ""https://upload.wikimedia.org/wikipedia/commons/8/85/Jaxa_logo.svg"",
         logo_position = ""top right"",
         logo_scale = 10) -> plot_logo

image_write(image = plot_logo, ""../2019_week_3/jp_vehicles_logo_plot.png"")
ggsave(""../2019_week_3/jp_vehicles_logo_plot.png"")
```


## tidy tuesday submission



```{r, message=FALSE}
# load packages
pacman::p_load(tidyverse, scales, ggbeeswarm, extrafont, glue, magick)

# load fonts
loadfonts()

# load data
launches_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")

# wrangle data
launches_jp_type <- launches_raw %>% 
  filter(state_code == ""J"") %>% 
  mutate(type = as_factor(type),
         type = fct_reorder(.f = type, .x = launch_date, 
                            .fun = min)) %>% 
  mutate(success = if_else(category == ""O"", ""Success"", ""Failure"") %>% as_factor())

# set color values
cols <- c(""Success"" = ""grey"", ""Failure"" = ""red"")

# PLOT
launches_jp_type %>% 
  ggplot(aes(launch_year, fct_rev(type), color = success)) +
  geom_beeswarm(groupOnX = FALSE, cex = 1.5) +
  scale_color_manual(values = cols, name = ""Launch Result"") +
  scale_x_continuous(breaks = scales::pretty_breaks(20)) +
  geom_rect(xmin = 1965, xmax = 2020, fill = NA, color = ""black"",
            ymin = 3.4, ymax = 7.825, alpha = 0.2) +
  labs(title = ""History of Japan's Space Vehicles"",
       subtitle = glue(""
                       The H-IIA (operated by Mitsubishi Heavy Industries) has been a reliable vehicle for the 
                       Japan Aerospace Exploration Agency (JAXA) throughout this century.""), 
       x = ""Year"",
       y = ""Launch Vehicle Type"",
       caption = ""
       Source: FiveThirtyEight
       By @R_by_Ryo"") +
  theme_minimal() +
  theme(panel.grid.minor.x = element_blank(),
        plot.title = element_text(size = 14),
        plot.subtitle = element_text(size = 10),
        text = element_text(family = ""Roboto Condensed""),
        legend.position = ""bottom"") +
  annotate(geom = ""text"", 
           label = glue(""
                        Only 1 of 40 launches of this type have failed.""),
           x = 1967, y = 5.5, hjust = 0, family = ""Roboto Condensed"")

# save plot
ggsave(glue(""../2019_week_3/jp_space_vehicles_plot.png""))

# add logo with Magick using Thomas Mock's custom function
# check out the explanation in his blog post: https://themockup.netlify.com/posts/2019-01-09-add-a-logo-to-your-plot/
add_logo <- function(plot_path, logo_path, logo_position, logo_scale = 10){

    # Requires magick R Package https://github.com/ropensci/magick

    # Useful error message for logo position
    if (!logo_position %in% c(""top right"", ""top left"", ""bottom right"", ""bottom left"")) {
        stop(""Error Message: Uh oh! Logo Position not recognized\n  Try: logo_positon = 'top left', 'top right', 'bottom left', or 'bottom right'"")
    }

    # read in raw images
    plot <- magick::image_read(plot_path)
    logo_raw <- magick::image_read(logo_path)

    # get dimensions of plot for scaling
    plot_height <- magick::image_info(plot)$height
    plot_width <- magick::image_info(plot)$width

    # default scale to 1/10th width of plot
    # Can change with logo_scale
    logo <- magick::image_scale(logo_raw, as.character(plot_width/logo_scale))

    # Get width of logo
    logo_width <- magick::image_info(logo)$width
    logo_height <- magick::image_info(logo)$height

    # Set position of logo
    # Position starts at 0,0 at top left
    # Using 0.01 for 1% - aesthetic padding

    if (logo_position == ""top right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""top left"") {
        x_pos = 0.01 * plot_width
        y_pos = 0.01 * plot_height
    } else if (logo_position == ""bottom right"") {
        x_pos = plot_width - logo_width - 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    } else if (logo_position == ""bottom left"") {
        x_pos = 0.01 * plot_width
        y_pos = plot_height - logo_height - 0.01 * plot_height
    }

    # Compose the actual overlay
    magick::image_composite(plot, logo, offset = paste0(""+"", x_pos, ""+"", y_pos))

}

# add_logo and save
plot_logo <- add_logo(plot_path = ""../2019_week_3/jp_space_vehicles_plot.png"",
                      logo_path = ""https://upload.wikimedia.org/wikipedia/commons/8/85/Jaxa_logo.svg"",
                      logo_position = ""top right"",
                      logo_scale = 10)

image_write(image = plot_logo, ""../2019_week_3/jp_vehicles_logo_plot.png"")
```

","2019"
"93",260,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","2019_week_5/cheesy.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""February 27, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Package

```{r}
pacman::p_load(tidyverse, scales)
```



```{r}
clean_cheese_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/clean_cheese.csv"")

glimpse(clean_cheese_raw)

clean_cheese_df <- clean_cheese_raw %>% 
  select(Year, contains(""Total""))

clean_cheese_df %>% 
  gather(key = ""cheese"", value = ""value"", -Year) %>% 
  ggplot(aes(Year, value, color = cheese)) +
  geom_point()
```

","2019"
"94",261,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","2019_week_9/french_trains.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""February 26, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r}
pacman::p_load(tidyverse, scales, lubridate, glue)
```


## Insert data

```{r}
frenchtrain_raw <- read_csv(""full_trains.csv"")
```

```{r}
frenchtrain_raw %>% skimr::skim()
```




```{r}
parisest <- frenchtrain_raw %>% 
  filter(departure_station == ""PARIS EST"") %>% 
  select(year, month, service, departure_station, arrival_station, 
         avg_delay_late_at_departure,
         avg_delay_all_departing) %>% 
  mutate(avg_delay_all_departing = round(avg_delay_all_departing, digits = 0),
         avg_delay_late_at_departure = round(avg_delay_late_at_departure, digits = 0))

glimpse(parisest)
```



```{r}
library(ggstraw)

ggstraw::flights %>% glimpse()
```


```{r}
parisest %>% 
  group_by(year, month) %>% 
  mutate(dep_time = ymd_hm(""2019-02-28 00:00"", tz = ""Pacific/Auckland"")) %>% 
  # mutate(dep_2 = if_else(avg_delay_all_departing >= 1, 
  #                        dep_time + avg_delay_all_departing,
  #                        dep_time)) %>% 
  mutate(dep_2 = dep_time + avg_delay_late_at_departure) %>% 
  mutate(late = if_else(dep_time == dep_2, FALSE, TRUE)) %>% 
  ggplot(aes(dep_time, service, xend = dep_2, color = late)) +
  geom_straw() +
  theme_minimal()
```


```{r}
parisest %>% 
  ggplot(aes(month, avg_delay_all_departing)) +
  geom_point() +
  geom_smooth()
```


```{r}
frenchtrain_raw %>% 
  arrange(departure_station, month) %>% 
  fill(service, .direction = ""down"") %>% 
  filter(service == ""International"") %>% 
  mutate_if(is.character, str_to_title(.))
```




```{r}
parisest2 <- frenchtrain_raw %>% 
  filter(departure_station == ""PARIS EST"") %>% 
  select(year, month, service, departure_station, arrival_station, 
         contains(""delay_cause""))

glimpse(parisest2)
```

```{r}
parisest2 %>% 
  group_by(year, month, departure_station) %>% 
  summarize_at(vars(contains(""delay_cause"")), mean, na.rm = TRUE) %>% 
  gather(""delay_cause"", ""value"", -year, -month, -departure_station) %>% 
  ggplot(aes(month, value, fill = delay_cause)) +
  geom_area() +
  facet_wrap(~year) +
  theme_minimal()
```





```{r fig.height=4, fig.width=12}
frenchtrain_raw %>% 
  filter(service == ""International"",
         #year == 2017,
         str_detect(departure_station, ""PARIS"")) %>% 
  select(-contains(""delay"")) %>% 
  arrange(year, month) %>% 
  mutate(prop_late = num_late_at_departure / total_num_trips,
         year = as_factor(as.character(year)),
         month = as_factor(as.character(month))) %>% 
  mutate(dest_country = case_when(
    arrival_station %in% c(""FRANCFORT"", ""STUTTGART"") ~ ""Allemagne"",
    arrival_station %in% c(""GENEVE"", ""LAUSANNE"", ""ZURICH"") ~ ""Suisse"",
    arrival_station %in% c(""ITALIE"") ~ ""Italie""
  )) %>% 
  #filter(departure_station == ""PARIS EST"") %>% 
  select(year, month, departure_station, arrival_station,
         prop_late, dest_country) %>% 
  ggplot(aes(month, prop_late, color = arrival_station, group = arrival_station)) + 
  geom_line() + 
  scale_y_continuous(labels = percent_format()) +
  facet_grid(year ~ dest_country)


frenchtrain_raw %>% 
  filter(service == ""International"",
         #year == 2017,
         str_detect(departure_station, ""PARIS"")) %>% 
  select(-contains(""delay"")) %>% 
  arrange(year, month) %>% 
  mutate(prop_late = num_late_at_departure / total_num_trips,
         year = as_factor(as.character(year)),
         month = as_factor(as.character(month))) %>% 
  mutate(dest_country = case_when(
    arrival_station %in% c(""FRANCFORT"", ""STUTTGART"") ~ ""Allemagne"",
    arrival_station %in% c(""GENEVE"", ""LAUSANNE"", ""ZURICH"") ~ ""Suisse"",
    arrival_station %in% c(""ITALIE"") ~ ""Italie""
  )) %>% 
  #filter(departure_station == ""PARIS EST"") %>% 
  select(year, month, departure_station, arrival_station,
         prop_late, dest_country) %>% 
  ggplot(aes(month, prop_late, color = arrival_station, group = arrival_station)) + 
  geom_line() + 
  scale_y_continuous(labels = percent_format()) +
  facet_wrap(~ dest_country, strip.position = ""bottom"") +
  theme_light() +
  theme(strip.placement = ""outside"")
```



```{r fig.height=4, fig.width=9}
inter_delays <- frenchtrain_raw %>% 
  filter(service == ""International"",
         #year == 2017,
         str_detect(departure_station, ""PARIS"")) %>% 
  select(-contains(""delay"")) %>% 
  arrange(year, month) %>% 
  select(year, month, departure_station, arrival_station,
         num_late_at_departure, total_num_trips) %>% 
  mutate_at(vars(contains(""station"")), str_to_title) %>% 
  mutate(prop_late = num_late_at_departure / total_num_trips,
         year = as_factor(as.character(year)),
         month = as_factor(as.character(month)),
         arrival_station = case_when(
           arrival_station == ""Francfort"" ~ ""Frankfurt"",
           arrival_station == ""Geneve"" ~ ""Geneva"",
           arrival_station == ""Italie"" ~ ""Italy"",
           TRUE ~ arrival_station),
         dest_country = case_when(
           arrival_station %in% c(""Frankfurt"", ""Stuttgart"") ~ ""Germany"",
           arrival_station %in% c(""Geneva"", ""Lausanne"", ""Zurich"") ~ ""Switzerland"",
           arrival_station == ""Italy"" ~ ""Italy""
         )) %>% 
  #mutate(month = fct_reorder(month, month.abb))
  arrange(departure_station, arrival_station) %>% 
  group_by(year) %>% 
  mutate(montho = str_replace(month, ""[0-9]+"", month.abb) %>% as_factor) %>% 
  ungroup() %>% 
  group_by(month, arrival_station) %>% 
  mutate(avg_prop_late = mean(prop_late)) %>% 
  ungroup()

cols <- c(""Geneva"" = ""#9AA199"", ""Lausanne"" = ""#BA514B"", ""Zurich"" = ""#6C9033"",
          ""Frankfurt"" = ""yellow"", ""Stuttgart"" = ""black"",
          ""Italy"" = ""purple"")
  
inter_delays %>% 
  filter(!dest_country == ""Italy"") %>% 
  ggplot(aes(montho, avg_prop_late, color = arrival_station, group = arrival_station)) + 
  geom_line(size = 1.25) + 
  scale_y_continuous(labels = percent_format(), 
                     limits = c(0, NA), 
                     expand = c(0, 0)) +
  scale_color_manual(values = cols) +
  labs(title = str_wrap(""Average delays (as % of all outbound trips) from Paris stations for international destinations"", 70),
       subtitle = glue(""
                       Timeframe: 2015-2018
                       ""),
       caption = glue(""
                       Departure stations: Paris Est and Paris Lyon""),
       x = ""Month"", 
       y = ""Average Delays"") +
  facet_wrap(~ dest_country, strip.position = ""bottom"") +
  ggpomological::theme_pomological_fancy() +
  theme(strip.placement = ""outside"",
        strip.background = element_blank())
  theme_minimal()
```




```{r}
national_delays <- frenchtrain_raw %>% 
  filter(service == ""National"",
         str_detect(departure_station, ""PARIS"")
         ) %>% 
  select(-contains(""delay"")) %>% 
  arrange(year, month) %>% 
  select(year, month, departure_station, arrival_station,
         num_late_at_departure, total_num_trips) %>% 
  mutate_at(vars(contains(""station"")), str_to_title) %>% 
  mutate(prop_late = num_late_at_departure / total_num_trips,
         year = as_factor(as.character(year)),
         month = as_factor(as.character(month))) %>% 
  arrange(departure_station, arrival_station) %>% 
  group_by(year) %>% 
  mutate(montho = str_replace(month, ""[0-9]+"", month.abb) %>% as_factor) %>% 
  ungroup() %>% 
  group_by(month, arrival_station) %>% 
  mutate(avg_prop_late = mean(prop_late)) %>% 
  ungroup()


national_delays <- frenchtrain_raw %>% 
  filter(service == ""National"",
         str_detect(departure_station, ""PARIS"")
         ) %>% 
  select(-contains(""delay"")) %>% 
  arrange(year, month) %>% 
  select(year, month, departure_station, arrival_station,
         num_late_at_departure, total_num_trips) %>% 
  mutate_at(vars(contains(""station"")), str_to_title) %>% 
  mutate(prop_late = num_late_at_departure / total_num_trips,
         year = as_factor(as.character(year)),
         month1 = as_factor(as.character(month))) %>% 
  arrange(departure_station, arrival_station) %>% 
  group_by(year) %>% 
  mutate(montho = str_replace(month1, ""[0-9]+"", month.abb) %>% as_factor) %>% 
  ungroup() %>% 
  group_by(month, arrival_station) %>% 
  summarize(avg_prop_late = mean(prop_late)) %>% 
  ungroup()


national_delays %>% 
  #filter(arrival_station %in% c(""Strasbourg"", ""Quimper"", ""Rennes"", ""Laval"", ""Brest"")) %>% 
  ggplot(aes(month, avg_prop_late, color = arrival_station, group = arrival_station)) + 
  geom_line() + 
  gghighlight::gghighlight(max(avg_prop_late) > 0.15 | min(avg_prop_late) < 0.02) +
  scale_y_continuous(labels = percent_format(), 
                     limits = c(0, NA), 
                     expand = c(0, 0)) +
  #scale_color_manual(values = cols) +
  labs(title = str_wrap(""Average delays (as % of all outbound trips) from Paris stations for domestic destinations"", 70),
       subtitle = glue(""
                       Timeframe: 2015-2018
                       ""),
       caption = glue(""
                       Departure stations: Paris Est and Paris Lyon""),
       x = ""Month"", 
       y = ""Average Delays"") +
  ggpomological::theme_pomological_fancy()


national_delays %>% 
  #filter(arrival_station %in% c(""Strasbourg"", ""Quimper"", ""Rennes"", ""Laval"", ""Brest"")) %>% 
  ggplot(aes(month, avg_prop_late, color = arrival_station, group = arrival_station)) + 
  geom_line() + 
  gghighlight::gghighlight(mean(avg_prop_late) > 0.07, max_highlight = 3) +
  scale_y_continuous(labels = percent_format(), 
                     limits = c(0, NA), 
                     expand = c(0, 0)) +
  scale_x_continuous(expand = c(0, 0),
                     breaks = seq(from = 1, to = 12, by = 1),
                     labels = month.abb) +
  geom_smooth(se = FALSE) +
  #scale_color_manual(values = cols) +
  labs(title = str_wrap(""Average delays (as % of all outbound trips) from Paris stations for domestic destinations"", 70),
       subtitle = glue(""
                       Timeframe: 2015-2018
                       ""),
       caption = glue(""
                       Departure stations: Paris Est and Paris Lyon""),
       x = ""Month"", 
       y = ""Average Delays"") +
  ggpomological::theme_pomological_fancy()
```

","2019"
"95",286,"https://github.com/Amalan-ConStat/TidyTuesday/tree/master/2019/Week8","Amalan-ConStat","TidyTuesday","2019/Week8/phds.Rmd","---
title: ""Week 8 Phds In USA""
author: ""M.Amalan""
date: ""February 19, 2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.width = 12,fig.height = 12,warning = FALSE,message = FALSE)
```


```{r load the packages and data}
# load the packages
library(tidyverse)
library(ggthemr)
library(readr)
library(gganimate)
library(ggridges)
library(ggalluvial)

ggthemr(""flat"")

#load the data
phdlist <- read_csv(""phd_by_field.csv"")
```

Five variables are representing this entire data-set and three of them are factors while 
one column represents the year and the final column is for counts. There are few missing values.
We can focus on Phds awarded from 2008 to 2017 in perspective of Broad Field, Major Field and 
Field.

[Dataset](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-02-19)

Broad Field and Major Field are considered specially but not the column Field as 
it would be difficult to plot based on the amount of categories.

# Broad Field 

Broad field has 7 categories and clearly Psychology and social sciences has produced
more than 4000 Phds each and every year. Which is twice comparing to other categories.
If we drop Psychology and Social sciences, now the changes over the years for other
categories are clear. 

There are more outliers in the field of Life sciences where some programs produce 
more than 1000 Phds each year comparatively to the rest categories. Except Life
sciences other categories tend to behave rarely as above producing more than 1000 Phds.

Engineering field has the lowest distribution with relative to other categories according 
to the box plot in every year.

## All fields

```{r Broad field boxplot}
p<-ggplot(phdlist,aes(x=str_wrap(broad_field,20),y=n_phds))+
          geom_boxplot()+
          xlab(""Broad Field"")+ylab(""No of Phds"")+
          transition_time(year)+ease_aes(""linear"")+
          ggtitle(""Boxplot to Number of Phds in Broad Field"",
              subtitle = ""Year : {round(frame_time)}"")+
          theme(axis.text.x = element_text(hjust=1,angle = 90))

animate(p,nframes=9,fps=1)
```

## Dropping Psychology and Social Sciences

```{r Broad field boxplot without psy and soc sciences}
p<-ggplot(subset(phdlist,broad_field != ""Psychology and social sciences""),
          aes(x=str_wrap(broad_field,20),y=n_phds))+
          geom_boxplot()+
          xlab(""Broad Field"")+ylab(""No of Phds"")+
          transition_time(year)+ease_aes(""linear"")+
          ggtitle(""Boxplot to Number of Phds in Broad Field"",
              subtitle = ""Year : {round(frame_time)}"")+
          theme(axis.text.x = element_text(hjust=1,angle = 90))

animate(p,nframes=9,fps=1)

```


# Major Field

Focus now solely switch towards the Major Field column and here also we can see the strong 
outlier in Psychology over the years. Further, Physics and Astronomy field also has a very
strong outlier where over the years it reaches 2000 Phds.

Without dropping Psychology  we can see the odd behavior from the fields ""Education Research"",
""Economics"" and ""Computer and Information Sciences"". Specially the gradual decrease of 
""Education Research"" from 2008 to 2017.

Also in ""Computer and Information Sciences"" field there is an odd increase in 2012. 

After dropping the ""Psychology"" field we can now clearly see how other Major fields behave
over the years.

## Major Fields with Box plot

```{r major field boxplot}
p<-ggplot(phdlist,aes(x=str_wrap(major_field,20),y=n_phds,fill=broad_field))+
          geom_boxplot()+coord_flip()+
          xlab(""Major Field"")+ylab(""No of Phds"")+
          transition_time(year)+ease_aes(""linear"")+
          ggtitle(""Boxplot to Number of Phds in Major Field"",
              subtitle = ""Year : {round(frame_time)}"")+
          theme(axis.text.x = element_text(hjust=1,angle = 90),
                legend.position = ""bottom"")+
          labs(fill=""Broad Field"")

animate(p,nframes=9,fps=1)
```

## Major Fields without Psychology

```{r Major field without psy}
q<-ggplot(subset(phdlist,major_field != ""Psychology""),
          aes(x=str_wrap(major_field,20),y=n_phds,fill=broad_field))+
          geom_boxplot()+coord_flip()+
          xlab(""Major Field"")+ylab(""No of Phds"")+
          transition_time(year)+ease_aes(""linear"")+
          ggtitle(""Boxplot to Number of Phds in Major Field"",
              subtitle = ""Year : {round(frame_time)}"")+
          theme(axis.text.x = element_text(hjust=1,angle = 90),
                legend.position = ""bottom"")+
          labs(fill=""Broad Field"")

animate(q,nframes=9,fps=1)
```


# Mathematics and Computer Sciences

I am a Statistics student with a glimpse of Computer science background, therefore my
next intention is to focus on the Broad Field ""Mathematics and Compute Sciences"". 

## Mathematics and Computer Science as a Broad field

Mathematics and Statistics has a gradual increase until 2012, but wavers higher and lower 
in the next years, but in 2016 there is a sudden increase of which would lead to around 700 
Phds awarded. Next year this decreases to 500 Phds. 

Comparing the 2 major fields ""Computer and Information Sciences"" with ""Mathematics and Statistics""
indicate the strong gap between them awarding Phds. ""Computer and Information Sciences"" award 
more than twice the amount of Phds what ""Mathematics and Statistics"" award each year.

""Computer and Information Sciences"" also hold a clear pattern with the Phds awarded.

```{r mathematics and cs bar chart}
subset(phdlist,broad_field == ""Mathematics and computer sciences"") %>%
      
ggplot(.,aes(x=factor(year),y=n_phds,fill=major_field))+
       geom_bar(stat=""identity"",position = ""dodge"")+
       theme(legend.position = ""bottom"")+
       xlab(""Major Field"")+ylab(""Number of Phds"")+
       ggtitle(""Number of Phds awarded under Mathematics and CS"",
               subtitle = ""Year : 2008 to 2017"")+
      scale_y_continuous(breaks=seq(0,1700,100),labels=seq(0,1700,100))+
          labs(fill=""Major Field"")
       
```


## Major Field for Mathematics and Computer Science

Box plot indicates the clear variation among these two major fields over years which 
could be used for comparison. The sudden peak in year 2012 for ""Computer and Information Sciences""
interests me alot. It should be noted that ""Mathematics and Statistics"" has more outliers 
than ""Computer and Information Sciences"".

```{r major field boxplot with maths and cs}
p<-ggplot(subset(phdlist,broad_field == ""Mathematics and computer sciences""),
          aes(x=str_wrap(major_field,20),y=n_phds))+
          geom_boxplot()+
          xlab(""Major Field"")+ylab(""No of Phds"")+
          transition_time(year)+ease_aes(""linear"")+
          ggtitle(""Boxplot to Number of Phds in Major Field"",
              subtitle = ""Year : {round(frame_time)}"")

animate(p,nframes=9,fps=1)
```

Below is a ridge plot to describe the same thing which would clearly indicate the data spread.

```{r ridge major fields}
ggplot(subset(phdlist,broad_field == ""Mathematics and computer sciences""),
          aes(y=str_wrap(major_field,20),x=n_phds))+
          geom_density_ridges()+
          xlab(""No of Phds"")+ ylab(""Major Field"")+
          theme(legend.position = ""bottom"")+
          ggtitle(""Ridge plot for Major Fields in Mathematics and Computer Sciences"",
                  subtitle = ""Year : 2008 to 2017"")
```

##  Fields for Major Field Mathematics and Computer Science

considering the sub categories of the chosen broad field in a box plot did not
work quite well, but Computer Science phds being awarded with highest amount would
indicate the boom of Artificial Intelligence.

```{r field boxplot with maths and cs}
p<-ggplot(subset(phdlist,broad_field == ""Mathematics and computer sciences""),
          aes(x=str_wrap(field,20),y=n_phds,fill=major_field))+
          geom_boxplot()+coord_flip()+
          xlab(""Field"")+ylab(""No of Phds"")+
          transition_time(year)+ease_aes(""linear"")+
          ggtitle(""Boxplot to Number of Phds in Field"",
              subtitle = ""Year : {round(frame_time)}"")+
          theme(legend.position = ""bottom"")+
          labs(fill=""Major Field"")

animate(p,nframes=9,fps=1)

```

To get a clear view here is the ridge plot, where Computer Science is very strong for 
""Computer and Information Sciences"". It should be noted though there is only three other 
fields in this major field which are ""Information Science systems"", 
""Computer and Information Sciences, other"" and ""Computer and Information sciences, general"".

More than 10 fields for the Major field ""Mathematics and Statistics"", where higher counts 
occur to ""Statistics(Mathematics)"", ""Applied mathematics"" and ""Mathematics and Statistics,general"".
Still non of these fields have passed the 1000 Phds awarded mark.

```{r ridge plot fields}
ggplot(subset(phdlist,broad_field == ""Mathematics and computer sciences""),
          aes(y=str_wrap(field,20),x=n_phds,fill=major_field))+
          geom_density_ridges()+
          xlab(""No of Phds"")+ ylab(""Field"")+
          theme(legend.position = ""bottom"")+
          ggtitle(""Ridge plot for Fields in Mathematics and Computer Sciences"",
                  subtitle = ""Year : 2008 to 2017"")+
          labs(fill=""Major Field"")
```

# Major Field, Field For Mathematics and Computer Sciences

Finally an alluvial diagram just to look at the impact of Computer science field with 
respective to each year and major field.

```{r broad and major and field}
data.frame(subset(phdlist,broad_field==""Mathematics and computer sciences"")) %>%
           na.omit() %>%
ggplot(.,aes(axis2=factor(str_wrap(year,10)), axis1= factor(str_wrap(major_field,10)), 
             axis3= factor(field), y=as.numeric(n_phds)))+
       scale_x_discrete(limits=c(""Major Field"",""Year"",""Field""),expand = c(.05, .05))+
       geom_alluvium(aes(fill=factor(major_field)),width = 1/2)+
       geom_stratum(width=1/2,fill=""white"",color=""grey"")+
       geom_text(stat = ""stratum"", label.strata = TRUE)+
       theme(legend.position = ""bottom"")+ylab(""No of Phds"")+
       ggtitle(""Major Field and Fields For Years 2008 to 2017"",
               subtitle=""Mathematics and Computer Science"")+
          labs(fill=""Major Field"")
```


*THANK YOU*","2019"
"96",287,"https://github.com/Amalan-ConStat/TidyTuesday/tree/master/2019/Week9","Amalan-ConStat","TidyTuesday","2019/Week9/Week_9_French_Trains.Rmd","---
title: ""Week 9 French Trains""
author: ""M.Amalan""
date: ""February 26, 2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE,fig.width = 12,fig.height = 12)
```

```{r load the data and packages}
library(readr)
library(tidyverse)
library(gganimate)
library(ggalluvial)
library(geomnet)
library(ggthemr)

ggthemr(""fresh"")

full_trains <- read_csv(""full_trains.csv"")
small_trains <- read_csv(""small_trains.csv"")
```

# Network Graph for the French City Trains

```{r network graph, fig.width= 14,fig.height=14}
ggplot(small_trains,aes(from_id=departure_station,to_id=arrival_station))+
          geom_net(directed = TRUE,labelon = TRUE,size=0.5,labelcolour = ""black"",
                   repel = FALSE,ecolour = ""grey70"", arrowsize = 0.75,
                   linewidth = 0.5,layout.alg = ""fruchtermanreingold"")+
          theme_net()+
          ggtitle(""Network Graph Showing from City to City of French Trains"")

```

# Paris Montparnasse

# Chosen City with Total Number of Trips

```{r Paris Montparnasse total num of trips}
p<-ggplot(subset(small_trains,departure_station==""PARIS MONTPARNASSE""),
       aes(x=str_wrap(arrival_station,20),y=total_num_trips,color=month))+
       geom_jitter()+coord_flip()+ labs(color=""Month"")+
       transition_time(year)+ease_aes(""linear"")+
       scale_y_continuous(breaks = seq(0,800,100),labels=seq(0,800,100))+
       ylab(""Arrival Station"")+xlab(""Total Number of Trips"")+
       ggtitle(""Paris Montparnasse and its arrival Station"" ,subtitle =""Year :{frame_time}"")

animate(p,nframes=4,fps=1)
```

# Chosen City with Average Journey Time

```{r Paris Montparnasse Journey time average}
p<-ggplot(subset(small_trains,departure_station==""PARIS MONTPARNASSE""),
       aes(x=str_wrap(arrival_station,20),y=journey_time_avg,color=month))+
       geom_jitter()+coord_flip()+ labs(color=""Month"")+
       transition_time(year)+ease_aes(""linear"")+
       xlab(""Arrival Station"")+ylab(""Average Journey Time"")+
       ggtitle(""Paris Montparnasse and its arrival Station"" ,subtitle =""Year :{frame_time}"")

animate(p,nframes=4,fps=1)
```

# Chosen City with Average Delay with All Departing

```{r Paris Montparnasse avg delay all departing}
p<-ggplot(subset(small_trains,departure_station==""PARIS MONTPARNASSE""),
       aes(x=str_wrap(arrival_station,20),y= avg_delay_all_departing,color=month))+
       geom_jitter()+coord_flip()+ labs(color=""Month"")+
       transition_time(year)+ease_aes(""linear"")+
       geom_hline(yintercept = 0,color=""red"")+
       xlab(""Arrival Station"")+ylab(""Average Delay All Departing"")+
       ggtitle(""Paris Montparnasse and its arrival Station"" ,subtitle =""Year :{frame_time}"")

animate(p,nframes=4,fps=1)
```

# Chosen City with Average Delay with All Arriving

```{r Paris Montparnasse avg delay all arriving}
p<-ggplot(subset(small_trains,departure_station==""PARIS MONTPARNASSE""),
       aes(x=str_wrap(arrival_station,20),y=avg_delay_all_arriving,color=month))+
       geom_jitter()+coord_flip()+ labs(color=""Month"")+
       transition_time(year)+ease_aes(""linear"")+
       geom_hline(yintercept = 0,color=""red"")+
       xlab(""Arrival Station"")+ylab(""Average Delay All Arriving"")+
       ggtitle(""Paris Montparnasse and its arrival Station"" ,subtitle =""Year :{frame_time}"")

animate(p,nframes=4,fps=1)
```

# Chosen City with Number of Late Departures

```{r Paris Montparnasse num late at departure}
p<-ggplot(subset(small_trains,departure_station==""PARIS MONTPARNASSE""),
       aes(x=str_wrap(arrival_station,20),y=num_late_at_departure,
           color=month))+
       geom_jitter()+coord_flip()+ labs(color=""Month"")+
       transition_time(year)+ease_aes(""linear"")+
       xlab(""Arrival Station"")+ylab(""Number of Lates at Departure"")+
       ggtitle(""Paris Montparnasse and its arrival Station"" ,subtitle =""Year :{frame_time}"")

animate(p,nframes=4,fps=1)
```

# Chosen City with Number of Late Arrivals

```{r Paris Montparnasse num arriving late}
p<-ggplot(subset(small_trains,departure_station==""PARIS MONTPARNASSE""),
       aes(x=str_wrap(arrival_station,20),y=num_arriving_late,
           color=month))+
       geom_jitter()+coord_flip()+ labs(color=""Month"")+
       transition_time(year)+ease_aes(""linear"")+
       xlab(""Arrival Station"")+ylab(""Number of Lates at Arriving"")+
       ggtitle(""Paris Montparnasse and its arrival Station"" ,subtitle =""Year :{frame_time}"")

animate(p,nframes=4,fps=1)
```

# Departure Station with Average Journey Time and Total Number of Trips

```{r departure station with journey time avg and total num trips}
p<-ggplot(small_trains,aes(x=journey_time_avg,y=total_num_trips,color=month))+
      geom_point()+transition_states(departure_station)+labs(color=""Month"")+
      ggtitle(""Average Journey Time and Total Number of Trips"",
              subtitle=""Departure Station : {closest_state}"")+
      scale_y_continuous(breaks=seq(0,900,50),labels=seq(0,900,50))+
      scale_x_continuous(breaks=seq(0,500,50),labels=seq(0,500,50))+  
      xlab(""Average Journey Time"")+ylab(""Total Number of Trips"")+
      shadow_mark()

animate(p,nframes=59,fps=1)
```

# Departure Station with Average Delay All Departing and Number of Late at Departures

```{r departure station with Number of late and average Delay}
p<-ggplot(small_trains,aes(x=num_late_at_departure,y=avg_delay_all_departing,
                           color=month))+
      geom_point()+transition_states(departure_station)+labs(color=""Month"")+
      ggtitle(""Average Delay at All Departing and Number of Lates at Departure"",
              subtitle=""Departure Station : {closest_state}"")+
      geom_vline(xintercept = 0,color=""red"")+
      geom_hline(yintercept = 0,color=""red"")+
      scale_y_continuous(breaks=seq(-5,175,5),labels=seq(-5,175,5))+
      scale_x_continuous(breaks=seq(0,500,50),labels=seq(0,500,50))+  
      xlab(""Number of Lates at Departure"")+ylab(""Average Delays at all Departing"")+
      shadow_mark()

animate(p,nframes=59,fps=1)
```

# Departure Station with Average Delay All Arriving and Number of Arriving Late

```{r departure station with Number of Arriving late and average Delay arriving}
p<-ggplot(small_trains,aes(x=num_arriving_late,y=avg_delay_all_arriving,
                           color=month))+
      geom_point()+transition_states(departure_station)+labs(color=""Month"")+
      ggtitle(""Average Delay at All Arriving and Number of Lates at Arriving"",
              subtitle=""Departure Station : {closest_state}"")+
      geom_vline(xintercept = 0,color=""red"")+
      geom_hline(yintercept = 0,color=""red"")+
      scale_y_continuous(breaks=seq(-150,40,5),labels=seq(-150,40,5))+
      scale_x_continuous(breaks=seq(0,250,25),labels=seq(0,250,25))+  
      xlab(""Number of Lates at Arriving"")+ylab(""Average Delays at all Arriving"")+
      shadow_mark()

animate(p,nframes=59,fps=1)
```

# Delayed Cause and Delayed Number 

```{r Delayed No and Delayed cause}
small_trains %>%
    mutate(delay_cause = str_remove(delay_cause,""delay_cause_"")) %>%
ggplot(.,aes(x=delay_cause,y=delayed_number))+
      xlab(""Delay Cause"")+ylab(""Delayed Number"")+
      ggtitle(""Delayed Causes and Delayed Number as percentage"")+
      geom_jitter()+coord_flip()
```

","2019"
"97",290,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 03-09-2019.R","
# Database ----------------------------------------------------------------



cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")



# Packages to upload ------------------------------------------------------

library(tidyverse)
library(sunburstR)

SB2<-cpu%>%
  mutate(path2 = paste(date_of_introduction, designer, process, area, sep=""-"")) %>%
  filter(date_of_introduction %in% c(2005:2019)) %>%
  select(path2, transistor_count) 


SB_2 <- as.data.frame(sapply(SB2,gsub,pattern=""-NA-NA"",replacement=""""))
SB_2 <- as.data.frame(sapply(SB2,gsub,pattern=""-NA"",replacement=""""))


p2 <- sunburst(SB_2, legend=FALSE)
p2


# Alternative -------------------------------------------------------------


sb3 <- sund2b(SB_2, width=""100%"")




# Data checking -----------------------------------------------------------


SByear<-cpu%>% group_by(date_of_introduction)%>%
  summarise(count=sum(transistor_count))
","2019"
"98",291,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 04-11-2019.R","# Upload the data ---------------------------------------------------------

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

# Upload packages ---------------------------------------------------------

library(readxl)
library(tidyverse)
library(readxl)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggalt)
library(scales)
library(hrbrthemes)


View(commute_mode)

# Prepare the data --------------------------------------------------------


data<-commute_mode %>% group_by(state_region,mode)%>%summarize(total=sum(n)) %>% spread(mode,total) %>%
 mutate (diff=round(Walk-Bike,1),
            label=ifelse(diff>0, paste0(""+"",comma_format()(diff)), paste0(diff))) %>%
  filter(state_region!=""NA"")






# Ggplot ------------------------------------------------------------------


g<-ggplot(data, aes(x = Walk, xend = Bike, y=reorder(state_region,Walk))) + 
  geom_dumbbell(colour = ""#dddddd"",
                size = 3,
                colour_x = ""#228b34"",
                colour_xend = ""#1380A1"")+
  labs(
    title = ""Bicycling and Walking to Work in the United States: 2008-2012"",
    subtitle = ""Number of commuters and difference by Region"",
    caption = ""\n Source:Tidy Tuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") + theme(legend.position = ""bottom"",
                    legend.box = ""vertical"")  + 
  geom_text(data = filter(data, state_region == ""Northeast""),
                                                          aes(x = Walk, y = state_region),
                                                          label = ""Walk"", fontface = ""bold"",
                                                          size=3,
                                                          color = ""#e13d3d"",
                                                          vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""Northeast""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""West""),
            aes(x = Walk, y = state_region),
            label = ""Walk"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""West""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8)+
  geom_text(data = filter(data, state_region == ""North Central""),
            aes(x = Walk, y = state_region),
            label = ""Walk"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""North Central""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""South""),
            aes(x = Walk, y = state_region),
            label = ""Walk"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""South""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8)
  

g2<-g + 
  geom_rect(aes(xmin=950000, xmax=1150000, ymin=-Inf, ymax=Inf), fill=""#d3d3d3"") +
  geom_text(aes(label=label, y=state_region, x=1050000), fontface=""bold"", size=3.5, color=""#008000"") +
  geom_text(aes(x=1050000, y=4.03, label=""Number of commuters""),
            size=3.5, vjust=-3, fontface=""bold"") +
  scale_x_continuous(breaks = c(100000, 300000, 500000, 700000), limits = c(-1, 1150000), label=comma_format()) + 
  theme_ipsum_rc(grid=""XY"")


g2 + geom_label(aes(x = 612611, y = 3.7, label = ""Northeast: Highest number of commuters who walked to work""), 
           hjust = 0, 
           vjust = 0.5, 
           lineheight = 0.8,
           colour = ""#648aed"", 
           fill = ""#f7f7f7"", 
           label.size = NA, 
           family=""Helvetica"", 
           size = 3) +theme(legend.position = ""top"",
                            legend.box = ""horizontal"",
                            plot.background=element_rect(fill=""#f7f7f7""))

","2019"
"99",292,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 05-08-2019.R","
# Upload the data ---------------------------------------------------------

bob_ross <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")
str(bob_ross)
colnames(bob_ross)
View(bob_ross)


# Data wrangling ----------------------------------------------------------


library(tidyverse)
test<-bob_ross%>%gather(Painting,value,3:69) %>%group_by(Painting)%>%summarise(total=sum(value))%>% arrange(total)

View(test)

test10<-top_n(test,10)


# Data visualization ------------------------------------------------------

library(hrbrthemes)
ggplot<-test10 %>% ggplot( aes(x=reorder(Painting,total), y=total)) +
  geom_bar(stat=""identity"", fill=""#69b3a2"", width=0.6) +
  coord_flip() +
  
  theme_ipsum() +
  
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.text = element_text(hjust = 0.5)
  ) + ylab(""total"") +
  xlab(""Paiting"") +
  labs(
    title = ""Bob Ross - painting by the numbers - Top 10"",
    subtitle = ""TidyTuesday 5.8.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") 




ggplot+geom_text(aes(label=total),hjust=-0.5) 
","2019"
"100",293,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 07-5-2019.R","
# Upload the data ---------------------------------------------------------

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")


# Create average student ratio ---------------------------------------------

library(dplyr)
student_ratio<-student_ratio%>%group_by(country)%>%mutate(mean = mean(student_ratio, na.rm = TRUE))


# Prepare the colour palette ----------------------------------------------


library(plotly)

# light grey boundaries
l <- list(color = toRGB(""grey""), width = 0.5)

# specify map projection/options
g <- list(
  showframe = FALSE,
  showcoastlines = FALSE,
  projection = list(type = 'Mercator')
)


# Plotly graph ------------------------------------------------------------



p <- plot_geo(student_ratio) %>%
  add_trace(
    z = ~student_ratio, color = ~student_ratio, colors = 'Blues',
    frame = ~year, 
    text =  ~paste('</br> Country: ', country,
                     '</br> Year: ', year,
                     '</br> Global Student to Teacher Ratios(%): ', round(student_ratio,2)), 
    
    
    hoverinfo = ""text""
  , locations = ~country_code, marker = list(line = l)
  ) %>%
  colorbar(title = 'Global Student to Teacher Ratios') %>%
  layout(
    title = 'Global Student to Teacher Ratios<br><a href=""http://data.uis.unesco.org/index.aspx?queryid=180"">UNESCO Institute of Statistics</a>',
    annotations = 
      list(text = ""#TidyTuesday 07.05.2019<br>@Juanma_MN"", 
           showarrow = F, xref='paper', yref='paper', 
           xref = 'paper', x = 0,
           yref = 'paper', y = 1,
           font=list(size=10, color=""black"")),
    geo = g
  )

p


","2019"
"101",294,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 13-8-2019.R","
# Upload the data ---------------------------------------------------------

library(ggplot2)
library(hrbrthemes)

library(gridExtra)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

View(emperors)

colnames(emperors)
str(emperors)

library(dplyr)
library(lubridate)


# Calculate the reign length ----------------------------------------------

reign_start <- as.POSIXct(emperors$reign_start, format = ""%Y-%m-%d"")
reign_end<- as.POSIXct(emperors$reign_end, format = ""%Y-%m-%d"")
View(emperors)


empeorers2<-emperors %>% mutate(elapsed_time = (reign_start %--% reign_end)/ddays(1)) %>% select(""name"", ""reign_start"",
                                                                                                 ""reign_end"", ""elapsed_time"", ""rise"",""cause"",""killer"",""dynasty"",""era"")
View(emperors)
View(empeorers2)


empeorers3<-empeorers2%>%group_by(dynasty)%>%summarize(average=round(sum(elapsed_time),0))    # for first graph




empeorers4<-empeorers2%>%group_by(dynasty,rise)%>%summarize(average=round(sum(elapsed_time),0)) %>%
  arrange(-average)   # for second graph





# First graph -------------------------------------------------------------



g<- ggplot(empeorers3, aes(x=reorder(dynasty,average), y=average)) +
  geom_bar(stat=""identity"", fill=""#69b3a2"", width=0.6) +
  coord_flip() +
  
  theme_ipsum() +
  
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.text = element_text( size=48 )
  ) +
  
  ylim(0,60000) +
  
  ylab(""Total time in days"") +
  
  xlab("""") +
  
  labs(
    title = ""Roman Emperors Dataset"",
    subtitle = ""Total length of reign by dynasty (in days)"",
    caption = ""\n Source: TidyTuesday 13.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")

g1<-g + geom_text(aes(label=average),hjust=-0.5) 



# Second graph --------------------------------------------------------------




g2<- ggplot(empeorers4, aes(reorder(dynasty,average))) +
  geom_bar(aes(y = average, fill = rise),stat=""identity"") +
  scale_fill_brewer(palette = ""Set3"") +
  coord_flip() +
  theme_ipsum()   + 
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position=""bottom"",
    axis.text = element_text( size=48 )
  ) +
  ylim(0,60000) +
  ylab(""Total time in days"") +
  xlab("""") +
  
  labs(
    title = ""Roman Emperors Dataset"",
    subtitle = ""Total length of reign by dynasty (in days)"",
    caption = ""\n Source: TidyTuesday 13.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")




grid.arrange(g1,g2, ncol=2)

","2019"
"102",295,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 14-08-2019.R","# Upload the data ---------------------------------------------------------

library(ggplot2)
library(hrbrthemes)
library(dplyr)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")




# Calculate the reign length ----------------------------------------------

reign_start <- as.POSIXct(emperors$reign_start, format = ""%Y-%m-%d"")
reign_end<- as.POSIXct(emperors$reign_end, format = ""%Y-%m-%d"")



empeorers2<-emperors %>% mutate(elapsed_time = (reign_start %--% reign_end)/ddays(1)) %>% select(""name"", ""reign_start"",
                                                                                                 ""reign_end"", ""elapsed_time"", ""rise"",""cause"",""killer"",""dynasty"",""era"")


empeorers4<-empeorers2%>%group_by(dynasty,rise)%>%summarize(total=round(sum(elapsed_time),0)) %>%
  arrange(-total)   # for second graph



# Order the column by total -----------------------------------------------


empeorers4$dynasty <- factor(empeorers4$dynasty, levels = c(""Theodosian"",""Flavian"",""Julio-Claudian"",""Severan"",""Gordian"", ""Valentinian"", 
                                                            ""Nerva-Antonine"",""Constantinian""))




g2<- ggplot(empeorers4, aes(dynasty)) +
  geom_bar(aes(y = total, fill = rise),stat=""identity"") +
  scale_fill_brewer(palette = ""Set3"") +
  coord_flip() +
  theme_ipsum_tw()  + 
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position=""bottom"",
    axis.text = element_text( size=48 )
  ) +
  ylim(0,60000) +
  ylab(""Total time in days"") +
  xlab("""") +
  
  labs(
    title = ""Roman Emperors Dataset"",
    subtitle = ""Total length of reign by dynasty (in days)"",
    caption = ""\n Source: TidyTuesday 14.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")
g2
","2019"
"103",296,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 14-10-2019.R","# Upload the data ---------------------------------------------------------

big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")


# Upload packages ---------------------------------------------------------

library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggalt)
library(scales)
library(hrbrthemes)


# Prepare the data --------------------------------------------------------


Electric_car<-big_epa_cars %>% filter(fuelType1 == ""Electricity"") %>% group_by(make)%>% select(make, cityE,highwayE) %>%
  summarise(avg_city_consumption=round(mean(cityE,na.rm=TRUE),1),
            avg_highway_consumption=round(mean(highwayE,na.rm=TRUE),1)) %>% na.omit()




# dumbbell graph ----------------------------------------------------------


ggplot(Electric_car, aes(x = avg_city_consumption, xend = avg_highway_consumption, y=reorder(make,avg_city_consumption))) + 
  geom_dumbbell(colour = ""#e5e5e5"",
                size = 3,
                colour_x = ""#228b34"",
                colour_xend = ""#1380A1"")+
  theme_ipsum_rc()  +
  labs(
    title = ""Electric vehicles - Average City VS Highway consumption"",
    subtitle = ""TidyTuesday 14.10.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = ""Consumption in kw-hrs/100 miles"",
    y = """") + theme(legend.position = ""top"",
                    legend.box = ""horizontal"",
                    plot.background=element_rect(fill=""#f7f7f7"")) +
 geom_text(data = filter(Electric_car, make == ""Plymouth""),
            aes(x = avg_highway_consumption, y = make),
            label = ""Highway"", fontface = ""bold"",
            color = ""#395B74"",
            vjust = 4) +
  geom_text(data = filter(Electric_car, make == ""Plymouth""),
            aes(x = avg_city_consumption, y = make),
            label = ""City"", fontface = ""bold"",
            color = ""#228b34"",
            vjust = 4)


","2019"
"104",297,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 14-5-2019.R","
# Upload the data ---------------------------------------------------------

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
View(nobel_winners)


# Upload the necessary packages -------------------------------------------

library(dplyr)
library(plotly)


# Prepare the data for plotly ---------------------------------------------

test<-nobel_winners%>%mutate(birth_year= format(birth_date,'%Y'))
View(test)

test_2<-test %>% mutate(winning_age=(as.numeric(prize_year)-as.numeric(birth_year))) %>% select(full_name,winning_age)

View(test_2)
test_3<-test_2 %>%   mutate(
    decade=case_when(
      test_2$winning_age %in% 10:20 ~ ""10-20"",
      test_2$winning_age %in% 21:30 ~ ""21-30"",
      test_2$winning_age %in% 31:40 ~ ""31-40"",
      test_2$winning_age %in% 41:50 ~ ""41-50"",
      test_2$winning_age %in% 51:60 ~ ""51-60"",
      test_2$winning_age %in% 61:70 ~ ""61-70"",
      test_2$winning_age  %in% 71:80 ~ ""71-80"",
      test_2$winning_age  %in% 81:90 ~ ""81-90"",
      test_2$winning_age %in% 91:100 ~ ""91-100"",
      TRUE ~ as.character(test_2$winning_age)
    )
  ) %>% group_by(decade) %>%
  summarize(n=n(), na.rm=TRUE)%>%  select(decade, n)

test_4<-test_3%>%filter(decade != ""NA"")
View(test_4)


# Plotly ------------------------------------------------------------------


t <- list(
  family = ""sans serif"",
  size = 16,
  color = 'black')
m <- list(
  l = 50,
  r = 50,
  b = 100,
  t = 100,
  pad = 4
)
p_3 <- plot_ly(test_4,
             y = ~n,
             x = ~decade,
             type = ""bar"",   
             text =  ~paste('</br> Age range: ', decade,
                            '</br> Total number of winners: ', round(n,2)),
             hoverinfo = ""text"",
             marker = list(color = 'rgb(158,202,225)',
                           line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
  layout(title = ""Nobel prize winners - Age Range"", font=t, autosize = F, width = 800, height = 600, margin = m)%>%
  layout(
    xaxis = list(title = """"),
    yaxis = list(title = """"),
    annotations = 
      list(text = ""#TidyTuesday 14.05.2019<br>@Juanma_MN"", 
           showarrow = F, xref='paper', yref='paper', 
           xref = 'paper', x = 0,
           yref = 'paper', y = 1.2,
           font=list(size=8, color=""black""))) %>%
  layout(
    
    annotations = 
      list(text = ""There are 31 winners with no date of birth"", 
           showarrow = F, xref='paper', yref='paper', 
           xref = 'paper', x = 1,
           yref = 'paper', y = -0.2,
           font=list(size=10, color=""black"")))
    
p_3



","2019"
"105",298,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 17-7-2019.R","
# Upload file -------------------------------------------------------------

library(readr)
r4ds_members <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")
View(r4ds_members)
colnames(r4ds_members)



# Upload packages ---------------------------------------------------------

library(ggplot2)
library(tidyverse)
library(lubridate)
library(dplyr)



# Data wrangling ----------------------------------------------------------

a1<-r4ds_members%>%mutate(month=format(r4ds_members$date,""%B""))%>% select(-1)%>%
  group_by(month)%>%
  summarise(total_membership=sum(total_membership),
            total_full_members= sum(full_members),
            total_daily_active_members= sum(daily_active_members),
            total_messages_in_public_channels= sum(messages_in_public_channels),
            total_messages_in_private_channels= sum(messages_in_private_channels),
            total_messages_in_d_ms= sum(messages_in_d_ms)) 


# Prepare the data for heatmap --------------------------------------------

a1<-a1[c(5,4,8,1,9,7,6,2,12,11,10,3),]
View(a1)

## add and index column
a1_2 <-a1  %>% mutate(id = row_number())

## Pass the first column to the number
library(dplyr)
a1_2 <- a1[, -(1)]
View(a1_2)

rownames(a1_2) <- a1$month



# heatmap -----------------------------------------------------------------


library(d3heatmap)

d3heatmap(a1_2, scale = ""column"", colors = ""GnBu"", dendrogram = ""none"", 
          
          xaxis_font_size = ""6pt"", yaxis_font_size = ""7pt"", 
          xaxis_height = 160, yaxis_width = 160,
          theme= ""dark"",
          show_grid = TRUE,
          brush_color = ""#0000FF"")

# https://rdrr.io/github/rstudio/d3heatmap/man/d3heatmap.html




","2019"
"106",299,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 17-9-2019.R","# Upload the data ---------------------------------------------------------

park_visits <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-17/national_parks.csv"")



# Packages to upload ------------------------------------------------------



library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(scales)
library(tidyverse)
library(streamgraph)
library(viridis)
library(hrbrthemes)
library(plotly)



# First graph - Multipoint ------------------------------------------------



park_visits1<-park_visits%>% 
  filter(parkname %in% c(""Gateway"",""George Washington Memorial Parkway"", ""Golden Gate"", ""Lake Mead"", ""Natchez Trace"") &
           year %in% c( ""1980"", ""1995"", ""2015"")) %>%
  select(year,parkname,visitors)%>% 
  spread(year,visitors)


View(park_visits1)


park_visits1$parkname <- factor(park_visits1$parkname, levels = c(""Natchez Trace"",
                                                                  ""George Washington Memorial Parkway"",
                                                                  ""Gateway"",
                                                                  ""Lake Mead"",
                                                                  ""Golden Gate""
))



names(park_visits1)[2]<-""Second""
names(park_visits1)[3]<-""Third""
names(park_visits1)[4]<-""Fourth""

ggplot() +
  
  geom_segment(
    data = gather(park_visits1, measure, val, -parkname) %>% 
      group_by(parkname) %>% 
      top_n(-1) %>% 
      slice(1) %>%
      ungroup(),
    aes(x = 4000000, xend = 20000000, y = parkname, yend = parkname),
    linetype = ""blank"", size = 0.3, color = ""gray80""
  ) +
  
  geom_segment(
    data = gather(park_visits1, measure, val, -parkname) %>% 
      group_by(parkname) %>% 
      summarise(start = range(val)[1], end = range(val)[2]) %>% 
      ungroup(),
    aes(x = start, xend = end, y = parkname, yend = parkname),
    color = ""gray80"", size = 2
  ) +
  # reshape the data frame & plot the points
  geom_point(
    data = gather(park_visits1, measure, value, -parkname),
    aes(value, parkname, color = measure), 
    size = 4
  )  + 
  geom_text(data = filter(park_visits1, parkname== ""Lake Mead""),
            aes(x = Second, y = parkname),
            label = ""2000"", fontface = ""bold"",
            color = ""#F7BC08"",
            vjust = -2) +
  geom_text(data = filter(park_visits1, parkname == ""Lake Mead""),
            aes(x = Third, y = parkname),
            label = ""2005"", fontface = ""bold"",
            color = ""#F7BC08"",
            vjust = -2)  +
  geom_text(data = filter(park_visits1, parkname == ""Lake Mead""),
            aes(x = Fourth, y = parkname),
            label = ""2015"", fontface = ""bold"",
            color = ""#F7BC08"",
            vjust = -2) +
  theme_ft_rc()+
  labs(
    title = ""National Park Visits"",
    subtitle = ""TidyTuesday 17.9.2019 - Top 5 parks by total number of visitors"",
    caption = ""Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = ""Number of visitors"",
    y = """")   + theme(legend.position="""") + theme(legend.title = element_blank()) +
  scale_x_continuous(label = unit_format(unit = ""m"", scale = 1e-6), breaks=c(5000000,10000000,15000000,20000000))







# area --------------------------------------------------------------------

park_visitArea<-park_visits%>% 
  filter(parkname %in% c(""Gateway"",""George Washington Memorial Parkway"", ""Golden Gate"", ""Lake Mead"", ""Natchez Trace"") &
           year %in% c(1950:2016)) %>%
  select(year,parkname,visitors)



park_visitArea$year<-as.numeric(park_visitArea$year)
#park_visitArea$visitors<-comma_format()(park_visitArea$visitors)

?comma_format

p2 <- park_visitArea%>% 
  ggplot(aes(x=year, y=visitors, fill=parkname, 
             text =paste(""Park name:"", parkname))) +
  geom_area() +
  scale_fill_viridis(discrete = TRUE)  +
  theme_ipsum() +
  theme(legend.position=""none"")  +
  scale_y_continuous(label = unit_format(unit = ""m"", scale = 1e-6))+
  scale_x_continuous(breaks=c(1950,1970,1990, 2010, 2016))+
  labs(
    title = ""National Park - Top 5 by Number of visitors"",
    subtitle = ""TidyTuesday 17.9.2019 - Top 5 parks by number of visitors"",
    caption = ""Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette=""YlGnBu"")




ggplotly(p2, tooltip=c(""text"",""x"", ""y""))
","2019"
"107",300,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 19-08-2019 (2).R","
# First ggridges ----------------------------------------------------------

nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")


# Upload the necessary packages -------------------------------------------

library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(dplyr)


test4<-nuclear_explosions%>%group_by(country,year)%>% filter(country %in% c(""CHINA"", ""FRANCE"", ""UK"", ""USA"", ""USSR"")) %>%
  summarize(total=n()) 

View(test4)


# ggplot ------------------------------------------------------------------


ggplot(test4, aes(x=year,y= reorder(country,desc(country)), fill = country, group = country)) +
  geom_density_ridges2(scale = 0.8)  + 
  scale_color_ipsum() +
  theme_ipsum_rc()+
  labs(
    title = ""Nuclear Explosions"",
    subtitle = ""TidyTuesday 19.8.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette = ""Spectral"") + theme(legend.position = """",
                                                  legend.box = """") +
  scale_x_continuous(
    limits = c(1940, 2005),
    expand = c(0, 0)
  )








","2019"
"108",301,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 19-08-2019.R","# Upload the dataset ------------------------------------------------------

nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")


# Upload the necessary packages -------------------------------------------

library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(dplyr)
library(plotly)
library(scales)

#change to decade to make the ""group_by"" functiom better.

nuclear_explosions$year[nuclear_explosions$year%in% c(1940:1949)] <- ""1940-1949""
nuclear_explosions$year[nuclear_explosions$year%in% c(1950:1959)] <- ""1950-1959""
nuclear_explosions$year[nuclear_explosions$year%in% c(1960:1969)] <- ""1960-1969""
nuclear_explosions$year[nuclear_explosions$year%in% c(1970:1979)] <- ""1970-1979""
nuclear_explosions$year[nuclear_explosions$year%in% c(1980:1989)] <- ""1980-1989""
nuclear_explosions$year[nuclear_explosions$year%in% c(1990:1999)] <- ""1990-1999""
View(nuclear_explosions)



test2<-nuclear_explosions%>%group_by(country,year)%>%
  summarize(total=n())



# Plotly ------------------------------------------------------------------


p <- plot_ly(test2, x = ~year, y = ~total, type = 'bar', color = ~country, name = ~country,
             text =  ~paste('</br> Country: ', country,
                            '</br> Decade: ', year,
                            '</br> Nuclear Explosions: ', comma_format()(total)),
             hoverinfo = ""text"") %>%
  layout(yaxis = list(title = ''), 
         xaxis = list(title = ''),
         barmode = 'stack')%>%
  layout(title = 
           list(
             text = ""Nuclear Explosions by decade"", 
             xanchor = ""middle"",
             font = list(
               family = ""times New Roman"", 
               color = ""#1E86FF"", 
               size = 20
             )
           )
  ) 

p%>% layout(annotations = list(
  list(x = 1, xanchor = ""right"", y = 800, showarrow = F, ax = 0, ay = 1, align = ""down"",
       text = ""TidyTuesday 19.8.2019
       Visualization: JuanmaMN 
       (Twitter @Juanma_MN)"")))



","2019"
"109",302,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 20-05-2019.R","
# Upload the data ---------------------------------------------------------

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

View(waste_vs_gdp)

colnames(waste_vs_gdp)

## name
names(waste_vs_gdp)[1]<- ""Country""
names(waste_vs_gdp)[4]<- ""Per_capita_plastic_waste""
names(waste_vs_gdp)[5]<- ""GDP_per_capita""
names(waste_vs_gdp)[6]<- ""Population""

View(waste_vs_gdp)


#############   omit na rows

data_plotly<-na.omit(waste_vs_gdp)  # Data for 2010 because for the rest of years we don't have all variables.


View(data_plotly)
colnames(data_plotly_Health_Education)

colnames(data_plotly)

library(plotly)
library(scales)
p_Tidy_Tuesday <-   plot_ly(data_plotly, 
                                x = ~GDP_per_capita, 
                                y = ~Per_capita_plastic_waste, 
                                color = ~Country, 
                                size = ~Population,
                                text =  ~paste('</br> Country: ', Country,
                                               '</br> Year: ', Year,
                                               '</br> Total population (Gapminder): ', comma_format()(Population),
                                               '</br> Per capita plastic waste (kilograms per person per day): ', Per_capita_plastic_waste,
                                               '</br> GDP per capita, PPP: ', round(GDP_per_capita,2)), 
                                
                                
                                hoverinfo = ""text"",
                                type = 'scatter',
                                mode = 'markers'
) %>%
  
  layout(xaxis = list(range = c(0, 130000), title = 'GDP per capita, PPP'),
         yaxis = list(range = c(0,5), title = 'Per capita plastic waste (kilograms per person per day)'),
         title = 'Per capita plastic waste VS GDP per capita by country',
         annotations = 
           list(text = ""#TidyTuesday"", 
                showarrow = F, xref='paper', yref='paper', 
                xref = 'paper', x = 0,
                yref = 'paper', y = 1,
                font=list(size=12, color=""black""))
)


p_Tidy_Tuesday


","2019"
"110",303,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 22-10-2019.R","# Packages ----------------------------------------------------------------

library(tidyverse)
library(anytime)
library(ggplot2)
library(waffle)


# Upload data -------------------------------------------------------------

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")
colnames(horror_movies)



# Prepare the data for geom_waffle ----------------------------------------

horror_movies_review<-horror_movies%>% select(3,6)%>%na.omit()


horror_movies_review_2<-horror_movies_review%>%  
  mutate(release_year_3=anydate(horror_movies_review$release_date),
         release_year_2=dmy(horror_movies_review$release_date)) %>%
  mutate(mycol = coalesce(release_year_2,release_year_3)) %>%
  mutate(Year=format(mycol,""%Y"")) %>% select(6,2)


# View(horror_movies_review_2)

horror_movies_review_2$review_rating<-as.numeric(horror_movies_review_2$review_rating)



horror_movies_review_3<-horror_movies_review_2%>%
  mutate(
    Review_Rating=case_when(
      horror_movies_review_2$review_rating >= 1 & horror_movies_review_2$review_rating < 5 ~ ""Less than 5"",
      horror_movies_review_2$review_rating >= 5 & horror_movies_review_2$review_rating < 7 ~ ""Between 5 & 6.9"",
      horror_movies_review_2$review_rating >= 7  ~ ""Higher than 7"",
      TRUE ~ as.character(horror_movies_review_2$review_rating)
    )
  ) %>% select(1,3)



horror_movies_review_3 %>%
  count(Year, Review_Rating) -> waffle

#View(waffle)



# waffle ------------------------------------------------------------------


ggplot(waffle, aes(fill = Review_Rating, values = n)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = T) +
  facet_wrap(~Year, nrow = 1, strip.position = ""bottom"") +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10, # make this multiplyer the same as n_rows
                     expand = c(0,0)) +
  scale_fill_manual(values = c(""#E7B800"",""#00AFBB"",""#FC4E07"")) +
  coord_equal() +
  labs(
    title = ""Horror movie metadata - Number of rating reviews by Year"",
    subtitle = ""What year received higher reviews?\n"",
    x = """",
    y = ""Number of Reviews\n"",
    caption =""\n Source: TidyTuesday 22.10.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)""
  ) +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = ""bold"", hjust = 0.5),
        plot.subtitle = element_text(size=9, face = ""italic"", hjust = 0.5),
        plot.caption = element_text(size = 8, face = ""italic"", color = ""black""),
        axis.title=element_text(size=8),
        legend.position = ""bottom"",
        panel.grid = element_blank(),
        axis.ticks.y = element_line(),
        legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE)) 





","2019"
"111",304,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 23-07-2019.R","wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")

View(wildlife_impacts)

# Understand the data -----------------------------------------------------

unique(wildlife_impacts$operator)

unique (wildlife_impacts$damage)

unique (wildlife_impacts$time_of_day)

unique(wildlife_impacts$damage)




# Tidyverse ---------------------------------------------------------------

library (tidyverse)
library(hrbrthemes)
library (ggridges)
library(dplyr)
library(ggplot2)


# Prepare the data --------------------------------------------------------

data_damage<-wildlife_impacts%>% group_by(incident_month,incident_year,time_of_day,operator, damage)%>% filter(!is.na(time_of_day) & damage %in% c(""N"", ""M"", ""S"")) %>%summarize(n=n())


# Graph -------------------------------------------------------------------


ggplot(data_damage, aes(x=incident_year,y = reorder(time_of_day,desc(time_of_day)), fill = operator, group = interaction(operator,time_of_day))) +
  geom_density_ridges2(scale = 0.9) + 
  theme_ft_rc(grid=""X"")+
  labs(
    title = ""Wildlife strikes 1990-2018"",
    subtitle = ""TidyTuesday 23.7.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette = ""Spectral"") + scale_x_continuous(breaks=seq(1990,2018,4))





#scale=1 to avoid overlap



# geom_dumbbell -----------------------------------------------------------------


library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggalt)
library(scales)
library(hrbrthemes)


data_damage_2<-wildlife_impacts%>% group_by(operator,incident_year)%>%  filter (incident_year %in% c(""1990"", ""2018"")) %>%summarize(n=n())


spread<-spread(data_damage_2,incident_year,n)

View(spread)



ggplot(spread, aes(x = `1990`, xend = `2018`, y=operator)) + 
  geom_dumbbell(colour = ""#dddddd"",
                size = 3,
                colour_x = ""#FAAB18"",
                colour_xend = ""#1380A1"")+
  labs(x=NULL, y=NULL, title=""ggplot2 geom_dumbbell with dot guide"") +
  theme_ft_rc(grid=""X"")  +
  labs(
    title = ""Wildlife strikes 1990-2018"",
    subtitle = ""TidyTuesday 23.7.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") + theme(legend.position = ""bottom"",
                    legend.box = ""vertical"")  + geom_text(data = filter(spread, operator == ""UNITED AIRLINES""),
                                                          aes(x = `2018`, y = operator),
                                                          label = ""2018"", fontface = ""bold"",
                                                          color = ""#395B74"",
                                                          vjust = -2) +
                                                geom_text(data = filter(spread, operator == ""UNITED AIRLINES""),
                                                          aes(x = `1990`, y = operator),
                                                          label = ""1990"", fontface = ""bold"",
                                                          color = ""#F7BC08"",
                                                          vjust = -2)
","2019"
"112",305,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 23-09-2019.R","# Upload the data ---------------------------------------------------------

school_diversity <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv"")


# Data manipulation -------------------------------------------------------

school_diversity2<-school_diversity %>% filter(SCHOOL_YEAR == ""1994-1995"") %>%
  select(2,6:10,12)%>%top_n(10,Total)
  


# Prepare the data for heatmap --------------------------------------------

school_diversity3<-school_diversity2%>% mutate(id = row_number())

school_diversity3<-school_diversity2[, -(1)]
rownames(school_diversity3) <- school_diversity2$LEA_NAME

View(school_diversity3)


school_diversity3[,1:5]<-round(school_diversity3[,1:5],2)







school_diversity3[,6]<-lapply(school_diversity3[,6], comma_format())

View(school_diversity3)



library(heatmaply)

library(d3heatmap)
d3heatmap(school_diversity3, scale = ""column"", colors = ""GnBu"", dendrogram = ""none"",xaxis_font_size = ""7pt"", yaxis_font_size = ""7pt"", show_legend = show.legend,main = ""TidyTuesday"")







","2019"
"113",306,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 27-08-2019.R","
# Upload the dataset ------------------------------------------------------

simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")


simpsons2<-simpsons



# Upload the packages -----------------------------------------------------

library(ggplot2)
library(tidyverse)#
library(plotly)
library(hrbrthemes)


# Top 10 ------------------------------------------------------------------

top_10<-simpsons%>% group_by(guest_star)%>%summarise(n=n())%>%top_n(10, wt=n)
View(top_10)
unique(top_10$guest_star)


# Group the seasons -------------------------------------------------------

simpsons2$season[simpsons2$season %in% c(1:10)] <- ""First 10 seasons""
simpsons2$season[simpsons2$season %in% c(11:20)] <- ""Season 11-20""
simpsons2$season[simpsons2$season %in% c(21:30)] <- ""Season 21-30""




top<-simpsons2 %>%
  filter(guest_star %in% c(""Marcia Wallace"",  
                           ""Phil Hartman"",
                           ""Joe Mantegna"",
                           ""Maurice LaMarche"",
                           ""Frank Welker"",
                           ""Kelsey Grammer"",
                           ""Jon Lovitz"",
                           ""Kevin Michael Richardson"",
                           ""Jackie Mason"",
                           ""Glenn Close""))%>% 
  group_by(season,guest_star)%>%summarise(n=n())




View(top)

top$guest_star <- factor(top$guest_star, levels = c(
  ""Glenn Close"",
  ""Jackie Mason"",
  ""Kevin Michael Richardson"",
  ""Jon Lovitz"",
  ""Kelsey Grammer"",
  ""Frank Welker"",
  ""Maurice LaMarche"",
  ""Joe Mantegna"",
  ""Phil Hartman"",
  ""Marcia Wallace""))



gS<- ggplot(top, aes(guest_star)) +
  geom_bar(aes(y = n, fill = season),stat=""identity"") +
  scale_fill_brewer(palette = ""Set3"") +
  coord_flip() +
  theme_ipsum_tw()  + 
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position=""bottom"",
    axis.text = element_text( size=48 )
  ) +
  ylim(0,180) +
  ylab(""Total Episodes"") +
  xlab("""") + 
  theme(legend.title = element_blank()) +
  labs(
    title = ""Simpsons Guest Stars - Top 10"",
    subtitle = ""Total Guest Stars per season"",
    caption = ""\n Source: TidyTuesday 27.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")
gS


ggplotly(gS)







","2019"
"114",307,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 28-10-2019.R","
# Upload the packages -----------------------------------------------------

library(tidyverse)
library(sunburstR)

# Upload the data ---------------------------------------------------------

nyc_squirrels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

View(nyc_squirrels)



# Work with the date ------------------------------------------------------


nyc_squirrels$date <- as.character(nyc_squirrels$date)

nyc_squirrels$date <- as.Date(nyc_squirrels$date, ""%m%d%Y"")


# Prepare the data for SunburstR ------------------------------------------


#Extract month, day of week

nyc_squirrels<-nyc_squirrels%>%mutate(month=format(nyc_squirrels$date,""%B""),
                                      day=format(nyc_squirrels$date,""%A"")) %>% select(shift,age,primary_fur_color,
                                                                                      day) %>%
  group_by(shift,age,primary_fur_color,day) %>%
  summarise(n=n())

# Prepare for sunburst

nyc_squirrels2<-nyc_squirrels%>%
  mutate(path2 = paste(day,shift,age,primary_fur_color, sep=""-"")) 

nyc_squirrels3<-nyc_squirrels2%>%ungroup()%>%select(path2,n)   #ungroup is necessary
  
nyc_squirrels3<- as.data.frame(sapply(nyc_squirrels3,gsub,pattern=""-NA"",replacement=""""))
nyc_squirrels3<- as.data.frame(sapply(nyc_squirrels3,gsub,pattern=""-NA-NA"",replacement=""""))
nyc_squirrels3<- as.data.frame(sapply(nyc_squirrels3,gsub,pattern=""-NA-NA-NA"",replacement=""""))


# Upload the packages -----------------------------------------------------




p2 <- sunburst(nyc_squirrels3,legend=FALSE,
               width = ""100%"",
               height = 600,
               colors = c(""#e6d8ad"",""#e6e6ad"",""#add8e6"", ""#ade6d8"", ""#e6adbb""),
               withD3=TRUE,
               valueField = ""size"")



","2019"
"115",308,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 29-4-2019.R","
# Upload data -------------------------------------------------------------

mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

View(mp_light)


# Group by month ---------------------------------------------------------


library(dplyr)
library(lubridate)

mp_light_2<-mp_light %>% group_by(month=floor_date(date, ""month"")) %>%
  summarize(amount=sum(light_score))

View(mp_light_2)
library(xts)



# Prepare the data for dygraphs--------------------------------------------

 
mp_light_3<- as.xts(mp_light_2, order.by=as.Date(mp_light_2$month,format=""%Y/%m/%d""))



# Dygraphs ----------------------------------------------------------------


library(dygraphs)


dygraph(mp_light_3$amount, main = ""#TidyTuesday"", xlab= """", ylab = ""Number of windows lit at the McCormick Place, Chicago"") %>% dyOptions(fillGraph = TRUE, fillAlpha = 0.4, colors = RColorBrewer::brewer.pal(4, ""Paired""), axisLineWidth = 1.5, drawGrid = FALSE)%>%dyRangeSelector(height = 20)

","2019"
"116",309,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 30-4-2019.R","# Upload data -------------------------------------------------------------

mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

View(mp_light)


# Group by month ---------------------------------------------------------


library(dplyr)
library(lubridate)

mp_light_2<-mp_light %>% group_by(month=floor_date(date, ""month"")) %>%
  summarize(amount=sum(light_score)) 

mp_light_3_plotly <- mp_light_2%>% mutate(month=format(mp_light_2$month,""%Y-%m""))




# Plotly ------------------------------------------------------------------


View(mp_light_3)

library(plotly)

p <- plot_ly(mp_light_3_plotly, x = ~month, y = ~amount, 
             type = 'scatter', mode = 'lines',
             line = list(color = 'rgb(205, 12, 24)', width = 2),
             text =  ~paste('</br> Light score: ', amount,
                            '</br> Month: ', month), 
             marker = list(color = 'rgb(166,206,227)',
                           line = list(color = 'rgb(8,48,107)',
                                       width = 1))) %>%
  layout(xaxis = list(title = ""month""),
         yaxis = list(title = ""amount""),
         title = 'Number of windows lit at the McCormick Place, Chicago',
         annotations = 
           list(text = ""#TidyTuesday @Juanma_MN"", 
                showarrow = F, xref='paper', yref='paper', 
                xref = 'paper', x = 1,
                yref = 'paper', y = 0,
                font=list(size=10, color=""black""))
  ) 

p
","2019"
"117",310,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 30-7-2019.R","
# Upload the data ---------------------------------------------------------

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

View(video_games)
str(video_games)
colnames(video_games)
# unique(video_games$owners)


# Upload the necessary packages -------------------------------------------

library(lubridate)
library(tidyverse)
library(hrbrthemes)
library(ggridges)


# Prepare the data --------------------------------------------------------

video_games$release_date<-mdy(video_games$release_date)

test2<-video_games%>%
  mutate(Year=year(release_date))%>%
  group_by(owners, Year) %>% filter(str_detect(owners, ""000,000"")) %>%
  filter(!str_detect(owners, ""200,000,000""))%>%
  summarize (mean=round(mean(average_playtime,na.rm=TRUE),2))

View(test2)



# ggridges ----------------------------------------------------------------


ggplot(test2, aes(x=Year,y = reorder(owners,desc(owners)), fill = owners, group = owners)) +
  geom_density_ridges2(scale =1) + 
  theme_ft_rc(grid=""X"")+
  labs(
    title = ""Video Games Dataset 2004-2018"",
    subtitle = ""TidyTuesday 30.7.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette = ""Spectral"") + theme(legend.position = """",
                                                  legend.box = """") +
  scale_x_continuous(
    breaks = c(2004:2018), limits = c(2000, 2025),
    expand = c(0, 0)
  )
","2019"
"118",311,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 30-9-2019.R","
# Upload the data ---------------------------------------------------------

pizza_jared <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_jared.csv"")



# Upload the packages -----------------------------------------------------

library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(lubridate)
library(plotly)
library(scales)
library(tidyverse)
library(viridis)

# Prepare the data for the graph ------------------------------------------

pizza_jared2<-pizza_jared%>%  mutate(date = as_datetime(time)) %>% mutate(Year=format(date,""%Y""),
                                                                           Month=format(date,""%B""))
# geom_area ---------------------------------------------------------------

pizza_jaredarea<-pizza_jared2%>%group_by (Year,  answer)%>% 
  summarise(total=sum(votes))

pizza_jaredarea$Year<-as.numeric(pizza_jaredarea$Year)


p2area3 <- pizza_jaredarea%>% 
  ggplot(aes(x=Year, y=total, fill=factor(answer), group=1,
             text =paste(""Answer:"", answer,
                         ""<br>Total Votes:"", total))) +
  geom_area() +
  scale_fill_viridis(discrete = TRUE)  +
  theme_ipsum_rc() +
  theme(legend.position=""bottom"",
        legend.title = element_blank()) +
  scale_y_continuous()+
  scale_x_continuous()+
  labs(
    title = ""NY pizza restaurants - TidyTuesday 30.9.2019"",
    subtitle = """",
    caption = ""Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette=""Set3"")

ggplotly(p2area3, tooltip=c(""text"",""x""))







# Ridgeline ---------------------------------------------------------------


# Excelent and Good

pizza_jaredREG<-pizza_jared2%>%group_by (Year, Month, answer)%>% filter (answer == ""Excellent"") %>%
  summarise(total=sum(votes))


pizza_jaredREG$Year<-as.numeric(pizza_jaredREG$Year)


head(pizza_jaredREG)
ggplot(pizza_jaredREG, aes(x=Year,y = reorder(Month,desc(Month)), fill = Month, group = interaction(Month, answer)),width=800, height=700) +
  geom_density_ridges2(scale =1) + 
  theme_ipsum_rc()+
  labs( 
    title = ""NY pizza restaurants - Excelent Answer"",
    subtitle = ""TidyTuesday 2.10.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """")  +
  theme(legend.position="""",
        legend.title = element_blank())



 ","2019"
"119",312,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 8-10-2019.R","
# Upload the data ---------------------------------------------------------

ipf_lifts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-08/ipf_lifts.csv"")


# Data manipulation -------------------------------------------------------


ipf_lifts$place[ipf_lifts$place == ""1""] <- ""Gold""

ipf_lifts$place[ipf_lifts$place ==""2""] <- ""Silver""

ipf_lifts$place[ipf_lifts$place ==""3""] <- ""Bronze""

ipf_lifts$place[ipf_lifts$place %in% c(""4"", ""5"",""6"", ""7"", ""8"", ""9"", ""10"")] <- ""4-10""

ipf_lifts$place[ipf_lifts$place %in% c(""11"", ""12"",""13"", ""14"", ""15"", ""16"", ""17"",
                                       ""18"", ""19"", ""20"", ""21"", ""22"", ""23"",
                                       ""24"", ""25"", ""26"", ""27"", ""28"", ""29"", ""30"", ""31"")] <- ""11-31""

ipf_lifts$place[ipf_lifts$place ==""G""] <- ""Guest lifter""
ipf_lifts$place[ipf_lifts$place ==""DQ""] <- ""Disqualified""
ipf_lifts$place[ipf_lifts$place ==""DD""] <- ""Doping Disqualification""
ipf_lifts$place[ipf_lifts$place ==""NS""] <- ""No-Show""

ipf_lifts1<-ipf_lifts%>%select(age_class, place)%>%group_by(age_class, place) %>%
  summarise(n=n())



ipf_lifts2<-ipf_lifts1 %>% spread(place,n)

# Reorder columns ---------------------------------------------------------

ipf_lifts3 <- ipf_lifts2[, c(1, 8,6,5,2,3,4,9,7)] %>% filter(age_class != ""5-12"")

View(ipf_lifts3)
# Prepare the data for heatmap --------------------------------------------

ipf_lifts4<-ipf_lifts3%>% mutate(id = row_number())

ipf_lifts4<-ipf_lifts3[, -(1)]
rownames(ipf_lifts4) <- ipf_lifts3$age_class

View(ipf_lifts4)



# heatmap -----------------------------------------------------------------


library(d3heatmap)
d3heatmap(ipf_lifts4, scale = ""column"", colors = ""Blues"", dendrogram = ""none"",xaxis_font_size = ""7pt"", yaxis_font_size = ""7pt"", show_legend = show.legend,main = ""TidyTuesday"")






","2019"
"120",313,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday15-4-2019.R","# Upload the necessary packages -------------------------------------------

library(readr)
library(plotly)
library(scales)



# Upload and prepare the data ---------------------------------------------------------


corbyn <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/corbyn.csv"")

corbyn
corbyn_2<-corbyn%>%mutate(percentage=avg_facebook_likes/sum(avg_facebook_likes))


# Plotly graph ------------------------------------------------------------


p <- plot_ly(corbyn_2, labels = ~political_group, values = ~avg_facebook_likes, type = 'pie',
             textposition = 'inside',
             textinfo = 'label+value') %>%
  layout(title = 'Political identity or group - Average number of facebook likes per Facebook post in 2016',
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         annotations = 
           list(text = ""#TidyTuesday.  "", 
                showarrow = F, xref='paper', yref='paper', 
                xref = 'paper', x = 0,
                yref = 'paper', y = 1,
                font=list(size=10, color=""black"")))

p","2019"
"121",317,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2018/2018-09-04/readme.rmd","# Fast food entree data

* Data from [fastfoodnutrition.com](https://fastfoodnutrition.org/mcdonalds/chart) 
* Please notice that I really only took entrees - feel free to select ALL food, sides, drinks, desserts, etc.

At the request of the website owner - I have removed web-scraping guide.
","2018"
"122",318,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2018/2018-09-25/raw/invasive_species.R","library(tidyverse)

df <- read_csv(""afr_species.csv"") %>% 
        janitor::clean_names() %>% 
        select(species:origin)

df %>% write_csv(""africa_species.csv"")

df1 <- read_csv(""table1.csv"") %>% janitor::clean_names()
tab_1 <- df1 %>% 
        select(rank:o_tt) %>% 
        bind_rows(df1 %>% 
                          select(rank_1:o_tt_1) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        bind_rows(df1 %>% 
                          select(rank_2:o_tt_2) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        filter(!is.na(rank)) %>% 
        rename(""invasion_threat"" = o_tt)

df2 <- read_csv(""table2.csv"") %>% janitor::clean_names()
tab_2 <- df2 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df2 %>% 
                select(""country"" = x4, ""ti_ct"" = ti_ct_millions_1) %>% 
                        mutate(rank = parse_number(country),
                               country = str_extract(country, ""[:alpha:].*$""),
                               ti_ct = parse_number(ti_ct) * 1000000) %>% 
                        filter(!is.na(rank))
        ) %>% 
        bind_rows(df2 %>% 
                          select(""country"" = x7, ""ti_ct"" = ti_ct_millions_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000) %>% 
                          filter(!is.na(rank))
                
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df3 <- read_csv(""table3.csv"") %>% janitor::clean_names()
tab_3 <- df3 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions, 
               ""gdp_mean"" = x4, ""gdp_proportion"" = proportion_of) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000,
               gdp_mean = parse_number(gdp_mean) * 1000000,
               gdp_proportion = as.numeric(gdp_proportion)
        ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x6, ""ti_ct"" = ti_ct_millions_1, 
                                 ""gdp_mean"" = x9, ""gdp_proportion"" = proportion_of_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x11, ""ti_ct"" = ti_ct_millions_2, 
                                 ""gdp_mean"" = x14, ""gdp_proportion"" = proportion_of_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df4 <- read_csv(""table4.csv"") %>% janitor::clean_names()
tab_4 <- df4 %>% 
        select(""country"" = rank_country, ""ti_cs"" = ti_cs_millions_us) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_cs = parse_number(ti_cs) * 1000000
               ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_1, ""ti_cs"" = ti_cs_millions_us_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
                  ) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_2, ""ti_cs"" = ti_cs_millions_us_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_cs)

df6 <- read_csv(""table6.csv"") %>% janitor::clean_names()
tab_6 <- df6 %>% 
        select(species, ""max_impact_percent"" = maximum_reported_species) %>%
        filter(!is.na(species)) %>% 
        mutate(rank = 1:n(),
               species = species,
               max_impact_percent = parse_number(max_impact_percent)
        ) %>% 
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species, 
                                 ""max_impact_percent"" = maximum_reported_species_1) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>%
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species_1, 
                                 ""max_impact_percent"" = maximum_reported) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>% 
        filter(!is.na(species))

tab_list <- list(table_1 = tab_1, table_2 = tab_2, table_3 = tab_3, table_4 = tab_4, table_6 = tab_6)

tab_list %>% 
        names() %>% 
        walk(~ write_csv(tab_list[[.]], glue::glue(""{.}.csv"")))
","2018"
"123",319,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2018/2018-09-25/raw/readme.rmd","# Raw tabular data

Table data extracted from supplementary PDF via [Tabula](https://tabula.technology/) open-source software. 

This ended up being super messy - cleaning script found below.

[Cleaning Script](https://github.com/rfordatascience/tidytuesday/blob/master/data/2018-09-25/raw/invasive_species.R)
","2018"
"124",320,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-01-22/example_code.R","# Load Library
library(tidyverse)

# Read in raw data from Vera
df_raw <- read_csv(""https://raw.githubusercontent.com/vera-institute/incarceration_trends/master/incarceration_trends.csv"")

# Check out the data structure
df_raw %>% str()

# add a row id (for later joining)
df <- df_raw %>% 
  mutate(row_id = row_number())

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong

df_population <- df %>% 
  select(yfips:land_area, -total_pop, row_id) %>% 
  gather(pop_category, population, total_pop_15to64:white_pop_15to64) %>% 
  mutate(pop_category = case_when(str_detect(pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(pop_category, ""white"") ~ ""White"",
                                  str_detect(pop_category, ""black"") ~ ""Black"",
                                  str_detect(pop_category, ""female"") ~ ""Female"",
                                  str_detect(pop_category, ""male_pop"") ~ ""Male"",
                                  str_detect(pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(pop_category, ""total"") ~ ""Total"",
                                  str_detect(pop_category, ""native"") ~ ""Native American"",
                                  str_detect(pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong
df_prison_pop <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_prison_pop:white_prison_pop, row_id) %>% 
  gather(prison_pop_category, prison_population, total_prison_pop:white_prison_pop) %>% 
  mutate(prison_pop_category = case_when(str_detect(prison_pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(prison_pop_category, ""white"") ~ ""White"",
                                  str_detect(prison_pop_category, ""black"") ~ ""Black"",
                                  str_detect(prison_pop_category, ""female"") ~ ""Female"",
                                  str_detect(prison_pop_category, ""male_prison"") ~ ""Male"",
                                  str_detect(prison_pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(prison_pop_category, ""total"") ~ ""Total"",
                                  str_detect(prison_pop_category, ""native"") ~ ""Native American"",
                                  str_detect(prison_pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Left join the two dataframes together
# I used all the common columns including row_id

full_prison_pop_df <- left_join(df_population, df_prison_pop, 
          by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                 ""pop_category"" = ""prison_pop_category"", ""urbanicity"", ""region"",
                 ""division"", ""commuting_zone"", ""metro_area"", ""land_area"", ""row_id"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone)) 

# Summary data to get rate per 100000 by group

summ_prison <- full_prison_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(prison_population)/sum(population) * 100000) %>% 
  ungroup()

# Test plot looks good
ggplot(summ_prison, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category)

# More gathers to get pre-trial data
df_pretrial <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_jail_pretrial:male_jail_pretrial) %>% 
  gather(pretrial_category, pretrial_population, total_jail_pretrial:male_jail_pretrial) %>% 
  mutate(pretrial_category = case_when(str_detect(pretrial_category, ""asian"") ~ ""Asian"",
                                  str_detect(pretrial_category, ""white"") ~ ""White"",
                                  str_detect(pretrial_category, ""black"") ~ ""Black"",
                                  str_detect(pretrial_category, ""female"") ~ ""Female"",
                                  str_detect(pretrial_category, ""male_jail"") ~ ""Male"",
                                  str_detect(pretrial_category, ""latino"") ~ ""Latino"",
                                  str_detect(pretrial_category, ""total"") ~ ""Total"",
                                  str_detect(pretrial_category, ""native"") ~ ""Native American"",
                                  str_detect(pretrial_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Pretrial dataset joined with population numbers
pretrial_pop_df <- left_join(df_population, df_pretrial, 
                         by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                                ""pop_category"" = ""pretrial_category"", ""urbanicity"", ""region"",
                                ""division"", ""commuting_zone"", ""metro_area"", ""land_area"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone))

# Summary data to get rate per 100000 by group
summ_pretrial <- pretrial_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(pretrial_population)/sum(population) * 100000) %>% 
  ungroup()

# plot matches Vera plot
ggplot(summ_pretrial, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category) +
  labs(title = ""Rate per 100,000 by county type and population group"")

# Write files to .csv
write_csv(summ_prison, ""prison_summary.csv"")
write_csv(summ_pretrial, ""pretrial_summary.csv"")
write_csv(full_prison_pop_df, ""prison_population.csv"")
write_csv(pretrial_pop_df, ""pretrial_population.csv"")
","2019"
"125",321,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-04-09/tennis_pros.rmd","---
title: ""Men's and Women's Tennis""
author: ""Thomas Mock""
date: ""4/6/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
library(lubridate)
library(janitor)
```

### Get Women's Slams Records

I couldn't find a great source of historical dates for the grand slam winner's dates but they are consistently within a few days of each other based off my cursory examination. I fully ackowledge that the dates used for the tournament date are only estimations.

```{r}
raw_slams <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_women%27s_singles_champions"") %>% 
  html_table(fill = TRUE) %>% 
  .[[3]] %>% 
  janitor::clean_names()

clean_slams <- raw_slams %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove(name, """")),
         name = str_trim(str_remove(name, ""Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          TRUE ~ name)) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Female"") %>% 
  group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()
```


 
### Get Mens Slams Records

```{r}

raw_slams_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_men%27s_singles_champions"") %>% 
  html_nodes(xpath = '//*[@id=""mw-content-text""]/div/table[1]') %>% 
  html_table(fill = TRUE) %>% .[[1]] %>% janitor::clean_names()

clean_slams_men <- raw_slams_men %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  separate(col = winner, into = c(""country"", ""winner""), sep = "":"", fill = ""left"") %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove_all(name, ""|"")),
         name = str_trim(str_remove(name, ""Amateur era tennis ends|Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Male"") %>% 
  select(-country) %>% 
   group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()

```

### Get the Dates of Birth for women

This got the majority of women but I had to manually add birthdates for Ann and Chris.

```{r}
clean_dob <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[2]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          str_detect(name, ""Reid"") ~ ""Kerry Melville Reid"",
                          str_detect(name, ""Vicario"") ~ ""Arantxa Snchez Vicario"",
                          TRUE ~ name)) %>% 
  bind_rows(tibble(name = c(""Ann Haydon-Jones"",""Chris O'Neil""),
                   date_of_birth = c(lubridate::dmy(""7 October 1938""), lubridate::dmy(""19 March 1956""))))

dob_df <- clean_dob %>% 
  select(date_of_birth, name)
```

### Combine to get approx age at each tourney

```{r}
age_slams <- left_join(clean_slams, dob_df, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))
```

### MEN

```{r}
clean_dob_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  bind_rows(tibble(name = ""William Bowrey"",
                   date_of_birth = lubridate::dmy(""25 December 1943"")))

dob_df_men <- clean_dob_men %>% 
  select(date_of_birth, name)
```

### Combine

```{r}
age_slams_men <- left_join(clean_slams_men, dob_df_men, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

age_slams_men %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step()
```

### Total Combine

```{r}
grand_slams <- bind_rows(clean_slams, clean_slams_men) %>% 
  select(-total_win_count)
```

```{r}
player_dob <- bind_rows(clean_dob, clean_dob_men)
```

```{r}
age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age, gender) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

# test plot
age_slams_comb %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step() +
  facet_wrap(~gender)
```


```{r}
write_csv(grand_slams, ""grand_slams.csv"")
write_csv(player_dob, ""player_dob.csv"")
```


### Tennis Timeline Performance

I thought this was interesting data that could lead to some unique plots.

```{r}
yr_1968_1970 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[12]]
clean_1968_1970 <- yr_1968_1970 %>% 
  set_names(nm = paste0(names(yr_1968_1970), ""_"", yr_1968_1970[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1964_AUS`:`1970_USA`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year)) %>% 
  filter(year >= 1968)

yr_1971_1977 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[13]]

clean_1971_1977 <- yr_1971_1977 %>% 
  set_names(nm = paste0(names(yr_1971_1977), ""_"", yr_1971_1977[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1971_AUS`:`1977_AUSD`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year))

names(yr_1968_1970) %>% unique() %>% .[. != ""Player""] %>% as.integer()
```

I re-factored into a function but there were some gotchas in the data that limited where I could apply the function. Given I will never use it again I will somewhat break DRY principles for my own sake.

```{r}

get_timeline <- function(table_num){
  
  Sys.sleep(5)
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    filter(Player_Player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    rename(player = Player_Player) %>%
    mutate(year = as.integer(year))
}
```

# Collect women's timeline

```{r}

clean_1978_2012 <- 5:9 %>%
  map(get_timeline) %>%
  bind_rows()

```

```{r}
df_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[10]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}
final_timeline <- bind_rows(list(clean_1968_1970, clean_1971_1977, clean_1978_2012, clean_2013_2019)) %>% 
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Female"")

```

```{r}
final_timeline %>% group_by(tournament) %>% count(sort = TRUE)
```

### MENS Timeline

The function works a bit nicer here and I have further re-factored it.

```{r}
get_timeline_men <- function(table_num){
  Sys.sleep(5)
  
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>%
    na.omit() %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    janitor::clean_names(""all_caps"") %>% 
    select(-matches(""NA"")) %>% 
    select(player = PLAYER_PLAYER, matches(""AUS|FRA|WIM|USA"")) %>% 
    select(-matches(""NA|`NA`"")) %>% 
    filter(player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    mutate(year = as.integer(year))
}
```


```{r}
men_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[8]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}

clean_men_1967_2019 <- 3:10 %>% 
  map(get_timeline_men) %>% 
  bind_rows() %>% 
  filter(year > 1967)

final_timeline_men <- clean_men_1967_2019 %>%  
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Male"")

```


```{r}
both_timeline <- bind_rows(final_timeline, final_timeline_men) %>% 
  filter(str_length(player) > 4) %>% 
  filter(year <= 2019)

anti_timeline <- both_timeline %>% 
  filter(year == 2019 & tournament != ""Australian Open"")

combined_timeline <- anti_join(both_timeline, anti_timeline)
```

```{r}
write_csv(combined_timeline, ""grand_slam_timeline.csv"")
```

","2019"
"126",322,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-04-16/economist-mistakes.R","library(tidyverse)
library(here)
library(janitor)

### Brexit Raw

brexit_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_brexit.csv""))

brexit_clean <- brexit_raw %>% 
  set_names(nm = .[3,]) %>% 
  clean_names() %>% 
  slice(4:nrow(.))

brexit_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""brexit.csv""))

### corbyn

corbyn_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_corbyn.csv""))

corbyn_clean <- corbyn_raw %>% 
  set_names(nm = ""political_group"", ""avg_facebook_likes"") %>% 
  na.omit()

corbyn_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""corbyn.csv""))

### dogs

dogs_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_dogs.csv""))

dogs_clean <- dogs_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""year"", ""avg_weight"", ""avg_neck""))

dogs_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""dogs.csv""))

### EU Balance

eu_balance_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_eu-balance.csv""))


names_eu <- eu_balance_raw %>% 
  .[1,] %>% 
  as.character()

datapasta::vector_paste_vertical(names_eu)  

clean_names_eu <- c(""country"",
              ""current_2009"",
              ""current_2010"",
              ""current_2011"",
              ""current_2012"",
              ""current_2013"",
              ""current_2014"",
              ""current_2015"",
              ""budget_2009"",
              ""budget_2010"",
              ""budget_2011"",
              ""budget_2012"",
              ""budget_2013"",
              ""budget_2014"",
              ""budget_2015"")

eu_current <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""current"")) %>% 
  select(-starts_with(""budget"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_budget <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""budget"")) %>% 
  select(-starts_with(""current"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_balance_clean <- bind_rows(eu_current, eu_budget)

eu_balance_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""eu_balance.csv""))

### Pensions

pensions_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_pensions.csv""))

pensions_clean <- pensions_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""country"", ""pop_65_percent"", ""gov_spend_percent_gdp""))

pensions_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""pensions.csv""))

### Trade

trade_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_us-trade-manufacturing.csv""))

trade_clean <- trade_raw %>% 
  set_names(nm = c(""year"", ""trade_deficit"", ""manufacture_employment"")) %>% 
  mutate(trade_deficit = trade_deficit * 1e9,
         manufacture_employment = manufacture_employment * 1e6) %>% 
  na.omit()

trade_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""trade.csv""))

### Women
women_research_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_women-research.csv""))

women_research_raw[1,] %>% 
  as.character() %>% 
  datapasta::vector_paste_vertical()

research_names <- c(""country"",
  ""Health sciences"",
  ""Physical sciences"",
  ""Engineering"",
  ""Computer science, maths"",
  ""Women inventores"")

women_research_clean <- women_research_raw %>% 
  na.omit() %>% 
  set_names(nm = research_names) %>% 
  filter(country != ""Country"") %>% 
  gather(field, percent_women, `Health sciences`:`Women inventores`)

women_research_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""women_research.csv""))

","2019"
"127",323,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-05-14/nobel_winners.R","library(tidyverse)
library(here)
library(janitor)

# read in the specific category/field datasets and the overall winners

nobel_winners <- read_csv(here(""2019"", ""2019-05-14"", ""archive.csv"")) %>% 
  janitor::clean_names() %>% 
  rename(""prize_year"" = year,
         ""gender"" = sex)

chem_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Chemistry publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""chemistry"")

med_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Medicine publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""medicine"")

physics_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Physics publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""physics"")

all_pubs <- bind_rows(chem_pubs, med_pubs, physics_pubs)

all_pubs %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winner_all_pubs.csv""))

nobel_winners %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winners.csv""))




nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

nobel_winner_all_pubs %>% 
  distinct(category)","2019"
"128",324,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-07-02/revenue.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/List_of_highest-grossing_media_franchises""

df <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE) %>% 
  .[[2]]

clean_money <- df %>% 
  set_names(nm = c(""franchise"", ""year_created"", ""total_revenue"", ""revenue_items"",
                   ""original_media"", ""creators"", ""owners"")) %>% 
  mutate(total_revenue = str_remove(total_revenue, ""est.""),
         total_revenue = str_trim(total_revenue),
         total_revenue = str_remove(total_revenue, ""[$]""),
         total_revenue = word(total_revenue, 1, 1),
         total_revenue = as.double(total_revenue))

clean_category <- clean_money %>% 
  separate_rows(revenue_items, sep = ""\\["") %>% 
  filter(str_detect(revenue_items, ""illion"")) %>% 
  separate(revenue_items, into = c(""revenue_category"", ""revenue""), sep = ""[$]"") %>% 
  mutate(revenue_category = str_remove(revenue_category, ""  ""),
         revenue_category = str_remove(revenue_category, regex("".*\\]"")),
         revenue_category = str_remove(revenue_category, ""\n"")) 

clean_df <- clean_category %>% 
  mutate(revenue_category = case_when(
    str_detect(str_to_lower(revenue_category), ""box office"") ~ ""Box Office"",
    str_detect(str_to_lower(revenue_category), ""dvd|blu|vhs|home video|video rentals|video sales|streaming|home entertainment"") ~ ""Home Video/Entertainment"",
    str_detect(str_to_lower(revenue_category), ""video game|computer game|mobile game|console|game|pachinko|pet|card"") ~ ""Video Games/Games"",
    str_detect(str_to_lower(revenue_category), ""comic|manga"") ~ ""Comic or Manga"",
    str_detect(str_to_lower(revenue_category), ""music|soundtrack"") ~ ""Music"",
    str_detect(str_to_lower(revenue_category), ""tv"") ~ ""TV"",
    str_detect(str_to_lower(revenue_category), ""merchandise|licens|mall|stage|retail"") ~ ""Merchandise, Licensing & Retail"",
    
    TRUE ~ revenue_category)) %>% 
  mutate(revenue = str_remove(revenue, ""illion""),
         revenue = str_trim(revenue),
         revenue = str_remove(revenue, "" ""),
         revenue = case_when(str_detect(revenue, ""m"") ~ paste0(str_extract(revenue, ""[:digit:]+""), ""e-3""),
                             str_detect(revenue, ""b"") ~ str_extract(revenue, ""[:digit:]+""),
                             TRUE ~ NA_character_),
         revenue = format(revenue, scientific = FALSE),
         revenue = parse_number(revenue)) %>%
  mutate(original_media = str_remove(original_media, ""\\[.+"")) 

sum_df <- clean_df %>%
  group_by(franchise, revenue_category) %>% 
  summarize(revenue = sum(revenue))

total_sum_df <- clean_df %>% 
  group_by(franchise) %>% 
  summarize(revenue = sum(revenue)) %>% 
  arrange(desc(revenue))

metadata_df <- clean_df %>% 
  select(franchise:revenue_category, original_media:owners, -total_revenue)

final_df <- left_join(sum_df, metadata_df, 
                      by = c(""franchise"", ""revenue_category"")) %>% 
  distinct(.keep_all = TRUE)

final_df
write_csv(final_df, ""media_franchises.csv"")
","2019"
"129",325,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-07-09/wwc_cleaning.R","library(tidyverse)
library(here)

# read in the datasets
df <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""wwc_results.xlsx"")) %>% 
  mutate(Year = as.integer(Year))

df_2019 <- read_csv(here(""2019"", ""2019-07-09"", ""wwc_2019.csv""))

squads <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""Womens Squads.xlsx"")) %>% 
  janitor::clean_names()

# bind datasets to include 2019
df_all <- bind_rows(df, df_2019) %>% 
  janitor::clean_names()

# add win, tie status
df_both <- df_all %>% 
  group_by(year) %>% 
  mutate(yearly_game_id = row_number(),
         winner = case_when(score_1 > score_2 ~ ""Team 1 Win"",
                   score_2 > score_1 ~ ""Team 2 Win"",
                   score_1 == score_2 ~ ""Tie"",
                   TRUE ~ NA_character_)) 

# grab team 1/score 1
df_team_1 <- df_both %>% 
  select(year:score_1, round, yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 1)

# grab team2/score 2
df_team_2 <- df_both %>% 
  select(year, team_2:yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 2)

# attach team1/team2 datasets together
# Assign winner, loser, tie,
# Correct for shootout wins in knockout stages

df_tidy <- bind_rows(df_team_1, df_team_2) %>% 
  arrange(year, yearly_game_id) %>% 
  mutate(win_status = case_when(team_num == as.integer(str_extract(winner, ""[:digit:]"")) ~ ""Won"",
                            team == ""USA"" & round == ""Final"" & year == 1999 ~ ""Won"",
                            team == ""NOR"" & round == ""Round of 16"" & year == 2019 ~ ""Won"",
                            team == ""JPN"" & round == ""Final"" & year == 2011 ~ ""Won"",
                            team == ""CHN"" & round == ""Quarter Final"" & year == 1995 ~ ""Won"",
                            team == ""FRA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""USA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""GER"" & round == ""Quarter Final"" & year == 2015 ~ ""Won"",
                            team == ""BRA"" & round == ""Third Place Playoff"" & year == 1999 ~ ""Won"",
                            round == ""Group"" & winner == ""Tie"" ~ ""Tie"",
                            TRUE ~ ""Lost"")) %>% 
  select(-winner)

# confirm no double winners/losers
df_tidy %>% 
  filter(round != ""Group"") %>% 
  group_by(year, round, yearly_game_id) %>% 
  count(win_status, sort = TRUE) %>% 
  filter(n >1)

# output to csv
df_tidy %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""wwc_outcomes.csv""))

squads %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""squads.csv""))


# data dictionaries for TidyTuesday
tomtom::create_dictionary(df_tidy)
tomtom::create_dictionary(squads)
","2019"
"130",326,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-09-03/moores_law.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/Transistor_count""

tables <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE)

df1 <- tables %>% chuck(1) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df1_clean <- df1 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = str_sub(date_of_introduction, 1, 4),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
    ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)


df1_clean %>%
  mutate() 
df2 <- tables %>% chuck(2) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df2_clean <- df2 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)

df3 <- tables %>% chuck(4) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df3

df3_clean <- df3 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = if_else(
      str_length(date_of_introduction) >= 5,
      str_sub(date_of_introduction, -4),
      str_sub(date_of_introduction, 1, 4)),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+""),
    bit_units = case_when(
      str_detect(capacity_bits, ""bit"") ~ ""Bits"",
      str_detect(capacity_bits, ""kb"") ~ ""kb"",
      str_detect(capacity_bits, ""Mb"") ~ ""Mb"",
      str_detect(capacity_bits, ""Gb"") ~ ""Gb"",
      TRUE ~ """"
                 )
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double) %>% 
  select(chip_name, capacity_bits, bit_units, everything()) %>% 
  mutate(capacity_bits = str_extract(capacity_bits, ""[:digit:]+""))

df3_clean

write_csv(df1_clean, here::here(""2019"", ""2019-09-03"", ""cpu.csv""))
write_csv(df2_clean, here::here(""2019"", ""2019-09-03"", ""gpu.csv""))
write_csv(df3_clean, here::here(""2019"", ""2019-09-03"", ""ram.csv""))

tomtom::create_dictionary(df1_clean)

cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")
gpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")
ram <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")

","2019"
"131",327,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-09-17/parks.R","library(tidyverse)
library(rvest)

df_raw <- read_csv(here::here(""2019/2019-09-17/All National Parks Visitation 1904-2016.csv"")) 

df <- df_raw %>% 
  janitor::clean_names() %>%
  mutate(date = lubridate::mdy_hms(year)) %>% 
  select(date, gnis_id, geometry:year_raw)

df %>% 
  write_csv(here::here(""2019/2019-09-17/national_parks.csv""))


# Get pop data

url <- ""https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_historical_population""

raw_html <- url %>% 
  read_html() %>% 
  html_table()

pop_df <- raw_html %>% 
  chuck(5) %>% 
  gather(key = ""state"", value = ""pop"", AL:DC) %>% 
  rename(""year"" = 1) %>% 
  mutate(pop = str_remove_all(pop, "",""),
         pop = as.double(pop))

pop_df %>% 
  write_csv(here::here(""2019/2019-09-17"", ""state_pop.csv""))

# Get gas prices

url2 <- ""https://www.energy.gov/eere/vehicles/fact-915-march-7-2016-average-historical-annual-gasoline-pump-price-1929-2015""

raw_gas <- url2 %>% 
  read_html() %>% 
  html_table()

gas <- raw_gas %>% 
  chuck(1) %>% 
  set_names(nm = c(""year"", ""gas_current"", ""gas_constant"")) %>%   
  as_tibble() %>% 
  filter(!str_detect(year, ""Source"")) %>% 
  mutate(year = as.double(year),
         gas_current = as.double(gas_current),
         gas_constant = as.double(gas_constant))

gas %>% 
  write_csv(here::here(""2019/2019-09-17"", ""gas_price.csv""))
","2019"
"132",328,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-11-05/bike_walk.R","# Load Packages -----------------------------------------------------------

library(tidyverse)
library(readxl)
library(here)
library(glue)
library(janitor)

# Read in Data ------------------------------------------------------------

table_num <- 1:6

# Generic read function for this dataset

supp_read <- function(number, ...){
  read_excel(here(""2019"", ""2019-11-05"", glue::glue(""supplemental-table{number}.xlsx"")), ...)
}

# 3 datasets for bikes, each of which has a corresponding City Size

small_bike <- supp_read(1, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"", 
         percentage_of_workers = as.numeric(percentage_of_workers),
         margin_of_error_2 = as.numeric(margin_of_error_2))

medium_bike <- supp_read(2, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_bike <- supp_read(3, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_bike <- bind_rows(small_bike, medium_bike, large_bike) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Bike"")


# 3 datasets for walking, each of which has a corresponding City Size

small_walk <- supp_read(4, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"")

medium_walk <- supp_read(5, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_walk <- supp_read(6, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_walk <- bind_rows(small_walk, medium_walk, large_walk) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Walk"")

# Built in state-level datasets
state_df <- tibble(
  state = state.name,
  state_abb = state.abb,
  state_region = as.character(state.region)
)

# Combine bike and walk data in tidy setup

full_commute <- 
  bind_rows(full_bike, full_walk) %>% 
  filter(!is.na(n),
         # There are some government-related areas that don't align with cities
         !str_detect(tolower(city), ""government|goverment"")) %>% 
  separate(city, into = c(""city"", ""state""), sep = "", "") %>% 
  select(city, state, city_size, mode, everything()) %>% 
  left_join(state_df, by = c(""state""))

full_commute %>% 
  write_csv(here(""2019"", ""2019-11-05"", ""commute.csv""))

# ACS Data ----------------------------------------------------------------

acs_data <- read_csv(here(""2019"", ""2019-11-05"", ""table_3.csv""))

age_data <- acs_data %>% 
  slice(1:6)

gender_data <- acs_data %>% 
  slice(9:10) %>% 
  rename(""gender"" = age)

race_data <- acs_data %>% 
  slice(13:18) %>% 
  rename(""race"" = age)

children_data <- acs_data %>% 
  slice(20:24) %>% 
  rename(""children"" = age)

income_data <- acs_data %>% 
  slice(27:36) %>% 
  rename(""income"" = age)

education_data <- acs_data %>% 
  slice(39:43) %>% 
  rename(""education"" = age)

","2019"
"133",368,"https://github.com/r0mymendez/R/tree/master/TidyTuesday/20190506","r0mymendez","R","TidyTuesday/20190506/script.R","library(extrafont)
library(tidyverse)

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")
unique(student_ratio$indicator)
df1=read.table('elements.txt',
               header = T,sep=',',stringsAsFactors = F)

df1$GroupName[113:118]='Others'


dff1=dff%>%filter(indicator=='Primary Education')%>%arrange(mean)
dff1=dff1[1:118,]

dft=data.frame(
  Column=df1$Column,
  Row=df1$Row,
  GroupName=df1$GroupName,
  continent=dff1$continent,
  codigo=dff1$country_code,
  country=dff1$country,
  value=round(dff1$mean,2),
  stringsAsFactors = F
)


loadfonts()

tile_width = 1
tile_height = 1



ggplot(dft, aes(Column, -Row)) + 
  geom_tile(data=dft, aes(fill=GroupName,width=tile_width, height=tile_height), 
            color=""black"",show.legend = F) + 
  geom_text( aes(label=codigo),parse=TRUE, nudge_y=.1, size=4)+
  geom_text( aes(label=value), nudge_x=-0.25, nudge_y=0.30,
            ha='left', va='top', fontweight='normal', size=3)+
  geom_text( aes(label=substr(country,1,10)), nudge_y=-0.125,size=3)+
  labs(x='',y='',caption = '@r0mymendez',
       title = 'The periodic table of education',
       subtitle = '\n Global Student to Teacher Ratios: Primary Education \n #TidyTuesday')+
  theme(plot.background = element_rect(fill='#2a2a2a')
        ,panel.background = element_rect(fill='#2a2a2a')
        ,axis.text.x = element_blank()
        ,axis.ticks = element_blank() 
        ,axis.text.y = element_blank()
        ,panel.grid.major= element_blank()
        ,axis.line = element_blank()
        ,plot.title = element_text(color = 'white',hjust = 0.5,size = 50,family = ""Pacifico"")
        ,plot.caption = element_text(color = 'white',size=18,family = ""Pacifico"")
        ,plot.subtitle = element_text(color = 'white',hjust = 0.5)
        ,panel.grid = element_line(colour = '#2a2a2a')
  )


ggsave(""plot.jpg"")

","2019"
"134",370,"https://github.com/r0mymendez/R/tree/master/TidyTuesday/20190514-NOBEL","r0mymendez","R","TidyTuesday/20190514-NOBEL/script.R","
rm(list=ls())
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")



library(patchwork)
library(grid)
library(gridExtra)
library(ggpubr)
library(tidyverse)
library(emojifont)
library(ggrepel)

emo=c(emoji('dollar'),
emoji('books'),
emoji('heart'),
emoji('microscope'),
emoji('globe_with_meridians'),
emoji('pill'))


df.category=nobel_winners%>%count(category)%>%top_n(10,n)%>%arrange((n))
df.category$x=1
df.category$y=seq(0,2.5,by=0.5) 
df.category$desc=paste0(df.category$category,' ',emo)
 

p0=
  df.category%>%mutate(category=reorder(category,n))%>%
  ggplot(aes(x=category,y=n))+
  geom_col(show.legend = F,fill='#2a2a2a')+
  geom_label_repel(aes(label = paste0(n,' in ',desc),color=category),
                   data = df.category,  size = 6,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0,
                   segment.size = 0,y = -500
  ) +
  coord_flip() +
  labs(x='',y='',title = ' ')+
  theme(
    axis.ticks = element_blank(),
    axis.text = element_blank(),
    axis.line = element_blank() ,
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.spacing = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_text(family = ""Atma Light"",
                              hjust = 0.5,size=20,colour = 'white',
                              face = 'bold')
  )


df.country=nobel_winners%>%count(birth_country)%>%top_n(10,n)%>%arrange((n))
usa=nobel_winners%>%filter(birth_country=='United States of America')%>%
  count(category)

p1=
  ggplot(usa,aes(category,n,fill=category))+
  geom_col(color='black',show.legend = F)+
  coord_flip()+
  labs(y = paste0('Usa: ',sum(usa$n),' prizes'),x='')+
  coord_polar()+
  geom_label_repel(aes(label = paste0(n,' in ',category)),
                   data = usa,  size = 4,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(1, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   segment.color='white',
                   show.legend = F)+
  theme(axis.title = element_text(family = ""Atma Light"",
                                    hjust = 0.5,size=20,colour = 'white'),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.line = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' )
        )

uk=nobel_winners%>%filter(birth_country=='United Kingdom')%>%
  count(category)

p2=ggplot(uk,aes(category,n,fill=category))+
  geom_col(color='black',show.legend = F)+
  labs(y = paste0('Uk: ',sum(uk$n),' prizes'),x='')+
  coord_flip()+
  coord_polar()+
  geom_label_repel(aes(label = paste0(n,' in ',category)),
                   data = uk,  size = 4,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(1, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   segment.color='white',
                   show.legend = F)+
  theme(axis.title = element_text(family = ""Atma Light"",
                                  hjust = 0.5,size=20,colour = 'white'),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.line = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' )
        
  )


Germany=nobel_winners%>%filter(birth_country=='Germany')%>%
  count(category)

p3=ggplot(Germany,aes(category,n,fill=category))+
  geom_col(color='black',show.legend = F)+
  labs(y = paste0('Germany: ',sum(Germany$n),' prizes'),x='')+
  coord_flip()+
  coord_polar()+
  geom_label_repel(aes(label = paste0(n,' in ',category)),
                   data = Germany,  size = 4,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(1, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   segment.color='white',
                   show.legend = F)+
  theme(axis.title = element_text(family = ""Atma Light"",
                                  hjust = 0.5,size=20,colour = 'white'),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.line = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' )
        
  )


df.genero=nobel_winners%>%filter(is.na(gender)==F)%>%count(gender,category)

p4=ggplot(df.genero,
       aes(x=category,y=n,fill=gender))+
  geom_col(position = ""dodge"",color='#2a2a2a',show.legend = F)+
  geom_label_repel(aes(label =paste0(n,' ',gender)),
                   data = df.genero,  size = 5,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   label.padding = 0.3,fontface = 'bold',
                   show.legend = F,
                   box.padding = unit(0.5, ""lines""),
                   segment.color='white',
                   point.padding = unit(0.5, ""lines""))+
  labs(x='',y='',title='The novel prize gender')+
  theme_bw()+   
  theme(legend.position = 'top', 
        legend.spacing.x = unit(0.41, 'cm'),
        legend.text = element_text(margin = margin(t = 10))) +
  guides(fill=guide_legend(title=""""))+
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        legend.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        axis.text =  element_text(colour='white'),
        legend.title =  element_text(colour='white'),
        plot.title =  element_text(colour = 'white',
                           family=""Atma Light"",face = 'bold'))




ggarrange(
ggarrange(p0,p1,p2,p3,ncol=4,nrow = 1, heights = c(0.05,0.1,0.1,0.1),
          widths =  c(0.15,0.2,0.2,0.2)),
p4,
          ncol = 1, nrow = 2)+
  labs(caption='@r0mymendez    \n   ',title='THE NOBEL PRIZE')+
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
        plot.caption = element_text(colour = 'white',size = 10,hjust = 1),
        plot.title  = element_text(colour = 'white',size = 40,hjust = 0.5,
                                   family =""Atma SemiBold"" ))








  ","2019"
"135",371,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190410/20190410.R","pacman::p_load(jpeg, png, ggplot2, grid, neuropsychology)
library(tidyverse)
library(emojifont)

partidos_fifa_copa_mundial_procesado <- 
  readr::read_delim(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-04-10/partidos.txt"",delim = ""\t"")

df=partidos_fifa_copa_mundial_procesado

dfp=rbind(df%>%select(anio,anfitrion,
                      equipo_1,goles=equipo_1_final)%>%
                      mutate(anfitrion=ifelse(anfitrion==equipo_1,1,0))%>%
                      select(anio,anfitrion,
                              equipo=equipo_1,goles),
          df%>%select(anio,anfitrion,
                      equipo_2,goles=equipo_2_final)%>%
            mutate(anfitrion=ifelse(anfitrion==equipo_2,1,0))%>%
            select(anio,anfitrion,
                   equipo=equipo_2,goles))

dfp=dfp%>%filter(anfitrion==1)%>%group_by(equipo)%>%summarise(totgol=sum(goles))%>%
  top_n(10,totgol)

imgage <- jpeg::readJPEG(""cancha-dimensiones-futbol.jpg"")

dfp%>%
  mutate(equipo = reorder(equipo, totgol)) %>%
ggplot( aes(equipo, totgol, fill = equipo))+
  labs(
    title=paste(emoji(""soccer""),""EQUIPOS ANFITRIONES CON MAS GOLES"",emoji(""soccer""), 
                collapse="" ""),
         subtitle=""Partidos de las Copas del Mundo de Ftbol (1930 a 2018)"", 
           x='',y='goles', 
        caption=paste0(emoji('point_right'),' @r0mymendez')) +
  annotation_custom(rasterGrob(imgage, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_col(stat=""identity"", position = ""dodge"", width = .75, colour = 'white',
           alpha=0.85,show.legend = F)   +
  scale_fill_viridis(discrete = TRUE)+
   coord_flip()+
  geom_text(aes(label = round(totgol)), size = 4, fontface = 2, 
            colour = 'white', hjust = 1.6, vjust = 1) +
 theme(
    plot.title = element_text(color = ""#3f704d"", hjust =0.4,
                              size = 18, face = ""bold""),
    plot.caption = element_text( face = ""italic"",hjust = 0,size=8),
    plot.background = element_rect(fill = ""#f7f7f7""),
    plot.subtitle = element_text(color = ""#3f704d"", hjust =0.4,
                                 size = 10 ))
  


","2019"
"136",372,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190410/20190423-gapminder.R","library(ghibli)
library(ggplot2)
library(ggrepel)
library(tidyverse)
library(extrafont)
library(showtext)
library(gapminder)
library(emojifont)

#fonts
font_import(pattern = ""MrBedfort-Regular.ttf"")
loadfonts(device=""win"")
loadfonts()
fonts()



# Filter
df=gapminder
df_fil=df%>%filter(year==2007)%>%top_n(10,pop)

#colora: ggpomological
pomological_palette <- c(
  ""#c03728"" #red
  ,""#919c4c"" #green darkish
  ,""#fd8f24"" #orange brighter
  ,""#f5c04a"" #yelloww
  ,""#e68c7c"" #pink
  ,""#828585"" #light grey
  ,""#c3c377"" #green light
  ,""#4f5157"" #darker blue/grey
  ,""#6f5438"" #lighter brown
)

#image
img_a <- png::readPNG(""C:/Users/ROMIMENDEZ/Desktop/ROMI/proyecto/20190423/logo.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 


# Base Plot
gg <- 
  ggplot(df%>%filter(year==2007,continent != ""Oceania""), 
         aes(x=gdpPercap, y=lifeExp,fill= continent,size=pop)) + 
  geom_point(show.legend = F,shape = 21,alpha=0.8) +
  scale_size_continuous(range = c(1,35))  +
  annotation_custom(a, xmin = 30000, xmax = 50000,
                    ymin = 10, ymax =100 ) +
   ylim(c(50, 87))+
  scale_fill_manual(values = pomological_palette)+
  labs(title=""Pbi per capita Vs Esperanza de vida ( 2007 ) "",
       subtitle="""", 
       y=""Esperanza de vida"",
       x=""pib per capita"", 
       caption=paste0(""@r0mymendez"",emoji(""heart""))) +
  theme(legend.position=""bottom"", legend.direction=""horizontal"",
        legend.box = ""horizontal"",
        legend.key.size = unit(1, ""cm""),
        plot.caption = element_text(size=12,family = ""Lucida Calligraphy""),
        axis.line = element_line(size=1, colour = ""black""),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_rect(fill = ""#fffeea"",
                                        colour = ""#fffeea""),
        plot.background =  element_rect(fill = ""#fffeea"",
                                        colour = ""#fffeea""),
        plot.title=element_text(family=""Mr Bedfort"", size = 30),
        plot.subtitle = element_text(family=""Mr Bedfort"", size = 20),
        text=element_text(family=""Mr Bedfort"", size = 20),
        axis.text.x=element_text(colour=""black"", size = 14),
        axis.text.y=element_text(colour=""black"", size = 14))+
  geom_label_repel(
                aes(label=country),
            size=4, data=df_fil,family=""Mr Bedfort"",
            fill ='#fffeea') + 
  theme(legend.position = ""None"") 

gg



","2019"
"137",373,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190502/20190502-ComercioExt.R","library(tidyverse)
library(extrafont)
library(patchwork)

font_import()
font_import(pattern = ""KOMIKAX.ttf"")
loadfonts(device=""win"")
loadfonts()
fonts()


comercio_hispanoamerica_mundo <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-05-01/comercio_hispanoamerica_mundo_agregado.csv"")
producto=data.frame(
  nombre_comunidad_producto=unique(comercio_hispanoamerica_mundo$nombre_comunidad_producto),
  nombre_corto=unique(comercio_hispanoamerica_mundo$nombre_comunidad_producto),
  stringsAsFactors = F
)


producto$nombre_corto=gsub(""Productos de "","""",producto$nombre_corto)
producto$nombre_corto=gsub(""Productos "","""",producto$nombre_corto)
producto$nombre_corto=gsub(""Composicin "",""Comp. "",producto$nombre_corto)



dfexp=comercio_hispanoamerica_mundo%>%
  filter(nombre_pais_origen=='Argentina',anio==2017,valor_exportado_dolares>0)   %>%     
  select(nombre_pais_destino,valor_exportado_dolares,nombre_comunidad_producto)   %>%
  group_by(nombre_comunidad_producto)%>%
  summarise(valor_exportado_dolares=sum(valor_exportado_dolares))%>%
  top_n(10,valor_exportado_dolares)%>%
  mutate(nombre_comunidad_producto=as.factor(nombre_comunidad_producto))%>%
  inner_join(producto)  


paisexp2017=(comercio_hispanoamerica_mundo%>%
               filter(nombre_pais_origen=='Argentina',anio==2017)%>%
               group_by(nombre_pais_destino)%>%
               summarise(valor=sum(valor_exportado_dolares))%>%
               top_n(6,valor)%>%select(nombre_pais_destino))

####################### GRAL #############################
pexp=
  comercio_hispanoamerica_mundo%>%
  filter(nombre_pais_origen=='Argentina',
         anio==2017,
         nombre_pais_destino %in% paisexp2017$nombre_pais_destino)%>%
  select(nombre_pais_destino,valor=valor_exportado_dolares,
         nombre_comunidad_producto)%>%
  inner_join(producto) %>%
  top_n(20,valor)

pais=pexp%>%filter( nombre_corto==""Vegetales"")%>%
  top_n(1,valor)%>%
  select(nombre_pais_destino)
pais=pais$nombre_pais_destino  


g_exp=
  ggplot(pexp,
         aes(x=nombre_corto,
             y=valor/1000000,
             fill=nombre_corto))+
  geom_col(show.legend = T,colour = ""black"")  +
  scale_fill_manual(
    breaks =pexp$nombre_corto,
    values =
      c( 'Alimentos'=""#8abdb6"",                            
         'Armas'=""#1c26b3"",                                    
         'Arte y Antiguedades'=""#7485aa"",                      
         'Artculos de Papel'=""#d05555"",                       
         'Calzado y Gorras'=""#872a41"",                         
         'Instrumentos'=""#5c57d9"",                             
         'Maquinaria'=""#d1a1bc"",                               
         'Metales'=""#a17cb0"",                                  
         'Metales Preciosos'=""#7454a6"",                        
         'Miscelnea'=""#4d6fd0"",                               
         'Piedras y Cristales'=""#993f7b"",                      
         'Pieles de Animales'=""#d6c650"",                       
         'Plsticos y Gomas'=""#ede788"",                        
         'Animales'=""#74c0e2"",                       
         'Comp. Vegetal y Animal'=""#549e95"",
         'Madera'=""#dc8e7a"",                      
         'Minerales'=""#bcd8af"",                      
         'Qumicos'=""#a8c380"",                       
         'Vegetales'=""#406662"",                      
         'Sin Especificar'=""#635b56"",                          
         'Textiles'=""#bf3251"",                                 
         'Transporte'=""#a1aafb"" )
  ) +
  coord_flip()+
  coord_polar()  +
  annotate(""text"", x = 11, y = 4006.8, 
           label =
             paste0(pais,' es el pais que\nrecibe mas exp. Arg'),
           family = ""AR CENA"",
           size = 4, hjust = 0,
           color='#2a2a2a',face=""bold"") +
  annotate(""segment"", x = 10.8, y =  3806.8, xend = 10, 
           yend = 3806.8, colour = ""#a1aafb"",
           size=1.5,
           arrow = arrow(length = unit(0.5, ""cm"")))+
  guides(fill=guide_legend(title=""""))+
  #facet_wrap(.~nombre_pais_destino) +
  labs(x='',y='',title='Categorias de productos exportados') +
  theme(  #axis.text.x = element_text(face = 'bold',size=10,color='#2a2a2a')
    legend.text = element_text(size=12,family = ""AR CENA"")
    ,axis.text.x = element_blank()
    , axis.ticks = element_blank() 
    , axis.text.y = element_blank()
    , panel.grid.major=element_line(size=0.3,linetype = 2
                                    ,colour=""#D3D3D3"")
    , panel.background = element_rect(fill = 'white')
    , plot.background =  element_rect(fill ='white')
    , axis.line = element_blank()
    , plot.title=  element_text(color=""#2a2a2a"",size=15,family = ""AR CENA"")
    , strip.background =element_rect(fill=""#8abdb6"")
    , strip.text = element_text(colour = '#2a2a2a')
  ) 
g_exp

######################## POR PAIS ######################

p_exp=
  ggplot(pexp,
         aes(x=nombre_corto,
             y=valor,
             fill=nombre_corto))+
  geom_col(show.legend = F,colour = ""black"")  +
  scale_fill_manual(
    breaks =pexp$nombre_corto,
    values =
      c( 'Alimentos'=""#8abdb6"",                            
         'Armas'=""#1c26b3"",                                    
         'Arte y Antiguedades'=""#7485aa"",                      
         'Artculos de Papel'=""#d05555"",                       
         'Calzado y Gorras'=""#872a41"",                         
         'Instrumentos'=""#5c57d9"",                             
         'Maquinaria'=""#d1a1bc"",                               
         'Metales'=""#a17cb0"",                                  
         'Metales Preciosos'=""#7454a6"",                        
         'Miscelnea'=""#4d6fd0"",                               
         'Piedras y Cristales'=""#993f7b"",                      
         'Pieles de Animales'=""#d6c650"",                       
         'Plsticos y Gomas'=""#ede788"",                        
         'Animales'=""#74c0e2"",                       
         'Comp. Vegetal y Animal'=""#549e95"",
         'Madera'=""#dc8e7a"",                      
         'Minerales'=""#bcd8af"",                      
         'Qumicos'=""#a8c380"",                       
         'Vegetales'=""#406662"",                      
         'Sin Especificar'=""#635b56"",                          
         'Textiles'=""#bf3251"",                                 
         'Transporte'=""#a1aafb"" )
  ) +
  coord_flip()+
  coord_polar()+
  facet_wrap(.~nombre_pais_destino,ncol=3,nrow = 2) +
  labs(x='',y='',title='Principales exportaciones por pais') +
  theme(    axis.text.x = element_blank()#element_text(face = 'bold',size=6)
            , axis.ticks = element_blank() 
            , axis.text.y = element_blank()
            , panel.grid.major=element_line(size=0.3,
                                            linetype = 2,
                                            colour=""#D3D3D3"")
            , panel.background = element_rect(fill = 'white')
            , plot.background =  element_rect(fill ='white')
            , plot.title=  element_text(color=""#2a2a2a"",size=15,family = ""AR CENA"")
            , axis.line = element_blank()
            , legend.title=element_blank()
            #, panel.border = element_rect(color = ""black"")
            , strip.background =element_rect(fill=""#406662"",color = ""black"")
            , strip.text = element_text(colour = 'white',face = 'bold',size=14,family = ""AR CENA"")
  ) 
p_exp

#################### GRAFICA #######################
wrap_plots(g_exp + p_exp,
           heights  =  c(3, 0.8))+
  plot_annotation(title = ""Exportaciones Argentinas 2017"",
                  subtitle = ""Los siguientes datos corresponden a las exportaciones realizada en el ao 2017 por la Republica Argentina, adicionalmente se graficaron los seis paises 
                  tienen mayor volumen de exportaciones en dolares."",
                  caption = ""Data:  Open Trade Statistics. | Visualizacion: @r0mymendez"",
                  theme = theme(
                    plot.title=  element_text(color=""#2a2a2a"",size=24,family = ""Komika Axis""),
                    plot.subtitle=element_text(color=""#2a2a2a"",size=14,family = ""AR CENA""))
  )

ggsave(""exportacion.png"")







","2019"
"138",374,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190507/20190507-MAPA.R","rm(list=ls())


library(ggrepel)
library(ggthemes)
library(emojifont)
library(htmltab)
library(ggplot2)
library(dplyr)
require(maps)
require(viridis)

datos_uip <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-05-08/datos_uip.csv"")

dfp=datos_uip
dfp$porcentaje_mujeres=ifelse(is.na(dfp$porcentaje_mujeres),0,dfp$porcentaje_mujeres)
dfp$cuota_genero=ifelse(is.na(dfp$cuota_genero),0,dfp$cuota_genero)
dfp$edad_elegibilidad=ifelse(is.na(dfp$edad_elegibilidad),0,dfp$edad_elegibilidad)
dfp$integrante_mas_joven=ifelse(is.na(dfp$integrante_mas_joven),0,dfp$integrante_mas_joven)
dfp$numero_integrantes=ifelse(is.na(dfp$numero_integrantes),0,dfp$numero_integrantes)

mapa <- map_data(""world"", region =dfp$countries)
mapa=mapa%>%filter(!(subregion %in% c('Isla Isabela','Isla San Cristobal',
                                      'Isla Santa Cruz','Isla Fernandina',
                                      'Isla San Salvador','Isla Santa Maria',
                                      'Easter Island')))


region.lab.data <- mapa %>%
  group_by(region) %>%
  summarise(long = mean(long), lat = mean(lat))


dfp1=dfp%>%left_join(region.lab.data, by=c('countries'='region'))

alta=dfp1%>%filter(camara=='alta')

ggplot(mapa, aes(x = long, y = lat)) +
  geom_polygon(aes(group = group, fill = group),colour='white')+
  geom_label_repel(aes(label = paste0(countries,'\n',porcentaje_mujeres,' %')),
                data = alta,  size = 4,  fill ='#fffeea',
                family=""Atma Light"" ,
                box.padding = unit(0.35, ""lines""),
                point.padding = unit(0.3, ""lines""))  +
  labs(title=paste0('Porcentaje de mujeres en la Camara Alta  ',emoji('womens')),
       subtitle = '\nAnalisis en America del sur de la participacion de mujeres en la camara alta del parlamento',
       caption=paste0(emoji('bird'),' @r0mymendez'))+
  annotate(""rect"", xmin = -60, xmax = -40, ymin =-55, ymax = -45, fill=""#fffeea"", colour=""#a2a2a2"") +
  annotate(""text"", label = paste0(""El pais con mas alta \nparticipacion de mujeres es "",alta$Pas[which.max(alta$porcentaje_mujeres)] ),
            x = -50, y = -50, size = 5,  fill ='#fffeea',  family=""Atma Light"",
           colour =""black"") +
  theme_economist() +
  theme(plot.title = element_text(family='Atma LIght',size='30',hjust=0.5),
        plot.subtitle = element_text(family='Atma LIght',size='15',hjust=0.5),
        plot.caption = element_text(family='Atma LIght',size='18',hjust=1,face = 'bold'),
        legend.position = ""none"")+ 
 scale_fill_viridis_c(option = 'D')  


","2019"
"139",375,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190515/20190515-spotify.R","#install.packages('httpuv')

rm(list=ls())
library(Rspotify)
library(tidyverse)
library(grid)
library(gridExtra)
library(ggpubr)
library(ggrepel)



keys <- spotifyOAuth(""app"", ""client"", ""key"")

paises_es <- c(""Argentina"", ""Bolivia"", ""Chile"", ""Colombia"", ""Costa Rica"",
               ""Cuba"",""la Republica Dominicana"", ""Dominican Republic"",
               ""Ecuador"", ""El Salvador"", ""Equatorial Guinea"", ""Espaa"",
               ""Guatemala"", ""Honduras"", ""Mxico"", ""Nicaragua"", ""Panam"",
               ""Paraguay"", ""Per"", ""Puerto Rico"", ""Uruguay"", ""Venezuela"")
user_playlists_1 <- getPlaylists(""qn9el801z6l32l2whymqqs18p"", token = keys)
user_playlists_2 <- getPlaylists(""qn9el801z6l32l2whymqqs18p"", 50, token = keys)
tops_50 <- rbind(user_playlists_1, user_playlists_2)
# encontr aparte el de venezuela que no estaba incluido
tops_50 <- rbind(tops_50, c(""624oAiyjMdmpdJWIylharU"", ""El Top 50 de Venezuela"", ""suo2sbl91eeth3elwrfuq7qwn"", 50))

paises <- purrr::map_chr(tops_50$name, ~ str_remove(.x, ""El Top 50 de ""))
bool_es <- purrr::map_lgl(paises, ~ .x %in% paises_es)
tops_50_es <- tops_50[bool_es, ]

viralcharts_user = ""qn9el801z6l32l2whymqqs18p""

canciones_tops50_es <- purrr::map(tops_50_es$id[-length(tops_50_es$id)],
                                  ~ getPlaylistSongs(user_id = viralcharts_user,
                                                     .x,
                                                     token = keys))
canciones_tops50_es[[18]] <- getPlaylistSongs(user_id = ""suo2sbl91eeth3elwrfuq7qwn"",
                                              ""624oAiyjMdmpdJWIylharU"",
                                              token = keys)

dataset_canciones = tibble()
for (i in 1:length(canciones_tops50_es)) {
  dataset_canciones = rbind(dataset_canciones, cbind(canciones_tops50_es[[i]],
                                                     top = as.character(tops_50_es$name)[i],
                                                     numero = 1:nrow(canciones_tops50_es[[i]])))
}
features_canciones = tibble()
for (j in 1:nrow(dataset_canciones)) {
  features_canciones = rbind(features_canciones,
                             getFeatures(dataset_canciones$id[j], keys))
}


dataset_spotify = cbind(dataset_canciones, features_canciones)
fechas = purrr::map(unique(dataset_spotify$album_id), ~getAlbumInfo(.x, keys)[1, 6])
album_fechas =  tibble(album_id = unique(dataset_spotify$album_id),
                       fecha = as.character(unlist(fechas)))
dataset_spotify = dataset_spotify[, -2] %>%
  left_join(album_fechas, by = ""album_id"")

dataset_spotify = dataset_spotify %>%
  select(-id, -artist_id, - album_id, -uri, -analysis_url)

nombres_columnas = c(""cancion"", ""popularidad"", ""artista"", ""artista_completo"",
                     ""album"", ""top_pais"", ""puesto"", ""bailabilidad"", ""energia"",
                     ""nota_musical"", ""volumen"", ""modo"", ""hablado"", ""acustico"",
                     ""instrumental"",""en_vivo"", ""positividad"", ""tempo"",
                     ""duracion"", ""tiempo_compas"", ""fecha"")
colnames(dataset_spotify) <- nombres_columnas


df.tracks=dataset_spotify%>%count(artista)%>%top_n(10,n)
df.tracks$x=1
df.tracks$y=seq(0,4.5,by=0.5) 
df.tracks$desc=paste0(emoji('musical_note'),' ',
                      df.tracks$artista)
df.tracks$color=hue_pal()(10)

p0=df.tracks%>%mutate(artista=reorder(artista,n))%>%
  ggplot(aes(x=artista,y=n,fill=artista)) +
  geom_col(show.legend = F) +
  scale_fill_manual(breaks =df.tracks$artista,
                    values =c(
                      ""Anuel Aa"" =""#F8766D"",
                      ""Bad Bunny""=""#D89000"",
                      ""Becky G""=""#A3A500"",
                      ""Daddy Yankee""=  ""#39B600"", 
                      ""J Balvin""=   ""#00BF7D"",     
                      ""Karol G""  =""#00BFC4"",       
                      ""Ozuna""=  ""#00B0F6"" ,         
                      ""Paulo Londra""=  ""#9590FF"", 
                      ""Piso 21""=    ""#E76BF3"",      
                      ""Sebastian Yatra""=""#FF62BC""
                    ))+
  geom_label_repel(aes(label = paste0(desc,' (',n,')')),color='black',
                   data = df.tracks,  size = 4,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0,
                   segment.size = 0,y = -500
  ) +
  coord_flip() +
  labs(x='',y='',title = 'Artistas mas populares')+
  theme(
    axis.ticks = element_blank(),
    axis.text = element_blank(),
    axis.line = element_blank() ,
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.background =element_rect(fill='#2a2a2a',color ='white' ),
    panel.spacing = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_text(family = ""Atma Light"",
                              hjust = 0,size=16,colour = 'white',
                              face = 'bold')
    
  )

p0
pop=arg%>%top_n(10,popularidad)
pop$id=seq_len(nrow(pop))
pop$cancion[12]=""I Don't Care""

setwd('/home/romimendez/Romi/Proyectos/miercolesdata/20190514-spotify')
img_a <- png::readPNG(""listen-on-spotify-logo.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 


p1=  
  pop%>%mutate(cancion=reorder(cancion,puesto))%>%
  ggplot()+
  geom_col(aes(x=cancion,y=bailabilidad,fill=artista),
           position = ""dodge"",color='#2a2a2a',show.legend = F)+
  scale_fill_manual(breaks =df.tracks$artista,
                    values =c(
                      ""Anuel Aa"" =""#F8766D"",
                      ""Bad Bunny""=""#D89000"",
                      ""Becky G""=""#A3A500"",
                      ""Daddy Yankee""=  ""#39B600"", 
                      ""J Balvin""=   ""#00BF7D"",     
                      ""Karol G""  =""#00BFC4"",       
                      ""Ozuna""=  ""#00B0F6"" ,         
                      ""Paulo Londra""=  ""#9590FF"", 
                      ""Piso 21""=    ""#E76BF3"",      
                      ""Sebastian Yatra""=""#FF62BC"",
                      ""Sech""=      ""#E9842C"",    
                      ""ROSALA""=  ""#00A7FF"" ,      
                      ""Nicky Jam""=  ""#7F96FF"",  
                      ""DJ Luian""=  ""#BC81FF""  ,    
                      ""Maluma""=  ""#FF8000""     , 
                      ""Pedro Cap""= ""#21CD11"",     
                      ""Billie Eilish""=""#FF62BF"",
                      ""Ed Sheeran""=""#F5D033""
                    ))  +
  geom_point(aes(x=id,y=energia),color='blue',show.legend = F) +
  geom_line(aes(x=id,y=energia),color='blue',show.legend = F) +
  annotation_custom(a, xmin = 0.5, xmax = 22.5,
                    ymin = 0, ymax =0.2) +
     geom_label_repel(aes( x=cancion,y=bailabilidad,
                           label =paste0(puesto,' puesto')),
                   data = pop,  size = 4.5,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   label.padding = 0.3,fontface = 'bold',
                   show.legend = F,
                   box.padding = unit(0.5, ""lines""),
                   segment.color='white',
                   point.padding = unit(0.5, ""lines""))    +
  geom_point(aes(x=id,y=hablado),color='white',show.legend = F)+
  geom_line(aes(x=id,y=hablado),color='white',show.legend = F) +
  labs(x='',y='bailabilidad',title='Top 10 en popularidad de canciones',
       subtitle =paste0('Ref: blanco ',emoji('arrow_right'),' hablado',
                  ' ,azul '   ,emoji('arrow_right'),' energia')
       )+
  theme_bw()+   
  theme(legend.position = 'top', 
        legend.spacing.x = unit(0.41, 'cm'),
        legend.text = element_text(margin = margin(t = 10)),
        axis.text.x = element_text(angle = 45, hjust = 0.5))+
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        legend.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        axis.text =  element_text(colour='white'),
        axis.text.x = element_text(angle = 50,hjust = 1),
        axis.title = element_text(colour='white', family=""Atma Light""),
        legend.title =  element_text(colour='white'),
        plot.title =  element_text(colour = 'white',size=16,
                                   family=""Atma Light"",face = 'bold'),
        plot.subtitle =  element_text(colour = 'white',size=12,hjust = 0.5,
                                   family=""Atma Light"",face = 'bold'),
        panel.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ))

  ggarrange(
   p0,p1,
    ncol = 2, nrow = 1,widths = c(0.4,1.4))+
    labs(caption='@r0mymendez    \n   ',title=paste0(emoji('musical_score'),'SPOTIFY ARGENTINA RANKING'),
         subtitle = ' ')+
    theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
          plot.caption = element_text(colour = 'white',size = 10,hjust = 1),
          plot.title  = element_text(colour = 'white',size = 40,hjust = 0.5,
                                     family =""Atma SemiBold"" ))
  
  ","2019"
"140",376,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190521/script.R","rm(list=ls())
library(tidyverse)
library(countrycode)
library(emojifont)
library(extrafont)
library(ggrepel)
library(ggpubr)

tuberculosis_oms <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-05-22/tuberculosis_oms.csv"")

countrycode=codelist%>% select(cowc,region,cow.name)
  
tuberculosis=tuberculosis_oms%>%
  gather(key='concepto',value='value',-c(1:4))%>%
  inner_join(countrycode,by=c('iso3'='cowc'))%>%
  filter(region=='South America', anio %in% c(1996:2012),
         is.na(value)==F)

tuberculosis=tuberculosis%>%
  mutate(postivo_frotis=ifelse(str_detect(tuberculosis$concepto,'fpp'),1,0),
         sexo=ifelse(str_detect(tuberculosis$concepto,'_h'),'Hombre','Mujer'))%>%
  filter(postivo_frotis==1)%>%
  mutate(edad=case_when(
    concepto %in% c(""nuevos_fpp_h014"",""nuevos_fpp_m014"")   ~ ' 0 - 14',
    concepto %in% c(""nuevos_fpp_h1524"",""nuevos_fpp_m1524"") ~ '15 - 24',
    concepto %in% c(""nuevos_fpp_h2534"",""nuevos_fpp_m2534"") ~ '25 - 34',
    concepto %in% c(""nuevos_fpp_h3534"",""nuevos_fpp_m3534"") ~ '35 - 44',
    concepto %in% c(""nuevos_fpp_h4554"",""nuevos_fpp_m4554"") ~ '45 - 54',
    concepto %in% c(""nuevos_fpp_h5564"",""nuevos_fpp_m5564"") ~ '55 - 64',
    concepto %in% c(""nuevos_fpp_h65""  ,""nuevos_fpp_m65"")   ~ 'Mayor 64'
  ))

tuberculosis$emoji=emoji('syringe')

a1=
  tuberculosis%>%group_by(sexo,edad)%>%summarise(s=sum(value))%>%
  ggplot(aes(edad,s,fill=sexo))+
  geom_col(color='black',position = ""dodge"",show.legend = T) +
  scale_fill_manual(values = c('Mujer'='#e68c7c','Hombre'='#0570b0'))+
  labs(title='Cantidad de casos por edad',
       subtitle = 'Paises: Argentina, Bolivia, Brasi, Chile, Colombia, Ecuador, Guyana, Per, Surinm y Venezuela""')+
  theme_bw()+   
  theme(legend.justification=c(0,0), legend.position=c(0.84,0.7),
        legend.background = element_rect(fill=""#fffeea"",color='#a2a2a2'),
        legend.text = element_text(family = ""Atma Light"")) + 
  theme(      panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
              axis.title.y =element_blank(),
              axis.ticks = element_blank(),
              axis.text = element_text(family = ""Atma Light"",face = 'bold'),
              #axis.text = element_rect(fill='white'),
              plot.subtitle =  element_text(family = ""Atma Light"",size=10,
                                            color='#a2a2a2'),
              plot.title =  element_text(family = ""Anton"" ,size=18,color='#a2a2a2'),
              axis.title = element_text(family = ""Atma Light"",size=13),
              plot.caption = element_text(family = ""Atma Light"",size=13),
              panel.background = element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              plot.background =  element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              panel.grid.major.x = element_blank(),
              panel.grid.major.y = element_line(color = '#2a2a2a',linetype = 3)
              
  )
  

targ=tuberculosis%>%filter(pais=='Argentina')%>%
        group_by(anio,sexo,emoji)%>%
          summarise(s=sum(value))
targ.g=targ%>%top_n(10,s)


total=tuberculosis%>%filter(pais=='Argentina',anio==2012,sexo=='Mujer')%>%
  select(value)

arg=tuberculosis%>%filter(pais=='Argentina',anio==2012)%>%top_n(1,value)%>%
  select(edad,s=value,anio,sexo)%>%mutate(prop=round(s/sum(total$value)*100,0))

a2=
  ggplot(targ,
       aes(x=anio, y=s,color= sexo,fill=sexo,label=emoji)) + 
 geom_point(show.legend = F,shape = 21,alpha=0.8,aes(size=s/100)) +
 geom_text(family='EmojiOne',size=12,show.legend = F)+
 geom_label_repel(aes(label=s),size=3.5, show.legend = F,
    data=targ%>%filter(s>2700),fill ='#fffeea') +
 geom_line(show.legend = F,linetype='dotted') +
  scale_x_continuous(breaks = seq(1995,2013,by=3))+
  scale_color_manual(values = c('Mujer'='#67001f','Hombre'='#08306b'))+
  scale_fill_manual(values = c('Mujer'='#e68c7c','Hombre'='#0570b0'))+
  theme_bw()+   
  labs(title='Tuberculosis en Argentina',x='Ao')+
  theme(      panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
              # axis.text.y = element_blank(),
              axis.ticks = element_blank(),
              plot.title =  element_text(family = ""Anton"" ,size=18,color='#a2a2a2'),
              axis.title = element_text(family = ""Atma Light"",size=13),
              plot.caption = element_text(family = ""Atma Light"",size=13),
              panel.background = element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              plot.background =  element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              panel.grid.major.x = element_blank(),
              panel.grid.major.y = element_line(color = '#2a2a2a',linetype = 3)
              
  )



ggarrange(
  a1,a2,
  ncol = 2, nrow = 1)+
  labs(caption=paste0(""Source: Organizacin Mundial de la Salud (OMS) | by @r0mymendez"",emoji(""heart"")),
       subtitle = ' ',
       title=paste0('Analisis de tuberculosis en America del sur (1996 - 2012) ',
                    emoji('syringe'))) +
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
        plot.caption = element_text(colour = 'white',size = 13,hjust = 1,
                                    family= ""Anton""  ),
        plot.title  = element_text(colour = 'white',size = 20,hjust = 0.5,
                                   family = ""Anton""    ),
        plot.subtitle = element_text(colour = 'white',size = 10,hjust = 0.5,
                                     family =""Anton"" ),
        plot.margin = unit(c(1,0,0.1,0), ""cm""))






","2019"
"141",377,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190612/20190612-VInosyQuesos.R","rm(list=ls())
library(tidyverse)
library(emojifont)
library(ggplot2)
library(ggrepel)


#Informacion sobre quesos y vinos: 
#https://www.bonvivir.com/2013/01/17/quesos-vinos/
#https://www.vix.com/es/imj/gourmet/2008/03/26/guia-de-vinos-y-quesos
#https://vinepair.com/wine-blog/an-illustrated-guide-to-pairing-wine-and-cheese/


vinos <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-06-12/vinos.csv"")
queso <- read_csv('queso.csv')
variedad=vinos%>%filter(is.na(variedad)==F,is.na(precio)==F)%>%
  group_by(variedad)%>%summarise(promedio=mean(precio,na.rm = T),
                                                cantidad=n())
queso$Queso=tolower(queso$Queso)
queso$Vino=tolower(queso$Vino)
queso=unique(queso)

variedad$variedad=tolower(variedad$variedad)
variedad$Cabernet_Sauvignon=ifelse(str_detect(variedad$variedad,""cabernet sauvignon""),1,0)
variedad$Zinfandel=ifelse(str_detect(variedad$variedad,""zinfandel""),1,0)
variedad$Tawnyport=ifelse(str_detect(variedad$variedad,""tawnyport""),1,0)
variedad$Jerez=ifelse(str_detect(variedad$variedad,""jerez""),1,0)
variedad$Chardonnay=ifelse(str_detect(variedad$variedad,""chardonnay""),1,0)
variedad$Sauvignon_Blanc=ifelse(str_detect(variedad$variedad,""sauvignon blanc""),1,0)
variedad$Pinot_Noir=ifelse(str_detect(variedad$variedad,""pinot noir""),1,0)
variedad$Merlot=ifelse(str_detect(variedad$variedad,""merlot""),1,0)
variedad$Gewrztraminer=ifelse(str_detect(variedad$variedad,""gewrztraminer""),1,0)
variedad$Champagne=ifelse(str_detect(variedad$variedad,""champagne""),1,0)
variedad$Barbera=ifelse(str_detect(variedad$variedad,""barbera""),1,0)
variedad$Nebbiolo=ifelse(str_detect(variedad$variedad,""nebbiolo""),1,0)
variedad$Riesling=ifelse(str_detect(variedad$variedad,""riesling""),1,0)
variedad$Chenin_Blanc=ifelse(str_detect(variedad$variedad,""chenin blanc""),1,0)
variedad$Pinot_Gris=ifelse(str_detect(variedad$variedad,""pinot gris""),1,0)         
variedad$malbec=ifelse(str_detect(variedad$variedad,""malbec""),1,0)
variedad$cabernet=ifelse(str_detect(variedad$variedad,""cabernet""),1,0)
variedad$syrah=ifelse(str_detect(variedad$variedad,""syrah""),1,0)
variedad$tinto=ifelse(str_detect(variedad$variedad,""tinto""),1,0)
variedad$prosecco=ifelse(str_detect(variedad$variedad,""prosecco""),1,0)
variedad$viognier=ifelse(str_detect(variedad$variedad,""viognier""),1,0)
variedad$pinot_grigio=ifelse(str_detect(variedad$variedad,""pinot grigio""),1,0)


variedad$total=variedad$Cabernet_Sauvignon+
  variedad$Zinfandel+
  variedad$Tawnyport+
  variedad$Jerez+
  variedad$Chardonnay+
  variedad$Sauvignon_Blanc+
  variedad$Pinot_Noir+
  variedad$Merlot+
  variedad$Gewrztraminer+
  variedad$Champagne+
  variedad$Barbera+
  variedad$Nebbiolo+
  variedad$Riesling+
  variedad$Chenin_Blanc+
  variedad$Pinot_Gris+
  variedad$malbec+
  variedad$cabernet+
  variedad$syrah+
  variedad$tinto+
  variedad$prosecco+
  variedad$viognier+
  variedad$pinot_grigio


variedadq= variedad%>%top_n(20,cantidad)  %>%
    filter(total>0)%>%gather(
                                key='concepto',
                                value='valor',
                                4:25)%>%
  filter(valor==1)%>%
  mutate(concepto=tolower(concepto))%>%
  mutate(concepto=gsub('_',' ',concepto))%>%
  inner_join(queso,by = c('concepto'='Vino'))%>%
  mutate(emoji=emoji('cheese'))


variedad1=vinos%>%filter(!is.na(variedad),!is.na(precio),!is.na(puntos))%>%
  select(variedad,precio,puntos)%>%
  group_by(variedad)%>%
  summarise(n=n(),prom.puntos=round(mean(puntos),0),
                                 prom.precios=round(mean(precio),0))%>%
  top_n(20,n)
variedad1$emoji=emoji(""wine_glass"")

img_a <- png::readPNG(""1.png"") 
a <- grid::rasterGrob(img_a, interpolate = T)   

ori=
  ggplot(variedad1, aes(x=variedad, y=n,color=variedad,size=prom.puntos,label=emoji)) +
  geom_segment(aes(x=variedad, xend=variedad, y=0, yend=n,color=variedad),
               show.legend = F,size=0.8) +
  geom_point(show.legend = F,alpha=0.4) +
  geom_text(family='EmojiOne',size=12,show.legend = F)+
  coord_flip()+
  geom_label_repel(aes(label=paste0('$ ',prom.precios)),size=4, show.legend = F,
                   data=variedad1,fill ='#fffeea')+
  labs(y='Cantidad',x='Variedades',caption = paste0(emoji('heart'),'@r0mymendez'))+
  theme(plot.background = element_rect(fill='#2a2a2a',colour = ""#2a2a2a""),
        panel.background = element_rect(fill = ""#2a2a2a"", colour = ""#2a2a2a""),
        axis.text = element_text(color='white',
                                 family = ""Atma Light"",size=15),
        plot.caption = element_text(color='white',size = 14, 
                                    family = ""Atma Light"",
                                    hjust = 1),
        plot.title = element_text(color='white',family = ""Mr Bedfort"",size=30,face = 'bold'),
        plot.subtitle = element_text(color = ""white"",size = 8),
        axis.title = element_text(color = ""white"",
                                  family = ""Atma Light"",size = 20),
        panel.grid.major.y = element_line(colour = ""#fdfdf3"", size = .1, linetype = 2),
        panel.grid.minor.y = element_line(colour = ""#2a2a2a"", size = .2),
        panel.grid.major.x = element_line(colour = ""#fdfdf3"", size = .2),
        panel.grid.minor = element_line(colour = ""#fdfdf3"", size = .2))+
  annotate(""text"", 
           label = paste0('Las 20 variedades de vino con \nmayor cantidad de reseas'),
           y = 10000, x = 18, size = 10,
           family= ""Atma Light"",
           colour =""white"")  +
  annotation_custom(a, xmin =0, xmax =10,
                    ymin=10000 ,ymax=15000) 

ori


gq=
  ggplot(variedadq%>%mutate(Queso=paste0(Queso,' ',emoji(""black_circle""))),
       aes(x=concepto,y=Queso,fill=concepto,size=promedio*2))+
  geom_point(show.legend = F,shape = 21,alpha=0.8) +
  scale_size_continuous(range = c(1,10))  +
    labs(
         y=paste0('Queso ',emoji('cheese')),
         x=paste0('Variedades ',emoji('wine_glass')),
        title='Quesos y Vinos',
        subtitle = 'Combinaciones de tipos de quesos en base a la variedad de vino',
        caption = paste0(emoji('heart'),'@r0mymendez')
           )+
  theme(plot.background = element_rect(fill='#2a2a2a',colour = ""#2a2a2a""),
        panel.background = element_rect(fill = ""#2a2a2a"", colour = ""#2a2a2a""),
        axis.text = element_text(color='white',
                                 family = ""Atma Light"",size=15),
        plot.caption = element_text(color='white',size = 14, 
                                    family = ""Atma Light"",
                                    hjust = 1),
        plot.title = element_text(color='white',family = ""Mr Bedfort"",size=30,face = 'bold'),
        plot.subtitle = element_text(color = ""white"",size = 10,family = ""Mr Bedfort""),
        axis.title = element_text(color = ""white"",
                                  family = ""Atma Light"",size = 20),
        axis.text.x = element_text(hjust = 1,angle = 45),
        panel.grid.major.y = element_line(colour = ""#fdfdf3"", size = .1, linetype = 2),
        panel.grid.minor.y = element_line(colour = ""#2a2a2a"", size = .2),
        panel.grid.major.x = element_line(colour = ""#fdfdf3"", size = .2),
        panel.grid.minor = element_line(colour = ""#fdfdf3"", size = .2))

gq","2019"
"142",378,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190625/script.R","capitulos_rladies <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-06-26/capitulos_rladies.csv"")


library(tidyverse)
library(grid)
library(gridExtra)
library(ggpubr)
library(ggrepel)
library(extrafont)


df_20=capitulos_rladies%>%top_n(20,miembros)


img_b <- jpeg::readJPEG(""1.jpg"")
b <- grid::rasterGrob(img_b, interpolate = T) 

  world_map <- map_data(""world"")
    
    ggplot() +
      geom_polygon(data=world_map, aes(x = long, y = lat, group = group),
                   fill=""#2a2a2a"", colour = ""#c495f0"")+
      geom_point(data=capitulos_rladies,aes(x=longitud,
                                            y=latitud,size=miembros
                               ),color='#88398A',show.legend = F) +
    #  annotation_custom(a, xmin =100, xmax =200,
    #                    ymin=50 ,ymax=90
    #  ) +
      annotation_custom(b, xmin =-200, xmax =-150,
                        ymin=-50 ,ymax=-90
      ) +
      geom_label_repel(aes(label=paste0(ciudad,':',miembros),x=longitud,
                           y=latitud),
                       size=3, show.legend = F,
                       data=df_20,fill ='#fffeea',
                       segment.color = 'white')+
      labs(x='',y='',title = paste0('Capitulos de RLadies  ',emojifont::emoji('two_women_holding_hands')),
           subtitle = 'Las 20 ciudades con mas miembros')+
      theme_void()+
      theme(
        legend.background = element_rect(fill='#2a2a2a'),
        legend.text = element_text(color='white'),
        plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a'),
        legend.position=c(0.11, 0.32),
        legend.key = element_rect(fill = ""#2a2a2a"", color = NA),
        legend.title = element_text(color = ""white"", size = 10, hjust = 0.5),
        plot.title = element_text(family =     ""Atma""    ,
                                  hjust = 0.5,
                                  size=30,colour = '#b87fed',
                                  face = 'bold'),
        plot.subtitle =  element_text(family =     ""Gill Sans MT""    ,
                                      hjust = 0.5,
                                      size=12,colour = '#ad6aea',
                                      face = 'bold'), 
      )
    
    
    
    
","2019"
"143",379,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190713/script.R","rm(list=ls())

library(tidyverse)
library(ggrepel)
library(extrafont)
library(grid)
library(ggpubr)

pokemon <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-07-10/pokemon.csv"")

df=pokemon%>%
      filter(nombre_traducido %in% c('Bulbasaur','Charmander','Squirtle'))

df.var=df%>%
  select(nombre_ingles,ataque,defensa,velocidad,fuerza_especial_ataque,
         fuerza_especial_defensa)%>%
  gather(key='caract',value = 'valor',2:6)


#GRAFICO G1
G1=
df.var%>%ggplot(aes(x=caract,y=valor,fill=nombre_ingles))+
  geom_col(position = 'dodge',color='#2a2a2a',show.legend = F)+
  scale_fill_manual(
    breaks =df.var$nombre_ingles,
    values =
      c( 'Charmander'=""#FFAF4E"",
         'Bulbasaur'='#8CDBA1',
         ""Squirtle""='#ACD3EB'))+
  geom_text(aes(label=valor), position=position_dodge(width=0.9), 
            vjust=-0.25,family=""Bangers"",color='white',
            size=10)+
  ylim(0,80)+
  labs(y='',x='')+
  theme_bw()+
  theme(plot.background = element_rect(color='black',fill='black'),
        panel.background =  element_rect(color='black',fill='black'),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        axis.text.x = element_text(size=14,family=""Bangers"",face = 'bold',
                                   color = 'white'))


vect=data.frame(
      x=1:3,y=1:3)

G2=
ggplot(vect,aes(x=x,y=y))+geom_point(color='black')+
  annotate(""text"", label = paste0('Total' ),
           x = 2, y = 2.6, size = 14, 
           family=""Bungee"",
           colour =""white"") +
  annotate(""text"", label = paste0(df$nombre_ingles[1],': ',df$total[1] ),
           x = 2, y = 2.0, size = 10, 
           family=""Bungee"",
           colour ='#8CDBA1') +
  annotate(""text"", label = paste0(df$nombre_ingles[2],': ',df$total[2] ),
           x = 2, y = 1.6, size = 10, 
           family=""Bungee"",
           colour =""#FFAF4E"") +
  annotate(""text"", label = paste0(df$nombre_ingles[3],': ',df$total[3] ),
           x = 2, y = 1.2, size = 10, 
           family=""Bungee"",
           colour ='#ACD3EB') +
  #coord_fixed() +
  scale_x_continuous(breaks = c(1,8,2,2.3,2.6))+
  theme_void()+
  theme(plot.background = element_rect(colour = 'black',fill='black'),
        panel.background = element_rect(colour =  'black',fill='black'))


#GRAFICO G4
setwd('/20190713-pokemon')
imgage <- png::readPNG('2.png')
G4=ggplot()+
  annotation_custom(rasterGrob(imgage, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  labs(caption = 'by @r0mymendez')+
  theme(plot.background = element_rect(colour = 'black',fill='black'),
        panel.background = element_rect(colour =  'black',fill='black'),
        plot.caption = element_text(color = 'white',size=10)
        )
#G4


ggarrange(
G1,
  (ggarrange(G2,G4,nrow = 1,ncol = 2,
           widths = c(1,1.3))),
 nrow = 2,ncol=1, heights =  c(1,0.7)
)+
  labs(title='Pokemon Data Analytics')+
  theme(plot.title = element_text(size=45,family = ""Pokemon Solid""      ,
                                  hjust = 0.5,colour = 'white'),
        plot.background = element_rect(colour = 'black',fill='black'),
        panel.background = element_rect(colour = 'black',fill='black'))

","2019"
"144",380,"https://github.com/r0mymendez/R","r0mymendez","R","DatosDeMiercoles/20190819/script.R","rm(list=ls())

libertad <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-08-14/libertad.csv"")


library(tidyverse)
library(grid)
library(gridExtra)
library(ggpubr)
library(ggrepel)
library(extrafont)
library(countrycode)
library(viridis)
library(viridisLite)


country=countrycode::codelist
country=country%>%select(genc3c,country.name.en)
country$genc3c[country$genc3c=='BRB']='BRD'
country$country.name.en[country$country.name.en=='United States']='USA'
country$country.name.en[country$country.name.en=='Hong Kong SAR China']='Hong Kong'

world_map <- map_data(""world"")
world_map$region[world_map$subregion=='Hong Kong']='Hong Kong'


dfp=libertad%>%
  left_join(country, by=c('codigo_iso'='genc3c'))%>%
  left_join(world_map, by=c('country.name.en'='region'))%>%
  filter(anio==max(libertad$anio))




menor_lib=libertad%>%filter(anio==2016)%>%top_n(-5,libertad_humana_puntaje)%>%
  select(pais,libertad_humana_puntaje)%>%
  arrange(libertad_humana_puntaje)

mayor_lib=libertad%>%filter(anio==2016)%>%top_n(5,libertad_humana_puntaje)%>%
  select(pais,libertad_humana_puntaje)%>%
  arrange(libertad_humana_puntaje)

dfp_menos=dfp%>%
  filter(pais %in% menor_lib$pais)%>%group_by(pais)%>%
  summarise(lat=mean(lat,na.rm = T),
            long=mean(long,na.rm = T))%>%
  left_join(menor_lib)
 
dfp_mayor=dfp%>%
  filter(pais %in% mayor_lib$pais)%>%group_by(pais)%>%
  summarise(lat=mean(lat,na.rm = T),
            long=mean(long,na.rm = T))%>%
  left_join(mayor_lib)

df_leyenda=rbind(dfp_mayor,dfp_menos)



vmax <- max(dfp$libertad_humana_puntaje, na.rm=T)
vmin <- min(dfp$libertad_humana_puntaje, na.rm=T)
ggplot() +
  geom_polygon(data=world_map, aes(x = long, y = lat, group = group),fill='grey')+
  geom_polygon(data=dfp, aes(x = long, y = lat, group = group,fill=libertad_humana_puntaje))+
  scale_fill_viridis(name=""Human freedom"", begin = 0, end = 1,
                     limits = c(vmin,vmax), na.value=""gray99"") +
  geom_label_repel(aes(label = paste0(pais,'\n',libertad_humana_puntaje),
                       x=long,
                       y=lat),
                   data = dfp_menos,  
                   size = 4,  fill ='#440154FF',
                   family=""Atma Light"" ,
                   color='white',fontface = 'bold',
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""))  +
  geom_label_repel(aes(label = paste0(pais,'\n',libertad_humana_puntaje),
                       x=long,
                       y=lat),
                   data = dfp_mayor,  
                   size = 5,  fill ='#e8fa5bff',
                   family=""Atma Light"" ,
                   color='black',fontface = 'bold',
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""))  +
labs(x='',y='',title = paste0('Human Freedom Index ',emojifont::emoji('earth_americas')),
     caption=paste0('informe ao: 2016 ~ ',emojifont::emoji('heart'),' by @r0mymendez'),
     subtitle = '""La libertad humana es un concepto social que reconoce la dignidad de los individuos ""')+
  theme_void()+
  theme(
    legend.background = element_rect(fill='#2a2a2a'),
    legend.text = element_text(color='white'),
    plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.background =element_rect(fill='#2a2a2a'),
    legend.position=c(0.11, 0.32),
    legend.key = element_rect(fill = ""#2a2a2a"", color = NA),
    legend.title = element_text(color = ""white"", size = 10, hjust = 0.5),
    plot.title = element_text(family =     ""Pacifico""    ,
                              hjust = 0.5,
                              size=30,colour = '#73d055ff',
                              face = 'bold'),
    plot.subtitle =  element_text(family =     ""Atma Light""     ,
                                  hjust = 0.5,
                                  size=15, face = 'bold',
                                  colour = '#73d055ff' ),
    plot.caption = element_text(family =     ""Atma Light""     ,
                                hjust =0.8,
                                size=13, face = 'bold',
                                colour = '#73d055ff' )
  )

  
  
   ","2019"
"145",381,"https://github.com/r0mymendez/R","r0mymendez","R","RLADIES/201904 - TALLER GGPLOT2/MeetUp_EjResuelto_20190406.Rmd","---
title: ""Taller de Visualizacion en R""
author: Mendez Romina
date: 2019-04-06
output: html_notebook
---

tags: { `rladies`, `r`,`ggplot2`,`plotly`,`emoji` } 


## Paquetes
Los siguientes son los paquetes que vamos a utilizar durante este taller:`ggplot2`, `reshape2`,`emojifont`y `plotly`.
Para instalar un paquete recuerda que debes utilizar la sintaxis:`install.packages('nombrePaquete')`

```{r include=FALSE}
library(ggplot2)
library(reshape2)
library(emojifont)
library(plotly)

```
* ggplot2: Es el paquete para generar graficas.
* reshape2: Es el paquete para obtener el dataset denominado tips, el mismo contiene la informacin sobre cada propina que recibi un camarero durante unos meses trabajando en un restaurante.
* emojifont: Este paquete nos permite obtener los valores unicode de los emojis.
* plotly: Este paquete permite generar graficas interactivas.


## Gglot2: Grafica en capas
Vamos a realizar el primer scatter plot, para lo cual creamos el dataset tips y posteriormente utlizamos la funcion ggplot para realizar el grafico.


```{r}

df.tips=tips
ggplot(      df.tips  ,       aes(x=total_bill  ,  y=tip)    )

```

En el grafico anterior, solo vemos los ejes pero necesitamos agregar una geometria para realizar nuestra grafica de scatter plot.
Recuerda que para agregar capas debes colocar el signo ""+"" al finalizar una capa.

```{r}

ggplot(      df.tips  ,       aes(x=total_bill  ,  y=tip)    ) +
  geom_point()

```

Vamos agregar las leyendas para que nuestro grafico se vea mas completo!

```{r}
ggplot(      df.tips  ,       aes(x=total_bill  ,  y=tip)    ) +
  geom_point() +
  labs ( 
        title='Mi primer grfico', 
       subtitle='El grfico fue realizado con ggplot2 y reshape2',
       x='Total de Factura', 
       y='Propinas',
       caption='Este grfico fue realizado en el meetup de RLadies')


```

Cambiemos un poco mas nuestro grafico, para lo cual agregamos una variables mas para distinguir nuestros puntos en base a si son hombres o mujeres.
La variable que nos muestra esto en nuestro grafico es ""sex"".
Adicionalmente aumentemos el tamao de nuestros puntos.

```{r}
ggplot( df.tips  , aes(x=total_bill , y=tip, color=sex ) ) +
  geom_point( size=3 ) +
  labs ( 
         title='Mi primer grfico', 
         subtitle='El grfico fue realizado con ggplot2 y reshape2',
         x='Total de Factura', 
         y='Propinas',
         caption='Este grfico fue realizado en el meetup de RLadies')
```

Podemos agregar otra capa de geometria para cambiar nuestro grafico, en este caso utilizaremos geom_line, y le daremos un color a la linea.

```{r}
ggplot(tips,aes(x=total_bill,y=tip, color=sex) ) +
  geom_point ( size=3 ) + 
  geom_line ( color='blue' ) +
  labs(title='Mi primer grfico', 
       subtitle='El grfico fue realizado con ggplot2 y reshape2',
       x='Total de Factura', 
       y='Propinas',
       caption='Este grfico fue realizado en el meetup de RLadies')

```

Cambiemos el tema de nuestro grafico, puedes ver que hay una amplia variedad todos ellos comienzacon con theme_<name>(), en este ejemplo utilizaremos theme_minimal()

```{r}
ggplot(tips,aes(x=total_bill,y=tip, color=sex) ) +
  geom_point ( size=3 ) +  geom_line ( color='blue') +
  labs(title='Mi primer grfico', 
       subtitle='El grfico fue realizado con ggplot2 y reshape2',
       x='Total de Factura', 
       y='Propinas',
 caption='Este grfico fue realizado en el meetup de RLadies') +
theme_minimal() 

```


Cambiemos un poco mas nuestro grafico, para lo cual agregamos una variables mas para distinguir nuestros puntos en base a si son hombres o mujeres.
La variable que nos muestra esto en nuestro grafico es ""sex"".
Adicionalmente aumentemos el tamao de nuestros puntos.

```{r}
ggplot(tips,aes(x=total_bill,y=tip, color=sex) ) +
  geom_point ( size=3 ) +  geom_line ( color='blue') +
  labs(title='Mi primer grfico', 
       subtitle='El grfico fue realizado con ggplot2 y reshape2',
       x='Total de Factura', 
       y='Propinas',
 caption='Este grfico fue realizado en el meetup de RLadies') +
theme_minimal ()  +
facet_wrap (.~day)
```

## EMOJIFONT: Grafica con emoticones
Emoji proviene del japones y ""e"" significa dibujo mientras ""moji"" significa caracter.
Los emoji para utilizarlos se incorporaron al standar Unicode.
Unicode es el estndar de codificacin de caracteres universal utilizado para la representacin de texto para procesamiento del equipo. Unicode proporciona una manera consistente de codificacin de texto multilinge y facilita el intercambio de archivos de texto internacionales.

Si quieres mas informacion sobre [EMOJIFONT](https://cran.r-project.org/web/packages/emojifont/vignettes/emojifont.html) puedes consultar la documentacion. 
En nuestro caso vamos a buscar emoji que queremos utilizar, para lo cual exise la funcion search_emoji, esta retorna todos los nombre de los emoji en base a un string de busqueda.
Veamos un ejemplo:
```{r}

search_emoji('smile')
```
Para ver el emoji que cada uno de estos string retorna, podemos ir a la  
[Emoji scheat sheet](https://www.webfx.com/tools/emoji-cheat-sheet/).
Ahora selecionamos un alias y utilizamos la funcion emoji para convertirlo en unicode.

```{r}

emoji('smile')
```

Ahora vamos a crear una columna nueva del dataset df.tips, con el valor unicode de un emoji. 
En mi caso yo seleccione corazones (""heart"")!
```{r}

  df.tips=tips
  df.tips$emoji=emoji(""heart"")
```


Una vez generada la columna vamos a realizar un grafico, y de esta manera nuestro scatterplot realizara la grafica de corazones

```{r}

  ggplot(tips,aes(x=total_bill,y=tip,color=sex,label=emoji))+
    geom_point()+ 
    geom_text(family=""EmojiOne"", size=12,show.legend = F)+
    labs(title='Mi primer grfico con emojifont', 
         x='Total de Factura', 
         y='Propinas') +
    theme_bw()
```
Una vez generada la columna vamos a realizar un grafico, y de esta manera nuestro scatterplot realizara la grafica de corazones

```{r}
  df.tips=tips
  df.tips$emoji=ifelse(df.tips$sex=='Female', emoji('girl'),emoji('boy') )

  ggplot(df.tips,aes(x=total_bill,y=tip,color=sex,label=emoji))+
    geom_point()+ 
    geom_text(family=""EmojiOne"", size=14,show.legend = F)+
    labs(title='Mi primer grfico con emojifont', 
         x='Total de Factura', 
         y='Propinas') +
    theme_bw()
```","2019"
"146",382,"https://github.com/r0mymendez/R","r0mymendez","R","SWDCHALLENGE/20190705-MARVEL/script.R","rm(list=ls())

setwd('/home/romimendez/Romi/Proyectos/miercolesdata/storytellingwithdata/20190705')

file=read.csv('marvel_characters_info.csv',header = T,stringsAsFactors = F)
file_ch=read.csv('charcters_stats.csv',header = T,stringsAsFactors = F)

library(tidyverse)
library(grid)
library(extrafont)
library(ggpubr)
library(ggrepel)

df=file%>%
  inner_join(file_ch)%>%
 group_by(Alignment,Gender)%>%
  #group_by(Race)%>%
  summarise(count=n(),mean=round(mean(Total),0),sum=sum(Total))

df$Alignment=ifelse(df$Alignment=='-','No Data',df$Alignment)
df$Gender=ifelse(df$Gender=='-','No Data',df$Gender)

img_b <- png::readPNG(""6.png"") 
  
G3= ggplot() + annotation_custom(rasterGrob(img_b, 
                                              width = unit(1,""npc""), 
                                              height = unit(1,""npc"")), 
                                   -Inf, Inf, -Inf, Inf) +
    theme(plot.background = element_rect(fill = 'black',color='black'),
          panel.background = element_rect(fill = 'black',color='black'))


G2=
  df%>%ggplot(aes(x=Alignment,y=mean,fill=Gender))+
  geom_col(show.legend = F,position = 'dodge',alpha=0.7,color='black')+
  coord_polar()+
  geom_label_repel(
                   aes(label = paste0('avg power: ',mean)),
                   color='black',
                   data = df,  size = 3.8,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0,
                   segment.size = 1,
                   segment.col='#fffeea')+
    scale_fill_manual(
    breaks =df$Gender,
    values =
      c( 'No Data'=""#85D6CB"",                            
         'Female'=""#E8707B"",                                    
         'Male'=""#0378A6""))+
  facet_wrap(.~Gender) +
  labs(x='',y='',title='Marvel superheroes stats and info',
       subtitle =  'Data: kaggle by @r0mymendez') +
  theme(plot.background = element_rect(fill = 'black',color='black'),
        panel.background = element_rect(fill = 'black',color = 'black'),
        axis.text = element_text(colour = 'white'),
        axis.line.x.bottom = element_blank(),
        axis.line.y = element_blank(),
        axis.title.x.top = element_blank(),
        axis.text.x = element_text(size=13,family =""Anton"")
        , axis.text.y = element_blank()
        ,panel.grid.major.y = element_blank()
        ,panel.grid.major.x = element_line(colour = ""#2a2a2a"")
        , plot.title=  element_text(color=""white"",size=35,family =""Anton"",hjust = 0.5)
        , strip.background =element_rect(fill=""#a71814"")
        , strip.text = element_text(colour = 'white',face =""bold"",size=14,family =""Anton"")
        ,legend.position=""bottom""
        ,legend.text = element_text( size=10)
        , plot.subtitle =   element_text(colour = ""white"",
                                     size=10,family =""Anton"",hjust = 1)
  )


 ggarrange(G3,G2,widths= c( 0.5, 1.2),
             ncol = 2, nrow = 1)  +
 theme(plot.background = element_rect(fill='black',color ='black'),
       panel.background = element_rect(fill='black',color ='black'), 
      plot.title=  element_text(colour = ""white"",
                                size=35,family =""Anton"",hjust = 1),
      plot.caption =  element_text(colour = ""white"",
                                size=20,family =""Anton"",hjust = 1)
       ) 

","2019"
"147",384,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190521-PlasticWaste/script.R","rm(list=ls())

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

library(tidyverse)
library(countrycode)
library(emojifont)
library(ggrepel)
library(ggridges)
library(ggpubr)


mismanaged_vs_gdp1 <- mismanaged_vs_gdp %>%
  rename('PerCapMismanaged'=`Per capita mismanaged plastic waste (kilograms per person per day)`,
         'GDPperCapita'=`GDP per capita, PPP (constant 2011 international $) (Rate)`,
         'TotalPop'=`Total population (Gapminder)`)%>%
  filter(!is.na(PerCapMismanaged),
         Year==2010,Entity!='World')%>%
  mutate(TotalPopM=TotalPop/1000000,
         PerCapMismanaged=PerCapMismanaged,
         continent = countrycode(sourcevar = Entity, 
                                 origin = ""country.name.en"", 
                                 destination = ""continent""))



gg <- 
  ggplot(mismanaged_vs_gdp1%>%top_n(15,PerCapMismanaged)%>%
           mutate(Entity=reorder(Entity,PerCapMismanaged)), 
         aes(x=Entity, y=PerCapMismanaged,fill=Entity)) + 
  geom_col(show.legend = F, color= '#2a2a2a',alpha = 0.75)+
  coord_flip()+
  geom_label_repel(
   aes(label=Entity),
   size=4, data=mismanaged_vs_gdp1%>%top_n(15,PerCapMismanaged),
   y=-10,
   fill ='#fffeea',
   family=""Atma Light"" ,
   box.padding = unit(0.35, ""lines""),
   point.padding = unit(0.3, ""lines""),
   show.legend = F,fontface = 'bold',
   hjust=0,vjust=0,
   segment.size = 0,
  ) +
  labs(title=""The 15 countries with more per capita mismanaged \nplastic waste "",
       subtitle="""", 
       x="""",
       y=""kg per person per day"" 
      ) +
  theme(      panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
              axis.text.y = element_blank(),
              axis.ticks = element_blank(),
              axis.title = element_text(family = ""Atma Light"",size=15),
              plot.caption = element_text(family = ""Atma Light"",size=15),
              plot.title =  element_text(family = ""Atma Light"",size=13),
              panel.background = element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              plot.background =  element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              panel.grid.major.x = element_line(color = '#2a2a2a')
              
  )


gg
  
img_a <- png::readPNG(""1.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 

gg1=
  mismanaged_vs_gdp1 %>% 
  mutate(continent = factor(continent)) %>%
  filter(is.na(continent)==F)%>%
  ggplot(aes(y=continent,x=PerCapMismanaged,
             fill = continent, color = continent)) +
    geom_density_ridges(alpha = 0.25,
                      show.legend = F,
                      aes(point_color = continent), 
                      jittered_points = TRUE)   +
  annotation_custom(a, xmin =0.26, xmax = 0.35,
                    ymin=0 ,ymax=2) +
  labs(y='Continent',x='Per capita mismanaged plastic waste',
       title='Analysis of continents with mismanaged plastic waste')+
  theme(      panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
             # axis.text.y = element_blank(),
              axis.ticks = element_blank(),
              plot.title =  element_text(family = ""Atma Light"",size=15),
              axis.title = element_text(family = ""Atma Light"",size=13),
              plot.caption = element_text(family = ""Atma Light"",size=13),
              panel.background = element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              plot.background =  element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              panel.grid.major.x = element_blank(),
              panel.grid.major.y = element_line(color = '#2a2a2a',linetype = 3)
              
  )
gg1



ggarrange(
  gg,gg1,
  ncol = 2, nrow = 1,widths = c(0.9,1.4))+
  labs(caption=paste0(""Source: Our World In Data | by @r0mymendez"",emoji(""heart"")),
       subtitle = ' ',
       title=paste0('Global Plastic Waste - year: 2010',emoji('earth_americas'))) +
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
        plot.caption = element_text(colour = 'white',size = 13,hjust = 1,
                                    family= ""Finger Paint""  ),
        plot.title  = element_text(colour = 'white',size = 30,hjust = 0.5,
                                   family = ""Finger Paint""      ),
        plot.subtitle = element_text(colour = 'white',size = 10,hjust = 0.5,
                                   family =""Atma SemiBold"" ),
        plot.margin = unit(c(1,0,0.1,0), ""cm""))
","2019"
"148",385,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190528-wine/script-wine.R","library(tidyverse)
library(ggpubr)
library(ggrepel)
library(tidytext)
library(packcircles)

df_wines <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

df_wines_top_countries <- df_wines %>% 
  group_by(country) %>% 
  summarize(
    rating = mean(points, na.rm = T),
    n = n()
  ) %>% 
  mutate(rating = (rating - 80) / 20) %>% 
  filter(
    !is.na(country),
    n > 99
  ) %>%
  top_n(6, rating)

library(emojifont)
df_top_variety <- 
  df_wines %>% 
  filter(
    !is.na(country))%>% 
  group_by(country ) %>% 
  summarize(points = mean(points, na.rm = T), n = n()) %>% 
  filter(n>100)%>% 
  top_n(10,points)%>%
  mutate(icon=emoji('wine_glass'))

setwd('/home/romimendez/Romi/Proyectos/miercolesdata/tidy/20190527-wine')

df_wines_1=df_wines%>%count(points,variety)%>%
  filter(n>50)%>%top_n(10,points)


imgage <- jpeg::readJPEG(""9.jpg"")

g1=df_top_variety%>%mutate(country=reorder(country,-n))%>%
ggplot(aes(x=country,y=n,label=icon))+
  annotation_custom(rasterGrob(imgage, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  scale_fill_brewer(type='seq', palette='Reds')+
  geom_col(aes(fill=country),show.legend = F,alpha=0.2,color='#2a2a2a')+
    annotate(""text"", label = paste0('The top ten country Wine' ,emoji('wine_glass')),
           x = 5, y = 40000, size = 20,  fill ='#fffeea',  family=""Jadyn Maria Free"",
           colour =""black"") +
  annotate(""text"", label = paste0('_________' ),
           x = 5, y = 40100, size = 20,  fill ='#fffeea',  family=""Jadyn Maria Free"",
           colour =""black"") +
  annotate(""text"", label = paste0('These Countries have the Best \nAverage Classification of wines'),
           x = 6, y = 25000, size = 12,  fill ='#fffeea',  family=""Jadyn Maria Free"",
           colour =""black"") +
  labs(y='Quantity',x='',caption = 'by @r0mymendez')+
  geom_label_repel(aes(label = paste0(round(points,0),' points avg')),color='black',
                   data = df_top_variety,  size = 4,  fill ='#E7D4B3',
                   alpha=0.8,
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0.8,
                   segment.size = 0,
  ) +
  theme(axis.title.y =element_text(color='black',
                                   family = ""Fabiana"",
                                   size=15),
        plot.background = element_rect(fill='#CAA867'),
        axis.text.x = element_text(color='black',
                                 family = ""Fabiana"",
                                 size=15),
        axis.text.y =element_text(color='black',
                                  family = ""Atma"" ,
                                  size=10) )


data(""stop_words"")

dftext=df_wines%>%select(X1,description)
df_token=dftext%>%unnest_tokens(word,description)
df_token=df_token%>%anti_join(stop_words)
df_token=df_token%>%count(word)%>%top_n(50)


imgage1 <- jpeg::readJPEG(""a1.jpeg"")
packing <- circleProgressiveLayout(df_token$n, sizetype='area')
packing$radius=1.2*packing$radius
data = cbind(df_token, packing)
dat.gg <- circleLayoutVertices(packing, npoints=50)

g2=
  ggplot() + 
  annotation_custom(rasterGrob(imgage1, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_polygon(data = dat.gg, aes(x, y, group = id, fill=id), 
               colour = ""black"", alpha = 0.6) +
  scale_fill_gradient(low='#FFF5F0', high='#FFE6E6')+
  geom_text(data = data, aes(x, y, label =word),size=6,family=""Atma Light"", color=""black"") +
  theme_void() + 
  theme(legend.position=""none"") + 
  #theme(axis.title = 'Palabras relacionadas con tecnologia y conocimientos mas frecuentes')
  coord_equal() +
  scale_size(range = c(10,1), guide = F) +
  labs(title='The most frequent words in the text description ', 
       caption='by @r0mymendez')+
  theme(plot.background = element_rect(fill='#CAA867'),
        plot.title = element_text(color='black',
                                  family = ""Fabiana"",
                                  size=25))



","2019"
"149",386,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190621-BirdCounts/script_eu.R","rm(list=ls())
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")
setwd('.../tidy/20190621-bird')

library(grid)
library(emojifont)
library(tidyverse)
library(ggpubr)
library(ggrepel)

df=bird_counts%>%
  filter(how_many_counted>0)%>%
  group_by(species)%>%
  summarise(total=sum(how_many_counted))%>%
  top_n(1,total)

df.bird=bird_counts%>%
  filter(how_many_counted>0,species %in% df$species)%>%
  group_by(year)%>%
  summarise(total=sum(how_many_counted))

A1 <- png::readPNG(""1.png"")
A1 <- grid::rasterGrob(A1, interpolate = T) 
A2 <- png::readPNG(""2.png"")
A2 <- grid::rasterGrob(A2, interpolate = T) 

img_a <- png::readPNG(""5c.png"") 
a <- grid::rasterGrob(img_a, interpolate = T)

b <- jpeg::readJPEG(""3.jpg"") 


ggplot(df.bird,aes(x=year, y=total)) +
  geom_point(show.legend = F,color='#001C3E',alpha=0.7) +
  geom_line(show.legend = F,color='#32686B')+
  annotation_custom(a, ymin =30000, ymax =60000,
                    xmin=1890,xmax=2000)+
  annotation_custom(A1, ymin =52000, ymax =72000,
                    xmin=1920,xmax=2000)+
  annotation_custom(A2, ymin =40000, ymax =52000,
                    xmin=1910,xmax=1960)+
 annotate(""text"", label ='European Starling',
         x = 1938, y = 65000, size = 15,  fill ='#fffeea',  family=""Jadyn Maria Free"",
         colour =""black"") +
  annotate(""text"", label ='(1925 - 2017)',
           x = 1940, y = 57000, size = 8,  fill ='#fffeea',  family=""Atma Light"",
           colour =""black"") +
  scale_x_continuous(breaks = seq(1925,2017,4))+
  geom_label_repel(aes(label = total),color='white',
                   data = df.bird%>%top_n(5,total),  size = 4,  fill ='#9DACC0',
                   alpha=0.8,
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0.8,
                   segment.size =0.8)+
  theme_minimal()+
  labs(caption = 'by @r0mymendez')+
  theme(plot.caption = element_text(size=14, family=""Atma Light""),
        axis.title = element_text(size=30, family=""Jadyn Maria Free""),
        plot.background = element_rect(fill = '#77939F'),
        panel.background = element_rect(fill = '#77939F'),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.x = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.grid.major.y = element_line(linetype = 2),
        axis.text = element_text(color = 'white')
        )

  

","2019"
"150",387,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190625-??/script.R","rm(list=ls())
ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

library(tidyverse)
library(grid)
library(gridExtra)
library(ggpubr)
library(ggrepel)
library(extrafont)


df=ufo_sightings%>%count(ufo_shape)%>%filter(is.na(ufo_shape)==F)
df=ufo_sightings%>%
  mutate(year=str_sub(date_time, -10, -7))%>%count(year)%>%
  mutate(year=as.numeric(year))%>%
  filter(as.numeric(year) %in% 1990:2014)


df_ufo=ufo_sightings%>%
  mutate(year=str_sub(date_time, -10, -7))%>%
  mutate(year=as.numeric(year),
         shape=ufo_shape)%>%
  filter(as.numeric(year) %in% 1990:2014)

df_ufo$id=seq_len(nrow(df_ufo))
dfsample=df_ufo%>%filter(df_ufo$id %in% sample(df_ufo$id,10))


img_a <- png::readPNG(""1.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 

img_b <- png::readPNG(""2.png"") 
b <- grid::rasterGrob(img_b, interpolate = T) 

world_map <- map_data(""world"")
g2=
  ggplot() +
  geom_polygon(data=world_map, aes(x = long, y = lat, group = group),
               fill=""#2a2a2a"", colour = ""#185060"")+
  geom_point(data=df_ufo,aes(x=longitude,y=latitude,color=shape))+
  annotation_custom(a, xmin =100, xmax =200,
                    ymin=50 ,ymax=90
                   ) +
  annotation_custom(b, xmin =50, xmax =100,
                    ymin=-50 ,ymax=-90
  ) +
  geom_label_repel(aes(label=described_encounter_length,x=longitude,y=latitude),
                   size=4, show.legend = F,
                   data=dfsample,fill ='#fffeea')+
  labs(x='',y='',title = paste0('UFO Sightings around the world ',emojifont::emoji('alien')),
       subtitle = 'FROM 1990-2014')+
  theme_void()+
  theme(
    legend.background = element_rect(fill='#2a2a2a'),
    legend.text = element_text(color='white'),
    plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.background =element_rect(fill='#2a2a2a'),
    legend.position=c(0.11, 0.32),
    legend.key = element_rect(fill = ""#2a2a2a"", color = NA),
    legend.title = element_text(color = ""white"", size = 10, hjust = 0.5),
    plot.title = element_text(family =     ""Atma""    ,
                              hjust = 0.5,
                              size=30,colour = '#00BFC4',
                              face = 'bold'),
    plot.subtitle =  element_text(family =     ""Atma Light""    ,
                                  hjust = 0.5,
                                  size=15,colour = '#00BFC4',
                                  face = 'bold'), 
  )

g2","2019"
"151",388,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190701/script.R","rm(list=ls())

library(tidyverse)
library(emojifont)
library(gridExtra)
library(grid)
library(ggrepel)
library(ggridges)

media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

df=media_franchises%>%
    mutate(category=
              case_when(
                revenue_category== ""Book sales""    ~ 'Book',
                revenue_category== ""TV""    ~ ""TV"",
                revenue_category== ""Video Games/Games""     ~ ""Video Games"",
                revenue_category== ""Comic or Manga""     ~ ""Comic"",
                revenue_category== ""Music""      ~ ""Music"" ,
                revenue_category== ""Box Office""      ~ ""Box Office"",
                revenue_category== ""Home Video/Entertainment""      ~ ""Entertainment"",
                revenue_category== ""Merchandise, Licensing & Retail""      ~ ""Merchandise""
              ),
            media=case_when(
                original_media==""Novel""             ~ ""Novel"",
                original_media==""Animated film""     ~ ""film"",
                original_media==""Video game""        ~ ""Video game"",
                original_media==""Manga""             ~ ""Manga"",
                original_media==""Comic book""        ~ ""Comic"",
                original_media== ""Animated series""  ~ ""series"",
                original_media==""Greeting card""     ~ ""card"",
                original_media== ""Film""             ~ ""Film"",
                original_media==""Visual novel""      ~ ""novel"",
                original_media==""Television series"" ~ ""series"",
                original_media==""Anime""             ~ ""Anime"",
                original_media==""Cartoon character"" ~ ""Cartoon"",
                original_media==""Cartoon""           ~ ""Cartoon"",
                original_media==""Animated cartoon""  ~ ""Cartoon"",
                original_media==""Comic strip""       ~ ""Comic"",
                original_media==""Musical theatre""   ~ ""Musical"",
                original_media==""Book""              ~ ""Book""
            )
    
    )
               


df.media=df%>%group_by(media)%>%summarise(revenue=sum(revenue))
df.category=df%>%group_by(category)%>%summarise(revenue=sum(revenue))
df.creators=df%>%group_by(creators)%>%summarise(revenue=sum(revenue))

df.franchise=df%>%group_by(franchise)%>%summarise(revenue=sum(revenue))%>%
  top_n(10,revenue)

img_a <- png::readPNG(""1.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""2.png"") 
b <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""3.png"") 
c <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""4.png"") 
d <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""5.png"") 
e <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""6.png"") 
f <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""7.png"") 
g <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""8.png"") 
h <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""9.png"") 
i <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""10.png"") 
j <- grid::rasterGrob(img_a, interpolate = T) 

df.franchise%>%mutate(franchise=reorder(franchise,revenue))%>%
  ggplot()+
  geom_col(aes(x=franchise,y=revenue,fill=franchise),
           position = ""dodge"",color='#2a2a2a',show.legend = F)+
  annotation_custom(a, xmin = 9.5, xmax =10.5,
                    ymin = -30, ymax =50) +
  annotation_custom(b, xmin = 8.5, xmax =9.5,
                    ymin = -40, ymax =50) +
  annotation_custom(c, xmin = 7.5, xmax =8.6,
                    ymin = -25, ymax =50)+
  annotation_custom(d, xmin = 6.5, xmax =7.5,
                    ymin = -30, ymax =50)+
  annotation_custom(e, xmin = 5.0, xmax =6.5,
                    ymin = -30, ymax =50)+
  annotation_custom(f, xmin = 4.5, xmax =5.5,
                    ymin = -30, ymax =50)+
  annotation_custom(g, xmin = 3.5, xmax =4.5,
                    ymin = -20, ymax =50)+
  annotation_custom(h, xmin = 2.5, xmax =3.5,
                    ymin = -25, ymax =50)+
  annotation_custom(i, xmin = 1.0, xmax =3,
                    ymin = -30, ymax =50)+
  annotation_custom(j, xmin = 0.5, xmax =1.5,
                    ymin = -30, ymax =50)+
  labs(title = 'Media Franchise Powerhouses',x='')+
  theme_bw() +   
  theme(legend.position = 'top', 
        legend.spacing.x = unit(0.41, 'cm'),
        legend.text = element_text(margin = margin(t = 10),size=30))+
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        legend.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        axis.text =  element_text(colour='white',family=""Atma Light"",size=12),
        axis.text.x = element_text(hjust = 1, angle=45),
        axis.title = element_text(colour='white', family=""Atma Light"",size=20),
        legend.title =  element_text(colour='white',size=20, family=""Atma Light""),
        plot.title =  element_text(colour = 'white',size=50,hjust = 0.5,
                                   family=""Atma Light"",face = 'bold'),
        plot.subtitle =  element_text(colour = 'white',size=12,hjust = 0.5,
                                      family=""Atma Light"",face = 'bold'),
        panel.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ))




","2019"
"152",389,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190813-Roman Emperors/script.R","rm(list=ls())
emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# Libraries
library(tidyverse)
library(grid)
library(ggpubr)

imgage1 <- jpeg::readJPEG(""8.jpg"")



df.as=
  emperors%>%
  count(cause)%>%
  ggplot(aes(x=cause,y=n))+
  annotation_custom(rasterGrob(imgage1, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_segment( aes(x=cause, xend=cause, y=0, yend=n),show.legend = F) +
  geom_point(aes(size=n),show.legend = F,alpha=0.5,stroke=2,color='#2a2a2a')+
  scale_size(range = c(4, 15))+
  labs(x='',y='')+
  annotate(""text"", label = 'Cause of death',
           x = 6.5, y = 21, size = 15,   family=""Jadyn Maria Free"",
           colour =""black"") +
  annotate(""text"", label = '_____________',
           x = 6.5, y = 20.8, size = 10,   family=""Jadyn Maria Free"",
           colour =""black"") +
  theme_bw()+
  theme(plot.background = element_rect(color='#CAA867',fill='#CAA867'),
        panel.background =  element_rect(color='#CAA867',fill='#CAA867'),
        axis.text.y = element_text(size=10,family=""Atma Light"",face = 'bold',
                                   color = 'black'),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        axis.text.x = element_text(size=20,family= ""Fabiana"",face = 'bold',
                                   color = 'black'))



df.as1=
  emperors%>%
  count(killer)%>%
  ggplot(aes(x=killer,y=n))+
  geom_segment( aes(x=killer, xend=killer, y=0, yend=n),show.legend = F) +
  geom_point(aes(size=n),show.legend = F,alpha=0.5,stroke=2,color='#2a2a2a')+
  scale_size(range = c(4, 10))+
  coord_flip()+
  annotate(""text"", label = 'Killers',
           x = 12, y = 16, size = 15,   family=""Jadyn Maria Free"",
           colour =""black"") +
  theme_bw()+
  labs(x='',y='')+
  theme(plot.background = element_rect(color='#CAA867',fill='#CAA867'),
        panel.background =  element_rect(color='#CAA867',fill='#CAA867'),
        axis.text.x =  element_text(size=10,family=""Atma Light"",face = 'bold',
                                     color = 'black'),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        axis.text.y = element_text(size=12,family= ""Fabiana"",
                                   color = 'black'))



ggarrange(df.as,df.as1,  nrow = 2,ncol=1,
 heights =  c(1,0.8))+
  labs(title='Roman Emperors',
       caption = 'by @r0mymendez')  +
  theme(plot.title = element_text(size=45,family = ""Fabiana""      ,
                                  hjust = 0.5,colour = 'white'),
        plot.caption = element_text(size=15,family = ""Atma""      ,
                                  hjust = 1,colour = 'white'),
        plot.background = element_rect(colour = 'black',fill='black'),
        panel.background = element_rect(colour = 'black',fill='black'))







","2019"
"153",390,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190822-Nuclear Explosions/script.R","rm(list=ls())
nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")

library(rworldmap)
library(tidyverse)
library(ggplot2)
library(geosphere)
library(gpclib)
library('mapproj')
library(ggrepel)
library(gganimate)
library(ggpubr)
library(animation)


# World map
worldMap <- getMap()
world.points <- fortify(worldMap)
world.points$region <- world.points$id
world.df <- world.points[,c(""long"",""lat"",""group"", ""region"")]

max.year=max(nuclear_explosions$year)
min.year=min(nuclear_explosions$year)

invisible(
  saveGIF({
    
    
for (i in min.year:max.year){

worldmap <-
  ggplot() + 
  geom_polygon(data=worldMap, aes(x = long, y = lat, group = group),
               color=""#FFD300"", fill = ""#2a2a2a"") +
  theme_void()  +
  labs(title = 'Nuclear Explosions')+
  labs(caption = 'by @r0mymendez \n')+
  theme(
    legend.background = element_rect(fill='#2a2a2a'),
    legend.text = element_text(color='white'),
    plot.background = element_rect(fill='#FFD300',color ='#FFD300' ),
    panel.background =element_rect(fill='#FFD300')  ,
    legend.position=c(0.11, 0.32),
    legend.key = element_rect(fill = ""#2a2a2a"", color = NA),
    legend.title = element_text(color = ""white"", size = 20, hjust = 0),
    plot.title = element_text(family =    ""Bangers""    ,
                              hjust = 0.5,
                              size=50,colour = '#2A2A2A',
                              face = 'bold'),
    plot.subtitle =  element_text(family =     ""Atma Light""     ,
                                  hjust = 0.5,
                                  size=15, face = 'bold',
                                  colour = '#73d055ff' ),
    plot.caption = element_text(family =""Atma Light"",
                                hjust =0.9,
                                size=20, face = 'bold',
                                colour = 'black' )
  )+
  geom_point(data =  nuclear_explosions%>%filter(year == i),
             aes(x = longitude,
                 y = latitude,
                 size=magnitude_surface+0.5,
                 color=magnitude_body),
             alpha=0.3,show.legend = F)+
  scale_color_gradient(low=""#BF6068"", high=""#8C041D"")+
  scale_size_continuous(range = c(1,20))  
  
  p3 <- ggplot(data = NULL, aes(x = min.year:max.year , y = 1)) +
  geom_line() +
  geom_point(aes(fill = (x = min.year:max.year > i)), shape = 21, size = 5) +
  theme_void() +
  theme(legend.position = ""none"") +
  scale_fill_manual(values = c(""#b2d1e0"",""gold"")) +
  geom_text(aes(x = i, y = 1, label = i), vjust = -1, size = 9,
            family=""Bangers"" ,color='white') +
  theme(panel.background = element_rect(fill = ""	#fcfcfc"", colour = ""	#cccccc""))+
  theme(plot.background = element_rect(fill='#2a2a2a',color = 'black'))  

 print(ggarrange(worldmap,p3,nrow = 2,ncol = 1,heights =  c(1.4,0.3)))

}
  
    
      },
  movie.name = ""nuclearExplosions.gif"",  
  interval = 1,
  ani.width = 1200, 
  ani.height = 900))




?saveGIF


","2019"
"154",418,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2018_03_GlobalMortality.Rmd","---
title: ""TidyTuesday 2018/03 - Gobal Mortality by OurWorldInData.org""
author: ""Cedric Scherer""
date: ""3rd of October 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```

```{r prep, message=FALSE, warning=FALSE}
## packages
library(tidyverse)
library(sf)
library(maptools)
library(cartogram)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))

theme_update(
  axis.ticks = element_blank(),
  axis.text = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.border = element_rect(color = NA),
  plot.title = element_text(family = ""Bitter"", size = 32, hjust = 0.5),
  plot.subtitle = element_text(family = ""Montserrat"", color = ""grey80"", size = 18, face = ""bold"", hjust = 0.5, margin = margin(b = 6)),
  plot.caption = element_text(family = ""Bitter"", color = ""grey60"", size = 14, hjust = 0.5, lineheight = 1.2),
  legend.position = ""bottom"",
  legend.title = element_text(family = ""Bitter"", color = ""grey60"", face = ""bold"", size = 14),
  legend.text = element_text(family = ""Roboto Mono"", color = ""grey60"", size = 10)
)
```

```{r data}
df_mortality <- readxl::read_excel(here::here(""data"", ""global_mortality.xlsx"")) %>% 
  janitor::clean_names()

data(""wrld_simpl"")
```

```{r carto-calculations, eval = F}
sf_mortality <- 
  wrld_simpl %>%
  st_as_sf() %>%
  st_transform(crs = ""+proj=robin"") %>% 
  mutate(country_code = as.character(ISO3)) %>% 
  left_join(df_mortality) %>% 
  filter(year == 2016)

## causes with more than 20 percent in at least 1 country
df_mortality %>% 
  gather(cause, percent, -country, -country_code, -year) %>% 
  filter(percent >= 25) %>% 
  distinct(cause)

## calculate carto data
if(!file.exists(here::here(""data"", ""cartogram-data"", ""carto_cvd.Rds""))) {
  carto_cvd <-
    sf_mortality %>% 
    cartogram_cont(""cardiovascular_diseases_percent"", itermax = 150)
  
  carto_cancer <-
    sf_mortality %>% 
    cartogram_cont(""cancers_percent"", itermax = 150)
  
  carto_diabetes <-
    sf_mortality %>% 
    cartogram_cont(""diabetes_percent"", itermax = 150)
  
  carto_hiv <-
    sf_mortality %>% 
    cartogram_cont(""hiv_aids_percent"", itermax = 150)
  
  carto_malaria <-
    sf_mortality %>% 
    mutate(malaria_percent = if_else(malaria_percent == 0, 0.01, malaria_percent)) %>% 
    cartogram_cont(""malaria_percent"", itermax = 150)
  
  carto_conflict <-
    sf_mortality %>% 
    mutate(conflict_percent = if_else(conflict_percent == 0, 0.001, conflict_percent)) %>% 
    cartogram_cont(""conflict_percent"", itermax = 150)
    
  saveRDS(carto_cvd,      here::here(""data"", ""cartogram-data"", ""carto_cvd.Rds""))
  saveRDS(carto_cancer,   here::here(""data"", ""cartogram-data"", ""carto_cancer.Rds""))
  saveRDS(carto_diabetes, here::here(""data"", ""cartogram-data"", ""carto_diabetes.Rds""))
  saveRDS(carto_hiv,      here::here(""data"", ""cartogram-data"", ""carto_hiv.Rds""))
  saveRDS(carto_malaria,  here::here(""data"", ""cartogram-data"", ""carto_malaria.Rds""))
  saveRDS(carto_conflict, here::here(""data"", ""cartogram-data"", ""carto_conflict.Rds""))
}else {
  carto_cvd      <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_cvd.Rds""))
  carto_cancer   <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_cancer.Rds""))
  carto_diabetes <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_diabetes.Rds""))
  carto_hiv      <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_hiv.Rds""))
  carto_malaria  <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_malaria.Rds""))
  carto_conflict <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_conflict.Rds""))
}
```

```{r cartograms}
base_map <-
  ggplot() +
    rcartocolor::scale_fill_carto_c(palette = ""BluYl"", 
                                    direction = -1, 
                                    guide = F,
                                    limits = c(0, 65.2)) +
  scale_x_continuous(breaks = c()) +
  scale_y_continuous(breaks = c())
  
map_cdv <- 
  base_map +
  geom_sf(data = carto_cvd, 
          aes(geometry = geometry, 
              fill = cardiovascular_diseases_percent),
          color = ""transparent"", size = 0.1) +
  labs(subtitle = ""Cardiovascular Diseases"")
  
map_cancer <- 
  base_map +
  geom_sf(data = carto_cancer, 
          aes(geometry = geometry, 
              fill = cancers_percent),
          color = ""transparent"", size = 0.1) +
  labs(title = ""\nWhat do most people die from?\n\n"",
       subtitle = ""Cancers"",
       caption = ""\n\nThe leading causes of death across the world still vary significantly.\nThese cartograms show causes of deaths in 2016 that exceeded 20 percent of total deaths in at least 1 country.\n\n"")

map_diabetes <- 
  base_map +
  geom_sf(data = carto_diabetes, 
          aes(geometry = geometry, 
              fill = diabetes_percent),
          color = ""transparent"", size = 0.1) +
  labs(subtitle = ""Diabetes"")

map_hiv <- 
  base_map +
  geom_sf(data = carto_hiv, 
          aes(geometry = geometry, 
              fill = hiv_aids_percent),
          color = ""transparent"", size = 0.1) +
  labs(subtitle = ""HIV Infections & Aids"")

map_malaria <- 
  ggplot(carto_malaria) +
    geom_sf(aes(geometry = geometry, 
                fill = malaria_percent),
            color = ""transparent"", size = 0.1) +
    rcartocolor::scale_fill_carto_c(palette = ""BluYl"", 
                                    direction = -1, 
                                    name = ""\n\nShare of Deaths"",
                                    limits = c(0, 65.2),  ## max percent overall
                                    breaks = seq(0, 65, by = 5),
                                    labels = glue::glue(""{seq(0, 65, by = 5)}%"")) +
    guides(fill = guide_colorbar(barheight = unit(2.3, units = ""mm""),  
                                 barwidth = unit(230, units = ""mm""),
                                 direction = ""horizontal"",
                                 ticks.colour = ""grey20"",
                                 title.position = ""top"",
                                 label.position = ""top"",
                                 title.hjust = 0.5)) +
    labs(subtitle = ""Malaria Infections"", 
         caption = ""The data refers to the specific cause of death, which is distinguished from risk factors for death, such as air pollution, diet and other lifestyle factors.\n\n\n\nVisualization by Cdric Scherer    Data by OurWorldInData.org\n"") +
    theme(plot.caption = element_text(size = 9))

map_conflict <- 
  base_map +
  geom_sf(data = carto_conflict, 
          aes(geometry = geometry, 
              fill = conflict_percent),
          color = ""transparent"", size = 0.1) +
  labs(subtitle = ""War & Conflicts"")
```

```{r full-panel, fig.width = 18, fig.height = 12.5}
map_cdv + map_cancer + map_diabetes + map_hiv + map_malaria + map_conflict + plot_layout(ncol = 3)

ggsave(here::here(""plots"", ""2018_03"", ""2018_03_GlobalMortality.pdf""), width = 18, height = 12.5, device = cairo_pdf)
```


## Alcohol & Drugs

```{r cartogram-alcohol-drugs, fig.width = 11, fig.height = 14}
if(!file.exists(here::here(""data"", ""cartogram-data"", ""carto_alcohol.Rds""))) {
  carto_alcohol <-
    sf_mortality %>% 
    cartogram_cont(""alcohol_disorders_percent"", itermax = 250)
  
  carto_drugs <-
    sf_mortality %>% 
    cartogram_cont(""drug_disorders_percent"", itermax = 250)
  
  saveRDS(carto_alcohol, here::here(""data"", ""cartogram-data"", ""carto_alcohol.Rds""))
  readRDS(carto_drugs,   here::here(""data"", ""cartogram-data"", ""carto_drugs.Rds""))
}else {
  carto_alcohol <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_alcohol.Rds""))
  carto_drugs   <- readRDS(here::here(""data"", ""cartogram-data"", ""carto_drugs.Rds""))
}

## cartograms
map_alcohol <-
  ggplot(carto_alcohol) +
    geom_sf(aes(geometry = geometry, 
                fill = alcohol_disorders_percent),
            color = ""transparent"", size = 0.1) +
    rcartocolor::scale_fill_carto_c(palette = ""Peach"", 
                                    limits = c(0, 2.5),
                                    breaks = seq(0, 2.5, by = 0.5),
                                    labels = c(""0.0%"", ""0.5%"", ""1.0%"", ""1.5%"", ""2.0%"", ""2.5%""),
                                    name = ""\nShare of Deaths"") +
    guides(fill = guide_colorbar(barheight = unit(2.3, units = ""mm""),  
                                 barwidth = unit(230, units = ""mm""),
                                 direction = ""horizontal"",
                                 ticks.colour = ""grey20"",
                                 title.position = ""top"",
                                 label.position = ""top"",
                                 title.hjust = 0.5)) +
    labs(title = ""\nIn 2016, around 164 million people were dying by alcohol or drug use disorder.\n\n"",
         subtitle = ""Alcohol Disorders"",
         caption = ""The data refers to the specific cause of death, which is distinguished from risk factors for death, such as air pollution, diet and other lifestyle factors.\n\n"") +
    theme(plot.title = element_text(size = 18, lineheight = 1.1, face = ""plain""),
          plot.subtitle = element_text(size = 22),
          plot.caption = element_text(size = 9),
          legend.title = element_text(size = 12))

map_drugs <-
  ggplot(carto_drugs) +
    geom_sf(aes(geometry = geometry, 
                fill = drug_disorders_percent),
            color = ""transparent"", size = 0.1) +
    rcartocolor::scale_fill_carto_c(palette = ""Peach"", 
                                    limits = c(0, 2.5),
                                    guide = F) +
    labs(subtitle = ""Drug Disorders"", 
         caption = ""\n\n\nVisualization by Cdric Scherer    Data by OurWorldInData.org\n"") +
    theme(plot.subtitle = element_text(size = 22),
          plot.caption = element_text(size = 9))

map_alcohol / map_drugs

ggsave(here::here(""plots"", ""2018_03"", ""2018_03_Alcohol_Drugs.pdf""), width = 11, height = 14, device = cairo_pdf)
```

***

```{r session-info}
sessionInfo()
```
","2018"
"155",419,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_14_SeattleBikes.Rmd","---
title: ""TidyTuesday 2019/14 - Seattle Bike Traffic by seattle.gov""
author: ""Cedric Scherer""
date: ""24th of April 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(lubridate)
library(RColorBrewer)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_bikes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")
```

```{r data-proc}
df_bikes_grouped <- df_bikes %>%
  mutate(
    date = mdy_hms(date),
    hour = hour(date),
    day = as.character(wday(date, label = T)),
    term = if_else(day %in% c(""Sa"", ""So""), ""Weekend"", ""Weekday""),
    month = month(date),
    season = case_when(
      month %in% 3:5 ~ 1,
      month %in% 6:8 ~ 2,
      month %in% 9:11 ~ 3,
      month %in% c(12, 1, 2) ~ 4
    ),
    crossing = case_when(
      crossing == ""Broadway Cycle Track North Of E Union St"" ~ ""Broadway Cycle Track"",
      crossing == ""39th Ave NE Greenway at NE 62nd St"" ~ ""39th Ave NE Greenway"",
      crossing == ""NW 58th St Greenway at 22nd Ave"" ~ ""NW 58th St Greenway"",
      crossing == ""Burke Gilman Trail"" ~ ""Burke Gilman Trail"",
      crossing == ""Elliot Bay Trail"" ~ ""Elliot Bay Trail"",
      crossing == ""Sealth Trail"" ~ ""Sealth Trail"",
      crossing == ""MTS Trail"" ~ ""MTS Trail""
    )
  ) %>% 
  filter(
    bike_count < 2000,
    year(date) < 2018
  ) %>% 
  group_by(crossing) %>% 
  mutate(crossing_avg = mean(bike_count, na.rm = T))
```

```{r plot-month, fig.width = 14, fig.heigth = 4.75}
df_bikes_month <- df_bikes_grouped %>% 
  group_by(crossing, term, month, hour) %>% 
  summarize(
    bike_avg = mean(bike_count, na.rm = T),
    crossing_avg = unique(crossing_avg)
  ) %>% 
  group_by(crossing, term, month, hour) %>% 
  mutate(
    diff = -((crossing_avg - bike_avg) / crossing_avg), 
    diff = if_else(diff > 2.5, 2.5, diff)
  ) %>% 
  ungroup() %>% 
  mutate(
    month = factor(month, levels = 1:12, 
                   labels = c(""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July"", 
                              ""August"", ""September"", ""October"", ""November"", ""December"")),
    crossing = fct_reorder(crossing, -crossing_avg)
  )

average <- df_bikes_month %>% 
  group_by(crossing, term) %>% 
  filter(term == ""Weekday"") %>% 
  summarize(avg = round(unique(crossing_avg), digits = 2)) %>% 
  mutate(avg = paste0(""yearly mean = "", avg))

bikes_month <- df_bikes_month %>% 
  ggplot(aes(hour + 0.5, fct_rev(month))) +
    geom_tile(aes(fill = diff)) +
    geom_text(data = average, aes(label = avg), x = 12, y = 11.7, size = 2.2, 
              hjust = 0.5, family = ""Poppins"", fontface = ""plain"", color = ""grey20"") +
    scale_x_continuous(breaks = 0:24, expand = c(0, 0),
                       labels = c(""0"", """", """", """", """", """", 
                                  ""6"", """", """", """", """", """",
                                  ""12"", """", """", """", """", """",
                                  ""18"", """", """", """", """", """", ""24"")) +
    scale_y_discrete(expand = c(0, 0)) +
    scale_fill_distiller(palette = ""RdYlGn"", name = ""Hourly bike count relative to yearly mean per crossing"",
                         limits = c(-1, 2.5),
                         breaks = seq(-1, 2.5, by = 0.5), 
                         labels = c(""-1.0"", ""-0.5"", ""0.0"", ""0.5"", ""1.0"", ""1.5"", ""2.0"", ""\u22652.5""),
                         guide = guide_colorbar(direction = ""horizontal"",
                                                barheight = unit(2, units = ""mm""), 
                                                barwidth = unit(120, units = ""mm""),
                                                draw.ulim = FALSE, title.position = 'top',
                                                title.hjust = 0.5, label.hjust = 0.5)) +
    facet_grid(term ~ crossing) +
    labs(x = ""Hour of the day"", y = NULL,
         caption = ""Visualization by Cdric Scherer"") +
    theme(strip.text = element_text(face = ""plain"", size = 10, angle = 0),
          panel.spacing.x = unit(10, ""pt""), 
          axis.text.x = element_text(family = ""Roboto Mono"", size = 8),
          axis.text.y = element_text(size = 5.5),
          axis.title.x = element_text(size = 12),
          legend.title = element_text(size = 9.5),
          legend.text = element_text(family = ""Roboto Mono"", size = 8),
          legend.position = ""bottom"")

## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Riding the green wave in Seattle"",
         subtitle = ""Monthly bike traffic (2014-2018), based on data from seattle.gov\n"") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())

## full panel
title + bikes_month + plot_layout(width = c(0, 1))

ggsave(here::here(""plots"", ""2019_14"", ""2019_14_SeattleBikes_month.pdf""), 
       width = 14, height = 4.75, device = cairo_pdf)
```

```{r plot-season, fig.width = 14, fig.heigth = 5}
bikes_season <- df_bikes_grouped %>% 
  mutate(season = factor(season, levels = 1:4, 
                         labels = c(""Spring\n(Mar-May)"", 
                                    ""Summer\n(Jun-Aug)"", 
                                    ""Autumn\n(Sep-Nov)"", 
                                    ""Winter\n(Dec-Jan)""))) %>% 
  group_by(crossing, term, season, hour) %>% 
  summarize(
    bike_avg = mean(bike_count, na.rm = T),
    crossing_avg = unique(crossing_avg)
  ) %>% 
  group_by(crossing, term, season, hour) %>% 
  mutate(
    diff = -((crossing_avg - bike_avg) / crossing_avg), 
    diff = if_else(diff > 2.5, 2.5, diff)
  ) %>% 
  ggplot(aes(hour + 0.5, fct_rev(term))) +
    geom_tile(aes(fill = diff)) +
    scale_x_continuous(breaks = 0:24, expand = c(0, 0),
                       labels = c(""0"", """", """", """", """", """", 
                                  ""6"", """", """", """", """", """",
                                  ""12"", """", """", """", """", """",
                                  ""18"", """", """", """", """", """", ""24"")) +
    scale_y_discrete(expand = c(0, 0), position = ""right"") +
    #scale_fill_carto_c(palette = ""TealRose"", name = ""Hourly bike count relative to yearly mean per crossing"", 
    scale_fill_distiller(palette = ""RdYlGn"", name = ""Hourly bike count relative to yearly mean per crossing"",
                         limits = c(-1, 2.5),
                         breaks = seq(-1, 2.5, by = 0.5), 
                         labels = c(""-1.0"", ""-0.5"", ""0.0"", ""0.5"", ""1.0"", ""1.5"", ""2.0"", ""\u22652.5""),
                         guide = guide_colorbar(direction = ""horizontal"",
                                                barheight = unit(2, units = ""mm""), 
                                                barwidth = unit(120, units = ""mm""),
                                                draw.ulim = FALSE, title.position = 'top',
                                                title.hjust = 0.5, label.hjust = 0.5)) +
    facet_grid(season ~ crossing, switch = ""y"") +
    labs(x = ""Hour of the day"", y = NULL,
         caption = ""Visualization by Cdric Scherer"") +
    theme(strip.text.x = element_text(face = ""plain"", size = 10, angle = 0),
          strip.text.y = element_text(face = ""plain"", size = 10, angle = 180),
          strip.background = element_rect(fill = ""grey20"", color = ""transparent""),
          panel.spacing.x = unit(10, ""pt""), 
          axis.text.x = element_text(family = ""Roboto Mono"", size = 8),
          axis.text.y = element_text(size = 10),
          axis.title.x = element_text(size = 12),
          legend.title = element_text(size = 9.5),
          legend.text = element_text(family = ""Roboto Mono"", size = 8),
          legend.position = ""bottom"")

## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
         title = ""Riding the green wave in Seattle"",
         subtitle = ""Bike traffic (2014-2018) by seasons, based on data from seattle.gov\n"") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())

## full panel
title + bikes_season + plot_layout(width = c(0, 1))


ggsave(here::here(""plots"", ""2019_14"", ""2019_14_SeattleBikes_season.pdf""), 
       width = 14, height = 5, device = cairo_pdf)
```

***

```{r session}
sessionInfo()
```
","2019"
"156",420,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_16_DataVizMistakes.Rmd","---
title: ""TidyTuesday 2019/16 - Data Viz Mistakes	by The Economist""
author: ""Cedric Scherer""
date: ""26th of April 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(ggthemes)
library(cowplot)
library(patchwork)
library(emoGG)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

## Trade deficit in goods and the number of people employed in manufacturing

```{r data-trade}
df_trade <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/trade.csv"")
```

```{r plot-trade, fig.width = 14, fig.heigth = 5}
p1 <- df_trade %>% 
  mutate(
    trade_deficit = trade_deficit / 10^9, 
    manufacture_employment = manufacture_employment / 10^5,
  ) %>% 
  gather(cat, value, -year) %>% 
  ggplot(aes(year, value, fill = cat)) + 
    geom_col(width = 0.8) +
    geom_hline(yintercept = 0, color = ""red1"", size = 0.7) +
    scale_x_continuous(breaks = 1995:2016, 
                       labels = c(""1995"", """", """", """", """", """", """", """", """", """", 
                                  ""2005"", """", """", """", """", """", """", """", """", """", """", ""2016"")) +
    scale_y_continuous(limits = c(-380, 210), breaks = seq(-300, 200, by = 100)) +
    scale_fill_manual(name = """", values = c(""dodgerblue3"", ""firebrick4""), 
                      labels = c(""Manufacturing employment (100K)"",
                                 ""Trade deficit with China in goods ($B)"")) +
    guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
    labs(x = NULL, y = NULL, 
         title = """",
         subtitle = ""\n"", 
         caption = ""\nVisualization by Cdric Scherer  |  Sources: US Census Bureau; BLS"") +
    theme_economist() +
    theme(text = element_text(family = ""Open Sans""), 
          axis.text = element_text(size = 12),
          axis.text.y = element_text(hjust = 1),
          axis.ticks.length = unit(5, ""pt""),
          legend.text = element_text(size = 14),
          legend.position = ""top"",
          legend.justification = c(0, 1),
          plot.caption = element_text(color = ""grey40""),
          plot.background = element_rect(fill = ""#dcf0f7""),
          panel.grid.major.y = element_line(color = ""grey70"", size = 0.4),
          panel.background = element_rect(fill = ""#dcf0f7""))

p_trade <- ggdraw(p1) + 
  draw_text(""Free markets and free workers"", x = 0.01, y = 0.98, hjust = 0, vjust = 1, size = 20, family = ""Open Sans ExtraBold"") +
  draw_text(""United States"", x = 0.01, y = 0.91, hjust = 0, vjust = 1, size = 14, family = ""Open Sans"")
```

## Gender in the global research landscape

```{r data-reseach}
df_research <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"") %>% 
  mutate(
    field = if_else(field == ""Women inventores"", ""Inventores"", field),
    field = if_else(field == ""Computer science, maths"", ""Computer sciences"", field),
    field = fct_reorder(field, percent_women),
    type = if_else(country %in% c(""Japan"", ""EU28"", ""Portugal""), country, NA_character_),
    type = factor(type, levels = c(""Japan"", ""EU28"", ""Portugal""))
  )
```

```{r plot-research}
p2 <- df_research %>% 
  ggplot(aes(percent_women * 100, field)) + 
    geom_vline(xintercept = 0, color = ""black"", size = 0.7) + 
    geom_vline(xintercept = 50, color = ""red1"", size = 0.7) + 
    geom_point(data = filter(df_research, !is.na(type)), aes(color = type, fill = type), 
               size = 9, alpha = 0.8, shape = 21) +
    geom_point(data = filter(df_research, is.na(type)), size = 4.5, 
               color = ""black"", fill = ""grey40"", alpha = 0.4, shape = 21) + 
    scale_x_continuous(limits = c(0, 65), breaks = seq(0, 60, by = 10), expand = c(0, 0)) +
    scale_color_manual(values = c(""firebrick4"", ""turquoise4"", ""dodgerblue3""), name = NULL) +
    scale_fill_manual(values = c(""firebrick4"", ""turquoise4"", ""dodgerblue3""), name = NULL) +
    guides(color = guide_legend(override.aes = list(size = 4))) +
    labs(x = NULL, y = NULL, title = """", subtitle = ""\n\n"", 
         caption = '\n Number of inventores who filed patent applications\nSources: ""Gender in the Global Research Landscape"" by Elsevier; The Economist\nVisualization by Cdric Scherer') +
    theme_economist() +
    theme(text = element_text(family = ""Open Sans""), 
          axis.text = element_text(size = 14),
          axis.ticks.x = element_blank(),
          axis.line.x = element_blank(),
          legend.text = element_text(size = 11),
          legend.position = ""top"",
          plot.caption = element_text(color = ""grey40""),
          plot.background = element_rect(fill = ""#dcf0f7""),
          panel.grid.major.y = element_blank(),
          panel.grid.major.x = element_line(color = ""grey70"", size = 0.4),
          panel.background = element_rect(fill = ""#dcf0f7""))

p_research <- ggdraw(p2) + 
  draw_text(""Still a man's world"", x = 0.02, y = 0.98, 
            hjust = 0, vjust = 1, size = 20, family = ""Open Sans ExtraBold"") +
  draw_text(""Women among researchers with papers published"", 
            x = 0.02, y = 0.91, hjust = 0, vjust = 1, size = 14, family = ""Open Sans"") +
   draw_text(""(indexed in Scopus from 2011 to 2015, % of total)"", 
            x = 0.02, y = 0.86, hjust = 0, vjust = 1, size = 11, family = ""Open Sans"")
```

## Emoji and title

```{r plot-shrug}
p_emoji <- tibble(a = 1, b = 1) %>% 
  ggplot(aes(a, b)) + 
    geom_emoji(emoji = ""1f937"", size = 0.25) +
    annotate(""text"", x = 1, y = 1.015, label = ""Better?"", family = ""Merriweather"", 
             fontface = ""bold"", size = 9, color = ""grey85"") +
    scale_x_continuous(limits = c(0.975, 1.025)) +
    scale_y_continuous(limits = c(0.975, 1.025)) +
    coord_fixed() +
    labs(title = 'The Economists ""Mistakes, weve drawn a few - Learning from our errors in data visualisation""                 ',
         subtitle = ""\n"") +
    theme_void() + 
    theme(panel.background = element_rect(fill = ""grey20""), 
          plot.background = element_rect(fill = ""grey20""),
          plot.title = element_text(size = 20, color = ""white"", hjust = 0.5, family = ""Poppins"", face = ""bold""),
          plot.subtitle = element_text(size = 8, color = ""white"", hjust = 0.5, family = ""Poppins""))
```

## Full panel

```{r full-panel, fig.width = 14, fig.height = 5.6}
(p_trade + p_emoji + p_research) + plot_layout(nrow = 1, widths = c(1, 0.35, 0.85))

ggsave(here::here(""plots"", ""2019_16"", ""2019_16_DataVizMistakes.png""), 
       width = 14, height = 5.6, dpi = 300)
```

## Remix with light background

```{r plot-light, fig.width = 14, fig.height = 5.6}
theme_update(rect = element_rect(fill = ""grey98""))

p_emoji_light <- tibble(a = 1, b = 1) %>% 
  ggplot(aes(a, b)) + 
    geom_emoji(emoji = ""1f937"", size = 0.25) +
    annotate(""text"", x = 1, y = 1.015, label = ""Better?"", family = ""Merriweather"", 
             fontface = ""bold"", size = 9, color = ""grey30"") +
    scale_x_continuous(limits = c(0.975, 1.025)) +
    scale_y_continuous(limits = c(0.975, 1.025)) +
    coord_fixed() +
    labs(title = 'The Economists ""Mistakes, weve drawn a few - Learning from our errors in data visualisation""               ',
         subtitle = ""Redesigns of data visualizations originally published by The Economist which Sarah Leo found to be misleading (left) and too crowded given the limited space (right).                               \nIn the article, Sarah asked for new ideas how these visualizations can be redesigned to adress the shortcomings while following the The Economist's design rules.                               \n"") +
    theme_void() + 
    theme(panel.background = element_rect(fill = ""grey98""), 
          plot.background = element_rect(fill = ""grey98""),
          plot.title = element_text(size = 19, color = ""black"", hjust = 0.5, 
                                    family = ""Open Sans ExtraBold"", face = ""bold""),
          plot.subtitle = element_text(size = 10, color = ""grey30"", hjust = 0.5, 
                                       family = ""Merriweather"", lineheight = 1.3))
    
(p_trade + p_emoji_light + p_research) + plot_layout(nrow = 1, widths = c(1, 0.35, 0.85))

ggsave(here::here(""plots"", ""2019_16"", ""2019_16_DataVizMistakes_light.png""), 
       width = 14, height = 6, dpi = 300)
```

***

```{r session}
sessionInfo()
```
","2019"
"157",421,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_17_animes.Rmd","---
title: ""TidyTuesday 2019/17 - Anime Data by MyAnimeList.net""
author: ""Cedric Scherer""
date: ""23rd of April 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(ggrepel)
library(patchwork)
library(ghibli)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_ghibli <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"") %>% 
  filter(studio == ""Studio Ghibli"", type == ""Movie"") %>% 
  dplyr::select(animeID, title_english, title_japanese, genre, score, scored_by, members)
```

```{r plot-genres}
img_a <- png::readPNG(here::here(""img"", ""totoro.png"")) 
a <- grid::rasterGrob(img_a, interpolate = T) 

ghibli_genres <- df_ghibli %>% 
  group_by(genre) %>% 
  count() %>% 
  filter(n > 5) %>% 
  ungroup() %>% 
  mutate(genre = fct_reorder(genre, n)) %>% 
  ggplot(aes(genre, n)) +
    geom_col(aes(fill = genre)) +
    coord_flip() +
    scale_y_continuous(limits = c(0, 20), expand = c(0.01, 0)) +
    scale_fill_ghibli_d(""MononokeLight"") +
    guides(fill = F) + 
    labs(x = ""Most common genres"", y = ""Count"") +
    annotation_custom(a, xmin = 0.4, xmax = 6.75, ymin = 12, ymax = 23) +
    theme(axis.text.x = element_text(family = ""Roboto Mono""))
```

```{r plot-ratings}
img_b <- png::readPNG(here::here(""img"", ""ghibli.png""))
b <- grid::rasterGrob(img_b, interpolate = T) 

set.seed(1)

df_ghibli_unique <-df_ghibli %>% 
  group_by(animeID) %>% 
  summarize_all(first) %>% 
  mutate(title = glue::glue(""{title_japanese}\n({title_english})""))

ghibli_scores <- df_ghibli_unique %>% 
  ggplot(aes(score, scored_by)) +
    geom_point(aes(size = members), color = ""#F4C59D"", alpha = 0.6) +
    geom_text_repel(data = filter(df_ghibli_unique, scored_by > 120000), aes(label = title), size = 1.75, family = ""Poppins"", 
                    color = ""#F4C59D"", segment.size = 0.3, xlim = c(9.25, 10), box.padding = 0.5, force = 5) +
    scale_x_continuous(limits = c(5, 10)) +
    scale_y_continuous(labels = scales::comma, limits = c(0, 600000)) + 
    scale_size_continuous(name = ""Times listed by MAL users:"",
                          breaks = c(1000, 10000, 100000, 250000, 500000), 
                          labels = c(""  1,000"", "" 10,000"", ""100,000"", ""250,000"", ""500,000"")) +
    guides(size = guide_legend(override.aes = list(alpha = 1))) +
    labs(x = ""Average MAL user score"", y = ""Number of ratings"",
         caption = ""\nVisualization by Cdric Scherer  |  Picture credit: Studio Ghibli, Inc & MangoKingoroo"") +
    annotation_custom(b, xmin = 5, xmax = 8, ymin = 400000, ymax = 600000) +
    theme(axis.text = element_text(family = ""Roboto Mono""),
          legend.position = c(0.32, 0.4),
          legend.background = element_rect(fill = ""transparent""),
          legend.title = element_text(size = 9),
          legend.text = element_text(family = ""Roboto Mono"", size = 8))
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Studio Ghibli movies listed on MyAnimeList.net (MAL)"",
       subtitle = """") +
  theme(line = element_blank(),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        plot.subtitle = element_text(size = 7),
        panel.background = element_rect(fill = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r fullpanel, fig.width = 14, fig.heigth = 5}
## full panel
title + ghibli_genres + ghibli_scores + plot_layout(width = c(0, 1, 1))

ggsave(here::here(""plots"", ""2019_17"", ""2019_17_animes.png""), 
       width = 14, height = 5.1, dpi = 300)
```

***

```{r session}
sessionInfo()
```
","2019"
"158",422,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_18_BirdCollisions.Rmd","---
title: ""TidyTuesday 2019/18 - Chicago Bird Collisions	by Winger et al. 2019""
author: ""Cedric Scherer""
date: ""30th of April 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(ggalluvial)
library(patchwork)
library(ggsci)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
df_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")
```

```{r}
## collisions by family (1978-2016)
(birds_fams <- df_collisions %>% 
  filter(locality == ""MP"") %>% 
  mutate(
    sum = n(),
    flight_call = if_else(flight_call %in% c(""No"", ""Rare""), ""No/Rare"", flight_call)
  ) %>% 
  group_by(family) %>% 
  mutate(
    n = n(),
    group = if_else(n < 2500, ""Other"", family)
  ) %>% 
  group_by(group, habitat, stratum, flight_call) %>% 
  summarize(n = n(), pct = n() / unique(sum)) %>%
  group_by(group) %>% 
  mutate(n_fam = sum(n)) %>% 
  ungroup() %>% 
  mutate(
    group = fct_reorder(group, -n_fam),
    group = fct_relevel(group, ""Other"", after = 4),
    flight_call = factor(flight_call, levels = c(""Yes"", ""No/Rare"")),
    habitat = factor(habitat, levels = c(""Forest"", ""Edge"", ""Open""))
  ) %>% 
  ggplot(aes(axis1 = group, axis2 = habitat, axis3 = stratum, y = pct)) +
    geom_alluvium(aes(fill = flight_call)) +
    geom_stratum(fill = ""grey70"", color = ""grey20"", size = 0.1, width = 0.4) +
    geom_text(stat = ""stratum"", family = ""Poppins"", color = ""grey20"", 
              size = 3, fontface = ""plain"", label.strata = T) +
    scale_x_discrete(limits = c(""Family"", ""Habitat"", ""Stratum""), 
                     expand = c(0, 0), position = ""top"") +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1), expand = c(0, 0)) +
    scale_fill_simpsons(name = ""Flight calls during migration?"") +
    theme(axis.title.x = element_text(size = 12),
          axis.title.y = element_text(size = 12),
          axis.text.x = element_text(size = 11, color = ""white"", face = ""bold""),
          axis.text.y = element_text(size = 10, family = ""Roboto Mono""),
          legend.position = ""bottom"",
          legend.key.width = unit(6, ""lines""),
          legend.key.height = unit(0.75, ""lines""),
          legend.spacing.x = unit(0.5, 'cm'),
          legend.title = element_text(size = 10, face = ""bold""),
          legend.text = element_text(size = 9)) +
    guides(fill = guide_legend(title.position = ""top"", title.hjust = 0.5, label.position = ""bottom"")) +
    labs(x = NULL, y = ""Percentage of cases (1978-2016)""))
```

```{r}
## collision per light intensity and species (2000-2016)
img_a <- png::readPNG(here::here(""img"", ""ChigacoNight.png""))
chicago <- grid::rasterGrob(img_a, interpolate = T) 

img_b <- png::readPNG(here::here(""img"", ""zonotrichia_albicollis.png""))
zonoalbi <- grid::rasterGrob(img_b, interpolate = T)  

(birds_light <- df_collisions %>% 
  filter(date >= min(df_light$date)) %>% 
  inner_join(df_light) %>% 
  mutate(
    sum = n(),
    species = glue::glue(""{genus} {species}""), 
    light_intensity = cut(light_score, breaks = 3, labels = c(""low"", ""medium"", ""high""))
  ) %>% 
  group_by(species, light_intensity) %>% 
  summarize(n = n(), pct = n() / unique(sum)) %>% 
  group_by(species) %>% 
  mutate(pct_sum = sum(pct)) %>% 
  filter(pct_sum >= 0.02) %>% 
  ggplot(aes(fct_reorder(species, pct_sum), pct)) +
    geom_bar(aes(alpha = light_intensity), stat  = ""identity"", fill = ""#ffd700"") +
    coord_flip() +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1), expand = c(0, 0), 
                       limits = c(0, 0.21), position = ""right"") +
    scale_alpha_discrete(range = c(0.3, 1), name = ""Night-time light intensity:"") +
    annotation_custom(chicago, xmin = -0.6, xmax = 5.9, ymin = 0.0475, ymax = 0.21) +
    annotation_custom(zonoalbi, xmin = 0.4, xmax = 6.4, ymin = 0.0156, ymax = 0.07) +
    guides(alpha = guide_legend(title.position = ""top"", title.hjust = 0.5, 
                                label.position = ""bottom"", reverse = T)) +
    labs(x = ""\nMost frequently detected species"", y = ""Percentage of cases (2000-2016)"",
         title = """",
         caption = ""\nVisualization by Cdric Scherer  |  Data: Winger et al. 2019 (doi: 10.1098/rspb.2019.0364)"") +
    theme(axis.title.x = element_text(size = 12),
          axis.title.y = element_text(size = 12),
          axis.text.x = element_text(size = 10, family = ""Roboto Mono""),
          axis.text.y = element_text(size = 10, face = ""italic""),
          legend.position = ""bottom"",
          legend.key.width = unit(6, ""lines""),
          legend.key.height = unit(0.75, ""lines""),
          legend.spacing.x = unit(0.5, 'cm'),
          legend.title = element_text(size = 10, face = ""bold""),
          legend.text = element_text(size = 9),
          plot.margin = margin(12, 50, 12, 12)))
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
         title = ""What drives collision risk in nocturnally migrating passerine birds?"",
         subtitle = ""Nocturnal bird collisions at McCormick Place, Chicago, IL"") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.5}
## full panel

## save as panel
title + birds_fams + birds_light + plot_layout(width = c(0, 1, 0.7))

ggsave(here::here(""plots"", ""2019_18"", ""2019_18_BirdCollisions.pdf""), 
       width = 14, height = 5.2, device = cairo_pdf)
```

***

```{r session}
sessionInfo()
```","2019"
"159",423,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_19_StudentTeacher.Rmd","---
title: ""TidyTuesday 2019/19 - Global Student to Teacher Ratios by UNESCO""
author: ""Cedric Scherer""
date: ""7th of May 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(egg)
library(rcartocolor)
library(LaCroixColoR)
library(patchwork)

## ggplot theme updates
source(""../theme/tidy_grey.R"")
```

```{r data}
df_students <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")
df_world_tile <- readr::read_csv(""https://gist.githubusercontent.com/maartenzam/787498bbc07ae06b637447dbd430ea0a/raw/9a9dafafb44d8990f85243a9c7ca349acd3a0d07/worldtilegrid.csv"") %>% 
  mutate(
    alpha.2 = if_else(name == ""Namibia"", ""NA"", alpha.2),
    region = if_else(region == ""Americas"", sub.region, region),
    region = if_else(region %in% c(""Northern America"", ""Central America"", ""Caribbean""), ""North America"", region),
    region = if_else(region == ""Southern America"", ""South America"", region),
    region = fct_reorder(region, x)
  )
```

```{r data-proc}
## data merged with tile map
df_students_tile <- df_students %>% 
  group_by(country, indicator) %>% 
  filter(year == max(year)) %>% 
  ungroup() %>% 
  complete(indicator, nesting(country, country_code)) %>% 
  filter(
    indicator %in% c(""Primary Education"", ""Secondary Education"", ""Tertiary Education""), 
    str_detect(country_code, ""[A-Z]"")
  ) %>% 
  mutate(alpha.3 = country_code) %>%
  full_join(df_world_tile) %>%
  filter(
    !is.na(indicator),
    !is.na(region)
  ) %>% 
  mutate(alpha.2 = if_else(country == ""Namibia"", ""NA"", alpha.2))
```

```{r lollipop}
## worldwide average
world_avg <- df_students_tile %>% 
  filter(indicator == ""Primary Education"") %>% 
  summarize(avg = mean(student_ratio, na.rm = T)) %>% 
  pull(avg)

## regions
map_regions <- df_students_tile %>% 
  filter(indicator == ""Primary Education"") %>% 
  ggplot(aes(x = x, y = y, fill = region, color = region)) + 
    geom_tile() +
    scale_y_reverse() +
    scale_fill_manual(values = lacroix_palette(""PeachPear"", n = 6, type = ""discrete""), guide = F) +
    scale_color_manual(values = lacroix_palette(""PeachPear"", n = 6, type = ""discrete""), guide = F) +
    coord_equal() +
    theme(line = element_blank(),
          panel.background = element_rect(fill = ""transparent""),
          plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
          panel.border = element_rect(colour = ""transparent""),
          strip.background = element_rect(colour = ""grey20""),
          axis.text = element_blank(),
          plot.margin = margin(0, 0, 0, 0)) +
    labs(x = NULL, y = NULL)

## lollipop plot
arrows <- tibble(
  x1 = c(world_avg + 6, 10.5, 11, 11, 76),
  x2 = c(world_avg + 0.2, 17.8, 14.1, 16.4, 83.41195),
  y1 = c(6, 3.65, 1.6, 1.6, 1.8),
  y2 = c(5.6, 4, 2.15, 1.95, 1.1)
)

set.seed(2019)

lolli_country <- df_students_tile %>% 
  filter(indicator == ""Primary Education"") %>% 
  group_by(region) %>% 
  mutate(student_ratio_cont = mean(student_ratio, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(
    region = fct_reorder(region, -student_ratio_cont), 
    region_col = fct_reorder(region, x)
  ) %>% 
  ggplot(aes(student_ratio_cont, region)) + 
    geom_vline(aes(xintercept = world_avg), color = ""grey85"") +
    geom_jitter(aes(x = student_ratio, y = region, fill = region_col), color = ""grey85"", 
                width = 0, height = 0.2, size = 2.5, alpha = 0.3, shape = 21) +
    geom_segment(aes(x = world_avg, xend = student_ratio_cont, y = region, yend = region), 
                 color = ""grey85"", size = 0.7) +
    geom_point(color = ""grey85"", size = 6) + 
    geom_point(aes(color = region_col), size = 5) + 
    annotate(""text"", x = 35, y = 6.3, family = ""Poppins"", size = 2.5, color = ""grey85"", 
             label = glue::glue(""Worldwide average:\n{round(world_avg, 1)} students per teacher"")) +
    annotate(""text"", x = 10, y = 3.5, family = ""Poppins"", size = 2.5, 
             color = ""grey85"", label = ""Continental average"") +
    annotate(""text"", x = 10, y = 1.5, family = ""Poppins"", size = 2.5, 
             color = ""grey85"", label = ""Countries"") +
    annotate(""text"", x = 65, y = 1.9, family = ""Poppins"", size = 2, color = ""grey85"", 
             label = ""The Central African Republic has by far\nthe most students per teacher"") +
    geom_curve(data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2), 
               arrow = arrow(length = unit(0.1, ""inch"")), 
               size = 0.3, color = ""grey85"", curvature = -0.3) +
    annotation_custom(ggplotGrob(map_regions), 
                      xmin = 55, xmax = 85, ymin = 2.5, ymax = 7.5) +
    scale_x_continuous(limits = c(1, 85), breaks = c(1, seq(10, 80, by = 10))) +
    scale_fill_manual(values = lacroix_palette(""PeachPear"", n = 6, type = ""discrete""), guide = F) +
    scale_color_manual(values = lacroix_palette(""PeachPear"", n = 6, type = ""discrete""), guide = F) +
    labs(x = NULL, y = NULL, caption = NULL) +
    theme(axis.title.x = element_text(size = 12, face = ""plain""),
          axis.text.x = element_text(size = 9, family = ""Roboto Mono""),
          axis.text.y = element_text(size = 12))
```

```{r map}
## primary education map by country
map_country <- df_students_tile %>% 
  filter(indicator == ""Primary Education"") %>% 
  ggplot(aes(x = x, y = y, fill = student_ratio)) + 
    geom_tile(color = ""grey70"") +
    geom_tile(data = filter(df_students_tile, is.na(student_ratio), 
                            indicator == ""Primary Education""), 
              fill = ""grey40"", color = ""grey70"") +
    geom_text(aes(x = x, y = y, label = alpha.2), color = ""white"", size = 2.3, 
              fontface = ""bold"", family = ""Roboto Mono"") +
    scale_y_reverse() +
    scale_fill_carto_c(palette = ""ag_Sunset"", limits = c(1, 85), breaks = c(1, seq(10, 80, by = 10)), name  = NULL,
                       guide = guide_colourbar(direction = ""horizontal"",
                                               barheight = unit(1.5, units = ""mm""), 
                                               barwidth = unit(120, units = ""mm""),
                                               draw.ulim = FALSE, title.position = 'bottom',
                                               title.hjust = 0.5, label.hjust = 0.5)) + 
    coord_equal() +
    theme(legend.position = c(0.5, 1.1),
          line = element_blank(),
          axis.text = element_blank(),
          axis.title.x = element_text(size = 10.8, color = ""white"", face = ""plain"", hjust = 1),
          legend.text = element_text(family = ""Roboto Mono"", size = 9),
          panel.border = element_rect(colour = ""grey20""),
          strip.background = element_rect(colour = ""grey20"")) +
    labs(caption = '\nVisualization by Cdric Scherer  |  Data: ""eAtlas of Teachers"" by UNESCO', x = NULL, y = NULL)
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Global student to teacher ratios in primary education"", 
       subtitle = ""Latest reported student to teacher ratio per country and continent (2012-2018)\n"")+
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(colour = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.5}
## full panel
title + lolli_country + map_country + plot_layout(width = c(0, 1, 0.8))

ggsave(""../plots/2019_19/2019_19_StudentTeacher.pdf"", width = 14, height = 5.5, device = cairo_pdf)
```

## Version 2: Facet with All Levels of Education

```{r plot-facets}
## facetted by prim., sec. and tert. education level
maps_facet <- df_students_tile %>% 
  ggplot(aes(x = x, y = y, fill = student_ratio)) + 
    geom_tile(color = ""grey70"", size = 0.1) +
    geom_tile(data = filter(df_students_tile, is.na(student_ratio)), 
              fill = ""grey40"", color = ""grey70"", size = 0.1) +
    geom_text(aes(x = x, y = y, label = alpha.2), color = ""white"", size = 1.6, 
              fontface = ""bold"", family = ""Roboto Mono"") +
    scale_y_reverse() +
    scale_fill_carto_c(palette = ""ag_Sunset"", limits = c(1, 85), breaks = c(1, seq(10, 80, by = 10)), name  = NULL,
                       guide = guide_colourbar(direction = ""horizontal"",
                                               barheight = unit(1.5, units = ""mm""), 
                                               barwidth = unit(120, units = ""mm""),
                                               draw.ulim = FALSE, title.position = 'bottom',
                                               title.hjust = 0.5, label.hjust = 0.5)) + 
    coord_equal() +
    facet_wrap(~indicator) +
    theme(line = element_blank(),
          axis.text = element_blank(),
          legend.position = c(0.5, -0.1),
          legend.text = element_text(family = ""Roboto Mono"", size = 9),
          panel.border = element_rect(colour = ""grey20""),
          strip.background = element_rect(colour = ""grey20"")) +
    labs(caption = '\nVisualization by Cdric Scherer  |  Data: ""eAtlas of Teachers"" by UNESCO', x = """", y = NULL)

title_facet <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Global student to teacher ratios"", 
       subtitle = ""Latest reported student to teacher ratio per country and educational level (2012-2018)\n"")+
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(colour = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel-2, fig.width = 14, fig.height = 5.4}
title_facet + maps_facet + plot_layout(widths = c(0, 1))

ggsave(here::here(""plots"", ""2019_19"", ""2019_19_StudentTeacher_facet.pdf""), 
       width = 14, height = 5.5, device = cairo_pdf)
```

***

```{r session}
sessionInfo()
```
","2019"
"160",424,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_20_NobelPriceWinners.Rmd","---
title: ""TidyTuesday 2019/20 - Nobel Prize Winners by Harvard Dataverse""
author: ""Cedric Scherer""
date: ""14th of May 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(scico)
library(emojifont)
library(showtext)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))

## add fonts via showtext (extrafont and emojifont do not worl together)
font_add_google(""Poppins"", ""Poppins"")
font_add_google(""Roboto Mono"", ""Roboto Mono"")
showtext_auto()
```

```{r data}
df_nobel <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
```

```{r plot, fig.width = 14, fig.height = 5.5}
## tile plot facetted by gender
tile_gender <- df_nobel %>% 
  filter(laureate_type == ""Individual"") %>% 
  mutate(decade = glue::glue(""{round(prize_year - 1, -1)}s"")) %>% 
  group_by(decade, category) %>% 
  mutate(ind_awards = n()) %>%
  group_by(decade, category, gender) %>% 
  summarize(prop = n() / unique(ind_awards)) %>%  
  ungroup() %>% 
  complete(decade, category, gender, fill = list(prop = 0)) %>% 
  group_by(decade, category) %>% 
  mutate(
    prop_fem = min(prop),
    prop_male = max(prop)
  ) %>% 
  group_by(category) %>% 
  mutate(avg_fem = mean(prop_fem)) %>% 
  ungroup() %>% 
  mutate(
    label = if_else(gender == ""Male"", fontawesome(""fa-mars""), 
                                      fontawesome(""fa-venus"")),
    category = fct_reorder(category, avg_fem),
    prop = if_else((prop_fem + prop_male) == 0, NA_real_, prop)
  ) %>% 
  ggplot(aes(decade, category, color = prop, label = label)) +
    geom_tile(fill = ""grey25"", color = ""grey20"", size = 0.7) +
    geom_text(family = 'fontawesome-webfont', size = 8) +
    facet_grid(. ~ gender) +
    scale_color_scico(palette = ""buda"", name = NULL, na.value = ""grey25"",
                      guide = guide_colorbar(direction = ""horizontal"",
                                             barheight = unit(3, units = ""mm""), 
                                             barwidth = unit(150, units = ""mm""),
                                             draw.ulim = FALSE, title.position = 'bottom',
                                             title.hjust = 0.5, label.hjust = 0.5)) +
    theme(strip.text = element_blank(),
          panel.spacing.x = unit(15, ""pt""),
          axis.text.x = element_text(family = ""Roboto Mono"", size = 9),
          legend.position = ""bottom"",
          axis.ticks = element_blank(),
          panel.border = element_rect(color = ""grey20"")) + 
    labs(x = NULL, y = NULL,
         caption = '\nVisualization by Cdric Scherer  |  Data: Harvard Dataverse, Li et al. 2018, doi: 10.7910/DVN/6NJ5RN')
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = 'The male dominance of the Nobel prize',
       subtitle = ""Proportion of female and male Nobel prize winners per category and decade.\n"") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.5}
## full panel
title + tile_gender + plot_layout(width = c(0, 1))

ggsave(here::here(""plots"", ""2019_20"", ""2019_20_NobelPrizeWinners.pdf""), 
       width = 14, height = 5.2, device = cairo_pdf)
```

***

```{r session}
sessionInfo()
```
","2019"
"161",425,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_21_PlasticWaste.Rmd","---
title: ""TidyTuesday 2019/21 - Global Plastic Waste by OurWorldInData.org""
author: ""Cedric Scherer""
date: ""7th of May 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(sf)
library(maptools)
library(scico)
library(patchwork)
library(cowplot)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_plastic_coast <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>% 
  rename(waste_t = `Mismanaged plastic waste (tonnes)`,
         population = `Total population (Gapminder)`)

df_mismanaged_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>% 
  rename(
    mismanaged_pc = `Per capita mismanaged plastic waste (kilograms per person per day)`,
    gdp = `GDP per capita, PPP (constant 2011 international $) (Rate)`,
    population = `Total population (Gapminder)`
  )

df_waste_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>% 
  rename(waste_pc = `Per capita plastic waste (kilograms per person per day)`)
```


```{r data-spatial}
data(""wrld_simpl"")

df_waste_gdp_map <- wrld_simpl %>%
  st_as_sf() %>%
  st_transform(crs = ""+proj=robin"") %>% 
  mutate(ISO3 = as.character(ISO3)) %>% 
  left_join(df_waste_gdp, by = c(""ISO3"" = ""Code"")) %>% 
  filter(Year == 2010)
```

```{r data-proportional}
df_plastic_prop <- df_mismanaged_gdp %>% 
  left_join(df_waste_gdp) %>% 
  filter(Year == 2010) %>% 
  select(Entity, Code, waste_pc, mismanaged_pc) %>% 
  mutate(
    prop_rec = (waste_pc - mismanaged_pc) / waste_pc,
    prop_mis = mismanaged_pc / waste_pc
  )
```

```{r map}
map_waste_prop <- df_waste_gdp_map %>% 
  left_join(df_plastic_prop, by = c(""ISO3"" = ""Code"")) %>% 
  mutate(prop_mis_cut = cut(prop_mis, breaks = seq(0, 0.9, by = 0.1))) %>% 
  ggplot() +
    geom_sf(aes(geometry = geometry, fill = prop_mis_cut), 
            color = ""grey20"", size = 0.05) +
    scale_fill_scico_d(palette = ""bilbao"", na.value = ""grey30"", 
                       name = ""Proportion of mismanaged plastic waste"",
                       labels = c(""0%10%"", ""10%20%"", ""20%30%"", 
                                  ""30%40%"", ""40%50%"", ""50%60%"", 
                                  ""60%70%"", ""70%80%"", ""80%90%"", 
                                  ""missing data"")) +
    theme(legend.position = c(0.55, -0.28),
          legend.key.height = unit(0.5, ""lines""), 
          legend.key.width = unit(3, ""lines""),
          legend.text = element_text(family = ""Roboto Mono"", size = 9),
          legend.title = element_text(face = ""bold"", 
                                      color = ""grey90"", size = 10.5),
          panel.border = element_rect(color = NA),
          axis.ticks.x = element_blank(),
          axis.text.x = element_text(family = ""Roboto Mono"",
                                     size = 9, color = ""grey40""),
          panel.grid.major = element_line(color = ""grey40"",
                                          size = 0.15)) +
    guides(fill = guide_legend(title.position = ""top"", 
                               title.hjust = 0.5, nrow = 1,
                               label.position = ""bottom"")) 
```

```{r bar-plots}
bar_waste <- df_plastic_prop %>% 
  top_n(20, waste_pc) %>% 
  ggplot(aes(fct_reorder(Entity, waste_pc), waste_pc)) + 
    geom_col(fill = ""#d6aa84"", width = 0.7) +
    geom_hline(yintercept = 0, color = ""grey40"", size = 0.15) +
    coord_flip() +
    scale_y_continuous(expand = c(0, 0), limits = c(0, 4), 
                       breaks = seq(0, 4, by = 1)) +
    theme(axis.ticks = element_blank(),
          axis.text.x = element_text(size = 9, family = ""Roboto Mono""),
          axis.text.y = element_text(size = 9),
          axis.title.x = element_text(size = 10.5, face = ""plain""),
          panel.border = element_rect(color = NA),
          panel.grid.major.x = element_line(color = ""grey40"", 
                                            size = 0.15)) +
    labs(x = NULL, y = ""Plastic waste\nper capita in kg"")
    
bar_mismanaged <- df_plastic_prop %>% 
  top_n(20, mismanaged_pc) %>% 
  ggplot(aes(fct_reorder(Entity, mismanaged_pc), mismanaged_pc)) + 
    geom_col(fill = ""#bb4848"", width = 0.7) +
    geom_hline(yintercept = 0, color = ""grey40"", size = 0.15) +
    coord_flip() +
    scale_y_continuous(expand = c(0, 0), limits = c(0, 0.3), 
                       breaks = seq(0, 0.3, by = 0.1)) +
    theme(axis.ticks = element_blank(),
          axis.text.x = element_text(size = 9, family = ""Roboto Mono""),
          axis.text.y = element_text(size = 9),
          axis.title.x = element_text(size = 10.5, face = ""plain""),
          panel.border = element_rect(color = NA),
          panel.grid.major.x = element_line(color = ""grey40"", 
                                            size = 0.15)) +
    labs(x = NULL, y = ""Mismanaged plastic waste\nper capita in kg"")
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Plastic pollution  absolute and relative plastic waste generation across the world"",
       subtitle = glue::glue(""Middle- and low income countries tend to generate high amounts of"",
                             "" mismanaged waste which is at high risk of entering the ocean.\n"")) +
  theme(line = element_blank(),
        panel.background = element_rect(fill = NA),
        plot.background = element_rect(fill = NA, color = NA),
        panel.border = element_rect(color = NA),
        axis.text = element_blank())
```

```{r caption}
## right-alligned caption
caption <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       caption = '\n\nVisualization by Cdric Scherer  |  Data: Ritchie & Roser (2019), OurWorldInData.org') +
  theme(line = element_blank(),
        panel.background = element_rect(fill = NA),
        plot.background = element_rect(fill = NA, color = NA),
        panel.border = element_rect(color = NA),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.2}
title + bar_waste + map_waste_prop + bar_mismanaged + caption +
  plot_layout(widths = c(0, 0.27, 1, 0.25, 0), nrow = 1)

ggsave(here::here(""plots"", ""2019_21"", ""2019_21_PlasticWaste.pdf""), 
       width = 14, height = 5.2, device = cairo_pdf)
```

***

```{r session}
sessionInfo()
```","2019"
"162",426,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_22_Wines.Rmd","---
title: ""TidyTuesday 2019/22 - Wine Ratings by Vivino""
author: ""Cedric Scherer""
date: ""28th of May 2019""
output:
  html_document:
    theme: paper
    highlight: kate
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_wines <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>% 
  dplyr::select(-X1) %>% 
  unique()
```

```{r data-top-countries}
df_wines_top_countries <- df_wines %>% 
  group_by(country) %>% 
  summarize(
    rating = mean(points, na.rm = T),
    n = n()
  ) %>% 
  mutate(rating = (rating - 80) / 20) %>% 
  filter(
    !is.na(country),
    n > 99
  ) %>%
  top_n(6, rating)
```


```{r plot}
img_b <- png::readPNG(""../img/bottle.png"") 
bottle <- grid::rasterGrob(img_b, interpolate = T) 

bottles <- df_wines_top_countries  %>% 
  mutate(country = fct_reorder(country, -rating)) %>% 
  ggplot(aes(country, rating)) +
    geom_col(width = 12, fill = ""#770000"") +
    annotation_custom(bottle, xmin = -24, xmax = 26, ymin = 0, ymax = 1.3) +
    facet_wrap(~ country, nrow = 1, scales = ""free_x"", strip.position = ""bottom"") +
    scale_x_discrete(expand = c(10, 10)) +
    scale_y_continuous(limits = c(0, 1.3), breaks = seq(0, 1, by = 0.25), 
                       labels = c(""80"", ""85"", ""90"", ""95"", ""100"")) +
    theme(plot.caption = element_text(size = 9),
          plot.margin = margin(0, 0, 0, 0),
          axis.title.y = element_text(size = 14, hjust = 0.3),
          axis.text.x = element_blank(),
          axis.text.y = element_text(size = 14, family = ""Roboto Mono""),
          axis.ticks = element_blank(),
          strip.background = element_rect(color = NA),
          strip.text = element_text(size = 16, vjust = 1),
          panel.border = element_rect(color = NA),
          panel.grid.major.y = element_line(color = ""grey30""),
          panel.spacing = unit(0, ""lines"")) +
  labs(x = NULL, y = ""Rating"", title = NULL, subtitle = NULL)
```

```{r}
words <- df_wines %>% 
  group_by(country) %>% 
  mutate(rating = mean(points, na.rm = T)) %>% 
  filter(country %in% df_wines_top_countries$country) %>%
  ungroup() %>% 
  mutate(country = fct_reorder(country, -rating)) %>% 
  group_by(country, variety) %>% 
  summarize(
    rating = mean(points, na.rm = T),
    count = n()
  ) %>% 
  arrange(-rating, -count) %>% 
  slice(1:5) %>% 
  mutate(id = row_number()) %>% 
  dplyr::select(-rating, -count) %>% 
  spread(id, variety) %>% 
  ggplot() +
    geom_text(aes(x = 5, y = 5, label = `1`), size = 3.5, family = ""Poppins"", color = ""#fff8f8"") + 
    geom_text(aes(x = 5, y = 4, label = `2`), size = 3.5, family = ""Poppins"", color = ""#ffc5c5"") + 
    geom_text(aes(x = 5, y = 3, label = `3`), size = 3.5, family = ""Poppins"", color = ""#ff7878"") + 
    geom_text(aes(x = 5, y = 2, label = `4`), size = 3.5, family = ""Poppins"", color = ""#ff2b2b"") + 
    geom_text(aes(x = 5, y = 1, label = `5`), size = 3.5, family = ""Poppins"", color = ""#c40000"") + 
    facet_wrap(~ country, nrow = 1, scales = ""free_y"") +
    theme(strip.text = element_blank(),
          axis.text = element_blank(),
          axis.title = element_blank(),
          panel.border = element_rect(color = ""transparent""),
          panel.spacing = unit(0, ""lines""),
          axis.ticks = element_blank()) +
    labs(caption = ""\nVisualization by Cdric Scherer  |  Data source: Kaggle"")
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""The best wines you can get."",
       subtitle = ""Highest average rating for countries with \u2265 100 wines and their 5 highest rated varieties listed on Vivino  (based on reviews with 80 points or more).\n"") +
  theme(line = element_blank(),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.background = element_rect(fill = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.3}
title + 
  (bottles + words + plot_layout(heights = c(1, 0.45), ncol = 1)) + 
  plot_layout(widths = c(0, 1))

ggsave(here::here(""plots"", ""2019_22"", ""2019_22_Wines.pdf""), 
       width = 14, height = 5.3, device = cairo_pdf)
```

***

```{r}
sessionInfo()
```
","2019"
"163",427,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_24_Meteorites.Rmd","---
title: ""TidyTuesday 2019/24 - Meteorites by NASA""
author: ""Cedric Scherer""
date: ""11th of June 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(patchwork)
library(showtext)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
theme_update(rect = element_rect(fill = ""black"", color = ""black""))

## add spacy font
font_add_google(""Orbitron"", ""Orbitron"")
font_add_google(""Roboto Mono"", ""Roboto Mono"")
showtext_auto()
```

```{r data}
df_meteor <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>% 
  mutate(
    decade = year - year %% 10,
    century = year - year %% 100
  )
```

```{r lineplot}
df_line <- df_meteor %>% 
  filter(
    decade >= 1500,
    fall == ""Fell"",
  ) %>% 
  group_by(decade) %>% 
  count() %>% 
  complete(decade = seq(1500, 2010, by = 10), fill = list(n = 0)) %>% 
  unique()

avg <- df_line %>% 
  ungroup() %>% 
  filter(decade < 2010) %>% 
  summarize(mean = mean(n)) %>% 
  pull(mean)

time_series <- df_line %>% ggplot(aes(decade, n)) +
  geom_line(size = 0.8, color = ""green"", alpha = 0.5) +
  geom_ribbon(aes(ymin = -Inf, ymax = n), fill = ""green"", alpha = 0.1) +
  geom_point(size = 1.25, color = ""green"") +
  geom_hline(aes(yintercept = avg), linetype = ""dashed"", color = ""green"", size = 0.8) +
  geom_point(data = filter(df_line, decade == 2010), aes(decade, n), 
             color = ""red"", alpha = 0.2, size = 15) +
  geom_point(data = filter(df_line, decade == 2010), aes(decade, n), 
             color = ""red"", alpha = 0.5, size = 5) +
  geom_point(data = filter(df_line, decade == 2010), aes(decade, n), 
             color = ""red"", size = 2) +
  annotate(""text"", x = 1710, y = 85, label = ""WARNING!"", color = ""red"", 
           family = ""Orbitron"", size = 8, fontface = ""bold"") +
  annotate(""text"", x = 1710, y = 78, label = ""The number of fallen meteorites"", 
           color = ""grey85"", family = ""Roboto Mono"", size = 3.7) +
  annotate(""text"", x = 1710, y = 74, label = ""is drastically decreasing!"", 
           color = ""grey85"", family = ""Roboto Mono"", size = 3.7) +
  scale_x_continuous(expand = c(0, 0), breaks = seq(1500, 2050, by = 50), 
                     limits = c(1490, 2055)) +
  scale_y_continuous(expand = c(0,0), limits = c(-2, 100), 
                     breaks = seq(0, 100, by = 10)) + 
  theme(panel.border = element_rect(color = ""grey40""),
        axis.text = element_text(family = ""Roboto Mono"", size = 9, 
                                 color = ""#009d00"", face = ""bold""),
        axis.ticks.length = unit(3, ""pt""),
        axis.ticks = element_line(color = ""transparent"")) +
  labs(x = NULL, y = NULL)
```

```{r map}
df_meteor_prev <- df_meteor %>% 
  filter(
    fall == ""Fell"", 
    decade >= 1500, 
    decade < 2010
  )

df_meteor_now <- df_meteor %>% 
  filter(
    fall == ""Fell"", 
    decade == 2010
  )

df_meteor_heavy <- df_meteor %>% 
  filter(
    fall == ""Fell"", 
    decade >= 1500
  ) %>% 
  mutate(group = if_else(decade == 2010, ""now"", ""prev"")) %>% 
  group_by(group) %>% 
  top_n(1, mass) %>% 
  mutate(
    name = glue::glue(""> {name} ({year})""),
    class = glue::glue(""> Class: {class}""),
    mass = glue::glue(""> Mass: {mass / 1000} kg"")
  )

map_pixel <- ggplot(map_data(""world""), aes(round(long, 0), round(lat, 0))) +
  geom_polygon(aes(group = group), fill = ""#001810"", color = ""#004e00"") +
  geom_point(data = df_meteor_prev, aes(long, lat), color = ""green"", size = 0.8, alpha = 0.35) +
  geom_point(data = df_meteor_now, aes(long, lat), color = ""red"", size = 9, alpha = 0.2) +
  geom_point(data = df_meteor_now, aes(long, lat), color = ""red"", size = 3.3, alpha = 0.5) +
  geom_point(data = df_meteor_now, aes(long, lat), color = ""red"", size = 1.5) +
  geom_rect(data = df_meteor_heavy, 
            aes(xmin = long - 25, xmax = long + 25, ymin = lat + 13.5, ymax = lat + 32), 
            color = ""grey55"", fill = ""#001810"", alpha = 0.7, size = 0.15) +
  geom_segment(data = df_meteor_heavy, 
               aes(x = long, xend = long, y = lat, yend = lat + 13.5), 
               color = ""grey55"", size = 0.5) +
  geom_segment(data = df_meteor_heavy, 
               aes(x = long - 25.1, xend = long + 25.1, y = lat + 13.5, yend = lat + 13.5), 
               color = ""grey55"", size = 1.3) +
  geom_text(data = df_meteor_heavy, aes(long - 23, lat + 28, label = name), 
            family = ""Orbitron"", color = ""green"", size = 2.5, fontface = ""bold"", hjust = 0) +
  geom_text(data = df_meteor_heavy, aes(long - 23, lat + 23, label = class), 
            family = ""Orbitron"", color = ""grey85"", size = 2.5, fontface = ""bold"", hjust = 0) +
  geom_text(data = df_meteor_heavy, aes(long - 23, lat + 18, label = mass), 
            family = ""Orbitron"", color = ""grey85"", size = 2.5, fontface = ""bold"", hjust = 0) +
  annotate(""text"", x = -162, y = -28, label = ""Please Enter Password for User 'NASA1'"", 
           color = ""grey85"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  annotate(""text"", x = -162, y = -33, label = ""> TRUMP123456"", 
           color = ""green"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  annotate(""text"", x = -162, y = -38, label = ""Welcome Mr. President!"", 
           color = ""grey85"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  annotate(""text"", x = -162, y = -43, label = ""> MapView.Basic(MeteoritesV19.06.12)"", 
           color = ""green"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  annotate(""text"", x = -162, y = -48, label = ""Processing: |||||||||||||||||||| 100%"", 
           color = ""grey85"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  annotate(""text"", x = -162, y = -53, label = ""Map `MeteoritesV19.06.12` loaded."", 
           color = ""grey85"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  annotate(""text"", x = -162, y = -58, label = ""> MapView.Highlight(MeteoritesV19.06.12$recent)"", 
           color = ""green"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  annotate(""text"", x = -162, y = -63, label = ""Processing: |||||||||||||| 73.4%"", 
           color = ""grey85"", family = ""Roboto Mono"", size = 2.3, hjust = 0) +
  scale_x_continuous(breaks = seq(-200, 200, by = 25), expand = c(0, 0)) +
  scale_y_continuous(breaks = seq(-100, 100, by = 25)) +
  scale_size_continuous(range = c(0.25, 1)) +
  coord_fixed(xlim = c(-165, 180), ylim = c(-76, 82)) +
  theme(plot.caption = element_text(family = ""Orbitron"",  
                                    color = ""grey20"", face = ""bold""),
        legend.position = ""none"",
        panel.border = element_rect(color = ""grey40""),
        axis.text = element_blank(),
        axis.ticks = element_line(color = ""transparent"")) +
  labs(x = NULL, y = NULL, 
       caption = ""Provided by Cdric Scherer & National Aeronautics and Space Administration (NASA)  "")
```

```{r title}
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""                                          SPACE OBSERVER 3000 X V3.5.1"") +
  theme(plot.title = element_text(family = ""Orbitron"", color = ""grey20""),
        line = element_blank(),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.background = element_rect(fill = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r panel, fig.width = 14, fig.height = 5.3}
(title + time_series + map_pixel + plot_layout(widths = c(0, 0.5, 1))) * 
  theme(panel.grid.major = element_line(color = ""#153915""),
        panel.grid.minor = element_line(color = ""#002700"")) 

ggsave(here::here(""plots"", ""2019_24"", ""2019_24_Meteorites.pdf""), 
       width = 14, height = 5.3, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"164",428,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_25_BirdsXmas.Rmd","---
title: ""TidyTuesday 2019/25 - Christmas Bird Counts by Bird Studies Canada""
author: ""Cedric Scherer""
date: ""25th of August 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_birds <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"") %>% 
  mutate(
    decade = year - year %% 10,
    genus = word(species_latin, 1)
  ) %>% 
  group_by(decade) %>% 
  mutate(n_years = n_distinct(year))
```

```{r data-check}
## check n() per species and year
df_birds %>% 
  group_by(species, year) %>% 
  filter(n() > 1)
```

```{r common-birds-top3}
df_birds_common <- df_birds %>%
  group_by(species, species_latin) %>%
  summarize(sum = sum(how_many_counted)) %>% 
  ungroup() %>% 
  top_n(3, sum) %>% 
  arrange(sum)

cols <- c(""#e0c396"", ""#c38b38"", ""#7e4b31"", ""#1d1414"")

df_labels <- tibble(
  species = c(""Other"", pull(df_birds_common[1])),
  species_latin = c("""", pull(df_birds_common[2])),
  col = cols,
  x = 2014,
  y1 = rev(seq(4000, 21000, length.out = 4)),
  y2 = rev(seq(1800, 18800, length.out = 4))
)

p_starling <- df_birds %>% 
  mutate(species = if_else(species %in% 
                             pull(df_birds_common[1]), species, ""Other"")) %>%
  group_by(species, decade) %>% 
  summarize(counts_year = sum(how_many_counted) / unique(n_years)) %>% 
  ungroup() %>% 
  mutate(species = factor(species, levels = c(""Other"", df_birds_common$species))) %>% 
  ggplot(aes(decade, counts_year, fill = species)) +
    geom_area(aes(fill = species), position = ""stack"", alpha = 0.75) +
    geom_rect(xmin = 2012, xmax = Inf, ymin = 1000, ymax = Inf, fill = ""grey20"") +
    geom_text(data = df_labels, aes(x = x, y = y1, label = species), 
              size = 3, col = cols, hjust = 0, fontface = ""bold"", family = ""Poppins"") +
    geom_text(data = df_labels, aes(x = x, y = y2, label = species_latin), 
              size = 3, col = cols, hjust = 0, fontface = ""italic"", family = ""Poppins"") +
    scale_x_continuous(limits = c(1920, 2055), breaks = seq(1920, 2020, by = 20),
                       expand = c(0.03, 0.03)) +
    scale_y_continuous(expand = c(0, 0), breaks = seq(0, 70000, by = 10000), 
                       labels = scales::comma_format()) +
    scale_fill_manual(values = cols) +
    theme(legend.position = ""none"",
          axis.title.y = element_text(size = 12, face = ""plain""),
          axis.text = element_text(family = ""Roboto Mono"", size = 10),
          axis.ticks.x = element_line(colour = ""grey40"", size = 0.3),
          axis.ticks.y = element_line(colour = ""transparent"", size = 0.3),
          panel.grid.major.y = element_line(colour = ""grey40"", size = 0.3),
          panel.border = element_blank(),
          strip.background = element_rect(color = ""transparent""))+
    labs(x = NULL, y = ""Yearly mean per decade (stacked)\n"")
```

```{r starling-comp-facet}
peak_starling <- df_birds %>% 
  filter(species == ""European Starling"") %>% 
  group_by(decade) %>% 
  summarize(sum = sum(how_many_counted) / unique(n_years)) %>% 
  top_n(1, sum)

df_birds_periods <- df_birds %>% 
  filter(decade != 1980) %>% 
  filter(species != ""European Starling"") %>% 
  mutate(period = if_else(decade < peak_starling$decade, 
                          ""earlier"", ""later"")) %>% 
  group_by(species, period) %>% 
  summarize(sum = sum(how_many_counted)) %>% 
  spread(period, sum) %>% 
  mutate(diff = earlier - later) %>% 
  ungroup()
  
top_early <- df_birds_periods %>% 
  top_n(4, diff) %>% 
  arrange(-diff) %>% 
  pull(species)

top_late <- df_birds_periods %>% 
  top_n(4, -diff) %>% 
  arrange(diff) %>% 
  pull(species)

df_starling <- df_birds %>% 
  dplyr::filter(species == ""European Starling"") %>% 
  group_by(decade) %>% 
  summarize(counts_year = sum(how_many_counted) / unique(n_years)) %>% 
  ungroup()

annotation <- tibble(
  decade = 1945,
  counts_year = 35500,
  species = factor(top_early[1], levels = c(top_early, top_late))
)

arrow <- tibble(
  species = factor(top_early[1], levels = c(top_early, top_late)),
  x = 1945, xend = 1966.8, 
  y = 31200, yend = 26000
)

p_top <- df_birds %>% 
  filter(species %in% c(top_early, top_late)) %>% 
  group_by(species, decade) %>% 
  summarize(counts_year = sum(how_many_counted) / unique(n_years)) %>% 
  ungroup() %>% 
  mutate(species = factor(species, levels = c(top_early, top_late))) %>% 
  ggplot(aes(decade, counts_year, fill = species)) +
    geom_area() + 
    geom_area(data = df_starling, fill = ""#1d1414"", alpha = 0.75) +
    geom_segment(x = peak_starling$decade, xend = peak_starling$decade, 
                 y = 0, yend = peak_starling$sum - 2000, 
                 color = ""grey30"", linetype = ""dashed"", size = 0.2) +
    geom_area(alpha = 0.75) + 
    geom_text(data = annotation, label = ""European\nStarling"", size = 3,
              color = ""white"", family = ""Poppins"", fontface = ""bold"",
              lineheight = 0.8) +
    geom_curve(data = arrow, aes(x = x, xend = xend, y = y, yend = yend),
               arrow = arrow(length = unit(0.07, ""inch"")), 
               size = 0.5, color = ""grey85"", curvature = 0.35) +
    facet_wrap(~ species, nrow = 2) +
    scale_x_continuous(limits = c(1920, 2020), breaks = seq(1920, 2020, by = 20),
                       labels = c(""1920"", """", """", ""1980"", """", ""2020"")) +
    scale_y_continuous(limits = c(0, 53000), expand = c(0, 0),
                       breaks = seq(0, 50000, by = 10000), 
                       labels = scales::comma_format()) +
    scale_fill_manual(values = c(""#ff3200"", ""#e26a50"", ""#e9bc7c"", ""#e9e4a6"",
                                 ""#1bb6af"", ""#0096ee"", ""#2f50d1"", ""#622abd"")) +
    theme(legend.position = ""none"",
          axis.title.y = element_text(size = 12, face = ""plain""),
          axis.text = element_text(family = ""Roboto Mono"", size = 8.5),
          axis.ticks.x = element_line(colour = ""grey40"", size = 0.3),
          axis.ticks.y = element_line(colour = ""transparent"", size = 0.3),
          panel.grid.major.y = element_line(colour = ""grey40"", size = 0.3),
          panel.border = element_blank(),
          strip.background = element_rect(color = ""transparent""),
          strip.text = element_text(size = 10),
          panel.spacing = unit(15, ""pt"")) +
    labs(x = NULL, y = ""Yearly mean per decade\n"", 
         caption = ""\nVisualization by Cdric Scherer  |  Data source: Bird Studies Canada"")
```

```{r title}
## left-alligned title
p_title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Is it a bird? Is it a plane? Is it Santa Clause?    It's probably a European Starling!"",
       subtitle = ""Bird counts during Christmas time in the Hamilton area of Ontario. Which species peaked before and after the record counts of the European Starling during the '80s?\n"") +
  theme(line = element_blank(),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.background = element_rect(fill = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.5}
p_title + p_starling + p_top + plot_layout(widths = c(0, 0.47, 1))

ggsave(here::here(""plots"", ""2019_25"", ""2019_25_BirdsXmas.pdf""), 
       width = 14, height = 5.6, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"165",429,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_27_Franchise.Rmd","---
title: ""TidyTuesday 2019/27 - Media Franchise Revenues by Wikipedia""
author: ""Cedric Scherer""
date: ""5th of August 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(patchwork)
library(tvthemes)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_media <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"") %>% 
  mutate(
    revenue_category = case_when(
      revenue_category == ""Video Games/Games"" ~ ""Video Games"",
      revenue_category %in% c(""Home Video/Entertainment"", ""TV"") ~ ""Home Entertainment"",
      revenue_category %in% c(""Comic or Manga"", ""Book sales"") ~ ""Books & Comics"",
      revenue_category == ""Merchandise, Licensing & Retail"" ~ ""Merchandise"",
      TRUE ~ revenue_category
    )
  )
```

```{r yearly}
df_media_per_year <- df_media %>% 
  group_by(franchise, revenue_category) %>% 
  summarize(
    revenue = sum(revenue),
    year_created = min(year_created, na.rm = T),
    original_media = unique(original_media)
  ) %>% 
  group_by(franchise) %>% 
  mutate(
    years_running = 2018.5 - year_created,
    rev_per_year = revenue / years_running,
    sum_per_year = sum(revenue) / unique(years_running),
  ) %>% 
  ungroup() %>% 
  mutate(
    franchise = case_when(
      franchise == ""Wizarding World / Harry Potter"" ~ ""Harry Potter"",
      franchise == ""Super Sentai / Power Rangers"" ~ ""Power Rangers"",
      str_detect(franchise, ""Jump"") ~ ""Shonen Jump"",
      TRUE ~ franchise
    ),
    original_media = case_when(
      original_media %in% c(""Film"", ""Animated film"") ~ ""Movie"",
      original_media %in% c(""Television series"", ""Animated series"", ""Anime"") ~ ""Series"",
      original_media == ""Video game"" ~ ""Game"",
      original_media == ""Cartoon character"" ~ ""Character"",
      TRUE ~ original_media
    )
  ) %>% 
  filter(sum_per_year > 0.825) %>% 
  mutate(franchise = fct_reorder(franchise, sum_per_year))

cols_a <- c(""#646464"", ""#700000"", ""#9D5931"", ""#D78808"", ""#005173"", ""#747940"")

revenue_yearly <- df_media_per_year %>% 
  ggplot(aes(franchise, rev_per_year)) + 
    geom_col(aes(fill = original_media), width = 0.65) +
    geom_hline(yintercept = 0, color = ""grey50"", size = 0.2) +
    geom_hline(data = tibble(y = 1:4), aes(yintercept = y), 
               color = ""grey50"", size = 0.2, linetype = ""dotted"") +
    geom_text(data = df_media_per_year %>% 
                       group_by(franchise) %>% 
                       summarize(
                         sum_per_year = unique(sum_per_year),
                         label = glue::glue(""${format(round(unique(sum_per_year), 2), nsmall = 2)}B"")
                       ),
              aes(franchise, sum_per_year, label = label), 
              color = ""grey90"", size = 2.5, family = ""Roboto Mono"", 
              nudge_y = 0.08, hjust = 0) +
    geom_text(data = df_media_per_year %>% 
                group_by(franchise) %>% 
                summarize(label = unique(original_media)),
              aes(franchise, 0.05, label = label), 
              color = ""grey90"", size = 2.2, family = ""Poppins"", 
              fontface = ""bold"", hjust = 0, vjust = 0.45) +
    geom_text(data = df_media_per_year %>% 
                group_by(franchise) %>% 
                summarize(label = glue::glue(""({unique(year_created)})"")),
              aes(franchise, -0.18, label = label), color = ""grey60"", 
              size = 2.7, family = ""Roboto Mono"", hjust = 1) +
    coord_flip(clip = ""off"") +
    scale_y_continuous(limits = c(-0.5, 4.3), breaks = c(0:4, 4.3), 
                       labels = c(glue::glue(""${0:4}B""), ""    per year""), 
                       expand = c(0.01, 0.01), position = ""right"") + 
    scale_fill_manual(values = cols_a, guide = F) +
    theme(axis.text.x = element_text(family = ""Roboto Mono"", size = 8),
          axis.text.y = element_text(size = 8, color = ""grey90"", face = ""bold""),
          axis.ticks = element_blank(),
          panel.border = element_rect(color = ""transparent""),
          strip.background = element_rect(color = ""transparent""),
          strip.text = element_text(size = 11)) +
    labs(x = NULL, y = NULL)
```


```{r relative}
df_media_rel <- df_media %>% 
  group_by(franchise, revenue_category) %>% 
  summarize(
    revenue = sum(revenue),
    year_created = min(year_created, na.rm = T),
  ) %>% 
  group_by(franchise) %>% 
  mutate(
    sum_revenue = sum(revenue, na.rm = T),
    revenue_rel = revenue / sum_revenue
  ) %>% 
  group_by(revenue_category) %>% 
  mutate(sum_cat = sum(revenue)) %>% 
  ungroup() %>% 
  mutate(
    franchise = case_when(
      franchise == ""Wizarding World / Harry Potter"" ~ ""Harry Potter"",
      franchise == ""Super Sentai / Power Rangers"" ~ ""Power Rangers"",
      str_detect(franchise, ""Jump"") ~ ""Shonen Jump"",
      TRUE ~ franchise
    )
  ) %>% 
  filter(franchise %in% as.vector(df_media_per_year$franchise))

categories <- df_media_rel %>% 
  arrange(sum_cat) %>% 
  mutate(revenue_category = glue::glue(""{revenue_category} (${round(sum_cat, 1)}B)"")) %>% 
  pull(revenue_category) %>% 
  unique() %>% 
  as.vector()

cols_b <- c(""#D96F63"", ""#6D3E4E"", ""#945744"", ""#7E6A69"", ""#A22B2B"", ""#E8B02A"")

revenue_relative <- df_media_rel %>% 
  mutate(
    revenue_category = glue::glue(""{revenue_category} (${round(sum_cat, 1)}B)""),
    revenue_category = factor(revenue_category, levels = categories),
    franchise = factor(franchise, levels = levels(df_media_per_year$franchise)),
    label = glue::glue(""${round(revenue, 1)}B""),
    label = ifelse(revenue_rel < 0.075, """", label)
  ) %>% 
  ggplot(aes(franchise, revenue_rel, fill = revenue_category, label = label)) + 
    geom_col(color = ""grey20"", size = 0.1, width = 0.65, position = ""stack"") +
    geom_hline(data = tibble(1:3), aes(yintercept = c(0.25, 0.5, 0.75)), 
               color = ""grey50"", size = 0.2, linetype = ""dotted"") +
    geom_hline(data = tibble(1:2), aes(yintercept = c(0, 1)), 
               color = ""grey50"", size = 0.2) +
    geom_text(color = ""grey90"", size = 1.8, family = ""Roboto Mono"", 
              fontface = ""bold"", position = position_stack(vjust = 0.5)) +
    geom_text(data = df_media_rel %>% 
                group_by(franchise) %>% 
                summarize(sum = unique(sum_revenue)) %>% 
                mutate(
                  label = glue::glue(""${format(round(sum, 1), nsmall = 1)}B         ""),
                  revenue_category = ""Music ($16.1B)"",  ## just any of the existing to avoid new key in legend
                ), 
              aes(x = franchise, y = 0, label = label), color = ""grey90"", 
              family = ""Roboto Mono"", size = 3, fontface = ""bold"", 
              position = ""stack"", hjust = 1) +
    coord_flip(clip = ""off"") +
    scale_y_continuous(limits = c(-0.5, 1), breaks = c(-0.28, seq(0, 1, by = 0.25)), 
                       expand = c(0, 0), position = ""right"", 
                       labels = c(""Total revenue"", ""0%"", ""25%"", ""50%"", ""75%"", ""100%"")) + 
    scale_fill_manual(values = cols_b, name = ""Revenue breakdown:"") +
    guides(fill = guide_legend(reverse = T)) +
    theme(axis.text.x = element_text(family = ""Roboto Mono"", size = 8),
          axis.text.y = element_blank(),
          axis.ticks = element_blank(),
          panel.border = element_rect(color = ""transparent""),
          legend.title = element_text(size = 9, face = ""bold""),
          legend.text = element_text(size = 7.5),
          legend.key.height = unit(1.25, ""lines""),
          legend.key.width = unit(0.5, ""lines""),
          legend.justification = ""top"") +
    labs(x = NULL, y = NULL)
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Gotta Catch 'Em All!  Franchise Fans Beg for Merchandise"",
       subtitle = ""Annual and total revenue of media franchise powerhouses and breakdown of revenues by category.\n"") +
  theme(line = element_blank(),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.background = element_rect(fill = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r caption}
## right-alligned caption
caption <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       caption = ""\nVisualization by Cdric Scherer  |  Data source: Wikipedia"") +
  theme(line = element_blank(),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.background = element_rect(fill = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.5}
title + revenue_yearly + revenue_relative + caption + plot_layout(widths = c(0, 1, 1, 0), nrow = 1)

ggsave(here::here(""plots"", ""2019_27"", ""2019_27_FranchiseRevenue.pdf""), 
       width = 14, height = 5.6, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"166",430,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_28_FIFA_WWCs.Rmd","---
title: ""TidyTuesday 2019/28 - Women's World Cups by data.world""
author: ""Cedric Scherer""
date: ""20th of July 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(patchwork)
library(showtext)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))

## add fonts via showtext (extrafont and ? do not work together)
font_add_google(""Poppins"", ""Poppins"")
font_add_google(""Roboto Mono"", ""Roboto Mono"")
font_add_google(""Roboto Condensed"", ""Roboto Condensed"")
showtext_auto()
```

```{r data}
df_codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
df_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"") %>% 
  left_join(df_codes, by = ""team"")
```

```{r data-prep}
df_outcomes_id <- df_outcomes %>% 
  filter(round != ""Third Place Playoff"") %>% 
  group_by(team, year) %>% 
  mutate(id = row_number()) %>% 
  group_by(team) %>% 
  mutate(
    win_num = if_else(win_status == ""Won"", 1, 0),
    wins = cumsum(win_num),
    points = case_when(
      win_status == ""Won"" ~ 3, 
      win_status == ""Tie"" ~ 1, 
      win_status == ""Lost"" ~ 0
    ),
    points_sum = cumsum(points),
    round = if_else(round == ""Group"", glue::glue(""Group Match {id}""), round),
    round_year = glue::glue(""{year} {round}"")
  ) %>% 
  ungroup() 

df_outcomes_rounds <- df_outcomes_id %>%
  dplyr::select(year, round) %>% 
  distinct() %>% 
  mutate(round_id = row_number()) %>% 
  full_join(df_outcomes_id) 

df_outcomes_top <- df_outcomes_rounds %>% 
  filter(team %in% c(""USA"", ""GER"", ""JPN"", ""NOR"")) %>% 
  group_by(team) %>% 
  mutate(
    wins_sum = max(wins),
    country = factor(country, levels = c(""United States"", ""Germany"", ""Norway"", ""Japan""))
  ) %>% 
  ungroup()
```

```{r step-chart}
## labels for x-axis
labs <- df_outcomes_rounds %>% 
  dplyr::select(round, year) %>% 
  distinct() %>% 
  pull(round)

## images for flag legend
img_usa <- png::readPNG(here::here(""img"", ""flag_usa.png""))
usa <- grid::rasterGrob(img_usa, interpolate = T)
img_ger <- png::readPNG(here::here(""img"", ""flag_ger.png""))
ger <- grid::rasterGrob(img_ger, interpolate = T)
img_jpn <- png::readPNG(here::here(""img"", ""flag_jpn.png""))
jpn <- grid::rasterGrob(img_jpn, interpolate = T)
img_nor <- png::readPNG(here::here(""img"", ""flag_nor.png""))
nor <- grid::rasterGrob(img_nor, interpolate = T)
img_ned <- png::readPNG(here::here(""img"", ""flag_ned.png"")) 
ned <- grid::rasterGrob(img_ned, interpolate = T)

## lines for legend
lines <- tibble(
  x = c(50, 48, 47, 48, 50),
  xend = rep(52.5, 5),
  y = c(120, 97, 48, 77, 22),
  yend = c(120, 97, 48, 77, 22),
  team = c(""USA"", ""GER"", ""JPN"", ""NOR"", ""NED"")
)

## rect coords for soccer field design
rects <- tibble(
  xmin = c(-Inf, 6.5, 12.5, 18.5, 24.5, 30.5, 36.5, 43.5, 50.5),
  xmax = c(7, 13, 19, 25, 31, 37, 44, 51, Inf),
  ymin = rep(-Inf, 9),
  ymax = rep(Inf, 9),
  group = c(""1"", ""2"", ""1"", ""2"", ""1"", ""2"", ""1"", ""2"", ""1""),
  round_id = rep(1, 9),
  wins = rep(1, 9),
  points_sum = rep(1, 9)
)

## label for year of WWC
years <- tibble(
  x = c(3.5, 9.5, 15.5, 21.5, 27.5, 33.5, 40, 47),
  y = rep(130, 8),
  label = as.character(seq(1991, 2019, by = 4))
)

p_steps <- 
  df_outcomes_rounds %>% 
  add_row(round_id = 0, team = ""USA"", points_sum = 0) %>% 
  group_by(team) %>% 
  mutate(
    wins_sum = max(wins),
    country = factor(country, levels = c(""United States"", ""Germany"", ""Norway"", ""Japan""))
  ) %>% 
  ggplot(aes(round_id, points_sum)) +
    geom_rect(data = rects, aes(xmin = xmin, xmax = xmax, 
                                ymin = ymin, ymax = ymax, fill = group)) +
    geom_text(data = years, aes(x = x, y = y, label = label), 
              family = ""Roboto Mono"", color = ""white"", fontface = ""bold"") +
    geom_segment(data = lines, aes(x = x, y = y, xend = xend, yend = yend, 
                                   color = team), linetype = ""dotted"") +
    annotation_custom(usa, xmin = 51.5, xmax = 53.5, ymin = 118, ymax = 122) +
    annotation_custom(ger, xmin = 51.5, xmax = 53.5, ymin = 95, ymax = 99) +
    annotation_custom(jpn, xmin = 51.5, xmax = 53.5, ymin = 46, ymax = 50) +
    annotation_custom(nor, xmin = 51.5, xmax = 53.5, ymin = 75, ymax = 79) +
    annotation_custom(ned, xmin = 51.5, xmax = 53.5, ymin = 20, ymax = 24) +
    geom_step(aes(group = team), colour = ""grey10"", alpha = 0.2, size = 0.4) +
    geom_step(data = df_outcomes_rounds %>% 
                filter(team %in% c(""USA"", ""GER"", ""JPN"", ""NOR"", ""NED"")), 
              aes(color = team), size = 0.7, alpha = 0.7) +
    geom_point(data = df_outcomes_rounds %>% 
                 filter(team %in% c(""USA"", ""GER"", ""JPN"", ""NOR"", ""NED""), 
                        win_status == ""Lost""), aes(color = team), size = 1.7, shape = 17) +
    geom_point(data = df_outcomes_rounds %>% 
                 filter(team %in% c(""USA"", ""GER"", ""JPN"", ""NOR"", ""NED""), 
                        round == ""Final"", win_status == ""Won"") %>% 
                 mutate(points_sum = points_sum + 0.5), 
               aes(color = team), size = 4, shape = ""?"") +
    annotate(""text"", x = 3.5, y = 20, label = ""USA win the\nfirst WWC"",
             color = ""white"", family = ""Roboto Condensed"", lineheight = 0.8, size = 2.1) +
    annotate(""text"", x = 12, y = 41, label = ""Norway wins the\ntitle in 1995"",
             color = ""darkcyan"", family = ""Roboto Condensed"", lineheight = 0.8, size = 2.1) +
    annotate(""text"", x = 8.5, y = 33, label = ""USA lose for\nthe first time"",
             color = ""white"", family = ""Roboto Condensed"", lineheight = 0.8, size = 2.1) +
    annotate(""text"", x = 31, y = 27, label = ""Japan starts its\nwinning streak that\nleads to the title in 2011"",
             color = ""indianred3"", family = ""Roboto Condensed"", lineheight = 0.8, size = 2.1) +
    annotate(""text"", x = 26.5, y = 76, label = ""Winning two titles in a\nrow, Germany becomes\nUSA's rival number 1"",
             color = ""goldenrod2"", family = ""Roboto Condensed"", lineheight = 0.8, size = 2.1) +
    annotate(""text"", x = 51, y = 12, label = ""The Netherlands\nmake it to the final\nfor the first time"",
             color = ""chocolate2"", family = ""Roboto Condensed"", lineheight = 0.8, size = 2.1) +
    annotate(""text"", x = 45.5, y = 121, label = ""USA win the WWC 2019"",
             color = ""white"", family = ""Roboto Condensed"", lineheight = 0.8, size = 2.1) +
    scale_x_continuous(limits = c(0, 54.5), breaks = 1:50, labels = labs, expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, 130), breaks = seq(0, 120, by = 20)) +
    scale_color_manual(values = c(""goldenrod1"", ""indianred3"", ""chocolate2"", 
                                  ""darkcyan"", ""white""),guide = F) +
    scale_fill_manual(values = c(""#445525"", ""#3b4a20""), guide = F) +
    theme(axis.text.x = element_text(size = 6, angle = 90, hjust = 1, vjust = 0.5),
          axis.text.y = element_text(family = ""Roboto Mono"", size = 8),
          axis.title.x = element_text(size = 11),
          axis.title.y = element_text(size = 11)) +
    labs(x = NULL, y = ""Points scored"")
```

```{r stellar-chart}
df_outcomes_stats_top <- df_outcomes_rounds %>% 
  mutate(winner = if_else(round == ""Final"" & win_status == ""Won"", 1, 0)) %>% 
  filter(team %in% c(""USA"", ""GER"", ""JPN"", ""NOR"")) %>% 
  group_by(team, country, year) %>% 
  summarize(
    wins = sum(win_num),
    points_sum = sum(points),
    scores = sum(score),
    winner = max(winner)
  ) %>% 
  ungroup() %>% 
  add_row(year = 1987, team = ""USA"", country = ""United States"") %>% 
  group_by(team) %>% 
  mutate(
    wins_sum = max(wins),
    country = factor(country, levels = c(""United States"", ""Germany"", ""Norway"", ""Japan""))
  )

years_lab <- tibble(
  points_sum = rep(3, 9),
  scores = rev(seq(2, 30, length.out = 9)),
  team = factor(""USA"", levels = c(""USA"", ""GER"", ""NOR"", ""JPN"")),
  country = factor(""United States"", levels = c(""United States"", ""Germany"", ""Norway"", ""Japan"")),
  year = seq(1987, 2019, by = 4)
)

p_stats <- 
  df_outcomes_stats_top %>% 
  ggplot(aes(points_sum, scores, color = year)) + 
    geom_path(alpha = 0.7) +
    geom_point(data = df_outcomes_stats_top %>% 
                 filter(winner == 0), size = 1.5) +
    geom_point(data = df_outcomes_stats_top %>% 
                 filter(winner == 1), 
               aes(points_sum, scores), size = 4.5, shape = ""?"") +
    geom_text(data = years_lab, aes(label = as.character(year)), 
              family = ""Roboto Mono"", size = 2.5, fontface = ""bold"") +
    facet_wrap(~ country, nrow = 1) +
    scale_x_continuous(limits = c(0, 23), breaks = seq(0, 20, by = 5), expand = c(0.05, 0.05)) +
    scale_y_continuous(limits = c(0, 29), breaks = seq(0, 25, by = 5), expand = c(0.05, 0.05)) +
    rcartocolor::scale_color_carto_c(palette = ""Emrld"", direction = -1, guide = F) +
    theme(axis.text = element_text(family = ""Roboto Mono"", size = 8),
          axis.title.x = element_text(size = 11),
          axis.title.y = element_text(size = 11),
          strip.background = element_rect(color = ""transparent""), 
          strip.text = element_text(size = 10, vjust = 1, face = ""plain""),
           plot.margin = margin(12, 12, 0, 12)) +
    labs(x = ""Points scored"", y = ""Goals scored"")
```

```{r dot-chart}
years_short <- years %>% 
  mutate(label = glue::glue(""'{str_sub(label, 3)}""))

p_wins <- 
  df_outcomes_top %>% 
  ggplot(aes(round_id, wins)) +
    geom_rect(data = rects, aes(xmin = xmin, xmax = xmax, 
                                ymin = ymin, ymax = ymax, fill = group)) +
    geom_text(data = years_short, aes(x = x, y = y - 86, label = label), 
              family = ""Roboto Mono"", color = ""white"", size = 1.8) +
    geom_point(aes(color = win_status), size = 0.4) +
    facet_wrap(~ country, nrow = 1) +
    scale_x_continuous(limits = c(0, 51), breaks = 1:50, labels = labs, expand = c(0, 0)) +
    scale_y_continuous(limits = c(0, 45), breaks = seq(0, 40, by = 10)) +
    scale_color_manual(values = c(""firebrick"", ""grey80"", ""goldenrod3""), name = """") +
    scale_fill_manual(values = c(""#445525"", ""#3b4a20""), guide = F) +
    guides(color = guide_legend(reverse = T, nrow = 1, 
                                override.aes = list(size = 3))) +
    theme(axis.text.x = element_blank(),
          axis.text.y = element_text(family = ""Roboto Mono"", size = 8),
          axis.ticks.x = element_blank(),
          axis.title.x = element_text(size = 11),
          axis.title.y = element_text(size = 11),
          legend.position = c(0.5, -0.1),
          legend.background = element_rect(color = ""transparent"", fill = ""transparent""),
          strip.background = element_rect(color = ""transparent""),
          strip.text = element_text(size = 10, vjust = 1, face = ""plain"")) +
    labs(x = NULL, y = ""Matches won"",
         caption = ""\nVisualization by Cdric Scherer  |  Data: data.world"")
```

```{r title}
## left-alligned title
p_title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""The US women's national soccer team is almost unbeatable at FIFA World Cups"",
       subtitle = ""Comparison of the US women's team to all former champions and the 2019 finalist, the Netherlands. Stats are shown for all tournament matches excluding third\nplace playoffs. Stars indicate world champions, triangles lost matches. Scored points are calculated based on the 3-1-0 scheme."") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 5.7}
(p_title + p_steps + (p_stats / p_wins)) + plot_layout(widths = c(0, 1, 0.9))

ggsave(here::here(""plots"", ""2019_28""m ""2019_28_FIFA_WWCs.pdf""), 
       width = 14, height = 5.7, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"167",431,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_28_FIFA_WWCs_stellar.Rmd","---
title: ""TidyTuesday 2019/28 - Women's World Cups by data.world""
author: ""Cedric Scherer""
date: ""20th of July 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(patchwork)
library(lemon)
library(showtext)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
theme_update(rect = element_rect(fill = ""#001a33""),
             strip.background = element_rect(fill = ""#001a33"", colour = ""transparent""), 
             plot.margin = margin(0, 80, 10, 80),
             panel.spacing.y = unit(50, ""pt""),
             strip.text = element_text(vjust = 0))

## add fonts via showtext
font_add_google(""Roboto Mono"", ""Roboto Mono"")
font_add_google(""Passion One"", ""Passion One"")
showtext_auto()
```

```{r data}
df_codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
df_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"") %>% 
  left_join(df_codes, by = ""team"")
```

```{r data-prep}
df_outcomes_id <- df_outcomes %>% 
  filter(round != ""Third Place Playoff"") %>% 
  mutate(
    country = if_else(country %in% c(""China PR"", ""Chinese Taipei""), ""China"", country),
    country = if_else(country == ""Ivory Coast (Cte d'Ivoire)"", ""Ivory Coast"", country)
  ) %>% 
  group_by(country) %>% 
  mutate(
    win_num = if_else(win_status == ""Won"", 1, 0),
    wins = cumsum(win_num),
    points = case_when(
      win_status == ""Won"" ~ 3, 
      win_status == ""Tie"" ~ 1, 
      win_status == ""Lost"" ~ 0
    ),
    points_sum = cumsum(points)
  ) %>% 
  ungroup() 

df_outcomes_stats <- df_outcomes_id %>%
  dplyr::select(year, round) %>% 
  distinct() %>% 
  mutate(round_id = row_number()) %>% 
  full_join(df_outcomes_id) %>% 
  mutate(winner = if_else(round == ""Final"" & win_status == ""Won"", 1, 0)) %>% 
  group_by(country, year) %>% 
  summarize(
    wins = sum(win_num),
    points_sum = sum(points),
    scores = sum(score),
    winner = max(winner)
  ) %>% 
  ungroup() %>% 
  add_row(year = 1987, country = ""United States"") %>% 
  group_by(country) %>% 
  mutate(wins_sum = max(wins))
```

```{r plot}
p_stellar <- 
  df_outcomes_stats %>% 
  ggplot(aes(points_sum, scores, color = year)) + 
    geom_path(size = 1, alpha = 0.6) +
    geom_point(data = df_outcomes_stats %>% 
                 filter(winner == 0), size = 4) +
    geom_point(data = df_outcomes_stats %>% 
                   filter(winner == 1), 
               aes(points_sum, scores), size = 15, shape = ""?"") +
    facet_wrap(~ country, ncol = 5) +
    scale_x_continuous(limits = c(0, 27), breaks = seq(0, 25, by = 5)) +
    scale_y_continuous(limits = c(0, 27), breaks = seq(0, 25, by = 5)) +
    rcartocolor::scale_color_carto_c(palette = ""Emrld"", direction = -1, guide = F) +
    coord_capped_cart(bottom = ""both"", left = ""both"") +
    theme(axis.text = element_text(color = ""grey20"", family = ""Roboto Mono""),
          axis.title.x = element_text(size = 18, hjust = 0, 
                                      family = ""Passion One"", 
                                      color = ""grey30"", face = ""plain""),
          axis.title.y = element_text(size = 18, hjust = 0, 
                                      family = ""Passion One"", 
                                      color = ""grey30"", face = ""plain""),
          axis.ticks = element_line(color = ""grey20""),
          axis.line = element_line(color = ""grey20""),
          strip.text = element_text(size = 18, vjust = 1, face = ""plain"", 
                                    family = ""Passion One"", color = ""grey30""),
          panel.border = element_blank(),
          plot.caption = element_text(size = 15, family = ""Passion One"", 
                                      color = ""grey20"")) +
    labs(x = ""\nPoints scored ?"", y = ""\nGoals scored ?"",
         caption = ""\nVisualization by Cdric Scherer  |  Data: data.world     \n\n\n\n\n"")

## colored text legend  
p_legend <- 
  ggplot(tibble(
           x = seq(0, 28, length.out = 9), 
           y = rep(33, 9),
           year = seq(1987, 2019, by = 4)
    ), aes(x, y, color = year, label = as.character(year))) +
    geom_text(size = 10, family = ""Roboto Mono"", fontface = ""bold"") +
    rcartocolor::scale_color_carto_c(palette = ""Emrld"", 
                                     direction = -1, guide = F) +
    scale_x_continuous(limits = c(2.5, 29)) +
    theme(line = element_blank(),
          axis.title = element_blank(),
          plot.title = element_text(hjust = 0.5),
          panel.background = element_rect(fill = ""transparent""),
          plot.background = element_rect(fill = ""transparent"", 
                                         color = ""transparent""),
          panel.border = element_rect(color = ""transparent""),
          axis.text = element_blank())

## centered title
p_title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""\n\n\nThe Stellar Map of the FIFA Women's World Cup\n"",
       subtitle = ""Number of goals and points scored per national team and FIFA World Cup.\n"",
       caption = ""\nStats are shown for all tournament matches excluding third place playoffs.\nStars indicate world champions, scored points are calculated based on the 3-1-0 scheme."") +
  theme(line = element_blank(),
        plot.title = element_text(size = 50, hjust = 0.5, 
                                  family = ""Passion One"", 
                                  lineheight = 0.5, face = ""bold""),
        plot.subtitle = element_text(size = 25, hjust = 0.5, 
                                     family = ""Passion One"", 
                                     lineheight = 0.5, 
                                     color = ""grey60""),
        plot.caption = element_text(size = 15, hjust = 0.5, 
                                    color = ""grey30"", 
                                    family = ""Passion One""),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", 
                                       color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 21, fig.height = 36}
(p_title / p_legend / p_stellar + plot_layout(heights = c(0, 0.08, 1)))

ggsave(here::here(""plots"", ""2019_28"", ""2019_28_FIFA_WWCs_stellar.pdf""), 
       width = 21, height = 36, device = cairo_pdf)
```

--------

```{r plot-clean}
p_stellar_clean <- 
  df_outcomes_stats %>% 
  ggplot(aes(points_sum, scores, color = year)) + 
    geom_path(size = 1, alpha = 0.6) +
    geom_point(data = df_outcomes_stats %>% 
                 filter(winner == 0), size = 4) +
    geom_point(data = df_outcomes_stats %>% 
                   filter(winner == 1), 
               aes(points_sum, scores), size = 15, shape = ""?"") +
    facet_wrap(~ country, ncol = 5) +
    scale_x_continuous(limits = c(0, 27), breaks = seq(0, 25, by = 5), expand = c(0.05, 0.05)) +
    scale_y_continuous(limits = c(0, 27), breaks = seq(0, 25, by = 5), expand = c(0.05, 0.05)) +
    rcartocolor::scale_color_carto_c(palette = ""Emrld"", direction = -1, guide = F) +
    coord_capped_cart(bottom = ""both"", left = ""both"") +
    theme(axis.text = element_blank(),
          axis.title.x = element_text(size = 18, hjust = 0, family = ""Passion One"", color = ""grey30"", face = ""plain""),
          axis.title.y = element_text(size = 18, hjust = 0, family = ""Passion One"", color = ""grey30"", face = ""plain""),
          axis.ticks = element_blank(),
          strip.text = element_text(size = 18, vjust = 1, face = ""plain"", family =""Passion One"", color = ""grey30""),
          panel.border = element_rect(color = ""transparent""),
          plot.caption = element_text(size = 15, family = ""Passion One"", color = ""grey20"")) +
    labs(x = ""\nPoints scored ?"", y = ""\nGoals scored ?"",
         caption = ""\nVisualization by Cdric Scherer  |  Data: data.world     \n\n\n\n\n"")
```

```{r full-panel-clean, fig.width = 14, fig.height = 5.7}
(p_title / p_legend / p_stellar_clean + plot_layout(heights = c(0, 0.08, 1)))

ggsave(here::here(""plots"", ""2019_28"", ""2019_28_FIFA_WWCs_stellar_clean.pdf""), 
       width = 21, height = 36, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```

","2019"
"168",432,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_33_RomanEmperors.Rmd","---
title: ""TidyTuesday 2019/33 - Roman Emperors by Wikipedia""
author: ""Cedric Scherer""
date: ""14th of August 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(lubridate)
library(ggrepel)
library(showtext)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
theme_update(line = element_blank(),
             rect = element_rect(fill = ""#f7f5ee"", color = ""transparent""),
             panel.border = element_blank(),
             axis.text = element_blank(),
             plot.title = element_text(color = ""black"", hjust = 0.5, size = 30),
             plot.subtitle = element_text(color = ""grey30"", hjust = 0.5, 
                                          size = 8, margin = margin(0, 0, 0, 0)),
             plot.caption = element_text(color = ""grey30"", size = 8))

## add fonts via showtext
font_add_google(""Cinzel"", ""Cinzel"")
showtext_auto()
```

```{r data}
df_emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"") %>% 
  mutate(
    birth = case_when(
      index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
      TRUE ~ birth
    ),
    reign_start = case_when(
      index == 1 ~ update(reign_start, year = -year(reign_start)),
      TRUE ~ reign_start
    )
  )
```

```{r plot}
labs_yrs <- tibble(x = rep(5, 10),
                   time = c(-50, 1, seq(50, 400, by = 50))) %>% 
  mutate(
    jesus = ifelse(time < 0, ""BC"", ""AD""),
    lab = glue::glue(""{time} {jesus}"")
  )
  
legend <- tibble(
  y = c(-50, -46, -42),
  text = c(""Natural Death in Peace"", 
           ""Fatality or in Captivity"", 
           ""Unknown Cause of Death"")
)

df_emperors %>% 
  mutate(
    reign_start = lubridate::year(reign_start),
    cause = case_when(
      cause == ""Natural Causes"" ~ ""Natural Death in Peace"",
      cause == ""Unknown"" ~ ""Unknown Cause of Death"",
      TRUE ~ ""Fatality or in Captivity""
    ),
    cause = fct_relevel(cause, ""Natural Death in Peace"", 
                                ""Fatality or in Captivity"", 
                                ""Unknown Cause of Death"")
  ) %>% 
  ggplot(aes(x = 1.6, y = reign_start)) + 
    geom_segment(data = labs_yrs, aes(x = 1.6, xend = 1.7, y = time, yend = time), 
                 size = 0.5, color = ""grey30"") +
    geom_segment(x = 1.6, xend = 1.6, y = 55, yend = -405, lineend = ""round"", 
                 size = 2.5, color = ""grey30"") +
    geom_text_repel(aes(label = name, color = cause), segment.color = ""grey60"",
                    segment.size = 0.1, family = ""Cinzel"", fontface = ""bold"",
                    size = 3.8, xlim  = c(0, 1.1), hjust = 1) +
    geom_point(color = ""transparent"", fill = ""white"", size = 5, shape = 21) +
    geom_point(color = ""grey30"", fill = alpha(""grey10"", 0.1), size = 5, shape = 21) +
    geom_text(data = labs_yrs, aes(x = 1.72, y = time, label = lab), 
              family = ""Cinzel"", hjust = 0, color = ""grey30"") + 
    geom_text(data = legend, aes(x = 0.75, y = y, label = text, color = text), 
              family = ""Cinzel"", hjust = 0.5, size = 3.2) + 
    scale_x_continuous(limits = c(0, 2.3)) +
    scale_y_reverse(limits = c(400, -50)) +
    scale_color_manual(values = c(""#b26a22"", ""#b22222"", ""grey50""), guide = F) +
    theme(plot.title = element_text(family = ""Cinzel""),
          plot.subtitle = element_text(family = ""Cinzel"")) +
    labs(x = NULL, y = NULL, title = ""The Emperors of Rome"",
         subtitle = ""\nTimeline of roman emperors, start of each reign and their cause of death.\nThe darker the circles, the more emperors were reigning during this period."",
         caption = ""\nVisualization by Cdric Scherer  |  Data: Wikipedia"")

ggsave(here::here(""plots"", ""2019_33"", ""2019_33_RomanEmperors.pdf""), 
       width = 7, height = 22, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"169",433,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_34_NuclearExplosions.Rmd","---
title: ""TidyTuesday 2019/34 - Nuclear Explosions by SIPRI""
author: ""Cedric Scherer""
date: ""21th of July 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(sf)
library(LaCroixColoR)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
theme_set(theme_custom(base_family = ""Rockwell""))
theme_update(rect = element_rect(fill = ""#173f50""))
```

```{r data}
df_nuclear <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")
```

```{r goode-map}
## code for Goode homolosine projection by Claus Wilke:
## https://gist.github.com/clauswilke/783e1a8ee3233775c9c3b8bfe531e28a

## world map as sf object
sf_world <- st_as_sf(rworldmap::getMap(resolution = ""low""))

## nuclear explosions as sf object
sf_nuclear <- st_as_sf(x = df_nuclear,                         
                       coords = c(""longitude"", ""latitude""),
                       crs = 4326) %>% 
  filter(!is.na(yield_upper)) %>% 
  mutate(country = case_when(
    country == ""CHINA"" ~ ""China"",
    country == ""FRANCE"" ~ ""France"",
    country == ""INDIA"" ~ ""India"",
    country == ""PAKIST"" ~ ""Pakistan"",
    country == ""UK"" ~ ""United Kingdom"",
    country == ""USA"" ~ ""United States"",
    country == ""USSR"" ~ ""Soviet Union""
    ),
    sealevel = if_else(depth < 0, ""below"", ""above""),
    sealevel = case_when(
      type == ""UG"" | type == ""TUNNEL"" | type == ""GALLERY"" |
        type == ""SHAFT"" | type == ""SHAFT/GR"" | type == ""SHAFT/LG"" |
        type == ""MINE"" | type == ""UW"" ~ ""underground"",
      TRUE ~ ""atmospheric""
    )
  )

## crs for Goode projection
crs_goode <- ""+proj=igh""

## projection outline in long-lat coordinates
lats <- c(
  90:-90, # right side down
  -90:0, 0:-90, # third cut bottom
  -90:0, 0:-90, # second cut bottom
  -90:0, 0:-90, # first cut bottom
  -90:90, # left side up
  90:0, 0:90, # cut top
  90 # close
)

longs <- c(
  rep(180, 181), # right side down
  rep(c(80.01, 79.99), each = 91), # third cut bottom
  rep(c(-19.99, -20.01), each = 91), # second cut bottom
  rep(c(-99.99, -100.01), each = 91), # first cut bottom
  rep(-180, 181), # left side up
  rep(c(-40.01, -39.99), each = 91), # cut top
  180 # close
)

goode_outline <- 
  list(cbind(longs, lats)) %>%
  st_polygon() %>%
  st_sfc(
    crs = ""+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs""
  ) %>% 
  st_transform(crs = crs_goode)

## bounding box in transformed coordinates
xlim <- c(-21945470, 21963330)
ylim <- c(-9538022, 9266738)

goode_bbox <- 
  list(
    cbind(
      c(xlim[1], xlim[2], xlim[2], xlim[1], xlim[1]), 
      c(ylim[1], ylim[1], ylim[2], ylim[2], ylim[1])
    )
  ) %>%
  st_polygon() %>%
  st_sfc(crs = crs_goode)

## area outside the earth outline
goode_without <- st_difference(goode_bbox, goode_outline)

## colors
cols <- c(""#7F3C8D"", ""#0F8E7E"", ""#3969AC"", ""#948273"", 
          ""#E73F74"", ""#80BA5A"", ""#F2B701"")

## map
goode <- ggplot(sf_world) + 
  geom_sf(fill = ""white"", color = ""transparent"") +
  geom_sf(data = goode_without, fill = ""#173f50"", color = NA) +
  geom_sf(data = goode_outline, fill = NA, color = ""grey95"", size = 0.5/.pt) +
  geom_sf(data = sf_nuclear, aes(fill = country, size = yield_upper, 
                                 shape = sealevel),
          color = ""grey20"", stroke = 0.01) +
  scale_x_continuous(name = NULL, breaks = seq(-120, 120, by = 60)) +
  scale_y_continuous(name = NULL, breaks = seq(-60, 60, by = 30)) +
  scale_size_continuous(range = c(1.5, 15), guide = F) +
  scale_shape_manual(values = c(24, 25), guide = F) +
  scale_fill_manual(name = """",
                    values = alpha(cols, 0.3)) +
  guides(fill = guide_legend(override.aes = list(alpha = 1)),
         color = guide_legend(override.aes = list(alpha = 0))) +
  coord_sf(xlim = 0.95*xlim, ylim = ylim, 
           expand = F, crs = crs_goode, ndiscr = 1000) +
  theme(panel.background = element_rect(fill = ""grey90"", color = ""#173f50""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank(),
        panel.grid.major = element_line(color = ""grey95"", size = 1),
        panel.grid.minor = element_line(color = ""grey95"", size = 0.5),
        legend.position = ""left"",
        legend.key = element_rect(fill = ""#173f50"", color = ""#173f50""),
        legend.key.height = unit(0.1, ""pt""),
        legend.key.width = unit(4.5, ""pt""),
        legend.text = element_text(size = 16, 
                                   margin = margin(t = 10, b = 10)))

## map with colored triangle borders
goode <- ggplot(sf_world) + 
  geom_sf(fill = ""white"", color = ""transparent"") +
  geom_sf(data = goode_without, fill = ""#173f50"", color = NA) +
  geom_sf(data = goode_outline, fill = NA, color = ""grey95"", size = 0.5/.pt) +
  geom_sf(data = sf_nuclear, aes(fill = country, color = country, 
                                 size = yield_upper, shape = sealevel),
          stroke = 0.01) +
  scale_x_continuous(name = NULL, breaks = seq(-120, 120, by = 60)) +
  scale_y_continuous(name = NULL, breaks = seq(-60, 60, by = 30)) +
  scale_size_continuous(range = c(1.5, 15), guide = F) +
  scale_shape_manual(values = c(24, 25), guide = F) +
  scale_fill_manual(name = """", values = alpha(cols, 0.3)) +
  scale_color_manual(guide = F, values = colorspace::darken(cols, 0.3)) +
  guides(fill = guide_legend(override.aes = list(alpha = 1))) +
  coord_sf(xlim = 0.95*xlim, ylim = ylim, 
           expand = F, crs = crs_goode, ndiscr = 1000) +
  theme(panel.background = element_rect(fill = ""grey90"", color = ""#173f50""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank(),
        panel.grid.major = element_line(color = ""grey95"", size = 1),
        panel.grid.minor = element_line(color = ""grey95"", size = 0.5),
        legend.position = ""left"",
        legend.key = element_rect(fill = ""#173f50"", color = ""#173f50""),
        legend.key.height = unit(0.1, ""pt""),
        legend.key.width = unit(4.5, ""pt""),
        legend.text = element_text(size = 16, 
                                   margin = margin(t = 10, b = 10)))
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""Nuclear Explosions from 1945 to 1998"",
       subtitle = ""Triangles depict nuclear explosions, either deployed in the atmosphere (pointing upwards) or under the ground/water (pointing downwards).\nThe size scales with the explosion yield estimate and the color indicates the country that deployed the nuclear device."") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = NA),
        plot.background = element_rect(fill = NA, color = NA),
        panel.border = element_rect(color = NA),
        axis.text = element_blank(),
        plot.title = element_text(family = ""Rockwell Extra Bold"", size = 30),
        plot.subtitle = element_text(size = 10))
```

```{r caption}
## right-alligned caption
caption <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       caption = ""Visualization by Cdric Scherer  |  Data: SIPRI Report 2000 (FOA-R--00-01572-180--SE)"") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = NA),
        plot.background = element_rect(fill = NA, color = NA),
        panel.border = element_rect(color = NA),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 14, fig.height = 6.4}
title + goode + caption + plot_layout(widths = c(0, 1, 0), nrow = 1)

ggsave(here::here(""plots"", ""2019_34"", ""2019_34_NuclearExplosions.pdf""), 
       width = 14, height = 6.4, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"170",434,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_35_SimpsonsGuests.Rmd","---
title: ""TidyTuesday 2019/35 - Simpsons Guest Stars by Wikipedia""
author: ""Cedric Scherer""
date: ""30th of August 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(ggtext)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
theme_update(rect = element_rect(color = NA, 
                                 fill = ""#FFCC00""),
             line = element_blank(),
             text = element_text(color = ""white""), 
             plot.margin = margin(10, 40, 20, 40))
```

```{r data}
df_simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")
```

```{r clean}
df_simpsons_series <- 
  df_simpsons %>% 
  filter(season != ""Movie"") %>% 
  mutate(season = as.numeric(season)) %>% 
  separate(number, c(""no_cont"", ""no_season""), sep = """")
```

```{r rank-guests}
top <- 
  df_simpsons_series %>% 
    count(guest_star) %>% 
    top_n(6, n) %>% 
    arrange(-n) %>%
    pull(guest_star)

lev <- c(top, ""other"")

df_simpsons_lumped <- 
  df_simpsons_series %>% 
  count(season, guest_star) %>% 
  group_by(guest_star) %>% 
  mutate(total = n()) %>% 
  group_by(season) %>% 
  arrange(desc(n), desc(total), guest_star) %>% 
  mutate(
    ranking = row_number(),
    top = ifelse(guest_star %in% top, guest_star, ""other""),
    top = factor(top, levels = lev)
  )

ranks <- 
  ggplot(df_simpsons_lumped, 
         aes(season, ranking, 
             color = top)) +
    geom_segment(data = tibble(x = 0.3, xend = 30.5, y = 1:61), 
                 aes(x = x, xend = xend, y = y, yend = y),
                 color = ""white"", linetype = ""dotted"") +
    geom_segment(data = tibble(x = 30.5, xend = 31, y = 2:61), 
                 aes(x = x, xend = xend, y = y, yend = y),
                 color = ""white"") +
    geom_segment(data = tibble(x = 30.5, xend = 31.5, y = c(1, seq(5, 60, by = 5))), 
                 aes(x = x, xend = xend, y = y, yend = y),
                 color = ""white"") +
    geom_point(color = ""white"", 
               size = 5) +
    geom_point(color = ""#FFCC00"", 
               size = 3) + 
    geom_line(data = filter(df_simpsons_lumped, top != ""other""), 
              size = 1, 
              alpha = 1) +
    geom_point(data = filter(df_simpsons_lumped, top != ""other""), 
              size = 9) + 
    geom_point(data = filter(df_simpsons_lumped, top != ""other""), 
               color = ""#FFCC00"", 
               size = 6) + 
    geom_text(data = filter(df_simpsons_lumped, top != ""other""), 
              aes(label = n),
              family = ""Roboto"",
              fontface = ""bold"", 
              size = 3) +
    annotate(""label"", x = 10, y = 55, 
             fill = ""#FFCC00"", 
             color = ""white"",
             family = ""Roboto Mono"", 
             fontface = ""bold"", 
             size = 4.5,
             label.padding = unit(1, ""lines""),
             label = 'Ranking of guest star appearances per\nseason in the TV series ""The Simpsons"".\n\nThe six top guests are colored\n and visualised as their common character.\nAll others are ranked anonymously and\nindicate the total number of guests\nper season. In case of a tie guest stars\nare sorted by the number of appearances.') +
    scale_x_continuous(position = ""top"", 
                       limits = c(0, 31.5), 
                       breaks = 1:30,
                       expand = c(0.01, 0.01)) +
    scale_y_reverse(position = ""right"", 
                    limits = c(61, 1), 
                    breaks = c(1, seq(5, 60, by = 5)),
                    expand = c(0.01, 0.01)) +
    scale_color_manual(values = c(""#00947E"", ""#FF5180"", ""#460046"", 
                                  ""#727273"", ""#B26C3A"", ""#C72626"")) +
    scale_linetype_manual(values = c(rep(1, 6), 0)) +
    theme(axis.text = element_text(color = ""white"",
                                   family = ""Roboto Mono"", 
                                   face = ""bold""),
          axis.title.y = element_text(hjust = 0),
          panel.border = element_rect(color = NA),
          legend.position = ""none"") +
    labs(x = ""Season"", y = ""Ranking\n"")
```

```{r image-legend}
labels <-
  tibble(
    labels = c(
      ""<img src='https://upload.wikimedia.org/wikipedia/en/7/76/Edna_Krabappel.png'
    +     width='100' /><br><b style='color:#00947E'>Marcia Wallace</b><br><i style='color:#00947E'>Edna Krabappel</i></b>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/6/6c/Troymcclure.png'
    +     width='90' /><br><b style='color:#FF5180'>Phil Hartman</b><br><i style='color:#FF5180'>Troy McClure</i></b>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/3/3e/FatTony.png'
    +     width='110' /><br><b style='color:#460046'>Joe Mantegna</b><br><i style='color:#460046'>Fat Tony</i></b>"",
      ""<img src='./img/orson.png'
    +     width='85' /><br><b style='color:#727273'>Maurice LaMarche</b><br><i style='color:#727273'>Several VIPs</i>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/8/8a/SantasLittleHelper.png'
    +     width='100' /><br><b style='color:#B26C3A'>Frank Welker</b><br><i style='color:#B26C3A'>Santas Little Helper</i></b>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/c/c8/C-bob.png'
    +     width='100' /><br><b style='color:#C72626'>Kelsey Grammer</b><br><i style='color:#C72626'>Sideshow Bob</i></b>""
    ),
    x = 1:6, 
    y = rep(1, 6)
  )

legend <- 
  ggplot(labels, aes(x, y)) +
    geom_richtext(aes(label = labels), 
                  fill = NA, 
                  color = NA, 
                  vjust = 0) +
    annotate(""text"", x = 3.5, y = 1.018, 
             label = 'Guest Voices in ""The Simpsons""', 
             size = 15, 
             fontface = ""bold"", 
             family = ""Poppins"") +
    scale_x_continuous(limits = c(0.6, 6.1)) +
    scale_y_continuous(limits = c(1, 1.02)) +
    theme_void() +
    theme(plot.background = element_rect(fill = ""#FFCC00""))
```

```{r caption}
caption <- 
  ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       caption = ""Visualization by Cdric Scherer  |  Source: Wikipedia  |  Image  Copyright: Matt Groening & 20th Century Fox                                                   "") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", 
                                       color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 16, fig.height = 24}
legend + ranks + caption + plot_layout(ncol = 1, heights = c(0.25, 1, 0))

ggsave(here::here(""plots"", ""2019_35"", ""2019_35_SimpsonsGuests.pdf""), 
       width = 16, height = 24, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"171",435,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_35_SimpsonsGuests_black.Rmd","---
title: ""TidyTuesday 2019/35 - Simpsons Guest Stars by Wikipedia""
author: ""Cedric Scherer""
date: ""30th of August 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r prep, message=FALSE}
## packages
library(tidyverse)
library(ggtext)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
theme_update(rect = element_rect(color = NA, 
                                 fill = ""#FFCC00""),
             line = element_blank(),
             text = element_text(color = ""black""), 
             plot.margin = margin(10, 40, 20, 40))
```

```{r data}
df_simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")
```

```{r clean}
df_simpsons_series <- 
  df_simpsons %>% 
  filter(season != ""Movie"") %>% 
  mutate(season = as.numeric(season)) %>% 
  separate(number, c(""no_cont"", ""no_season""), sep = """")
```

```{r rank-guests}
top <- 
  df_simpsons_series %>% 
    count(guest_star) %>% 
    top_n(6, n) %>% 
    arrange(-n) %>%
    pull(guest_star)

lev <- c(top, ""other"")

df_simpsons_lumped <- 
  df_simpsons_series %>% 
  count(season, guest_star) %>% 
  group_by(guest_star) %>% 
  mutate(total = n()) %>% 
  group_by(season) %>% 
  arrange(desc(n), desc(total), guest_star) %>% 
  mutate(
    ranking = row_number(),
    top = ifelse(guest_star %in% top, guest_star, ""other""),
    top = factor(top, levels = lev)
  )

ranks <- 
  ggplot(df_simpsons_lumped, 
         aes(season, ranking, 
             color = top)) +
    geom_segment(data = tibble(x = 0.3, xend = 30.5, y = 1:61), 
                 aes(x = x, xend = xend, y = y, yend = y),
                 color = ""white"", linetype = ""dotted"") +
    geom_segment(data = tibble(x = 30.5, xend = 31, y = 2:61), 
                 aes(x = x, xend = xend, y = y, yend = y),
                 color = ""black"") +
    geom_segment(data = tibble(x = 30.5, xend = 31.5, y = c(1, seq(5, 60, by = 5))), 
                 aes(x = x, xend = xend, y = y, yend = y),
                 color = ""black"") +
    geom_point(color = ""white"", 
               size = 5) +
    geom_point(color = ""#FFCC00"", 
               size = 3) + 
    geom_line(data = filter(df_simpsons_lumped, top != ""other""), 
              size = 1, 
              alpha = 1) +
    geom_point(data = filter(df_simpsons_lumped, top != ""other""), 
              size = 9) + 
    geom_point(data = filter(df_simpsons_lumped, top != ""other""), 
               color = ""#FFCC00"", 
               size = 6) + 
    geom_text(data = filter(df_simpsons_lumped, top != ""other""), 
              aes(label = n),
              family = ""Roboto"",
              fontface = ""bold"", 
              size = 3) +
    annotate(""label"", x = 10, y = 55, 
             fill = ""#FFCC00"", 
             color = ""black"",
             family = ""Roboto Mono"", 
             fontface = ""bold"", 
             size = 4.5,
             label.padding = unit(1, ""lines""),
             label = 'Ranking of guest star appearances per\nseason in the TV series ""The Simpsons"".\n\nThe six top guests are colored\n and visualised as their common character.\nAll others are ranked anonymously and\nindicate the total number of guests\nper season. In case of a tie guest stars\nare sorted by the number of appearances.') +
    scale_x_continuous(position = ""top"", 
                       limits = c(0, 31.5), 
                       breaks = 1:30,
                       expand = c(0.01, 0.01)) +
    scale_y_reverse(position = ""right"", 
                    limits = c(61, 1), 
                    breaks = c(1, seq(5, 60, by = 5)),
                    expand = c(0.01, 0.01)) +
    scale_color_manual(values = c(""#00947E"", ""#FF5180"", ""#460046"", 
                                  ""#727273"", ""#B26C3A"", ""#C72626"")) +
    scale_linetype_manual(values = c(rep(1, 6), 0)) +
    theme(axis.text = element_text(color = ""black"",
                                   family = ""Roboto Mono"", 
                                   face = ""bold""),
          axis.title.y = element_text(hjust = 0),
          panel.border = element_rect(color = NA),
          legend.position = ""none"") +
    labs(x = ""Season"", y = ""Ranking\n"")
```

```{r image-legend}
labels <-
  tibble(
    labels = c(
      ""<img src='https://upload.wikimedia.org/wikipedia/en/7/76/Edna_Krabappel.png'
    +     width='100' /><br><b style='color:#00947E'>Marcia Wallace</b><br><i style='color:#00947E'>Edna Krabappel</i></b>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/6/6c/Troymcclure.png'
    +     width='90' /><br><b style='color:#FF5180'>Phil Hartman</b><br><i style='color:#FF5180'>Troy McClure</i></b>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/3/3e/FatTony.png'
    +     width='110' /><br><b style='color:#460046'>Joe Mantegna</b><br><i style='color:#460046'>Fat Tony</i></b>"",
      ""<img src='./img/orson.png'
    +     width='85' /><br><b style='color:#727273'>Maurice LaMarche</b><br><i style='color:#727273'>Several VIPs</i>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/8/8a/SantasLittleHelper.png'
    +     width='100' /><br><b style='color:#B26C3A'>Frank Welker</b><br><i style='color:#B26C3A'>Santas Little Helper</i></b>"",
      ""<img src='https://upload.wikimedia.org/wikipedia/en/c/c8/C-bob.png'
    +     width='100' /><br><b style='color:#C72626'>Kelsey Grammer</b><br><i style='color:#C72626'>Sideshow Bob</i></b>""
    ),
    x = 1:6, 
    y = rep(1, 6)
  )

legend <- 
  ggplot(labels, aes(x, y)) +
    geom_richtext(aes(label = labels), 
                  fill = NA, 
                  color = NA, 
                  vjust = 0) +
    annotate(""text"", x = 3.5, y = 1.018, 
             label = 'Guest Voices in ""The Simpsons""', 
             size = 15, 
             fontface = ""bold"", 
             family = ""Poppins"") +
    scale_x_continuous(limits = c(0.6, 6.1)) +
    scale_y_continuous(limits = c(1, 1.02)) +
    theme_void() +
    theme(plot.background = element_rect(fill = ""#FFCC00""))
```

```{r caption}
caption <- 
  ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       caption = ""Visualization by Cdric Scherer  |  Source: Wikipedia  |  Image  Copyright: Matt Groening & 20th Century Fox                                                   "") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", 
                                       color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank())
```

```{r full-panel, fig.width = 16, fig.height = 24}
legend + ranks + caption + plot_layout(ncol = 1, heights = c(0.25, 1, 0))

ggsave(here::here(""plots"", ""2019_35"", ""2019_35_SimpsonsGuests_black.pdf""), 
       width = 16, height = 24, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"172",436,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_36_MooresLaw.Rmd","---
title: ""TidyTuesday 2019/36 - Moore's Law by Wikipedia""
author: ""Cedric Scherer""
date: ""4th of September 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```

```{r prep, message=FALSE, warning=FALSE}
## packages
library(tidyverse)
library(ggtext)
library(patchwork)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")

df_gpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")

df_ram <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")
```

```{r combine-data}
df_moore_all <-
  df_ram %>% 
  dplyr::select(
    name = chip_name,
    transistor_count,
    date_of_introduction,
    designer = manufacturer_s,
    process, 
    area
  ) %>% 
  mutate(type = ""RAM"") %>% 
  bind_rows(df_cpu %>% 
              rename(name = processor) %>% 
              mutate(type = ""CPU"")) %>% 
  bind_rows(df_gpu %>% 
              dplyr::select(
                name = processor,
                transistor_count,
                date_of_introduction,
                designer = manufacturer_s,
                process, 
                area
              ) %>% 
              mutate(type = ""GPU"")
            )
```

```{r plot}
df_opt <-
  df_moore_all %>% 
  mutate(year_cum = date_of_introduction %/% 2 * 2) %>% 
  group_by(type, year_cum) %>% 
  summarize(transistor_count = mean(transistor_count, na.rm = T)) %>% 
  group_by(type) %>% 
  mutate(
    min = min(transistor_count, na.rm = T),
    start = min(year_cum, na.rm = T),
    lev = 2^(year_cum / 2 - start / 2),
    opt = min * lev
  )

labels <- tibble(
  x1 = c(1986, 1992, 1995),
  x2 = c(1993.5, 1999.8, 1990.2),
  y1 = c(3.3*10^7, 1.3*10^9, 7000),
  y2 = c(12000000, 2*10^8, 32000),
  type = rep(""CPU"", 3),
  text = c(""**Predicted** number of transistors<br>according to **Moore's Law**"",
           ""**Maximum** number of transistors<br>in the respective 2-year period"",
           ""**Minimum** number of transistors<br>in the respective 2-year period"")
)

plot <- 
  df_moore_all %>% 
  mutate(year_cum = date_of_introduction %/% 2 * 2) %>% 
  group_by(type, year_cum) %>% 
  mutate(
    min = min(transistor_count, na.rm = T),
    max = max(transistor_count, na.rm = T)
  ) %>% 
  ggplot(aes(year_cum, transistor_count)) +
    ## centered in-plot striptext
    #geom_text(aes(label = type, x = 1990, y = 1.5*10^11), 
    #          color = ""grey16"",
    #          family = ""Montserrat Black"",
    #          size = 28) +
    ## left-alligned in-plot striptext
    geom_text(aes(label = type, x = 1961, y = 1.5*10^11), 
              color = ""grey16"",
              family = ""Montserrat Black"",
              size = 27,
              hjust = 0) +
    geom_segment(aes(x = year_cum, xend = year_cum, 
                     y = min, yend = max), 
                 size = 2.5,
                 color = ""grey40"",
                 lineend = ""round"") +
    geom_point(data = df_opt, 
               aes(year_cum, opt), 
               color = ""grey80"",
               shape = 1,
               size = 2) +
    geom_point(aes(y = min), 
               color = ""#ffc04d"", 
               size = 0.8) +
    geom_point(aes(y = max), 
               color = ""#30d59f"", 
               size = 0.8) +
    geom_curve(data = labels, 
               aes(x = x1, y = y1, xend = x2, yend = y2), 
               size = 0.3, 
               color = c(""grey80"", ""#30d59f"", ""#ffc04d""), 
               linetype = ""dotted"", 
               curvature = -0.3) +
    geom_richtext(data = labels, 
                  aes(x = x1, y = y1, label = text),
                  color = c(""grey80"", ""#30d59f"", ""#ffc04d""),
                  family = ""Montserrat"",
                  size = 2,
                  fill = NA, 
                  label.color = NA,
                  hjust = c(1, 1, 0)) +
    scale_x_continuous(breaks = seq(1962, 2018, by = 8)) +
    scale_y_log10(breaks = c(1, 10^3, 10^6, 10^9, 10^12),
                  labels = scales::comma) +
    coord_cartesian(xlim = c(1962, 2018), ylim = c(1, 2*10^12), clip = ""off"") +
    facet_grid(~ type) +
    theme(axis.text = element_text(family = ""Roboto Mono"",
                                   size = 10),
          axis.title.y = element_text(family = ""Montserrat"", 
                                      face = ""plain"",
                                      size = 13,
                                      color = ""grey85""),
          strip.text = element_blank(),
          strip.background = element_blank(),
          panel.spacing.x = unit(12, ""pt"")) +
    labs(x = NULL, y = ""Number of Transistors"")
```

```{r title}
## left-alligned title
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       title = ""MOORE'S LAW"", 
       subtitle = ""*Moore's law* is the observation that the **number of transistors** in a dense integrated circuit **doubles about every two years**.<br>The observation is named after *Gordon E. Moore*, the co-founder of Fairchild Semiconductor and CEO of Intel.<br>"")+
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
        panel.border = element_rect(colour = ""transparent""),
        axis.text = element_blank(),
        plot.title = element_text(family = ""Montserrat Black"", 
                                  size = 30, 
                                  color = ""grey95""),
        plot.subtitle = element_markdown(family = ""Montserrat"", 
                                         size = 10, 
                                         color = ""grey85"",
                                         lineheight = 1.25))
```

```{r caption}
caption <- 
  ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(x = NULL, y = NULL,
       caption = ""\nVisualization by Cdric Scherer  |  Source: Wikipedia"") +
  theme(line = element_blank(),
        panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""transparent"", 
                                       color = ""transparent""),
        panel.border = element_rect(color = ""transparent""),
        axis.text = element_blank(),
        plot.caption = element_text(family = ""Montserrat"", 
                                    size = 9, 
                                    color = ""grey85""))
```

```{r full-panel, fig.width = 14, fig.height = 5.8}
title + plot + caption + plot_layout(nrow = 1, widths = c(0, 1, 0))

ggsave(here::here(""plots"", ""2019_36"", ""2019_36_MooresLaw.pdf""), 
       width = 14, height = 5.8, device = cairo_pdf)
```

## 2nd version with prediction as twice the previous maximum

```{r double-version, fig.width = 14, fig.height = 5.8}
labels_double <- tibble(
  x1 = c(1981, 1991.5, 1988, 2004.7, 1979),
  x2 = c(1988, 1999.9, 1980, 2013.8, 1970),
  y1 = c(2.6*10^7, 9*10^8, 500, 1.2*10^10, 8),
  y2 = c(1460000, 2*10^8, 11500, 10^10, 2250),
  type = rep(""CPU"", 5),
  text = c(""**Predicted** transistor count =<br>twice the maximum count of<br>the previous 2-year period"",
           ""Maximum transistor count<br>**higher** than predicted"",
           ""Maximum transistor count<br>**lower** than predicted"",
           ""Maximum transistor count<br>**exactly** as predicted"",
           ""No prediction possible because<br>no data in previous 2-year period"")
)

plot_double <- 
  df_moore_all %>% 
  mutate(year_cum = date_of_introduction %/% 2 * 2) %>% 
  group_by(type, year_cum) %>% 
  summarize(max = max(transistor_count, na.rm = T)) %>% 
  group_by(type) %>% 
  complete(year_cum = seq(1962, 2018, by = 2)) %>% 
  mutate(
    exp = lag(max) * 2,
    exp = if_else(is.na(exp), max, exp),
    exp = if_else(exp < lag(exp), lag(exp), exp),
    exp = if_else(is.na(max), NA_real_, exp),
    exp = if_else(is.na(lag(max)), NA_real_, exp),
    comp = case_when(
      max > exp ~ ""higher"", 
      max == exp ~ ""equal"",
      max < exp ~ ""lower"",
      is.na(exp) ~ ""not known""
    )
  ) %>% 
  ggplot(aes(year_cum, max)) +
    geom_text(aes(label = type, x = 1961, y = 1.5*10^11), 
              color = ""grey16"",
              family = ""Montserrat Black"",
              size = 27,
              hjust = 0) +
    geom_segment(aes(x = year_cum, xend = year_cum, 
                     y = exp, yend = max, 
                     color = comp),
                 size = 0.3) + 
    geom_curve(data = labels_double, 
               aes(x = x1, y = y1, xend = x2, yend = y2), 
               size = 0.3, 
               color = c(""grey60"", ""#30d59f"", ""#ffc04d"", ""#9f30d5"", ""grey80""),
               linetype = ""dotted"",
               curvature = -0.3) +
    geom_richtext(data = labels_double, 
                  aes(x = x1, y = y1, label = text),
                  color = c(""grey60"", ""#30d59f"", ""#ffc04d"", ""#9f30d5"", ""grey80""),
                  family = ""Montserrat"",
                  size = 2,
                  fill = NA, 
                  label.color = NA,
                  hjust = c(1, 1, 0, 1, 0)) +
    geom_point(aes(year_cum, exp), 
               color = ""grey60"",
               fill = ""grey20"",
               shape = 21,
               size = 2) +
    geom_point(aes(color = comp), size = 1.5) +
    scale_x_continuous(breaks = seq(1962, 2018, by = 8)) +
    scale_y_log10(breaks = c(1, 10^3, 10^6, 10^9, 10^12),
                  labels = scales::comma) +
    scale_color_manual(guide = F, values = c(""#9f30d5"", ""#30d59f"", ""#ffc04d"", ""grey80"")) +
    facet_grid(~ type) +
    coord_cartesian(xlim = c(1962, 2018), ylim = c(1, 2*10^12), clip = ""off"") +
    theme(axis.text = element_text(family = ""Roboto Mono"",
                                   size = 10),
          axis.title.y = element_text(family = ""Montserrat"", 
                                      face = ""plain"",
                                      size = 13,
                                      color = ""grey85""),
          strip.text = element_blank(),
          strip.background = element_blank(),
          panel.spacing.x = unit(12, ""pt"")) +
    labs(x = NULL, y = ""Number of Transistors"")

title + plot_double + caption + plot_layout(nrow = 1, widths = c(0, 1, 0))

ggsave(here::here(""plots"", ""2019_36"", ""2019_36_MooresLaw_double.pdf""), 
       width = 14, height = 5.8, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```","2019"
"173",437,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_39_SchoolDiversity.Rmd","---
title: ""TidyTuesday 2019/39 - School Diversity by NCES""
author: ""Cedric Scherer""
date: ""25th of September 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```

```{r prep, message=FALSE, warning=FALSE}
## packages
library(tidyverse)
library(ggbeeswarm)
library(biscale)
library(fiftystater)
library(geofacet)
library(cowplot)
library(patchwork)
library(ggtext)
library(broom)
library(geojsonio)
library(rgdal)
library(rgeos)

## ggplot theme updates
source(here::here(""theme"", ""tidy_grey.R""))

theme_set(theme_custom(base_family = ""Montserrat""))
theme_update(rect = element_rect(fill = ""grey10""),
             panel.border = element_rect(color = ""grey30""),
             axis.ticks = element_line(color = ""grey30""),
             axis.text = element_text(color = ""grey50""),
             plot.title = element_text(size = 30, 
                                       family = ""Montserrat ExtraBold"",
                                       hjust = 0.5),
             plot.subtitle = element_markdown(size = 12, 
                                              family = ""Bitter"", 
                                              color = ""grey50"", 
                                              lineheight = 1.4,
                                              hjust = 0.5),
             plot.caption = element_text(size = 9, 
                                         family = ""Bitter"", 
                                         color = ""grey50""))
```

```{r data}
df_schools <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv"")
```

```{r prep-data}
df_school_index <- 
  df_schools %>% 
  group_by(ST) %>% 
  mutate_at(vars(AIAN:Multi), ~ replace_na(., 0)) %>% 
  mutate(
    total = AIAN + Asian + Black + Hispanic + White + Multi,
    prop_whites = median(White)
  ) %>%
  ungroup() %>% 
  mutate(prop_whites = White) %>% 
  dplyr::select(LEAID, ST, SCHOOL_YEAR, AIAN:Multi, total, prop_whites) %>% 
  gather(ethnicity, value, -c(LEAID, ST, SCHOOL_YEAR, total, prop_whites)) %>% 
  filter(value > 0) %>% 
  group_by(LEAID, ST, SCHOOL_YEAR, prop_whites) %>% 
  summarize(
    simpson = (1 - sum(value * (value - 1)) / (100*(100 - 1))),
    shannon = -sum((value / total) * log(value / total))
  ) %>% 
  ungroup()
```

## Main plot

```{r biscale-map}
## biscale map
df_schools_biscale <- 
  df_school_index %>% 
  filter(SCHOOL_YEAR == ""2016-2017"") %>% 
  group_by(ST) %>% 
  summarize(
    simpson = median(simpson),
    prop_whites = median(prop_whites)
  ) %>% 
  bi_class(x = simpson, y = prop_whites, style = ""quantile"", dim = 3)

map <- 
  fifty_states %>%
  as_tibble() %>%
  mutate(region = stringr::str_to_title(id)) %>% 
  left_join(state_ranks[, 1:2], by = c(""region"" = ""name"")) %>% 
  full_join(df_schools_biscale, by = c(""state"" = ""ST"")) %>% 
  ggplot() +
    geom_map(aes(map_id = id, fill = bi_class), 
             map = fifty_states,
             color = ""grey20"",
             size = 0.01) +  
    expand_limits(x = fifty_states$long, y = fifty_states$lat) +
    fifty_states_inset_boxes() +
    bi_scale_fill(pal = ""Brown"", dim = 3, guide = F) +
    coord_map() +
    scale_x_continuous(breaks = NULL) + 
    scale_y_continuous(breaks = NULL) +
    theme(panel.background = element_blank(),
          panel.border = element_blank()) +
    labs(x = NULL, y = NULL,
         title = ""How diverse are schools in the US?"", 
         subtitle = ""<br>Bivariate map showing the combination of racial diversity measured as <b style='color:#C8B35A'>Simpson index</b>, a quantitative diversity measure,<br>and the <b style='color:#9972AF'>proportion of students with white ethnicity</b> during the <b>school year 20162017</b>."")

legend <- 
  bi_legend(pal = ""Brown"",
            dim = 3,
            xlab = ""Diversity "",
            ylab = ""% Whites "") +
  theme_custom() +
  theme(rect = element_rect(fill = ""grey10""),
        panel.border = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title.x = element_text(size = 10,
                                    color = ""grey70""),
        axis.title.y = element_text(size = 10,
                                    color = ""grey70""))

map_legend <- ggdraw() +
  draw_plot(map, 0, 0, 1, 1) +
  draw_plot(legend, 0.75, 0.1, 0.2, 0.2)
```

```{r beeswarm-diversity}
## beeswarm diversity
beeswarm_simpson <- 
  df_school_index %>% 
  filter(SCHOOL_YEAR == ""2016-2017"") %>% 
  group_by(ST) %>% 
  mutate(
    median = median(simpson),
    simpson_h = if_else(simpson >= median, simpson, NA_real_),
    simpson_l = if_else(simpson < median, simpson, NA_real_)
  ) %>% 
  ungroup() %>% 
  mutate(median_all = median(simpson)) %>% 
  group_by(ST, median_all) %>% 
  mutate(diff = unique(median) - unique(median_all)) %>% 
  ungroup() %>% 
  mutate(ST = fct_reorder(ST, -median)) %>% 
  ggplot(aes(ST, simpson,
             fill = diff)) + 
    ggbeeswarm::geom_beeswarm(aes(ST, simpson_l), 
                              priority = 'descending', 
                              cex = 0.32,
                              size = 1.2, 
                              stroke = 0.05,
                              color = ""grey40"", 
                              shape = 21) +
    ggbeeswarm::geom_beeswarm(aes(ST, simpson_h),
                              cex = 0.32,
                              size = 1.2,
                              stroke = 0.05,
                              color = ""white"", 
                              shape = 21) +
    geom_hline(aes(yintercept = median_all), 
               color = ""grey50"", 
               linetype = ""dashed"",
               size = 0.1) +
    geom_point(aes(ST, median),
               color = ""grey10"", 
               shape = 21, 
               size = 3,
               stroke = 0.6) +
    scale_fill_gradient2(low = ""#E8E8E8"", 
                         mid = ""#E4D9AC"",
                         high = ""#C8B35A"",
                         guide = F) +
    theme(axis.text.x = element_text(size = 9,
                                     face = ""bold""),
          axis.text.y = element_text(size = 9, 
                                     family = ""Roboto Mono"")) +
    labs(x = NULL, y = NULL, title = NULL,
         subtitle = ""<b style='color:#E4D9AC'>Simpson diversity index</b> for all schools grouped per state, ranked from states with <b style='color:#C8B35A'>high diversity</b> to those with <b style='color:#E8E8E8'>low diversity</b>.<br>Larger dots represent each state's median diversity with darker colored points laying below and lighter colored points laying above this value.<br>"")
```

```{r beeswarm-whites}
## beeswarm whites
beeswarm_whites <- 
  df_school_index %>% 
  filter(SCHOOL_YEAR == ""2016-2017"") %>% 
  group_by(ST) %>% 
  mutate(
    median = median(prop_whites),
    whites_h = if_else(prop_whites >= median, prop_whites, NA_real_),
    whites_l = if_else(prop_whites < median, prop_whites, NA_real_)
  ) %>% 
  ungroup() %>% 
  mutate(median_all = median(prop_whites)) %>% 
  group_by(ST, median_all) %>% 
  mutate(diff = unique(median) - unique(median_all)) %>% 
  ungroup() %>% 
  mutate(ST = fct_reorder(ST, median)) %>% 
  ggplot(aes(ST, median,
             fill = diff)) + 
    ggbeeswarm::geom_beeswarm(aes(ST, whites_l), 
                              priority = 'descending', 
                              cex = 0.23,
                              size = 1.2,
                              stroke = 0.05,
                              color = ""white"", 
                              shape = 21) +
    ggbeeswarm::geom_beeswarm(aes(ST, whites_h),
                              cex = 0.23,
                              size = 1.2, 
                              stroke = 0.05,
                              color = ""grey40"", 
                              shape = 21) +
    geom_hline(aes(yintercept = median_all), 
               color = ""grey50"", 
               linetype = ""dashed"",
               size = 0.1) +
    geom_point(aes(ST, median),
               color = ""grey10"",
               shape = 21, 
               size = 3,
               stroke = 0.6) +
    scale_y_continuous(breaks = seq(0, 100, by = 20),
                       labels = glue::glue(""{seq(0, 100, by = 20)}%"")) +   
    scale_fill_gradient2(low = ""#E8E8E8"", 
                         mid = ""#CBB8D7"",
                         high = ""#9972AF"",
                         guide = F) +
    theme(axis.text.x = element_text(size = 9,
                                     face = ""bold""),
          axis.text.y = element_text(size = 9,
                                     family = ""Roboto Mono"")) +
    labs(x = NULL, y = NULL,
         subtitle = ""<br><b style='color:#CBB8D7'>Proportion of white students</b> for all schools grouped per state, ranked from states with <b style='color:#E8E8E8'>few white students</b> to those with <b style='color:#9972AF'>many white students</b>.<br>Larger dots represent each state's median proportion with lighter colored points laying below and darker colored points laying above this value.<br>"",
         caption = ""\n\nVisualization by Cdric Scherer  |  Data: NCES"")
```

```{r full-panel, fig.width = 14, fig.height = 16.5}
## panel
map_legend / beeswarm_simpson / beeswarm_whites + plot_layout(heights = c(1, 0.25, 0.25))

ggsave(here::here(""plots"", ""2019_39"", ""2019_39_SchoolDiversity_brpurp.pdf""), 
       width = 14, height = 17, device = cairo_pdf)
```


## Pointdensity plot

```{r corr-plot, fig.width = 11.5, fig.height = 12}
df_school_index %>% 
  ggplot(aes(simpson, prop_whites)) +
  ggpointdensity::geom_pointdensity(size = 0.3) +
  rcartocolor::scale_color_carto_c(palette = ""SunsetDark"",
                                   name = ""Density:"",
                                   limits = c(0, NA)) + 
  scale_y_continuous(limits = c(0, 100), 
                     breaks = seq(0, 100, by = 20),
                     labels = glue::glue(""{seq(0, 100, by = 20)}%"")) +
  labs(x = ""Simpson Diversity Index"", y = ""Proportion of White Students"",
       title = ""How are those measurements correlated?"",
       subtitle = ""Pointdensity scatterplot of the  <b style='color:#d3d3d3'>Simpson diversity index</b> and the <b style='color:#d3d3d3'>proportion of white students</b> in US schools during the school year 20162017<br>"",
       caption =""\nVisualization by Cdric Scherer  |  Data: NCES"") +
  theme(axis.text = element_text(family = ""Roboto Mono"", color = ""grey70""),
        plot.title = element_text(size = 24),
        plot.subtitle = element_markdown(size = 10),
        legend.position = c(0.9, 0.85),
        legend.title = element_text(face = ""bold"", color = ""grey70""),
        legend.text = element_text(family = ""Roboto Mono"", color = ""grey70""),
        legend.key.width = unit(0.5, ""lines""))

ggsave(here::here(""plots"", ""2019_39"", ""2019_39_SchoolDiversity_correlation.pdf""),
       width = 11.5, height = 12, device = cairo_pdf)
```


## Geofacet

```{r geofacet, fig.width = 28, fig.height = 22}
## geofacet diversity
df_median_all <- df_school_index %>% 
  group_by(SCHOOL_YEAR) %>% 
  summarize(median = median(simpson))

df_school_index %>% 
  semi_join(state_ranks, by = c(""ST"" = ""state"")) %>% 
  mutate(
    SCHOOL_YEAR = if_else(SCHOOL_YEAR == ""1994-1995"", ""'94/'95"", ""'16/'17""),
    SCHOOL_YEAR = fct_rev(SCHOOL_YEAR)
  ) %>% 
  group_by(ST, SCHOOL_YEAR) %>% 
  mutate(
    median = median(simpson),
    simpson_h1 = if_else(SCHOOL_YEAR == ""'94/'95"" & simpson >= median, 
                         simpson, NA_real_),
    simpson_l1 = if_else(SCHOOL_YEAR == ""'94/'95"" & simpson < median, 
                         simpson, NA_real_),
    simpson_h2 = if_else(SCHOOL_YEAR == ""'16/'17"" & simpson >= median, 
                         simpson, NA_real_),
    simpson_l2 = if_else(SCHOOL_YEAR == ""'16/'17"" & simpson < median, 
                         simpson, NA_real_)
  ) %>% 
  group_by(ST) %>% 
  mutate(
    zeros_1 = sum(if_else(SCHOOL_YEAR == ""'94/'95"" & simpson == 0, 1, 0)),
    zeros_2 = sum(if_else(SCHOOL_YEAR == ""'16/'17"" & simpson == 0, 1, 0)),
    zeros_1 = if_else(zeros_1 == 0, NA_real_, zeros_1),
    zeros_2 = if_else(zeros_2 == 0, NA_real_, zeros_2)
  ) %>% 
  ggplot(aes(1, simpson)) + 
    annotate(""segment"",
             x = -Inf, xend = Inf,
             y = df_median_all$median[1],
             yend = df_median_all$median[1],
             color = ""grey70"",
             size = 0.1,
             linetype = ""dotted"") +
    annotate(""segment"",
             x = -Inf, xend = Inf,
             y = df_median_all$median[2],
             yend = df_median_all$median[2],
             color = ""goldenrod3"",
             size = 0.1,
             linetype = ""dotted"") +
    ggbeeswarm::geom_beeswarm(aes(SCHOOL_YEAR, simpson_l1),
                              groupOnX = F,
                              priority = 'descending', 
                              cex = 0.06,
                              size = 0.005, 
                              color = ""grey50"") +
    ggbeeswarm::geom_beeswarm(aes(SCHOOL_YEAR, simpson_h1), 
                              groupOnX = F,
                              cex = 0.06,
                              size = 0.005, 
                              color = ""grey90"") +
    ggbeeswarm::geom_beeswarm(aes(SCHOOL_YEAR, simpson_l2), 
                              groupOnX = F,
                              priority = 'descending', 
                              cex = 0.06,
                              size = 0.005, 
                              color = ""firebrick"") +
    ggbeeswarm::geom_beeswarm(aes(SCHOOL_YEAR, simpson_h2), 
                              groupOnX = F,
                              cex = 0.06,
                              size = 0.005, 
                              color = ""goldenrod"") +
    scale_x_discrete(expand = c(0.6, 0.6)) +
    scale_y_continuous(limits = c(-0.02, 0.82), 
                       breaks = seq(0, 0.8, by = 0.2),
                       labels = c(""0"", "".2"", "".4"", "".6"", "".8"")) +
    coord_flip(xlim = c(0.75, 2.25), clip = ""off"") + 
    geofacet::facet_geo(~ ST, grid = ""us_state_grid2"", label = ""name"") +
    theme_custom(base_size = 24, base_family = ""Montserrat"") +
    theme(rect = element_rect(fill = ""grey10""),
          plot.title = element_text(size = 50,
                                    family = ""Montserrat ExtraBold"",
                                    hjust = 0.5,
                                    lineheight = 1.2),
          plot.subtitle = element_markdown(size = 22, 
                                           family = ""Bitter"", 
                                           color = ""grey50"", 
                                           hjust = 0.5,
                                           lineheight = 1.4),
          plot.caption = element_markdown(family = ""Bitter"", 
                                          size = 18,
                                          color = ""grey50""),
          axis.text.x = element_text(size = 14, 
                                     family = ""Roboto Mono"",
                                     color = ""grey40""),
          axis.text.y = element_blank(),
          axis.ticks.x = element_line(color = ""grey30""),
          axis.ticks.y = element_blank(),
          strip.background = element_blank(),
          strip.text = element_text(size = 18,
                                    family = ""Roboto Condensed"",
                                    color = ""grey80""),
          panel.border = element_rect(color = ""grey30"")) +
    labs(x = NULL, y = NULL, 
         title = ""How the growing racial diversity in the US is reflected in schools"", 
         subtitle = ""Comparison of the Simpson diversity index, a quantitative measure that reflects the racial diversity, during the school years <b style='color:#b3b3b3'>19941995</b><br>and <b style='color:#cd9b1d'>20162017</b> for schools with the racial <b>diversity being lower than (<b style='color:#b22222'></b> or <b style='color:#7f7f7f'></b>) or higher than/equal to (<b style='color:#daa520'></b> or <b style='color:#e5e5e5'></b>) the state's median</b>.<br>Dotted lines indicate the US median diversity. <br>"",
         caption = ""Visualization by Cdric Scherer  |  Data: NCES"")
  
ggsave(here::here(""plots"", ""2019_39"", ""2019_39_SchoolDiversity_geofacet_raw.pdf""), 
       width = 28, height = 22, device = cairo_pdf)
```


## Hex bin maps 

```{r theme-hex-bin-maps, message=FALSE, warning=FALSE}
## ggplot theme updates (different theme here, thus reload and new changes)
source(here::here(""theme"", ""tidy_grey.R""))

theme_set(theme_custom(base_family = ""Merriweather Sans""))

theme_update(rect = element_rect(fill = ""grey10""),
             panel.border = element_blank(),
             axis.ticks = element_blank(),
             axis.text = element_blank(),
             axis.title = element_blank(),
             legend.position = c(0.48, 0.92),
             legend.title = element_text(size = 12, 
                                         color = ""grey75"",
                                         lineheight = 1.04),
             legend.text = element_text(family = ""Roboto Mono"", 
                                        color = ""grey75"", 
                                        size = 11),
             plot.title = element_text(size = 27,
                                       hjust = 0.5,
                                       margin = margin(t = 15, b = 40)),
             plot.caption = element_text(size = 12, 
                                         color = ""grey45"",
                                         hjust = 0.5,
                                         margin = margin(t = 30, b = 10)))
```

```{r hex-bin-maps, fig.width = 15, fig.height = 6.5}
## load data key state names <-> ISO2
df_states <- readr::read_csv(here::here(""data"", ""50_us_states_all_data.csv""), col_names = F) %>% 
  dplyr::select(state = ""X2"", ISO2 = ""X3"") %>% 
  add_row(state = ""District of Columbia"", ISO2 = ""DC"")

## load US hex bin map
map_hex <- geojson_read(here::here(""data"", ""us_states_hexgrid.geojson.json""),  what = ""sp"")

map_hex@data <-
  map_hex@data %>%
  mutate(google_name = gsub("" \\(United States\\)"", """", google_name))

## fortify
map_hex_fortified <- tidy(map_hex, region = ""google_name"")

## centroids for labels
centroids <- cbind.data.frame(data.frame(gCentroid(map_hex, byid = T), id = map_hex@data$iso3166_2))

## calculate Simpson index and spread per school year
df_schools_index_wide <- 
  df_schools %>% 
  group_by(ST) %>% 
  mutate_at(vars(AIAN:Multi), ~ replace_na(., 0)) %>% 
  mutate(
    total = AIAN + Asian + Black + Hispanic + White + Multi,
    prop_whites = median(White)
  ) %>%
  ungroup() %>% 
  mutate(prop_whites = White) %>% 
  dplyr::select(LEAID, ST, SCHOOL_YEAR, AIAN:Multi, total) %>% 
  gather(ethnicity, value, -c(LEAID, ST, SCHOOL_YEAR, total)) %>% 
  filter(value > 0) %>% 
  group_by(LEAID, ST, SCHOOL_YEAR) %>% 
  summarize(simpson = (1 - sum(value * (value - 1)) / (100*(100 - 1)))) %>% 
  group_by(ST, SCHOOL_YEAR) %>% 
  summarize(simpson = mean(simpson, na.rm = T)) %>% 
  pivot_wider(names_from = SCHOOL_YEAR, values_from = simpson) %>% 
  mutate(change = `2016-2017` - `1994-1995`)

## combine data
df_schools_hex <- 
  map_hex_fortified %>%
  left_join(df_states, by = c(""id"" = ""state"")) %>% 
  left_join(df_schools_index_wide, by = c(""ISO2"" = ""ST""))

## hex bin map diversity 2016/17
map_hex_diversity <-
 ggplot(df_schools_hex) +
  geom_polygon(aes(long, lat, 
                   group = group, 
                   fill = `2016-2017`), 
               color = ""grey85"") +
  geom_text(data = centroids, 
            aes(x = x, y = y, label = id),
            family = ""Montserrat"",
            fontface = ""bold"") +
  coord_map() +
  rcartocolor::scale_fill_carto_c(palette = ""SunsetDark"", 
                                  name = ""Simpson diversity index\nduring the 2016/17 school year"",
                                  limits = c(0, 0.65)) +
  guides(fill = guide_colorbar(barheight = unit(2.5, units = ""mm""),  
                               barwidth = unit(90, units = ""mm""),
                               direction = ""horizontal"",
                               ticks.colour = ""grey10"",
                               title.position = ""top"",
                               title.hjust = 0.5))

## hex bin map change diversity
map_hex_change <-
 ggplot(df_schools_hex) +
  geom_polygon(aes(long, lat, 
                   group = group, 
                   fill = change), 
               color = ""grey85"") +
  geom_text(data = centroids, 
            aes(x = x, y = y, label = id),
            family = ""Montserrat"",
            fontface = ""bold"") +
  coord_map() +
  rcartocolor::scale_fill_carto_c(palette = ""PurpOr"", na.value = ""grey85"",
                                  name = ""Change in the Simpson diversity index\ncompared to the 1994/95 school year"") +
  guides(fill = guide_colorbar(barheight = unit(2.5, units = ""mm""),  
                               barwidth = unit(90, units = ""mm""),
                               direction = ""horizontal"",
                               ticks.colour = ""grey10"",
                               title.position = ""top"",
                               title.hjust = 0.5))

## centered title + caption
title <- ggplot(data.frame(x = 1:2, y = 1:10)) +
  labs(title = ""United States schools became more racially diverse over the last decades"",
       caption = ""Visualization by Cdric Scherer    Data by National Center for Education Statistics (NCES)"")

## full panel
map_hex_diversity + title + map_hex_change + plot_layout(nrow = 1, widths = c(1, 0.01, 1))

ggsave(here::here(""plots"", ""2019_39"", ""2019_39_SchoolDiversity_hex.pdf""), 
       width = 15, height = 6.5, device = cairo_pdf)
```

***
  
```{r}
sessionInfo()
```
","2019"
"174",438,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_40_Pizza.Rmd","---
title: ""TidyTuesday 2019/40 - Pizza Ratings by Jared Lander & Tyler Richards""
author: ""Cedric Scherer""
date: ""4th of October 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```

```{r prep, message=FALSE, warning=FALSE}
## packages
library(tidyverse)
library(ggtext)
library(extrafont)
library(emo)

extrafont::loadfonts(device = ""win"", quiet = TRUE)

theme_update(plot.title = element_text(size = 25))
```

```{r data}
df_pizza_jared <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_jared.csv"")
df_pizza_barstool <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_barstool.csv"")
#df_pizza_datafiniti <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_datafiniti.csv"")
```

```{r plot-jared, fig.width = 7, fig.height = 16}
df_pizza_jared %>% 
  filter(total_votes > 0) %>% 
  mutate(answer = case_when(
    answer == ""Never Again"" ~ 0, 
    answer == ""Poor"" ~ 1, 
    answer == ""Average"" ~ 2, 
    answer == ""Fair"" ~ 3, 
    answer == ""Good"" ~ 4, 
    answer == ""Excellent"" ~ 5
  ),
  score = answer * votes
  ) %>% 
  group_by(polla_qid) %>% 
  summarize(
    place = unique(place),
    score = sum(score),
    total_votes = unique(total_votes)
  ) %>% 
  group_by(place) %>% 
  summarize(eaten = sum(score) / sum(total_votes)) %>% 
  mutate(
    leftover = 5 - eaten,
    place = gsub('(.{1,15})(\\s|$)', '\\1\n', place),
    place = substr(place, 1, nchar(place) - 1)
  ) %>% 
  ungroup() %>% 
  mutate(place = fct_reorder(place, -eaten)) %>%
  gather(var, val, -place) %>% 
  ggplot(aes(x = 1, y = val)) + 
    geom_col(aes(fill = var), width = 1) + 
    coord_polar(theta = ""y"") + 
    facet_wrap(~ place, ncol = 5) +
    scale_fill_manual(values = c(""#dacab9"", ""#ffdb88""), guide = F) +
    theme_void() +
    labs(x = NULL, y = NULL, 
         title = paste(""<span style='font-size:21pt'>Where to Eat Pizza in NYC</span><span style='font-size:25pt'>"", emo::ji(""pizza""), ""</span><br><span style='font-size:12pt'>(Jared Edition)</span>""),
         subtitle = ""<span style='color:#848484'>Pizza ratings by Jared & friends at the R Meetups in New York City.</span><br><br>The <span style='color:#d3c0ac'>grey plates</span> indicate the average score of restaurants,<br>the <span style='color:#ffd574'>pizza leftovers</span> the difference from the highest score possible."",
         caption = ""\n\n\nVisualization by Cdric Scherer"") +
    theme(strip.text = element_text(family = ""Roboto Condensed"", 
                                    face = ""bold""),
          plot.title = element_markdown(family = ""Ultra"", 
                                        face = ""plain"",
                                        hjust = 0.5,
                                        margin = margin(b = 12)),
          plot.subtitle = element_markdown(family = ""Ultra"", 
                                           face = ""plain"",
                                           size = 9,
                                           color = ""grey80"",
                                           lineheight = 1.3,
                                           hjust = 0.5,
                                           margin = margin(b = 25)),
          plot.caption = element_text(family = ""Ultra"", 
                                      color = ""#d3c0ac"", 
                                      size = 7,
                                      hjust = 0.5),
          panel.spacing.x = unit(20, ""pt""),
          panel.spacing.y = unit(10, ""pt""),
          plot.margin = margin(30, 30, 30, 30))
  
ggsave(here::here(""plots"", ""2019_40"", ""2019_40_Pizza_jared.png""),
       width = 7, height = 16, dpi = 600)
```

```{r plot-barstool, fig.width = 9, fig.height = 50}
theme_update(plot.title = element_text(size = 30))

df_pizza_barstool %>% 
  filter(city == ""New York"") %>% 
  group_by(name) %>% 
  summarize(eaten = mean(review_stats_all_average_score)) %>% 
  mutate(
    leftover = 10 - eaten,
    name = gsub('(.{1,15})(\\s|$)', '\\1\n', name),
    name = substr(name, 1, nchar(name) - 1)
  ) %>% 
  ungroup() %>% 
  mutate(name = fct_reorder(name, -eaten)) %>%
  gather(var, val, -name) %>% 
  ggplot(aes(x = 1, y = val)) + 
    geom_col(aes(fill = var), width = 1) + 
    coord_polar(theta = ""y"") + 
    facet_wrap(~ name, ncol = 7) +
    scale_fill_manual(values = c(""#dacab9"", ""#ffdb88""), guide = F) +
    theme_void() +
    labs(x = NULL, y = NULL, 
         title = paste(""<span style='font-size:28pt'>Where to Eat Pizza in NYC</span><span style='font-size:25pt'>"", emo::ji(""pizza""), ""</span><br><span style='font-size:14pt'>(Barstool Sports Edition)</span>""),
         subtitle = ""<span style='color:#848484'>Average ratings on Barstool Sports for pizzerias in New York City.</span><br><br>The <span style='color:#d3c0ac'>grey plates</span> indicate the score of listed restaurants,<br>the <span style='color:#ffd574'>pizza leftovers</span> the difference from the highest score possible (10)."",
         caption = ""\n\nVisualization by Cdric Scherer"") +
    theme(strip.text = element_text(family = ""Roboto Condensed"", 
                                    face = ""bold""),
          plot.title = element_markdown(family = ""Ultra"", 
                                        face = ""plain"",
                                        hjust = 0.5,
                                        margin = margin(b = 12)),
          plot.subtitle = element_markdown(family = ""Ultra"", 
                                           face = ""plain"",
                                           size = 11,
                                           color = ""grey80"",
                                           lineheight = 1.3,
                                           hjust = 0.5,
                                           margin = margin(b = 25)),
          plot.caption = element_text(family = ""Ultra"", 
                                      color = ""#d3c0ac"", 
                                      size = 9,
                                      hjust = 0.5),
          panel.spacing.x = unit(20, ""pt""),
          panel.spacing.y = unit(10, ""pt""),
          plot.margin = margin(25, 30, 25, 30))

ggsave(here::here(""plots"", ""2019_40"", ""2019_40_Pizza_barstool.png""),
       width = 9, height = 50, dpi = 350, limitsize = F)
```

***
  
```{r}
sessionInfo()
```
","2019"
"175",439,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_42_BigCars.Rmd","---
title: ""TidyTuesday 2019/42 - Car Fuel Economy by EPA""
author: ""Cedric Scherer""
date: ""20th of October 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```

```{r prep, message=FALSE, warning=FALSE}
## packages
library(tidyverse)
library(gganimate)
library(ggimage)
library(emo)

## ggplot theme
source(here::here(""theme"", ""tidy_grey.R""))
```

```{r data}
df_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")
```

## Animation city mpg 

```{r animation-city, fig.width = 13, fig.height = 9.5}
## set seed for shuffling
set.seed(2019)

df_cars_top <- 
  df_cars %>%
  pivot_longer(cols = c(""city08"", ""cityA08""), 
               names_to = ""fuel"",
               values_to = ""mpg"") %>%
  filter(mpg > 0) %>%
  group_by(make) %>%
  summarize(median = median(mpg)) %>%
  ungroup()  %>% 
  arrange(-median) %>% 
  top_n(20, median) %>%
  mutate(
    make = fct_shuffle(make),
    make_id =  as.numeric(make),
    median_0 = 0,  
    ## determine status each 5 miles
    ## (otherwise speed would vary a lot between cars)
    median_5 = if_else(median > 5, 5, median),
    median_10 = if_else(median > 10, 10, median),
    median_15 = if_else(median > 15, 15, median),
    median_20 = if_else(median > 20, 20, median),
    median_25 = if_else(median > 25, 25, median),
    median_30 = if_else(median > 30, 30, median),
    median_35 = if_else(median > 35, 35, median),
    median_40 = if_else(median > 40, 40, median),
    median_45 = if_else(median > 45, 45, median),
    median_50 = if_else(median > 50, 50, median),
    median_55 = if_else(median > 55, 55, median),
    median_60 = if_else(median > 60, 60, median),
    median_65 = if_else(median > 65, 65, median),
    median_70 = if_else(median > 70, 70, median),
    median_75 = if_else(median > 75, 75, median),
    median_80 = if_else(median > 80, 80, median),
    median_85 = if_else(median > 85, 85, median),
    median_90 = if_else(median > 90, 90, median),
    median_95 = if_else(median > 95, 95, median)
  ) %>% 
  dplyr::select(-median) %>% 
  gather(state, median, -make, -make_id) %>% 
  mutate(state = as.numeric(str_sub(state, 8)))

car <- here::here(""img"", ""car.png"")

lines <-
  df_cars_top %>% 
  group_by(make_id) %>% 
  summarize(val = unique(make_id) + 0.5) %>% 
  add_row(make_id = 0, val = 0.5)

df_cars_anim <- 
  ggplot(df_cars_top, 
         aes(make_id, median, group = make_id)) +
    ## lower tire track
    geom_segment(aes(x = make_id - 0.15, xend = make_id - 0.15, 
                     y = 0, yend = median),
                 size = 1.7) +
    ## upper tire track
    geom_segment(aes(x = make_id + 0.15, xend = make_id + 0.15, 
                     y = 0, yend = median),
                 size = 1.7) +
    ## car
    geom_image(aes(make_id, median + 1.5, image = car), size = 0.05, asp = 0.7) +
    ## guard stripes 
    geom_vline(data = lines,
               aes(xintercept = val),
               color = ""white"",
               linetype = ""dashed"",
               size = 0.3) +
    ## labels manufacturer
    geom_text(aes(make_id, -16, label = make),
              color = ""grey80"",
              hjust = 0,
              family = ""Montserrat"",
              size = 5,
              fontface = ""bold"") +
    scale_x_continuous(expand = c(0.01, 0.01)) +
    scale_y_continuous(limits = c(-17, 102), 
                       expand = c(0.001, 0.001),
                       breaks = seq(0, 100, by = 10),
                       labels = c(""0 miles"", as.character(seq(10, 100, by = 10)))) + 
    coord_flip() + 
    theme_custom(base_family = ""Montserrat"") +
    theme(axis.ticks.x = element_blank(),
          axis.text.x = element_text(size = 16),
          axis.ticks.y = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(size = 32),
          plot.subtitle = element_text(size = 18,
                                       lineheight = 1.2),
          plot.caption = element_text(size = 16,
                                      color = ""grey80""),
          panel.border = element_blank(),
          panel.grid.major.x = element_line(color = ""grey10"", 
                                            size = 0.2),
          plot.margin = margin(12, 18, 12, 12)) +
      labs(x = NULL, y = NULL,
           title = ""How far can you go with 1 gallon of gas?"",
           subtitle = ""Top 20 most energy efficient brands in city driving. Estimates are based on median MPG and MPGe of all models since 1984.\n\n"",
           caption = ""\n\nVisualization by Cdric Scherer  |  Data: EPA  |  Icon: mynamepong via flaticon.com"") +
  transition_reveal(state)

animate(df_cars_anim, 
        nframes = 5 * n_distinct(df_cars_top$state), 
        width = 1300, height = 950, 
        fps = 10, detail = 5, 
        start_pause = 5, end_pause = 10,
        renderer = gifski_renderer(here::here(""plots"", ""2019_42"", 
                                              ""2019_42_BigCars_City.gif"")))
```

## Animation city mpg with varying speed

```{r with-varying-speed, fig.width = 13, fig.height = 9.5}
set.seed(2019)

df_cars_top <- 
  df_cars %>%
  pivot_longer(cols = c(""city08"", ""cityA08""), 
               names_to = ""fuel"", 
               values_to = ""mpg"") %>%
  filter(mpg > 0) %>%
  group_by(make) %>%
  summarize(median = median(mpg)) %>%
  ungroup()  %>% 
  arrange(-median) %>% 
  top_n(20, median) %>%
  mutate(
    make = fct_shuffle(make),
    make_id =  as.numeric(make),
    state = 1
  ) 

lines <-
  df_cars_top %>% 
  group_by(make_id) %>% 
  summarize(val = unique(make_id) + 0.5) %>% 
  add_row(make_id = 0, val = 0.5)

df_cars_anim <- 
  df_cars_top %>% 
  mutate(
    median = 0,
    state = 0
  ) %>% 
  bind_rows(df_cars_top) %>% 
  ggplot(aes(make_id, median, group = make_id)) +
    geom_segment(aes(x = make_id - 0.15, xend = make_id - 0.15, 
                     y = 0, yend = median),
                 size = 1.7) +
    geom_segment(aes(x = make_id + 0.15, xend = make_id + 0.15, 
                     y = 0, yend = median),
                 size = 1.7) +
    geom_image(aes(make_id, median + 1.5, image = car), size = 0.05, asp = 0.7) +
    geom_vline(data = lines,
               aes(xintercept = val),
               color = ""white"",
               linetype = ""dashed"",
               size = 0.3) +
    geom_text(aes(make_id, -16, label = make),
              color = ""grey80"",
              hjust = 0,
              family = ""Montserrat"",
              size = 5,
              fontface = ""bold"") +
    scale_x_continuous(expand = c(0.01, 0.01)) +
    scale_y_continuous(limits = c(-17, 102), 
                       expand = c(0.001, 0.001),
                       breaks = seq(0, 100, by = 10),
                       labels = c(""0 miles"", as.character(seq(10, 100, by = 10)))) + 
    coord_flip() + 
    theme_custom(base_family = ""Montserrat"") +
    theme(axis.ticks.x = element_blank(),
          axis.text.x = element_text(size = 16,
                                     vjust = 0),
          axis.ticks.y = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(size = 32),
          plot.subtitle = element_text(size = 18,
                                       lineheight = 1.2),
          plot.caption = element_text(size = 16,
                                      color = ""grey80""),
          panel.border = element_blank(),
          panel.grid.major.x = element_line(color = ""grey10"", 
                                            size = 0.2),
          plot.margin = margin(12, 18, 12, 12)) +
      labs(x = NULL, y = NULL,
           title = ""How far can you go with 1 gallon of gas?"",
           subtitle = ""Top 20 most energy efficient brands in city driving. Estimates are based on median MPG and MPGe of all models since 1984.\n\n"",
           caption = ""\n\nVisualization by Cdric Scherer  |  Data: EPA  |  Icon: mynamepong via flaticon.com"") +
  transition_reveal(state)

animate(df_cars_anim, 
        nframes = 50, 
        width = 1300, height = 950, 
        fps = 10, detail = 5, 
        start_pause = 5, end_pause = 10,
        renderer = gifski_renderer(here::here(""plots"", ""2019_42"", 
                                              ""2019_42_BigCars_City_vary.gif"")))
```

## Animation of highway mpg with race start sequence

```{r animation-highway}
set.seed(2019)

df_cars_top_high <- 
  df_cars %>%
  pivot_longer(cols = c(""highway08"", ""highwayA08""), 
               names_to = ""fuel"", 
               values_to = ""mpg"") %>%
  filter(mpg > 0) %>%
  group_by(make) %>%
  summarize(median = median(mpg)) %>%
  ungroup()  %>% 
  arrange(-median) %>% 
  top_n(20, median) %>%
  mutate(
    make = if_else(make == ""Panoz Auto-Development"", ""Panoz"", make),
    make = fct_shuffle(make),
    make_id =  as.numeric(make),
    median_0 = -3.7,  ## so that cars stand behind the line (but segments are not visible)
    median_97 = -3.7,  ## to avoid starting before starting sequence is over
    median_100 = if_else(median > 0, 0, median),  ## slowly going into position
    median_105 = if_else(median > 5, 5, median),  ## and going for the first 5 miles
    median_110 = if_else(median > 10, 10, median),
    median_115 = if_else(median > 15, 15, median),
    median_120 = if_else(median > 20, 20, median),
    median_125 = if_else(median > 25, 25, median),
    median_130 = if_else(median > 30, 30, median),
    median_135 = if_else(median > 35, 35, median),
    median_140 = if_else(median > 40, 40, median),
    median_145 = if_else(median > 45, 45, median),
    median_150 = if_else(median > 50, 50, median),
    median_155 = if_else(median > 55, 55, median),
    median_160 = if_else(median > 60, 60, median),
    median_165 = if_else(median > 65, 65, median),
    median_170 = if_else(median > 70, 70, median),
    median_175 = if_else(median > 75, 75, median),
    median_180 = if_else(median > 80, 80, median),
    median_185 = if_else(median > 85, 85, median),
    median_190 = if_else(median > 90, 90, median)
  ) %>% 
  dplyr::select(-median) %>% 
  gather(state, median, -make, -make_id) %>% 
  mutate(state = as.numeric(str_sub(state, 8)))

start <-
  tibble(
    state = c(0, 25, 50, 75, 103),
    label = c(""3"", ""2"", ""1"", ""START!"", """")
  )

car <- here::here(""img"", ""car.png"")

lines_high <-
  df_cars_top_high %>% 
  group_by(make_id) %>% 
  summarize(val = unique(make_id) + 0.5) %>% 
  add_row(make_id = 0, val = 0.5)

df_cars_anim_high <- 
  df_cars_top_high %>% 
  bind_rows(start) %>% 
  mutate(label = if_else(is.na(label), """", label)) %>% 
  ggplot(aes(make_id, median, group = make_id)) +
    annotate(""segment"", 
             x = -Inf, xend = Inf,
             y = 0, yend = 0,
             color = ""grey80"",
             size = 2) +
    geom_segment(aes(x = make_id - 0.15, xend = make_id - 0.15, 
                     y = -0.3, yend = median),
                 size = 1.7) +
    geom_segment(aes(x = make_id + 0.1, xend = make_id + 0.1, 
                     y = -0.3, yend = median),
                 size = 1.7) +
    geom_image(aes(make_id, median + 1.5, image = car), size = 0.05, asp = 0.7) +
    geom_vline(data = lines_high,
               aes(xintercept = val),
               color = ""white"",
               linetype = ""dashed"",
               size = 0.3) +
    geom_text(aes(make_id, -18, label = make),
              color = ""grey80"",
              hjust = 0,
              family = ""Montserrat"",
              size = 5,
              fontface = ""bold"") +
    geom_text(aes(13, 50, label = label),
              color = ""white"",
              hjust = 0.5,
              family = ""Racing Sans One"",
              size = 100,
              fontface = ""bold"") +
    scale_x_continuous(expand = c(0.01, 0.01)) +
    scale_y_continuous(limits = c(-19, 102), 
                       expand = c(0.001, 0.001),
                       breaks = seq(0, 100, by = 10),
                       labels = c(""0 miles"", as.character(seq(10, 100, by = 10)))) + 
    coord_flip() + 
    theme_custom(base_family = ""Montserrat"") +
    theme(axis.ticks.x = element_blank(),
          axis.text.x = element_text(size = 16),
          axis.ticks.y = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(size = 32),
          plot.subtitle = element_text(size = 18,
                                       lineheight = 1.2),
          plot.caption = element_text(size = 16,
                                      color = ""grey80"",
                                      family = ""Racing Sans One""),
          panel.border = element_blank(),
          panel.grid.major.x = element_line(color = ""grey10"", 
                                            size = 0.2),
          plot.margin = margin(12, 18, 12, 12)) +
      labs(x = NULL, y = NULL,
           title = ""How far can you go with 1 gallon of gas?"",
           subtitle = ""Top 20 most energy efficient brands in highway driving. Estimates are based on median MPG and MPGe of all models since 1984.\n\n"",
           caption = paste(
             ""\n\nVisualization by Cdric Scherer  "",
             emo::ji(""oncoming_automobile""), 
             ""  Data: EPA  "", 
             emo::ji(""fuelpump""), 
             ""  Icon: mynamepong via flaticon.com""
           )) +
  transition_reveal(state)

animate(df_cars_anim_high, width = 1300, height = 950, 
        nframes = 570, fps = 50, detail = 5, end_pause = 50,
        renderer = gifski_renderer(here::here(""plots"", ""2019_42"", 
                                              ""2019_42_BigCars_Highway.gif"")))
```

## Plot money savings

```{r, plot-savings, fig.width = 16, fig.height = 10}
set.seed(2019)

df_cars %>% 
  filter(highwayE > 0) %>% 
  group_by(make) %>% 
  summarize(avg = mean(youSaveSpend)) %>% 
  filter(avg > 0) %>% 
  ungroup() %>% 
  mutate(
    make = fct_reorder(make, avg),
    make_id =  as.numeric(make)
  ) %>% 
  ggplot(aes(make_id, avg, group = make_id)) +
    geom_segment(aes(x = make_id - 0.15, xend = make_id - 0.15, 
                     y = 0, yend = avg),
                 size = 1.7) +
    geom_segment(aes(x = make_id + 0.15, xend = make_id + 0.15, 
                     y = 0, yend = avg),
                 size = 1.7) +
    geom_image(aes(make_id, avg + 1.5, image = car), size = 0.05, asp = 0.7) +
    geom_text(aes(make_id, -50, label = make),
              color = ""grey80"",
              hjust = 1,
              family = ""Racing Sans One"",
              size = 6,
              fontface = ""plain"") +
    annotate(""segment"",
             x = -Inf, xend = Inf,
             y = 0, yend = 0,
             color = ""grey50"",
             size = 0.4) +
    scale_x_continuous(expand = c(0.02, 0.02)) +
    scale_y_continuous(limits = c(-800, 4900), 
                       expand = c(0.001, 0.001),
                       breaks = seq(0, 4700, by = 500),
                       labels = glue::glue(""{seq(0, 4500, by = 500)}$""),
                       position = ""right"") + 
    coord_flip() + 
    theme_custom(base_family = ""Montserrat"") +
    theme(axis.ticks.x = element_blank(),
          axis.text.x = element_text(size = 12),
          axis.ticks.y = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(size = 32),
          plot.subtitle = element_text(size = 15,
                                       lineheight = 1.2),
          plot.caption = element_text(size = 13, 
                                      family = ""Racing Sans One"",
                                      color = ""grey80""),
          panel.border = element_blank(),
          panel.grid.major.x = element_line(color = ""grey50"", 
                                            size = 0.2),
          plot.margin = margin(12, 18, 12, 12)) +
      labs(x = NULL, y = NULL,
           title = paste(
             ""How much money can you save with an electric car?"", 
             emo::ji(""money_with_wings"")
            ),
           subtitle = paste(
             ""Estimates are based on mean savings of cars that use electricity"", 
             emo::ji(""electric_plug""),
             ""compared to an average car "", 
             emo::ji(""fuelpump""),
             "" over a period of 5 years.\n""
           ),
           caption = paste(
             ""\nVisualization by Cdric Scherer "", 
             emo::ji(""electric_plug""), 
             "" Data: EPA  "", 
             emo::ji(""oncoming_automobile""), 
             ""  Icon: mynamepong via flaticon.com""
           ))

ggsave(here::here(""plots"", ""2019_42"", 
                  ""2019_42_BigCars_Savings.png""), 
       width = 16, height = 10, dpi = 300)
```

***
  
```{r}
sessionInfo()
```
","2019"
"176",440,"https://github.com/Z3tt/TidyTuesday","Z3tt","TidyTuesday","R/2019_44_Squirrels.Rmd","---
title: ""TidyTuesday 2019/44 - NYC Squirrels by NYC Squirrel Census""
author: ""Cedric Scherer""
date: ""30th of October 2019""
output:
  html_document:
  theme: paper
highlight: kate
editor_options:
  chunk_output_type: console
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F)
```

```{r prep, message=FALSE, warning=FALSE}
## packages
library(tidyverse)
library(sf)
library(ggtext)
library(ggpointdensity)
library(patchwork)

## ggplot theme
source(here::here(""theme"", ""tidy_grey.R""))

library(showtext)

font_add_google(""Alice"", ""Alice"")


theme_update(rect = element_rect(fill = ""#f2eadf""),
             axis.text = element_blank(),
             axis.title = element_blank(),
             axis.ticks = element_blank(),
             panel.border = element_rect(color = ""grey55"", 
                                         size = 2))
```

```{r data}
df_squirrels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

cp <- sf::read_sf(dsn = here::here(""data"", ""shp_CentralPark"", ""CentralPark.shp""), layer = ""CentralPark"")
```

```{r map-squirrel-density}
map_density <- 
  ggplot(df_squirrels) +
    geom_sf(data = cp, color = ""grey70"") +
    geom_point(aes(long, lat), size = 1.8, color = ""grey55"") +
    ggpointdensity::geom_pointdensity(aes(long, lat),
                                      adjust = 0.001,
                                      size = 1.2) +
    scale_x_continuous(limits = c(-73.982, -73.9495)) +
    scale_y_continuous(limits = c(40.7648, 40.8)) +
    rcartocolor::scale_color_carto_c(palette = ""Sunset"", 
                                     direction = -1,
                                     breaks = c(4, 44.5, 86),
                                     labels = c(""low"", ""**<span style='font-family:Cambria'>?  </span> Clustering of Sightings <span style='font-family:Cambria'>  ?</span>**"", ""high""),
                                     name = ""Squirrel Sightings\nin NYC's Central Park"",
                                     guide = guide_colorbar(direction = ""horizontal"",
                                                            barheight = unit(3, units = ""mm""), 
                                                            barwidth = unit(100, units = ""mm""),
                                                            draw.ulim = FALSE, 
                                                            ticks.colour = ""transparent"",
                                                            title.position = 'top',
                                                            title.hjust = 0.5, 
                                                            label.hjust = 0.5)) +
    
    annotate(""text"", x = -73.9625, y = 40.786, 
             label = ""Jacqueline Kennedy\nOnassis Reservoir"",
             family = ""Alice"", fontface = ""bold"", 
             color = ""#2e85b0"", size = 4.5) +  ## 580000 in combination with palette = ""Burg""
    labs(caption = ""  Visualization by Cdric Scherer  Data: NYC Squirrel Census  Map: OpenStreetMap"") +
    theme(legend.position = c(0.295, 0.9),
          legend.title = element_text(family = ""Alice"",
                                     size = 26,
                                     face = ""bold"",
                                     color = ""grey40"",
                                     lineheight = 1.025,
                                     margin = margin(b = 4)), 
          legend.text = element_markdown(family = ""Alice"",
                                     size = 15,
                                     color = ""grey40""),
          legend.background = element_rect(fill = ""#f2eadf"", 
                                           color = ""grey55"", 
                                           size = 1.2),
          legend.margin = margin(7, 9, 7, 9, ""mm""),
          plot.caption = element_text(family = ""Alice"", 
                                      color = ""grey40"", 
                                      hjust = 0),
          plot.margin = margin(12, 6, 12, 18),
          panel.background = element_rect(fill = ""grey90"", colour = NA))
```

```{r map-fur-color}
map_fur <- 
  df_squirrels %>% 
  filter(!is.na(primary_fur_color)) %>% 
  mutate(primary_fur_color = glue::glue(""{primary_fur_color} Squirrels"")) %>% 
  ggplot() +
    geom_sf(data = cp, color = ""grey70"", size = 0.3) +
    geom_point(aes(long, lat, 
                   fill = primary_fur_color,
                   alpha = primary_fur_color),
               shape = 21, color = ""grey20"", 
               size = 1.2, stroke = 0.2) +
    scale_x_continuous(limits = c(-73.982, -73.9495)) +
    scale_y_continuous(limits = c(40.7648, 40.8)) +
    scale_fill_manual(values = c(""black"", ""#d2691e"", ""grey60""),
                      guide = F) +
    scale_alpha_manual(values = c(0.4, 0.4, 0.2),
                      guide = F) +
    facet_grid(primary_fur_color~.) +
    theme(strip.background = element_rect(fill = ""transparent"",
                                          color = ""transparent""),
          strip.text.y = element_text(family = ""Alice"", 
                                      color = ""grey55"",
                                      size = 22,
                                      face = ""bold"",
                                      margin = margin(l = 15)),
          plot.margin = margin(12, 0, 12, 6),
          panel.background = element_rect(fill = ""grey90"", colour = NA),
          panel.spacing = unit(20, ""pt""))
```

```{r full-panel, fig.width = 13, fig.height = 12.8}
map_density + map_fur + plot_layout(widths = c(1, 0.4))

ggsave(here::here(""plots"", ""2019_44"", ""2019_44_Squirrels.pdf""), 
       width = 13, height = 12.8, device = cairo_pdf)
```

## Hex map

```{r hex-map, fig.width = 11.5, fig.height = 12}
img_a <- png::readPNG(here::here(""img"", ""compass.png"")) 
a <- grid::rasterGrob(img_a, interpolate = T) 

ggplot(df_squirrels) + 
  geom_hex(aes(long, lat, color = ..count..), size = 0.03) + 
  coord_fixed() + 
  scale_x_continuous(labels = scales::unit_format(accuracy = 0.01, sep = """", unit = ""W""), 
                     position = ""top"") + 
  scale_y_continuous(labels = scales::unit_format(accuracy = 0.01, sep = """", unit = ""N"")) +
  rcartocolor::scale_color_carto_c(palette = ""Sunset"", 
                                   name = ""Number of Squirrels Counted\nin NYC's Central Park"", 
                                   breaks = c(1,seq(5, 40, by = 5)),
                                   guide = guide_colorbar(barheight = unit(5, units = ""mm""), 
                                                          barwidth = unit(120, units = ""mm""),
                                                          direction = ""horizontal"",
                                                          title.position = ""top"",
                                                          title.hjust = 0.5)) +
  rcartocolor::scale_fill_carto_c(palette = ""Sunset"", guide = F) +
  annotate(""text"", x = -73.963, y = 40.786, 
             label = ""Jacqueline Kennedy\nOnassis Reservoir"",
             family = ""Alice"", fontface = ""bold"", 
             color = ""#2e85b0"", size = 4.5) +
  annotation_custom(a, xmin = -73.957, xmax = -73.953, ymin = 40.773, ymax = 40.777) +
  labs(x = NULL, y = NULL, caption = ""\nVisualization by Cdric Scherer  Data by NYC Squirrel Census"") + 
  theme_light() + 
  theme(axis.text = element_text(family = ""Roboto Mono"", size = 15, color = ""grey50""),
        panel.grid.minor = element_blank(), 
        plot.caption = element_text(family = ""Alice"", size = 13, color = ""grey50""),
        legend.position = c(0.28, 0.86), 
        legend.title = element_text(size = 25, family = ""Alice"", face = ""bold""), 
        legend.text = element_text(family = ""Alice"", size = 20, color = ""grey50""), 
        legend.background = element_rect(fill = NA))

ggsave(here::here(""plots"", ""2019_44"", ""2019_44_Squirrels_hex.pdf""), width = 11.5, height = 12, device = cairo_pdf)
```

***

```{r session-info}
sessionInfo()
```

","2019"
"177",524,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-07-09/network_squads.R","csmontt","tidy-tuesdays","2019-07-09/network_squads.R","########################################################################
## Project: Women's World Cup 2019 Network Visualization
## Script purpose: To explore how countries and teams are connected
## Date: 15-07-2019
## Author: csmontt
########################################################################

options(stringsAsFactors = FALSE)

library(tidyverse)
library(here)
library(rvest)
library(R.utils)
library(tidygraph) # tidy graph analysis
library(ggraph)    # for plotting


# Scrape data ------------------------------------------------------------------------

url <- ""https://es.wikipedia.org/wiki/Anexo:Equipos_participantes_en_la_Copa_Mundial_Femenina_de_F%C3%BAtbol_de_2019""

html_content <- url %>% 
  read_html()

# get clubs ----
clubs <- html_content %>%
                html_nodes(""td:nth-child(6) , .jquery-tablesorter .flagicon+ a"") %>%
                html_text() %>% gsub(""^\\s+|\\s+$"", """", .)



# Get country of clubs ----
flags <- html_content %>%
                html_nodes(""a img"") %>% html_attr(""alt"")

flags <- flags[c(-(length(flags)-1), -length(flags))]

flags <- flags[-grep(""Capitn"", flags)]

inds <- grep(""equipo"", clubs)[1:3] #just the first three don't have flags

country_club <- insert(flags, inds, values=""?"")



# get countries ----
nationality <- html_content %>%
                html_nodes(""h2+ h3 , .plainrowheaders+ h3"") %>%
                html_text() %>% gsub(""^\\s+|\\s+$"", """", .) %>% gsub(""\\[editar\\]"", """", .)


nationality <- rep(nationality, each=23)



# combine all ----

df <- as.data.frame(cbind(nationality, clubs, country_club))

df <- df %>% group_by(nationality, clubs) %>% mutate(n_players = n()) # *5 so in visnetwork
                                                                    # the width is noticeable
                                                                    # in ggraph changes the legend
                                                                    # for visnetwork have
                                                                    # to call it width


# Vis --------------------------------------------------------------------------------
cuartos <- c(""Noruega"", ""Inglaterra"", ""Francia"", ""Estados Unidos"", ""Italia"", 
             ""Pases Bajos"", ""Suecia"", ""Alemania"")

df2 <- df[df$nationality %in% cuartos, ]


# there is some annoying character in netherlands name.
df2$nationality <- gsub(""P...es..ajos"", ""Pases Bajos"", df2$nationality)
df2$country_club <- gsub(""P...es..ajos"", ""Pases Bajos"", df2$country_club)


# Create graph -----
df_graph <- as_tbl_graph(df2, directed = FALSE) %>%
  mutate(n_rank_trv = node_rank_traveller(),
         neighbors = centrality_degree(),
         group = group_infomap(),
         center = node_is_center(),
         dist_to_center = node_distance_to(node_is_center()),
         keyplayer = node_is_keyplayer(k = 10)) %>%
  activate(edges) %>% 
  filter(!edge_is_multiple()) %>%
  mutate(centrality_e = centrality_edge_betweenness())



# create layout ----
layout <- create_layout(df_graph, 
                        layout = ""fr"")


# Add country of origin to layout, to colour the nodes by country
club_layout <- as.data.frame(layout$name)
names(club_layout) <- ""name""
df3 <- df2[, c(""clubs"", ""country_club"")]
df3 <- df3[!duplicated(df3), ]
club_layout2 <- left_join(club_layout, df3, by = c(""name"" = ""clubs""))
club_layout2$country_club <- ifelse(is.na(club_layout2$country_club), club_layout2$name, 
                               club_layout2$country_club)
layout$group <- club_layout2$country_club

# Create vis ----
ggraph(layout) + 
    geom_edge_density(aes(fill = n_players)) +
    geom_edge_link(aes(width = n_players), alpha = 0.2) + 
    geom_node_point(aes(color = factor(group)), size = 3) +
    geom_node_text(aes(label = name), size = 2, repel = TRUE) +
    theme_graph() +
    labs(title = ""Women's World Cup 2019: Where do players of each country play?"",
         subtitle = ""The connectiveness of quarter round finalists"",
         caption = ""Source: Wikipedia | Vis: @csmontt"") +
    scale_colour_discrete(name  =""Country"") #,
                          #labels = c(""Germany"", ""Spain"", ""United States"", 
                          #           ""France"", ""England"", ""Italy"", ""Norway"",
                          #           ""Netherlands"", ""Sweden""))
                                   

ggsave(here(""figures"", ""network_football_women.png""), width = 11, height = 6)


# option, use visNetwork
library(visNetwork)
df_graph %>% as.igraph() %>%
  visIgraph(idToLabel = TRUE) %>% # remove long url labels from underneath nodes
  visOptions(highlightNearest = TRUE) #%>%
  #visLegend()","2019"
"178",525,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/custom_theme.R","custom_theme <- function () 
{
    font <- ""Consolas""
    ggplot2::theme(plot.title = ggplot2::element_text(family = font, 
                         size = 10, face = ""bold"", color = ""#222222"", hjust = 0.5), 
                         plot.subtitle = ggplot2::element_text(family = font, 
                         size = 8, 
                         margin = ggplot2::margin(1, 0, -30, 0)), 
                   legend.position = c(0.50, 0.15), 
                   #legend.position = ""none"",
                   legend.text.align = 0, 
                   legend.title = ggplot2::element_blank(), 
                   legend.key = ggplot2::element_blank(), 
                   legend.key.size = unit(0.65,""line""),
                   legend.text = ggplot2::element_text(family = font, size = 6, 
                   color = ""black""), 
                   legend.direction = ""horizontal"",
                   axis.title = ggplot2::element_blank(), 
                   axis.text = ggplot2::element_text(family = font, size = 8, 
                   color = ""#222222""), 
                   axis.text.x = ggplot2::element_blank(), # , angle = 20
                   axis.text.y = ggplot2::element_blank(),
                   axis.ticks = ggplot2::element_blank(), 
                   axis.line = ggplot2::element_blank(), 
                   panel.grid.minor = ggplot2::element_blank(), 
                   # facet labels
                   #strip.background = element_rect(color=""transparent"", 
                   #                                fill=""transparent""),
                   #strip.text.x = element_text(size = 12, color = ""black"",
                   #                            family = font,
                   #                            face = ""bold""), #, face = ""bold.italic""
                   #horizontal line color
                   plot.caption=element_text(hjust=1,size=5, family = font),
        panel.grid.major.y = ggplot2::element_blank(), 
        panel.grid.major.x = ggplot2::element_blank(), 
        plot.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        panel.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        legend.background = element_rect(fill = ""#f5f5f2"", color = NA),
        strip.text = ggplot2::element_text(size = 10, hjust = 0)) 
}","2019"
"179",526,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/custom_theme2.R","custom_theme2 <- function () 
{
    font <- ""Consolas""
    ggplot2::theme(plot.title = ggplot2::element_text(family = font, 
                         size = 10, face = ""bold"", color = ""#222222"", hjust = 0.5), 
                         plot.subtitle = ggplot2::element_text(family = font, hjust = 0.5,
                         size = 8, 
                         margin = ggplot2::margin(1, 0, -30, 0)), 
                   legend.position = c(0.50, 0.17), 
                   #legend.position = ""none"",
                   legend.text.align = 0, 
                   legend.title = ggplot2::element_blank(), 
                   legend.key = ggplot2::element_blank(), 
                   legend.key.size = unit(0.65,""line""),
                   legend.text = ggplot2::element_text(family = font, size = 6, 
                   color = ""black""), 
                   legend.direction = ""horizontal"",
                   axis.title = ggplot2::element_blank(), 
                   axis.text = ggplot2::element_text(family = font, size = 8, 
                   color = ""#222222""), 
                   axis.text.x = ggplot2::element_text(vjust = 125, size = 5), # , angle = 20
                   axis.text.y = ggplot2::element_blank(),
                   axis.ticks = ggplot2::element_blank(), 
                   #axis.ticks.x = ggplot2::element_line(vjust = 135), 
                   axis.line = ggplot2::element_blank(), 
                   panel.grid.minor = ggplot2::element_blank(), 
                   # facet labels
                   #strip.background = element_rect(color=""transparent"", 
                   #                                fill=""transparent""),
                   #strip.text.x = element_text(size = 12, color = ""black"",
                   #                            family = font,
                   #                            face = ""bold""), #, face = ""bold.italic""
                   #horizontal line color
                   plot.caption=element_text(hjust=0.5,size=5, family = font),
        panel.grid.major.y = ggplot2::element_blank(), 
        panel.grid.major.x = ggplot2::element_blank(), 
        plot.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        panel.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        legend.background = element_rect(fill = ""#f5f5f2"", color = NA),
        strip.text = ggplot2::element_text(size = 10, hjust = 0)) 
}","2019"
"180",527,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/emperor_death_scarf.R","
library(tidyverse)
library(lubridate)
library(here)
library(extrafont)

loadfonts(device=""win"")
font <- ""Consolas""


source(here(""2019-08-13"", ""custom_theme.R""))

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

emperors$reign_start[1] <- lubridate::ymd(""0026/01/16"") - lubridate::years(52)
emperors$years_rule <- emperors$reign_end - emperors$reign_start
emperors$nothing <- ""nothing""
emperors2 <- emperors %>% filter(cause != ""Unknown"")


p <- ggplot(emperors2, aes(x = 1:nrow(emperors2), y=nothing,
                           fill=cause)) +
  geom_tile(color=""#f5f5f2"", height=0.35) +
        custom_theme() + guides(fill = guide_legend(nrow = 1)) +
        scale_fill_brewer(palette=""Set3"") +
        scale_x_continuous(expand = c(0,0)) +
        labs(title = ""\n\n\n\n\n\n\n\n\n\n\nHow Roman Emperors Died"",
        subtitle = ""                                                                       one tile one emperor"",
        caption = ""Data: Wikipedia via @geokaramanis | Vis: @Cristobal_Montt"") 
p  

p2 <- p + geom_segment(aes(x = 0.5, y = 0.81, xend = 0.5, yend = 1.2),linetype = ""dotted"") + 
#annotate(""rect"", linetype = ""dotted"", xmin = 0.47, xmax = 0.48, ymin = 0.81, ymax = 1.2, color = ""black"") +
    #annotate(""rect"", linetype = ""dotted"", xmin = 5.5, xmax = 5.51, ymin = 0.81, ymax = 1.2, color = ""black"") +
    geom_segment(aes(x = 5.52, y = 0.81, xend = 5.52, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 11.51, y = 0.81, xend = 11.51, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 18.50, y = 0.81, xend = 18.50, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 26.51, y = 0.81, xend = 26.51, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 46.5, y = 0.81, xend = 46.5, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 60.5, y = 0.81, xend = 60.5, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 64.52, y = 0.81, xend = 64.52, yend = 1.2),linetype = ""dotted"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 11.5, xmax = 11.51, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 18.48, xmax = 18.49, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 26.49, xmax = 26.5, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 46.5, xmax = 46.51, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 60.48, xmax = 60.49, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 64.49, xmax = 64.5, ymin = 0.81, ymax = 1.2, color = ""black"") + 
    annotate(""text"", x = 2.98, y = 1.23, label = ""Julio-Claudian"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 8.4, y = 1.23, label = ""Flavian"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 15, y = 1.23, label = ""Nerva-Antonine"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 22.3, y = 1.23, label = ""Severan"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 36, y = 1.23, label = ""Gordian"", 
             color = ""black"", size = 2.23, family = font) + 
    annotate(""text"", x = 53.5, y = 1.23, label = ""Constantinian"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 62.5, y = 1.23, label = ""Valentinian"", 
             color = ""black"", size = 2.23, family = font)
   
ggsave(here(""figures"", ""2019-08-13.png""), plot = p, width = 10, height = 6)  
ggsave(here(""figures"", ""2019-08-13b.png""), plot = p2, width = 10, height = 6)  

# other plots ----------------------------------------------------------------------------
# need to change the theme so the axis are visible
new_dest <- paste0(emperors$name, "" ("", emperors$reign_start, "")"")
emperors$names_ordered <- reorder(emperors$name, emperors$reign_start)

ggplot(emperors, aes(x = reign_start, y=names_ordered,  fill=cause)) +
  geom_tile(color=""#f5f5f2"", width=emperors$years_rule, height=1) +
        custom_theme()

ggplot(emperors, aes(x = reign_start, y=nothing,  fill=cause)) +
  geom_tile(color=""#f5f5f2"", width=emperors$years_rule*1.3, height=1) +
        custom_theme()
","2019"
"181",528,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/emperor_death_scarf_days.R","library(tidyverse)
library(lubridate)
library(here)
library(extrafont)

loadfonts(device=""win"")
font <- ""Consolas""


source(here(""2019-08-13"", ""custom_theme2.R""))

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

emperors$reign_start[1] <- lubridate::ymd(""0026/01/16"") - lubridate::years(52)
emperors$years_rule <- as.numeric(emperors$reign_end - emperors$reign_start)


emperors$gp <- seq(from = nrow(emperors), to = 1)
p3 <- ggplot(emperors, aes(x=""thing"", y=years_rule, fill=cause, group=factor(gp))) + 
       geom_bar(stat=""identity"", colour=""#f5f5f2"", width = 0.3, size = 0.001)  +
       scale_fill_brewer(palette=""Set3"") +
       guides(fill = guide_legend(nrow = 1)) +
       labs(title = ""\n\n\n\n\n\n\n\n\nHow Roman Emperors Died"",
       subtitle = ""one tile one emperor"",
       caption = ""Data: Wikipedia via @geokaramanis | Vis: @Cristobal_Montt"") +
       scale_y_continuous(breaks = c(0, 50000, 150000, 200000)) +
       coord_flip() +
       custom_theme2() +
       annotate(""text"", x = 0.831, y = 100000, label = ""Days since the beginning of the Roman Empire"", 
             color = ""black"", size = 1.8, family = font)
p3

ggsave(here(""figures"", ""2019-08-13c.png""), plot = p3, width = 10, height = 6)  
","2019"
"182",529,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-06-18/birds-time-series.R","csmontt","tidy-tuesdays","2019-06-18/birds-time-series.R","########################################################################
## Project: Tidytuesday 2019-06-18
## Script purpose: Create an animated time series of bird counts per hour
## over the last 60 years
##
## Date: 2019-06-18
## Author: csmontt
########################################################################
options(scipen = 999)

library(tidyverse)
library(plotly)
library(animation)
library(RColorBrewer)
library(here)

source(here(""2019-06-18"", ""theme_custom.R""))

# idea from 
# https://towardsdatascience.com/animating-your-data-visualizations-like-a-boss-using-r-f94ae20843e3
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")


# consider years where there is no missing data
nas_year <-  bird_counts %>% group_by(year) %>% 
        summarize(total_nas = sum(is.na(how_many_counted_by_hour)))

# get the latest interval of years without missing values 
# It gives back the row index of the last year with missing data
nas_year$missing <- nas_year$total_nas > 0
last_ind_missing = NA
for(i in 1:nrow(nas_year)){
        if (nas_year$missing[i] == TRUE){
                last_ind_missing <- i
        } 
}

nas_year <- nas_year[last_ind_missing + 1:nrow(nas_year), ]

# Im keeping only the interval of years without missing data (every year since
# 1950)
bird_counts <- bird_counts %>% filter(bird_counts$year %in% nas_year$year)

# keep the three most observed species over time, otherwise plot gets too 
# clutter
most_observed <- bird_counts %>% group_by(species) %>% 
        summarize(total_obs  = sum(how_many_counted)) %>%
        arrange(desc(total_obs)) %>% head(3)

most_obs_species <- most_observed$species


bird_filtered <- bird_counts %>% 
        filter(species %in% most_obs_species) %>%
        select(year, species, how_many_counted_by_hour)

# convert species to factor
bird_filtered$species<-as.factor(bird_filtered$species)


# animation --------------------------------------------------------------------
# set some of the options 
ani.options(interval = 0.2, 
            nmax = 100, ani.width = 800)

## The good animation as a simple GIF
saveGIF({
  end_year = 2017 #last year of the plot
  num_years = length(unique(bird_filtered$year)) #number of years in the animation
  #create a loop that does the subsetting
  for(i in 1:num_years){
    bird_subset <- bird_filtered %>% filter(year <= end_year-(num_years-i))
    #write the plot with a subset
    p<-ggplot(bird_subset,aes(x=year,y=how_many_counted_by_hour,
                                group=species,colour=species)) +
      geom_line(size = 1.5) +
      scale_x_continuous(breaks=c(1950, 1960, 1970, 1980, 1990, 2000, 2017)) +
      ylim(0,440)+
      xlab('') +
      ylab('') +
      scale_colour_brewer(palette=""Dark2"") +
      theme_custom() +
      labs(title=""Birds count per hour"", caption=""Data: www.birdscanada.org | Vis: @cristobal_montt"") +
      guides(fill=guide_legend(title=""Species""))
      print(p)
  }#close the for loop
  
}, movie.name = here(""figures"", ""2019-06-18.gif"")) #close the animation builder





","2019"
"183",530,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-07-02/box_plot_media_franchise.R","csmontt","tidy-tuesdays","2019-07-02/box_plot_media_franchise.R","########################################################################
## Project: tidytuesdays
## Script purpose: a simple annotated boxplot
##
##
## Date: 02-07-2019
## Author: csmontt
########################################################################
library(devtools)
library(extrafont)
library(here)
loadfonts(device = ""win"")
library(tidyverse)

source(here(""2019-07-02"", ""custom_theme.R""))

# load data --------------------------------------------------------------------------                     
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

# delete duplicates
media_franchises <- media_franchises[!duplicated(media_franchises), ]

# get most succesful media franchise by cateory
max_revenue <-  media_franchises %>% group_by(revenue_category) %>% 
        slice(which.max(revenue)) %>% tidyr::unnest()

# create plot
ggplot(media_franchises, 
              aes(x = factor(revenue_category), y = revenue, fill = revenue_category)) + 
        geom_boxplot() + custom_theme() +
        geom_text(data = max_revenue, 
              aes(x = factor(revenue_category), y = revenue, label = franchise, 
                  family = ""Century Gothic""), 
              nudge_x = 0, nudge_y = 2, size = 2) +
        labs(title=""Most succesful media franchises"",
             subtitle = ""Revenue in billions by media category"",
             caption = ""Source: Wikipedia | Vis: @csmontt"") +
        guides(fill=guide_legend(nrow=1))

# save plot
ggsave(here(""figures"", ""media_franchise_boxplot.png""), width = 11, height = 6)





                ","2019"
"184",531,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-07-16/streamgrapgh_R_slack.R","csmontt","tidy-tuesdays","2019-07-16/streamgrapgh_R_slack.R","library(tidyverse)
library(streamgraph)

# read the data ----

r4ds_members <-
        readr::read_csv(
                ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv""
        )

inds <- grep(""messages_in"", names(r4ds_members))
r4ds_members <- r4ds_members[, c(inds, 1)]

names(r4ds_members) <-
        c(
                'Messages in public channels',
                'Messages in private channels',
                'Messages in shared channels',
                'messages in Direct Messages',
                'date'
        )

# wide to long ----

r4ds_long <- gather(
        r4ds_members,
        message_type,
        total,
        'Messages in public channels':'messages in Direct Messages',
        factor_key = TRUE
)


# Create streamgraph ----
r4ds_long %>%
        group_by(date, message_type) %>%
        tally(wt = total) %>%
        streamgraph(""message_type"", ""n"", ""date"") %>%
        sg_axis_x(1, ""month"", ""%b/%Y"")







        
        
        ","2019"
"185",532,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-06-10/gganimate_meteorites.R","csmontt","tidy-tuesdays","2019-06-10/gganimate_meteorites.R","########################################################################
## Project: Tidy Tuesday 2019-10-04
## Script purpose: Use gganimate package to create an animate vis
## of meteorite collisions over time
##
## Date: 2019-06-10
## Author: csmontt
########################################################################

library(ggplot2)
library(ggthemes)
library(gganimate)


# Get base map
world <- ggplot() +
  borders(""world"", colour = ""#353535"", fill = ""#353535"") +
  theme_map()

# Read data
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

meteorites <- meteorites[!is.na(meteorites$lat) & !is.na(meteorites$year), ]

# Took the log of mass and divided it by 5, so when using this new 
# variable to size the geom_points in ggplot they didn't get too big.
meteorites <- meteorites %>% mutate(log_mass = log(mass)/5) %>%
        filter(year >= 1800 & year <= 20013)


# Specifiy vis
met_map <- world + geom_point(data = meteorites, 
               x = meteorites$long,
               y = meteorites$lat,
               color = ""#ffa500"",
               alpha = 0.7,
               size = meteorites$log_mass) + 
           transition_states(meteorites$year, 
                          transition_length = 1, 
                          state_length = 1) +
           shadow_mark(past=TRUE) +
           theme(plot.title = element_text(color = ""white"", 
                                           size = 20, 
                                           face = ""bold"",
                                           vjust = -10),
                 panel.background = element_rect(fill = ""#35535F"")) +
           labs(title = ""{closest_state}"")

options(gganimate.dev_args = list(width = 1000, height = 600))
ani_met <- animate(met_map, nframes = 300, fps=10, detail = 1)

# Save GIF
anim_save(""./figures/2019-06-10.gif"")

# To do:
# Should have specified more frames as 300 were not enough to show all 
# years with data.
# Add a lbel for the mass of the meteorites, maybe create categories instead
# of using a continous variable.
# add mapping by color to denote type of meteorite.

","2019"
"186",533,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_2019_week_6","Cyranka","rviz","tidy_tuesday_2019_week_6/tidy_tuesday_2019_week_6.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/francisco06121988/Desktop/rviz/tidy_tuesday_2019_week_6/"")
library(tidyverse)

x <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")


##
us_track <- x %>% group_by(year,state) %>%
  summarise(state_median = median(price_index),
            us_median = median(us_avg)) %>%
  select(year, us_median) %>% unique()

###


###
top_label <- x %>% group_by(year,state) %>%
  summarise(state_median = median(price_index),
            us_median = median(us_avg)) %>%
  ungroup() %>% filter(year == max(year)) %>%
  top_n(5, state_median)


down_label <- x %>% group_by(year,state) %>%
  summarise(state_median = median(price_index),
            us_median = median(us_avg)) %>%
  ungroup() %>% filter(year == max(year)) %>%
  top_n(-5, state_median)


##
x %>% group_by(year,state) %>%
  summarise(state_median = median(price_index),
            us_median = median(us_avg)) %>%
  ungroup() %>%
  ggplot(aes(x = year, y = state_median, group = state)) + 
  geom_line(size = 2, alpha = 0.2) + 
  geom_line(data = us_track,aes(x = year, y = us_median),
            inherit.aes = FALSE, size = 3, color = ""firebrick2"", alpha = 0.9) + 
  hrbrthemes::theme_modern_rc(axis_title_size = 13) + 
  theme(
    panel.grid.minor = element_blank()
  ) + 
  scale_x_continuous(breaks = c(seq(1975, 2015, by = 5), 2018)) + 
  labs(x = ""Year"",
       y = ""Median Price Index"",
       title = ""Changes in State Price Index"",
       subtitle = ""Data aggregated by year. Red line represents the US average\nState labels shown represent top and bottom 5"",
       caption = ""Tidy Tuesday 2019 - Week 6"") + 
  ggrepel::geom_text_repel(data = subset(top_label,year == max(year)),
                           mapping = aes(x = year, y = state_median, label = state),
                           size =3, segment.color = ""black"",color = ""white"", fontface = ""bold"") + 
  ggrepel::geom_text_repel(data = subset(down_label,year == max(year)),
                           mapping = aes(x = year, y = state_median, label = state),
                           size =3,segment.size = 0,segment.color = ""black"",color = ""white"", fontface = ""bold"") 
  
  


","2019"
"187",564,"https://github.com/JulianCollins/TidyTuesday","JulianCollins","TidyTuesday","tt_2019_w27/tidy_tuesday_2019_w27.R","## 2019-07-02 - Week 27 - Media Franchises 

library(tidyverse)

# load data
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

# create decade variable
media_franchises <- media_franchises %>% mutate(decade = paste0(year_created - year_created %% 10, ""s""))

# create time since created variable
media_franchises <- media_franchises %>% mutate(years_since_created = 2018 - year_created)

# create total revenue per franchise
media_franchises <- media_franchises %>% group_by(franchise) %>% mutate(revenue_total = sum(revenue))

# create revenue per year variable
media_franchises <- media_franchises %>% mutate(annualised_revenue = revenue_total / years_since_created)

media_franchises %>% arrange(desc(annualised_revenue)) %>% View()

# manual colour palette
  cols3 <- c(""1960s"" = ""#C06962"", ""1970s"" = ""#BADA96"", ""1980s"" = ""#EDA115"", ""1990s"" = ""#A283A0"", ""2000s"" = ""#F8F2B3"", ""2010s"" = ""#F1C8A9"")

# lollipop chart - annualised revenue
media_franchises %>% filter(annualised_revenue > 1) %>%  
  ggplot(., aes(fct_reorder(franchise, annualised_revenue), annualised_revenue)) +
  geom_point(size = 5, colour = ""black"") +
  geom_point(aes(colour = decade), size = 4) +
  geom_segment(aes(x = franchise, xend = franchise, 
                   y = 0, yend = annualised_revenue), 
               linetype=""dashed"", 
               size=0.3,
               colour = ""grey40"") +  
  scale_colour_manual(values = cols3, name = ""Decade of release"") +
  scale_y_continuous(labels = scales::dollar_format(prefix=""$"", suffix = ""bn""), breaks = seq(1:5)) +
  coord_flip() +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank()) +
  theme(legend.position = ""bottom"") +
  theme(legend.text = element_text(size = 12)) +
  labs(title = ""Annualised revenue earned by media franchises"", subtitle = ""franchises with > $1bn annualised income"", x = """") +
  ylab(""\nTotal annualised revenue, US$bn\n"") +
  theme(plot.title = element_text(size = 18), plot.subtitle = element_text(size = 14), axis.title.x = element_text(size = 14), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 12)) +
  theme(plot.background = element_rect(fill = ""#FFFBF9""))
ggsave(""tt2019_w27.png"", width = 24, height = 20, units = ""cm"", dpi = 150)





########## rejeced charts - grouping without franchise doesn't really make sense #########

# manual colour palette 
cols <- c(""Book sales"" = ""#47761E"", ""Box Office"" = ""#FED985"", ""Home Video/Entertainment"" = ""#F09E71"", ""TV"" = ""#61B5CB"", 
          ""Video Games/Games"" = ""#93B592"", ""Merchandise, Licensing & Retail"" =  ""#D5A0C4"", ""Music"" = ""#C4EB98"", ""Comic or Manga"" = ""#449FAF"")


# bar chart                                            
media_franchises %>% group_by(decade, revenue_category) %>% summarise(totrev = sum(revenue)) %>% 
  ggplot(., aes(revenue_category, totrev, fill = revenue_category)) +
  geom_col() +
  scale_fill_manual(values = cols) +
  scale_y_continuous(labels = scales::dollar_format(prefix=""$"", suffix = ""m"")) +
  coord_flip() +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank()) +
  theme(legend.position = ""bottom"", legend.title = element_blank()) +
  facet_wrap(~ decade, ncol = 2) +
  theme(strip.text = element_text(size = 12, face = ""bold"")) +
  labs(title = ""Total revenue earned by media franchises, by decade and revenue category"", x = """") +
  ylab(""\nTotal revenue, US$m\n"") +
  theme(plot.title = element_text(size = 18), axis.title.y = element_text(size = 14), axis.text.x = element_text(size = 12)) +
  theme(panel.background = element_rect(fill = ""#FCFBF7""))
        

# manual colour palette v2
cols2 <- c(""Other"" = ""#DE9DC8"", ""Box Office"" = ""#444EC1"", ""Home Video/Entertainment"" = ""#DD005D"", 
          ""Video Games/Games"" = ""#090088"", ""Merchandise, Licensing & Retail"" =  ""#9A0078"")

# lollipop chart
media_franchises %>% mutate(rev_cat = fct_lump(revenue_category, 4)) %>% group_by(decade, rev_cat) %>% summarise(totrev = sum(revenue)) %>% 
  ggplot(., aes(rev_cat, totrev)) +
  geom_point(aes(colour = rev_cat), size = 3.5) +
  geom_segment(aes(x = rev_cat, xend = rev_cat, 
                   y = 0, yend = totrev), 
                   linetype=""dashed"", 
                   size=0.5,
                   colour = ""grey40"") +  
  scale_colour_manual(values = cols2) +
  scale_y_continuous(labels = scales::dollar_format(prefix=""$"", suffix = ""bn"")) +
  coord_flip() +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank()) +
  theme(legend.position = ""bottom"", legend.title = element_blank()) +
  theme(legend.text = element_text(size = 12)) +
  facet_wrap(~ decade, ncol = 2) +
  theme(strip.text = element_text(size = 12, face = ""bold"")) +
  labs(title = ""Total revenue earned by media franchises, by decade and revenue category"", x = """") +
  ylab(""\nTotal revenue, US$bn\n"") +
  theme(plot.title = element_text(size = 18), axis.title.x = element_text(size = 14), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 12)) +
  theme(panel.background = element_rect(fill = ""#FCFBF7""))
","2019"
"188",565,"https://github.com/JulianCollins/TidyTuesday","JulianCollins","TidyTuesday","tt_2019_w33/tidy_tuesday_2019_w33.R","library(tidyverse)
library(lubridate)
devtools::install_github(""liamgilbey/ggwaffle"")
library(ggwaffle)
library(patchwork)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

emperors <- emperors %>% mutate(reign_length = interval(reign_start, reign_end) / years(1))

# manual correction to deal with Augustus' BCE reign_start
#emperors[1,17] <- 40.83

#emperors$dynasty <- factor(emperors$dynasty, levels = c(""Julio-Claudian"", ""Flavian"", ""Nerva-Antonine"", ""Severan"", ""Gordian"", ""Constantinian"", ""Valentinian"", ""Theodosian""), ordered = T)

emperors <- emperors %>% mutate(C = if_else(year(death) < 0100, ""1st Century AD"", if_else(year(death) >= 0100 & year(death) < 0200, ""2nd Century AD"", if_else(year(death) >= 0200, ""3rd Century AD"", NA_character_)))) 

waffle_C1 <- emperors %>% filter(C == ""1st Century AD"") %>% waffle_iron(aes_d(group = cause))
waffle_C2 <- emperors %>% filter(C == ""2nd Century AD"") %>% waffle_iron(aes_d(group = cause))
waffle_C3 <- emperors %>% filter(C == ""3rd Century AD"") %>% waffle_iron(aes_d(group = cause))

p1 <- ggplot(waffle_C1, aes(x, y, fill = group)) + 
  geom_waffle() + 
  coord_equal() + 
  scale_fill_viridis_d(option = ""B"", alpha = 0.8) + 
  theme_waffle() +
  theme(legend.position = ""none"") +
  labs(title = """", x = """", y = ""1st Century"") +
  theme(axis.title.y = element_text(size = 18, family = ""serif""))

p2 <- ggplot(waffle_C2, aes(x, y, fill = group)) + 
  geom_waffle() + 
  coord_equal() + 
  scale_fill_viridis_d(option = ""B"", alpha = 0.8) + 
  theme_waffle() +
  theme(legend.position = ""none"") +
  labs(title = """", x = """", y = ""2nd Century"") +
  theme(axis.title.y = element_text(size = 18, family = ""serif""))

p3 <- ggplot(waffle_C3, aes(x, y, fill = group)) + 
  geom_waffle() + 
  coord_equal() + 
  scale_fill_viridis_d(option = ""B"", alpha = 0.8) + 
  theme_waffle() +
  theme(legend.title = element_blank()) +
  labs(title = """", x = """", y = ""3rd Century"") +
  theme(axis.title.y = element_text(size = 18, family = ""serif"")) +
  theme(legend.text = element_text(family = ""serif"", size = 16)) +
  theme(legend.margin = margin(0, 0.1, 0.1, 0, ""cm""))


  p1 + p2 + p3 + 
  plot_layout(ncol = 3, widths = c(1,1,3), heights = c(1,1,1)) + 
  plot_annotation(title = ""\""Not that I loved Caesar less, but that I loved Rome more\"""",
                  subtitle = ""  Roman Emperors, cause of death by century"",
                  theme = theme(
                                plot.title = element_text(size = 32, family = ""serif"", face = ""italic""),
                                plot.subtitle = element_text(size = 24, family = ""serif"")
                                )
                  )
","2019"
"189",690,"https://github.com/jthomasmock/tidytuesday_projects/blob/master/2019/2019-02-09/tennis_grandslams.R","jthomasmock","tidytuesday_projects","2019/2019-02-09/tennis_grandslams.R","library(tidyverse)

# read in data
player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")
grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")
grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

# get age
age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>%
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age, gender) %>%
  summarize(counts = n()) %>%
  group_by(name) %>%
  mutate(total_wins = cumsum(counts)) %>%
  arrange(desc(total_wins)) %>%
  ungroup() %>%
  mutate(age = age / 365)

# find top 5 players
top_players <- age_slams_comb %>%
  group_by(name) %>%
  top_n(1, total_wins) %>%
  ungroup() %>%
  top_n(5, total_wins) %>%
  pull(name)

# create plot dataframe
plot_data <- age_slams_comb %>%
  ungroup() %>%
  mutate(
    colour = case_when(
      name == ""Serena Williams"" ~ ""#003399"",
      name == ""Steffi Graf"" ~ ""#FF2B4F"",
      name == ""Roger Federer"" ~ ""#fcab27"",
      name == ""Chris Evert"" ~ ""#3686d3"",
      name == ""Martina Navratilova"" ~ ""#88398a"",
      T ~ ""gray80""),
    name = fct_reorder(name, total_wins)
    ) %>%
  mutate(hj = if_else(name == ""Chris Evert"", 1, 0))

# plot - a lot of borrowing from John Burn-Murdoch
# https://gist.github.com/johnburnmurdoch/bd20db77b2582031604ccd1bdc4be582

(plot_slams <- ggplot(
  plot_data,
  aes(age, total_wins,
    group = name, col = colour, fill = colour,
    alpha = name %in% top_players)) +
  theme_minimal() +
  geom_step(aes(size = name %in% top_players)) +
  geom_point(data = . %>%
    group_by(name) %>%
    top_n(1, total_wins), shape = 21, aes(col = colour), size = 2.5, stroke = 1) +
  geom_text(
    data = . %>%
      group_by(name) %>%
      top_n(1, total_wins) %>%
      filter(name %in% top_players) %>%
      mutate(
        first_initial = str_sub(name, 1, 1),
        last_name = gsub("".+\\s"", """", name),
        short_name_wins = paste0(""  "", first_initial, "". "", last_name, "":"", total_wins, ""  "")),
    aes(label = short_name_wins, hjust = hj), family = ""Roboto Mono Medium"") +
  scale_color_identity() +
  scale_fill_identity() +
  scale_alpha_manual(values = c(0.7, 1), guide = F) +
  scale_size_manual(values = c(0.5, 0.8), guide = F) +
  scale_x_continuous(limits = c(15, 40), breaks = seq(15, 35, 5), expand = c(0, 0)) +
  scale_y_continuous(position = ""right"", expand = expand_scale(add = c(0, 5))) +
  tomtom::theme_tom() +
  theme(
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = ""gray85"", size = 0.3),
    axis.ticks.y = element_blank(),
    axis.ticks.x = element_line(color = ""#212121"", size = 0.3),
    axis.ticks.length = unit(0.2, ""cm""),
    axis.line.x = element_line(size = 0.3, color = ""#212121""),
    axis.text.y.right = element_text(hjust = 1),
    axis.title.y = element_blank(),
    plot.caption = element_text(hjust = 0, face = ""bold""),
    text = element_text(family = ""Roboto Mono"")) +
  labs(
    x = ""\nAge"",
    y = """",
    title = ""Serena owns the most Grand Slam wins, but was less efficient than Graf"",
    subtitle = ""Cumulative Open Era Grand Slams won, by age"",
    caption = ""\nSource: Wikipedia | Graphic: Thomas Mock / @thomas_mock"")
  )

ggsave(""top_slams.png"", width = 14, height = 8, units = ""in"")

colorblindr::cvd_grid(plot_slams)
","2019"
"190",740,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/roman_emperors.R","JonathonMifsud","tidytuesday","2019/code/roman_emperors.R","# Roman Emperors TidyTuesday
# 13/08/19


library(tidyverse)
library(lubridate)
library(scales)
library(ggraph)
library(igraph)
library(viridis)
library(treemap)
library(data.tree)  

# Data
emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# Cleaning
circle_data <- emperors %>% 
  select(name, cause, reign_start, reign_end, dynasty) %>%
  mutate(span = interval(ymd(reign_start), ymd(reign_end))) %>% 
  mutate(spandays = abs(span %/% days(1))) %>%
  mutate(spanmonths = round(spandays / 30)) %>% # length of reign in days
  mutate(spanyears = round(spanmonths / 12) + 1) %>% # length of reign in months
  select(-reign_start, -reign_end)

# Here I transform the dataframe into a hierarchical structure which is used for circle stacking plots. I was planning to have 3 levels of depth:
# 1. Cause of death 2. Dynasty and 3. Emperor Name and use the length of reign to size the circle but I ran out of time to do so. 

circle_data$pathString <- paste(""start"", 
                            circle_data$cause, 
                            circle_data$name,
                            sep = ""/"")
hier_emperors <- as.Node(circle_data, mode = ""table"")
hier_clone <- Clone(hier_emperors)
hier_network <- ToDataFrameNetwork(hier_clone, ""spandays"", ""spanmonths"", ""spanyears"") #spandays etc is added to the network
mygraph <- graph_from_data_frame(hier_network)

set.seed(123)
gg <- ggraph(mygraph, layout = 'circlepack') + 
  geom_node_circle(aes(fill = as.factor(depth), color = as.factor(depth))) +
  scale_fill_manual(values=c(""0"" = ""white"", ""1"" = viridis(4)[3], ""2"" = viridis(4)[4])) +
  scale_color_manual( values=c(""0"" = ""white"", ""1"" = ""black"", ""2"" = ""black"", ""3"" = ""black"", ""4""=""black"") ) +
  annotate(""text"", x = -6,9, y = 5.4, fontface = ""bold"", size = 5.5, label = ""Assassination"") + #text annotations
  annotate(""text"", x = 5.2, y = 6.1, fontface = ""bold"", size = 5.5, label = ""Execution"") +
  annotate(""text"", x = 7.2, y = 1.8, fontface = ""bold"", size = 5.5, label = ""Unknown"") +
  annotate(""text"", x = 5.3, y = -3.2, fontface = ""bold"", size = 5.5, label = ""Captivity"") +
  annotate(""text"", x = 5.4, y = -5.3, fontface = ""bold"", size = 5.5, label = ""Natural Causes"") +
  annotate(""text"", x = -6.4, y = -5.0, fontface = ""bold"", size = 5.5, label = ""Died in Battle"") +
  annotate(""text"", x = 1, y = -0.2, fontface = ""bold"", size = 5.5, label = ""Suicide"") +
  theme_void()+
  theme(legend.position=""FALSE"",
    plot.title = element_text(hjust = 0.5, size = 26),
    plot.subtitle = element_text(hjust = 0.5, size = 22),
    plot.caption = element_text(size = 8,
                                color = ""#939184"")
  )
 

arrows <- tibble(    
  x2 = c(-4.6,4.3,5.6,4.3,4.3,-5.2),    
  x1 = c(-6,5,6.5,5,5,-6.2),    
  y2 = c(4,4.6,0.4,-2.3,-4.3,-4.3),    
  y1 = c(5,5.7,1.5,-3,-5,-4.8)  
)  

gg1 <-gg +    geom_curve(data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2),
                       arrow = arrow(length = unit(0.1, ""inch"")),
                       size = 1, color = ""black"", curvature = 0.15)  

ggfull <- gg1 + labs(title = ""Roman Emperors:"", subtitle = ""How they meet their end"", caption = ""Author: @jonathon_mifsud, Source: Wikipedia / Zonination"") 
ggsave(
  ""emperors.png"",
  plot = ggfull,
  width = 40,
  height = 30,
  units = ""cm""
)



















## Drafts ##
data <- emperors %>% 
  select(name, cause, reign_start, reign_end, dynasty) %>%
  mutate(span = interval(ymd(reign_start), ymd(reign_end))) %>% 
  mutate(spandays = abs(span %/% days(1))) %>% 
  mutate(spanmonths = round(spandays / 30)) %>% 
  mutate(spanyears = round(spanmonths / 12) + 1)

# Set a number of 'empty bar' to add at the end of each group
empty_bar <- 3
to_add <- data.frame( matrix(NA, empty_bar*nlevels(data$cause), ncol(data)) )
colnames(to_add) <- colnames(data)
to_add$cause <- rep(levels(data$cause), each=empty_bar)
data <- rbind(data, to_add)
data <- data %>% arrange(cause)
data$id <- seq(1, nrow(data))

# Get the name and the y position of each label
label_data <- data
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
label_data$hjust <- ifelse( angle < -90, 1, 0)
label_data$angle <- ifelse(angle < -90, angle+180, angle)

# prepare a data frame for base lines
base_data <- data %>% 
  group_by(cause) %>% 
  summarize(start=min(id), end=max(id) - empty_bar) %>% 
  rowwise() %>% 
  mutate(title=mean(c(start, end)))

# prepare a data frame for grid (scales)
grid_data <- base_data
grid_data$end <- grid_data$end[ c( nrow(grid_data), 1:nrow(grid_data)-1)] + 1
grid_data$start <- grid_data$start - 1
grid_data <- grid_data[-1,]

# Make the plot
p <- ggplot(data, aes(x=as.factor(id), y=spanyears, fill=cause)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  
  geom_bar(aes(x=as.factor(id), y=spanyears, fill=cause), stat=""identity"", alpha=0.5) +
  
  # Add a val=100/75/50/25 lines. I do it at the beginning to make sur barplots are OVER it.
  geom_segment(data=grid_data, aes(x = end, y = 33, xend = start, yend = 33), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  geom_segment(data=grid_data, aes(x = end, y = 23, xend = start, yend = 23), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  geom_segment(data=grid_data, aes(x = end, y = 13, xend = start, yend = 13), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  geom_segment(data=grid_data, aes(x = end, y = 3, xend = start, yend = 3), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  
  # Add text showing the value of each 100/75/50/25 lines
  annotate(""text"", x = rep(max(data$id),4), y = c(3, 13, 23, 33), label = c(""100"", ""200"", ""300"", ""400"") , color=""grey"", size=3 , angle=0, fontface=""bold"", hjust=1) +
  
  geom_bar(aes(x=as.factor(id), y=spanyears, fill=cause), stat=""identity"", alpha=0.5) +
  ylim(-100,40) +
  theme_minimal() +
  theme(
    legend.position = ""none"",
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), ""cm"") 
  ) +
  coord_polar() + 
  geom_text(data=label_data, aes(x=id, y=spanyears+10, label=name), color=""black"", fontface=""bold"",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE )+
  
  
  # Add base line information
  geom_segment(data=base_data, aes(x = start, y = -5, xend = end, yend = -5), colour = ""black"", alpha=0.8, size=0.6 , inherit.aes = FALSE )  +
  geom_text(data=base_data, aes(x = title, y = -18, label=cause), colour = ""black"", alpha=0.8, size=4, fontface=""bold"", inherit.aes = FALSE)

p

hjust <- c(0,0,1,1)



","2019"
"191",741,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/bobross.R","JonathonMifsud","tidytuesday","2019/code/bobross.R","## TidyTuesday 05/08/19
## Bob Ross Paintings

library(tidyverse)
library(ggridges)
library(viridis)# for scale_fill_viridis in one of the extra plots
library(hrbrthemes) # for theme_ipsum in main plot

bob_ross <-
  readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv""
  )

## In total we have 31 seasons each with a number of episodes.
## I am thinking of combining all elements into a total count.
## With this I will look at whether the total count of elements
## changes across seasons.


# to clean up the episode information
bob_ross <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer)

bobepiseason <- bob_ross %>%
  select(-title) %>%
  mutate(rowsum = rowSums(.[3:69])) %>% #sum all elements across each row
  select(season, episode, rowsum) %>%
  mutate(episode = as.factor(episode))



# Final plot
plot <- bobepiseason %>%
  mutate(episode = fct_rev(episode)) %>%
  ggplot(aes(y = episode, x = rowsum, fill = episode)) +
  geom_density_ridges(
    alpha = 0.6,
    stat = ""binline"",
    bins = 18,
    binwidth = 1,
    scale = 0.95
  ) +
  geom_text( # adding the numbers for each bin
    stat = ""bin"",
    aes(
      y = group + 0.95 * (..count.. / max(..count..)),
      label = ifelse(..count.. > 0, ..count.., """")
    ),
    vjust = 1,
    size = 3,
    color = ""black"",
    binwidth = 1
  ) +
  annotate( #annotation next to arrow
    ""text"",
    x = 13.7,
    y = 7.55,
    fontface = ""bold"",
    size = 3.5,
    label = ""Across all seasons Episode 7 \n had 11 elements on 4 occasions""
  ) +
  theme_ridges(grid = FALSE) +
  theme(
    legend.position = ""none"",
    strip.text.x = element_text(size = 8),
    axis.title.x = element_text(hjust = 0.5, face = ""bold""),
    axis.title.y = element_text(hjust = 0.5, face = ""bold""),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5),
    plot.caption = element_text(size = 8,
                                color = ""#939184"")
  )


# adding Labels
plot <- plot + labs(
  x = ""Number of Elements in a Painting"",
  y = ""Episode Number"",
  title = ""Are the number of elements to each Bob Ross painting consistent across each episode?"",
  subtitle = ""Occurence across all 33 seasons"",
  caption = ""Author: @jonathon_mifsud, Source: FiveThirtyEight""
)

# arrows
arrows <-
  tibble(x1 = 12.3, #arrow coords
         x2 = 11.6,
         y1 = 7.7,
         y2 = 7.3) 

# adding arrows
p <- plot + geom_curve(
    data = arrows,
    inherit.aes = FALSE,
    aes(
      x = x1,
      y = y1,
      xend = x2,
      yend = y2),
    arrow = arrow(length = unit(0.10, ""inch"")),
    size = 0.8,
    color = ""gray20"",
    curvature = 0.20
  )

# saving plot
ggsave(
  ""bobross.png"",
  plot = p,
  width = 40,
  height = 18,
  units = ""cm""
)





## Extras
bobseason <- bob_ross %>%
  select(-title,-episode) %>%
  group_by(season) %>%
  summarise_all(list(totalsum = sum)) %>%
  mutate(rowsum = rowSums(.[2:68])) %>%
  select(season, rowsum)

bobepisode <- bob_ross %>%
  select(-title) %>%
  group_by(episode) %>%
  summarise_all(list(totalsum = sum)) %>%
  mutate(rowsum = rowSums(.[3:68])) %>%
  mutate(episode = as.factor(episode)) %>%
  select(episode, rowsum) %>%
  na.omit

# First draft of final plot
ggplot(bobepiseason, aes(x = rowsum, y = episode, fill = episode)) +
  geom_density_ridges(scale = 1,
                      jittered_points = TRUE,
                      alpha = 0.8) +
  theme_ridges() +
  theme(legend.position = ""none"")

# Second draft of final plot
ggplot(bobepiseason, aes(x = `rowsum`, y = `episode`, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(name = ""rowsum"", option = ""F"") +
  labs(title = 'Title') +
  theme_ipsum() +
  theme(
    legend.position = ""none"",
    panel.spacing = unit(0.1, ""lines""),
    strip.text.x = element_text(size = 8)
  )
","2019"
"192",742,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/birdstrikes.R","JonathonMifsud","tidytuesday","2019/code/birdstrikes.R","###########################################
##      TidyTuesday Bird Strikes         ##
##            Jonathon Mifsud            ##
###########################################

library(rstudioapi)
library(tidyverse)
library(magrittr)
library(lintr)
library(sf)
library(raster)
library(viridis)
library(cowplot)
library(rvest)
library(albersusa)
### Cleaning

# I wanted to try a spatial plot this week. The dataset provided would need some rearranging for this to work.
# The first thing I did was look for infomation on how busy each airport in the US is.
# From this I can gather a really rough estimate of the amount of flights and aggregate this acrosss each state.
# I then can compare this to the number of bird strike incidents.
# Airport data taken from tables found in https://en.wikipedia.org/wiki/List_of_the_busiest_airports_in_the_United_States

airport_data <-
  read_html(
    ""https://en.wikipedia.org/wiki/List_of_the_busiest_airports_in_the_United_States""
  )

# The tables came in two parts with slightly different headings so I extracted them, cleaned and join them together
# Used rvest to import the table and the chrome extension SelectorGadget to obtain the xpath's

ad1 <- airport_data %>%
  html_node(xpath = '//*[@id=""mw-content-text""]/div/table[1]') %>%
  html_table()

ad1_clean <- ad1 %>%
  dplyr::select(""State"", ""2017[3]"", ""2016[4]"", ""2015[5]"", ""2014[6]"") %>%
  rename(
    ""state"" = ""State"",
    ""2017"" = ""2017[3]"",
    ""2016"" = ""2016[4]"",
    ""2015"" = ""2015[5]"",
    ""2014"" = ""2014[6]""
  )

ad2 <- airport_data %>%
  html_node(xpath = '//*[@id=""mw-content-text""]/div/table[2]') %>%
  html_table()

ad2_clean <- ad2 %>%
  dplyr::select(-""IATACode"",-""2018"",-""Airports (Medium Hubs)"",-""City Served"",-""Rank(2017)"") %>%
  rename(""state"" = ""State"",
         ""2015"" = ""2015[4]"",
         ""2014"" = ""2014[1]"")

## A horriblly unclean way to convert these to numeric and remove commas but it was the only one I found to work of the top of my head
ad1_clean$`2017` <- as.numeric(gsub("","", """", ad1_clean$`2017`))
ad1_clean$`2016` <- as.numeric(gsub("","", """", ad1_clean$`2016`))
ad1_clean$`2015` <- as.numeric(gsub("","", """", ad1_clean$`2015`))
ad1_clean$`2014` <- as.numeric(gsub("","", """", ad1_clean$`2014`))

ad2_clean$`2017` <- as.numeric(gsub("","", """", ad2_clean$`2017`))
ad2_clean$`2016` <- as.numeric(gsub("","", """", ad2_clean$`2016`))
ad2_clean$`2015` <- as.numeric(gsub("","", """", ad2_clean$`2015`))
ad2_clean$`2014` <- as.numeric(gsub("","", """", ad2_clean$`2014`))

passangers <- rbind(ad1_clean, ad2_clean)

passangers <- passangers %>%
  mutate(mean_pass = rowMeans(dplyr::select(passangers, -state))) %>%
  dplyr::select(state, mean_pass) %>%
  group_by(state) %>%
  summarise(mean_pass = sum(mean_pass)) %>% #calculating an average passanger count across 2017:2014
  mutate(state = recode(state, ""OH/KY"" = ""KY"")) #for the purposes of the analysis it is easier to break these up


# Bird data
bird_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")

bird_trim <- bird_impacts %>%
  dplyr::select(""state"", ""incident_year"") %>%
  filter(
    incident_year == 2017 |
      incident_year == 2016 |
      incident_year == 2015 |
      incident_year == 2014
  ) %>% #used the same years as the passanger dataset
  group_by(state) %>%
  summarise(incidents = sum(n()))


# Joining the two datasets
us_counties <-
  usa_sf(proj = c(""longlat"", ""laea"", ""lcc"", ""eqdc"", ""aeqd""))
pas_bird <- merge(passangers, bird_trim, by = ""state"")

# as each state doesnt have spatial components I used https://geocode.localfocus.nl/ to obtain these as a csv. file ""states""
states <-
  read.csv(""state.csv"", header = TRUE, stringsAsFactors = FALSE)
usa_strikes <- merge(pas_bird, states, by = ""state"")

#converting non sf to sf
usa_strikes_fips <- usa_strikes %>%
  st_as_sf(crs = 4326, coords = c(""long"", ""lat""))

cont_usa_sightings <- st_join(us_counties, usa_strikes_fips)



### Plotting
# This section is heavily based upon Timo Grossenbacher great bivariate map tutorial: https://timogrossenbacher.ch/2019/04/bivariate-maps-with-ggplot2-and-sf/

theme_map <- function(...) {
  theme_minimal() +
    theme(
      text = element_text(color = ""black""),
      # remove all axes
      axis.line = element_blank(),
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
      # add a subtle grid
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      # background colors
      plot.background = element_rect(fill = ""white"", colour = NA),
      panel.background = element_rect(fill = ""white"", colour = NA),
      legend.background = element_rect(fill = ""white"", colour = NA),
      # borders and margins
      plot.margin = unit(c(.5, .5, .2, .5), ""cm""),
      panel.border = element_blank(),
      panel.spacing = unit(c(-.1, 0.2, .2, 0.2), ""cm""),
      # titles
      legend.title = element_text(size = 11),
      legend.text = element_text(
        size = 9,
        hjust = 0,
        color = ""black""
      ),
      plot.title = element_text(
        size = 20,
        hjust = 0.5,
        color = ""black""
      ),
      plot.subtitle = element_text(
        size = 15,
        hjust = 0.5,
        color = ""black"",
        margin = margin(
          b = -0.1,
          t = -0.1,
          l = 2,
          unit = ""cm""
        ),
        debug = F
      ),
      # captions
      plot.caption = element_text(
        size = 7,
        hjust = .5,
        margin = margin(t = 0.2,
                        b = 0,
                        unit = ""cm""),
        color = ""#939184""
      ),
      ...
    )
}

# create 3 buckets for incidents
quantiles_incidents <- cont_usa_sightings %>%
  na.omit() %>%
  pull(incidents) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# create 3 buckets for mean passangers
quantiles_mean_pass <- cont_usa_sightings %>%
  na.omit() %>%
  pull(mean_pass) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# As found on Timo Grossenbacher tutorial
# create color scale that encodes two variables
# red for incidents and blue for mean passangers
bivariate_color_scale <- tibble(
  ""3 - 3"" = ""#3F2949"",
  # high incidents, high passangers
  ""2 - 3"" = ""#435786"",
  ""1 - 3"" = ""#4885C1"",
  # low incidents, high passangers
  ""3 - 2"" = ""#77324C"",
  ""2 - 2"" = ""#806A8A"",
  # medium incidents, medium passangers
  ""1 - 2"" = ""#89A1C8"",
  ""3 - 1"" = ""#AE3A4E"",
  # high incidents, low passangers
  ""2 - 1"" = ""#BC7C8F"",
  ""1 - 1"" = ""#CABED0"" # low incidents, low passangers
) %>%
  gather(""group"", ""fill"")


# cut into groups defined above and join fill
cont_usa_sightings %<>%
  mutate(
    incidents_quantiles = cut(incidents,
                              breaks = quantiles_incidents,
                              include.lowest = TRUE),
    mean_pass_quantiles = cut(mean_pass,
                              breaks = quantiles_mean_pass,
                              include.lowest = TRUE),
    group = paste(
      as.numeric(incidents_quantiles),
      ""-"",
      as.numeric(mean_pass_quantiles)
    )
  ) %>%
  left_join(bivariate_color_scale, by = ""group"")

### Blank map used for states that do not have data

us_all_counties <-
  usa_sf(proj = c(""longlat"", ""laea"", ""lcc"", ""eqdc"", ""aeqd""))
states_all <-
  read.csv(""all_states.csv"",
           header = TRUE,
           stringsAsFactors = FALSE)

states_all_fips <- states_all %>%
  st_as_sf(crs = 4326, coords = c(""long"", ""lat""))

all_usa <- st_join(us_all_counties, states_all_fips)

# Final plot starts here
map <- ggplot(
  data = cont_usa_sightings) +
  geom_sf(aes(fill = ""gray88""), # states that have no data
          color = NA,
          size = 0.2,
          data = all_usa) +
  geom_sf(aes(fill = fill),
          # line for state borders
          color = ""white"",
          size = 0.4) +
  scale_alpha(name = """",
              range = c(0.6, 0),
              guide = F) +
  scale_fill_identity() +
  labs(
    x = NULL,
    y = NULL,
    title = ""More flights, more wildlife strikes?"",
    subtitle = paste0(""Average reported wildlife strikes by airplanes across 29 US states from 2014-2017""),
    caption = ""Author: @jonathon_mifsud, Code: , Source: FAAs Wildlife Strike Reporting Database""
  ) +
  theme_map()

bivariate_color_scale %<>%
  separate(group,
           into = c(""incidents"", ""mean_pass""),
           sep = "" - "") %>%
  mutate(gini = as.integer(incidents),
         mean = as.integer(mean_pass))

legend <- ggplot() +
  geom_tile(data = bivariate_color_scale,
            mapping = aes(x = incidents,
                          y = mean_pass,
                          fill = fill)) +
  scale_fill_identity() +
  labs(x = ""More incidents"",
       y = ""More flights"")+ # Arrows were added using illustrator after trying endlessly to do it in R
  theme_map() +
  theme(axis.title = element_text(size = 14)) +
  coord_fixed()

# Joining the plot and legend 

plot <- ggdraw() +
  draw_plot(map, 0, 0, 1, 1) +
  draw_plot(legend, 0.05, 0.075, 0.2, 0.2)

ggsave(
  ""2019/plots/plot_2019-07-24.png"",
  width = 29,
  height = 21,
  units = ""cm"",
  dpi = ""retina""
)
","2019"
"193",743,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/r4ds_stats.R","JonathonMifsud","tidytuesday","2019/code/r4ds_stats.R","#############################################################
##    R for Data Science Online Learning Community Stats   ##
##                       Jonathon Mifsud                   ##
#############################################################

library(tidyverse)
library(reshape2)
library(emojifont)
library(ggthemes)


r4ds_members <-
  readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv""
  )

theme <- theme_minimal()

## After looking at the data I am planning to examine which day slack is the busiest

r4ds_members <-  r4ds_members %>%
  filter(total_membership >= 428) %>% #removing slack early membership
  mutate(day = wday(date, label = TRUE, abbr = FALSE)) %>%
  mutate(daily_quiet_members = daily_active_members - daily_members_posting_messages)

r4ds_day <- r4ds_members %>%
  select(day,
         daily_members_posting_messages,
         daily_quiet_members) %>%
  group_by(day) %>%
  summarise(
    posting_members = round(sum(daily_members_posting_messages)),
    shy_members = round(sum(daily_quiet_members)),
    day_count = n()
  )

r4ds_melt <- r4ds_day %>%
  select(-day_count) %>%
  melt()

p <- r4ds_melt %>%
  ggplot(aes(day, value, fill = variable)) +
  geom_chicklet(width = .6, radius = grid::unit(5, ""pt"")) +
  theme_minimal() +
  ggthemes::scale_fill_tableau('Color Blind',
                               name = ""Type of R4DS Member:"",
                               labels = c(""Poster"", ""Shy"")) +
  theme(
    plot.background = element_rect(fill = ""grey97"", color = ""white""),
    legend.position = ""bottom"",
    legend.title = element_text(color = ""grey30"", size = 14, face = ""bold""),
    legend.text = element_text(
      color = ""grey30"",
      size = 12,
      face = ""bold"",
      margin = margin(t = 10)
    ),
    legend.spacing.x = unit(0.8, ""cm""),
    legend.spacing.y = NULL,
    axis.text.y = element_text(color = ""grey30"", size = 12),
    axis.text.x = element_text(color = ""grey30"", size = 12),
    axis.title.y = element_text(
      color = ""grey30"",
      size = 16,
      face = ""bold"",
      margin = margin(
        t = 0,
        r = 20,
        b = 0,
        l = 0
      )
    ),
    axis.title.x = element_text(color = ""grey30"", size = 12, face = ""bold""),
    plot.title = element_text(color = ""grey30"", size = 22, face = ""bold""),
    plot.subtitle = element_text(size = 14)
  ) +
  labs(
    x = NULL ,
    y = ""Total Number of Active Members Overtime"",
    title = ""User activity on R4DS Slack"",
    subtitle = ""By day of the week, segmented by whether the user contributes a message/post or just reads (shy)"",
    caption = ""Source R4DS Slack, Plot by @jonathon_mifsud""
  ) +
  guides(
    fill = guide_legend(
      title = ""Type of R4DS Member:"",
      label.position = ""right"",
      label.hjust = 0.5,
      title.position = ""top"",
      title.vjust = 0.3
    )
  )
p




## For exporting (problems with font size)
p2 <- r4ds_melt %>%
  ggplot(aes(day, value, fill = variable)) +
  geom_chicklet(width = .6, radius = grid::unit(5, ""pt"")) +
  theme_minimal() +
  ggthemes::scale_fill_tableau('Color Blind',
                               name = ""Type of R4DS Member:"",
                               labels = c(""Poster"", ""Shy"")) +
  theme(
    plot.background = element_rect(fill = ""grey97"", color = ""white""),
    legend.position = ""bottom"",
    legend.title = element_text(color = ""grey30"", size = 32, face = ""bold""),
    legend.text = element_text(
      color = ""grey30"",
      size = 32,
      face = ""bold"",
      margin = margin(t = 10)
    ),
    legend.spacing.x = unit(0.8, ""cm""),
    legend.spacing.y = NULL,
    axis.text.y = element_text(color = ""grey30"", size = 30),
    axis.text.x = element_text(color = ""grey30"", size = 40),
    axis.title.y = element_text(
      color = ""grey30"",
      size = 40,
      face = ""bold"",
      margin = margin(
        t = 0,
        r = 20,
        b = 0,
        l = 0
      )
    ),
    axis.title.x = element_text(color = ""grey30"", size = 40, face = ""bold""),
    plot.title = element_text(color = ""grey30"", size = 60, face = ""bold""),
    plot.subtitle = element_text(size = 40),
    plot.caption = element_text(size = 18)
  ) +
  labs(
    x = NULL ,
    y = ""Total Number of Active Members Overtime"",
    title = ""User activity on R4DS Slack"",
    subtitle = ""By day of the week, segmented by whether the user contributes a message/post or just reads (shy)"",
    caption = ""Source R4DS Slack, Plot by @jonathon_mifsud""
  ) +
  guides(
    fill = guide_legend(
      title = ""Type of R4DS Member:"",
      label.position = ""right"",
      label.hjust = 0.5,
      title.position = ""top"",
      title.vjust = 0.3
    )
  )
p2



ggsave(""2019/plots/plot_2019-07-16.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019"
"194",744,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/media_franchises.R","JonathonMifsud","tidytuesday","2019/code/media_franchises.R","## TidyTuesday WK1 media_franchises ##
## jonathon_mifsud ##
## 03/07/19 ##

library(tidyverse)
library(hrbrthemes)
library(ggthemes)
library(ggchicklet)

## Reading in the file ##
media_franchises <- readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

# Looking at the data I think this week I would like to make a bar-plot. Franchise has a length of 103 unique titles,
# which may be too lengthy to analyse in this form. Instead, I aim to make a  of the total revenue separated by year.
# I will segment each year to show the contributions of each each type of original media.

## CLEANING ##

# delete duplicates
media_franchises <-
  media_franchises[!duplicated(media_franchises),]

# We have alot of years to work with. Instead of looking at a subset of this I will try creating multiple bins.
#We have 52 individual years so we could break this evenly into 13 bins. I am sure there is a better way to generate the labels!

media_franchises$year_created <-
  cut(
    media_franchises$year_created,
    breaks = 13,
    labels = c(
      ""1924-1931"",
      ""1931-1938"",
      ""1938-1945"",
      ""1945-1951"",
      ""1951-1958"",
      ""1958-1965"",
      ""1965-1972"",
      ""1972-1979"",
      ""1979-1986"",
      ""1986-1992"",
      ""1992-1999"",
      ""1999-2006"",
      ""2006-2013"")

year_counts <- media_franchises %>%
  group_by(revenue_category, year_created) %>%
  summarise(total_yearly_revenue_by_category = round(sum(revenue)),
            media_count = n())

## PLOT ##

#This barplot was inspired by a post and wonderful barplot tutorial by @hrbrmstr https://rud.is/b/2019/06/30/make-refreshing-segmented-column-charts-with-ggchicklet/ using the package ggchicklet

p <- year_counts %>%
  ggplot(aes(year_created, total_yearly_revenue_by_category, fill = revenue_category)) +
  geom_chicklet(width = 0.75) +
  scale_y_comma(position = ""right"") +
  coord_flip() +
  ggthemes::scale_fill_tableau('Superfishel Stone', name = NULL) +
  labs(
    x = NULL ,
    y = ""Total revenue generated overtime (in billions)"",
    fill = NULL,
    title = ""Revenue Generated by Media Franchise Powerhouses"",
    subtitle = ""By Year of Franchise Inception"",
    caption = ""Source Wikipedia, Plot by @jonathon_mifsud""
  ) +
  theme_ipsum_rc(grid = ""X"") +
  theme(legend.position = ""bottom"")

ggsave(
  ""plots/plot_2019-07-03.png"",
  width = 29,
  height = 21,
  units = ""cm"",
  dpi = ""retina""
)

## I have also made a version with the bar-plot ordered ##
year_counts_ordered <- media_franchises %>%
  group_by(revenue_category, year_created) %>%
  summarise(total_yearly_revenue_by_category = round(sum(revenue)),
            media_count = n()) %>%
  mutate(
    year_created = fct_relevel(
      year_created,
      ""1992-1999"",
      ""1972-1979"",
      ""1999-2006"",
      ""1979-1986"",
      ""1924-1931"",
      ""1986-1992"",
      ""2006-2013"",
      ""1965-1972"",
      ""1958-1965"",
      ""1938-1945"",
      ""1945-1951"",
      ""1951-1958"",
      ""1931-1938""))
#I am sure there is a better way to do this

year_counts_ordered <- year_counts_ordered %>%
  mutate(year_created = fct_rev(year_created))# after manually inputting the order I realised that it was lowest value first so I am reversing it so we get the higher revenes first.

p2 <- year_counts_ordered %>%
  ggplot(aes(year_created, total_yearly_revenue_by_category, fill = revenue_category)) +
  geom_chicklet(width = 0.75) +
  scale_y_comma(position = ""right"") +
  coord_flip() +
  ggthemes::scale_fill_tableau('Superfishel Stone', name = NULL) +
  labs(
    x = NULL ,
    y = ""Total revenue generated overtime (in billions)"",
    fill = NULL,
    title = ""Revenue Generated by Media Franchise Powerhouses"",
    subtitle = ""By Year of Franchise Inception"",
    caption = ""Source Wikipedia, Plot by @jonathon_mifsud""
  ) +
  theme_ipsum_rc(grid = ""X"") +
  theme(legend.position = ""bottom"")
","2019"
"195",745,"https://github.com/soroosj/TidyTuesday/blob/master/2019-08-06/bob_ross.Rmd","soroosj","TidyTuesday","2019-08-06/bob_ross.Rmd","----
   title: ""Bob Ross Paintings""
   author: ""Joel Soroos""
   date: ""August 10, 2019""
   output: pdf_document
---

### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   bob_ross_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"") %>%
      clean_names () 
```
   
   
### 2.  Convert show titles to one row per word
```{r transform, message = F}

   library (tidytext)

   bob_ross <- bob_ross_raw %>%
      select (episode, title) %>%
      unnest_tokens(word, title) %>%
      count(word, sort = TRUE) %>%
      rename (freq = n) %>%
      anti_join(stop_words) %>%
      inner_join (get_sentiments(""bing""))
```


### 3.  Create word tree
```{r}

   library (wordcloud2)
   png('filename.png')
   #https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
   letterCloud(bob_ross, word = ""BOB ROSS"", size = 1.3)
   dev.off ()
```","2019"
"196",746,"https://github.com/soroosj/TidyTuesday/blob/master/2019-04-23/Anime.Rmd","soroosj","TidyTuesday","2019-04-23/Anime.Rmd","---
title: ""Anime""
output:
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}
   library (tidyverse)
   library (janitor)
   library (stringr)
   library (kableExtra)
```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }
   anime_raw <- 
      read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/raw_anime.csv"") %>%
      clean_names ()
```

### 3. Tidy data
```{r analyze}
   anime <- anime_raw %>%
      drop_na () %>%
      mutate (
         studio = str_remove_all (studio, ""\\[|\\]|'"")
         )
```

## 4. Create table
```{r analyze}
   anime %>%
      select (source,score) %>%
      group_by (source) %>%
      summarise_all (list(~median, ~mean, ~mad, ~sd, ~IQR,~n())) %>%
      arrange (desc(median)) %>%
      mutate_if (is.numeric,~round(., 2)) %>%
      mutate (
         median = ifelse(median> 7.3,
                     cell_spec(median, ""html"", background = ""green"", color = ""white"", align = ""left""),
                     cell_spec(median, ""html"", background = ""red"", color = ""white"", align = ""left""))
         ) %>%
      kable (escape =F) %>%
      kable_styling (bootstrap_options = ""striped"", full_width = F) %>%
      add_header_above (c("" "" = 1, "" "" = 6)) %>%
      add_header_above (
         c(""Anime Rating Summary Statistics by Source"" = 7),
         align = ""c"",
         font_size = 16
         ) %>%
      save_kable (""anime.png"")
```    

","2019"
"197",747,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-02-12/govt_spend.Rmd","---
title: ""US R&D Spending""
output: html_document
---


## Load libraries
```{r setup, echo = TRUE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(tidyverse)
library(ggthemes)
library(scales)
```


## Source and wrangle data
```{r source_files, echo = TRUE}
govt_raw <- read_csv (""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")
govt_clean <- govt_raw %>%
   drop_na() %>%
   mutate_at (3:6, funs(round(./1000000000,1)))
head(govt_clean,10)
```


## R&D 2017 by department

```{r govt_2017, echo=TRUE}
govt_clean %>%
   filter (year == ""2017"") %>%
   ggplot(aes(x=reorder(department, rd_budget), y=rd_budget)) +
      geom_bar(stat='identity') +
      coord_flip() +
      theme_economist () +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(title = ""R&D budget by department"",
           subtitle = ""2017, billions of USD"",
           caption = ""Source: American Association for the Advancement of Science"")
```


## Department of Defense R&D over Time

```{r dod, echo = TRUE}
govt_clean %>%
   filter (department == ""DOD"") %>%
   ggplot () +
      geom_rect(aes(xmin=1974, xmax=1977, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1977, xmax=1981, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=1981, xmax=1993, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1993, xmax=2001, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=2001, xmax=2009, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=2009, xmax=2017, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      scale_fill_manual (values = c('blue','red')) +
   
      geom_line(aes (year, rd_budget)) +
   
      scale_x_continuous(breaks = seq(1976, 2017,4)) +
      theme_economist() +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(title = ""Dept of Defense R&D budget increases with Republican presidents"",
           subtitle = ""1976-2017, billions of USD"",
           caption = ""Source: American Association for the Advancement of Science"")
```

## R&D by department over time

```{r govt_all, echo=TRUE}
govt_all <-
   govt_clean %>%
   ggplot() +
      geom_rect(aes(xmin=1974, xmax=1977, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1977, xmax=1981, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=1981, xmax=1993, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1993, xmax=2001, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=2001, xmax=2009, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=2009, xmax=2017, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      scale_fill_manual (values = c('blue','red')) +
   
      geom_line(aes (year, rd_budget)) +
   
      theme_economist() +
      theme(axis.title.x = element_blank(),
         axis.title.y = element_blank(),
         axis.text.x = element_text(size = 8),
         axis.text.y = element_text(size = 7),
         legend.text=element_text(size = 8),
         legend.title = element_blank(),
         panel.spacing = unit(2, ""lines""),
         strip.text = element_text(size = 7)) +
      facet_grid(department ~., scales = ""free_y"") +
      scale_x_continuous(breaks = seq(1976, 2017,4)) +
      scale_y_continuous(breaks = scales::pretty_breaks(2)) +
      labs(title = ""R&D budget by department"",
        subtitle = ""1976-2017, billions of USD"",
        caption = ""Source: American Association for the Advancement of Science"")
   
ggsave(""govt_all.png"",govt_all)","2019"
"198",748,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-02-12/govt_spend_flex.Rmd","---
title: ""U.S. Government R&D Budget""
output:
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    source_code: embed
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(ggthemes)
library(scales)
library(cluster)
library(dendextend)
library(ggdendro)

govt_raw <- read_csv (""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")

govt_clean <- govt_raw %>%
   drop_na() %>%
   mutate_at (3:6, funs(round(./1000000000,1))) 
   

head(govt_clean,10)
```



Column {data-width=500}
-----------------------------------------------------------------------

### 1. R&D budget by department in 2017 ($b)

```{r}
govt_clean %>%
   filter (year == ""2017"") %>%
   ggplot(aes(x=reorder(department, rd_budget), y=rd_budget)) +
      geom_bar(stat='identity') +
      coord_flip() +
      theme_economist () +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(caption = ""Source: American Association for the Advancement of Science"")
```



### 3. R&D budget over time by department ($b)

```{r}
govt_clean %>%
   ggplot(aes(x=year, y=rd_budget, color=department)) +
      geom_point() +
      theme_economist () +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank(),
            legend.position = ""right"",
            legend.text=element_text(size=8)) +
      labs(caption = ""Source: American Association for the Advancement of Science"")
```

Column {data-width=500}
-----------------------------------------------------------------------
### 2. Dept of Defense R&D budget by presidential party 1976-2017 ($b)

```{r}
govt_clean %>%
   filter (department == ""DOD"") %>%
   ggplot () +
      geom_rect(aes(xmin=1974, xmax=1977, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1977, xmax=1981, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=1981, xmax=1993, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1993, xmax=2001, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=2001, xmax=2009, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=2009, xmax=2017, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      scale_fill_manual (values = c('blue','red')) +
   
      geom_line(aes (year, rd_budget)) +
   
      scale_x_continuous(breaks = seq(1976, 2017,4)) +
      theme_economist() +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(caption = ""Source: American Association for the Advancement of Science"")
```

### 4. R&D budget by department over time cluster analysis

```{r}
govt_spread <- govt_clean %>%
   select (department, year, rd_budget) %>%
   spread (year, rd_budget) %>%
   column_to_rownames(""department"")

govt_dist <- govt_spread %>%
   dist(method = 'euclidean') 

govt_clust <- govt_dist %>%
   hclust (method = 'complete') %>%
   as.dendrogram() %>%
   dendro_data(type=""rectangle"")

#ggplot(segment(govt_clust),labels=rownames(govt_clust)) + 
  #geom_segment(aes(x=x, y=y, xend=xend, yend=yend)) + 
  #theme_dendro() +
  #coord_flip() +
  #scale_x_reverse()

ggdendrogram(govt_clust)
```

","2019"
"199",749,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-02-26/Trains.Rmd","---
title: ""French Trains""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidygraph)
library(ggraph)

trains_raw <- read_csv (""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

trains <- trains_raw %>%
   select (year, month, departure_station, arrival_station, journey_time_avg, total_num_trips) %>%
   arrange (-total_num_trips)

trains_2017 <- trains %>%
   filter (year == 2017)

```

## R Markdown


```{r network}
departures <- trains_2017 %>%
   distinct(departure_station) %>%
   rename(station = departure_station)

arrivals <- trains_2017 %>%
   distinct(arrival_station) %>%
   rename(station = arrival_station)

nodes <- full_join(departures, arrivals, by = ""station"") %>%
    rowid_to_column(""id"")

per_route <- trains_2017 %>%  
  group_by(departure_station, arrival_station) %>%
  summarise(trips = n()) %>% 
  ungroup()

edges <- per_route %>% 
  left_join(nodes, by = c(""departure_station"" = ""station"")) %>% 
  rename(from = id) %>% 
  left_join(nodes, by = c(""arrival_station"" = ""station"")) %>% 
  rename(to = id) %>%
  select(from, to, trips)

routes_tidy <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

ggraph(routes_tidy) +
   geom_edge_link() +
   geom_node_point() +
   theme_graph() +
   scale_edge_width(range = c(0.2, 2)) +
   geom_node_text(aes(label = station), size = 2, repel = TRUE) 
```

","2019"
"200",750,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-03-26/Pet breeds.Rmd","---
title: ""Seattle Pets""
output: html_document
---

### 1. Load packages
```{r setup}
knitr::opts_chunk$set(echo = TRUE)

library (tidyverse)
library (ggthemes)
library (ggtextures)
library (magick)

```

### 2. Source data 
```{r import, echo = TRUE} 
pets <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")

```

### 3. Identify most popular dog breeds
```{r popular}

pets_summ <- pets %>%
   drop_na () %>%
   filter (species == ""Dog"") %>%
   group_by (primary_breed) %>%
   summarize (count = n ()) %>%
   arrange (-count) %>%
   head (10)

pets_summ

```

### 4. Load dog images
```{r images}

pets_summ$image <- list (
   image_read (""https://www.petinsurancereview.com/sites/default/files/inline-images/Labrador%20Retriever%202.jpg""),
   image_read (""http://www.allsmalldogbreeds.com/breeds/chihuahua-short-coat.jpg""),
   image_read (""https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12133017/Golden-Care.jpg""),
   image_read (""https://bowwowinsurance.com.au/wp-content/uploads/2018/10/australian-aussie-terrier-700x700.jpg""),
   image_read (""https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRjJqstuFnEQYpXeNbb3Sqv6l5EHxE1TWrEkFwnsW8zMwiIEiwn""),
   image_read (""https://previews.123rf.com/images/fotojagodka/fotojagodka1311/fotojagodka131100256/23734288-miniature-poodle-puppy-sits-on-a-white-background.jpg""),
   image_read (""https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Female_German_Shepherd.jpg/330px-Female_German_Shepherd.jpg""),
   image_read (""https://cf-s3.petcoach.co/uploads/breed/48/1520278916-Aussie2.jpg""),
   image_read (""https://dailystormer.name/wp-content/uploads/2017/12/840dfdd1804b7291c59af3ae134660d8-bully-pitbull-pitbull-terrier.jpg""),
   image_read (""https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12212849/Australian-Cattle-Dog-History-06.jpg"")
      )

``` 

### 5. Create chart 
```{r chart}

pets_bar <- ggplot(pets_summ, aes(x=reorder(primary_breed,count), y=count, image = image)) +
      geom_textured_col (img_height = grid::unit(1,""null""), img_width = grid::unit(0.6,""cm""), ncol = 1, nrow = 1, hjust = 0, vjust = 0.5, fill = ""light blue"") + 
      theme_economist () +
      theme(
         axis.title.x=element_blank(),
         axis.title.y=element_blank(),
         axis.text.y=element_blank()) +
      labs(
         title = ""Most popular dog breeds"",
         subtitle = ""Seattle: April 2017 - September 2018"",
         caption = ""Source: City of Seattle"") +
      coord_flip ()

ggsave(""breeds.png"", pets_bar)
pets_bar  

```","2019"
"201",751,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-04-09/Tennis.Rmd","---
title: ""Grand Slam""
output:
  pdf_document: default
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

library (tidyverse)
library (janitor)
library (ggthemes)
library (ggrepel)
library (stringr)

```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }

tennis_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")
   
```
### 3. Convert outcomes to numeric
```{r}

tennis <- tennis_raw %>%
   clean_names() %>%
   mutate(
     outcome_num = case_when(
        outcome == ""Won"" ~ 8,
        outcome == ""Finalist"" ~ 7,
        outcome == ""Semi-finalist"" ~ 6,
        outcome == ""Quarterfinalist"" ~ 5,
        outcome == ""4th Round"" ~ 4,
        outcome == ""3rd Round"" ~ 3,
        outcome == ""2nd Round"" ~ 2,
        outcome == ""1st Round"" ~ 1
         ),
     player = str_remove (player, ""// ""),
     player = str_replace (player, ""Sele"", ""Seles"")
     )  %>%
   drop_na ()

tennis %>%
   head (10)

```

### 4. Calculate average outcomes
```{r aggregate}
  
tennis_avg <- tennis %>%
   group_by (player) %>%
   summarize (
      avg = round(mean (outcome_num),2),
      st_dev = round(sd (outcome_num),2),
      n = n ()
      ) %>%
   arrange (-avg) %>%
   filter (n>9) %>%
   drop_na ()

tennis_avg %>%
   head (10)
```

### 4. Create visualization
```{r chart}

tennis_plot <- ggplot (tennis_avg, aes (avg, st_dev, label = player)) +
   geom_point () +
   theme_economist() +
   scale_y_continuous(trans = ""reverse"") +
   geom_label_repel(
      aes(label=ifelse(avg>5.8,as.character(player),'')),
      box.padding   = 0.35, 
      point.padding = 0.5,
      size = 3,
      segment.color = 'grey50') +
   labs(
      title = ""Average and Dispersion of Grand Slam Outcomes (1968-2018)"",
      subtitle = ""Win = 8, 1st Round = 1"",
      caption = ""Source:Wikipedia"",
      x = ""Average"",
      y = ""Standard Deviation""
      ) +
   theme(
      axis.title.x=element_text(size=9),
      axis.title.y=element_text(size=9)
   )

tennis_plot
ggsave (""tennis.png"", tennis_plot)

```
","2019"
"202",752,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-04-30/birds.Rmd","---
title: ""Birds""
output:
  pdf_document: default
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

library (tidyverse)
library (janitor)
library (ggthemes)
library (ggridges)
library (stringr)

```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }

birds_raw <- read_delim(
   ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_call.csv"",
   delim = "" ""
   )%>%
   clean_names() 
   
```
### 3. Explore data
```{r}

birds <- birds_raw %>%
   drop_na () %>%
   group_by (species) %>%
   filter (flight > 50)

tabyl (birds, collisions)

   
```


### 4. Create visualization
```{r chart}

ggplot (data = birds, aes(x = flight, y = collisions)) +
  geom_density_ridges ()

```
","2019"
"203",753,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-05-07/student.Rmd","---
title: ""Student Ratio""
output:
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

library (tidyverse)
library (janitor)
library (inspectdf)
library (ggridges)
library (ggthemes)
library (countrycode)

```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }

student_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")%>%
   clean_names()

inspect_cat (student_raw, show_plot = T)
inspect_num (student_raw, show_plot = T)
inspect_na (student_raw, show_plot = T)

   
```

### 3. Transform data
```{r transform}

student <- student_raw %>%
   mutate (
      continent = countrycode(country, origin = ""country.name"", destination = ""continent""),
      indicator = str_replace (indicator, "" Education"", """"),
      indicator = as.factor(indicator),
      indicator = fct_relevel(indicator, c(""Pre-Primary"", ""Primary"", ""Lower Secondary"", ""Secondary"", ""Upper Secondary"", ""Post-Secondary Non-Tertiary"", ""Tertiary""))
      )%>%
   select (continent, country_code, country, indicator, year, student_ratio) %>%
   drop_na ()

```


### 4a. Create ridgeline chart by continent
```{r plot1}

continent_plot <- student %>%
   filter (
      year == 2016,
      indicator == ""Upper Secondary""
      ) %>%
   ggplot (aes(x = student_ratio, y = reorder(continent,desc(continent)), group = continent)) +
   geom_density_ridges (fill = ""skyblue"") +
   theme_economist() +
   labs(
      title = ""Upper Secondary Student/Teacher Ratio by Continent (2016)"",
      subtitle = ""Oceania has the most dispersion, Europe the least."",
      caption = ""\n Source:UNESCO Institute of Statistics  |  R4DS Tidy Tuesday
      Visualization: Joel Soroos (Twitter @soroosj)"",
      x = ""Student Teacher Ratio"",
      y = """") 

ggsave (""plots/continent.png"", continent_plot)

continent_plot

```

### 4b. Create ridgeline chart by indicator
```{r plot2}

indicator_plot <- student %>%
   filter (
      year == 2016,
      continent == ""Asia""
      ) %>%
   ggplot (aes(x = student_ratio, y = reorder(indicator,desc(indicator)), group = indicator)) +
   geom_density_ridges (fill = ""skyblue"") +
   theme_economist() %>%
   labs(
      title = ""Student/Teacher Ratio by Education Level in Asia (2016)"",
      caption = ""Source:UNESCO Institute of Statistics  |  R4DS Tidy Tuesday
      Visualization: Joel Soroos @soroosj"",
      x = """",
      y = """")

ggsave (""plots/indicator.png"", indicator_plot)

indicator_plot

```","2019"
"204",754,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-05-21/Plastic Waste.Rmd","---
title: ""Plastic Waste""
author: ""Joel Soroos""
date: ""May 26, 2019""
output:
  pdf_document: default
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor)
   library (ggrepel)
   library (scales)
   library (kableExtra)
   
```


### 2. Get data
```{r source, warning = TRUE, results = FALSE, message = FALSE}
   
   mismanaged_vs_gdp<- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>%
      clean_names()
   
   coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>%
      clean_names()

```


### 3. Transform data
```{r transform}

   waste_raw <- left_join (mismanaged_vs_gdp, coast_vs_waste, by = c(""code"", ""year"")) %>%
      filter (year == 2010)
   
   waste <- waste_raw %>%
      filter (year == 2010) %>%
      drop_na () %>%
      rename (
         country_name = entity.x,
         waste = mismanaged_plastic_waste_tonnes,
         gdp_per_capita = gdp_per_capita_ppp_constant_2011_international_rate,
         population = total_population_gapminder.x
         )%>%
      mutate (
          waste_per_coastal_capita = waste / coastal_population * 100,
          population = population / 1000000
         ) %>%
      select (country_name, waste, coastal_population, waste_per_coastal_capita,  gdp_per_capita, population) %>%
      arrange (-waste_per_coastal_capita)
   
   kable (head(waste,10))

```

### 4. Visualize
```{r plot}

   ggplot (waste,
      aes(x = gdp_per_capita, y = waste_per_coastal_capita, size = population)) +
      geom_point () +
      geom_smooth () +
      #scales
         scale_x_continuous(
            label = unit_format(prefix = ""$"", unit = ""K"", scale = 1e-3, sep = """"),
            trans = log10_trans()
            ) +
         scale_y_continuous(trans = log10_trans()) +
         scale_size_continuous(breaks = c(10, 100, 1000)) +
      theme(
         plot.title = element_text(hjust=0, size = 14),
         plot.caption = element_text(color=""black"", size=8),
         legend.title = element_text(colour=""black"", size=9),
         legend.text = element_text(colour=""black"", size=9),
         legend.position = ""top"",
         axis.title=element_text(size=9),
         panel.grid.major = element_line(size = 0.05, linetype = 'solid', color = 'grey50'),
         panel.grid.minor = element_blank (),
         panel.background = element_rect(fill = ""white"")
         ) +
      guides(size = guide_legend(override.aes = list(linetype = 0))) +
      geom_label_repel(
         aes (label = ""India's waste lower than predicted \nfor its per capita GDP""),
         data = subset (waste, country_name == ""India""),
         box.padding = 0.8, 
         point.padding = 0.7,
         size = 3,
         alpha = .8,
         segment.color = 'grey50'
         ) +
       labs(
         title = ""Mismanaged waste decreases as nations reach middle income"",
         caption = ""\n Sources: National Geographic, Gapminder, R4DS Tidy Tuesday
         Visualization: Joel Soroos (Twitter: @soroosj)"",
         x = ""GDP per capita"",
         y = ""Mismanaged waste per coastal capita (100 kg/year)"",
         size = ""Population (millions): ""
         ) +
   ggsave(""plot1.png"")

```
","2019"
"205",755,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-05-28/Wine Reviews.Rmd","---
title: ""Wine Reviews""
author: ""Joel Soroos""
date: ""May 31, 2019""
output: pdf_document
---

### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor)  

   wine_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
      clean_names ()
```

### 2. Transform data
```{r transform, message = F}

   wine_raw %>%
      group_by (variety) %>%
      summarize (n = n()) %>%
      arrange (-n) %>%
      top_n (10) %>%
      select (-n) -> wine_group

   wine_raw %>%
      drop_na (variety, price) %>%
      mutate (
         variety = as.factor(variety),
         popularity = ifelse (variety %in% wine_group$variety, ""High"", ""Low""),
         color = case_when(
            variety %in% c(""Pinot Noir"", ""Cabernet Sauvignon"", ""Red Blend"", ""Bordeaux-style Red Blend"", ""Syrah"", ""Merlot"") ~ ""red4"",
            variety %in% c(""Pinot Noir"", ""Chardonnay"", ""Riesling"", ""Sauvignon Blanc"") ~ ""Oldlace"",
            variety %in% c(""Ros"") ~ ""Deeppink""
            )
         ) %>%
      filter (
         popularity == ""High"",
         price < 300
         ) %>%
      select (variety, color, price) -> wine
```

### 3. Visualize data
```{r plot}

   library (ggdark)
   library (scales)

   ggplot (
         data = wine,
         aes (x = reorder(variety, price, median), y = price, fill = I(color))
           ) +
      geom_violin(draw_quantiles = c(.50)) +
      scale_x_discrete(position = ""top"") +
      scale_y_continuous (
         trans = log10_trans(),
         label = unit_format(prefix = ""$"", unit = """")
            ) +
      coord_flip () +
      dark_mode(theme_minimal()) +
      theme (
          plot.title = element_text(hjust = 0, size = 15),
          plot.caption = element_text(hjust = 0, size = 9),
          axis.title=element_text(size=9),
          axis.text=element_text(size=9, face = ""bold""),
          axis.ticks = element_blank()
         ) +
      labs(
         title = ""Open your wallet wide if you prefer red wine!"",
         caption = ""\nVertical line within violin represents median wine bottle price for that grape variety. \nVarietals with 10 most reviews displayed.  Excludes wines priced > $300 per bottle. \nSource: Wine Enthusiast via Kaggle via R4DS Tidy Tuesday       |       Visualization: Joel Soroos @soroosj"",
         x = """",
         y = ""Price per 750ml bottle""
         ) +
   ggsave(""wine.png"")
```
","2019"
"206",756,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-06-24/UFO.Rmd","---
   title: ""UFO Sightings""
   author: ""Joel Soroos""
   date: ""June 30, 2019""
   output: pdf_document
---

### 1a. Source UFO encounter data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   ufo_raw<- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"") %>%
      clean_names ()
```
   
### 1b. Source North Carolina map borders 
```{r source, warning = TRUE, results = FALSE, message = FALSE}
   
   map_borders <- map_data(""state"", region = ""north carolina"") 
```

### 2.  Transform UFO data
```{r transform, message = F}

  library (lubridate)

   ufo <- ufo_raw %>%
      select (date_time, city_area, state, latitude, longitude, encounter_length) %>%
      filter (
         state == ""nc"",
         latitude > 30,      # remove borders erroneously listed as NC outside of state borders
         latitude < 37,      # remove borders erroneously listed as NC outside of state borders
         longitude < -75     # remove borders erroneously listed as NC outside of state borders
         )  %>%
      mutate (
         encounter_length = encounter_length/3600,              #convert seconds to hours
         date_time = as.Date(date_time, format = ""%m/%d/%Y"")
         )
```

### 3. Visualize data
```{r plot}

   library (ggdark)

   ggplot () +
      #plot North Carolina borders
      geom_polygon (data = map_borders, aes(x = long, y = lat, group = group), color = ""black"", fill = ""#303030"", size = 1.15) +
      #plot UFO encounters
      geom_point (data = ufo, aes (x = longitude, y = latitude, size = encounter_length), color = ""green"") +
      #Deep Gap encounter annotation
         annotate(""text"",
            label = ""30 hour encounter\nin Deep Gap (2009)"",
            size = 3, hjust = 0, color = ""green"", family = ""Rockwell"",
            x = -84.9, y = 36.1
            ) +
         geom_curve(
            aes(x = -83.2, y = 36.2, xend = -81.7, yend = 36.27),
            arrow = arrow(length = unit(0.2, ""cm"")), 
            size = 0.4, color = ""green"", curvature = -0.4
            ) +
      #Gastonia encounter annotation
         annotate(""text"",
            label = ""120 hour encounter\nin Gastonia (1993)."",
            size = 3, hjust = 0, color = ""green"", family = ""Rockwell"",
            x = -83.1, y = 34.5, xmax = -83.5
            ) +
         geom_curve(
            aes(x = -82.27, y = 34.65, xend = -81.37, yend = 35.2),
            arrow = arrow(length = unit(0.2, ""cm"")), 
            size = 0.4, color = ""green"", curvature = -0.3
            ) +
       labs(
         title = ""UFOs over North Carolina\n"",
         size = ""Encounter (hrs)"",
         caption = ""\nEach dot represents a reported UFO sighting between 1995 and 2014.  \nSource: National UFO Reporting Center  | Visualization: Joel Soroos @soroosj""
         ) +
      coord_fixed(1.3) +
      scale_size_continuous(breaks = c(1, 10, 100)) +
      dark_mode(theme_minimal()) +
      theme(
         text = element_text(family = ""Rockwell"", color = ""green""),
         plot.title = element_text(hjust = 0.5, size = 18),
         plot.caption = element_text(hjust = 0, size = 8),
         axis.title = element_blank(),
         axis.text = element_blank(),
         axis.ticks = element_blank(),
         legend.title = element_text(size = 10, hjust = 0.5, vjust = 0.5),
         legend.text = element_text(size = 9, hjust = 0.5, vjust = 0.5),
         legend.position = c(0.82,0.18),
         legend.justification=c(0, 1), 
         legend.key.size = unit(0.1, 'lines')
         ) +
      ggsave(""ufo.png"", height =3.85)
```
","2019"
"207",757,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-07-02/Media Franchises.Rmd","---
   title: ""Animated File Media Franchise Revenues""
   author: ""Joel Soroos""
   date: ""July 7, 2019""
   output: pdf_document
---

### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   franchise_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"") %>%
      clean_names ()
```
   
### 2. Transform data
```{r transform, message = F}

  franchise <- franchise_raw %>%
      filter (original_media == ""Animated film"") %>%
      select (franchise, year_created, revenue_category, revenue) %>%
      mutate (
         franchise = case_when (
            franchise == ""Despicable Me / Minions"" ~ ""Minions"",
            franchise == ""The Lion King"" ~ ""Lion King"",
            TRUE ~ franchise
            ),
         #concatenate franchise and start date to enable two rows on x axis
         franchise_start = paste (franchise, ""\n("", year_created, "")"", sep = """"), 
         franchise_start = fct_relevel(franchise_start,              #Control franchise order in chart
            ""Barbie\n(1987)"", ""Cars\n(2006)"", ""Toy Story\n(1995)"", ""Lion King\n(1994)"", ""Frozen\n(2013)"", ""Minions\n(2010)"", ""Aladdin\n(1992)"", ""Ice Age\n(2002)"" 
            ),
         revenue = revenue * 10,          #Multiply by 10 to generate more boxes in waffle chart for additional granularity.
         revenue_category = case_when (
            revenue_category == ""Home Video/Entertainment"" ~ ""Home Video"",
            revenue_category == ""Video Games/Games"" ~ ""Video Games"",
            revenue_category == ""Merchandise, Licensing & Retail"" ~ ""Merchandise"",
            TRUE ~ revenue_category
            ),
         #control revenue group order in chart
         revenue_category = fct_relevel(revenue_category, ""Box Office"", ""Home Video"", ""Music"", ""Video Games"", ""Merchandise"")
         ) 
```

#3.  Create chart
```{r chart, warning = TRUE, results = FALSE, message = FALSE}

   library (waffle)
   library (ggdark)

   ggplot(franchise, aes(fill=revenue_category, values=revenue)) + 
     geom_waffle(color = ""white"", size=.3, n_rows = 8, flip = T) +
     facet_wrap(~franchise_start, nrow=1, strip.position = ""bottom"") +     #creates multiple waffle columns
     #scales
         scale_x_discrete(expand=c(0,0)) +
         scale_y_continuous(
            breaks = seq(5, 50, by = 5), 
            labels = function(x) x * .8, # make this multiplier the same as n_rows
            expand = c(0,0)
            ) +
         scale_fill_brewer(palette = ""Set1"") +
     #themes
        dark_mode(theme_minimal()) +
        theme(
           #download custom Waltograph font and then upload to R via extrafont package:https://www.dafont.com/waltograph.font
           text = element_text(family = ""Waltograph"", color = ""white""),   
           plot.title = element_text(hjust = .5, size = 22, face = ""bold""),
           plot.caption = element_text(hjust = 1, size = 12, vjust = .5),
           axis.title.y = element_text(hjust=1, size = 12, face = ""bold""),
           axis.text.y=element_text(size=12, face = ""bold""),
           strip.text = element_text(size = 13),
           legend.position = c(0.92,0.67),
           legend.text = element_text(size=12),
           legend.key.size = unit(0.5, ""cm"")
           ) +
     labs(
        title = ""Animated Film Franchise Revenues"",
        y = ""Revenues ($, billions)"",
        fill = """",
        caption = ""\nEach square represents $100 million in revenues. Year below franchise signifies year of creation. \nSource: Wikipedia  |  Visualization: Joel Soroos @soroosj""
        ) +
      ggsave(""franchise.png"", width = 15, height = 9.5, units = ""cm"")
```
","2019"
"208",758,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-08-13/Emperor.Rmd","---
   title: ""Roman Emperors""
   author: ""Joel Soroos""
   date: ""August 18, 2019""
   output: pdf_document
---


### 1. Source 
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   emperors_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"") %>%
      clean_names () %>%
      drop_na (birth)
```


### 2a.  Transform data - count by death cause
```{r, warning = TRUE, results = FALSE, message = FALSE}

   library (glue)

   emperor_cause <- emperors_raw %>%
      filter (era == ""Principate"") %>%
      mutate (cause = fct_lump (cause,4)) %>%
      count (cause, sort = TRUE) %>%
      mutate (cause_long = glue (""{cause} ({n})"")) %>%
      select (cause, cause_long)
```

   
### 2b.  Transform data - calculate reign ages
```{r source, warning = TRUE, results = FALSE, message = FALSE}
   
   library (lubridate)

   emperors <- emperors_raw %>%
      filter (era == ""Principate"") %>%
      mutate (
         birth = case_when (
            index %in% c(1,2,4,6) ~ update (birth, year = - year (birth)),
            TRUE~ birth
            ),
        reign_start = case_when (
            index %in% c(1) ~ update (reign_start, year = - year (reign_start)),
            TRUE~ reign_start
            ),
         reign_start_age = (reign_start- birth)/365.25,
         reign_end_age = (reign_end - birth)/365.25,
         reign_length = (reign_end - reign_start)/365.25,
         cause = fct_lump (cause, 4)
      ) %>%
      #add count of emperor death cause to death cause
      right_join (emperor_cause) %>%
      select (index, name, birth, death, reign_start_age, reign_end_age, reign_length, cause_long, cause) 
```


### 3. Visualize data
```{r plot}

   ggplot( data = emperors) +
      #reign segments and death age points
         geom_segment(
            aes(
               x = reign_start_age, 
               xend = reign_end_age, 
               y = reorder(name, -reign_end_age), 
               yend = name
               ),
            alpha = 0.15, color = ""black"" 
            ) +
         geom_point(
            aes(y=name, x=reign_end_age, color = cause_long),
            size = 1
            ) +
      #youngest reign annotation
         annotate(""text"",
            label = ""Youngest\nreign"",
            size = 3, hjust = 0.5, family = ""Trajanus Roman"", color = ""black"",
            x = 12, y = 36 
            ) +
         geom_curve(
            aes(x = 12, xend = 12, y = 37,  yend = 38.6),
            arrow = arrow(length = unit(0.1, ""cm"")), 
            size = 0.1, color = ""black"", curvature = 0, alpha = 0.07
            ) +
      #last reign annotation
         annotate(""text"",
            label = ""Final reign"",
            size = 3, hjust = 0.5, family = ""Trajanus Roman"", color = ""black"",
            x = 49, y = 23
            ) +
         geom_curve(
            aes(x = 50.5, xend = 52.4, y = 23.2, yend = 24),
            arrow = arrow(length = unit(0.1, ""cm"")), 
            size = 0.1, color = ""black"", curvature = -0.3, alpha = 0.07
            ) +
      #longest reign annotation
         annotate(""text"",
            label = ""Longest reign"",
            size = 3, hjust = 0.5, family = ""Trajanus Roman"", color = ""black"",
            x = 31.5, y = 5, xmax = 36  
            ) +
         geom_curve(
            aes(x = 36.2, xend = 38, y = 4.8, yend = 4.2),
            arrow = arrow(length = unit(0.1, ""cm"")), 
            size = 0.1, color = ""black"", curvature = -0.3, alpha = 0.07
            ) +
      #scales
         scale_x_continuous(
            breaks = c(20, 40, 60, 80),
            labels = c(""XX"", ""LIX"", ""LX"", ""LXXX"")
            ) +
         scale_color_brewer(palette = ""Set1"") +
      theme (
         plot.title = element_text(hjust = 0.5, vjust = 0, size = 16, face = ""bold""),
         plot.subtitle = element_text(hjust = 0.5, vjust = 1, size = 12, face = ""bold""),
         plot.caption = element_text (hjust = 0, size = 10),
         plot.background = element_rect(fill = ""#fdf6e3""),
         panel.background = element_rect(fill = ""#fdf6e3""),     
         panel.grid = element_blank (),
         text = element_text(family = ""Trajanus Roman"", color = ""black"", face = ""bold""),   #download font from https://www.fontspace.com/roger-white/trajanus-roman
         axis.title.x = element_text (hjust = 0.5),
         axis.text.x = element_text (size = 8),
         axis.title.y = element_blank (),
         axis.ticks = element_blank (),
         legend.background = element_rect(fill = ""#fdf6e3""),
         legend.title = element_blank(),
         legend.position = c(0.85,0.88),
         legend.key.size = unit(0.1, 'lines')
         ) +
      labs(
         title = ""Roman Emperor Principate Era (62 BCE to AD 283)"",
         subtitle = ""They ruled history's largest empire but often died brutally.\n\n"",
         caption = ""\nLines represent the beginning through ending age of each emperor's reign.\nData: Wikipedia   Visualization: Joel Soroos @soroosj"",
         x = ""\nAge (Years)""
         ) +
     ggsave(""emperors.png"", width = 20, units = ""cm"")
```

","2019"
"209",759,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-08-20/Explosions.Rmd","---
   title: ""Nuclear Explosions""
   author: ""Joel Soroos""
   date: ""September 1, 2019""
   output: pdf_document
---


### 1. Source nuclear explosion data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   explosions_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"") %>%
      clean_names () %>%
      drop_na (country)
```
   

### 2.  Transform nuclear explosion data
```{r transform, message = F, results = F}

   explosions <- explosions_raw %>%
      mutate (
         country = ifelse(country == ""PAKIST"", ""Pakistan"", country),
         country = ifelse(country %in% c(""FRANCE"", ""INDIA"", ""CHINA""), str_to_title (country), country)
         ) %>%
      group_by (year) %>%
         count (country) %>%
         arrange (year, n) %>%
         mutate(rank = row_number(-n) * 1) %>%
         ungroup () 
```


### 3. Visualize nuclear explosion data
```{r plot}

   library (scales)
   library (ggdark)
   library (gganimate)
   library (gifski)

   g <-ggplot (explosions, aes (rank)) +
      #bars
         geom_tile (
            aes(y = n/2, height = n, fill = country),
            width = 0.5
            ) +
      #bar labels
         geom_text(
            aes(y = 0, label = paste (country, ""  "")), 
            hjust = 1, color = ""white"", size = 4.5, family = ""sans""
            ) +
         geom_text(
            aes(y = n, label = paste ("" "",n)), 
            hjust = ""left"", color = ""white"", size = 4, family = ""sans""
            ) +
      #scales
         coord_flip (clip = ""off"", expand = FALSE) +
         scale_x_reverse() +
         scale_y_continuous(trans = log10_trans()) +
         ylim (-18, 105) +
         scale_fill_brewer(type = ""qual"", palette = 2) +
      #themes
         dark_theme_classic () +
         theme(
            plot.title = element_text(hjust = 0.5, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,25,0)),
            plot.caption = element_text (hjust = 0, size = 11, margin = margin (20,0,0,0)),
            axis.title = element_blank(),
            axis.text = element_blank(),
            axis.ticks = element_blank(),
            axis.line = element_blank(),
            legend.position = ""none""
            ) +
      labs(
         title = ""Nuclear Weapon Explosions\n{closest_state}"",
         caption = ""Data: Stockholm International Peace Research Institute via R4DS Tidy Tuesday\nVisualization: Joel Soroos @soroosj""
         ) +
      #separate charts by year
         transition_states(year, transition_length = 4, state_length = 1)

      #animate charts
         animate(g, nframes = 200, fps = 5, width = 420, height = 230, 
           renderer = gifski_renderer(""explosions.gif""))
```
","2019"
"210",760,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-09-03/Moore.Rmd","---
   title: ""Moore's Law""
   author: ""Joel Soroos""
   date: ""September 15, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   cpu_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"") %>%
      clean_names ()

   #remove scientific notation 
   options(scipen=999)
```
   

### 2a.  Build Moore's Law prediction
```{r transform, message = F, results = F}

   moore <- tibble (
      year = as.numeric (seq (1971, 2020)),
      cpu_moore = round(2250 * sqrt(2) ^ (year - 1971),0)
   )
```


### 2b.  Transform actual transistor counts
```{r transform, message = F, results = F}

   cpu_all <- cpu_raw %>%
      select(date_of_introduction, transistor_count) %>%
      rename (
         year = date_of_introduction,
         cpu_actual = transistor_count
         )

   cpu_max <- cpu_all %>%
      group_by (year) %>%
      summarize (cpu_actual = max(cpu_actual))
```


### 2c.  Combine data
```{r transform, message = F, results = F}     
   
   combine <- moore %>%
      left_join (cpu_max) %>%
      select (year, cpu_moore, cpu_actual) %>%
      na.omit()
```

### 3.  Calculate model
```{r}

   library (broom)

   combine <- loess(		    
          log10(cpu_actual) ~ year,		   
          data = cpu_max,		       
          na.action = na.omit
          ) %>%		
       augment (combine) %>%
       mutate (cpu_model = 10^.fitted)
```


### 4. Visualize data
```{r plot}

   library (scales)
   library (ggdark)

   ggplot () +
      #Lines
         #Moore's law prediction
             geom_line(
                data = combine,
                aes (x=year, y = cpu_moore),
                size = 0.4, linetype = 3
                ) +
         #Actual CPU model
            geom_line(
                data = combine,
                aes (x=year, y = cpu_model),
                size = 0.7, linetype = 2
                ) + 
      #Ribbons
         #Underpredict
            geom_ribbon (
               data = filter (combine, cpu_moore < cpu_model),
               aes (x=year, ymin = cpu_moore, ymax = cpu_model, fill = ""Model fit > Moore's Law""),
               show.legend = T
               ) +
         #Overpredict
            geom_ribbon (
               data = filter (combine, cpu_moore > cpu_model),
               aes (x=year, ymin = cpu_moore, ymax = cpu_model, fill = ""Model fit < Moore's Law""),
               show.legend = T
               ) +
      #Points
         geom_point(
            data = cpu_max,
            aes (x= year, y = cpu_actual, fill = ""CPU actual""),
            size = 2, alpha = 0.6, show.legend = T
             ) +
      #Annotation
         #Moore's Law
             annotate(
                  geom=""text"", x=1991.5,y=30000000,
                  label=""Moore's\nLaw"", 
                  color=""white"", size=3, hjust=0.5,vjust=0.5, fontface=""bold""
                  ) +
               geom_curve(
                  aes(x = 1991.5, xend = 1991.5, y = 13000000, yend = 3000000),
                  arrow = arrow(length = unit(0.1, ""inch"")),
                  size = 0.25, color = ""white"", curvature = 0  
                  ) +   
         #Model
                annotate(
                  geom=""text"", x=1990,y=80000,
                  label=""Model"", 
                  color=""white"", size=3, hjust=0.5,vjust=0.5, fontface=""bold""
                  ) +
               geom_curve(
                  aes(x = 1990, xend = 1990, y = 99000, yend = 800000),
                  arrow = arrow(length = unit(0.1, ""inch"")),
                  size = 0.25, color = ""white"", curvature = 0  
                  ) +   
      #scales
         scale_y_continuous(
            trans = log10_trans(),
            breaks = c(2250, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, 10000000000, 100000000000),
            labels = comma
            ) +
         scale_x_continuous(breaks = seq (1970, 2020, 10)) +
         scale_fill_manual(values = c(""white"",""red"", ""green"")) +
      #themes
         dark_theme_classic () +
         theme(
            plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,7,0)),
            plot.title.position = ""plot"",
            plot.subtitle = element_text(hjust = 0, vjust = 0, size = 8, face = ""bold"", margin = margin (0,0,30,0)),
            plot.caption = element_text (hjust = 0, size = 8, face = ""plain"", margin = margin (15,0,0,0), color=""#6D7C83""),
            plot.caption.position = ""plot"",
            panel.grid.major = element_line(colour=""white"", size=0.03),
            axis.title.y = element_text (size = 9, hjust = 0),
            axis.title.x = element_blank(),
            legend.position = c(0.87,0.33),
            legend.title = element_blank (),
            legend.text = element_text(size=8),
            legend.key.size = unit(0.2, ""cm"")
            ) +
         guides(fill = guide_legend(override.aes = list(shape = NA))) +
      labs(
         title = ""Exponential growth in computing power"",
         subtitle = ""Gordon Moore predicted in 1971 that computing power would double approximately every 2 years (Moore's Law).\nOver the next 38 years he has largely been correct - slightly below through 2000, slightly above from 2001-2012 and slightly trailing more recently."",
         y = ""# of transistors on a CPU microchip"",
         caption = ""Visualization: Joel Soroos @soroosj  |  Data: Wikipedia via R4DS Tidy Tuesday""
         ) +
      ggsave(""moore.png"", width = 22, height = 13, units = ""cm"")
```","2019"
"211",761,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-09-17/Parks.Rmd","---
   title: ""National Parks""
   author: ""Joel Soroos""
   date: ""September 29, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   visits_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-17/national_parks.csv"") %>%
      clean_names ()
```


### 2.  Transform visits
```{r transform, message = F, results = F}

   visits <- visits_raw %>%
      filter (
         unit_type == ""National Park"",
         unit_name != ""Total"",
         year %in% c(1995, 2005, 2015)
         ) %>%
      select(year, unit_code, unit_code, unit_name, state, visitors) %>%
      mutate (year = as.numeric (year)) %>%
      arrange (-year, -visitors) %>%
      group_by (year) %>%
      mutate (rank_visitors = rank(desc(visitors), ties.method = ""first"")) %>%
      do(head(., n = 10)) %>%
      ungroup (year)

   visits_max <- visits %>%
      filter(year == max(year)) %>%
      mutate(year = as.numeric(year) + 0.25)

  visits_min <- visits %>%
      filter(year == min(year)) %>%
      mutate(year = as.numeric(year) - 0.25)

```


### 3a. Visualize data
```{r}

   library (ggrepel)

   ggplot(data = visits, mapping = aes(year, y = rank_visitors, group = unit_code, color = unit_code)) +
     geom_line(size = 1.7, alpha = 0.25, data = visits) +
     geom_line(size = 2.5, data = visits) +
     geom_point(size = 4, alpha = 0.25, data = visits) +
     geom_point(size = 4, data = visits) +
     geom_point(size = 1.75, color = ""white"", data = visits) +
     geom_text_repel(
        data = visits_max, 
        aes(label = unit_code), 
        hjust = ""inward"", size = 3
        ) +
     geom_text_repel(
        data = visits_min,
        aes(label = unit_code),
        hjust = ""inward"", size = 3
        ) +
     #scales
         scale_x_continuous(
            breaks = seq (1995, 2015, 10),
            expand = c(.1, .1)
            ) +
         scale_y_reverse (breaks = c(1,5,10)) +
         scale_color_manual(values = c(""#a6cee3"", ""#1f78b4"", ""#b2df8a"", ""#33a02c"", ""#fb9a99"", ""#e31a1c"", ""#fdbf6f"", ""#ff7f00"", ""#cab2d6"", ""#6a3d9a"", ""#ffff99"")) +
     labs (
       title = ""United States National Park Visitors (1995 - 2015)"",
       subtitle = ""     - Great Smoky Mountain and Grand Canyon National Parks continue as #1 and #2 most visited.\n     - Rocky Mountain National Park has grown from #7 to #3 while Olympic National Park has slipped from #4 to #7."",
       caption = ""Visualization: Joel Soroos @soroosj  |  Data: Wikipedia via R4DS Tidy Tuesday"",
       y = ""# of visitors rank""
         ) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,3,0)),
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 9, face = ""bold"", margin = margin (0,0,20,0)),
         plot.caption = element_text (hjust = 0, size = 8, face = ""plain"", margin = margin (20,0,0,0), color=""#6D7C83""),
         legend.position = ""none"",
         axis.title.y = element_text (size = 10, hjust = 1),
         axis.title.x = element_blank ()
         ) +
      ggsave(""parks.png"", width = 22, height = 13, units = ""cm"")
```












","2019"
"212",762,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-09-17/Slope Chart.R","### 3b. Visualize data
```{r plot}

library (ggrepel)

ggplot(data = visits, aes(x = year, y = z_visitors, group = unit_code)) +
   geom_line(
      aes(color = unit_code),
      alpha = 1, size = 1
   )+
   geom_text_repel(
      data = visits %>% 
         filter(year == 1966), 
      aes(label = unit_code) ,
      hjust = ""left"", fontface = ""bold"", size = 3, nudge_x = -.45, direction = ""y""
   ) +
   geom_text_repel(
      data = visits %>% 
         filter(year == 2016), 
      aes(label = unit_code) , 
      hjust = ""right"", fontface = ""bold"", size = 3, nudge_x = .5, direction = ""y""
   ) +
   geom_label(
      aes(label = z_visitors), 
      size = 2.5, 
      label.padding = unit(0.05, ""lines""), 
      label.size = 0.0
   ) +
   scale_x_discrete(position = ""top"") +
   theme_bw() +
   theme(
      legend.position = ""none"",
      panel.border     = element_blank(),
      axis.title.y     = element_blank(),
      axis.text.y      = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      axis.title.x     = element_blank(),
      panel.grid.major.x = element_blank(),
      axis.text.x.top      = element_text(size=12),
      axis.ticks       = element_blank(),
      plot.title       = element_text(size=14, face = ""bold"", hjust = 0.5),
      plot.subtitle    = element_text(hjust = 0.5)
   ) +
   labs(
      title = ""Estimates of Percent Survival Rates"",
      subtitle = ""Based on: Edward Tufte, Beautiful Evidence, 174, 176."",
      caption = ""Visualization: Joel Soroos @soroosj  |  Data: Wikipedia via R4DS Tidy Tuesday""
   ) 
```","2019"
"213",763,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-10-15/Cars.Rmd","---
   title: ""Vehicle MPG""
   author: ""Joel Soroos""
   date: ""October 20, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 
   library (magick)
   library (grid)

   cars_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")%>%
      clean_names () 
   	
   pump_img <- image_read(""petrol-pump.jpg"") %>%
      rasterGrob(width = unit(2,""in""))
```


### 2.  Transform data
```{r transform, message = F, results = F}

   cars <- cars_raw %>%
      filter (year == 2019) %>%
      select(id, make, model, eng_dscr, v_class, fuel_type1, comb08) %>%
      rename (
         fuel_type = fuel_type1,
         vehicle_class = v_class,
         mph_comb = comb08
         ) %>%
      mutate (vehicle_class = str_remove(vehicle_class, "" 2WD| 4WD"")) 
```


###3.  Model data
```{r}

   library (broom)

   cars_tidy <- lm (mph_comb ~ vehicle_class + fuel_type, cars) %>%
      tidy() %>%                 #coefficient estimates
      mutate (
         term = str_remove_all(term, ""fuel_type|vehicle_class| -""),                  #remove field names
         term = fct_reorder(term, estimate),
         estimate_direction = ifelse(estimate >=0, ""positive"", ""negative"")
         ) 
```


### 4. Visualize data
```{r}

   ggplot(data = cars_tidy, aes(y = estimate, x = term, fill = estimate_direction)) +
      geom_col() +
      annotation_custom (pump_img, ymin = -10, xmin = -2) +
      #scales
         scale_y_continuous(limits = c (-20, 80)) +
         scale_fill_manual(values = c(""red"", ""darkgreen"")) +
         coord_flip () +
      labs(
         title = ""How does your vehicle choice impact fuel efficiency?"",
         subtitle = ""Electric cars contribute most marginal miles per hour on average, vans and pickup trucks detract most."",
         x = ""Regression term"",
         y = ""Estimated marginal contribution (detraction) to mph"",
         caption = ""Each row represents linear regression estimate of vehicle class & gasoline type indepedent variables vs. miles per gallon dependent variable.\nVisualization: Joel Soroos @soroosj  |  Data: U.S. EPA via R4DS Tidy Tuesday""
         ) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,3,0)),
         plot.title.position = ""plot"",
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 10, face = ""bold"", margin = margin (0,0,25,0)),
         plot.caption = element_text (hjust = 0, size = 8, face = ""plain"", margin = margin (20,0,0,0)),
         plot.caption.position = ""plot"",
         panel.background = element_rect (fill = ""white""),
         axis.title = element_text (size = 9, hjust = 0.75, color = ""gray20""),
         axis.line = element_line(color = ""gray70""),
         axis.ticks = element_line(color = ""gray70""),
         legend.position = ""none""
            ) +
      ggsave(""cars.png"", width = 18, height = 13, units = ""cm"")
```","2019"
"214",764,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-10-29/Squirrels.Rmd","---
   title: ""Squirrels""
   author: ""Joel Soroos""
   date: ""November 3, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library(""tidyverse"")
   library(""ggmap"")

   squirrels_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")
   
   register_google(key = Sys.getenv(""GOOGLE_MAPS_API""))
```


### 2.  Transform data
```{r transform, message = F, results = F}

   squirrels <- squirrels_raw %>%
      pivot_longer (
         cols = c(running:foraging, kuks:runs_from), 
         names_to = ""activity"", 
         values_to = ""value""
         ) %>%
      filter (value == T) %>%
      select (long, lat, activity) %>%
      mutate (
         activity = str_to_title (activity),
         activity = case_when (
            activity == ""Tail_flags"" ~ ""Tail Flags"",
            activity == ""Tail_twitches"" ~ ""Tail Twitches"",
            activity == ""Runs_from"" ~ ""Runs From"",
            TRUE ~ activity)
         )
```


### 3. Visualize data
```{r visualize}

   library (ggdark)

   ggmap(
      get_googlemap(
         center = c(""Central Park""),
         zoom = 13, scale = 2, color = 'color',
         maptype ='roadmap',
         style = 'style=feature:all|element:labels|visibility:off'
         )
      ) +
      geom_point(
         data = squirrels, 
         aes(x = long, y = lat),
         size = 0.05, alpha = 0.7, color = ""blue""
         ) +
      scale_x_continuous(limits = c(-73.982, -73.95)) +
      scale_y_continuous(limits = c(40.765, 40.80)) +
      dark_mode(theme_minimal()) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,4,0)),
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 8, margin = margin (0,0,25,0)),
         plot.caption = element_text (hjust = 1, size = 7, face = ""plain"", margin = margin (10,0,0,0), color=""#6D7C83""),
         axis.title=element_blank(),
         axis.text=element_blank(),
         axis.ticks=element_blank(),
         strip.text = element_text (size = 8),
         legend.title=element_blank()
         ) +
      facet_wrap (
         facets = vars(activity),
         nrow = 3
         ) +
      labs(
         title = ""Squirrel Behaviors in New York's Central Park"",
         subtitle = ""      - Movements such as climbing/foraging far more common than sounds such as kuks/moans.\n      - Results from a study conducted by Jamie Allen and a team of 300 volunteers from October 6-20, 2018."",
         caption = ""Visualization: Joel Soroos @soroosj  |  Data: The Squirrel Census via R4DS Tidy Tuesday""
         ) +
      ggsave(""squirrels.png"", width = 15, height = 17, units = ""cm"")
```","2019"
"215",765,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-11-4/Commute.Rmd","---
   title: ""Commute""
   author: ""Joel Soroos""
   date: ""November 10, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library(""tidyverse"")
   library(""ggmap"")

   commute_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")
   
   register_google(key = Sys.getenv(""GOOGLE_MAPS_API""))
```


### 2.  Transform data
```{r transform, message = F, results = F}

   library (glue)   

   commute <- commute_raw %>%
      head (100) %>%
      select (city, state, n, percent) %>%
      mutate (city_state = glue (""{city}, {state}"")) %>%
      mutate_geocode (city_state)
```


### 3. Visualize data
```{r visualize}

   library (ggdark)

   ggmap(
      get_googlemap(
         center = c(""United States""),
         zoom = 4, scale = 2, color = 'color',
         maptype ='roadmap',
         style = 'style=feature:all|element:labels|visibility:off'
         )
      ) +
      geom_point(
         data = commute, 
         aes(x = lon, y = lat, fill = percent),
         alpha = 0.7
         ) +
      scale_fill_brewer(palette = ""BuPu"") +
      dark_mode(theme_minimal()) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,4,0)),
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 8, margin = margin (0,0,25,0)),
         plot.caption = element_text (hjust = 1, size = 7, face = ""plain"", margin = margin (10,0,0,0), color=""#6D7C83""),
         axis.title=element_blank(),
         axis.text=element_blank(),
         axis.ticks=element_blank(),
         legend.title=element_blank()
         ) +
      labs(
         title = ""Squirrel Behaviors in New York's Central Park"",
         subtitle = ""      - Movements such as climbing/foraging far more common than sounds such as kuks/moans.\n      - Results from a study conducted by Jamie Allen and a team of 300 volunteers from October 6-20, 2018."",
         caption = ""Visualization: Joel Soroos @soroosj  |  Data: The Squirrel Census via R4DS Tidy Tuesday""
         ) +
      ggsave(""commute.png"", width = 25, height = 14, units = ""cm"")
```","2019"
"216",766,"https://github.com/MiguelHeCa/tidytuesday/blob/master/2019-06-11/Meteorites.R","MiguelHeCa","tidytuesday","2019-06-11/Meteorites.R","# Tidy Tuesday | Week 24
# Meteorites!
# Source: ""https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-06-11""

library(tidyverse)
library(gganimate)

# Read data ---------------------------------------------------------------

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

world <- map_data(""world"")

# Prepare data ------------------------------------------------------------

meteo <- meteorites %>%
  drop_na() %>% 
  filter(mass > 0, year > 1300) %>% 
  mutate(year = if_else(name == ""Northwest Africa 7701"", 2010, year),
         year = as.integer(year),
         calc_mass = if_else(mass > 10000, 10000, mass))

fallen <- meteo %>% filter(fall == ""Fell"")
found <- meteo %>% filter(fall == ""Found"")

# Create static plot ------------------------------------------------------

map <- ggplot() +
  geom_polygon(
    data = world,
    aes(x = long, y = lat, group = group),
    fill = ""#e6e6e9"",
    size = 0.1
  ) +
  geom_point(
    data = fallen,
    aes(
      x = long,
      y = lat,
      size = calc_mass,
      color = calc_mass
    ),
    alpha = 0.5
  ) +
  scale_color_distiller(
    palette = ""Reds"",
    direction = 1,
    labels = c(""0"", ""2.5"", ""5.0"", ""7.5"", ""10.0+""),
    guide = guide_colorbar(
      direction = ""horizontal"",
      barheight = unit(3, units = ""mm""),
      barwidth = unit(60, units = ""mm""),
      title.position = ""top"",
      title.hjust = 0.5,
      label.hjust = 0.5
    )
  ) +
  geom_point(
    data = found,
    aes(
      x = long,
      y = lat,
      size = calc_mass,
      fill = calc_mass
    ),
    shape = 21,
    alpha = 0.5
  ) +
  scale_fill_distiller(
    palette = ""Blues"",
    direction = 1,
    labels = c(""0"", ""2.5"", ""5.0"", ""7.5"", ""10.0+""),
    guide = guide_colorbar(
      direction = ""horizontal"",
      barheight = unit(3, units = ""mm""),
      barwidth = unit(60, units = ""mm""),
      title.position = ""top"",
      title.hjust = 0.5,
      label.hjust = 0.5
    )
  ) +
  scale_size(guide = ""none"") +
  theme_void() +
  theme(
    legend.position = c(0.15, 0.1),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, color = ""gray50"", size = 14), 
    plot.caption = element_text(hjust = 0.5),
    text = element_text(family = ""B612 Mono"")
  ) +
  labs(
    color = ""Fallen mass in kilograms"",
    fill = ""Found mass in kilograms"",
    title = ""Meteorites on Earth"",
    subtitle = ""Year: {frame_time}"",
    caption = ""Source: NASA""
  ) +
  coord_map(""mollweide"", orientation = c(90, 0, 0))

# Create GIF --------------------------------------------------------------

map_gif <- map +
  transition_events(start = year,
                    end = year + 5L,
                    enter_length = 6L,
                    exit_length = 4L) +
  enter_grow() +
  exit_fade()

animate(map_gif, nframes = 160, duration = 40, height = 768, width = 1024)

anim_save(""2019-06-11/Meteorites.gif"")
","2019"
"217",767,"https://github.com/MiguelHeCa/tidytuesday/blob/master/2019-05-28/wine.R","MiguelHeCa","tidytuesday","2019-05-28/wine.R","# TidyTuesday Week 22


# Load packages -----------------------------------------------------------

library(tidyverse)
library(tidytext)
library(wordcloud2)

# Prepare data ------------------------------------------------------------

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

wr <- wine_ratings %>% drop_na(points, price)

# Select only latinamerican countries
latinamerica <- c(""Argentina"", ""Brazil"",  ""Chile"", ""Mexico"", ""Peru"", ""Uruguay"")

wr_lat <- wr %>% 
  filter(country %in% latinamerica) %>% 
  select(country, description, points, price)

# It was easier to include this words in the stop_words data frame than
# using regex. I excluded this words because I thought they might not give 
# give any useful insight about wine description.
additional_stop_words <- tibble(
  word = c(
    ""flavor"",
    ""flavors"",
    ""aroma"",
    ""aromas"",
    ""drink"",
    ""drinks""
  ),
  lexicon = ""Wine""
)

all_stop_words <- stop_words %>% 
  bind_rows(additional_stop_words)

# Select only the observations whose points are ranked in the top ten.
# Then I prepare data for the word clouds
wine_lat <- wr_lat %>%
  group_by(country) %>% 
  mutate(ranking = dense_rank(points)) %>% 
  arrange(ranking) %>% 
  ungroup() %>% 
  filter(ranking >= 10) %>% 
  mutate(description = str_replace_all(description, ""\\d"", """")) %>% 
  group_by(country) %>% 
  unnest_tokens(word, description) %>% 
  anti_join(all_stop_words, by = c(""word"" = ""word"")) %>% 
  count(word, sort = T, name = ""freq"") %>% 
  ungroup()

# Get a vector of the countries that are left from the criteria. Sorry Peru!
rated_countries <- wine_lat %>% 
  distinct(country) %>% 
  arrange(country) %>% 
  unlist() %>% 
  unname()

# Word cloud --------------------------------------------------------------

wine_colors <-  c(""#5b0b0b"", ""#790000"", ""#8f8023"", ""#9e934d"", ""#bcb37b"")

create_wordcloud <- function(COUNTRY){
  wine_lat %>% 
    filter(country == COUNTRY) %>% 
    select(word, freq) %>% 
    wordcloud2(size = 1,
               color = rep_len(wine_colors, nrow(.)),
               fontFamily = ""Open Sans"")
}  

wc_a <- create_wordcloud(rated_countries[1])
wc_b <- create_wordcloud(rated_countries[2])
wc_c <- create_wordcloud(rated_countries[3])
wc_m <- create_wordcloud(rated_countries[4])
wc_u <- create_wordcloud(rated_countries[5])

# Saved word clouds manually through RStudio given that saving it by code
# is too convoluted.
# I tried ggwordcloud and wordcloud also, but rendering took too long and the 
# cloud is not as aesthetically pleasing as in wordcloud2.
# Caveat is that making grids with wordcloud2 are a real pain, though,
# so I cheated a little bit with the final plot (edited it elsewhere).
# If you know any realiable method to make grids with wordcloud or wordcloud2
# please let me know.


","2019"
"218",784,"https://github.com/oscarbaruffa/tidytuesday-2019-01-01-rtweet","oscarbaruffa","tidytuesday-2019-01-01-rtweet","2019-01-01_rstats_tweets_script.R","
library(tidyverse)
library(tidytext)
library(extrafont)

font_import()
loadfonts(device = ""win"")

#reduce size of dataset

# tweets_raw <- read_rds(""data/rstats_tweets.rds"")
# 
# tweets_raw %>%
#   filter(lang == ""en"") %>%
#   select(""status_id"", ""created_at"", ""text"", ""source"") %>%
#   write_rds(""data/tweets_raw2.rds"", ""gz"")


tweets_raw2 <- read_rds(""data/tweets_raw2.rds"")

#View some summary stats
# summary(tweets_raw2)
# skimr::skim(tweets_raw2)
# glimpse(tweets_raw2)

#Let's see the top words. Code from https://github.com/jasonbaik94/rstats-2019-goals/find/master

# Get rid of all non-ASCII characters
# Get rid of 2019, #rstats, goals
# Get rid of \n
# Get rid of periods, numbers, https (urls), amp, tco

tweets <- tweets_raw2 %>% 
  mutate(text = str_replace_all(text, ""[^\x01-\x7F]"", """"),
         text = str_replace_all(text, ""2019|goals|#rstats|#Rstats|#RStats"", """"),
         text = str_replace_all(text, ""\n"", """"),
         text = str_replace_all(text, ""\\.|[[:digit:]]+"", """"),
         text = str_replace_all(text, ""http|rt|Http|Rt|https|amp|tco"", """"))

#just checking top 20 words
tweets %>%  
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = ""word"") %>% 
  count(word, sort = TRUE) %>%
  head(20)
 
#filter for passion words
tweets %>%  
  unnest_tokens(word, text) %>% 
  filter(word %in% c(""love"", ""Love"", ""hate"", ""Hate"")) %>% 
  count(word, sort = TRUE)

#created Date-formatted dates
tweets$created_at <-  as.Date(tweets$created_at, 'GMT') 

#cumulative sum of passion words
passion_tweets <- tweets %>%  
  unnest_tokens(word, text) %>% 
  filter(word %in% c(""love"", ""Love"", ""hate"", ""Hate"")) %>% 
  arrange(created_at) %>% 
  mutate(hate_count = ifelse(word == ""hate"", 1, 0)) %>% 
  mutate(love_count = ifelse(word == ""love"", 1, 0)) %>% 
  mutate(hate = cumsum(hate_count)) %>% 
  mutate(love = cumsum(love_count)) %>% 
  gather(hate:love, key = passion_word, value = total_tweets)


ggplot(passion_tweets) + 
  geom_line(aes(created_at, total_tweets, color = passion_word), size = 2) +
  labs(title = ""Come for the #Rstats, stay for the Love"",
       subtitle = ""Cumulative sum of words 'love' and 'hate' in #rstats tweets"",
       x = """",
       y = """",
       caption = ""TidyTuesday 2019-01-01\n Plot: @oscar_b123 \n Data: rwteet"") +
  ylim(0, 5000) +
  geom_text(data = subset(passion_tweets, created_at == max(created_at)), 
            aes(x = max(created_at), y = total_tweets, label = passion_word,
                colour = passion_word), size = 6, hjust = 1, vjust = -0.2) +
  scale_colour_manual(values = c(""#000000"", ""#e00fc8""))+
  theme_minimal() +
  theme(legend.position = ""none"",
        text = element_text(family = ""Bahnschrift""),
        plot.background = element_rect(fill='#f5d59a', colour = ""#f5d59a""),
        panel.background = element_rect(fill='#f5d59a', colour = ""#f5d59a""),
        panel.grid.major = element_line(colour = ""#f4ece1""),
        panel.grid.minor = element_line(colour = ""#f4ece1""))
  

 


  
","2019"
"219",785,"https://github.com/PMassicotte/r-blog/blob/master/content/post/2019-07-30-tidytuesday-video-games.en.Rmd","PMassicotte","r-blog","content/post/2019-07-30-tidytuesday-video-games.en.Rmd","---
title: 'Tidytuesday: video games'
author: Philippe Massicotte
date: '2019-07-30'
slug: tidytuesday-video-games
categories:
  - R
  - Tidytuesday
tags: []
type: ''
subtitle: ''
image: ''
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = ""#>"",
  collapse = TRUE,
  cache = TRUE,
  dpi = 300,
  out.width = ""100%"",
  fig.align = ""center"",
  fig.width = 8,
  fig.asp = 0.618, # 1 / phi
  fig.show = ""hold"",
  dev = ""svg"",
  message = FALSE
)

library(tidyverse)
library(ggpmthemes)
library(glue)
theme_set(theme_poppins())
```

I must admit, I played a lot of PC video games when I was younger, *Battlefield*, *Half-life*, *Dark Age of Camelot*, *World of Warcraft*, *Diablo* just to name a few. This is why this week [tidytuesday](https://github.com/rfordatascience/tidytuesday) was a good occasion to participate in this weekly R visualization challenge. 

## Video Games Dataset

> This week's data comes courtesy of Liza Wood via Steam Spy. She recently published a blog post on her data analysis of this video game data. She was kind enough to provide a fairly clean dataset, and I have done some small additional clean up seen below. There is time played, ownership, release date, publishing information, and for some a metascore! Lots of ways to slice and dice this data!

Let us get started! First, read the data and remove duplicated entries.

```{r}
video_games <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"") %>%
  mutate(release_date = as.Date(release_date, ""%b %d, %Y"")) %>%
  distinct(game, developer, publisher, .keep_all = TRUE)
```

## Top played games

Which games have the highest average playing time in the past two weeks? In the following graph, it can be seen that *Clicker Heroes* (released in 2015) has an average playtime of about 80 hours. That is 40 hours per week, a full-time job.

```{r}
video_games %>%
  top_n(16, average_playtime) %>%
  mutate(game = glue(""{game} ({lubridate::year(release_date)})"")) %>%
  mutate(game = fct_reorder(game, average_playtime)) %>%
  ggplot(aes(x = game, y = average_playtime / 60)) +
  geom_col() +
  coord_flip() +
  xlab(NULL) +
  ylab(""Average played time (hours)"") +
  labs(title = str_wrap(""Average played time for the last two weeks"", 25)) +
  labs(subtitle = ""Only the top 16 averaged played game are shown"")
```

## Temporal evolution of metascore

What is the evolution of the metascore by the publishers? It seems that *high ranked* publishers have pretty constant metascore for their games. However, there is an interesting decreasing trend with *SEGA* that started in 2006.

```{r}
equal_breaks <- function(n = 3, s = 0.05, ...) {
  function(x) {
    # rescaling
    d <- s * diff(range(x)) / (1 + 2 * s)
    seq(min(x) + d, max(x) - d, length = n)
  }
}

video_games %>%
  drop_na(metascore) %>%
  add_count(publisher) %>%
  filter(dense_rank(desc(n)) <= 6) %>%
  group_by(year = lubridate::year(release_date), publisher) %>%
  summarise(mean_metascore = mean(metascore), sd_metascore = sd(metascore)) %>%
  ggplot(aes(x = year, y = mean_metascore)) +
  geom_line(size = 2) +
  facet_wrap(~publisher, scale = ""free_x"") +
  scale_x_continuous(
    labels = function(x) floor(x),
    breaks = equal_breaks(n = 4, s = 0.05)
  ) +
  xlab(NULL) +
  ylab(""Median metascore"") +
  theme(legend.position = ""none"") +
  theme(panel.spacing = unit(2, ""lines"")) +
  labs(title = ""Time series of metascore by publisher"") +
  labs(subtitle = ""Only the six publishers with the highest number of release are shown"")
```

## Price evolution of games

The median prices of the released game appear to decrease between 2015 and 2018. Also, we can see the lowest prices are happening in January, right after Christmas.

```{r}
video_games %>%
  drop_na(release_date) %>%
  group_by(year = lubridate::year(release_date), month = lubridate::month(release_date, label = TRUE)) %>%
  summarise(medan_price = median(price, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = month, fill = medan_price)) +
  geom_tile() +
  scale_fill_viridis_c(option = ""A"", labels = scales::dollar) +
  coord_equal() +
  scale_x_continuous(expand = c(0, 0), breaks = seq(2000, 2020, by = 2)) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(fill = ""Median\nprice (USD)"") +
  xlab(NULL) +
  ylab(NULL) +
  labs(title = ""Price evolution of games"") +
  labs(subtitle = ""Median price calculated monthly and yearly"")
```

There is a clear peak in November 2006 which can be explained by few game prices above 10$.

```{r}
video_games %>%
  filter(
    lubridate::year(release_date) == 2006 &
      lubridate::month(release_date) == 11
  ) %>%
  select(game, release_date, price) %>%
  arrange(desc(price)) %>%
  knitr::kable()
```

## Most expensive games

I was also surprised to see that the most expensive game was almost 600$ USD!

```{r}
video_games %>%
  top_n(5, price) %>%
  mutate(game = glue(""{game} ({lubridate::year(release_date)})"")) %>%
  mutate(game = str_wrap(game, 30)) %>%
  mutate(game = fct_reorder(game, price)) %>%
  ggplot(aes(x = game, y = price)) +
  geom_col() +
  coord_flip() +
  xlab(NULL) +
  ylab(""Price (USD)"") +
  labs(title = ""Top priced games"") +
  labs(subtitle = ""Only shows the top 5 most expensive games"") +
  scale_y_continuous(labels = scales::dollar)
```
","2019"
"220",786,"https://github.com/pabrodez/tidytuesday","pabrodez","tidytuesday","2019-07-16/script.R","library(tidyverse)
library(lubridate)
library(ggthemes)
library(grid)

r4ds_members <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")

df <-
  r4ds_members %>%  ## inspiration from https://github.com/andriy-gazin/geowaffle/blob/master/geowaffle.R
  select(date,
         messages_in_public_channels,
         messages_in_private_channels,
         messages_in_d_ms) %>%
  mutate(date = floor_date(date, ""month"")) %>%
  gather(""type_msg"", ""n_msg"", -date) %>%
  group_by(date, type_msg) %>%
  summarise(n_msg = sum(n_msg)) %>%
  mutate(total_msg = sum(n_msg)) %>%
  group_by(type_msg, add = TRUE) %>%
  summarise(prop_msg = floor(n_msg / total_msg * 100)) %>%
  group_by(type_msg, add = TRUE) %>%
  group_modify(.f = ~ slice(.x, rep(1, .x$prop_msg))) %>%
  select(-prop_msg) %>%
  arrange(date, type_msg) %>%
  ungroup() %>%
  group_by(date) %>%
  group_modify(.f = ~ {
    bind_cols(type_msg = .x$type_msg, head(expand.grid(x = 1:10, y = 1:10), nrow(.x)))
  }) %>%
  ungroup() %>%
  mutate(date = factor(strftime(date, ""%b %y""),
                       levels = strftime(seq.Date(
                         min(.$date), max(.$date), ""months""
                       ), ""%b %y"")))


plot_r4ds <- ggplot(df, aes(x = x, y = y, fill = type_msg)) +
  geom_tile(alpha = .5) +
  facet_wrap( ~ date) +
  coord_fixed(ratio = 1.5 / 1) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 12)) +
  scale_fill_solarized(
    label = c(""Direct\nmessages"", ""Private\nchannels"", ""Public\nchannels""),
    guide = guide_legend(
      title = NULL,
      label.position = ""bottom"",
      label.hjust = 0
    )
  ) +
  labs(title = ""How does the R4DS community message?"",
       caption = ""Data: R4DS tidytuesday | Graphic: @pabrodez"") +
  theme_void() +
  theme(
    text = element_text(color = ""#6b634e"", family = ""Ubuntu Mono""),
    panel.background = element_rect(fill = ""#ffefbf""),
    plot.background = element_rect(fill = ""#ffefbf""), 
    legend.direction = ""horizontal"",
    legend.spacing.x = unit(.1, ""cm""),
    legend.key.height = unit(.1, ""cm""),
    legend.position = c(.5, 1.1),
    strip.text = element_text(hjust = 0.1, vjust = 1, size = 10),
    plot.margin = margin(.5, 1, .5, 1, unit = ""cm""),
    plot.title = element_text(margin = margin(t = 1, b = 4, unit = ""cm""), hjust = .5, size = 16, face = ""bold""),
    plot.caption = element_text(margin = margin(t = 2, unit = ""cm""), size = 10)
  )

plot_r4ds <- ggplotGrob(plot_r4ds)  ## code from https://stackoverflow.com/questions/48199791/rounded-corners-in-ggplot2
bg <- plot_r4ds$grobs[[1]]
round_bg <- roundrectGrob(x=bg$x, y=bg$y, width=bg$width, height=bg$height,
                          r=unit(0.1, ""snpc""),
                          just=bg$just, name=bg$name, gp=bg$gp, vp=bg$vp)
plot_r4ds$grobs[[1]] <- round_bg

ggsave(""./tidytuesday/2019_07_16.png"", plot_r4ds, height = 29, width = 21, units = ""cm"", dpi = ""retina"")
","2019"
"221",787,"https://github.com/pabrodez/tidytuesday","pabrodez","tidytuesday","2019-07-30/2019_07_30.R","library(tidyverse)
library(janitor)
library(lubridate)
library(cowplot)

# clean dataset from lizawood's github
url <- ""https://raw.githubusercontent.com/lizawood/apps-and-games/master/PC_Games/PCgames_2004_2018_raw.csv""

# read in raw data
raw_df <- url %>% 
  read_csv() %>% 
  janitor::clean_names() 

# clean up some of the factors and playtime data
clean_df <- raw_df %>% 
  mutate(price = as.numeric(price),
         score_rank = word(score_rank_userscore_metascore, 1),
         average_playtime = word(playtime_median, 1),
         median_playtime = word(playtime_median, 2),
         median_playtime = str_remove(median_playtime, ""\\(""),
         median_playtime = str_remove(median_playtime, ""\\)""),
         average_playtime = 60 * as.numeric(str_sub(average_playtime, 1, 2)) +
           as.numeric(str_sub(average_playtime, 4, 5)),
         median_playtime = 60 * as.numeric(str_sub(median_playtime, 1, 2)) +
           as.numeric(str_sub(median_playtime, 4, 5)),
         metascore = as.double(str_sub(score_rank_userscore_metascore, start = -4, end = -3))) %>% 
  select(-score_rank_userscore_metascore, -score_rank, -playtime_median) %>% 
  rename(publisher = publisher_s, developer = developer_s) %>% 
  mutate(release_date = as.Date(release_date, ""%b %e, %Y""))

# top 5 publishers
top_publishers <- select(clean_df, publisher) %>% 
  na.omit() %>% 
  count(publisher) %>% 
  top_n(5) %>% 
  inner_join(., clean_df, by = ""publisher"") 

# plot
mean_price_plot <- 
  top_publishers %>% 
  group_by(publisher, release_year = year(release_date)) %>% 
  summarise(mean_year_price = mean(price, na.rm = TRUE)) %>% 
  ggplot(aes(y = publisher, x = release_year, fill = mean_year_price)) +
  geom_tile(height = .15) +
  scale_fill_continuous(low = ""#543f43"", high = ""#9e767d"", 
                        name = ""Mean price"", 
                        guide = guide_legend(label.position = ""bottom"", title.position = ""top"", title.hjust = .5)) +
  scale_x_continuous(breaks = 2004:2018, labels = function(x) substr(x, 3, 4), limits = c(2003, 2019)) +
  coord_polar() +
  ylim(letters[1], unique(top_publishers$publisher)) +  ## create dummy levels of discrete scale to create space between center and first level
  annotate(""segment"", x = seq(2003.5, 2017.5, 1), y = 2, xend = seq(2003.5, 2017.5, 1), yend = 6, alpha = .1) +
  theme_void() +
  theme(text = element_text(color = ""#CCCCCC"", family = ""Avant Garde""),
        plot.background = element_rect(fill = ""transparent""), 
        panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        legend.position = ""bottom"", 
        legend.key.height = unit(1, ""mm""),
        legend.spacing.x = unit(4, ""mm""))

legend_price <- get_legend(mean_price_plot)
mean_price_plot <- mean_price_plot + theme(legend.position = ""none"")

main_circle_plot <- 
  top_publishers %>% 
  group_by(publisher, release_year = year(release_date)) %>% 
  summarise(n = n()) %>% 
  ungroup() %>% 
  ggplot(aes(x = release_year, y = publisher, fill = n)) +
  geom_tile(height = .25) +
  scale_fill_continuous(low = ""#3f3f54"", high = ""#8d8eb7"",
                        breaks = c(10, 30, 60, 90), 
                        name = ""Games released"",
                        guide = guide_legend(label.position = ""bottom"", title.position = ""top"", title.hjust = .5)) +
  scale_x_continuous(breaks = 2004:2018, labels = function(x) substr(x, 3, 4), limits = c(2003, 2019)) +
  geom_text(aes(label = publisher, x = 2018.55), vjust = 0.5, hjust = 0, color = ""#CCCCCC"", family = ""Avant Garde"", size = 4) +
  coord_polar() +
  ylim(letters[1:10], unique(top_publishers$publisher)) +  ## create dummy levels of discrete scale to create space between center and first level
  annotate(""segment"", x = seq(2003.5, 2017.5, 1), y = 11, xend = seq(2003.5, 2017.5, 1), yend = 15, alpha = .1) +
  labs(title = ""Games released and mean price by year by top 5 publishers"",
       caption = ""Source: Steam Spy | Graphic: @pabrodez"") +
  theme_minimal() +
  theme(text = element_text(color = ""#CCCCCC"", family = ""Avant Garde""),
        plot.background = element_rect(fill = ""#405450""), 
        panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_text(margin = margin(t = -5, unit = ""mm""), color = ""#CCCCCC""),
        legend.position = ""bottom"", 
        legend.key.height = unit(1, ""mm""),
        legend.spacing.x = unit(4, ""mm""),
        plot.margin = margin(.5, 1, .5, 1, unit = ""cm""),
        plot.caption = element_text(margin = margin(t = 100)),
        plot.title = element_text(hjust = .5, margin = margin(t = 25, b = 30)))

legend_games <- get_legend(main_circle_plot)
main_circle_plot <- main_circle_plot + theme(legend.position = ""none"")

arranged_plot <- 
  ggdraw() +
  draw_plot(main_circle_plot, 0, 0, 1, 1) +
  draw_plot(mean_price_plot, .225, .245, .55, .55) + ## adjusting position has been a source of affliction 
  draw_plot(legend_price, .2, .1, .1, .1) +
  draw_plot(legend_games, .7, .1, .1, .1)

ggsave(""./tidytuesday/2019_07_30.png"", plot = arranged_plot, height = 11, width = 9, dpi = ""retina"")
","2019"
"222",788,"https://github.com/pabrodez/tidytuesday","pabrodez","tidytuesday","2019-09-24/2019_09_24.R","library(tidyverse)
library(ggforce)
library(scales)

school_diversity <-
  readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv""
  ) %>%
  set_names(tolower)

## cut prop of white into 0-25, 25-50, etc. groups in first and second school years
df <-
  school_diversity %>%
  select(leaid, school_year, white) %>% 
  group_by(leaid) %>%
  mutate(n = n()) %>%
  ungroup() %>%
  filter(n == 2) %>% 
  select(-n) %>% 
  pivot_wider(names_from = ""school_year"", values_from = ""white"") %>%
  mutate(perc_diff = `2016-2017` - `1994-1995`) %>% 
  mutate(perc_group_94 = cut_width(`1994-1995`, 25, boundary = 0, closed = ""left""),
         perc_group_17 = cut_width(`2016-2017`, 25, boundary = 0, closed = ""left"")) 

plot_schools <- 
  df %>% 
  ggplot() +
  geom_curve(aes(
    x = -10,
    y = `1994-1995`,
    xend = `2016-2017`,
    yend = -30,
    color = perc_diff
  ),
  curvature = -0.4,
  size = .1,
  ncp = 10) +
  scale_x_continuous(expand = expand_scale(mult = c(0, .01)),
                     labels = function(x) paste0(x, ""%"")) +
  scale_y_continuous(breaks = seq(0, 100, 25),
                     labels = function(x) paste0(x, ""%""),
                     expand = expand_scale(mult = c(0, .2))) +
  scale_color_gradient2(low = ""#004B40"", mid = ""#F6F6F6"", high = ""#533600"",
                        breaks = seq(-100, 100, 50),
                        limits = c(-100, 100),
                        labels = paste0(seq(-100, 100, 50), ""%""),
                        guide = guide_colorbar(title = ""Change in % units"",
                                               title.position = ""top"",
                                               title.hjust = .5,
                                               barheight = unit(2, ""mm""),
                                               barwidth = unit(50, ""mm""))) +
  facet_col(~ perc_group_94) +
  labs(x = ""2016-2017"", y = ""1994-1995"", 
       title = ""Change in proportion of white students\nin schools from 1994-95 to 2016-17"",
       caption = ""Graphic: @pabrodez | Source: The Washington Post"") +
  theme_minimal(base_family = ""Cabin"") +
  theme(strip.text = element_blank(),
        panel.grid.major.x = element_line(size = rel(.5), color = ""grey70""),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.spacing.y = unit(.5, ""cm""),
        plot.background = element_rect(fill = ""grey85""),
        panel.border = element_rect(color = ""transparent"", fill = ""transparent""),
        legend.position = ""top"",
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.direction = ""horizontal"", legend.spacing.x = unit(0, units = ""cm""),
        plot.margin = margin(0, 1, 0, 0.5, unit = ""cm""),
        plot.caption = element_text(margin = margin(t = 1, b = .5, unit = ""cm"")),
        plot.title = element_text(margin = margin(t = 1, b = 1, unit = ""cm""), 
                                  hjust = .5, lineheight = 1.5, face = ""bold"", color = ""grey40"", size = 16)) 

ggsave(plot = plot_schools, filename = ""2019_09_24.png"", height = 10, width = 5, dpi = ""retina"")
","2019"
"223",789,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-04-23-anime.R","library(tidyverse)
library(ggthemes)

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

score_summary <- tidy_anime %>%
     filter(!is.na(studio)) %>% 
     group_by(studio) %>%
     summarise(
          n = n(),
          score_mean = mean(score, na.rm = TRUE),
          scored_by_mean = mean(scored_by, na.rm = TRUE),
          ) %>% 
     ungroup()

plot <- ggplot(score_summary, aes(n, score_mean)) +
     geom_point(aes(size = scored_by_mean), alpha = 0.7,
                show.legend = FALSE) +
     geom_smooth(se = FALSE, color = ""dimgray"") +
     scale_x_log10() +
     scale_color_viridis(option = ""A"") +
     labs(title = ""Do Bigger Studios Make Higher Rated Anime?"",
          subtitle = ""Point size correlates with number of user ratings"",
          x = ""Number of Titles from Studio"",
          y = ""Average Rating"",
          caption = ""Data: MyAnimeList \nVisualization: @frau_dr_barber"") +
     theme_solarized() +
     theme(plot.title = element_text(color = ""black""),
          plot.subtitle = element_text(size = 9),
          plot.caption = element_text(size = 7))

ggsave(""studio_rating.png"", height = 4, width = 5, units = ""in"")
","2019"
"224",790,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-04-30_bird-collisions.R","library(tidyverse)
library(lubridate)

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

plot <- bird_collisions %>%
     mutate(year = lubridate::year(date)) %>%
     ggplot(aes(year)) +
     geom_bar(aes(fill = fct_infreq(habitat) %>% fct_rev()), 
              position = ""stack"") +
     geom_hline(yintercept = 0, color = ""white"") +
     scale_fill_manual(values = c(""#FFF5EE"", ""#B5D7A6"", ""#197230"")) +
     labs(x = ""Year"", y = ""Number of Collisions"",
          title = ""Bird-Window Collisions in Chicago: 1978-present"",
          subtitle = ""Overall increase in the number of collisions, with forest-living birds showing a disproportionate increase"",
          fill = ""Natural Habitat:   "",
          caption = ""Visualization: @frau_dr_barber
          Source: https://doi.org/10.1098/rspb.2019.0364"") +
     theme(plot.background = element_rect(fill = ""#B3DDF2""),
           panel.background = element_rect(fill = ""#B3DDF2""),
           legend.background = element_rect(fill = ""#B3DDF2""),
           axis.text = element_text(size = 12),
           axis.title = element_text(size = 14),
           plot.title = element_text(size = 14, face = ""bold""),
           legend.position = c(0.12, 0.79),
           axis.ticks = element_blank(),
           panel.grid.major.x = element_blank(),
           panel.grid.minor.x = element_blank(),
           panel.grid.minor.y = element_blank()
           ) 

ggsave(""bird_collisions.png"", dpi = ""retina"", height = 5, width = 8, units = ""in"")
","2019"
"225",791,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-05-07_teacher-ratios.R","library(tidyverse)
library(paletteer)
library(ggthemes)
library(patchwork)

# Datasets ----
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

Europe_countries <- c(""Albania"", ""Andorra"", ""Austria"",  ""Belarus"",
                      ""Belgium"", ""Bosnia and Herzegovina"", ""Bulgaria"", 
                      ""Croatia"", ""Cyprus"", ""Czech Republic"", ""Denmark"", 
                      ""Estonia"",""Finland"", ""France"", ""Germany"", ""Greece"", 
                      ""Hungary"", ""Ireland"", ""Italy"", ""Iceland"", ""Kosovo"", 
                      ""Latvia"", ""Liechtenstein"",""Lithuania"", ""Luxembourg"", 
                      ""Malta"", ""Moldova"", ""Montenegro"", ""Monaco"", ""Macedonia"", 
                      ""Netherlands"", ""Norway"", ""Poland"", ""Portugal"", 
                      ""Romania"", ""San Marino"", ""Serbia"",""Slovakia"", ""Slovenia"",
                      ""Spain"", ""Sweden"", ""Switzerland"", ""Ukraine"", ""UK"")

map_data <- map_data(""world"") 
     
#fix country names to match names in Map database
student_ratio <- student_ratio %>% 
     mutate(
          country = str_replace_all(country, c(""Czechia"" = ""Czech Republic"",
                                               ""United Kingdom of Great Britain and Northern Ireland"" = ""UK"",
                                               ""Russian Federation"" = ""Russia"",
                                               ""Republic of Moldova"" = ""Moldova"",
                                               ""The former Yugoslav Republic of Macedonia"" = ""Macedonia"")),
          indicator = factor(indicator, levels = c(""Pre-Primary Education"",
                                                   ""Primary Education"",
                                                   ""Lower Secondary Education"",
                                                   ""Upper Secondary Education"",
                                                   ""Secondary Education"",
                                                   ""Post-Secondary Non-Tertiary Education"",
                                                   ""Tertiary Education""
          ))
     )
# collapse educaiton levels to combine lower and upper secondary
student_ratio_collapse <- student_ratio %>% 
     mutate(indicator = fct_collapse(indicator, 
                                     ""Secondary Education"" = c(""Lower Secondary Education"", ""Upper Secondary Education"",
                                                               ""Secondary Education""),
                                     ""Post-secondary Education"" = c(""Post-Secondary Non-Tertiary Education"",
                                                                    ""Tertiary Education""))
     )

# Map of Primary Education Class Sizes ----
primary <- student_ratio_collapse %>% 
     filter(country %in% Europe_countries, indicator == ""Primary Education"",
            country != ""Iceland"") %>% #sorry Iceland
     group_by(country) %>% 
     summarise(
          n = n(),
          average = mean(student_ratio, na.rm = TRUE)
     ) 

plot_primary <- primary %>% 
     left_join(map_data, by = c(""country"" = ""region"")) %>% 
     ggplot(aes(x = long, y = lat)) +
     geom_polygon(aes(fill = average, group = group), color = ""black"", size = 0.2) +
     coord_map(""mollweide"", ylim = c(30, 72)) +
     theme_economist() +
     labs(x = """",
          y = """",
          fill = ""Student-to-teacher ratio"",
          title = ""Primary Education\n(ISCED 1)"") +
     scale_fill_paletteer_c(""ggthemes"", ""Red-Green-White Diverging"", -1,
                            breaks = c(6, 9, 12, 15, 18)) +
     theme(axis.line.x = element_blank(),
           axis.text = element_blank(),
           axis.ticks = element_blank(),
           panel.grid = element_blank(),
           legend.position = ""bottom"",
           legend.direction = ""horizontal"",
           plot.title = element_text(hjust = 0.5, size = rel(1.4)),
           plot.margin = unit(c(0.2,0.2,0.2,0.2),""cm"")
     )

# Map of Secondary Education Class Sizes ---- 
secondary <- student_ratio_collapse %>% 
     filter(country %in% Europe_countries, indicator == ""Secondary Education"",
            country != ""Iceland"") %>% #sorry again Iceland
     group_by(country) %>% 
     summarise(
          n = n(),
          average = mean(student_ratio, na.rm = TRUE)
     ) 

plot_secondary <- secondary %>% 
     left_join(map_data, by = c(""country"" = ""region"")) %>% 
     ggplot(aes(x = long, y = lat)) +
     geom_polygon(aes(fill = average, group = group), color = ""black"", size = 0.2) +
     theme_economist() +
     coord_map(""mollweide"", ylim = c(30, 72)) +
     scale_fill_paletteer_c(""ggthemes"", ""Red-Green-White Diverging"", -1,
                            breaks = c(6, 9, 12, 15, 18)) +
     labs(x = """",
          y = """",
          fill = ""Student-to-teacher ratio"",
          title = ""Secondary Education\n(ISCED 2 & 3)"") +
     theme(axis.line.x = element_blank(),
           axis.text = element_blank(),
           axis.ticks = element_blank(),
           panel.grid = element_blank(),
           legend.position = ""bottom"",
           legend.direction = ""horizontal"",
           plot.title = element_text(hjust = 0.5, size = rel(1.4)),
           plot.margin = unit(c(0.2,0.2,0.2,0.2),""cm"")
     )

# Primary vs. secondary comparison ----
primary_secondary_comparison <- primary %>% 
     inner_join(secondary, by = ""country"") %>% 
     rename(primary = average.x, secondary = average.y) %>% 
     select(country, primary, secondary) %>% 
     mutate(diff = secondary - primary,
            perc_diff = (secondary / primary) - 1
            )

top_5 <- primary_secondary_comparison %>% top_n(5, perc_diff)
bottom_5 <- primary_secondary_comparison %>% top_n(-5, perc_diff)

plot_comparison <- bind_rows(top_5, bottom_5) %>% 
     ggplot(aes(fct_reorder(country, perc_diff), perc_diff)) +
     geom_col() +
     scale_y_continuous(labels = scales::percent_format(accuracy = 1), 
                        position = ""right"") +
     coord_flip() +
     labs(x = """", 
          y = ""Positive values = secondary school\nclasses larger than primary classes\n"",
          title = ""\nCountries with the greatest differences in\nprimary and secondary school class sizes\n\n""
     ) +
     theme_economist() +
     theme(panel.grid.major = element_line(size = 0.45),
           axis.text = element_text(size = rel(1.3)),
           axis.title = element_text(size = rel(1.3)),
           aspect.ratio = 1.4,
           plot.title = element_text(hjust = 0.7, size = rel(1.4))
     )

# Combine plots
grid <- plot_primary + plot_comparison + plot_secondary +
     plot_layout(ncol = 3, width = c(1, 0.6, 1)) +
     plot_annotation(theme = theme_economist(),
                     title = ""Student-to-Teacher Ratios in European Primary and Secondary Schools (2012-2017)"",
                     caption = ""Source: UNESCO
                     Visualization: @Frau_Dr_Barber"")

ggsave(""teacher_ratios.png"", dpi = ""retina"", height = 8, width = 15, units = ""in"")
","2019"
"226",792,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-05-14_nobel-winners.R","library(tidyverse)
library(ggalluvial)
library(paletteer)
library(cowplot)

# get dataset
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

# change historic countries to their modern day equivalents
nobel_winners_fixed <- nobel_winners %>% 
     filter(!is.na(birth_country), !is.na(death_country)) %>% 
     #364 winners are still alive and excluded from this visualization
     mutate(birth_country_modern = str_extract(birth_country, ""\\(([^()]*)\\)""),
            birth_country_modern = substr(birth_country_modern, 2, nchar(birth_country_modern)-1),
            death_country_modern = str_extract(death_country, ""\\(([^()]*)\\)""),
            death_country_modern = substr(death_country_modern, 2, nchar(death_country_modern)-1),
            birth_country = if_else(str_detect(birth_country, ""\\(""), birth_country_modern, birth_country),
            death_country = if_else(str_detect(death_country, ""\\(""), death_country_modern, death_country)
            ) %>%
     select(-birth_country_modern, -death_country_modern) %>%
     # assign Northern Ireland and Scotland to UK and abbrevaite UK and USA
     mutate(birth_country = str_replace_all(birth_country,
                                            c(""Northern Ireland"" = ""UK"",
                                            ""Scotland"" = ""UK"",
                                            ""United Kingdom"" = ""UK"",
                                            ""United States of America"" = ""USA"")),
            death_country = str_replace_all(death_country,
                                            c(""Northern Ireland"" = ""UK"",
                                              ""Scotland"" = ""UK"",
                                              ""United Kingdom"" = ""UK"",
                                              ""United States of America"" = ""USA""))
            ) %>%
     # condense countries to top 6 for less cluttered visualization
     mutate(birth_country = fct_lump(birth_country, 5),
            death_country = fct_lump(death_country, 5))

# time to plot
plot <- nobel_winners_fixed %>%
     filter(category %in% c(""Medicine"", ""Chemistry"", ""Physics"")) %>% 
     select(full_name, birth_country, death_country) %>%
     gather(birth_country, death_country, key = ""Event"", value = ""Country"") %>% 
     mutate(Event = str_replace_all(Event, c(""birth_country"" = ""Place of Birth"",
                                             ""death_country"" = ""Place of Death"")),
            Country = fct_infreq(Country)) %>%
     distinct() %>% 
     ggplot(aes(x = Event, stratum = Country, alluvium = full_name,
                fill = Country, label = Country, y = 1)) +
     geom_flow(alpha = 0.7) +
     geom_stratum(alpha = 0.8, size = 0) +
     geom_text(stat = ""stratum"", size = 4) +
     annotate(""text"", x = 1.75, y = -25, 
              label = ""(Laureates still alive excluded from analysis)"") +
     scale_x_discrete(expand = c(0.1, 0.1), position = ""top"") +
     scale_fill_paletteer_d(ggsci, light_uchicago) +
     labs(x = """", 
          y = ""Number of Nobel Laureates"",
          title = ""Mobility Among Nobel Laureates in the Sciences"",
          caption = ""Source: Kaggle
          Visualization @Frau_Dr_Barber"") +
     theme(
           plot.caption = element_text(size = 9),
           axis.line = element_blank(),
           axis.ticks = element_blank(),
           legend.position = ""none"",
           ) 

save_plot(""nobel.png"", plot, base_height = 4, base_width = 6)
","2019"
"227",793,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-05-27_wine-ratings.R","library(tidyverse)
library(ggridges)
library(ggthemes)

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

wine_color <- function(variety) {
     case_when(
          variety %in% c(""Riesling"", ""Pinot Gris"", ""Sauvignon Blanc"",
                         ""White Blend"", ""Sparkling Blend"", ""Portuguese White"",
                         ""Pinot Grigio"", ""Chardonnay"") ~ ""White"",
          variety %in% c(""Zinfandel"", ""Syrah"", ""Red Blend"", ""Portuguese Red"",
                         ""Bordeaux-style Red Blend"", ""Tempranillo"", ""Pinot Noir"",
                         ""Merlot"", ""Malbec"", ""Cabernet Sauvignon"") ~ ""Red"",
          variety == ""Ros"" ~ ""Ros""
     )
}

# best $20 wines by variety
p1 <- wine_ratings %>% 
     filter(price <= 20) %>%
     mutate(Color = wine_color(variety)) %>%
     add_count(variety) %>% 
     filter(n >= 700) %>% #remove wines with low numbers of reviews for less-cluttered graph
     ggplot(aes(points, fct_reorder(variety, points))) +
     stat_density_ridges(aes(fill = Color), quantile_lines = TRUE, quantiles = 2) +
     scale_fill_manual(values = c(""firebrick"", ""rosybrown2"", ""lightyellow"")) +
     xlim(81, 92) +
     labs(title = ""Best Wines under $20"",
          fill = """",
          caption = ""\nSource: Kaggle
     Visualization @Frau_Dr_Barber"") +
     theme_wsj(color = ""gray"") +
     theme(plot.title = element_text(hjust = 1),
           plot.caption = element_text(size = 10))

ggsave(""wine.png"", p1, dpi = ""retina"", height = 6, width = 5.5, units = ""in"")
","2019"
"228",794,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-06-03_ramen-ratings.R","library(tidyverse)
library(tidytext)
library(widyr)
library(igraph)
library(ggraph)

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

ramen_words <- ramen_ratings %>%
     unnest_tokens(word, variety) %>% 
     anti_join(stop_words, by = ""word"")

top_ramen_words <- ramen_words %>%
     count(word, sort = TRUE) %>%
     head(125)

ramen_words_correlation <- ramen_words %>%
     filter(word %in% top_ramen_words$word) %>% 
     pairwise_cor(word, review_number, sort = TRUE)

set.seed(13)
ramen_words_correlation %>%
     filter(correlation > 0.13) %>% 
     graph_from_data_frame() %>% 
     ggraph(layout = ""fr"") + 
     geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
     geom_node_point(color = ""#C3272B"", size = 3) +
     geom_node_text(aes(label = name), repel = TRUE) +
     labs(title = ""Co-occuring Words in Ramen Flavors"",
          subtitle = ""among the 125 most common words\n"",
          caption = ""\nSource: TheRamenRater.com
          Visualization @Frau_Dr_Barber"") +
     set_graph_style(family = ""Century Schoolbook"") +
     theme_void()+ 
     theme(text = element_text(family = ""Century Schoolbook""),
          plot.title = element_text(hjust = 0.5),
          plot.subtitle = element_text(hjust = 0.5),
          plot.margin = margin(0.25, 0.25, 0.25, 0.25, ""in"")) 

ggsave(""ramen.png"", dpi = 300, width = 7, height = 5, units = ""in"")
","2019"
"229",795,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-07-02_media-franchises.R","library(tidyverse)
library(ggthemes)
library(patchwork)

# load and clean datasets ----
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

#film revenue data from https://www.boxofficemojo.com/
hp_movie_revenue <- read_csv2(""hp_movie_revenue.csv"") %>%
     janitor::clean_names() %>% 
     mutate_at(vars(contains(""gross"")), parse_number) %>% 
     mutate(release = lubridate::mdy(release))

#book revenue from https://en.wikipedia.org/wiki/List_of_best-selling_books
hp_book_revenue <- read_csv2(""hp_book_revenue.csv"") %>% 
     janitor::clean_names()

# graphing ----
house_colors <- c(""#9c1203"", ""#FFC500"", ""#033807"", ""#00165e"", ""#000000"", ""#8A8F81"")

background <- ""#f8f2e4""

#overall revenue graph
overall <- media_franchises %>% 
     filter(str_detect(franchise, ""Harry Potter"")) %>% 
     distinct() %>% 
     mutate(revenue_category = fct_reorder(revenue_category, revenue)) %>% 
     ggplot(aes(revenue_category, revenue, fill = revenue_category)) +
     geom_col(show.legend = FALSE) +
     coord_flip() +
     scale_fill_manual(values = rev(house_colors)) +
     labs(x = """",
          y = ""Revenue\n(in billions)"",
          title = ""Overall"",
          caption = ""Source: Wikipedia"") +
     theme_classic() +
     theme(text = element_text(family = ""Garamond""),
           line = element_blank(),
           panel.background = element_rect(fill = background),
           panel.grid.major.x = element_line(color = ""black"", linetype = ""dotted""),
           axis.title.x = element_text(family = ""AbleNew"", size = rel(1.5)),
           axis.text.y = element_text(size = rel(1.7)),
           plot.title = element_text(family = ""AbleNew"", size = rel(2))
          )

#film revenue graph
film <- hp_movie_revenue %>%
     arrange(release) %>% 
     mutate(title = str_c(c(1:6, ""7a"", ""7b"", ""."", "".""), "". "", title),
            title = fct_reorder(title, release),
            adjusted_gross = adjusted_gross / 10^6) %>% 
     ggplot(aes(fct_rev(title), adjusted_gross)) +
     geom_col(fill = house_colors[1], show.legend = FALSE) + 
     coord_flip() +
     labs(x = """",
          y = ""Adjusted gross revenue\n(in millions)"",
          title = ""Film Revenue"",
          caption = ""Source: Box Office Mojo"") +
     theme_classic() +
     theme(text = element_text(family = ""Garamond""),
           line = element_blank(),
           panel.background = element_rect(fill = background),
           panel.grid.major.x = element_line(color = ""black"", linetype = ""dotted""),
           axis.title.x = element_text(family = ""AbleNew"", size = rel(1.5)),
           axis.text.y = element_text(size = rel(1.5)),
           plot.title = element_text(family = ""AbleNew"", size = rel(2))
     )

#book revenue graph
book <- hp_book_revenue %>% 
     mutate(book = str_c(1:7, "". "", book)) %>% 
     ggplot(aes(fct_rev(book), approximate_sales_million)) +
     geom_col(fill = house_colors[3], show.legend = FALSE) +
     coord_flip() +
     labs(x = """",
          y = ""Approximate sales\n(in millions)"",
          title = ""Books Sales"",
          caption = ""Source: Wikipedia"") +
     theme_classic() +
     theme(text = element_text(family = ""Garamond""),
           line = element_blank(),
           panel.background = element_rect(fill = background),
           panel.grid.major.x = element_line(color = ""black"", linetype = ""dotted""),
           axis.title.x = element_text(family = ""AbleNew"", size = rel(1.5)),
           axis.text.y = element_text(size = rel(1.5)),
           plot.title = element_text(family = ""AbleNew"", size = rel(2)),
           plot.margin = margin(0, 10, 0, 0, ""lines"")
     )

#title & caption
title <- ggplot(data.frame(x = 1, y = 1:10)) +
     labs(x = NULL, y = NULL,
          title = ""The Magical World of Harry Potter Revenue"",
          subtitle = ""The franchise has grossed an estimated 35 billion\nRevenue comes primarily from the box office, books, and merch\n""
          ) +
     theme(line = element_blank(),
           rect = element_rect(fill = ""transparent""),
           plot.title = element_text(family = ""Harry P"", size = rel(6)),
           plot.subtitle = element_text(family = ""AbleNew"", size = rel(2.1)),
           panel.background = element_rect(fill = ""transparent""),
           plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
           panel.border = element_rect(color = ""transparent""),
           axis.text = element_blank())

caption <- ggplot(data.frame(x = 1, y = 1:10)) +
     labs(x = NULL, y = NULL,
          caption = ""Visualization by Frau_Dr_Barber\n(Slytherin House)"") +
     theme(line = element_blank(),
           rect = element_rect(fill = ""transparent""),
           plot.caption = element_text(family = ""AbleNew"", size = rel(1.2)),
           panel.background = element_rect(fill = ""transparent""),
           plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
           panel.border = element_rect(color = ""transparent""),
           axis.text = element_blank())

#combine plots using patchwork
title + 
     (overall + film + book + plot_layout(widths = c(0.95, 0.75, 0.75))) + 
     caption +
     plot_layout(nrow = 3, heights = c(0, 20, 0)) +
     plot_annotation(theme = theme_wsj())

ggsave(""harry_potter.png"", height = 7.5, width = 18, units = ""in"")
","2019"
"230",796,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-07-09_womens-world-cup.R","library(tidyverse)
library(paletteer)

wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
logo <- png::readPNG(""uswnt.png"")
logo <- grid::rasterGrob(logo, interpolate = TRUE) 
usa_blue <- ""#1D2642""
usa_red <- ""#BB222E""
grey_palette <- paletteer_dynamic(""cartography"", ""grey.pal"", 17, direction = 1)
grey_palette <- grey_palette[1:11]

wwc_outcomes %>%
     mutate(
          place = case_when( #assign revere place order for graphing
               round == ""Final"" & win_status == ""Won"" ~ 5,
               round == ""Final"" & win_status == ""Lost"" ~ 4,
               round == ""Third Place Playoff"" & win_status == ""Won"" ~ 3,
               round == ""Third Place Playoff""& win_status == ""Lost"" ~ 2,
               round == ""Quarter Final"" & win_status == ""Lost"" ~ 1
          )
     ) %>%
     filter(!is.na(place)) %>%
     mutate(highlight = if_else(team == ""USA"", ""yes"", ""no"")) %>% 
     ggplot(aes(year, place, group = team)) +
     annotation_custom(logo, xmin = 2003, xmax = 2007, ymin = 3.95, ymax = 4.95) +
     geom_line(aes(color = team), size = 1) +
     geom_point(aes(color = team), size = 6) +
     labs(x = ""World Cup"",
          y = """",
          title = ""\nThe US Women's Team is the Winningest Team\nin World Cup History"",
          subtitle = ""The women's team is more successful and brings in more revenue than the men's team, 
          yet they are paid significantly less - around 38% of what the men make."",
          caption = ""Source: data.world
          Visualization: Frau_Dr_Barber""
     ) +
     geom_text(data = . %>% filter(year == 2019, place > 1), 
               aes(label = team, x = 2021, family = ""Roboto Condensed"")) +
     scale_x_continuous(breaks = c(1991, 1995, 1999, 2003, 2007, 2011, 2015, 2019),
                        expand = c(.05, .05)) +
     scale_y_continuous(labels = c(""5th-8th\n(Quarter Finals)"",
                                   ""4th"", ""3rd"", ""2nd"", ""1st"")) +
     scale_color_manual(values = c(sample(grey_palette, 17, replace = TRUE), usa_red)) +
     theme_minimal() +
     theme(legend.position = ""none"",
           panel.grid.major.y = element_blank(),
           panel.grid.minor = element_blank(),
           text = element_text(color = usa_blue, family = ""Roboto Condensed""),
           axis.text.x = element_text(size = 14),
           axis.text.y = element_text(size = 14),
           axis.title.x = element_text(size = 14),
           plot.title = element_text(size = 18, face = ""bold""),
           plot.margin = margin(0, 1, 0, 0, unit = ""cm""))

ggsave(""wwc.png"")
","2019"
"231",797,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-08-30_simpsons-guest-stars.Rmd","---
title: 'Tidy Tuesday: Simpsons Guest Stars'
date: '2019-08-30'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


```{r load packages, get data}
library(tidyverse)
library(cowplot)

simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")
```


```{r names to graph}
top_stars <- simpsons %>% 
    count(guest_star, name = ""total_n"", sort = TRUE) %>% 
    head(8) 
```


```{r plot extras, echo=FALSE}
simpsons_palette <- c(
    ""#FC0209"", # bart red
    ""#fed90f"", # simpsons yellow
    ""#46732EFF"", # Flanders green 
    ""#0363C3"", # marge blue
    ""#d1b271"", # lightbrownbeige
    ""#7A491E"", # beige 
    ""#000000"",  # black
    ""#424f46""  # greyish-blue
)

# quick but messy (manual) way to get the axis labels how I want
x_labels <- c("""", ""S1"", """", """", """", ""S5"", """", """", """", """",
              ""S10"", """", """", """", """", ""S15"", """", """", """", """",
              ""S20"", """", """", """", """", ""S25"", """", """", """", """", ""S30"",
              """", """", """", """")

y_labels <- c(""Marcia Wallace\n(Edna Krabappel)"", 
              ""Phil Hartman\n(Troy McClure & Others)"",
              ""Joe Mantegna\n(Fat Tony)"",
              ""Maurice LaMache\n(Various Roles)"",
              ""Kelsey Grammer\n(Sideshow Bob)"", 
              ""Frank Welker\n(Various Roles)"",
              ""Jon Lovitz\n(Various Roles)"",
              ""Kevin Michael Richardson\n(Various Roles)"")
```


```{r final plot, fig.width=8, fig.height=5}
simpsons %>%
    count(season, guest_star) %>%
    inner_join(top_stars, by = ""guest_star"") %>% 
    filter(season != ""Movie"") %>% # editorial choice; its not a season
    mutate(guest_star = fct_reorder(guest_star, total_n),
           season = fct_inseq(season)) %>% 
    ggplot(aes(season, guest_star, label = total_n)) +
    geom_point(aes(fill = guest_star, size = n), shape = 23, show.legend = FALSE) +
    geom_text(data = . %>% distinct(guest_star, total_n) %>% arrange(desc(total_n)),
              aes(x = 33.5, y = 8:1, label = total_n), family = ""Akbar"",
              size = 4, hjust = 0.5) +
    annotate(""text"", x = 33.5, y = 8.5, label = ""# epi"", family = ""Akbar"", 
             hjust = 0.5, size = 4) +
    scale_size(range = c(3, 8)) +
    scale_x_discrete(position = ""top"", limits = 0:34, labels = x_labels) +
    scale_y_discrete(labels = rev(y_labels)) +
    labs(x = NULL, y = NULL,
         title = ""The Most Frequent Simpsons Guest Stars by Season"",
         caption = ""source: Wikipedia
         Visualization @Frau_Dr_Barber""
         ) +
    scale_fill_manual(values = rev(simpsons_palette)) +
    theme_minimal_grid(font_family = ""Akbar"") +
    theme(plot.title.position = ""plot"") #low this new feature of ggplot
```
","2019"
"232",798,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-09-17_National-park-visits.R","library(tidyverse)

# get data
park_visits <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-17/national_parks.csv"")
centroids <- read_csv(""~/Downloads/National_Park_Service__Park_Unit_Centroids.csv"") %>% 
    rename_all(tolower) %>% #downloaded from https://public-nps.opendata.arcgis.com/datasets/national-park-service-park-unit-centroids
    mutate(label = str_extract(unit_name, ""^.*(?=(National Park))""))
usa_df <- map_data(""state"")

# calculate average visits per year for last 10 years
ave_visits <- park_visits %>%
    mutate(year = parse_integer(year)) %>% 
    filter(year >= 2006, unit_type == ""National Park"") %>%
    group_by(unit_code) %>% 
    summarise(ave_visit = mean(visitors, na.rm = TRUE)) %>% 
    ungroup() 

# graph
centroids %>% 
    left_join(ave_visits) %>%
    filter(!state %in% c(""AK"", ""HI"")) %>% 
    ggplot(aes(x, y)) +
    geom_polygon(data = usa_df, aes(long, lat, group = group),
                 fill = ""white"", color = ""#99542c"", size = 0.25) +
    geom_point(aes(size = ave_visit), color = ""#2d4b1e"") +
    ggrepel::geom_text_repel(data = . %>% filter(!unit_code %in% c(""GRSM"", ""DRTO"", ""VIIS"")),
                             aes(label = label), family = ""National Park"", size = 2.1) +
    coord_map(xlim = c(-123, -69.5), ylim = c(25, 48.1)) +
    scale_size_area(""Average annual visits"", breaks = c(1e+7, 3e+7, 5e+7),
                    labels = c(""10 million"", ""30 million"", ""50 million"")) +
    annotate(""text"", x = -77, y = 30, size = 4, hjust = 0,
             family = ""National Park"", color = ""white"",
             label = glue::glue(""Great Smoky
                        Mountains NP
                        sees the most
                        visitors annually"")
    ) +
    annotate(""segment"", xend = -81.75, yend = 35.3, x = -75, y = 33.75,
             arrow = arrow(length = unit(0.03, ""npc"")),
             color = ""#2d4b1e"", size = 0.5) +
    labs(title = ""The United States National Parks"",
         subtitle = ""Point size corresponds to average number of visitors (2006-2016)"") +
    # National Park font downloaded from https://nationalparktypeface.com/
    cowplot::theme_map(font_size = 16, rel_tiny = 0.75,
                       font_family = ""National Park"") + 
    theme(text = element_text(color = ""white""),
          legend.position = ""bottom"",
          legend.justification = ""center"",
          plot.background = element_rect(fill = ""#99542c"")
    ) 

ggsave(""national_parks.png"", width = 7, height = 5)
","2019"
"233",799,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-11-05_commuting.R","library(tidyverse)
library(cowplot)
library(glue)

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

commute_mode %>%
    filter(mode == ""Bike"", !is.na(state_region)) %>%
    mutate(
        fraction = percent / 100,
        city_size = glue::glue(""{city_size}
                               cities""),
        state_region = fct_reorder(state_region, fraction)
    ) %>% 
    ggplot(aes(city_size, fraction)) +
    geom_boxplot(aes(fill = city_size), notch = TRUE, outlier.size = 1,
                 color = ""white"", show.legend = FALSE) +
    scale_y_continuous(trans = ""log10"",
                       labels = scales::percent) +
    facet_wrap(vars(fct_rev(state_region)), nrow = 1) +
    labs(x = """", y = NULL,
         title = ""Nobody Bikes to Work in the US - less than 1%!"",
         subtitle = ""More people cycle to work in bigger cities and in the western US. Ridership is equally low throughout the south."",
         caption = glue::glue(""Source: ACS - US Census
                              Visualization @frau_dr_barber"")) +
    cowplot::theme_minimal_hgrid(font_family = ""Roboto Condensed"",
                                 rel_tiny = 10/14) +
    cowplot::panel_border() +
    scale_fill_manual(values = c(""#81A7A6"", ""#5F799C"", ""#374685"")) +
    theme(plot.background = element_rect(fill = ""grey23""),
          axis.text = element_text(color = ""grey85""),
          text = element_text(color = ""white""))

ggsave(here::here(""plots"", ""bike_commuting.png""))
","2019"
"234",801,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-08-06","jas1","tidytuesday","jas1_weeks/2019/2019-08-06/readme.rmd","
---
title: ""Tidy tuesday challenge: Week 2019-08-06 Bob Ross""
author: ""julio""
date: ""2019-08-04""
output: html_document
---

# Tidy tuesday challenge:  Week 2019-08-06 Bob Ross

keep it simple:

## Objectives: 

**general:**

* work on data, 
* practice, 
* get better on your workflow,
* get better on your skills: import, tidy , understand( transform, visualize,model ) , communicate


** this week **

### Data:
 
 Week 2019-08-06 Bob Ross
 
### objectives:

Seen voronoi & brickr stuff, really liked it.

AI art its quite interesting , nevertheless got short time to invest.

initial some data explore, and last the voronoi.

## details:


## import data
```{r echo=FALSE,message=FALSE,warning=FALSE}
library(magrittr) # para el %T>%
library(tidyverse)
# library(sf)
library(dplyr)
library(stringr)#;
# library(rebus)#; install.packages('rebus')
# library(tidytext)
library(prophet)


# install.packages(""Rcpp"")
# remotes::install_github(""tylermorganwall/rayshader"")
# library(rayshader)
library(lubridate)
library(ggforce)
library(ggrepel)

library(arules)#install.packages('arules')
library(arulesViz)#install.packages('arulesViz')
library(igraph)

```


```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")
bob_ross_processed <- bob_ross %>% 
    janitor::clean_names() %>% 
    mutate(title=str_remove_all(title,'""'))
```

# explore data


```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed %>% head()

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed %>% glimpse()

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed %>% skimr::skim()


```

we can see that we got a lot with "" tree "" a nd another column "" trees"" they might be the same stuff. 
lets check.

```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed_trees <- bob_ross_processed %>% 
    mutate(id=paste0(episode,title)) %>% 
    select(id,tree,trees) %>% filter(trees==1 | tree == 1)

bob_ross_processed_trees %>% select(tree,trees) %>% table()

bob_ross_processed_trees %>% filter(trees==0)
bob_ross_processed_trees %>% filter(trees==1)

```

after looking at data, we see there is no tree alone, 
when tree exist, might or might not be with a group of them.

then decided to doble check at the internet to see the images. 
to my criteria there are some ""TREES==0"" that are not that way.
ex: WINTER CABIN ; WESTERN EXPANSE, etc

also ""TREE"" alone, do not exist., so ill be droping ""TREES"", and keep tree
or ... or can keep the focus on this difference as it took a while :p 


# elements thogether >> association rules :D 

as we need to see the problem as transactions
we can see every paint as a transaction, and every element as a item. 
the collection of elements its the itemset of the transaction

ive done this before and will be cool to explore this on an unknown subject :)

based on previous work and other references: 

- https://twitter.com/jspairani/status/1083717747173928960
- https://michael.hahsler.net/research/arules_RUG_2015/demo/#association-rules
- https://www.datacamp.com/community/tutorials/market-basket-analysis-r
- https://stackoverflow.com/questions/44677670/exporting-a-network-produced-with-visnetwork-for-r

first we need to make the transactions object 

```{r echo=FALSE,message=FALSE,warning=FALSE}
elements_picture <- bob_ross_processed %>%  
    tibble::rownames_to_column() %>% # to get transactions id's
    mutate(rowname=as.integer(rowname)) %>% 
    rename(r_id=rowname) %>% 
    gather(element,appear,-episode,-title,-r_id) %>% 
    filter(appear==1)




transactions <- elements_picture %>% select(r_id,element) %>% arrange(r_id) %>% rename(itemset=element)
# elements_picture_graph_data <- elements_picture %>% select(TITLE,ELEMENT)

data_file <- here::here(""jas1_weeks"",""2019"",""2019-08-06"",""tx_file.txt"")
write.csv(transactions,file = data_file,row.names=FALSE,fileEncoding = ""UTF-8"")

tx <- read.transactions(data_file ,
                        format = ""single"",
                        sep = "","",
                        cols = c(""r_id"", ""itemset""),
                        rm.duplicates = TRUE)

# transactions %>% distinct(itemset)

```

after getting the transactions loaded, want to make default package item frequency plot but as ggplot.

```{r echo=FALSE,message=FALSE,warning=FALSE}

# summary(tx)
# itemFrequencyPlot(tx,topN=20,type=""absolute"")
# itemFrequencyPlot(tx,topN=20,type=""relative"")

item_freq <- tx %>% itemFrequency()
item_freq_names <- item_freq %>% names()
tx_for_plot <- data.frame(element=item_freq_names,freq=item_freq,stringsAsFactors = FALSE) %>%
    as_tibble() %>%
    mutate(element=fct_reorder(element,freq))
    
set.seed(42)
freq_elements_plot <- tx_for_plot %>% 
ggplot(aes(element,freq,fill=element)) + 
geom_col() + 
scale_y_continuous(breaks = seq(0,1,0.25))+
theme_light()+
theme(legend.position = ""none"")+
coord_flip()+
    labs(title=""Frequency of Elements of Bob Ross paintings"",
         # subtitle="""",
         x="""",
         y=""frequency"",
         caption = ""#TidyTuesday""
         )
freq_elements_plot
ggsave(freq_elements_plot,filename = ""freq_elements_plot.png"",height = 8,width = 6)
```

## items as absolute values

```{r echo=FALSE,message=FALSE,warning=FALSE}

# summary(tx)
# itemFrequencyPlot(tx,topN=20,type=""absolute"")
# itemFrequencyPlot(tx,topN=20,type=""relative"")

item_freq_count <- tx %>% itemFrequency(type=""absolute"")
item_freq_names_count <- item_freq_count %>% names()
tx_for_plot_count <- data.frame(element=item_freq_names,count=item_freq_count,stringsAsFactors = FALSE) %>%
    as_tibble() %>%
    mutate(element=fct_reorder(element,count))
    
set.seed(42)
freq_elements_plot_count <- tx_for_plot_count %>% 
ggplot(aes(element,count,fill=element)) + 
geom_col() + 
scale_y_continuous(breaks = seq(0,375,25))+
theme_light()+
theme(legend.position = ""none"",
      axis.text.x=element_text(angle=90))+
coord_flip()+
    labs(title=""Count of Elements of Bob Ross paintings"",
         #subtitle="""",
         x="""",
         y="""",
         caption = ""#TidyTuesday""
         )
freq_elements_plot_count
ggsave(freq_elements_plot_count,
       filename = ""freq_elements_plot_count.png"",
       height = 8,width = 5)
```

# association rules rules

```{r echo=FALSE,message=FALSE,warning=FALSE}

rules <- apriori(tx,
             parameter=list(supp=0.01,
                            conf=0.8,
                            maxlen=10))

subset_rules <- which(colSums(is.subset(rules, rules)) > 1)
length(subset_rules)
no_redundant_rules <- rules[-subset_rules] # remove subset rules.
length(no_redundant_rules)
# rules

 # inspect(sort(rules))

# inspect(head(sort(rules), n=10))
#


# plot(head(sort(rules, by = ""lift""), n=50),
#      method = ""graph"",
#      control=list(cex=.8))
# 

element_visnet <- plot(head(sort(no_redundant_rules, by = ""lift""), n=50),
     method = ""graph"",
     engine=""htmlwidget"",
     control=list(cex=.8))

element_visnet %>% 
    visNetwork::visSave( file = ""bob_ross_rules.html"")
# visNetwork::visExport(type = ""png"", name = ""network"",
#   label = paste0(""Export as png""), background = ""#fff"",
#   float = ""right"", style = NULL, loadDependencies = TRUE)


```


# tried some graph stuff till i remembered arules :D

```{r echo=FALSE,message=FALSE,warning=FALSE}

# graph_from_picture <- igraph::graph_from_data_frame(elements_picture_graph_data) %>% as_tbl_graph()
# igraph::V(graph_from_picture)$type <- igraph::V(graph_from_picture)$name == elements_picture_graph_data$TITLE
# igraph::V(graph_from_picture)$color <- if_else(igraph::V(graph_from_picture)$type == 1,""#FF0000"",""#0000FF"")
# 
# 
# # visNetwork::visIgraph(igraph_network)
# visNetwork::visIgraph(graph_from_picture) %>% 
#     visNetwork::visIgraphLayout(randomSeed = 42, layout=""layout_as_bipartite"")
# 
# 
# 
#     ggplot(aes(x=TITLE,y=element,fill=as.factor(appear)))+
#     geom_tile()+
#     theme(axis.text.x = element_text(angle=90))
    # labs()
```

## bob ross voronoi

code from: https://github.com/othomantegazza/code-tidytuesday/blob/master/2-32-painting-voronoi.R
he inspired on: https://chichacha.netlify.com/2018/11/12/utilizing-k-means-to-extract-colours-from-your-favourite-images/

wanted to do this at least once, so here to pick a picture: 
i like auroras ... so lets look some samples on google

i didnt like them much, there are better ones :D 

```{r}
bob_ross_processed %>% filter(fire==1)
```



```{r echo=FALSE,message=FALSE,warning=FALSE}
#https://github.com/othomantegazza/code-tidytuesday/blob/master/2-32-painting-voronoi.R
# Most steps are taken form:
# https://chichacha.netlify.com/2018/11/12/utilizing-k-means-to-extract-colours-from-your-favourite-images/


# set up ------------------------------------------------------------------


library(tidyverse)
library(imager)
library(ggvoronoi) # install.packages(""ggvoronoi"")
library(grid)

# background color
bg_color <- ""#E8EDEF""

# Get image ---------------------------------------------------------------

image_path <- ""2-32-bob-ross-sunset.Rdata""


if(!file.exists(image_path)) {
  # img <- load.image(""https://fivethirtyeight.com/wp-content/uploads/2014/04/campfire_banner1.jpg"")
  img <- load.image(""campfire_banner1.jpg"")
  save(img, file = image_path)
} else {
  load(image_path)
}


# analyze -----------------------------------------------------------------

# number of pixel?
dim(img)[1]*dim(img)[2]

# colours: hex value for every pixel
hex_pix <- 
  img  %>% 
  as.data.frame(wide = ""c"") %>% 
  mutate(hexval = rgb(c.1,c.2,c.3))

# luminosity for every pixes
grey_pix <- 
  img %>% 
  grayscale() %>% 
  as.data.frame()

# merge
hex_pix <- 
  hex_pix %>%
  inner_join(grey_pix)


# sample pixels ------------------------------------------------------------

set.seed(42); hex_pix_mini <- 
  hex_pix %>% 
  sample_n(2500, weight = value) # more likely if luminosity is higher 
  
# colors named vectors
# for plotting
pix_colors <- 
  hex_pix_mini %>% 
  pull(hexval) %>% 
  {purrr::set_names(x = .,
                   nm = .)}

# range of axis
range_x <- c(0, dim(img)[1])
range_y <-  c(dim(img)[2], 0)

p <- 
  hex_pix_mini %>% 
  ggplot(aes(x = x,
             y = y)) +
  # geom_point(aes(colour = hexvalue)) +
  ggvoronoi::geom_voronoi(aes(fill = hexval),
                          colour = bg_color,
                          size = .2) +
  scale_y_reverse(limits = range_y,
                  expand = expand_scale(mult = .01)) +
  scale_x_continuous(limits = range_x,
                     expand = expand_scale(mult = .01)) +
  scale_fill_manual(values = pix_colors, guide = FALSE) +
  coord_fixed() +
  theme_void() +
  theme(plot.background = element_rect(fill = bg_color),
        plot.margin = margin(0,0,0,0)) +
    labs(title = ""Voronoi test on: S03E10 - CAMPFIRE"",
         subtitle = ""Bob Ross paint , voronoi code by @othomn, @chisatini"",
         caption = ""#TidyTuesday"")

# svglite::svglite(file = ""plots/2-32-painting-voronoi.svg"")
# p %>% print()
# dev.off()
ggsave(plot = p ,filename = ""voronoi_2.png"")


# decorate plot with grid and save ----------------------------------------
# 
# # png parameters
# img_height <- 2800
# img_width <- 2300
# 
# # position of bottom left corner
# img_x <- .2
# img_y <- .18
# 
# # and plot size
# plot_width <- 1 - img_x - .05
# plot_height <- 1 - img_y - .05
# 
# # save
# png(file = ""2-32-painting-voronoi.png"",
#     height = img_height,
#     width = img_width,
#     res = 300)
# grid.newpage()
# # background
# grid.rect(gp = gpar(fill = ""#838798""))
# # plot
# p %>% print(vp = viewport(x = img_x, y = img_y, 
#                           just = c(0, 0),
#                           height = plot_height,
#                           width = plot_width))
# # side caption
# grid.text(label = str_wrap(""Voronoi tesselation of one of Bob Ross paintigs. Inspired by @chisatini's blog."",
#                            width = 14),
#           x = img_x - .003, y = .945,
#           hjust = 1, vjust = 1, gp = gpar(size = 14, lineheight = 1,
#                                           col = bg_color))
# # signature
# grid.text(label = ""Painting by Bob Ross | Plot by @othomn"",
#           x = .92, y = .1,
#           hjust = 1, vjust = 1, gp = gpar(fontsize = 10, lineheight = 1,
#                                           col = bg_color))
# dev.off()
# 
# 
# # save json for d3 --------------------------------------------------------
# 
# library(jsonlite)
# 
# hex_pix_mini %>% 
#   toJSON() %>%
#   {paste(""var hexpix = "", .)} %>% 
#   cat(file = ""d3/json_data/2-32-painting-voronoi.js"")

```


#tweet: 

2019-08-13 #TidyTuesday #rstats Roman Emperors ! 
Explored time spans of roman emperors. Some birth dates were NA, so imputed somes values based on wikipedia aproximated dates. The ones imputed are commented.
img & code: https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-08-13



# communicate

other stuff that was not on the plot is: 
got the max date of dynasties and eras.

## resources: 

- wikipedia for emperor missing dates.
","2019"
"235",836,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-07-02","jas1","tidytuesday","jas1_weeks/2019/2019-07-02/readme.rmd","
---
title: ""Tidy tuesday challenge: Week 2019-07-02 Media Franchise revenues""
author: ""julio""
date: ""2019-06-25""
output: html_document
---

# Tidy tuesday challenge: Week 2019-07-02 Media Franchise revenues

keep it simple:

## Objectives: 

**general:**

* work on data, 
* practice, 
* get better on your workflow,
* get better on your skills: import, tidy , understand( transform, visualize,model ) , communicate


** this week **

### Data:

Media Franchise revenues

### objectives:

check the data and do something.

## details:


## import data
```{r echo=FALSE,message=FALSE,warning=FALSE}
library(magrittr) # para el %T>%
library(tidyverse)
# library(sf)
library(dplyr)
library(stringr)#;
library(rebus)#; install.packages('rebus')
library(tidytext)

# install.packages(""Rcpp"")
# remotes::install_github(""tylermorganwall/rayshader"")
library(rayshader)


```


```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")
```

# explore data


```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises %>% head()

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
glimpse(media_franchises)

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises %>% skimr::skim()

```



```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises %>% 
    count(creators,owners) %>%
    mutate(creators=fct_reorder(creators,n)) %>% 
    ggplot(aes(x=creators,y=n,fill=owners))+
    geom_col()+
    coord_flip()+
    theme(legend.position = ""none"")

media_franchises %>% 
    count(owners) %>%
    mutate(creators=fct_reorder(owners,n)) %>% 
    ggplot(aes(x=owners,y=n,fill=owners))+
    geom_col()+
    coord_flip()+
    theme(legend.position = ""none"")

media_franchises %>% 
    mutate(year_origin=lubridate::ymd(paste0(year_created,""-01-01""))) %>%
    mutate(year_now=lubridate::ymd(paste0(lubridate::year(lubridate::today()),""-01-01""))) %>% 
    mutate(years_elapsed=lubridate::year(year_now)-lubridate::year(year_origin)) %>% 
    mutate(revenue_years=revenue/years_elapsed*1000) %>% 
    ggplot(aes(x=years_elapsed,
               y=revenue,color=revenue_category))+
    geom_point()

media_franchises %>% 
    mutate(year_origin=lubridate::ymd(paste0(year_created,""-01-01""))) %>%
    mutate(year_now=lubridate::ymd(paste0(lubridate::year(lubridate::today()),""-01-01""))) %>% 
    mutate(years_elapsed=lubridate::year(year_now)-lubridate::year(year_origin)) %>% 
    mutate(revenue_years=revenue/years_elapsed*1000) %>% 
    ggplot(aes(x=years_elapsed,
               y=revenue_years,color=revenue_category))+
    geom_point()
```


```{r echo=FALSE,message=FALSE,warning=FALSE}



data_processed <- media_franchises %>% 
    group_by(franchise) %>% 
    summarise(year_created_min=min(year_created),total_revenue=sum(revenue)) %>% 
    mutate(year_origin=lubridate::ymd(paste0(year_created_min,""-01-01""))) %>%
    mutate(year_now=lubridate::ymd(paste0(lubridate::year(lubridate::today()),""-01-01""))) %>% 
    mutate(years_elapsed=lubridate::year(year_now)-lubridate::year(year_origin)) %>% 
    mutate(revenue_years=total_revenue/years_elapsed*1000) %>% 
    mutate(franchise=fct_reorder(franchise,years_elapsed))
```


```{r echo=FALSE,message=FALSE,warning=FALSE}
background_diff <- ""#bad8df""

plot_out <- data_processed %>%            
    ggplot(aes(x=year_now-(years_elapsed/2),
               y=franchise,
               color=franchise))+
    # geom_col()+
    geom_errorbarh(aes(xmin = year_origin, 
                       xmax = year_now), 
                  size = .5, alpha = 0.8)+
    scale_x_date(date_breaks = ""5 years"",date_labels = ""%Y"")+
    # coord_flip()+
    theme_light()+
    theme(legend.position = ""none"",
          axis.text.x = element_text(angle=90))+
    labs(title=""Which Franchises are longer living?"",
         x="""",y="""",caption=""#tidytuesday"")+
    
    geom_vline(xintercept = lubridate::ymd(c(""1920-01-01"",
                                             ""1930-01-01"",
                                             ""1940-01-01"",
                                             ""1950-01-01"",
                                             ""1960-01-01"",
                                             ""1970-01-01"",
                                             ""1980-01-01"",
                                             ""1990-01-01"",
                                             ""2000-01-01"",
                                             ""2010-01-01"",
                                             ""2020-01-01"")),
               linetype='dashed')+ 
  # Expand y axis scale so that the legend can fit
  scale_y_discrete(
    expand = expand_scale(add=c(0.65,1))
  )     +
    
# rectangle with years.
    geom_rect(
    mapping = aes(xmin = lubridate::ymd(""2022-01-01""), xmax = lubridate::ymd(""2026-01-01"") , 
                  ymin = -Inf, ymax = Inf),
    fill = ""white"",
    color = ""white""
  ) +
  # Add rectangle with correct banground color for the differences
  geom_rect(
    mapping = aes(xmin = lubridate::ymd(""2022-01-01""), xmax = lubridate::ymd(""2026-01-01"") , 
                  ymin = -Inf, ymax = Inf),
    fill = background_diff,
    color = background_diff
  ) +
  # Add Differences values
  geom_text(
    # Bold face
    fontface = ""bold"",
    # Font size
    size = 4,
    # Font Color
    colour = ""black"",
    # Position
    mapping = 
      aes(
        x = lubridate::ymd(""2024-05-01""),
        y = franchise,
        label = years_elapsed
      )
  ) +
  # Insert Title of Differences
  geom_text(
    # Bold face
    fontface = ""bold"",
    # Font size
    size = 4,
    # Cor
    colour = ""#333333"",
    # Set text a little above the dots
    nudge_y = 2,
    # Position
    mapping = 
      aes(
        x = lubridate::ymd(""2024-01-01""),
        y = franchise,
        label = 
          # If Country is Germany, plot values
          ifelse(str_detect(franchise,""Winnie""),
                 # Value_if_True
                 ""Years"",
                 #Value_if_False
                 """"
          )
      )
  )

plot_out

ggsave(filename = ""franchise_ages.png"",plot = plot_out,height = 20,width = 10)

```


#tweet: 

2019-07-02 #TidyTuesday #rstats media franchises! 
Explored which are the longer living media franchises.


# communicate

well almost there, some errors on the years elapsed label :/.

credit of the bar to: 

https://ogustavo.com/post/dotplot-ggplot/





","2019"
"236",837,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-02-26","jas1","tidytuesday","jas1_weeks/2019/2019-02-26/readme.rmd","---
title: ""Tidy tuesday challenge: Week 2019-02-26 french train delays""
author: ""julio""
date: ""2019-03-03""
output: html_document
---

# Tidy tuesday challenge: Week 2019-02-26 french train delays

keep it simple:

## Objectives: 

**general:**

* work on data, 
* practice, 
* get better on your workflow,
* get better on your skills: import, tidy , understand( transform, visualize,model ) , communicate


** this week **

### Data:

this week data its related to PhDs Awarded by Field

### objectives:

- issues on git syhcroing.
- just went to a graph visualization. showing how are linked from/to , and if its tgv as color.

## details:

- selected small trains dataset

## import data

```{r echo=FALSE,message=FALSE,warning=FALSE}
library(dplyr)
# library(Rcpp) #; install.packages(""Rcpp"")
library(skimr) #; install.packages(""skimr"")
# library(circlepackeR) #; devtools::install_github(""jeromefroe/circlepackeR"")
# library(data.tree)  #; install.packages(""data.tree"")

library(igraph)
library(visNetwork)
library(ggplot2)

```



```{r echo=FALSE,message=FALSE,warning=FALSE}
small_trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/small_trains.csv"") 

color_palette <- c(""blue"",""green"",""red"")
uniques_graph <- small_trains %>%    
        rename(from=departure_station) %>%
        rename(to=arrival_station) %>% 
        group_by(from,to) %>% 
        summarize(total_delay=sum(avg_delay_all_departing+avg_delay_all_arriving)) %>% 
        # mutate(is_tgv=str_detect(from,""TGV"")|str_detect(to,""TGV"")) %>% 
        # mutate(color=if_else(is_tgv,'red','blue')) %>%
        mutate(intervals=if_else(total_delay<=2000,""0-2k"",
                                 if_else(total_delay>4000,"">4k"",""2k1-4k""))) %>% 
        mutate(color=case_when (
            total_delay<=2000 ~ color_palette[1],
            total_delay>4000 ~ color_palette[3],
            total_delay>2000 & total_delay<=4000 ~ color_palette[2]))
        


hist(uniques_graph$total_delay)
boxplot(uniques_graph$total_delay)

```


```{r echo=FALSE,message=FALSE,warning=FALSE}
glimpse(small_trains) 


small_trains %>% 
    count(service)

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
skimr::skim(phd_raw) 


```

## tidy

always wante to try circle pack, so there we go: prepare data: deprecated -- shifted to the shiny app of the guy as i wan to have a functional deployable that i can give other people.
not just my pc.

```{r echo=FALSE,message=FALSE,warning=FALSE}
# library(circlepackeR) #; devtools::install_github(""jeromefroe/circlepackeR"")
# 
# phd_processed <- phd_raw %>% filter(year==2008) %>% select(-year) %>%  
#         mutate(path_string = paste(""phds"", broad_field, major_field, field, sep = ""/""))
# # sample: http://shiny.rstudio.com/gallery/submitbutton-demo.html
# # UI
# 
# # library(data.tree)
# # phd_processed_circler <- data.tree::as.Node(phd_processed)
# 
# 
# phd_processed %>% count(field) %>%  filter(n>1)
# 
# phd_processed %>% filter(field==""Environmental toxicologyc"")
# 
# circlepackeR::circlepackeR(phd_raw)
# 
# 
# 
# phd_processed2 <- phd_raw %>% filter(year==2008) %>% select(-year) %>% 
#     mutate(from=) %>% mutate( to="""")
# 
# 
# # Libraries
# library(ggraph)
# library(igraph)
# library(tidyverse)
# library(viridis)
#  
# # We need a data frame giving a hierarchical structure. Let's consider the flare dataset:
# edges=flare$edges
# vertices = flare$vertices
# mygraph <- graph_from_data_frame( edges, vertices=vertices )
#  
# # Control the size of each circle: (use the size column of the vertices data frame)
# # png(""~/Dropbox/R_GG/R_GRAPH/#314_custom_circle_packing1.png"", height = 480, width=480)
# ggraph(mygraph, layout = 'circlepack', weight=""size"") + 
#   geom_node_circle() +
#   theme_void()


```

## visualize

as i want interactive for the shiny app im using package: circlepackeR: canceled.
using the guy shiny app as ive made some stuff with that library before should not be complex.

```{r echo=FALSE,message=FALSE,warning=FALSE}
# library(circlepackeR)
# library(data.tree)
# library(treemap)#;install.packages(""treemap""); install.packages(""httpuv""); install.packages(""mime"")
# 
# data(GNI2014)
# head(GNI2014)
# 
# GNI2014$pathString <- paste(""world"", 
#                             GNI2014$continent, 
#                             GNI2014$country, 
#                             sep = ""/"")
# population <- as.Node(GNI2014)
# 
# circlepackeR(population, size = ""population"", color_min = ""hsl(56,80%,80%)"", 
#              color_max = ""hsl(341,30%,40%)"")


```


## communicate

### issues with git 

remeber any step on command line, you previous gotta be on the repository folder. 
like: 'cd /user/me/git/tidytuesday'

got issues with git syncrho. 
generally use windows desktop , now on linux notebook
i got the repo on dropbox folder. so config of windows its shared on dropbox and autosynchroed.
that causes issues as both computers got different context. 

- on windows got the  autocrlf, to true. 

so when i downloaded from github, it transformed the lf, to crlf > making the linux version see 'differences' just when i downloaded the repo.

to solve this i've set it to false:

git config --global core.autocrlf false

- issues on this computer sychro, on windows i use notepad++ , it wont work right on linux, so as alternative i use atom. 

nevertheless, it is not so happy when using terminal, at least on my experience at setting it as default editor. 
after commiting and filling the message on the editor, and closing it ( file & atom ) , the terminal keeps saying waiting to close ... 

i used this command to set atom as default:

git config --global core.editor ""atom --wait""

i used this one to fall back to default editor on my notebook 
( my default is pluma, you gotta search which is the name of your default editor. )

git config --global core.editor ""pluma""


as i already was in the problem, of getting commited or undone things ... 
i just fall back to previous commit that ive done. 

to know which was i looked at: 

git log

and see the log searching for the commit that i was the last to submit.
then when i see: 
Merge: 75253ed 354de7b

the id to reset its the 1st part '75253ed'

WARNING: THIS WILL DROP WHATEVER YOU HAVE DONE AFTER THAT POINT !

if you decide to move further, to do the reset all you need to go is: 

git reset --hard 75253ed3

Then after that i resinchroed to the current week data, uploads like: 

git pull https://github.com/rfordatascience/tidytuesday.git master

it was quite time consuming to debug this, so ill just go for one interesing visualization and try to reproduce.


### shiny app of graph data using gist

several lesons learnt

- for shiny deploy: https://shiny.rstudio.com/tutorial/written-tutorial/lesson7/
- couldnt make work the URL stuff, so switchetd to gist
- it worked ok from gist. followed the gist tutorial shown there. 
 ","2019"
"237",838,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-02-26","jas1","tidytuesday","jas1_weeks/2019/2019-02-26/shiny_app/app.R","
# imports -----------------------------------------------------------------

library(dplyr)
library(readr)
library(skimr) #; install.packages(""skimr"")
library(igraph)
library(visNetwork)
library(shiny)
library(shinydashboard)
library(stringr)


# load data ---------------------------------------------------------------

# load data
small_trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/small_trains.csv"") 

# filter data
df_for_graph <- small_trains %>% 
    select(departure_station,arrival_station,year,month,journey_time_avg,total_num_trips) %>% 
    rename(from=departure_station) %>% 
    rename(to=arrival_station)


color_palette <- c(""blue"",""green"",""red"")
uniques_graph <- small_trains %>%    
    rename(from=departure_station) %>%
    rename(to=arrival_station) %>% 
    group_by(from,to) %>% 
    summarize(total_delay=sum(avg_delay_all_departing+avg_delay_all_arriving)) %>% 
    # mutate(is_tgv=str_detect(from,""TGV"")|str_detect(to,""TGV"")) %>% 
    # mutate(color=if_else(is_tgv,'red','blue')) %>%
    mutate(intervals=if_else(total_delay<=2000,""0-2k"",
                             if_else(total_delay>4000,"">4k"",""2k1-4k""))) %>% 
    mutate(color=case_when (
        total_delay<=2000 ~ color_palette[1],
        total_delay>4000 ~ color_palette[3],
        total_delay>2000 & total_delay<=4000 ~ color_palette[2]))


# make directed graph
trains_graph <- igraph::graph_from_data_frame(uniques_graph,directed = TRUE)


# UI ----------------------------------------------------------------------
header <- dashboardHeader(
    title=""Tidy tuesday challenge: Week 2019-02-26 french train delays"",
    titleWidth = 770#,
    #dropdownMenu(dropdownMenuOutput(""msg_menu""))
)
sidebar <- dashboardSidebar(
    sidebarMenu(
        menuItem(""French Trains As Graph"",
                 tabName = ""graph_pov""
        ),
        menuItem(""Contact"", 
                 href=""https://www.juliospairani.com"" )
    )
)

body <- dashboardBody(
    tabItems(
        # TAB graph pov --------------------------------------------------------------------------
        tabItem(tabName = ""graph_pov"",
                visNetworkOutput(""output_network"")
                )# end of graph pov
        ) # tab items end
    )# body end

ui <- dashboardPage(header, sidebar, body)


# SERVER ------------------------------------------------------------------
server <- function(input, output,session) {
    reactive_network <- reactive({
        set.seed(12345)
        visNetwork:::visIgraph(trains_graph) %>% 
            visNetwork:::visOptions(  selectedBy= list(variable = ""label""), # esto hace aparecer combos en la red.
                                      highlightNearest = list(enabled = TRUE, hover = TRUE))
    })
    
    output$output_network <- renderVisNetwork({

        reactive_network()
    })
}



# shiny app ---------------------------------------------------------------
shinyApp(ui = ui, server = server)","2019"
"238",839,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201913_seattle_pets.r","library(tidyverse)
library(lubridate)
library(broom)
library(ggrepel)

raw_data <- read_csv(
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-03-26/seattle_pets.csv'
  )
)

pets_totals <- raw_data %>%
  mutate(
    year = year(mdy(license_issue_date)),
    animals_name = str_to_title(animals_name)
  ) %>%
  filter(species %in% c('Cat', 'Dog'), !is.na(animals_name), year >= 2015) %>%
  count(species, animals_name) %>%
  pivot_wider(
    names_from = species, values_from = n, values_fill = list(n = 0)
  ) %>%
  transmute(animal_name = animals_name, dog = Dog, cat = Cat)

model <- lm(cat ~ dog, pets_totals)
intercept <- model$coefficients[1]
slope <- model$coefficients[2]

pets_popular <- augment(model, pets_totals) %>%
  mutate(
    total = dog + cat,
    most_popular = total >= 230,
    popular = total >= 70,
    sign = factor(-sign(.resid))
  )

pets_popular %>%
  ggplot(aes(x = dog, y = cat)) +
    geom_abline(
      intercept = intercept, slope = slope, size = 0.25, linetype = 2
    ) +
    geom_text_repel(
      data = filter(pets_popular, popular & !most_popular),
      aes(label = animal_name, size = total, color = sign),
      fontface = 'bold', segment.size = 0.25, segment.alpha = 0.35, seed = 6,
      show.legend = FALSE
    ) +
    geom_text(
      data = filter(pets_popular, most_popular),
      aes(label = animal_name, size = total, color = sign),
      fontface = 'bold', show.legend = FALSE
    ) +
    geom_label_repel(
      data = filter(pets_popular, most_popular),
      aes(label = paste0(total, ' (', dog, '/', cat, ')')),
      fontface = 'bold', label.padding = 0.2, size = 2, nudge_y = -3.5,
      show.legend = FALSE
    ) +
    expand_limits(x = 0, y = 0) +
    scale_y_continuous(breaks = c(0, 25, 50, 75, 100)) +
    scale_size_continuous(range = c(1.5, 4.25)) +
    labs(
      x = 'Number of Dogs',
      y = 'Number of Cats',
      title = ""Seattle's Most Popular Dog and Cat Names 2015-2018"",
      subtitle = '#tidytuesday 13|2019',
      caption = ' 2019 spren9er'
    )

ggsave(
  'images/tidytuesday_201913_seattle_pets.png',
  dpi = 600, bg = 'transparent'
)
","2019"
"239",840,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201914_seattle_bike_counters.r","library(tidyverse)
library(lubridate)
library(viridis)

options(lubridate.week.start = 1)

raw_data <- read_csv(
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-04-02/bike_traffic.csv'
  ),
  col_types = list(
    date = col_datetime('%m/%d/%Y %H:%M:%S %p'),
    bike_count = col_integer(),
    ped_count = col_integer()
  )
)

bike_traffic <- raw_data %>%
  filter(!is.na(bike_count), bike_count < 2000, date >= ymd(20140101))

bike_traffic_totals <- bike_traffic %>%
  mutate(wday = wday(date, label = TRUE), hour = hour(date)) %>%
  group_by(crossing, direction, wday, hour) %>%
  summarize(total = sum(bike_count)) %>%
  group_by(crossing, direction) %>%
  mutate(
    percentage = total / max(total) * 100,
    name = paste0(crossing, ' (', direction, ')')
  )

levels <- c(
  '39th Ave NE Greenway at NE 62nd St (North)',
  '39th Ave NE Greenway at NE 62nd St (South)',
  'Broadway Cycle Track North Of E Union St (North)',
  'Broadway Cycle Track North Of E Union St (South)',
  'Burke Gilman Trail (North)',
  'Burke Gilman Trail (South)',
  'Elliot Bay Trail (North)',
  'Elliot Bay Trail (South)',
  'NW 58th St Greenway at 22nd Ave (West)',
  'NW 58th St Greenway at 22nd Ave (East)',
  'Sealth Trail (North)',
  'Sealth Trail (South)',
  'MTS Trail (East)'
)

bike_traffic_totals %>%
  mutate(name = factor(name, levels = levels)) %>%
  ggplot() +
    geom_tile(aes(x = hour, y = wday, fill = percentage)) +
    scale_x_continuous(breaks = 0:23) +
    scale_fill_viridis(breaks = c(0, 100), labels = c('low', 'high')) +
    facet_wrap(~ name, ncol = 2, scales = 'free') +
    labs(
      x = 'Time of Day',
      y = 'Weekday',
      fill = '',
      title = ""Seattle's Bike Counts per Time of Day and Weekday 2014-2019"",
      subtitle = '#tidytuesday 14|2019',
      caption = ' 2019 spren9er'
    )

ggsave(
  'images/tidytuesday_201914_seattle_bike_counters.png',
  width = 10, height = 13, bg = 'transparent'
)
","2019"
"240",841,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201915_tennis_grand_slams.r","library(tidyverse)
library(circlize)
library(magick)

# data preparation
path <- paste0(
  'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
  'master/data/2019/2019-04-09/'
)
players <- read_csv(paste0(path, 'player_dob.csv'))
grand_slams <- read_csv(paste0(path, 'grand_slam_timeline.csv'))

last_round <- function(outcome) {
  case_when(
    outcome == 'Won'             ~   1,
    outcome == 'Finalist'        ~   2,
    outcome == 'Semi-finalist'   ~   4,
    outcome == 'Quarterfinalist' ~   8,
    outcome == '4th Round'       ~  16,
    outcome == '3rd Round'       ~  32,
    outcome == '2nd Round'       ~  64,
    outcome == '1st Round'       ~ 128
  )
}

grand_slams <- grand_slams %>%
  mutate(
    last_round = last_round(outcome),
    gender = fct_recode(gender, 'female' = 'Female', 'male' = 'Male')
  ) %>%
  filter(!is.na(last_round))

# select four female and male tennis players (aged < 39) with most won
# grand slam tournaments
(best_players <- grand_slams %>%
  left_join(players, by = c('player' = 'name')) %>%
  filter(date_of_birth > '1981-01-01', last_round == 1) %>%
  group_by(gender, player) %>%
  summarize(total = n()) %>%
  group_by(gender) %>%
  top_n(4, total) %>%
  arrange(gender, total))

grand_slams_best_players <- grand_slams %>%
  filter(player %in% pull(best_players, player), last_round <= 4) %>%
  select(player, gender, year, tournament, last_round)

# prepare adjacency list for chord diagram
player_tournament <- grand_slams_best_players %>%
  filter(last_round == 1) %>%
  group_by(player, tournament) %>%
  summarize(total = n()) %>%
  ungroup() %>%
  transmute(player, to = tournament, total)

player_year <- grand_slams_best_players %>%
  filter(last_round == 1) %>%
  group_by(player, year) %>%
  summarize(total = n()) %>%
  ungroup() %>%
  transmute(player, to = as.character(year), total)

player_last_round <- grand_slams_best_players %>%
  group_by(player, last_round) %>%
  summarize(total = n()) %>%
  ungroup() %>%
  transmute(player, to = as.character(last_round), total)

# build and save chord diagrams for 8 selected tennis players
imap(best_players$player, function(player, idx) {
  adjacency_list <-
    bind_rows(player_tournament, player_year, player_last_round) %>%
    mutate(
      color = case_when(
        player == !!player & str_starts(to, 'A')      ~ '#c54950',
        player == !!player & str_starts(to, 'F')      ~ '#2a9e46',
        player == !!player & str_starts(to, 'W')      ~ '#3766aa',
        player == !!player & str_starts(to, 'U')      ~ '#6b42b8',
        player == !!player & str_starts(to, '1')      ~ '#c54950',
        player == !!player & str_starts(to, '2')      ~ '#2a9e46',
        player == !!player & str_starts(to, '4')      ~ '#3766aa',
        player == !!player & str_detect(to, '\\d{4}') ~ '#777777',
        TRUE ~ '#efefef80'
      ),
      to = case_when(
        to == 1 ~ 'Champion',
        to == 2 ~ 'Final',
        to == 4 ~ 'Semi-Final',
        TRUE ~ to
      ),
      rank = if_else(color == '#efefef80', 1, 2)
    )

  # prepare colors
  years <- sort(unique(player_year$to))
  year_colors <-  rep('#dedede', length(years))
  names(year_colors) <- years

  players <- best_players$player
  player_colors <- rep('#dedede', length(players))
  names(player_colors) <- players

  colors <- c(
    'Australian Open' = '#c54950', 'French Open' = '#2a9e46',
    'Wimbledon' = '#3766aa', 'US Open' = '#6b42b8',
    year_colors,
    'Champion' = '#c54950', 'Final' = '#2a9e46', 'Semi-Final' = '#3766aa',
    player_colors
  )

  player_years <- adjacency_list %>%
    filter(player == !!player, str_detect(to, '\\d{4}')) %>%
    pull(as.integer(to))

  colors[player_years] <- '#777777'
  colors[player] <- '#333333'

  # create image
  png(
    file = paste0('images/chord_diagram_', idx, '.png'),
    height = 7, width = 7,  units = 'in', res = 300
  )

  circos.par(
    gap.after = c(
      rep(2, 3), 9, rep(2, length(years) - 1), 9, rep(2, 2), 15,
      rep(2, 7), 15
    ),
    start.degree = 90
  )

  par(
    col = '#333333', col.main = '#333333', mar = c(0, 0, 3.1, 0), bg = '#fef9f4'
  )

  chordDiagram(
    select(adjacency_list, player, to, total),
    order = names(colors),
    grid.col = colors,
    col = pull(adjacency_list, color),
    transparency = 0.4,
    annotationTrack = 'grid',
    preAllocateTracks = list(list(track.height = 0.2)),
    link.rank = pull(adjacency_list, rank),
  )

  circos.track(
    track.index = 1,
    panel.fun = function(x, y) {
      circos.text(
        CELL_META$xcenter, CELL_META$ylim[1], CELL_META$sector.index,
        facing = 'clockwise', niceFacing = TRUE, adj = c(-0.025, 0.5),
        cex = 0.6
      )
    },
    bg.border = NA
  )

  text(-1, -1, '#tidytuesday 15|2019', cex = 0.5)
  text(1, -1, ' 2019 spren9er', cex = 0.5)
  title('Grand Slam Heroes of the Modern Era')

  dev.off()
})

# build and save animation
frames <- map(1:8, function(idx) {
  file <- paste0('images/chord_diagram_', idx, '.png')
  img <- image_read(file)
  image_scale(img, '1024x1024')
})

animation <- image_animate(image_join(frames), fps = 0.5)

image_write(
  image = animation,
  path = 'images/tidytuesday_201915_tennis_grand_slams.gif',
  quality = 100
)
","2019"
"241",842,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201916_new_economist.r","library(tidyverse)

raw_data <- read_csv(
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-04-16/women_research.csv'
  )
)

women_research <- raw_data %>%
  mutate(
    field = gsub('Women Inventores', 'Inventors', str_to_title(field)),
    percent_men = 1 - percent_women,
    women_ratio = ifelse(percent_women < percent_men, 'less', 'not_less')
  ) %>%
  pivot_longer(
    starts_with('percent'), names_to = 'sex', values_to = 'percent',
    names_prefix = 'percent_'
  )

women_field_averages <- women_research %>%
  filter(sex == 'women') %>%
  group_by(field) %>%
  summarize(avg_field_percent = mean(percent)) %>%
  arrange(avg_field_percent)

women_country_averages <- women_research %>%
  filter(sex == 'women') %>%
  group_by(country) %>%
  summarize(avg_country_percent = mean(percent)) %>%
  arrange(avg_country_percent)

plot <- women_research %>%
  mutate(
    field = factor(field, levels = women_field_averages$field),
    country = factor(country, levels = women_country_averages$country),
    sex_women_ratio = interaction(sex, women_ratio)
  ) %>%
  ggplot() +
    geom_bar(
      aes(x = '', y = percent, fill = sex_women_ratio, color = women_ratio),
      stat = 'identity', show.legend = FALSE
    ) +
    scale_fill_manual(values = c('#efefef', '#333333', '#efefef', '#c54950')) +
    scale_color_manual(values = c('#333333', '#c54950')) +
    coord_polar('y', start = 0) +
    facet_grid(field ~ country, switch = 'y') +
    labs(
      x = '',
      y = '',
      title = ""Still a man's world"",
      subtitle = paste(
        '#tidytuesday 16|2019',
        'women among researchers with papers published 2011-2015',
        sep = '  '
      ),
      caption = ' 2019 spren9er'
    )

plot +
  theme_minimal() +
  theme(
    panel.border = element_blank(),
    panel.grid = element_blank(),
    panel.spacing.x = unit(0.9, 'lines'),
    panel.spacing.y = unit(0.9, 'lines'),
    axis.title.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    strip.background = element_blank(),
    strip.text = element_text(size = 9, face = 'plain'),
    strip.text.x = element_text(angle = 90, hjust = 0, margin = margin(b = 10)),
    strip.text.y = element_text(
      angle = 180, hjust = 1, margin = margin(r = 10)
    ),
    plot.title = element_text(face = 'bold', margin = margin(b = 7)),
    plot.subtitle = element_text(margin = margin(b = 20)),
    plot.caption = element_text(
      color = '#333333', face = 'plain', size = 7, hjust = 1,
      margin = margin(t = 20)
    )
  )

ggsave(
  'images/tidytuesday_201916_the_economist.png',
  width = 9.5, height = 6.5, bg = '#efefef'
)
","2019"
"242",843,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201917_anime.r","library(tidyverse)
library(av)
library(gganimate)
library(ggbeeswarm)
library(lubridate)

raw_data <- read_csv(
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-04-23/tidy_anime.csv'
  )
)

anime <- raw_data %>%
  select(anime_id = animeID, everything(), -synopsis, -background) %>%
  filter(!type %in% c('Music', 'Unknown'), rating != 'None') %>%
  distinct(anime_id, .keep_all = TRUE) %>%
  mutate(
    year = year(start_date),
    rating = fct_relevel(
      fct_recode(
        rating,
        'G'     = 'G - All Ages',
        'PG'    = 'PG - Children',
        'PG-13' = 'PG-13 - Teens 13 or older',
        'R'     = 'R+ - Mild Nudity',
        'NC-17' = 'R - 17+ (violence & profanity)'
      ),
      c('G', 'PG', 'PG-13', 'R', 'NC-17')
    )
  )

start_year <- 1978
end_year <- 2018
anime_years <- reduce(
  start_year:end_year, .init = tibble(),
  function(agg, year) {
    bind_rows(
      agg,
      anime %>%
        filter(year >= start_year, year <= !!year) %>%
        mutate(until_year = !!year)
    )
  }
)

animation <- anime_years %>%
  ggplot(aes(x = rating, y = score)) +
    geom_quasirandom(alpha = 0.15) +
    geom_violin(fill = 'transparent', draw_quantiles = c(0.5)) +
    scale_y_continuous(
      breaks = 0:10, labels = 0:10, minor_breaks = NULL, expand = c(0, 0)
    ) +
    expand_limits(y = 0) +
    labs(
      x = 'Rating',
      y = 'Score',
      title = 'Score Distributions of Animes per Rating',
      subtitle = paste(
        '#tidytuesday 17|2019',
        '{start_year} - {floor(frame_time)}',
        sep = '  '
      ),
      caption = ' 2019 spren9er'
    ) +
    transition_time(until_year) +
    enter_fade() +
    ease_aes('linear')

animate(
  animation,
  nframes = end_year - start_year + 1, duration = 8,
  renderer = av_renderer(), width = 1000, height = 1000
)

anim_save('images/tidytuesday_201917_anime.mp4')
","2019"
"243",844,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201918_chicago_bird_collisions.r","library(tidyverse)
library(treemapify)
library(lubridate)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-04-30/'
  )

bird_collisions <- read_csv(paste0(path, 'bird_collisions.csv'))
mp_light <- read_csv(paste0(path, 'mp_light.csv'))

mp_bird_collisions <- bird_collisions %>%
  filter(locality == 'MP', year(date) >= 2000) %>%
  left_join(mp_light, by = 'date')

mp_bird_collisions.agg <- mp_bird_collisions %>%
  mutate(species = str_to_title(species)) %>%
  group_by(family, genus, species) %>%
  summarize(
    deaths = n(),
    avg_light_score = mean(light_score, na.rm = TRUE)
  )

mp_bird_collisions.agg %>%
  ggplot(aes(
    area = deaths, fill = avg_light_score,
    subgroup = family, subgroup2 = genus, label = species
  )) +
    geom_treemap(size = 0) +
    geom_treemap_text(place = 'middle', size = 8, min.size = 0) +
    geom_treemap_subgroup2_border(color = '#ffffff', size = 1) +
    geom_treemap_subgroup2_text(
      color = '#ffffff', place = 'topleft', size = 10, min.size = 8
    ) +
    geom_treemap_subgroup_border(color = '#430252', size = 1) +
    geom_treemap_subgroup_text(
      color = '#430252', place = 'center', size = 18, min.size = 3
    ) +
    scale_fill_viridis_c(option = 'magma') +
    labs(
      title = 'Chicago Bird Collisions (McCormick Place) 2000-2016',
      subtitle = expression(
        atop('#tidytuesday 18|2019', atop('[size of tile ? number of deaths]'))
      ),
      fill = 'Avg. Light Score',
      caption = ' 2019 spren9er'
    )

ggsave(
  'images/tidytuesday_201918_chicago_bird_collisions.png',
  width = 7, height = 7, bg = 'transparent'
)
","2019"
"244",845,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201920_nobel_prize_winners.r","library(tidyverse)
library(lubridate)
library(ggrepel)

nobel_winners <- read_csv(
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-05-14/nobel_winners.csv'
  )
)

dead_nobel_winners <- nobel_winners %>%
  filter(!is.na(death_date)) %>%
  mutate(years_until_death = year(death_date) - prize_year) %>%
  distinct(category, full_name, years_until_death)

avg_years_until_death <- dead_nobel_winners %>%
  group_by(category) %>%
  summarize(avg_years_until_death = mean(years_until_death))

max_years_until_death <- dead_nobel_winners %>%
  group_by(category) %>%
  top_n(1, years_until_death)

min_years_until_death <- dead_nobel_winners %>%
  group_by(category) %>%
  top_n(1, -years_until_death)

dead_nobel_winners %>%
  left_join(avg_years_until_death, by = 'category') %>%
  anti_join(min_years_until_death) %>%
  anti_join(max_years_until_death) %>%
  mutate(category = fct_reorder(category, avg_years_until_death)) %>%
  ggplot() +
    geom_vline(aes(xintercept = 0)) +
    geom_jitter(
      aes(x = -years_until_death, y = category),
      color = 'red', alpha = 1/3, height = 0.15, width = 0
    ) +
    geom_line(
      data = avg_years_until_death,
      aes(x = -avg_years_until_death, y = category, group = 1)
    ) +
    geom_point(
      data = avg_years_until_death,
      aes(x = -avg_years_until_death, y = category)
    ) +
    geom_point(
      data = max_years_until_death,
      aes(x = -years_until_death, y = category),
      color = 'red', alpha = 1/3
    ) +
    geom_label_repel(
      data = max_years_until_death,
      aes(x = -years_until_death, y = category, label = full_name),
      hjust = 1, size = 2.25, nudge_y = -0.4, nudge_x = 0.8,
      segment.size = 0.3, segment.alpha = 0.9, label.size = 0.25
    ) +
    geom_point(
      data = min_years_until_death,
      aes(x = -years_until_death, y = category),
      color = 'red', alpha = 1/3
    ) +
    geom_label_repel(
      data = min_years_until_death,
      aes(x = -years_until_death, y = category, label = full_name),
      hjust = 1, size = 2.25, nudge_y = -0.4, nudge_x = -0.8,
      segment.size = 0.3, segment.alpha = 0.9, label.size = 0.25
    ) +
    scale_x_continuous(
      breaks = seq(-60, 0, by = 5), labels = function(l) {-l}
    ) +
    labs(
      x = 'Number of Years',
      y = 'Category',
      title = 'Number of Years between Nobel Prize and Death',
      subtitle = paste(
        'Distribution and Average',
        '#tidytuesday 20|2019',
        sep = '  '
      ),
      caption = ' 2019 spren9er'
    )

ggsave(
  'images/tidytuesday_201920_nobel_prize_winners.png',
  width = 6.5, height = 6.5, bg = 'transparent'
)
","2019"
"245",846,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201921_global_plastic_waste.r","library(tidyverse)
library(janitor)
library(rgdal)
library(ggforce)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-05-21/'
  )

mismanaged_vs_gdp <- read_csv(
  paste0(path, 'per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv')
)

waste_vs_gdp <- read_csv(
  paste0(path, 'per-capita-plastic-waste-vs-gdp-per-capita.csv')
)

data <- mismanaged_vs_gdp %>%
  inner_join(waste_vs_gdp, by = c('Entity', 'Code', 'Year')) %>%
  clean_names() %>%
  transmute(
    country = entity,
    code,
    waste_per_day_pc =
      per_capita_plastic_waste_kilograms_per_person_per_day,
    mismanaged_waste_per_day_pc =
      per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day,
    mismanaged_waste_rate = mismanaged_waste_per_day_pc / waste_per_day_pc
  ) %>%
  filter(!is.na(coalesce(mismanaged_waste_per_day_pc, waste_per_day_pc)))

# naturalearthdata.com/downloads/110m-physical-vectors/110m-land
world <- readOGR(dsn = 'data/ne_110m_land', layer = 'ne_110m_land')

world_df <- fortify(world) %>%
  filter(!id %in% as.character(0:7)) # remove antarctica

# naturalearthdata.com/downloads/110m-cultural-vectors/110m-admin-0-countries
countries <- readOGR(
  dsn = 'data/ne_110m_admin_0_countries', layer = 'ne_110m_admin_0_countries'
)

countries_df <- fortify(countries) %>%
  filter(id != '159')  # remove antarctica

countries_mapping <- as.tibble(countries) %>%
  mutate(id = as.character(row_number() - 1)) %>%
  clean_names() %>%
  transmute(id, country_code = coalesce(adm0_a3, iso_a3), name_en)

centers <- countries_df %>%
  filter(
    str_detect(group, '^.*\\.1$'), # select only main part of country
  ) %>%
  group_by(id) %>%
  group_map(~ as.tibble(geosphere::centroid(select(., long, lat)))) %>%
  rename(center_long = lon, center_lat = lat)

(kpis_per_country <- data %>%
  arrange(mismanaged_waste_rate) %>%
  left_join(countries_mapping, by = c('code' = 'country_code')) %>%
  select(id, everything()) %>%
  filter(!is.na(id), id != 175)) # wrong data for Trinidad & Tobago?

kpis_per_country_gathered <- kpis_per_country %>%
  left_join(centers, by = 'id') %>%
  pivot_longer(
    c(waste_per_day_pc, mismanaged_waste_per_day_pc),
    names_to = 'waste_key', values_to = 'waste_value'
  )

selected_countries <- c(
  'KOR', 'JPN', 'AUS', 'GBR', 'QAT', 'NLD', 'PRT', 'FLK', 'GRL', 'NCL', 'GRC',
  'DEU', 'FRA', 'USA', 'CAN', 'MEX', 'BRA', 'SOM', 'PAK', 'PNG', 'SLB', 'VNM',
  'KHM', 'MMR', 'BGD', 'PRK', 'IND', 'ZAF'
)

country_labels <- kpis_per_country %>%
  mutate(
    rank = row_number(),
    name = paste0(
      rank, '. ', name_en,
      ' (', as.character(scales::percent_format()(mismanaged_waste_rate)), ')'
    )
  ) %>%
  left_join(centers, by = 'id') %>%
  select(code, center_long, center_lat, name, mismanaged_waste_rate) %>%
  filter(
    code %in% selected_countries
  ) %>%
  mutate(code = factor(code, levels = selected_countries))

theme_opts <- list(theme(
  panel.grid.minor = element_blank(),
  panel.grid.major = element_blank(),
  panel.background = element_blank(),
  plot.background = element_blank(),
  panel.border = element_blank(),
  axis.line = element_blank(),
  axis.text.x = element_blank(),
  axis.text.y = element_blank(),
  axis.ticks = element_blank(),
  axis.title.x = element_blank(),
  axis.title.y = element_blank()
))

ggplot() +
  geom_polygon(
    data = world_df,
    aes(x = long, y = lat, group = group, fill = hole)) +
  geom_path(
    data = countries_df,
    aes(x = long, y = lat, group = group, fill = hole),
    size = 0.1, color = '#cccccc'
  ) +
  geom_point(
    data = kpis_per_country_gathered,
    aes(
      x = center_long, y = center_lat,
      size = waste_value, color = waste_key
    )
  ) +
  geom_mark_circle(
    data = country_labels,
    aes(x = center_long, y = center_lat, group = name, label = name),
    fill = 'transparent', size = 0,
    label.fill = 'transparent', label.fontsize = 4,
    con.size = 0.05, con.cap = 0, expand = unit(0, 'mm')
  ) +
  scale_fill_manual(values = c('#dedede', '#ffffff'), guide = 'none') +
  scale_color_manual(
    labels = c(
      'mismanaged plastic waste per capita (in kg per day)',
      'plastic waste per capita (in kg per day)'
    )
  ) +
  scale_size_area(max_size = 6, breaks = c(0.1, 0.2, 0.4, 0.6)) +
  coord_equal() +
  theme_opts +
  labs(
    color = 'Color',
    size = 'Size',
    title = 'Global Plastic Waste 2010',
    subtitle = paste(
      'Mismanaged Plastic Waste Rates per Country',
      '#tidytuesday 21|2019',
      sep = '    '
    ),
    caption = ' 2019 spren9er'
  )

ggsave(
  'images/tidytuesday_201921_global_plastic_waste.png',
  width = 13, height = 8, dpi = 300
)
","2019"
"246",847,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201922_wine_ratings.r","library(tidyverse)
library(tidytext)
library(widyr)
library(igraph)
library(ggraph)
library(viridis)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-05-28/'
  )

wine_ratings <- read_csv(paste0(path, 'winemag-data-130k-v2.csv')) %>%
  rename(id = X1)

# common words to describe wine: https://www.words-to-use.com/words/wine/
wine_adjectives <- read_csv2('data/wine_adjectives.csv', col_names = c('word'))

theme_options <- theme(
  legend.title = element_text(
    size = 9, margin = margin(b = 5), face = 'bold'
  ),
  legend.text = element_text(size = 7),
  legend.margin = margin(t = 15, b = 15),
  legend.key.width = unit(10, 'points'),
  plot.title = element_text(
    margin = margin(b = 12), color = '#32b37f', size = 14, hjust = 0.5,
    face = 'bold'
  ),
  plot.subtitle = element_text(
    margin = margin(b = 15), size = 11, hjust = 0.5, face = 'bold'
  ),
  plot.caption = element_text(color = '#dadada', size = 6, hjust = 1.09),
  plot.margin = margin(t = 40, r = 20, b = 20, l = 20)
)

wine_words <- wine_ratings %>%
  unnest_tokens('word', description) %>%
  filter(word %in% wine_adjectives$word) %>%
  select(id, country, points, price, variety, word)

top_wine_words <- wine_words %>%
  group_by(word) %>%
  summarize(total = n()) %>%
  arrange(desc(total)) %>%
  head(120)

threshold <- 0.02

wine_word_correlations <- wine_words %>%
  filter(word %in% top_wine_words$word) %>%
  pairwise_cor(word, id, sort = TRUE) %>%
  filter(correlation > threshold) %>%
  arrange(desc(correlation))

wine_averages_per_word <- wine_words %>%
  filter(word %in% top_wine_words$word) %>%
  group_by(word) %>%
  summarize(
    total = n(),
    avg_points = mean(points, na.rm = TRUE),
    avg_price = mean(price, na.rm = TRUE)
  ) %>%
  rename(name = word) %>%
  arrange(desc(total))

graph <- wine_word_correlations %>%
  rename(weight = correlation) %>%
  mutate(alpha = cut(weight, c(threshold, 0.05, 1))) %>%
  graph_from_data_frame(vertices = wine_averages_per_word)

ggraph(graph, layout = 'fr', niter = 15000) +
  geom_edge_link(aes(edge_alpha = alpha), edge_width = 0.2) +
  geom_node_point(aes(size = total, color = avg_points)) +
  geom_node_text(
    aes(label = name), size = 3, repel = TRUE
  ) +
  scale_color_viridis(breaks = c(85.0, 87.5, 90.0, 92.5)) +
  scale_size_area(
    breaks = c(250, 1000, 2500, 5000, 10000, 25000),
    labels = function(n) { format(n, big.mark = ',') }
  ) +
  scale_edge_alpha_manual(
    values = c(0.03, 0.4), labels = c('weak', 'strong')
  ) +
  labs(
    title = paste(
      'Words in',
      format(nrow(wine_ratings), big.mark = ','),
      'Wine Descriptions I.'
    ),
    subtitle = paste(
      '120 common words to describe wine and their correlation',
      '#tidytuesday 22 | 2019',
      sep = '      '
    ),
    caption = ' 2019 spren9er',
    color = 'Average Rating',
    size = 'Word Count',
    edge_alpha = 'Correlation'
  ) +
  theme_void() +
  theme_options +
  guides(
    edge_alpha = guide_legend(order = 1),
    size = guide_legend(order = 2)
  )

ggsave(
  'images/tidytuesday_201922_wine_ratings_most_common_words.png',
  width = 10, height = 8.5, dpi = 300
)

################################################################################

wine_words <- wine_ratings %>%
  unnest_tokens('word', description) %>%
  anti_join(stop_words, by = 'word') %>%
  filter(
    !str_detect(word, '^\\d+$'),
    !word %in% c('alongside', 'offers', 'feels')
  ) %>%
  select(id, country, points, price, variety, word)

top_wine_words <- wine_words %>%
  count(word, sort = TRUE) %>%
  head(150)

wine_word_correlations <- wine_words %>%
  filter(word %in% top_wine_words$word) %>%
  pairwise_cor(word, id, sort = TRUE) %>%
  filter(correlation > 0.0) %>%
  arrange(desc(correlation))

wine_averages_per_word <- wine_words %>%
  filter(word %in% top_wine_words$word) %>%
  group_by(word) %>%
  summarize(
    total = n(),
    avg_points = mean(points, na.rm = TRUE),
    avg_price = mean(price, na.rm = TRUE)
  ) %>%
  rename(name = word) %>%
  arrange(desc(total))

threshold <- 0.065

graph <- wine_word_correlations %>%
  filter(correlation > threshold) %>%
  rename(weight = correlation) %>%
  mutate(alpha = cut(weight, c(0, threshold, 0.13, 1))) %>%
  graph_from_data_frame(vertices = wine_averages_per_word)

ggraph(graph, layout = 'fr', niter = 15000) +
  geom_edge_link(aes(edge_alpha = alpha), edge_width = 0.2) +
  geom_node_point(aes(size = total, color = avg_points)) +
  geom_node_text(
    aes(label = name), size = 3, repel = TRUE
  ) +
  scale_color_viridis(breaks = c(86.0, 87.0, 88.0, 89.0, 90.0)) +
  scale_size_area(
    breaks = c(5000, 10000, 25000, 50000),
    labels = function(n) { format(n, big.mark = ',') }
  ) +
  scale_edge_alpha_manual(
    values = c(0.03, 0.4), labels = c('weak', 'strong')
  ) +
  labs(
    title = paste(
      'Words in',
      format(nrow(wine_ratings), big.mark = ','),
      'Wine Descriptions II.'
    ),
    subtitle = paste(
      '150 most frequent words and their correlation',
      '#tidytuesday 22 | 2019',
      sep = '      '
    ),
    caption = ' 2019 spren9er',
    color = 'Average Rating',
    size = 'Word Count',
    edge_alpha = 'Correlation'
  ) +
  theme_void() +
  theme_options +
  guides(
    edge_alpha = guide_legend(order = 1),
    size = guide_legend(order = 2)
  )

ggsave(
  'images/tidytuesday_201922_wine_ratings_most_frequent_words.png',
  width = 10, height = 8.5, dpi = 300
)
","2019"
"247",848,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201924_meteorites.r","library(tidyverse)
library(rgdal)
library(ggrepel)
library(ggforce)
library(cowplot)
library(magick)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-06-11/'
  )

meteorites <- read_csv(paste0(path, 'meteorites.csv'))

group_name <- Vectorize(function(name) {
  name <- str_replace_all(name, '\\d', '')
  name <- str_replace_all(name, '\\(.*\\)', '')
  name <- str_replace_all(name, '\\s\\w$', '')
  str_trim(name)
})

superclass <- Vectorize(function(class) {
  if (str_detect(class, '^H[\\d|\\~].*')) return('H')
  if (str_detect(class, '^LL\\d*.*')) return('LL')
  if (str_detect(class, '^L\\d.*')) return('L')
  if (str_starts(class, 'Iron')) return('Iron')
  class
})

format_kg <- Vectorize(function(mass) {
  mass_kg <- format(round(mass / 1000, 0), nsmall = 0)
  if (mass / 1000 < 100) mass_kg <- format(round(mass / 1000, 1), nsmall = 1)
  paste0(str_trim(mass_kg), 'kg')
})

grouped_meteorites <- meteorites %>%
  filter(
    !is.na(long), long >= -180, long <= 180,
     !is.na(lat),  lat >=  -90, lat  <=  90,
    long != 0, lat != 0
  ) %>%
  mutate(
    group_name = fct_lump(group_name(name), 50),
    superclass = fct_lump(superclass(class), 4)
  ) %>%
  filter(group_name != 'Other') %>%
  group_by(group_name) %>%
  mutate(group_size = n_distinct(geolocation)) %>%
  ungroup()

filtered_grouped_meteorites <- grouped_meteorites %>%
  group_by(group_name) %>%
  mutate(
    median_long = median(long),
    median_lat = median(lat)
  ) %>%
  filter(
    group_size >= 450,
    abs(long - median_long) <= 2 * IQR(long) | id %in% c(9594, 13504),
    abs(lat - median_lat) <= 2 * IQR(lat) | id %in% c(9594, 13504),
  ) %>%
  ungroup() %>%
  mutate(group_name = fct_reorder(group_name, group_size))

top_mass_meteorites <- filtered_grouped_meteorites %>%
  group_by(group_name) %>%
  top_n(3, mass) %>%
  arrange(desc(mass)) %>%
  mutate(
    rank = row_number(),
    label = paste0(
      rank, '. ', name, ' (',
      format_kg(mass),
      ')'
    )
  ) %>%
  ungroup()

groups <- filtered_grouped_meteorites %>%
  group_by(group_name) %>%
  summarize(
    median_long = first(median_long),
    median_lat = first(median_lat),
    group_size = first(group_size)
  )

# http://www.naturalearthdata.com/downloads/110m-physical-vectors/110m-land/
world <- readOGR(dsn = 'ne_110m_land', layer = 'ne_110m_land')
world_df <- fortify(world)

# http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-admin-0-countries/
countries <- readOGR(
  dsn = 'ne_110m_admin_0_countries', layer = 'ne_110m_admin_0_countries'
)
countries_df <- fortify(countries)

# %%
frames <- map(1:nrow(groups), function(idx) {
  group_name <- groups$group_name[idx]
  group_size <- groups$group_size[idx]
  group <- filter(groups, group_name == !!group_name)

  world_map <- ggplot() +
    geom_polygon(
      data = world_df,
      aes(x = long, y = lat, group = group, fill = hole)) +
    geom_path(
      data = countries_df,
      aes(x = long, y = lat, group = group, fill = hole),
      size = 0.1, color = '#cccccc'
    ) +
    geom_point(
      data = groups,
      aes(x = median_long, y = median_lat, size = group_size),
      alpha = 0.7, color = '#333333', show.legend = FALSE
    ) +
    geom_point(
      data = group,
      aes(x = median_long, y = median_lat, size = group_size),
      color = '#2dae81', show.legend = FALSE
    ) +
    scale_fill_manual(values = c('#dedede', 'transparent'), guide = 'none') +
    scale_size_continuous(range = c(0.01, 3)) +
    scale_x_continuous(expand = c(0, 0)) +
    scale_y_continuous(expand = c(0, 0)) +
    coord_quickmap(clip = 'off') +
    theme_void() +
    theme(
      plot.background = element_rect(
        fill = 'transparent', color = 'transparent'
      ),
      plot.margin = margin(t = 0, b = 0, l = 0, r = 0)
    )

  meteorites_map <- ggplot() +
    geom_point(
      data = filter(filtered_grouped_meteorites, group_name == !!group_name),
      aes(x = long, y = lat, color = superclass, size = mass),
      alpha = 0.6
    ) +
    geom_label_repel(
      data = filter(top_mass_meteorites, group_name == !!group_name),
      aes(x = long, y = lat, color = superclass, label = label),
      size = 3, show.legend = FALSE
    ) +
    scale_size_continuous(
      range = c(0.2, 16),
      limits = c(0, 550001),
      breaks = c(1000, 10000, 25000, 100000, 250000),
      labels = c('1kg', '10kg', '25kg', '100kg', '250kg')
    ) +
    scale_color_viridis_d(drop = FALSE) +
    coord_cartesian() +
    theme_void() +
    labs(
      title = 'Areas with over 450 different meteorite locations',
      subtitle = paste0(
        idx, '. ',
        str_to_title(group_name), '    ', format(group_size, big.mark = ','),
        ' Meteorites'
      ),
      caption = ' 2019 spren9er    tidytuesday 24|2019',
      color = 'Meteorite Class',
      size = 'Meteorite Mass'
    ) +
    theme(
      text = element_text(family = 'Puritan'),
      panel.background = element_rect(fill = '#ffffff', color = 'transparent'),
      plot.title = element_text(
        margin = margin(b = 12), color = '#2dae81', size = 14, hjust = 0.5,
        face = 'bold'
      ),
      plot.subtitle = element_text(
        margin = margin(b = 15), size = 11, hjust = 0.5
      ),
      plot.caption = element_text(color = '#cccccc', size = 8, hjust = 0),
      plot.margin = margin(t = 0, b = 0),
      legend.title = element_text(size = 8, hjust = 0.5),
      legend.text = element_text(size = 7, color = '#777777', hjust = 1),
      legend.spacing.y = unit(10, 'points'),
      legend.margin = margin(b = 2, l = 20),
      legend.background = element_rect(fill = 'transparent', color = NA)
    )

  ggdraw() +
    draw_plot(
      meteorites_map, x = 0.05, y = 0.075, width = 0.9, height = 0.85
    ) +
    draw_plot(
      world_map, x = 0.68, y = 0.02, width = 0.3, height = 0.15, scale = 1
    ) +
    theme(plot.background = element_rect(fill = '#efefef', color = NA))

  filename <- paste0(
    'images/tidytuesday_201924_meteorites/tidytuesday_201924_meteorites',
    str_pad(idx, 2, pad = '0'),
    '.png'
  )

  ggsave(filename, width = 8, height = 8, dpi = 300)
  img <- image_read(filename)
  image_scale(img, '1200x1200')
})

animation <- image_animate(image_join(frames), fps = 0.4)

image_write(
  image = animation,
  path = 'images/tidytuesday_201924_meteorites.gif',
  quality = 100
)
","2019"
"248",849,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201926_ufo_sightings.r","library(tidyverse)
library(janitor)
library(lubridate)
library(tweenr)
library(rayshader)
library(magick)
library(maps)
library(av)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-06-25/'
  )

ufo_sightings <- read_csv(
  paste0(path, 'ufo_sightings.csv'),
  col_types = list(date_time = col_datetime('%m/%d/%Y %H:%M'))
)

ufo_sightings.us <- ufo_sightings %>%
  mutate(year = year(date_time)) %>%
  filter(country == 'us', !state %in% c('ak', 'hi', 'pr'))

min_long.us <- -124.848974
max_long.us <- -66.885444
min_lat.us <- 24.396308
max_lat.us <- 49.384358

long_width <- max_long.us - min_long.us
lat_height <- max_lat.us - min_lat.us

factor <- 2
size_x <- ceiling(factor * long_width)
size_y <- ceiling(factor * lat_height)

ufo_sightings_us_for_year <- function(year) {
  ufo_coordinates <- ufo_sightings.us %>%
    filter(year == !!year)

  kde <- MASS::kde2d(
    pull(ufo_coordinates, longitude),
    pull(ufo_coordinates, latitude),
    n = c(size_x, size_y),
    h = 1,
    lims = c(min_long.us, max_long.us, min_lat.us, max_lat.us)
  )

  bind_cols(
    crossing(x = kde$x, y = kde$y),
    height = as.vector(t(kde$z))
  )
}

start_year <- 1990
end_year <- 2014

ufo_sightings.us.total <- reduce(
  start_year:end_year,
  .init = tibble(),
  function(agg, year) {
    bind_rows(
      agg,
      ufo_sightings_us_for_year(year) %>%
        mutate(year = !!year)
    )
  }
)

(ufo_sightings.us.agg <- ufo_sightings.us.total %>%
  group_by(year) %>%
  summarize(min_height = min(height), max_height = max(height)))

max_height <- ufo_sightings.us.agg %>%
  summarize(max_height = max(max_height)) %>%
  pull(max_height)

ufo_sightings.us.total <- ufo_sightings.us.total %>%
  mutate(height = height / max_height)

ufo <- split(ufo_sightings.us.total, ufo_sightings.us.total$year)

ufo_frames <- reduce(
  (start_year + 1):end_year,
  .init = ufo[[!!start_year]],
  function(agg, year) {
    tween_state(agg, ufo[[as.character(year)]], ease = 'linear', nframes = 20)
  }
)

ufo_frames <- split(ufo_frames, ufo_frames$.frame)

theme_bare <- theme(
  axis.line = element_blank(),
  axis.text.x = element_blank(),
  axis.text.y = element_blank(),
  axis.ticks = element_blank(),
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  legend.text = element_text(size = 7),
  legend.title = element_text(size = 8),
  panel.background = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.border = element_blank()
)

us.df <- map_data('state')

p_base <- function(year) {
  ggplot() +
    geom_polygon(
      data = us.df,
      aes(x = long, y = lat, group = group),
      fill = '#efefef', size = 0, show.legend = FALSE
    ) +
    geom_path(
      data = us.df,
      aes(x = long, y = lat, group = group),
      size = 0.25, color = '#333333'
    ) +
    geom_tile(
      aes(x = x, y = y, fill = ifelse(height < 0.01, NA, height)),
      alpha = 1, size = 0, show.legend = FALSE, color = 'transparent'
    ) +
    scale_fill_viridis_c(option = 'C', na.value = NA) +
    coord_quickmap() +
    labs(
      title = 'Ufo Sightings in United States',
      subtitle = paste('tidytuesday 26|2019', year, sep = '    '),
      caption = ' 2019 spren9er'
    ) +
    theme_bare +
    theme(
      text = element_text(family = 'Bitter'),
      panel.background = element_rect(fill = '#333333', color = NA),
      plot.background = element_rect(fill = '#333333', color = NA),
      plot.title = element_text(
        margin = margin(b = 8), size = 14, hjust = 0.5, face = 'bold',
        color = '#efefef'
      ),
      plot.subtitle = element_text(
        size = 11, hjust = 0.5, face = 'plain', color = '#efefef'
      ),
      plot.caption = element_text(
        color = '#cccccc', size = 6, margin = margin(t = -11), hjust = 0.88
      ),
      plot.margin = margin(t = 20, b = 66.15)
    )
}

filename <- function(id) {
  paste0('images/tidytuesday_201926_ufo_sightings/ufo_', id, '.png')
}

for (d in ufo_frames) {
  year <- floor(d$year[[1]])
  p <- p_base(year) %+% d
  id <- str_pad(d$.frame[1], width = 5, side = 'left', pad = '0')

  plot_gg(
    plot(p),
    shadow_intensity = 0.8, scale = 300, shadow = FALSE, width = 8, height = 6,
    solid = FALSE, background = '#efefef', baseshape = 'rectangle',
    windowsize = c(1200, 800), offset_edges = TRUE
  )
  render_camera(phi = 55, theta = 0, zoom = 0.41, fov = 60)
  render_snapshot(filename(id), clear = TRUE)
}

frames <- purrr::map(1:length(ufo_frames), function(idx) {
  id <- str_pad(idx, width = 5, side = 'left', pad = '0')
  file <- filename(id)
  img <- image_read(file)
  img <- image_scale(img, '900x600')
  if (idx %% 20 != 0) return(img)
  return(rep(img, 20))
})

animation <- image_animate(image_join(frames), fps = 20)

image_write(
  image = animation,
  path = 'images/tidytuesday_201926_ufo_sightings.gif',
  quality = 100
)

frames.files <- unlist(purrr::map(0:480, function(idx) {
  id <- str_pad(idx, width = 5, side = 'left', pad = '0')
  file <- filename(id)
  if (idx %% 20 != 0) return(file)
  rep(file, 20)
}))

av_encode_video(
  frames.files,
  'images/tidytuesday_201926_ufo_sightings.mp4',
  framerate = 24
)
","2019"
"249",850,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201932_bob_ross_paintings.r","library(tidyverse)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-08-06/'
  )

data <- read_csv(paste0(path, 'bob-ross.csv')) %>%
  janitor::clean_names() %>%
  mutate(
    episode = str_replace(episode, 'S0', 'S'),
    episode = str_replace(episode, 'E0', 'E'),
    title = str_to_title(str_replace_all(title, '""', ''))
  ) %>%
  select(-contains('STEVE'), -contains('DIANE'), -contains('FRAME'))

colors <- read_csv(
    'data/tidytuesday_201932_bob_ross_paintings.csv',
    col_names = c('episode', 'title', 'color', 'color_name')
  ) %>%
  filter(!color %in% c('#FFFFFF', '#000000'))

ordered_colors <- c(
  'Phthalo Blue', 'Prussian Blue', 'Phthalo Green', 'Sap Green',
  'Van Dyke Brown', 'Alizarin Crimson', 'Dark Sienna', 'Burnt Umber',
  'Bright Red', 'Indian Red', 'Yellow Ochre', 'Indian Yellow', 'Cadmium Yellow'
)

palette <- colors %>%
  distinct(color, color_name) %>%
  mutate(color_name = fct_relevel(color_name, ordered_colors)) %>%
  arrange(color_name)

objects <- data %>%
  pivot_longer(
    -one_of('episode', 'title'),
    names_to = 'object', values_to = 'painted'
  ) %>%
  mutate(object = str_to_title(str_replace_all(object, '_', ' '))) %>%
  filter(object != 'Guest')

top_objects <- objects %>%
  filter(painted == 1) %>%
  count(object, name = 'object_total', sort = TRUE) %>%
  filter(object_total >= 10) %>%
  mutate(object = fct_reorder(object, -object_total))

objects_colors <- objects %>%
  right_join(top_objects, by = 'object') %>%
  inner_join(select(colors, -title), by = 'episode') %>%
  count(object, color_name, painted, name = 'total', sort = TRUE) %>%
  filter(painted == 1) %>%
  select(-painted) %>%
  pivot_wider(names_from = color_name, values_from = total) %>%
  replace(is.na(.), 0)

objects_colors_mtx <- as.matrix(column_to_rownames(objects_colors, 'object'))
chi2 <- chisq.test(objects_colors_mtx, correct = F)
residuals <- as.tibble(chi2$residuals, rownames = 'object')

cut_residuals <- residuals %>%
  pivot_longer(-object, names_to = 'color', values_to = 'residual') %>%
  mutate(
    cut_residual = ifelse(residual > 1, 1, residual),
    cut_residual = ifelse(residual < 0, 0, cut_residual)
  )

dist_mtx <- cut_residuals %>%
  pivot_wider(object, names_from = color, values_from = cut_residual) %>%
  column_to_rownames('object') %>%
  as.matrix() %>%
  dist()

cluster <- hclust(dist_mtx)

reordered_objects <- cluster$labels[cluster$order]

cut_residuals %>%
  mutate(
    color = fct_relevel(color, as.character(palette$color_name)),
    object = fct_relevel(object, reordered_objects)
  ) %>%
  filter(cut_residual > 0) %>%
  ggplot(aes(x = color, y = object, fill = color, alpha = cut_residual)) +
    geom_tile(width = 0.9, height = 0.9, show.legend = FALSE) +
    scale_fill_manual(values = palette$color) +
    scale_x_discrete(position = 'top') +
    scale_alpha_continuous(range = c(0, 1)) +
    labs(
      x = '',
      y = '',
      title = 'Elements & Colors in Bob Ross Paintings',
      subtitle = '#tidytuesday 32 | 2019',
      caption = ' 2019 spren9er'
    ) +
    theme(
      text = element_text(family = 'Dosis'),
      axis.text.x = element_text(size = 6.5, angle = 90, hjust = 0),
      axis.text.y = element_text(size = 6.5),
      axis.text.x.top = element_text(vjust = 0.5),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_blank(),
      plot.title = element_text(
        size = 8, hjust = -0.53, margin = margin(t = 10, b = 5),
        color = '#555555'
      ),
      plot.subtitle = element_text(
        size = 7, hjust = -0.28, face = 'plain', color = '#555555'
      ),
      plot.caption = element_text(
        color = '#cccccc', size = 5, margin = margin(t = -6), hjust = 0.9825,
        face = 'plain'
      ),
      plot.margin = margin(t = 10, r = 10, b = 10, l = -6)
    )

ggsave(
  'images/tidytuesday_201932_bob_ross_paintings.png',
  width = 3.8, height = 8, dpi = 300
)
","2019"
"250",851,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201938_national_park_visits.r","library(tidyverse)
library(gganimate)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-09-17/'
  )

parks <- read_csv(paste0(path, 'national_parks.csv'))
parks <- parks %>%
  mutate(
    parkname =
      if_else(
        is.na(parkname),
        str_trim(str_remove(unit_name, 'National Park')),
        parkname
      )
  )

highlight_parks <- c(
  'GREAT SMOKY MOUNTAINS',
  'GRAND CANYON',
  'ROCKY MOUNTAIN',
  'YOSEMITE',
  'YELLOWSTONE',
  'ZION',
  'ACADIA',
  'DENALI',
  'HOT SPRINGS',
  'CARLSBAD CAVERNS',
  'GREAT BASIN'
)

highlight_colors <- c(
  '#223e15',
  '#176785',
  '#499989',
  '#5fa73f',
  '#ff8706',
  '#ff534e',
  '#f5b901',
  '#9a91fa',
  '#c988d2',
  '#6da5c2',
  '#fe43bc'
)

ranking_parks <- parks %>%
  filter(
    year != 'Total',
    unit_type == 'National Park',
    !is.na(parkname),
    unit_name != 'Denali National Preserve'
  ) %>%
  mutate(
    year = as.integer(year),
    parkname = str_to_upper(parkname)
  ) %>%
  filter(year < 2016) %>%
  group_by(year) %>%
  arrange(year, desc(visitors)) %>%
  mutate(rank = row_number()) %>%
  ungroup()

top_parks <- ranking_parks %>%
  filter(parkname %in% highlight_parks) %>%
  mutate(parkname = fct_relevel(str_to_upper(parkname), highlight_parks)) %>%
  arrange(year, desc(parkname))

other_parks <- ranking_parks %>%
  filter(!parkname %in% highlight_parks)

animation <- top_parks %>%
  ggplot(aes(x = year, y = rank, group = parkname, color = parkname)) +
  geom_line(
    data = other_parks, size = 0.5, show.legend = FALSE, color = '#dadada'
  ) +
  geom_line(show.legend = FALSE, size = 0.8) +
  geom_text(
    aes(x = year + 0.8, label = parkname),
    size = 4.5, show.legend = FALSE, hjust = 0, fontface = 'bold'
  ) +
  scale_x_continuous(breaks = c(1925, 1950, 1975, 2000)) +
  scale_y_continuous(
    breaks = c(1, 25, 50), labels = c('1??', '25??', '50??'), trans = 'reverse'
  ) +
  scale_color_manual(values = highlight_colors) +
  coord_cartesian(clip = 'off') +
  transition_reveal(year, keep_last = TRUE) +
  labs(
    title = 'The most popular national parks',
    subtitle = 'National parks ranked by number of visitors in a given year',
    x = '',
    y = 'Rank',
    caption = '#tidytuesday 38|2019     2019 spren9er'
  ) +
  theme(
    plot.background = element_rect(fill = '#f0f0f0'),
    plot.margin = margin(t = 40, r = 155, b = 20, l = 20),
    plot.title = element_text(
      margin = margin(b = 8), size = 38, hjust = -0.17, face = 'bold',
      color = '#333333'
    ),
    plot.subtitle = element_text(
      margin = margin(t = 6, b = 5), size = 29, hjust = -0.72,
      face = 'plain', color = '#333333'
    ),
    plot.caption = element_text(
      color = '#999999', size = 13, margin = margin(t = 10), hjust = 0.5,
      face = 'plain', family = 'Decima Mono Pro'
    ),
    panel.background = element_rect(fill = '#f0f0f0'),
    panel.grid.major = element_line(size = 0.5, color = '#d3d3d3'),
    panel.border = element_blank(),
    axis.text.x = element_text(
      family = 'Decima Mono Pro', color = '#999999', face = 'plain', size = 20,
      margin = margin(t = 6)
    ),
    axis.text.y = element_text(
      family = 'Decima Mono Pro', color = '#999999', face = 'plain', size = 20,
      margin = margin(r = 6)
    ),
    axis.title.y = element_text(color = '#333333', face = 'bold', size = 16)
  )

animate(animation, width = 1000, height = 1000, end_pause = 30)

anim_save('images/tidytuesday_201938_national_park_visits.gif')
","2019"
"251",852,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201939_school_diversity.r","library(tidyverse)
library(janitor)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-09-24/'
  )

data <- read_csv(paste0(path, 'school_diversity.csv')) %>%
  clean_names()

data <- data %>%
  select(leaid, total, school_year, diverse) %>%
  rename(id = leaid) %>%
  mutate(
    school_year = str_sub(school_year, 1, 4),
    diverse = fct_recode(
      diverse,
      '1' = 'Diverse', '0' = 'Undiverse', '-1' = 'Extremely undiverse'
    )
  ) %>%
  pivot_wider(names_from = school_year, values_from = c(diverse, total)) %>%
  drop_na()

nrow(data)

# raw data -> d3 (use d3.force layout to calculate source and target coords)
write_csv(data, 'data/tidytuesday_201939_school_diversity_raw.csv')

################################################################################

# combine source and target coords to one single data frame
data_source <- read_csv(
  'data/tidytuesday_201939_school_diversity_preprocessed_source.csv'
)

data_target <- read_csv(
  'data/tidytuesday_201939_school_diversity_preprocessed_target.csv'
)

data_source <- data_source %>%
  mutate(sourceX = x, sourceY = y) %>%
  select(id, x, y, color, sourceRadius, targetRadius, sourceX, sourceY)

data_target <- data_target %>%
  mutate(targetX = x, targetY = y) %>%
  select(id, targetX, targetY)

data_source %>%
  inner_join(data_target) %>%
  write_csv('data/tidytuesday_201939_school_diversity_preprocessed.csv')

################################################################################

# export d3 animation to video (.mov) using quick time player screen recording
# and ffmpeg to downsample and change frame rate
# ffmpeg -y -i input.mov
#   -vf ""setpts=0.1*PTS,scale=1200:-1"" -r 40000/1001 output.mp4
#   -vf ""setpts=0.1*PTS,scale=1200:-1"" -r 40000/1001 output.gif
","2019"
"252",853,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201940_all_the_pizza.r","library(tidyverse)
library(viridis)
library(gganimate)
library(sf)

path <-
  'https://raw.githubusercontent.com/tylerjrichards/Barstool_Pizza/master/'

pizza <- read_csv(paste0(path, 'pizza_data.csv')) %>%
  janitor::clean_names()

number_of_days <- nrow(pizza)

pizza.manhattan <- pizza %>%
  filter(
    city == 'New York',
    review_number != 128
  ) %>%
  mutate(
    score = review_stats_dave_average_score,
    day = review_number + 1
  ) %>%
  select(day, name, longitude, latitude, score) %>%
  drop_na() %>%
  arrange(day)

pizza.manhattan <- pizza.manhattan %>%
  mutate(
    next_longitude = lag(longitude),
    next_latitude = lag(latitude)
  )

days <- tibble(day = 1:number_of_days)
pizza.manhattan <- left_join(days, pizza.manhattan, by = 'day') %>%
  filter(!is.na(longitude) | !is.na(next_longitude)) %>%
  mutate(row_id = row_number())

nyc <- read_sf('data/new_york')

animation <- ggplot(nyc) +
  geom_sf(color='#ffffff', fill='#dedede', size = 0.1) +
  geom_segment(
    data = pizza.manhattan,
    aes(
      x = longitude, y = latitude,
      xend = next_longitude, yend = next_latitude
    ),
    size = 0.2, color = '#333333'
  ) +
  geom_point(
    data = pizza.manhattan,
    aes(x = longitude, y = latitude, color = score),
    size = 1.1
  ) +
  geom_text(
    data = pizza.manhattan,
    aes(
      x = -73.98, y = 40.808,
      label = paste('Day', floor(day))
    ),
    color = ""#333333"", size = 2.75, hjust = 0.5, fontface = 'bold'
  ) +
  geom_text(
    data = pizza.manhattan,
    aes(x = -73.98, y = 40.803, label = name),
    color = ""#333333"", size = 2.5, hjust = 0.5
  ) +
  coord_sf(xlim = c(-74.03, -73.93), ylim = c(40.7, 40.81)) +
  scale_color_viridis_c(limits = c(0, 10), breaks = seq(0,10, 2)) +
  transition_reveal(row_id, keep_last = FALSE) +
  shadow_wake(
    0.07, size = FALSE, alpha = TRUE, wrap = FALSE,
    falloff = 'sine-in', exclude_phase = 'enter', exclude_layer = c(1, 2, 5, 6)
  ) +
  labs(
    title = ""Dave's Pizza Route through Manhattan"",
    subtitle = '#tidytuesday 40|2019',
    caption = ' 2019 spren9er',
    color = 'Rating'
  ) +
  theme_void() +
  theme(
    plot.title = element_text(
      margin = margin(t = 12), size = 11, face = 'plain'
    ),
    plot.subtitle = element_text(
      margin = margin(t = 6.5), size = 8, face = 'bold'
    ),
    plot.caption = element_text(
      color = '#dedede', size = 5, margin = margin(t = -12, b = 4),
      hjust = 0.94
    ),
    legend.text = element_text(size = 6),
    legend.title = element_text(size = 7, margin = margin(b = 2)),
    legend.key.width = unit(0.35, 'cm')
  )

animate(
  animation, nframes = nrow(pizza.manhattan) * 2, width = 750, height = 900, res = 200
)

anim_save('images/tidytuesday_201940_all_the_pizza.gif')
","2019"
"253",854,"https://github.com/spren9er/tidytuesday","spren9er","tidytuesday","tidytuesday_201945_bike_and_walk_commutes.r","library(tidyverse)
library(geofacet)
library(xkcd)

path <-
  paste0(
    'https://raw.githubusercontent.com/rfordatascience/tidytuesday/',
    'master/data/2019/2019-11-05/'
  )

data <- read_csv(paste0(path, 'commute.csv'))

totals <- data %>%
  mutate(
    state_abb = ifelse(state == 'District of Columbia', 'DC', state_abb)
  ) %>%
  drop_na(state_abb) %>%
  group_by(mode, state, state_abb, city_size) %>%
  summarize(total = sum(n)) %>%
  ungroup() %>%
  mutate(
    mode = str_to_lower(mode),
    city_size = str_to_lower(city_size)
  )

percentages <- totals %>%
  group_by(state, state_abb, city_size) %>%
  mutate(total_city_size = sum(total)) %>%
  group_by(state, state_abb) %>%
  mutate(
    total_state = sum(total),
    percentage_city_size = total_city_size / total_state,
    percentage = total / total_city_size
  ) %>%
 pivot_wider(names_from = mode, values_from = c(percentage, total)) %>%
 select(
   state, state_abb, city_size, percentage_city_size, percentage_walk,
   percentage_bike
 ) %>%
 arrange(state, state_abb, city_size)

cum_percentages <- percentages %>%
  group_by(state, state_abb) %>%
  mutate(
    cum_percentage_city_size = cumsum(percentage_city_size),
    lag_cum_percentage_city_size = lag(cum_percentage_city_size, default = 0)
  )

cum_percentages %>%
  ggplot() +
  xkcdrect(
    data = cum_percentages,
    aes(
      xmin = 0, xmax = percentage_walk,
      ymin = lag_cum_percentage_city_size, ymax = cum_percentage_city_size,
      fill = paste('walk', city_size, sep = ' / ')
    ), size = 0.1, show.legend = FALSE) +
  xkcdrect(
    data = cum_percentages,
    aes(
      xmin = percentage_walk, xmax = 1,
      ymin = lag_cum_percentage_city_size, ymax = cum_percentage_city_size,
      fill = paste('bike', city_size, sep = ' / ')
    ), size = 0.1, show.legend = FALSE) +
  scale_fill_manual(
    values = c(
      '#161A29', '#11433F', '#217D66', '#7E4997', '#726BA4', '#85A6CD'
    )
  ) +
  coord_fixed() +
  facet_geo(~state_abb) +
  theme_void() +
  theme(
    text = element_text(family = 'xkcd Script'),
    strip.background = element_blank(),
    plot.title = element_text(
      margin = margin(t = 15), size = 15, hjust = 0.5
    ),
    plot.subtitle = element_text(
      margin = margin(t = 10, b = 11), size = 11, hjust = 0.5
    ),
    plot.caption = element_text(
      color = '#dedede', size = 7, margin = margin(t = 5, b = 6),
      hjust = 0.995
    )
  ) +
  labs(
    title = 'Walk/Bike Ratios of Commutes in U.S. 2008 - 2012',
    subtitle = '(per State & City Size) #tidytuesday 45/2019',
    caption = ' 2019 spren9er'
  )

ggsave('images/tidytuesday_201945_bike_and_walk_commutes.png', dpi = 150)
","2019"
"254",900,"https://github.com/KCachel/kathleen-tidy-tuesdays/tree/master/2019-07-23","KCachel","kathleen-tidy-tuesdays","2019-07-23/tidy_tuesday_7_23_2019.R","library(tidyverse)
library(lubridate)
library(openintro) #convert state abb to full


wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


wildlife <- wildlife_impacts %>%
  filter(state != ""N/A"") %>% 
  filter(state != ""NA"") %>%
  filter(state != ""AC"") %>%
  mutate(year  = year(incident_date)) %>%
  mutate(state = abbr2state(state)) %>%
  select(state, year, operator)
#American Airlines

AA <- wildlife %>%
  filter(operator == ""AMERICAN AIRLINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()
base_size <- 9
#plot american
ggplot(data = AA, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#ece7f2"", high=""#2b8cbe"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""American Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 

ggsave(""2019-07-23/american.png"", width = 7, height = 7)

#United Airlines
united <- wildlife %>%
  filter(operator == ""UNITED AIRLINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()

#plot united
ggplot(data = united, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#ffeda0"", high=""#f03b20"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""United Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 
ggsave(""2019-07-23/united.png"", width = 7, height = 7)

#Delta
delta <- wildlife %>%
  filter(operator == ""DELTA AIR LINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()

#plot delta
ggplot(data = delta, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#e5f5e0"", high=""#31a354"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""Delta Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 
ggsave(""2019-07-23/delta.png"", width = 7, height = 7)

#Southwest
southwest<- wildlife %>%
  filter(operator == ""SOUTHWEST AIRLINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()

#plot southwest
ggplot(data = southwest, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#e7e1ef"", high=""#dd1c77"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""Southwest Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 

ggsave(""2019-07-23/southwest.png"", width = 7, height = 7)

","2019"
"255",901,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-04-16/tidy_tuesday_4_16_2019.R","# Kathleen Cachel

library(tidyverse)
library(reshape2)
library(scales)
library(ggdark)
library(ggthemes)
library(ggpomological)

women_research_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/Economist_women-research.csv"")

research_titles <- c(""country"",
                     ""Health sciences"",
                     ""Physical sciences"",
                     ""Engineering"",
                     ""Computer science, maths"",
                     ""Women inventors"")

# remove rows with NA values
# update Column Names
women_research_clean <- women_research_raw %>% 
  na.omit() %>% 
  set_names(nm = research_titles) %>% 
  filter(country != ""Country"" & country != ""Brazil"" & country != ""Denmark"" & country !=""Britain"" &
           country != ""France"" & country != ""United Kingdom"") %>% 
  gather(field, percent, `Health sciences`:`Women inventors`)

#make men version
men_research_clean <- women_research_clean %>%
  mutate(percent = 1 - as.numeric(percent))

#create new gender column
women_research_clean$gender <- ""female""
men_research_clean$gender <- "" amale""

#update type in women data frame
women_research_clean$percent <- as.numeric(women_research_clean$percent)

#union rows to make one big tidy data set
research_clean <- union(women_research_clean, men_research_clean)




#plotting
united_research <-  unite(research_clean, field_gender, field, gender, sep = ""."", remove = FALSE)


ggplot(data=united_research, aes(x=field, y=percent, fill=field_gender)) + 
  geom_bar(stat=""identity"") + 
  facet_grid(country~., switch = ""y"")+
  scale_fill_manual(breaks = c(""Women inventors.female"", ""Physical sciences.female"",""Health sciences.female"", ""Engineering.female"", ""Computer science, maths.female""),
                    values = c(""#efedf5"", ""#756bb1"",""#e5f5e0"" , ""#31a354"",""#deebf7"", ""#3182bd"",
                               ""#fde0dd"", ""#c51b8a"",""#fff7bc"", ""#d95f0e""), 
                    labels =c(""Women inventors"", ""Physical sciences"",""Health sciences"", ""Engineering"", ""Computer science & Math""),
                    name = ""Field:"")+
  coord_flip()+
  theme_economist_white( base_size = 14)+
  theme(axis.text.y = element_blank(),
        legend.position = ""bottom"",
        strip.text.y = element_text(angle = 180),
        legend.text = element_text(size =10, face = ""bold"")
  )+
  labs(x = """", y = ""Percent of total field that are Women"",
       title = ""Still a man's world"",
       subtitle = ""Women among researchers with papers published 2011-2015 *"",
       caption = ""Sources: 'Gender in the Global Research Landscape' by Elsevier *Indexed in Scopus"")+
  scale_y_continuous(labels = percent)+
  geom_hline(yintercept=.50, linetype=""dashed"", 
             color = ""red"", size=2)

ggsave(""my_women_researcher_plot.png"", width = 10.5, height = 8)


","2019"
"256",902,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-06-04/tidy_tuesday_6_4_2019.R","library(tidyverse)
library(ggthemes)
library(ggdark)
library(LaCroixColoR)
ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

summary(ramen_ratings)

#Find the top 20 producing countries 
ramen_topcountries <- ramen_ratings %>%
  group_by(country,style) %>%
  tally() %>%
  arrange(-n) %>%
  #head(20) %>%
  inner_join(ramen_ratings)

#Find average ratings per country:
country_average <- ramen_topcountries %>%
  group_by(country,style) %>%
  summarize(
    avg = mean(stars, na.rm = TRUE)
  ) %>%
  arrange(-avg)

topcountrieslist <- ramen_topcountries %>% 
  group_by(country) %>%
  summarize(
    avg = mean(stars, na.rm = TRUE)
  ) %>%
  arrange(-avg) %>%
  head(25) %>% 
  select(country)

country_averagestyle <- filter(country_average, style == ""Bowl"" |
                                 style == ""Cup"" |
                                 style == ""Pack"") %>%
  inner_join(topcountrieslist)

# Create palette
pal <- c(""#803515"", ""#F0B630"", ""#E6442E"")

###gplot
ggplot(country_averagestyle, aes(avg, country, fill = style)) +
  #geom_point(size = 4) +
  geom_bar(stat = ""identity"")
  dark_mode() +
  scale_fill_manual(values = pal, name = ""Style:"") +
    coord_flip()
  labs(x = """", y = ""Country"", title = ""Average Ramen Rating by Country"") +
  theme(legend.position = ""top"",
        axis.text.x=element_text(size=11, face = ""bold"", hjust = 1, color = ""#666C1C""),
        axis.text.y = element_text(size = 10, color = ""#666C1C""),
        axis.title.y = element_text(color = ""#666C1C"", face = ""bold""),
        legend.title = element_text(color = ""#666C1C"", size = 12, face = ""bold""),
        legend.text = element_text(color = ""#666C1C"", face = ""bold""),
        plot.title = element_text(color = ""#666C1C"", face = ""bold"")) 



","2019"
"257",903,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-06-18/R_rainclouds.R","### Script from : https://github.com/RainCloudPlots/RainCloudPlots/blob/master/tutorial_R/R_rainclouds.R
### This script creates an R function to generate raincloud plots, then simulates
### data for plots. If using for your own data, you only need lines 1-80.
### It relies largely on code previously written by David Robinson
### (https://gist.github.com/dgrtwo/eb7750e74997891d7c20)
### and the package ggplot2 by Hadley Wickham

# Check if required packages are installed ----
packages <- c(""cowplot"", ""readr"", ""ggplot2"", ""dplyr"", ""lavaan"", ""smooth"", ""Hmisc"")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}

# Load packages ----
library(ggplot2)

# Defining the geom_flat_violin function ----
# Note: the below code modifies the
# existing github page by removing a parenthesis in line 50

""%||%"" <- function(a, b) {
  if (!is.null(a)) a else b
}

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = ""ydensity"",
                             position = ""dodge"", trim = TRUE, scale = ""area"",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}


#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
  ggproto(""GeomFlatViolin"", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            # ymin, ymax, xmin, and xmax define the bounding rectangle for each group
            data %>%
              group_by(group) %>%
              mutate(
                ymin = min(y),
                ymax = max(y),
                xmin = x,
                xmax = x + width / 2
              )
          },
          
          draw_group = function(data, panel_scales, coord) {
            # Find the points for the line to go all the way around
            data <- transform(data,
                              xminv = x,
                              xmaxv = x + violinwidth * (xmax - x)
            )
            
            # Make sure it's sorted properly to draw the outline
            newdata <- rbind(
              plyr::arrange(transform(data, x = xminv), y),
              plyr::arrange(transform(data, x = xmaxv), -y)
            )
            
            # Close the polygon: set first and last point the same
            # Needed for coord_polar and such
            newdata <- rbind(newdata, newdata[1, ])
            
            ggplot2:::ggname(""geom_flat_violin"", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          
          draw_key = draw_key_polygon,
          
          default_aes = aes(
            weight = 1, colour = ""grey20"", fill = ""white"", size = 0.5,
            alpha = NA, linetype = ""solid""
          ),
          
          required_aes = c(""x"", ""y"")
  )

","2019"
"258",904,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-06-18/tidy_tuesday_6_18_2019.R","library(tidyverse)
library(ggthemes)
library(ggdark)
library(magick)
library(grid)
library(gridExtra)
library(gganimate)
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

summary(bird_counts)

top8birds <- bird_counts %>%
  group_by(species) %>%
  summarize(s = sum(how_many_counted)) %>%
  arrange(-s) %>%
  head(8) %>%
  inner_join(bird_counts) %>%
  filter(species != ""European Starling"")

b <- ggplot(data = top8birds, aes(y = how_many_counted, x = species, fill = species)) +
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .8) +
  geom_point(aes(y = how_many_counted, color = species), position = position_jitter(width = .15), size = .5, alpha = 0.8) +
  geom_boxplot(width = .1, outlier.shape = NA, alpha = 0.5) +
  #expand_limits(x = 1) +
  guides(fill = FALSE) +
  guides(color = FALSE) +
  scale_color_brewer(palette = ""Spectral"") +
  scale_fill_brewer(palette = ""Spectral"") +
  coord_flip() +
  theme_bw()


a <- ggplot(top8birds, aes(x = total_hours, y = how_many_counted, color = species)) + 
  geom_point(size = 3.5) +
  scale_color_brewer(palette = ""Spectral"") + 
  theme_bw()
  
a + transition_time(year) +
  labs(title = ""Year: {frame_time}"")+
  shadow_wake(wake_length = 0, alpha = FALSE)

p <- ggplot(data = top8birds, aes(y = how_many_counted, x = year, color = species)) +
  geom_line(stat= 'identity')+
  scale_color_brewer(palette = ""Spectral"") +
  theme_bw()

p + transition_reveal(year)
","2019"
"259",905,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-07-30/tidy_tuesday_7_30_2019.R","library(tidyverse)
library(lubridate)
library(ggridges)
library(viridis)
library(ggdark)
library(LaCroixColoR)
# clean dataset from lizawood's github
url <- ""https://raw.githubusercontent.com/lizawood/apps-and-games/master/PC_Games/PCgames_2004_2018_raw.csv""

# read in raw data
raw_df <- url %>% 
  read_csv() %>% 
  janitor::clean_names() 

# clean up some of the factors and playtime data
clean_df <- raw_df %>% 
  mutate(price = as.numeric(price),
         score_rank = word(score_rank_userscore_metascore, 1),
         average_playtime = word(playtime_median, 1),
         median_playtime = word(playtime_median, 2),
         median_playtime = str_remove(median_playtime, ""\\(""),
         median_playtime = str_remove(median_playtime, ""\\)""),
         average_playtime = 60 * as.numeric(str_sub(average_playtime, 1, 2)) +
           as.numeric(str_sub(average_playtime, 4, 5)),
         median_playtime = 60 * as.numeric(str_sub(median_playtime, 1, 2)) +
           as.numeric(str_sub(median_playtime, 4, 5)),
         metascore = as.double(str_sub(score_rank_userscore_metascore, start = -4, end = -3))) %>% 
  select(-score_rank_userscore_metascore, -score_rank, -playtime_median) %>% 
  rename(publisher = publisher_s, developer = developer_s)



pub <- clean_df %>% 
  filter(publisher == ""Paradox Interactive"") %>%
  mutate( release_date = mdy(release_date)) %>%
  mutate( release_date = year(release_date)) %>%
  arrange(release_date) %>%
  filter(price != ""NA"")
  
  

ggplot(pub, aes(x = price, y = release_date, group = release_date, fill = ..x..)) + 
  geom_density_ridges_gradient() +
  scale_fill_viridis(option= 'B', name = ""Game Price [$]"") +
  dark_theme_grey() +
  labs(title = 'Are Paradox Interactive video game prices increasing?') +
  theme(legend.position = ""bottom"",
        axis.text.x=element_text(size=11, face = ""bold"", hjust = 1, color = ""deeppink""),
        axis.text.y = element_text(size = 10, color = ""deeppink"", face = ""bold""),
        axis.title.x = element_text(color = ""deeppink"", face = ""bold""),
        legend.title = element_text(color = ""deeppink"", size = 12, face = ""bold""),
        legend.text = element_text(color = ""deeppink"", face = ""bold""),
        plot.title = element_text(color = ""deeppink"", face = ""bold""))

ggsave(""2019-07-30/paradox.png"", width = 7, height = 7)

","2019"
"260",921,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-04-10 CopaMundial.R","library(tidyverse)

partidos_fifa_copa_mundial_procesado <- readr::read_delim(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-04-10/partidos.txt"",delim = ""\t"")

partidos <- partidos_fifa_copa_mundial_procesado

head(partidos)

## Organizacin de los datos

partidos <- partidos %>% 
  mutate(partido_orden = as.numeric(gsub(""[()]"", """", partido_orden)))

## Grafico exploratorio de cantidad de goles por Copa

partidos %>% 
  group_by(anio) %>% 
  summarize(num_partidos = n(), goles = sum(equipo_1_final,equipo_2_final), rate = goles/num_partidos) %>% 
  ggplot(aes(anio, rate)) +
  geom_col() + geom_smooth()

## Cantidad de partidos ganados en Mundiales por Pas
  
partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(ganador, sort = TRUE) %>% 
  ggplot(aes(fct_reorder(ganador, n), n, fill = ganador, label = n)) + 
  geom_col() +
  geom_text(hjust = -0.2) +
  coord_flip() +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Cantidad de partidos ganados en Mundiales por Pas"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Pas"",
       y = ""Cantidad de partidos ganados"") 

## Pas con mayor cantidad de partidos ganados por Copa Mundial

partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(anio, ganador, sort = TRUE) %>% 
  group_by(anio) %>% 
  mutate(posicion = rank(-n, ties.method = ""first"")) %>% 
  ungroup() %>% 
  filter(posicion <= 1) %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas con mayor cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 

## Identificando el partido final de cada Copa

max_partidos <- partidos %>% 
  group_by(anio) %>% 
  summarize(max_partido = max(partido_orden))

## Definiendo el ganar de cada partido, este si incluye el Empate

ganador_partido <- partidos %>% 
  mutate(ganador = case_when(
    equipo_1_final > equipo_2_final ~ equipo_1,
    equipo_1_final < equipo_2_final ~ equipo_2,
    TRUE ~ ""Empate"")) 

## Seleccionando el ganador del ltimo partido de cada copa con su nmero de partidos ganados

campeon <- ganador_partido %>% 
  semi_join(max_partidos, by = c(""partido_orden"" = ""max_partido"", ""anio"" = ""anio"")) %>% 
  select(anio, ganador)

## Grfico del Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial

ganador_partido %>% 
  count(anio, ganador, sort = TRUE) %>% 
  right_join(campeon, by = c(""anio"", ""ganador"")) %>% 
  filter(ganador != ""Empate"") %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 
  
","2019"
"261",922,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-04-15 EU_balance.R","library(tidyverse)


eu_balance <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")


## Just factor declarations for country and account_type

eu_balance <- eu_balance %>% 
  mutate(country = as_factor(country),
         account_type = as_factor(account_type))

## Did a percentual balance growth, but at the end didn't use it

eu_balance %>% 
  filter(year %in% c(2009,2015), account_type == ""current"") %>% 
  spread(key = ""year"", value = ""value"") %>% 
  mutate(balance_growth = (`2015` - `2009`) / `2015`) -> eu_balance_growth 

min(eu_balance_growth$`2009`)
min(eu_balance_growth$`2015`)

## Graph 2009 to 2015 Growth relationship of Current Values by Country

eu_balance_growth %>% 
  mutate(`2009` = `2009` + 56192,
         `2015` = `2015` + 18091) %>% ## Had to add values for the log transformation
  ggplot(aes(x = `2009`, y = `2015`, col = country, label = country)) +
  geom_jitter(alpha = 0.5) +
  geom_text(vjust = -0.5) +
  scale_x_log10() + 
  scale_y_log10() + 
  labs(title = ""2009 to 2015 Growth relationship of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""2009 \n log10 value"",
       y = ""2015 \n log10 value"") +
  theme_light() +
  theme(legend.position = ""none"")

## 2009 to 2015 Growth of Current Values by Country

eu_balance_growth %>% 
  select(country, `2009`,`2015`) %>% 
  mutate(country = fct_reorder(country, `2015`)) %>% 
  gather(key = year, value = value, `2009`:`2015`, -country) %>% 
  ggplot(aes(x = country, y = value, group = country, col = year)) + 
  geom_point(size = 2) +
  geom_path(arrow = arrow(length = unit(1.5, ""mm""), type = ""closed""), col = ""DarkBlue"") + 
  coord_flip() +
  labs(title = ""2009 to 2015 Growth of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""Country"",
       y = ""2009 to 2015 value"") +
  theme_light() 
","2019"
"262",923,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-04-30 Birds.R","library(tidyverse)
library(lubridate)
Sys.setlocale(""LC_TIME"", ""C"")

bird_collisions_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

head(bird_collisions_raw)

## Tidy the Dates

bird_collisions <- bird_collisions_raw %>% 
  mutate_at(vars(-date), as_factor) %>% 
  mutate(month = months(ymd(date)),
         day = weekdays(ymd(date)))
  

library(FactoMineR)
library(""factoextra"")

## Correspondence analysis

bird_mca <- bird_collisions %>% 
  filter(flight_call != c(""Rare"", ""No""),
         genus %in% c(""Melospiza"", ""Zonotrichia"", ""Catharus"", ""Junco"", ""Setophaga"")) %>% 
  select(genus, habitat, locality, month) %>% 
  MCA(ncp = 5, graph = FALSE)

fviz_mca_var(bird_mca, col.var = ""cos2"", 
             repel = TRUE, # Avoid text overlapping
             ggtheme = theme_minimal()) + 
  labs(title = ""Flight call birds Correspondence analysis by genus, habitat, locality and month \nfor Genus top 5 bird crashers"", 
       caption = ""Winger BM, Weeks BC, Farnsworth A, Jones AW, Hennen M, Willard DE (2019)\nNocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. \nProceedings of the Royal Society B 286(1900): 20190364."")



","2019"
"263",924,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-06-04 Ramen ratings.R","library(tidyverse)
library(countrycode)
library(ggridges)


ramen_ratings_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")


## Cargar fuentes de windows
library(extrafont)
loadfonts(device = ""win"")


ramen_ratings <- ramen_ratings_raw %>% 
  filter(style %in% c(""Bowl"", ""Cup"", ""Pack"", ""Tray"")) %>% 
  mutate(continent = countrycode(sourcevar = country, 
                                 origin = ""country.name.en"", 
                                 destination = ""continent"")) %>% 
  filter(!is.na(continent))


## Density ridges plot

ramen_ratings %>% 
  ggplot(aes(x = stars, y = continent, fill = continent, group = continent)) + 
  geom_density_ridges(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

## Violin plot

ramen_ratings %>% 
  ggplot(aes(x = continent, y = stars, fill = continent, group = continent)) + 
  geom_violin(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  coord_flip() + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))
","2019"
"264",925,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-07-25 Play Store.Rmd","---
title: ""Datos aplicaciones Google""
author: ""R para la ciencia de datos - DlanyR""
date: ""25/7/2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

apps <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-07-24/apps_googleplaystore.csv"")

glimpse(apps)

```

## Explorar los datos

```{r}

apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(categoria = fct_reorder(categoria, n)) %>% 
  ggplot(aes(x = categoria, y = n, label = n)) + 
  geom_col() + 
  geom_text(hjust = 1, col = ""white"") +
  coord_flip() + 
  labs(title = ""Cantidad de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia absoluta"",
       caption = ""Fuente de datos: Kaggle"")

perc_redondeado <- function(x){
    paste(round(x, 3)*100, ""%"", sep = """")
}


apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(perc = n / sum(n),
         perc_acum = cumsum(perc),
         categoria = fct_reorder(categoria, -n)) %>% 
  ggplot(aes(categoria, perc)) + 
  geom_col() + 
  geom_point(aes(x = categoria, y = perc_acum, group = 1)) +
  geom_line(aes(x = categoria, y = perc_acum, group = 1)) + 
  geom_text(aes(x = categoria, y = perc_acum, group = 1, label = perc_redondeado(perc_acum)),
            vjust = -1, angle = 30, size = 3.5) + 
  theme_light() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = ""Pareto de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia relativa"",
       caption = ""Fuente de datos: Kaggle"")
  


```

","2019"
"265",926,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-08-06 Bob Ross.R","library(tidyverse)
library(janitor)
library(RColorBrewer)
library(extrafont)

font_import()
loadfonts(device = ""win"")


bob_ross_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")

glimpse(bob_ross_raw)

bob_ross <- bob_ross_raw %>% 
  gather(key = ""element"", value = ""presence"", APPLE_FRAME:WOOD_FRAMED) %>% 
  filter(presence != 0) %>% 
  separate(col = EPISODE, into = c(""season"", ""episode""), sep = ""E"") %>% 
  mutate(season = parse_number(season),
         season = factor(season),
         episode = parse_integer(episode)) %>% 
  clean_names() %>% 
  select(-presence)

bob_ross_season_top10 <- bob_ross %>% 
  group_by(season) %>% 
  count(element, sort = TRUE) %>% 
  slice(1:10) %>% 
  ungroup() 

getPalette = colorRampPalette(brewer.pal(9, ""Greens""))

bob_ross_season_top10 %>% 
  ggplot(aes(season, n, fill = element, label = paste(str_to_lower(element), n, sep = "" ""))) + 
  geom_col() + 
  geom_text(position = ""stack"", size = 3, hjust = 1) + 
  coord_flip() + 
  labs(title = ""Bob Ross Top 10 word-element by Season"",
       x = ""Season"",
       y = ""Number of episodes mentioned"",
       caption = ""Data Source: 538"") + 
  scale_fill_manual(values = getPalette(22)) + 
  theme_minimal() + 
  theme(legend.position = ""none"",
        text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

","2019"
"266",927,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-04-10 CopaMundial.R","library(tidyverse)

partidos_fifa_copa_mundial_procesado <- readr::read_delim(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-04-10/partidos.txt"",delim = ""\t"")

partidos <- partidos_fifa_copa_mundial_procesado

head(partidos)

## Organizacin de los datos

partidos <- partidos %>% 
  mutate(partido_orden = as.numeric(gsub(""[()]"", """", partido_orden)))

## Grafico exploratorio de cantidad de goles por Copa

partidos %>% 
  group_by(anio) %>% 
  summarize(num_partidos = n(), goles = sum(equipo_1_final,equipo_2_final), rate = goles/num_partidos) %>% 
  ggplot(aes(anio, rate)) +
  geom_col() + geom_smooth()

## Cantidad de partidos ganados en Mundiales por Pas
  
partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(ganador, sort = TRUE) %>% 
  ggplot(aes(fct_reorder(ganador, n), n, fill = ganador, label = n)) + 
  geom_col() +
  geom_text(hjust = -0.2) +
  coord_flip() +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Cantidad de partidos ganados en Mundiales por Pas"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Pas"",
       y = ""Cantidad de partidos ganados"") 

## Pas con mayor cantidad de partidos ganados por Copa Mundial

partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(anio, ganador, sort = TRUE) %>% 
  group_by(anio) %>% 
  mutate(posicion = rank(-n, ties.method = ""first"")) %>% 
  ungroup() %>% 
  filter(posicion <= 1) %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas con mayor cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 

## Identificando el partido final de cada Copa

max_partidos <- partidos %>% 
  group_by(anio) %>% 
  summarize(max_partido = max(partido_orden))

## Definiendo el ganar de cada partido, este si incluye el Empate

ganador_partido <- partidos %>% 
  mutate(ganador = case_when(
    equipo_1_final > equipo_2_final ~ equipo_1,
    equipo_1_final < equipo_2_final ~ equipo_2,
    TRUE ~ ""Empate"")) 

## Seleccionando el ganador del ltimo partido de cada copa con su nmero de partidos ganados

campeon <- ganador_partido %>% 
  semi_join(max_partidos, by = c(""partido_orden"" = ""max_partido"", ""anio"" = ""anio"")) %>% 
  select(anio, ganador)

## Grfico del Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial

ganador_partido %>% 
  count(anio, ganador, sort = TRUE) %>% 
  right_join(campeon, by = c(""anio"", ""ganador"")) %>% 
  filter(ganador != ""Empate"") %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 
  
","2019"
"267",928,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-04-15 EU_balance.R","library(tidyverse)


eu_balance <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")


## Just factor declarations for country and account_type

eu_balance <- eu_balance %>% 
  mutate(country = as_factor(country),
         account_type = as_factor(account_type))

## Did a percentual balance growth, but at the end didn't use it

eu_balance %>% 
  filter(year %in% c(2009,2015), account_type == ""current"") %>% 
  spread(key = ""year"", value = ""value"") %>% 
  mutate(balance_growth = (`2015` - `2009`) / `2015`) -> eu_balance_growth 

min(eu_balance_growth$`2009`)
min(eu_balance_growth$`2015`)

## Graph 2009 to 2015 Growth relationship of Current Values by Country

eu_balance_growth %>% 
  mutate(`2009` = `2009` + 56192,
         `2015` = `2015` + 18091) %>% ## Had to add values for the log transformation
  ggplot(aes(x = `2009`, y = `2015`, col = country, label = country)) +
  geom_jitter(alpha = 0.5) +
  geom_text(vjust = -0.5) +
  scale_x_log10() + 
  scale_y_log10() + 
  labs(title = ""2009 to 2015 Growth relationship of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""2009 \n log10 value"",
       y = ""2015 \n log10 value"") +
  theme_light() +
  theme(legend.position = ""none"")

## 2009 to 2015 Growth of Current Values by Country

eu_balance_growth %>% 
  select(country, `2009`,`2015`) %>% 
  mutate(country = fct_reorder(country, `2015`)) %>% 
  gather(key = year, value = value, `2009`:`2015`, -country) %>% 
  ggplot(aes(x = country, y = value, group = country, col = year)) + 
  geom_point(size = 2) +
  geom_path(arrow = arrow(length = unit(1.5, ""mm""), type = ""closed""), col = ""DarkBlue"") + 
  coord_flip() +
  labs(title = ""2009 to 2015 Growth of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""Country"",
       y = ""2009 to 2015 value"") +
  theme_light() 
","2019"
"268",929,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-04-30 Birds.R","library(tidyverse)
library(lubridate)
Sys.setlocale(""LC_TIME"", ""C"")

bird_collisions_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

head(bird_collisions_raw)

## Tidy the Dates

bird_collisions <- bird_collisions_raw %>% 
  mutate_at(vars(-date), as_factor) %>% 
  mutate(month = months(ymd(date)),
         day = weekdays(ymd(date)))
  

library(FactoMineR)
library(""factoextra"")

## Correspondence analysis

bird_mca <- bird_collisions %>% 
  filter(flight_call != c(""Rare"", ""No""),
         genus %in% c(""Melospiza"", ""Zonotrichia"", ""Catharus"", ""Junco"", ""Setophaga"")) %>% 
  select(genus, habitat, locality, month) %>% 
  MCA(ncp = 5, graph = FALSE)

fviz_mca_var(bird_mca, col.var = ""cos2"", 
             repel = TRUE, # Avoid text overlapping
             ggtheme = theme_minimal()) + 
  labs(title = ""Flight call birds Correspondence analysis by genus, habitat, locality and month \nfor Genus top 5 bird crashers"", 
       caption = ""Winger BM, Weeks BC, Farnsworth A, Jones AW, Hennen M, Willard DE (2019)\nNocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. \nProceedings of the Royal Society B 286(1900): 20190364."")



","2019"
"269",930,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-06-04 Ramen ratings.R","library(tidyverse)
library(countrycode)
library(ggridges)


ramen_ratings_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")


## Cargar fuentes de windows
library(extrafont)
loadfonts(device = ""win"")


ramen_ratings <- ramen_ratings_raw %>% 
  filter(style %in% c(""Bowl"", ""Cup"", ""Pack"", ""Tray"")) %>% 
  mutate(continent = countrycode(sourcevar = country, 
                                 origin = ""country.name.en"", 
                                 destination = ""continent"")) %>% 
  filter(!is.na(continent))


## Density ridges plot

ramen_ratings %>% 
  ggplot(aes(x = stars, y = continent, fill = continent, group = continent)) + 
  geom_density_ridges(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

## Violin plot

ramen_ratings %>% 
  ggplot(aes(x = continent, y = stars, fill = continent, group = continent)) + 
  geom_violin(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  coord_flip() + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))
","2019"
"270",931,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-07-25 Play Store.Rmd","---
title: ""Datos aplicaciones Google""
author: ""R para la ciencia de datos - DlanyR""
date: ""25/7/2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

apps <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-07-24/apps_googleplaystore.csv"")

glimpse(apps)

```

## Explorar los datos

```{r}

apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(categoria = fct_reorder(categoria, n)) %>% 
  ggplot(aes(x = categoria, y = n, label = n)) + 
  geom_col() + 
  geom_text(hjust = 1, col = ""white"") +
  coord_flip() + 
  labs(title = ""Cantidad de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia absoluta"",
       caption = ""Fuente de datos: Kaggle"")

perc_redondeado <- function(x){
    paste(round(x, 3)*100, ""%"", sep = """")
}


apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(perc = n / sum(n),
         perc_acum = cumsum(perc),
         categoria = fct_reorder(categoria, -n)) %>% 
  ggplot(aes(categoria, perc)) + 
  geom_col() + 
  geom_point(aes(x = categoria, y = perc_acum, group = 1)) +
  geom_line(aes(x = categoria, y = perc_acum, group = 1)) + 
  geom_text(aes(x = categoria, y = perc_acum, group = 1, label = perc_redondeado(perc_acum)),
            vjust = -1, angle = 30, size = 3.5) + 
  theme_light() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = ""Pareto de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia relativa"",
       caption = ""Fuente de datos: Kaggle"")
  


```

","2019"
"271",932,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-08-06 Bob Ross.R","library(tidyverse)
library(janitor)
library(RColorBrewer)
library(extrafont)

font_import()
loadfonts(device = ""win"")


bob_ross_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")

glimpse(bob_ross_raw)

bob_ross <- bob_ross_raw %>% 
  gather(key = ""element"", value = ""presence"", APPLE_FRAME:WOOD_FRAMED) %>% 
  filter(presence != 0) %>% 
  separate(col = EPISODE, into = c(""season"", ""episode""), sep = ""E"") %>% 
  mutate(season = parse_number(season),
         season = factor(season),
         episode = parse_integer(episode)) %>% 
  clean_names() %>% 
  select(-presence)

bob_ross_season_top10 <- bob_ross %>% 
  group_by(season) %>% 
  count(element, sort = TRUE) %>% 
  slice(1:10) %>% 
  ungroup() 

getPalette = colorRampPalette(brewer.pal(9, ""Greens""))

bob_ross_season_top10 %>% 
  ggplot(aes(season, n, fill = element, label = paste(str_to_lower(element), n, sep = "" ""))) + 
  geom_col() + 
  geom_text(position = ""stack"", size = 3, hjust = 1) + 
  coord_flip() + 
  labs(title = ""Bob Ross Top 10 word-element by Season"",
       x = ""Season"",
       y = ""Number of episodes mentioned"",
       caption = ""Data Source: 538"") + 
  scale_fill_manual(values = getPalette(22)) + 
  theme_minimal() + 
  theme(legend.position = ""none"",
        text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

","2019"
"272",970,"https://github.com/tomasu909/Tidy-Tuesday-Submissions/blob/master/2019/tidytuesday29.Rmd","tomasu909","Tidy-Tuesday-Submissions","2019/tidytuesday29.Rmd","---
title: ""Tidy Tuesday #29 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      dpi = 144,
                      fig.align = ""center"")
remove(list = ls(all.names = TRUE))
detachAllPackages <- function() {
  basic.packages.blank <-  c(""stats"",""graphics"",""grDevices"",""utils"",""datasets"",""methods"",""base"")
  basic.packages <- paste(""package:"", basic.packages.blank, sep = """")
  package.list <- search()[ifelse(unlist(gregexpr(""package:"", search())) == 1,TRUE,FALSE)]
  package.list <- setdiff(package.list, basic.packages)
  if (length(package.list) > 0)  for (package in package.list) {
    detach(package, character.only = TRUE)}}
detachAllPackages()
if (!require(pacman)) {
  install.packages(""pacman"")
  require(pacman)
}
p_load(tidyverse, knitr, data.table, lubridate, zoo, hrbrthemes, tidytuesdayR, prophet, forecast, gridExtra)

`%g%` <- function(x,y) {
  z <- paste0(y, collapse = ""|"")
  grepl(z, x, ignore.case = T)
}

nowt <- function(x = NULL) x
```

```{r}
tt_load(2019, week = 29) %>% 
  map(~list2env(.x[1], envir = .GlobalEnv))
```

```{r}
fit <- r4ds_members %>% 
  select(ds = date, 
         y  = weekly_active_members) %>% 
  prophet(yearly.seasonality = T, 
          weekly.seasonality = T)

future <- make_future_dataframe(fit, periods = 365.25/2, freq = 'day')

m <- predict(fit, future)

plot(fit, m) +
  theme_ipsum_rc() +
  labs(
    title = ""R for Data Science Online Learning Community"",
    subtitle = ""Modeling and Forecasting Weekly Active Slack Members"",
    caption = ""Source: https://github.com/rfordatascience/tidytuesday"",
    y = ""Active Members"",
    x = """"
  ) -> p

ggsave(p, filename = ""tt_2019_29.png"",device = ""png"", dpi = 144, width = 8, height = 6)
```



","2019"
"273",971,"https://github.com/tomasu909/Tidy-Tuesday-Submissions/blob/master/2019/tidytuesday28.Rmd","tomasu909","Tidy-Tuesday-Submissions","2019/tidytuesday28.Rmd","---
title: ""Women's World Cup""
output: html_document
---

```{r setup, include=FALSE}
options(repos='http://cran.rstudio.com/')
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
remove(list = ls(all.names = TRUE))
detachAllPackages <- function() {
  basic.packages.blank <- c(
    ""stats"",
    ""graphics"",
    ""grDevices"",
    ""utils"",
    ""datasets"",
    ""methods"",
    ""base""
  )
  basic.packages <- paste(""package:"", basic.packages.blank, sep = """")
  package.list <- search()[ifelse(unlist(gregexpr(""package:"", search())) == 1, TRUE, FALSE)]
  package.list <- setdiff(package.list, basic.packages)
  if (length(package.list) > 0) {
    for (package in package.list) {
      detach(package, character.only = TRUE)
    }
  }
}
detachAllPackages()
if (!require(pacman)) {
  install.packages(""pacman"")
  require(pacman)
}

`%g%` <- function(x,y) {
  z <- paste0(y, collapse = ""|"")
  grepl(z, x, ignore.case = T)
}

nowt <- function(x = NULL) x

extrafont::loadfonts(quiet = T)

tc <- c(""#A5143F"", ""#E5350F"", ""#E67F18"", ""#F5BD0E"", ""#8BDEFC"", ""#38BAB6"", ""#234C68"", ""#4B3460"")

p_load(janitor, tidyverse, hrbrthemes, scales, carbonate)
```

```{r}
wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
```

```{r}
goal_diff <- wwc_outcomes %>% 
  filter(win_status != ""Tie"") %>% 
  nest(-year, -yearly_game_id) %>% 
  mutate(data = map(data, ~.x %>% 
                      mutate(team = paste(team, score, sep = ""_"")) %>% 
                      select(team, round, win_status) %>% 
                      spread(win_status, team))) %>% 
  unnest() %>% 
  separate(Won, c(""W_T"", ""W_S""), ""_"") %>% 
  separate(Lost, c(""L_T"", ""L_S""), ""_"") %>% 
  transmute(Game = paste(W_T, "" vs "", L_T, "" ("", year, "")"", sep = """"),
            Diff = as.numeric(W_S) - as.numeric(L_S),
            Score = paste(W_S, L_S, sep = "" - ""),
            Round = round) %>% 
  arrange(desc(Diff))
```

```{r}
goal_diff %>% 
  head(10) %>% 
  ggplot(aes(reorder(Game, Diff), Diff, fill = Round)) + 
  geom_bar(stat = ""identity"") +
  theme_ipsum_rc(plot_title_size = 20) +
  geom_text(aes(label = Score),
    colour = ""white"", 
    nudge_y = -.5, 
    nudge_x = .02, 
    fontface = ""bold"",
    size = 3
  ) +
  coord_flip() +
  scale_fill_manual(values = c(""#234C68"", ""#E5350F"")) +
  labs(
    title = ""	Women's World Cup: Biggest Blowouts"",
    subtitle = ""Top 10 Games With the Largest Goal Differential"",
    caption = ""Source: https://data.world/sportsvizsunday/womens-world-cup-data"",
    x = """",
    y = ""Goal Differential""
  ) +
  nowt() -> wwc_tt28

ggsave(
  wwc_tt28, 
  filename = ""wwc_tt28.png"", 
  device = ""png"", dpi = 200, 
  width = 10, height = 5.625, 
  units = ""in""
  )
```


","2019"
"274",972,"https://github.com/tomasu909/Tidy-Tuesday-Submissions/blob/master/2019/tidytuesday31.Rmd","tomasu909","Tidy-Tuesday-Submissions","2019/tidytuesday31.Rmd","---
title: ""Tidy Tuesday #30 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE, 
                      dpi = 144,
                      fig.align = ""center"")
remove(list = ls(all.names = TRUE))
detachAllPackages <- function() {
  basic.packages.blank <-  c(""stats"",""graphics"",""grDevices"",""utils"",""datasets"",""methods"",""base"")
  basic.packages <- paste(""package:"", basic.packages.blank, sep = """")
  package.list <- search()[ifelse(unlist(gregexpr(""package:"", search())) == 1,TRUE,FALSE)]
  package.list <- setdiff(package.list, basic.packages)
  if (length(package.list) > 0)  for (package in package.list) {
    detach(package, character.only = TRUE)}}
detachAllPackages()
if (!require(pacman)) {
  install.packages(""pacman"")
  require(pacman)
}

# devtools::install_github(""hrbrmstr/statebins"") # Install newest statebins package

p_load(tidyverse, knitr, data.table, lubridate, zoo, hrbrthemes, tidytuesdayR, prophet, forecast, gridExtra, statebins, gganimate, gifski, png, Hmisc, janitor, ggridges, highcharter, viridis)

`%g%` <- function(x,y) {
  z <- paste0(y, collapse = ""|"")
  grepl(z, x, ignore.case = T)
}

nowt <- function(x = NULL) x
```

```{r}
tt_load(2019, week = 31) %>% 
  map(~list2env(.x[1], envir = .GlobalEnv))
```

```{r, fig.height=5, fig.width=7}
tc <- c(""#A5143F"", ""#E5350F"", ""#E67F18"", ""#F5BD0E"", ""#8BDEFC"", ""#38BAB6"", ""#234C68"", ""#4B3460"")

ce <- c(""#303030"", ""#063A9C"", ""#36A8DC"", ""#BAE8F3"", ""#FACB6B"", ""#FC8D1E"", ""#F74543"", ""#7C246C"")

video_games %>%
  select(publisher, metascore, owners) %>%
  filter(!is.na(metascore)) %>%
  group_by(publisher) %>%
  mutate(
    total = n(),
    med   = median(metascore)
  ) %>%
  ungroup() %>%
  nest(metascore, owners) %>%
  arrange(med) %>%
  top_n(10, total) %>%
  mutate(publisher = fct_inorder(factor(paste(publisher, total, sep = "" - "")))) %>%
  unnest() %>%
  ggplot(aes(x = metascore, y = publisher, fill = publisher)) +
  geom_density_ridges(
    scale = 3,
    size = .01,
    color = ""lightgrey"",
    show.legend = F,
    rel_min_height = 0.0001,
    alpha = .9
  ) +
  theme_ipsum_rc() +
  theme(plot.title    = element_text(hjust = 9),
        plot.subtitle = element_text(hjust = 16.5)) +
  scale_fill_viridis(direction = 1, discrete = T, option = ""D"") + 
  labs(
    title = ""PC Game Publishers on Steam by Metascore"",
    subtitle = ""Top 10 by volume with valid Metascore. Total noted by name."",
    caption = ""Source: steamspy.com"",
    y = """",
    x = ""Metacritic Metascore""
  ) -> p

ggsave(p, filename = ""tt_31_2019.png"", device = ""png"", dpi = 300, width = 7, height = 5)

p
```

","2019"
"275",996,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190129-milk_production/milk_production.Rmd","Eeysirhc","tidytuesday","20190129-milk_production/milk_production.Rmd","---
title: ""TidyTuesday: Milk Production""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 1/29/2019 ([source](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-29))

```{r}
library(tidyverse)
library(scales)
library(lubridate)
library(ggmap)
library(gganimate)
library(ggthemes)
library(transformr)

milk_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/state_milk_production.csv"")
milk <- milk_raw
```

```{r}
usa <- as_tibble(map_data(""state""))
usa$region <- str_to_title(usa$region)
usa <- usa %>%
  rename(state = region)

milk_parsed <- milk %>%
  select(-region) %>%
  mutate(milk_10billion = milk_produced / 10000000000,
         year = as.integer(year)) %>%
  full_join(usa) %>%
  filter(!is.na(year), !is.na(long), !is.na(lat))
```

```{r}
milk_animation <- milk_parsed %>%
  ggplot(aes(long, lat, group = group, fill = milk_10billion)) +
  geom_polygon(color = 'black') +
  scale_fill_gradient2(low = ""gray97"", mid = ""steelblue"", high = ""midnightblue"", midpoint = 2.5) +
  theme_map(base_size = 15) + 
  coord_map() +
  labs(x = NULL,
       y = NULL,
       fill = NULL,
       title = ""Milk production per 10 billion pounds"",
       subtitle = ""Year: {round(frame_time)}"",
       caption = ""Source: USDA"") +
  transition_time(year)

animate(milk_animation, height = 800, width = 800)
anim_save(""milkproduction.gif"")
```
","2019"
"276",997,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181127-baltimore_bridges/baltimore_bridges.Rmd","Eeysirhc","tidytuesday","20181127-baltimore_bridges/baltimore_bridges.Rmd","---
title: ""TidyTuesday: Baltimore Bridges""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 11/27/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-11-27

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(ggmap)

bridges_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-27/baltimore_bridges.csv"")

bridges <- bridges_raw
```

### Do bridge conditions get better over time?
```{r}
# manually reorder bridge_condition factors
x <- bridges
x$bridge_condition <- as.factor(x$bridge_condition)
x$bridge_condition <- factor(x$bridge_condition, levels = c(""Poor"", ""Fair"", ""Good""))

x %>%  
  filter(yr_built >= 1900) %>% # removing 2017 due to outlier
  select(lat, long, yr_built, bridge_condition, avg_daily_traffic) %>%
  group_by(yr_built, bridge_condition) %>%
  summarize(avg_daily_traffic = mean(avg_daily_traffic)) %>%
  ggplot() + 
  geom_col(aes(yr_built, avg_daily_traffic, fill = bridge_condition),
           alpha = 0.3) +
  scale_y_continuous(label = comma_format(), 
                     limits = c(0, 223000)) +
  scale_fill_brewer(palette = 'Set1') +
  scale_color_brewer(palette = 'Set1') +
  geom_smooth(aes(yr_built, avg_daily_traffic, 
                  color = bridge_condition),
              se = FALSE) +
  theme_bw(base_size = 15) +
  labs(x = """",
        y = """",
        title = ""Baltimore bridges: average daily traffic over time"",
       subtitle = ""Applied smoothing to highlight differences in bridge conditions and dampen outliers"",
       fill = ""Bridge Condition"",
       color = ""Bridge Condition"") 

```

### Is the improvement consistent across all bridge owners?
```{r}
x %>%
  select(owner, bridge_condition, yr_built) %>% 
  filter(owner != ""Army"", owner != ""National Park Service"", owner != ""Navy/Marines"", 
         owner != ""Other Local Agencies"", owner != ""Private (other than railroad)"",
         owner != ""Town or Township Highway Agency"", owner != ""Other State Agencies"") %>%
  filter(yr_built > 1958) %>%
  ggplot() + 
  geom_density(aes(x = yr_built, fill = bridge_condition, color = bridge_condition), 
               alpha = 0.3) +
  facet_wrap(~owner) +
  theme_bw(base_size = 15) +
  scale_fill_brewer(palette = 'Set1') +
  scale_color_brewer(palette = 'Set1') +
  labs(x = """",
       y = """",
       fill = ""Bridge Condition"",
       color = ""Bridge Condition"",
       title = ""Baltimore bridges: status of conditions over time by owner"") +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank())
  
```






### How much does it cost to maintain the bridge per car?
```{r}
# replace NA with 0
bridges$total_improve_cost_thousands[is.na(bridges$total_improve_cost_thousands)] <- 0

bridges %>% 
  filter(yr_built >= 1900) %>%
  select(lat, long, yr_built, bridge_condition, avg_daily_traffic, total_improve_cost_thousands) %>%
  mutate(cost_car_improve = total_improve_cost_thousands / avg_daily_traffic) %>% 
  group_by(yr_built, bridge_condition) %>%
  ggplot() +
  geom_col(aes(yr_built, cost_car_improve, fill = bridge_condition)) +
  scale_y_continuous(label = dollar_format()) + 
  facet_grid(bridge_condition ~ .) + 
  theme_bw()

```

### Validating lat/long data to fit Baltimore map
```{r}
# note to self: coordinates from file not matching ggmap so come back to this at a later time

baltimore <- as_tibble(map_data(""county"", regions = ""maryland,baltimore""))

bridges %>%
  full_join(baltimore) %>%
  group_by(lat, long) %>%
  ggplot() + 
  geom_point(aes(long, lat)) +
  geom_polygon(data = baltimore, aes(long, lat, group = group), fill = NA, color = 'black')

```

","2018"
"277",998,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190101-rtweet_data/rtweet_data.Rmd","Eeysirhc","tidytuesday","20190101-rtweet_data/rtweet_data.Rmd","---
title: ""TidyTuesday: rtweet data""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 01/01/2019

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-01

```{r}
# LOAD PACKAGES AND PARSE DATA
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(tidytext)
library(topicmodels)

tweets_raw <- as_tibble(readRDS(""rstats_tweets.rds""))
```

### Parse data and identify top users
```{r}
# IDEA BEHIND THIS IS TO FILTER OUT BOTS

# FIND TOP USERS
top_interactions <- tweets_raw %>%
  select(screen_name, favorite_count, retweet_count) %>%
  group_by(screen_name) %>%
  summarize(favorite = sum(favorite_count),
            retweet = sum(retweet_count)) %>%
  group_by(screen_name) %>%
  mutate(total = sum(favorite, retweet)) %>%
  arrange(desc(total)) %>%
  head(12) 

# JOIN TOP USERS WITH RAW DATASET
tweets <- tweets_raw %>% 
  inner_join(top_interactions, by='screen_name')

# FINAL DATA PROCESSING
tweets_parsed <- tweets %>% 
  select(screen_name, text) %>%
  group_by(screen_name) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  filter(!grepl(""https|t.co|http|bit.ly|kindly|goo.gl|rstats|amp"", word)) # REMOVE EXTRA STOP WORDS
```

### What are the most significant keywords for each #rstats Twitter user?
```{r}
tweets_tfidf <- tweets_parsed %>%
  count(screen_name, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word, screen_name, n)

tweets_tfidf %>%
  filter(!near(tf, 1)) %>%
  arrange(desc(tf_idf)) %>%
  group_by(screen_name) %>%
  distinct(screen_name, word, .keep_all = TRUE) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  ggplot(aes(word, tf_idf, fill = screen_name)) + 
  geom_col(show.legend = FALSE) +
  facet_wrap(~screen_name, ncol = 4, scales = ""free"") +
  coord_flip() +
  theme_light() +
  labs(x = """",
       y = """",
       title = ""Highest TF-IDF words for top #rstats Twitter users"",
       caption = ""Source: data from {rtweet} package"") +
  scale_fill_brewer(palette = 'Paired')
```

### What are the topics and highest proability keywords for each?
```{r}
tweet_words <- tweets_parsed %>%
  count(screen_name, word, sort = TRUE) %>%
  ungroup()

tweet_dtm <- tweet_words %>%
  cast_dtm(screen_name, word, n)

tweets_lda <- LDA(tweet_dtm, k=12, control = list(seed = 2008))

tidy_lda <- tidy(tweets_lda)

top_terms <- tidy_lda %>% 
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  group_by(topic, term) %>%
  arrange(desc(beta)) %>%
  ungroup() %>%
  mutate(term = factor(paste(term, topic, sep = ""__""),
                       levels = rev(paste(term, topic, sep = ""__"")))) %>%
  ggplot(aes(term, beta, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  scale_x_discrete(labels = function(x) gsub(""__.+$"", """", x)) +
  scale_fill_brewer(palette = 'Paired') +
  labs(title = ""Top 10 terms in each LDA topic from #rstats"",
       caption = ""Source: data from {rtweet} package"",
       x = """",
       y = """") +
  theme_light() +
  facet_wrap(~topic, ncol = 4, scales = ""free"")
```
","2019"
"278",999,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181211-nyc_restaurants/nyc_restaurants.Rmd","Eeysirhc","tidytuesday","20181211-nyc_restaurants/nyc_restaurants.Rmd","---
title: ""TidyTuesday: NYC Restaurant Inspections""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 12/11/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-12-11

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(lubridate)
library(ebbr)

nyc_restaurants_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-11/nyc_restaurants.csv"")

nyc_restaurants <- nyc_restaurants_raw %>%
  filter(inspection_date != '01/01/1900') #%>% # filter out establishments which have not been inspected yet
  #filter(grepl(""A|B|C"", grade)) %>% # filter those without grades
  #filter(!grepl(""Missing"", boro))
```


### Does a high score equate to a high grade?
```{r}
nyc_restaurants %>%
  select(score, grade) %>%
  drop_na(score) %>%
  group_by(grade) %>%
  summarize(min = min(score),
            mean = mean(score),
            median = median(score),
            max = max(score))
   

nyc_restaurants %>%
  select(score, grade) %>%
  drop_na(score) %>%
  ggplot() + 
  geom_density(aes(score, fill = grade)) +
  theme_bw()

```

No, there is an inverse relationship between grade and score. Thus, a lower score == A (higher grade)



### What is the average score by cuisine type?
```{r}
scores <- nyc_restaurants %>%
  select(cuisine_description, score) %>%
  group_by(cuisine_description) %>%
  na.omit() %>%
  summarize(mean = mean(score),
            total = n(),
            low = qbeta(0.025, mean + 0.5, total - mean + 0.5),
            high = qbeta(0.975, mean + 0.5, total - mean + 0.5),
            segment = ifelse(mean >= 21.336, ""above"", 
                             ifelse(mean <= 17.665, ""below"", ""average""))) %>%
  na.omit()

summary(scores$mean)
#1stQ: 17.665
#3rdQ: 21.336

scores %>%
  filter(total > 100) %>%
  arrange(desc(total)) %>%
  select(cuisine_description, low, mean, high, total, segment) %>% 
  ggplot() +
  geom_point(aes(reorder(cuisine_description, -mean), mean, color = segment),
             size = 2) + 
  geom_errorbar(aes(x=cuisine_description, ymin=mean-low, ymax=mean+high, color = segment),
                size = 0.5) +
  coord_flip() +
  theme_bw(base_size = 10) +
  labs(x = """",
       y = """",
       title = ""Average inspection score for NY restaurants by cuisine"",
       subtitle = ""Best score of \""5.733\""; minimum 100 inspections per cruisine type"",
       caption = ""Source: NYC Open Data"") + 
  scale_color_brewer(palette = 'Accent', direction = -1) +
  theme(legend.position = 'none')

```



### What is the rate of inspection grade of ""A"" by cuisine type (added 12/16/2018)
```{r}
cuisine_grades <- nyc_restaurants %>%
  select(cuisine_description, grade) %>%
  na.omit() %>%
  group_by(cuisine_description) %>%
  count(grade) %>%
  mutate(total = sum(n),
         pct_total = n/total) %>%
  ungroup()

ebb_cuisine_grades <- cuisine_grades %>%
  add_ebb_estimate(n, total) %>%
  filter(grade == ""A"") %>%
  arrange(desc(.fitted)) %>%
  filter(n >= 100) %>%
  head(30) 

ebb_cuisine_grades %>%
  select(cuisine_description, ""Empirical Bayes Rate""=.fitted, ""Measured Rate""=.raw, .low, .high) %>%
  gather(key, value, -cuisine_description, -.low, -.high) %>%
  ggplot() + 
  geom_point(aes(reorder(cuisine_description, value), value, color = key), size = 3) +
  geom_errorbar(aes(ymin = .low, ymax = .high, x=cuisine_description), color = ""gray50"") +
  scale_y_continuous(labels = percent_format(round(1))) +
  coord_flip() +
  theme_minimal(base_size = 15) +
  labs(x = """",
       y = """",
       title = ""Rate of NYC restaurant inspections with a final grade of \'A\' by cuisine type"",
       subtitle = ""95% credible intervals with a minimum of 100 inspections"",
       caption = ""Source: NYC Open Data"") +
  scale_color_brewer(palette = 'Set1', direction = -1) +
  theme(legend.title=element_blank())

```





### What is the distribution of scores based on cuisine ?
```{r}
top_cuisines <- nyc_restaurants %>%
  select(cuisine_description, score) %>%
  count(cuisine_description) %>%
  arrange(desc(n)) %>%
  top_n(20)

# density by score
nyc_restaurants %>%
  select(cuisine_description, score) %>% 
  left_join(top_cuisines) %>% 
  drop_na(n) %>%
  ggplot() + 
  geom_density(aes(score, fill = cuisine_description, color = cuisine_description), 
               alpha = 0.1) +
  scale_x_log10() +
  theme_bw()

```




### Is there a difference in scores by cuisine for each boro ?
```{r}
nyc_restaurants %>%
  select(cuisine_description, boro, score) %>%
  group_by(cuisine_description, boro) %>%
  na.omit() %>%
  summarize(mean = mean(score),
            total = n(),
            low = qbeta(0.025, mean + 0.5, total - mean + 0.5),
            high = qbeta(0.975, mean + 0.5, total - mean + 0.5)) %>%
  na.omit() %>% 
  top_n(50) %>% 
  select(cuisine_description, boro, low, mean, high, total) %>% 
  ggplot() +
  geom_point(aes(reorder(cuisine_description, mean), mean)) + 
  geom_errorbar(aes(x=cuisine_description, ymin=mean-low, ymax=mean+high)) +
  coord_flip() +
  theme_bw() +
  facet_wrap(~boro)

```

","2018"
"279",1000,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181218-cetaceans/cetaceans.Rmd","Eeysirhc","tidytuesday","20181218-cetaceans/cetaceans.Rmd","---
title: ""TidyTuesday: Cetaceans Dataset""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 12/18/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-12-18

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(lubridate)
library(tidytext)

cetaceans_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-18/allCetaceanData.csv"")

cetaceans <- cetaceans_raw
```



```{r}
# most notable deaths between M vs F?
cetaceans %>% 
  select(sex, COD) %>%
  filter(sex != ""U"") %>%
  na.omit() %>%
  mutate(sex = replace(sex, str_detect(sex, ""F""), ""Female""), 
         sex = replace(sex, str_detect(sex, ""M""), ""Male"")) %>%
  unnest_tokens(bigram, COD, token = ""ngrams"", n = 2) %>%
  count(sex, bigram) %>%
  bind_tf_idf(bigram, sex, n) %>%
  arrange(desc(tf_idf)) %>%
  filter(tf_idf > 0.0011) %>%
  ggplot() +
  geom_col(aes(reorder(bigram, tf_idf), tf_idf, fill = sex)) +
  coord_flip() +
  scale_fill_brewer(palette = 'Set2',
                    name = """") +
  labs(x = """",
       y = """",
       title = ""Bigrams with highest TF-IDF for cause of death between Female and Male Cetacean (reported)"",
       caption = ""Source: The Pudding"") +
  theme_bw(base_size = 15) 

```



```{r}
# what is the primary cause of death between Born vs Capture?
cod_acquisition_ratio <- cetaceans %>%
  select(acquisition, COD) %>%
  filter(acquisition == 'Born' | acquisition == 'Capture') %>%
  na.omit() %>%
  mutate(COD = tolower(COD)) %>%
  count(COD, acquisition) %>%
  filter(sum(n) >= 10) %>%
  ungroup() %>%
  spread(acquisition, n, fill = 0) %>%
  mutate_if(is.numeric, funs((. + 1) / sum(. +1))) %>%
  mutate(logratio = log(Born / Capture)) %>%
  arrange(desc(logratio))
  
cod_acquisition_ratio %>%
  arrange(abs(logratio)) %>%
  group_by(logratio < 0) %>%
  top_n(10, abs(logratio)) %>%
  ungroup() %>%
  mutate(COD = reorder(COD, logratio)) %>%
  ggplot() +
  geom_col(aes(COD, logratio, fill = logratio < 0)) +
  coord_flip() +
  scale_fill_brewer(palette = 'Accent',
                    name = """", 
                    labels = c(""Born"", ""Capture"")) +
  theme_bw(base_size = 15) +
  labs(x = """",
       y = ""Log Odds Ratio (Born / Capture)"",
       title = ""Comparing the odds ratio of words for cause of death \n  between Cetacean's captured from the ocean or born in captivity (reported)"",
       caption = ""Source: The Pudding"")

```





```{r}
# group birth years by decade for better segmentation of analysis
cetaceans_age <- cetaceans %>% 
  select(species, sex, acquisition, status, birthYear, originDate, statusDate) %>% 
  mutate(statusDate = replace_na(statusDate, ""2017-05-07""), # BASED ON DATA DICTIONARY
         statusYear = year(statusDate),
         originYear = year(originDate),
         birthYear = year(as.Date(birthYear, format = ""%Y"")),
         age_years = statusYear - birthYear) %>%
  filter(age_years >= 0)


### average life span
cetaceans_age %>% 
  group_by(species) %>% 
  filter(status == 'Died', acquisition == 'Capture') %>% 
  View()

```




```{r}
# raw cause of death
cetaceans %>% 
  select(COD) %>%
  na.omit() %>%
  unnest_tokens(word, COD) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  mutate(pct_total = n/sum(n)) %>%
  filter(n > 30) %>%
  ggplot() + 
  geom_col(aes(reorder(word, pct_total), pct_total)) +
  coord_flip() +
  theme_bw(base_size = 10) +
  labs(x = """",
       y = """",
       title = ""Top terms as reported for the cause of Cetacean death"") +
  scale_y_continuous(labels = percent_format(round(1)))

# does not give a whole lot of information so bigram may be btter

cetaceans %>% 
  select(COD) %>%
  na.omit() %>%
  unnest_tokens(bigram, COD, token = ""ngrams"", n = 2) %>%
  count(bigram, sort = TRUE) %>%
  mutate(pct_total = n/sum(n)) %>%
  filter(n > 12) %>%
  filter(bigram != ""due to"") %>%
  ggplot() + 
  geom_col(aes(reorder(bigram, pct_total), pct_total)) + 
  coord_flip() + 
  theme_bw(base_size = 10) +
  labs(x = """",
       y = """") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

# mostly old age and pneumonia but may require additional data cleaning

```

","2018"
"280",1001,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190115-space_launches/space_launches.Rmd","Eeysirhc","tidytuesday","20190115-space_launches/space_launches.Rmd","---
title: ""TidyTuesday: Space Launches""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-15
```{r}
# LOAD PACKAGES AND PARSE DATA
library(tidyverse)
library(RColorBrewer)
library(forcats)
library(scales)
library(ebbr)
library(grid)

launches_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")

launches <- launches_raw %>%
  filter(launch_year >= '1960')
```

### Trophy for most space launches over time?
```{r}
countries <- launches %>%
  count(state_code, sort = TRUE) %>%
  filter(n >= 100)

launches %>%
  inner_join(countries) %>%
  # INCOMING NASTY IFELSE CODE (NEED TO REFACTOR)
  mutate(state_code = ifelse(state_code == 'RU', 'Russia / Soviet Union',
                             ifelse(state_code == 'SU', 'Russia / Soviet Union', 
                                    ifelse(state_code == 'US', 'United States',
                                           ifelse(state_code == 'CN', 'China',
                                                  ifelse(state_code == 'IN', 'India',
                                                         ifelse(state_code == 'F', 'France',
                                                                ifelse(state_code == 'J', 'Japan', state_code)))))))) %>%
  ggplot() + 
  geom_density(aes(launch_year, fill = state_code, color = state_code),
               alpha = 0.2) +
  theme_light() +
  scale_color_brewer(palette = 'Set1') +
  scale_fill_brewer(palette = 'Set1') +
  labs(x = """",
       y = """",
       title = ""Distribution of space launches over time by country"",
       subtitle = ""Minimum of 100 launches"",
       caption = ""Source: The Economist"",
       fill = ""Country"",
       color = ""Country"") +
  scale_y_continuous(labels = percent_format(round(1)))
```

### Who has a better success rate: private, startup or states ?
```{r}
launches %>%
  mutate(category = ifelse(category == 'O', 1, 0)) %>%
  select(launch_year, agency_type, category) %>%
  group_by(launch_year, agency_type) %>%
  summarize(success = sum(category),
            total = n(),
            rate = success / total) %>%
  ungroup() %>%
  add_ebb_estimate(success, total) %>%
  mutate(agency_type = str_to_title(agency_type)) %>%
  ggplot() +
  geom_line(aes(launch_year, .fitted, color = agency_type), 
            size = 1) +
  geom_ribbon(aes(x = launch_year, ymin = .low, ymax = .high, fill = agency_type),
              alpha = 0.1) +
  theme_light() +
  scale_fill_brewer(palette = 'Set1') +
  scale_color_brewer(palette = 'Set1') +
  labs(x = """",
       y = """",
       caption = ""Source: The Economist"",
       title = ""Success rate of space launches by type"",
       subtitle = ""Empirical Bayes rate @ 95% credible interval"",
       color = ""Type"",
       fill = ""Type"") +
  scale_y_continuous(labels = percent_format(round(1)),
                     limits = c(0,1))
```

### Success rate for each country by agency type ?
```{r}
# APPLY EMPIRICAL BAYESIAN STATS TO DATASET
launches_parsed <- launches %>%
  mutate(category = ifelse(category == 'O', 1, 0),
         agency_type = str_to_title(agency_type)) %>%
  select(launch_year, state_code, agency_type, category) %>%
  group_by(state_code, agency_type) %>%
  summarize(success = sum(category),
         total = n(),
         rate = success / total) %>%
  ungroup() %>%
  add_ebb_estimate(success, total) 

# PLOT THE GRAPH
launches_parsed %>%  
  filter(total >= 10) %>%
  select(""Empirical Bayes Rate""=.fitted, 
         ""Measured Rate""=.raw, 
         everything()) %>%
  gather(key, value, `Empirical Bayes Rate`:`Measured Rate`) %>%
    # INCOMING NASTY IFELSE CODE (NEED TO REFACTOR)
  mutate(state_code = ifelse(state_code == 'RU', 'Russia',
                             ifelse(state_code == 'SU', 'Soviet Union', 
                                    ifelse(state_code == 'US', 'United States',
                                           ifelse(state_code == 'CN', 'China',
                                                  ifelse(state_code == 'IN', 'India',
                                                         ifelse(state_code == 'F', 'France',
                                                                ifelse(state_code == 'J', 'Japan', 
                                                                       ifelse(state_code == 'IL', 'Israel', state_code))))))))) %>%
  ggplot() +
  geom_point(aes(x=reorder(state_code, value), y=value, color = key), size = 4) +
  geom_errorbar(aes(x = state_code, ymin = .low, ymax = .high), size = 0.5, color = ""gray50"") +
  geom_hline(data=launches_parsed, aes(yintercept = median(.fitted)), color = 'salmon', linetype = 'dashed', size = 1) +
  coord_flip() +
  theme_light(base_size = 15) +
  scale_y_continuous(labels = percent_format(round(1)),
                     limits = c(0,1)) +
  labs(x = """",
       title = ""Estimated success rate of space launches per country by type"",
       subtitle = ""with 95% credible interval and 10+ launches"",
       y = """",
       caption = ""Source: The Economist"",
       color = """") +
  scale_color_brewer(palette = 'Paired', direction = -1) +
  facet_grid(agency_type~.)
  
```

```{r}
# EMPIRICAL BAYES MIXTURE MODELING AND EXPECTATION-MAXIMIZATION
rockets <- launches %>%
  select(type, state_code, category) %>%
  mutate(category = ifelse(category == 'O', 1, 0)) %>%
  group_by(type, state_code) %>%
  summarize(success = sum(category),
         total = n()) %>%
  ungroup() %>%
  add_ebb_estimate(success, total) 

mm <- ebb_fit_mixture(rockets, success, total, clusters = 5)

# CHECK INITIAL RESULTS
ggplot(mm$assignments, aes(success / total, fill = .cluster)) +
  geom_histogram(position = 'identity', alpha = 0.8, binwidth = .05) 

launches %>%
  inner_join(mm$assignments) %>%
  mutate(.cluster = ifelse(.cluster == '1', 'Excellent', 
                           ifelse(.cluster == '2', 'Horrible',
                                  ifelse(.cluster == '3', 'Good',
                                         ifelse(.cluster == '4', 'Bad',
                                                ifelse(.cluster == '5', 'Average', .cluster))))),
         .cluster = fct_relevel(.cluster, c(""Excellent"", ""Good"", ""Average"", ""Bad"", ""Horrible"")),
         state_code = ifelse(state_code == 'RU', 'Russia / USSR',
                             ifelse(state_code == 'SU', 'Russia / USSR', 
                                    ifelse(state_code == 'US', 'United States',
                                           ifelse(state_code == 'CN', 'China',
                                                  ifelse(state_code == 'IN', 'India',
                                                         ifelse(state_code == 'F', 'France',
                                                                ifelse(state_code == 'J', 'Japan', 
                                                                       ifelse(state_code == 'IL', 'Israel', state_code))))))))) %>%
  group_by(launch_year, .cluster) %>%
  mutate(count = n()) %>%
  filter(grepl(""China|France|Japan|Russia|United"", state_code)) %>%
  ggplot() +
  geom_col(aes(launch_year, count, fill = .cluster), position = 'fill') +
  facet_grid(state_code~.) +
  theme_light(base_size = 15) +
  scale_fill_brewer(palette = 'Spectral', direction = -1) +
  labs(x = """",
       y = """",
       title = ""Composition of space launch performance by country"",
       subtitle = ""Assigned via mixture modeling and expectation-maximization"",
       caption = ""Source: The Economist"",
       fill = ""Cluster"") +
  scale_y_continuous(labels = percent_format())
```
","2019"
"281",1002,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190205-housing_prices/app.R","Eeysirhc","tidytuesday","20190205-housing_prices/app.R","
# Author: https://twitter.com/Eeysirhc
# Data project for tidytuesday week of 2/5/2019
# Source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-02-05

# LOAD PACKAGES
library(tidyverse)
library(scales)
library(shiny)

# PARSE DATA
state_hpi_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")
state_hpi <- state_hpi_raw %>%
  group_by(state, year) %>%
  summarize(us_avg = mean(us_avg),
            price_index = mean(price_index)) %>%
  mutate(pct_diff = (price_index / us_avg) - 1,
         segment = ifelse(pct_diff > 0, 'above', 'below'),
         segment = str_to_title(segment))



# UI 
ui <- fluidPage(
  ""Housing Price Index: US Average vs State"",
  selectInput(inputId = ""select_state"",
              label = ""Choose a state"",
              c(state.abb)),
  plotOutput(""hpi1""),
  plotOutput(""hpi2"")
)



# SERVER
server <- function(input, output, session) {
  
  output$hpi1 <- renderPlot({
    state_hpi %>%
      filter(state == input$select_state) %>%
      group_by(year, state) %>%
      summarize(price_index = mean(price_index),
                us_avg = mean(us_avg)) %>% 
      ggplot() +
      geom_line(aes(year, price_index), size = 2, color = 'steelblue') +
      geom_col(aes(year, us_avg), alpha = 0.3, fill = 'grey54') +
      theme_bw() +
      labs(x = NULL,
           y = ""Housing Price Index"") + 
      theme_bw(base_size = 15) + 
      scale_y_continuous(limits = c(0,300)) 
  })
  
  output$hpi2 <- renderPlot({
    state_hpi %>%
      filter(state == input$select_state) %>%
      ggplot() + 
      geom_col(aes(year, pct_diff, fill = segment), alpha = 0.8) +
      geom_hline(yintercept = 0, lty = 'dashed') +
      scale_fill_brewer(palette = 'Set1', direction = -1) +
      scale_y_continuous(labels = percent_format(round(1))) +
      theme_bw(base_size = 15) +
      theme(legend.position = 'top') +
      labs(x = NULL,
           y = ""Difference to US Average"",
           fill = NULL,
           caption = ""\n Source: Freddie Mac House Price Index\n Author: eeysirhc"")
    })  
}



# APP
shinyApp(ui, server)
","2019"
"282",1003,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181204-medium_articles/medium_articles.Rmd","Eeysirhc","tidytuesday","20181204-medium_articles/medium_articles.Rmd","---
title: ""TidyTuesday: Medium Article Metadata""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 12/4/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-12-04

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(ggcorrplot)
library(tidytext)
library(stringr)

articles_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-04/medium_datasci.csv"")

articles <- articles_raw
```

### Who are the top authors in terms of total articles?
```{r}
top_authors <- articles %>%
  select(author) %>%
  group_by(author) %>%
  count() %>%
  arrange(desc(n)) %>%
  na.omit() %>%
  head(10)

top_authors %>%
  ggplot() + 
  geom_col(aes(reorder(author, n), n), 
           fill = ""darkslategray4"",
           alpha = 0.8) + 
  coord_flip() +
  theme_bw(base_size = 15) +
  labs(x = """",
       y = """",
       title = ""Top 10 authors on Medium in terms of total articles published"")
```

### Are there differences in words used between the titles and subtitles for articles ?
```{r}
data(stop_words)

tidy_authors <-
  articles %>%
  inner_join(top_authors) %>%
  select(title, subtitle, author) %>%
  na.omit() %>%
  mutate(text = paste(title, "" "", subtitle)) %>%
  select(author, text) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_authors %>%
  group_by(author) %>%
  mutate(word = str_extract(word, ""[a-z']+"")) %>%
  count(word, sort = TRUE) %>%
  mutate(proportion = n / sum(n)) %>%
  select(-n) %>%
  spread(author, proportion) %>% 
  gather(author, proportion, `AI Hawk`:`Synced`) %>%
  ggplot(aes(x=proportion, y=`Yves Mulkers`, color = abs(`Yves Mulkers` - proportion))) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 1) +
  geom_abline(color = ""darkslategray4"", linetype = 2) +
  scale_color_gradient(limits = c(0, 0.01), 
                       low = ""salmon"", high = ""blue"") +
  scale_x_log10(labels = percent_format(round(1))) +
  scale_y_log10(labels = percent_format(round(1))) +
  labs(y = ""Yves Mulkers"",
       x = """",
       title = ""Comparing the word frequencies for the top 10 authors on Medium (title & subtitle only)"",
       subtitle = "" \""Top 10\"" defined as the total number of articles published"") +
  theme_bw(base_size = 15) +
  theme(legend.position = ""none"") +
  facet_wrap(~author, ncol = 3)
```


### Is there a relationship between reading time and claps by article?
```{r}
# Plot to see if there are any trends
articles %>%
  select(reading_time, claps, tag_ai:tag_machine_learning) %>%
  gather(tag = tag_ai:tag_machine_learning) %>% 
  select(-value) %>% 
  group_by(key, reading_time) %>%
  summarize(claps = sum(claps)) %>% 
  ggplot(aes(reading_time, claps, fill = key)) + 
  geom_col() +
  facet_wrap(~key) +
  scale_y_continuous(labels = comma_format()) +
  scale_x_continuous(limits = c(0,25)) +
  theme_bw() + 
  theme(legend.position = 'none') +
  labs(x = """",
       y = """",
       title = ""Relationship between reading time of article and total number of claps"",
       subtitle = ""The 'sweet spot' is 5 minutes"")

# What about correlation?
articles_tags <- 
  articles %>%
  select(reading_time, claps, tag_ai:tag_machine_learning) 
articles_correlations <- round(cor(articles_tags), 1)

ggcorrplot(articles_correlations, hc.order = TRUE, 
           type = ""lower"", 
           lab = TRUE, 
           lab_size = 3, 
           method=""circle"", 
           colors = c(""salmon"", ""white"", ""steelblue""), 
           title=""Correlogram of article tags"", 
           ggtheme=theme_bw)

# No clear relationship but perhaps there might be something between the different tags ?
```
","2018"
"283",1004,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190122-incarceration_trends/incarceration_trends.Rmd","Eeysirhc","tidytuesday","20190122-incarceration_trends/incarceration_trends.Rmd","---
title: ""TidyTuesday: Incarceration Trends""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 1/22/2019 ([source](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-22))

```{r}
# LOAD PACKAGES AND PARSE DATA
library(tidyverse)
library(scales)
library(lubridate)
library(RColorBrewer)

prison_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/prison_population.csv"")

# DELETE THIS LATER
prison %>% 
  write_csv(""prison_population.csv"")

prison <- prison_raw
```


```{r}
# PROCESS RAW DATA
total <- prison %>%
  filter(pop_category != 'Total' & pop_category != 'Male' & pop_category != 'Female') %>% 
  select(county_name, urbanicity, pop_category, population, prison_population) %>%
  na.omit() %>% 
  group_by(county_name, urbanicity, pop_category) %>%
  summarize(population = sum(population),
            prison_population = sum(prison_population)) %>%
  ungroup() %>%
  group_by(county_name, urbanicity) %>%
  mutate(pct_population = population / sum(population),
         pct_prisoner = prison_population / sum(prison_population))
```

### What is the proportion of population:prisoners per demographic ?
```{r}
total %>%
  filter(pop_category != 'Other') %>%
  ggplot() + 
  geom_point(aes(pct_population, pct_prisoner),
             alpha = 0.1, size = 2, color = 'grey') +
  geom_smooth(aes(pct_population, pct_prisoner, color = pop_category),
              size = 1.2,
             se = FALSE) +
  theme_light(base_size = 15) +
  scale_y_continuous(labels = percent_format()) +
  scale_x_continuous(labels = percent_format()) +
  labs(x = ""County Population"",
       y = ""Prisoner Population"",
       color = """",
       title = ""Comparison of county to prison population by ethnicity from 1970 to 2016"",
       subtitle = ""Specific groups are overrepresented in the prisoner population"",
       caption = ""Source: Vera Institute of Justice"") +
  geom_abline(linetype = 'dashed') +
  scale_color_brewer(palette = 'Set1') +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        legend.position = 'top',
        panel.background = element_rect(fill = 'gray97',
                                        color = 'gray97',
                                        size = 0.5, linetype = 'solid'))
```


### Does urbanicity play a role ?
Answer: variations between different races but long answer short...not really.
```{r}
total %>%
  filter(pop_category != 'Other') %>%
  ggplot() + 
  geom_point(aes(pct_population, pct_prisoner),
             alpha = 0.1, size = 2, color = 'grey') +
  geom_smooth(aes(pct_population, pct_prisoner, color = urbanicity),
              se = FALSE) +
  theme_light() +
  scale_y_continuous(labels = percent_format()) +
  scale_x_continuous(labels = percent_format()) +
  labs(x = ""County Population (%)"",
       y = ""Prisoner Population (%)"",
       color = ""Urbanicity"") +
  facet_wrap(~pop_category) +
  geom_abline(linetype = 'dashed')
```
","2019"
"284",1005,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190305-women_workforce/women_workforce.Rmd","Eeysirhc","tidytuesday","20190305-women_workforce/women_workforce.Rmd","---
title: ""TidyTuesday: Women in the Workforce""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 3/05/2019 ([source](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-03-05))

```{r}
library(tidyverse)
library(scales)
library(lubridate)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")
```

```{r}
jobs_gender %>%
  filter(year == '2016') %>%
  mutate(male_diff = ((((total_earnings_male/total_earnings)-1)*workers_male)/total_workers),
         female_diff = (((total_earnings_female/total_earnings)-1)*workers_female)/total_workers) %>%
  ggplot() +
  geom_jitter(aes(total_earnings, female_diff), 
              color = 'salmon',
              alpha = 0.5,
              size = 2.5) +
  geom_jitter(aes(total_earnings, male_diff), 
              color = 'steelblue',
              alpha = 0.5, 
              size = 2.5) +
  geom_hline(yintercept = 0, color = 'grey54', lty = 'dashed') +
  facet_wrap(~major_category) +
  scale_x_continuous(labels = dollar_format(),
                     limits = c(0,200000)) +
  scale_y_continuous(labels = percent_format(round(1)),
                     limits = c(-0.3,0.3)) +
  labs(x = ""Average Median Earnings"",
       y = ""Difference from Average"",
       caption = ""Graphic: @eeysirhc\nSource: Bureau of Labor Statistics"",
       title = ""2016 Earnings Differences (Weighted) by Job Sector"",
       subtitle = ""Blue = Male; Red = Female"") +
  theme_bw(base_size = 15) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.subtitle = element_text(size = 12),
        legend.position = 'none')
```

","2019"
"285",1006,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190108-tv_golden_age/tv_golden_age.Rmd","Eeysirhc","tidytuesday","20190108-tv_golden_age/tv_golden_age.Rmd","---
title: ""R Notebook""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 01/08/2019

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-08

```{r}
# LOAD PACKAGES AND PARSE DATA

library(tidyverse)
library(RColorBrewer)
library(forcats)
library(lubridate)
library(broom)

tv_data_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"")

tv_data <- tv_data_raw
```

```{r}
# K-MEANS CLUSTERING
tv_data_summarized <- tv_data %>%
  group_by(title, genres, date) %>%
  summarize(min_rating = min(av_rating),
            avg_rating = mean(av_rating),
            max_rating = max(av_rating),
            min_share = min(share),
            avg_share = mean(share),
            max_share = max(share)) %>%
  ungroup()

kclust_data <- tv_data_summarized %>%
  select(-title, -genres, -date)

kclust_results <- kmeans(kclust_data, center = 9)
```

```{r}
# CHECK OUTPUT DATA
tv_data_summarized %>%
  left_join(augment(kclust_results, kclust_data)) %>%
  mutate(title = factor(title)) %>%
  group_by(.cluster) %>%
  ggplot() +
  geom_boxplot(aes(.cluster, avg_rating, fill = .cluster),
               show.legend = FALSE,
               alpha = 0.5) +
  theme_light() +
  labs(x = ""Cluster #"",
       y = ""Average Rating"",
       caption = ""Source: The Economist"",
       title = ""Average rating distribution for each cluster assignment"") +
  scale_fill_brewer(palette = 'Paired')

tv_data_summarized %>%
  left_join(augment(kclust_results, kclust_data)) %>%
  mutate(title = factor(title)) %>%
  group_by(.cluster) %>%
  ggplot(aes(avg_rating, log10(avg_share)+1, color = .cluster)) +
  geom_point(alpha = 0.7, size = 3, show.legend = FALSE) +
  theme_light() +
    labs(x = ""Average Rating"",
       y = ""Share (log10)"",
       caption = ""Source: The Economist"",
       title = ""Relationship between Average Rating and Shares by cluster assignment"") +
  scale_fill_brewer(palette = 'Paired')
```

```{r}
# FINALIZE PLOT
tv_data_summarized %>%
  left_join(augment(kclust_results, kclust_data)) %>%
  mutate(title = factor(title),
         five_years = 5 * (year(date) %/% 5 )) %>%
  group_by(.cluster) %>%
  top_n(20, avg_rating) %>%
  ggplot(aes(avg_rating, log10(avg_share)+1, label = title, color = .cluster)) + 
  geom_text(show.legend = FALSE) +
  facet_wrap(~five_years) +
  theme_light() +
  labs(x = ""Average Rating"",
       y = ""Share (log10)"",
       caption = ""Source: The Economist"",
       title = ""Top TV Shows Every 5yrs by Average Rating and Shares (log10)"",
       subtitle = ""Note: duplicates indicate multiple seasons"") 
```
","2019"
"286",1007,"https://github.com/abichat/tidytuesday/blob/master/scripts/script_2019-07-02.R","abichat","tidytuesday","scripts/script_2019-07-02.R","library(gameofthrones)
library(ggchicklet)
library(hrbrthemes)
library(tidyverse)
library(glue)

#### Data ####

media_franchises <- 
  read_csv(""data/data_2019-07-02.csv"", col_types = ""ccddccc"") %>% 
  unique()


#### Table ####

df_biggest <- 
  media_franchises %>%
  group_by(franchise, revenue_category, year_created) %>%
  summarise(revenue = sum(revenue)) %>%
  ungroup() %>%
  mutate(revenue_category = fct_reorder(revenue_category, 
                                        revenue, sum, .desc = TRUE),
         franchise = fct_lump(franchise, n = 15, w = revenue)) %>%
  filter(franchise != ""Other"") %>%
  mutate(franchise = str_remove_all(franchise, ""^.*/ ""), 
         franchise = str_remove_all(franchise, "" &.*$""), 
         franchise = glue(""{franchise} ({year_created})""),
         franchise = fct_reorder(franchise, revenue, sum)) %>% 
  filter(revenue > 0.5)


#### Plot ####

ggplot(df_biggest) +
  aes(x = franchise, y = revenue, fill = revenue_category) +
  geom_chicklet(width = 0.75, color = NA, radius = grid::unit(4, ""pt"")) +
  scale_fill_got_d(option = ""Daenerys"") +
  coord_flip() +
  guides(fill = guide_legend(override.aes = list(size = 10))) +
  labs(x = NULL, y = ""Revenue (B$)"", fill = NULL, 
       title = ""Highest Grossing Media Franchises"", 
       caption = ""Source: Wikipedia\n@_abichat for #TidyTuesday"") +
  theme_ft_rc() +
  theme(legend.position = c(0.8, 0.3),
    plot.title = element_text(color = ""#929299"", hjust = 0.5, size = 25),
    axis.title.x = element_text(size = 18),
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14),
    legend.text = element_text(size = 15),
    plot.caption = element_text(size = 10),
    plot.margin = margin(15, 15, 15, 15))

ggsave(""plots/plot_2019-07-02.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019"
"287",1009,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-03-19.R","library(tidyverse)
library(ggimage)
library(sf)

##### Data ####

combined_data <- read_csv(""data/data_2019-03-19.csv"", col_types = ""cccdddddddd"")


#### Function ####

plot_pie <- function(df) {
  ggplot(df) +
    aes(x = 0, y = stops_per_year, fill = driver_race) +
    geom_col(position = ""fill"", show.legend = FALSE, color = ""grey30"") +
    coord_polar(theta = ""y"") +
    scale_fill_manual(values = c(Black = ""#3C2C2B"", Hispanic = ""#B27A58"", 
                                 White = ""#F8DED2"")) +
    theme_void() +
    theme_transparent()
}


#### Get maps ####

sf_connecticut <-
  maps::map(""county"", plot = FALSE, fill = TRUE) %>%
  st_as_sf() %>%
  separate(ID, into = c(""state"", ""county""), sep = "","") %>% 
  filter(state == ""connecticut"")

mat_coord_cent <-
  sf_connecticut %>%
  st_centroid() %>%
  arrange(county) %>%
  st_coordinates()

sf_adjacent <-
  maps::map(""state"", plot = FALSE, fill = TRUE) %>%
  st_as_sf() %>%
  filter(ID %in% c(""connecticut"", ""massachusetts"",
                   ""new york"", ""rhode island""))


#### Tables ####

data_CT <-
  combined_data %>%
  filter(state == ""CT"") %>%
  select(location, driver_race, stops_per_year)

df_pie <-
  data_CT %>%
  arrange(location) %>%
  group_by(location) %>%
  nest() %>%
  mutate(total = map_dbl(data, ~ sum(pull(., stops_per_year))),
         total = total / 10 ^ 5 / 1.1,
         pie = map(data, plot_pie)) %>%
  mutate(x = mat_coord_cent[, 1],
         y = mat_coord_cent[, 2])


#### Plots ####

p_legend <-
  ggplot(df_pie$data[[1]]) +
  aes(x = 0, y = stops_per_year, fill = driver_race) +
  geom_col(position = ""fill"",color = ""grey30"") +
  scale_fill_manual(values = c(Black = ""#3C2C2B"", Hispanic = ""#B27A58"", 
                               White = ""#F8DED2"")) +
  guides(fill = guide_legend(title = ""Driver race"")) +
  theme(legend.background = element_rect(fill=""#d2ecf8""))

leg <- cowplot::get_legend(p_legend)

df_pie <-
  df_pie %>% 
  add_row(total = 0.5, pie = list(leg), x = -71.75, y = 41.1)

p <-
  ggplot() +
  geom_sf(data = sf_adjacent, fill = ""#f8f1d2"") +
  geom_sf(data = sf_connecticut, fill = ""#d2f8de"") +
  coord_sf(xlim = c(-73.7, -71.75), ylim = c(41.05, 42.05)) +
  theme_void() +
  theme(panel.background = element_rect(fill = ""#d2ecf8"", color = ""grey30""),
        panel.grid = element_line(colour = NA),
        plot.title = element_text(hjust = 0.5, face = ""bold"", 
                                  size = 20, lineheight = 0.1),
        plot.caption = element_text(size = 12)) +
  labs(title = ""\nRepartition of annual traffic stops by race in Connecticut\n"",
       caption = ""Source: Stanford Open Policing Project\n@_abichat for #TidyTuesday\n"")

p + geom_subview(data = df_pie, aes(x = x, y = y, subview = pie, 
                                    width = total, height = total))

ggsave(""plots/plot_2019-03-19.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019"
"288",1010,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-03-26.R","library(tidyverse)
library(ggwordcloud)
library(patchwork)

#### Data ####

seattle_pets <- read_csv(""data/data_2019-03-26.csv"", col_types = ""ccccccc"")


#### Table ####

data_count <-
  seattle_pets %>%
  drop_na(animals_name) %>%
  count(species, animals_name, sort = TRUE) %>%
  filter(n > 5) %>%
  group_split(species)


#### Plots ####

p_cat <-
  ggplot(data_count[[1]]) +
  aes(label = animals_name, size = n, color = n) +
  geom_text_wordcloud_area(mask = png::readPNG(""ressources/img_2019-03-26_cat.png""), 
                           rm_outside = TRUE) +
  theme_minimal() +
  scale_color_gradient(low = ""darkblue"", high = ""blue"")

p_dog <-
  ggplot(data_count[[2]]) +
  aes(label = animals_name, size = n, color = n) +
  geom_text_wordcloud_area(mask = png::readPNG(""ressources/img_2019-03-26_dog.png""), 
                           rm_outside = TRUE) +
  theme_minimal() +
  scale_color_gradient(low = ""darkred"", high = ""red"")

p_all <-
  p_dog + p_cat + 
  plot_annotation(title = ""Most used names for dogs and cats in Seattle"",
                  caption = ""Source: Seattle's open data portal\n@_abichat for #TidyTuesday"",
                  theme = theme(text = element_text(size = 12, family = ""Arial Rounded MT Bold""),
                                plot.title = element_text(hjust = 0.5, face = ""bold"", 
                                                          size = 20, lineheight = 0.1)))

set.seed(42)
ggsave(plot = p_all, ""plots/plot_2019-03-26.png"", width = 29, height = 12, units = ""cm"", dpi = ""retina"")

","2019"
"289",1011,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-02.R","library(tidyverse)
library(lubridate)

#### Data ####

bike_traffic <- read_csv(""data/data_2019-04-02.csv"", col_types = ""cccdd"")


#### Functions ####

my_max <- partial(max, na.rm = TRUE)
my_mean <- partial(mean, na.rm = TRUE)


#### Tables ####

traffic <-
  bike_traffic %>%
  mutate(date = mdy_hms(date)) %>%
  filter(crossing != ""Sealth Trail"") %>%
  mutate(
    year = year(date),
    month = month(date, label = TRUE, abbr = FALSE),
    week = week(date),
    weekday = weekdays(date),
    crossing = fct_reorder(crossing, bike_count, my_max, .desc = TRUE)
  )

traffic_per_month <-
  traffic %>%
  group_by(year, month, crossing) %>%
  summarise(day = mean(date), total_bike = my_mean(bike_count))

traffic_per_week <-
  traffic %>%
  group_by(year, month, week, crossing) %>%
  summarise(day = mean(date), total_bike = my_mean(bike_count))

traffic_per_day <-
  traffic %>%
  group_by(year, month, week, weekday, crossing) %>%
  summarise(day = mean(date), total_bike = my_mean(bike_count))


#### Plot ####

ggplot(traffic_per_day) +
  aes(x = day, y = total_bike, group = crossing) +
  geom_line(color = ""#a57259"", alpha = 0.3) +
  geom_line(data = traffic_per_week, color = ""#a57259"") +
  geom_line(data = traffic_per_month, color = ""#73503e"") +
  scale_y_continuous(limits = c(NA, 80)) +
  facet_wrap(~ crossing) +
  labs(x = ""Date"", y = ""Average number of bikes per hour"",
       title = ""Use of bike lanes in Seattle"", 
       subtitle = ""Smoothed per day, week and month"",
       caption = ""Source: Seattle Department of Transportation\n@_abichat for #TidyTuesday"") +
  ggthemes::theme_economist()

ggsave(""plots/plot_2019-04-02.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019"
"290",1012,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-09.R","library(tidyverse)
library(gganimate)

#### Data ####

grand_slam_timeline <- read_csv(""data/data_2019-04-09.csv"", col_types = ""cdccc"")


#### Tables ####

ordered_outcomes <-c(""Absent"", ""Lost Qualifier"", ""Qualification Stage 1"", 
                     ""Qualification Stage 2"", ""1st Round"", ""2nd Round"", 
                     ""3rd Round"", ""4th Round"", ""Quarterfinalist"", 
                     ""Semi-finalist"", ""Finalist"", ""Won"")

df_frenchOpen <-
  grand_slam_timeline %>%
  mutate(outcome = as_factor(outcome)) %>%
  mutate(player = str_remove_all(player, ""^/* "")) %>%
  filter(tournament == ""French Open"") %>%
  group_by(player) %>%
  mutate(
    winner = ""Won"" %in% outcome,
    begining = min(year),
    median = median(year)
  ) %>%
  ungroup() %>%
  filter(winner == TRUE) %>%
  mutate(
    outcome = fct_explicit_na(outcome, ""Absent""),
    outcome = fct_collapse(outcome, Absent = c(""Retired"")),
    outcome = fct_relevel(outcome, ordered_outcomes)
  )

ordered_players <-
  df_frenchOpen %>% 
  arrange(median, begining) %>% 
  pull(player) %>% 
  unique()

df_frenchOpen <- mutate(df_frenchOpen,
                        player = factor(player, level = ordered_players))


#### Plot ####

p <-
  df_frenchOpen %>%
  ggplot() +
  aes(x = year, y = outcome, group = player) +
  geom_line(aes(color = gender), show.legend = FALSE) +
  geom_point() +
  labs(x = ""Year"", y = ""Outcome"",
       title = ""Outcomes at Roland-Garros for {closest_state}"",
       caption = ""Source: Wikipedia\n@_abichat for #TidyTuesday"") +
  theme_minimal() +
  theme(plot.margin = margin(5.5, 9, 5.5, 5.5),
        plot.title = element_text(face = ""bold""))

anim <-
  p +
  transition_states(player) +
  enter_fade() +
  exit_fade()

animate(anim, nframes = 12 * length(ordered_players))

anim_save(""plots/plot_2019-04-09.gif"")
","2019"
"291",1013,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-23.R","library(tidyverse)
library(lubridate)
library(ggpomological)

#### Data ####

anime <- read_csv(""data/data_2019-04-23.csv"")


#### Tables ####

df_movies <-
  anime %>%
  filter(type == ""Movie"") %>% 
  select(title_english, start_date, score, scored_by, source) %>% 
  filter(scored_by > 10000) %>% 
  drop_na() %>% 
  unique() %>% 
  mutate(year = year(start_date)) %>% 
  mutate(ntop = dense_rank(desc(score)), 
         nbot = dense_rank(score)) %>% 
  arrange(ntop) %>% 
  filter(ntop %in% 1:10 | nbot %in% 1:10) %>% 
  mutate(title_english = fct_reorder(title_english, score),
         source = fct_collapse(source, 
                               ""Other"" = ""Other"", 
                               ""Other"" = ""Unknown"", 
                               ""Novel"" = ""Light novel""))

middle <- mean(range(df_movies$score))
min <- min(range(df_movies$score))
max <- max(range(df_movies$score))

seg_top <-
  seq(middle, max, length.out = 100) %>%
  tibble(x = ., xend = lag(x)) %>%
  drop_na() %>%
  mutate(alpha = 0.5 + (row_number() - 1) / (2 * n()))

df_seg_top <-
  df_movies %>%
  select(title_english, score) %>%
  filter(score > middle) %>%
  mutate(data = rerun(n(), seg_top)) %>%
  unnest(data) %>%
  filter(xend < score)

seg_bot <-
  seq(min, middle, length.out = 100) %>%
  tibble(xend = ., x = lead(xend)) %>%
  drop_na() %>%
  mutate(alpha = 1 - (row_number() - 1) / (2 * n()))

df_seg_bot <-
  df_movies %>%
  select(title_english, score) %>%
  filter(score < middle) %>%
  mutate(data = rerun(n(), seg_bot)) %>%
  unnest(data) %>%
  filter(x > score)

df_seg <- bind_rows(df_seg_bot, df_seg_top)


#### Plot ####

ggplot(df_movies) +
  aes(x = score, y = title_english) +
  geom_segment(data = df_seg, aes(x = x, y = title_english, xend = xend, 
                                  yend = title_english, alpha = alpha),
               size = 1) +
  geom_segment(data = df_seg, aes(x = x, y = title_english, xend = xend, 
                                  yend = title_english, alpha = alpha ), 
               size = 1) +
  geom_point(aes(fill = source, shape = source), size = 3.5) +
  geom_label(aes(x = middle, label = title_english, fill = source), 
             color = ""white"", show.legend = FALSE, 
             size = 4, family = ""Luminari"") +
  labs(x = ""Score (out of 10)"", y = NULL, 
       fill = ""Type"", shape = ""Type"", 
       title = ""Best and worst anime movies"", 
       caption = ""Source: MyAnimeList\n@_abichat for #TidyTuesday"") +
  theme_pomological_plain() +
  guides(alpha = FALSE) +
  scale_shape_manual(values = 21:25) +
  scale_fill_pomological() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = ""bottom"",
    text = element_text(size = 15, family = ""Luminari""),
    plot.title = element_text(hjust = 0.5, face = ""bold"", size = 20)
  )

ggsave(""plots/plot_2019-04-23.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019"
"292",1014,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-30.R","library(harrypotter)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(ggimage)
library(cowplot)
library(ggtree)
library(yatah)

#### Data ####

bird_collisions <-
  read_csv(""data/data_2019-04-30.csv"") %>%
  mutate(species = paste(genus, species))
  
months <- 
  as_factor(c(""January"", ""February"", ""March"", ""April"", 
              ""May"", ""June"", ""July"", ""August"", ""September"", 
              ""October"", ""November"", ""December"")) 

font <- ""Trattatello""


#### Tables and data ####

collision_per_month <-
  bird_collisions  %>%
  mutate(month = months[month(date)], 
         month = fct_drop(month),
         monthyear = floor_date(date, unit = ""month"")) %>% 
  count(species, month, monthyear) %>% 
  group_by(species, month) %>% 
  summarise(mean = mean(n)) %>% 
  ungroup()

most_collision_per_month <- 
  collision_per_month %>% 
  group_by(species) %>% 
  summarise(total = sum(mean)) %>% 
  top_n(n = 15)

ymax <- max(most_collision_per_month$total)

species_most <- most_collision_per_month$species

taxonomy <-
  bird_collisions %>% 
  select(family, genus, species) %>% 
  filter(species %in% species_most) %>% 
  taxtree(root = ""Passerine"")


#### Plots ####

# Insets

ggcol_inset <- function(df) {
  s <- round(sum(df$mean))
  ggplot(df) +
    aes(x = 0, y = mean, fill = month) +
    geom_col(position = position_stack(reverse = T)) +
    geom_text(x = 0, y = s, label = s, family = font, hjust = -0.2) +
    scale_fill_hp(discrete = TRUE, option = ""HarryPotter"", 
                  name = """", direction = -1, drop = FALSE) +
    ylim(c(0, ymax + 1)) +
    coord_flip() +
    theme_inset()
}

splitlist <-
  collision_per_month %>% 
  filter(species %in% species_most) %>% 
  group_by(species) %>% 
  group_split() %>% 
  set_names(species_most) %>% 
  `[`(taxonomy$tip.label) %>% 
  set_names(seq_along(species_most))

inset_cols <- map(splitlist, ggcol_inset)


# Legend

p_legend <-
  splitlist[[1]] %>% 
  ggplot() +
  aes(x = 0, y = mean, fill = month) +
  geom_col(position = position_stack(reverse = T)) +
  scale_fill_hp(discrete = TRUE, option = ""HarryPotter"", 
                name = """", direction = -1, drop = FALSE) +
  theme_wsj() +
  theme(legend.text = element_text(family = font, size = 15), 
        legend.direction = ""vertical"", legend.box = ""vertical"") 

legend <- get_legend(p_legend)


# Taxonomy

ptree <-
  ggtree(taxonomy, alpha = 0.8, color = ""grey"") +
  geom_nodelab(geom = ""label"", family = font, size = 4) +
  geom_tiplab(hjust = 1, vjust = -0.6, family = font, size = 5)


# Final plot

inset(ptree, inset_cols, width = 1, height = 1, hjust = -0.46) + 
  geom_subview(x = 1.75, y = 4.5, subview = legend) +
  xlim(NA, 1.88) +
  labs(title = ""\n\nNumber of bird collisions per month in Chicago\n"",
       caption = ""Source: Winger et al, 2019\n@_abichat for #TidyTuesday"") +
  theme_wsj() +
  theme(plot.title = element_text(family = font, hjust = 0.5, 
                                  face = ""bold"", size = 25,
                                  lineheight = 0.1), 
        plot.caption = element_text(family = font, size = 15), 
        panel.grid = element_blank(), axis.text = element_blank(),
        axis.line = element_blank(), axis.ticks = element_blank())

ggsave(""plots/plot_2019-04-30.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")




","2019"
"293",1015,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-07.R","library(tidyverse)
library(cowplot)
library(scales)

#### Data ####

student_ratio <- read_csv(""data/data_2019-05-07.csv"", col_types = ""ccccddcc"")

oecd <-
  tribble(~country, ~shortname,
          ""Australia"", ""Australia"",
          ""Austria"", ""Austria"",
          ""Belgium"", ""Belgium"",
          ""Canada"", ""Canada"",
          ""Chile"", ""Chile"",
          ""Czechia"", ""Czechia"",
          ""Denmark"", ""Denmark"",
          ""Estonia"", ""Estonia"",
          ""Finland"", ""Finland"",
          ""France"", ""France"", 
          ""Germany"", ""Germany"",
          ""Greece"", ""Greece"",
          ""Hungary"", ""Hungary"",
          ""Iceland"", ""Iceland"",
          ""Ireland"", ""Ireland"", 
          ""Israel"", ""Israel"",
          ""Italy"", ""Italy"",
          ""Japan"", ""Japan"",
          ""Republic of Korea"", ""South Korea"",
          ""Latvia"", ""Latvia"", 
          ""Lithuania"", ""Lithuania"", 
          ""Luxembourg"", ""Luxembourg"",
          ""Mexico"", ""Mexico"", 
          ""Netherlands"", ""Netherlands"",
          ""New Zealand"", ""New Zealand"",
          ""Norway"", ""Norway"", 
          ""Poland"", ""Poland"", 
          ""Portugal"", ""Portugal"", 
          ""Slovakia"", ""Slovakia"", 
          ""Slovenia"", ""Slovenia"", 
          ""Spain"", ""Spain"", 
          ""Sweden"", ""Sweden"", 
          ""Switzerland"", ""Switzerland"",
          ""Turkey"", ""Turkey"",
          ""United Kingdom of Great Britain and Northern Ireland"", ""UK"",
          ""United States of America"", ""USA"")


#### Table ####

df_oecd <-
  student_ratio %>%
  inner_join(oecd, by = ""country"") %>%
  filter(indicator == ""Primary Education"") %>%
  mutate(shortname = fct_reorder(shortname, student_ratio, .desc = TRUE))


#### Plot ####

p_ocde <-
  ggplot(df_oecd) +
  aes(x = student_ratio, y = shortname) +
  geom_point(color = ""grey90"", alpha = 0.7, size = 3) +
  scale_x_continuous(breaks = pretty_breaks()) +
  annotate(""text"", x = 21, y = 25, size = 8, family = ""MV Boli"", color = ""grey90"", 
           label = ""Average number of students per professor\nin primary school for OECD members"") +
  labs(x = ""Ratio"", y = NULL,
       caption = ""Source: UNESCO Institute of Statistics\n@_abichat for #TidyTuesday"") +
  theme(panel.grid.major = element_line(color = ""grey80"", size = 0.05), 
        axis.ticks = element_blank(), 
        axis.line = element_blank(), 
        text = element_text(color = ""grey90"", family = ""MV Boli""), 
        plot.caption = element_text(size = 13), 
        axis.text = element_text(color = ""grey90"", family = ""MV Boli""), 
        axis.text.y = element_text(size = 13))

ggdraw() +
  draw_image(""ressources/img_2019-05-07.jpg"", scale = 1.5) + 
  draw_plot(p_ocde)

ggsave(""plots/plot_2019-05-07.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019"
"294",1016,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-14.R","library(LaCroixColoR)
library(tidyverse)
library(ggthemes)
library(ggimage)

#### Data and ressources ####

nobel_winners <- read_csv(""data/data_2019-05-14.csv"",
                          col_types = ""dccccdccDccccccDcc"")

df_countrycode <-
  tribble(~country, ~code, 
          ""United States of America"", ""US"",
          ""Germany"", ""DE"",
          ""United Kingdom"", ""GB"",
          ""France"", ""FR"",
          ""Japan"", ""JP"",
          ""Netherlands"", ""NL"",
          ""Sweden"", ""SE"",
          ""Russia"", ""RU"",
          ""Canada"", ""CA"",
          ""Austria"", ""AT"")


#### Tables ####

countries <-
  nobel_winners %>%
  filter(category == ""Chemistry"") %>%
  count(birth_country, sort = TRUE) %>%
  head(n = 10) %>%
  pull(birth_country)

nobel_counts <-
  nobel_winners %>%
  filter(birth_country %in% countries, category == ""Chemistry"") %>%
  select(prize_year, birth_country) %>%
  arrange(prize_year) %>%
  group_by(birth_country) %>%
  mutate(n_prize = n(),
         first_prize = min(prize_year),
         last_prize = max(prize_year),
         cum = row_number()) %>%
  ungroup()

nobel_counts <-
  nobel_counts %>%
  filter(cum == 1) %>%
  mutate(cum = 0) %>%
  bind_rows(nobel_counts) %>%
  arrange(prize_year, cum) %>%
  mutate(birth_country = fct_reorder(birth_country, n_prize, .desc = TRUE))

first_last_nobel <-
  nobel_counts %>%
  select(birth_country, n_prize, first_prize, last_prize) %>%
  unique() %>%
  left_join(df_countrycode, by = c(""birth_country"" = ""country""))


#### Plot ####

ggplot(nobel_counts) +
  aes(x = prize_year, y = cum, group = birth_country) +
  geom_line(aes(color = birth_country)) +
  geom_point(data = first_last_nobel, y = 0,
             aes(x = first_prize, y = n_prize, color = birth_country)) +
  geom_flag(data = first_last_nobel, size = 0.03, asp=2,
            aes(x = last_prize, y = n_prize, image = code)) +
  scale_color_manual(values = lacroix_palette(""PeachPear"", n = 10, type = ""continuous"")) +
  scale_y_continuous(limits = c(NA, 60)) +
  labs(title = ""Number of chemistry Nobel prizes by birth country"", color = NULL,
       caption = ""Source: The Nobel Prize\n@_abichat for #TidyTuesday"") +
  theme_wsj(color = ""gray"") +
  theme(legend.position = ""bottom"", 
        plot.caption = element_text(size = 12), 
        plot.title = element_text(size = 25),
        legend.text = element_text(family = ""mono""))

ggsave(""plots/plot_2019-05-14.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")


","2019"
"295",1017,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-21.R","library(countrycode)
library(treemapify)
library(tidyverse)
library(janitor)
library(glue)

#### Data and ressources ####

waste_vs_gdp <-
  read_csv(""data/data_2019-05-21.csv"", col_types = ""ccdddd"") %>%
  rename(WastePC = `Per capita plastic waste (kilograms per person per day)`,
         Population = `Total population (Gapminder)`)

olympic_colors <- c(Oceania = ""#00A651"", Africa = ""#000000"", Asia = ""#FCB131"", 
                    Europe = ""#0081C8"", Americas = ""#EE334E"")


#### Tables ####

df_waste <-
  waste_vs_gdp %>%
  select(Entity, Code, Year, WastePC, Population) %>%
  drop_na() %>%
  mutate(TotalWaste = WastePC * Population,
         Continent1 = countrycode(Entity, origin = ""country.name"", 
                                  destination = ""continent"", warn = FALSE),
         Continent2 = countrycode(Code, origin = ""iso3c"", 
                                  destination = ""continent"", warn = FALSE),
         Continent = coalesce(Continent1, Continent2),
         Continent1 = NULL, Continent2 = NULL) %>%
  filter(Year == 2010, !is.na(Continent)) %>%
  group_by(Continent) %>%
  mutate(Country_TTW = fct_lump(Entity, n = 9, w = TotalWaste)) %>%
  ungroup()

df_waste_sum <-
  df_waste %>%
  group_by(Continent, Country_TTW) %>%
  summarise(TotalWaste = sum(TotalWaste)) %>%
  mutate(rank = min_rank(TotalWaste)) %>%
  ungroup() %>%
  mutate(label = case_when(Country_TTW == ""Other"" ~ glue(""Other {Continent}""),
                           Country_TTW == ""Democratic Republic of Congo"" ~ ""DR Congo"",
                           TRUE ~ Country_TTW),
         label = case_when(Continent == ""Oceania"" ~ glue('{label} - {round(TotalWaste/10^6, 1)} kT'),
                           TRUE ~ glue('{label}\n{round(TotalWaste/10^6, 1)} kT')))


#### Plot ####

ggplot(df_waste_sum) +
  aes(area = TotalWaste, subgroup = Continent) +
  geom_treemap(aes(fill = Continent, alpha = rank), size = 0.5, color = ""white"") +
  geom_treemap_text(aes(label = label), color = ""white"", 
                    family = ""Basicdots"", place = ""topleft"", grow = FALSE) +
  scale_fill_manual(values = olympic_colors) +
  scale_alpha(range = c(0.3, 1)) +
  labs(title = ""Daily amount of plastic waste entering the ocean"",
       caption = ""Source: Our World in Data\n@_abichat for #TidyTuesday"") +
  theme(legend.position = ""none"",
        title = element_text(family = ""Andale Mono"", hjust = 0.5, size = 20),
        plot.caption = element_text(family = ""Andale Mono"", size = 10))

ggsave(""plots/plot_2019-05-21.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019"
"296",1018,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-28.R","library(ggpomological)
library(tidyverse)
library(ggridges)

#### Data ####

wine_ratings <- read_csv(""data/data_2019-05-28.csv"", col_types = ""dcccddcccccccc"")


#### Tables ####

best_french_wines <-
  wine_ratings %>%
  filter(country == ""France"") %>%
  select(country, variety, points) %>%
  group_by(variety) %>%
  summarise(mean = mean(points), n = n()) %>%
  filter(n > 50) %>%
  arrange(desc(mean), n) %>%
  head(9) %>%
  pull(variety)

df_best_french_wines <-
  wine_ratings %>%
  select(country, variety, points) %>%
  filter(country == ""France"", variety %in% best_french_wines) %>%
  mutate(variety = fct_reorder(variety, desc(points)))


#### Plot ####

ggplot(df_best_french_wines) +
  aes(x = points, y = variety) +
  geom_density_ridges(aes(fill = variety, color = variety), alpha = 0.9) +
  geom_text(aes(label = variety), x = 80, nudge_y = 0.3, 
            family = ""Chopin Script"", size = 7, hjust = 0) +
  scale_fill_pomological() +
  scale_color_pomological() +
  scale_x_continuous(limits = c(80, 100)) +
  expand_limits(y = c(NA, 10.7)) +
  labs(x = ""Score"", title = ""Best French Wines"", 
       caption = ""Source: WineEnthusiast\n@_abichat for #TidyTuesday"") +
  theme_pomological() +
  theme(text = element_text(family = ""Chopin Script"", size = 20), 
        plot.title = element_text(size = 30, hjust = 0.5), 
        axis.text.x = element_text(size = 12), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank(), 
        legend.position = ""none"")

ggsave(""plots/plot_2019-05-28.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019"
"297",1019,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-06-18.R","library(tidyverse)
library(ggthemes)
library(cowplot)

#### Data ####

bird_counts <- read_csv(""data/data_2019-06-18.csv"", col_types = ""dccddd"") 


#### Table ####

df_diff <-
  bird_counts %>% 
  select(species_latin, year, how_many_counted_by_hour) %>% 
  drop_na(how_many_counted_by_hour) %>% 
  filter(year %in% c(1957, 1967, 1977, 1987, 1997, 2007, 2017)) %>%
  mutate(year = paste0(""Y"", year)) %>% 
  spread(year, how_many_counted_by_hour) %>% 
  mutate(diff1707 = Y2017 - Y2007,
         diff0797 = Y2007 - Y1997,
         diff9787 = Y1997 - Y1987,
         diff8777 = Y1987 - Y1977,
         diff7767 = Y1977 - Y1967,
         diff6757 = Y1967 - Y1957) %>% 
  mutate(species_latin = fct_lump(species_latin, n = 20, w = Y2017)) %>%
  filter(species_latin != ""Other"") %>% 
  mutate(species_latin = fct_reorder(species_latin, desc(diff1707)))


#### Plots ####

p1707 <-
  ggplot(df_diff) +
  aes(x = diff1707, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff1707 > 0)) +
  geom_point(aes(color = diff1707 > 0, size = Y2017)) +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""right"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 2017 and 2007"",
       subtitle = ""Area are proportional to the number of observations per hour during the current year (2017)"",
       caption = ""Source: Bird Studies Canada\n@_abichat for #TidyTuesday"") +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", plot.caption = element_text(hjust = 0),
        title = element_text(size = 12), axis.text = element_text(size = 10))

p0797 <-
  ggplot(df_diff) +
  aes(x = diff0797, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff0797 > 0)) +
  geom_point(aes(color = diff0797 > 0, size = Y2007)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 2007 and 1997"",
       subtitle = ""Area are proportional to the number of observations per hour during the current year (2007)"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""right"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", 
        title = element_text(size = 8), axis.text = element_text(size = 6),
        plot.margin = margin(0.5, 0.1, 0.5, 0.5, ""lines""))

p9787 <-
  ggplot(df_diff) +
  aes(x = diff9787, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff9787 > 0)) +
  geom_point(aes(color = diff9787 > 0, size = Y1997)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 1997 and 1987"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""left"") +
  expand_limits(y = c(NA, 21)) +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", 
        title = element_text(size = 4), axis.text = element_text(size = 4),
        plot.margin = margin(0.5, 0.5, 0.5, 0.1, ""lines""))

p8777 <-
  ggplot(df_diff) +
  aes(x = diff8777, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff8777 > 0)) +
  geom_point(aes(color = diff8777 > 0, size = Y1987)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 1987 and 1977"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""left"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  scale_size_continuous(range = c(1, 4)) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", title = element_text(size = 1.8), 
        axis.text.x = element_text(size = 2), axis.text.y  = element_blank(), 
        panel.grid.major = element_line(size = 0.1),
        plot.margin = margin(t = 0.1, r = 0, b = 0, l = 0, unit = ""pt""))

p7767 <-
  ggplot(df_diff) +
  aes(x = diff7767, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff7767 > 0)) +
  geom_point(aes(color = diff7767 > 0, size = Y1977)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 1977 and 1967"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""left"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  scale_size_continuous(range = c(1, 3)) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", 
        title = element_text(size = 1), axis.text = element_blank(), 
        panel.grid.major = element_line(size = 0.05),
        plot.margin = margin(t = 0.1, r = 0, b = 0, l = 0, unit = ""pt""))

p6757 <-
  ggplot(df_diff) +
  aes(x = diff6757, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff6757 > 0)) +
  geom_point(aes(color = diff6757 > 0, size = Y1967)) +
  labs(x = NULL, y = NULL) +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  scale_size_continuous(range = c(1, 2)) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", axis.text = element_blank(), 
        panel.grid.major = element_line(size = 0.05),
        plot.margin = margin(t = 0.1, r = 0, b = 0, l = 0, unit = ""pt""))

ggdraw(p1707) +
  draw_plot(p0797, x = 0, y = 0.1, width = 0.609, height = 0.609) +
  draw_plot(p9787, x = 0, y = 0.2, width = 0.355, height = 0.355) +
  draw_plot(p8777, x = 0.15, y = 0.255, width = 0.13, height = 0.13) +
  draw_plot(p7767, x = 0.182, y = 0.262, width = 0.079, height = 0.079) +
  draw_plot(p6757, x = 0.192, y = 0.267, width = 0.04, height = 0.04) 

ggsave(""plots/plot_2019-06-18.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019"
"298",1020,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-06-25.R","library(tidyverse)
library(lubridate)
library(gganimate)
library(lwgeom)
library(sf)

#### Data ####

ufo_sightings <-
  read_csv(""data/data_2019-06-25.csv"", col_types = ""cccccdcccdd"") %>%
  mutate(date_time = mdy_hm(date_time),
         date = as_date(date_time),
         year = year(date))


#### Maps ####

world <- st_as_sf(rworldmap::getMap(resolution = ""low""))
graticule <- st_graticule(lat = c(-89.9, seq(-80, 80, 20), 89.9))

lats <- c(90:-90, -90:90, 90)
longs <- c(rep(c(180, -180), each = 181), 180)
outline <-
  list(cbind(longs, lats)) %>%
  st_polygon() %>%
  st_sfc(crs = ""+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"")

crs_wintri <- ""+proj=wintri +datum=WGS84 +no_defs +over""
world_wintri <- st_transform_proj(world, crs = crs_wintri)
graticule_wintri <- st_transform_proj(graticule, crs = crs_wintri)
outline_wintri <- st_transform_proj(outline, crs = crs_wintri)


#### Tables ####

df_ufo <-
  ufo_sightings %>%
  filter(year >= 1980)

coord_wintri <-
  df_ufo %>%
  drop_na(longitude, latitude) %>%
  st_as_sf(coords = c(""longitude"", ""latitude""), crs = 4326) %>%
  lwgeom::st_transform_proj(crs = crs_wintri) %>%
  `$`(geometry) %>%
  map(as.matrix) %>%
  reduce(rbind)

df_ufo$longitude_wintri <- coord_wintri[, 1]
df_ufo$latitude_wintri <- coord_wintri[, 2]
  

#### Plot ####

anim <-
  df_ufo %>% 
  ggplot() + 
  geom_sf(data = outline_wintri, fill = ""black"", color = NA) + 
  geom_sf(data = graticule_wintri, color = ""gray30"", size = 0.25/.pt) +
  geom_sf(data = world_wintri, fill = ""forestgreen"", color = NA, size = 0.5/.pt) + 
  geom_sf(data = outline_wintri, fill = NA, color = ""grey30"", size = 0.5/.pt) + 
  geom_point(aes(x = longitude_wintri, y = latitude_wintri, alpha = encounter_length), 
             color = ""red"") + # points
  coord_sf(datum = NA, expand = FALSE) +
  labs(x = NULL, y = NULL, title = ""Reported UFO in {current_frame}"", 
       caption = ""Source: National UFO Reporting Center \n@_abichat for #TidyTuesday"") +
  theme_void() +
  theme(plot.margin = margin(6, 1.5, 3, 1.5), legend.position = ""none"",
        plot.title = element_text(size = 20, hjust = 0.5, face = ""bold""), 
        plot.caption = element_text(size = 12)) +
  transition_manual(year) +
  enter_appear() +
  exit_shrink()

animate(anim, width = 29, height = 19, units = ""cm"", res = 320, nframes = 170)

anim_save(""plots/plot_2019-06-25.gif"")




        ","2019"
"299",1021,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-07-23.R","library(wesanderson)
library(tidyverse)
library(cowplot)
library(waffle)
library(scales)

#### Data ####

wildlife_impacts <- 
  read_csv(""data/data_2019-07-23.csv"", col_types = ""Tcccccccccdddcdddcccd"") %>% 
  mutate(phase_of_flt = str_to_title(phase_of_flt))

levels_phase_of_flt <- c(""Parked"", ""Taxi"", ""Take-Off Run"", ""Climb"", ""En Route"", 
                         ""Descent"", ""Approach"", ""Landing Roll"")

levels_damage <- c(""None"", ""Minor"", ""Damaged"", ""Substantial"", ""Unknown"")

color_damage <- c(wes_palette(name = ""FantasticFox1"")[c(3, 2, 1, 5)], ""grey80"")
names(color_damage) <- levels_damage


#### Tables ####

df_phase_damage_height <-
  wildlife_impacts %>%
  select(phase_of_flt, damage, height) %>%
  filter(phase_of_flt %in% levels_phase_of_flt) %>%
  mutate(phase_of_flt = factor(phase_of_flt, levels = levels_phase_of_flt)) %>%
  mutate(damage = fct_recode(damage, None = ""N"", Minor = ""M"", 
                             Damaged = ""M?"", Substantial = ""S""),
    damage = fct_explicit_na(damage, ""Unknown""),
    damage = fct_relevel(damage, levels_damage))

df_phase_damage_count <-
  df_phase_damage_height %>%
  count(phase_of_flt, damage) %>%
  mutate(n = ceiling(n / 10))

df_height <-
  df_phase_damage_height %>%
  group_by(phase_of_flt) %>%
  summarise(n = n(), height = median(height, na.rm = TRUE)) %>%
  mutate(y = ceiling(n / 100) + 1,
         height = paste(round(height, 0), ""ft"")) 


#### Plots ####

p <-
  df_phase_damage_count %>%
  ggplot() +
  geom_waffle(aes(fill = damage, values = n), flip = TRUE, color = ""white"", 
              n_rows = 10, radius = unit(1, ""pt"")) +
  geom_text(data = df_height, aes(y = y, label = height), 
            x = 5.5, nudge_y = 1.9, family = ""Ink Free"") +
  facet_wrap(~ phase_of_flt, nrow = 1, strip.position = ""bottom"") +
  scale_y_continuous(labels = function(x) comma(x * 1000), expand = c(0, 1.7)) +
  scale_fill_manual(values = color_damage) +
  labs(x = NULL, y = NULL, fill = ""Damage"", 
       caption = ""Source: FAA\n@_abichat for #TidyTuesday"") +
  theme_minimal(base_family = ""Ink Free"") +
  theme(
    axis.text.x = element_blank(),
    strip.text = element_text(size = 12),
    panel.grid = element_blank(),
    legend.direction = ""horizontal"",
    legend.position = c(0.57, 0.69),
    legend.justification = ""right"",
    legend.title = element_text(size = 13),
    legend.text = element_text(size = 13),
    axis.title.y.right = element_blank()
  )


ggdraw(p) +
  draw_label(""Number of impacts between flights and wildlife since 1990 in the US"",
             x = 0.4, y = 0.81, fontfamily = ""Ink Free"", size = 20) +
  draw_label(""Each square represents 10 collisions, figures correspond to median collision height"", 
             x = 0.35, y = 0.75, fontfamily = ""Ink Free"", size = 13) +
  draw_label(""Count"", x = 0.02, y = 0.15, fontfamily = ""Ink Free"", angle = 90, size = 13)


ggsave(""plots/plot_2019-07-23.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
  
","2019"
"300",1022,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-08-20.R","library(tidyverse)
library(ggexpanse)
library(cowplot)

#### Data ####

nuclear_explosions <- 
  read_csv(""data/data_2019-08-20.csv"", col_types = ""cddcccdddddddccc"") %>% 
  mutate(country = fct_lump(country, n = 5, other_level = ""Pakistan \n& India""),
         country = fct_infreq(country))


#### Tables ####

df_ts <- 
  nuclear_explosions %>% 
  group_by(year, country, .drop = FALSE) %>% 
  summarise(count = n()) 

df_count <- count(nuclear_explosions, country)


#### Plot ####

p_count <-
  ggplot(df_count) +
  aes(x = country, y = n, fill = country) +
  geom_col(color = NA) +
  coord_flip() +
  scale_fill_expanse() +
  labs(x = NULL, y = NULL,
       title = ""Total per country"") +
  theme_expanse(grid = ""XY"", 
                plot_title_size = 15,
                axis_text_size = 9) +
  theme(legend.position = ""none"", 
        panel.grid.major.y = element_blank(),
        plot.background = element_rect(color = alpha(expanse_cols$white, 1/2)),
        plot.margin = unit(c(10, 10, 10, 10), ""points""))

p_year <-
  ggplot(df_ts) +
  aes(x = year, y = count, fill = country) +
  geom_area(color = NA) +
  scale_fill_expanse() +
  labs(x = NULL, y = ""Count"", fill = ""Device deployed by"",
       title = ""Number of nuclear explosions per year and country"",
       caption = ""Source: SIPRI\n@_abichat for #TidyTuesday"") +
  theme_expanse(grid = ""XY"", 
                plot_title_size = 22,
                caption_size = 11,
                axis_title_size = 10) +
  theme(legend.position = ""none"", plot.margin = unit(c(20, 20, 20, 20), ""points""))

ggdraw(p_year) +
  draw_plot(p_count, .528, .47, .4, .4)

ggsave(""plots/plot_2019-08-20.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019"
"301",1023,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-09-24.R","library(ggeconodist)
library(tidyverse)
library(ggthemes)
library(cowplot)
library(scales)

#### Data ####

school_diversity <- read_csv(""data/data_2019-09-24.csv"", col_types = ""cccccdddddddcdc"")


#### Tables ####

df_diversity <-
  school_diversity %>% 
  select(LEAID, ST, SCHOOL_YEAR, White) %>%
  group_by(LEAID) %>%
  mutate(N = n()) %>%
  ungroup() %>%
  filter(N == 2) %>%
  group_by(ST, SCHOOL_YEAR) %>%
  mutate(N = n()) %>%
  ungroup() %>%
  filter(N > 10) %>%
  ungroup() %>%
  select(-N) %>%
  mutate(ST = fct_reorder(ST, White, .desc = TRUE), 
         White = White / 100)


#### Plot ####

# Legend 

p_legend <-
  ggplot(df_diversity) +
  aes(x = SCHOOL_YEAR, y = White, fill = SCHOOL_YEAR) +
  geom_col(alpha = 0.2) +
  scale_fill_tableau() +
  theme_econodist() +
  labs(fill = ""School Year"") +
  theme(legend.position = ""bottom"", legend.direction = ""horizontal"", 
        legend.title = element_text(family = ""EconSansCndLig"", color = ""#3b454a"", size = 10),
        legend.text = element_text(family = ""EconSansCndLig"", color = ""#3b454a"", size = 10))

legend <- get_legend(p_legend)

# Final plot 

p <-
  ggplot(df_diversity) +
  aes(x = ST, y = White, fill = SCHOOL_YEAR) +
  geom_econodist(tenth_col = ""#b07aa1"", ninetieth_col = ""#591a4f"",
                 show.legend = FALSE) +
  scale_y_continuous(labels = percent) +
  scale_fill_tableau() +
  labs(x = NULL, y = NULL, 
       title = ""Evolution of the Proportion of Whites in US Schools"",
       caption = ""Source: The Washington Post\n@_abichat for #TidyTuesday"") +
  theme_econodist() +
  theme(title = element_text(size = 15))

ggdraw(p) +
  draw_plot(legend, x = -0.305, y = -0.465) + 
  draw_plot(econodist_legend_grob(tenth_col = ""#b07aa1"", ninetieth_col = ""#591a4f""),
            x = 0.35, y = 0.027) 

ggsave(""plots/plot_2019-09-24.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019"
"302",1024,"https://github.com/edugonzaloalmorox/tidy-tuesdays/blob/master/week_26_02_2019/week_26_02_201.R","edugonzaloalmorox","tidy-tuesdays","week_26_02_2019/week_26_02_201.R","##########################
# Tidytuesday 
# Week: 26/02/2019
# @ EdudinGonzalo
##########################




library(tidyverse)
library(readr)
library(janitor)
library(hrbrthemes)


full_train = read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")


line_departures = full_train %>%
  tabyl(departure_station, year)  %>%
  gather(year, lines, -departure_station) %>%
  arrange(departure_station)

traffic =  full_train %>%
  group_by(departure_station, year) %>%
  summarise(trains = sum(total_num_trips))



traffic$year = as.character(traffic$year)

complete_data = line_departures %>%
  left_join(., traffic, by = c(""departure_station"", ""year""))


sncf_plot = complete_data %>%
   filter(!departure_station %in% c(""PARIS LYON"",""PARIS MONTPARNASSE""), year %in% c(""2015"", ""2018"")) %>%
  ggplot(., aes(lines, str_to_title(departure_station))) +
  geom_line(aes(group = departure_station), color = 'grey50', alpha = 0.5) +
  geom_point(aes(color = year, size = trains), alpha = 0.875) +
  scale_colour_viridis_d(name =""Year"", guide = guide_legend(title.position = ""top"", nrow = 1, title.hjust = 0.5, option = ""cividis"")) +
  scale_x_continuous(limits = c(0, 80), 
                     breaks = seq(0, 80, by = 5)) +
  labs(y= """", x= ""Number of lines"", size=""Traffic (number of trains)"",
       title =  ""How many lines & trains from each destination?"", 
       subtitle = ""Most stations have reduced the number of lines since 2015"",
       caption =  ""Paris Lyon and Paris Montparnasse excluded from the analysis \n Source: SNCF \n @EdudinGonzalo"") +
  theme_ipsum(base_size = 6.5) + 
  theme(panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
       legend.position = ""bottom"",
        legend.background = element_blank(),
        legend.direction=""horizontal"",
        text = element_text(family = ""Helvetica"")) +
 guides(size = guide_legend(title.position=""top"", title.hjust = 0.5))



ggsave(""week_26_02_2019/sncf.png"", sncf_plot)

","2019"
"303",1025,"https://github.com/edugonzaloalmorox/tidy-tuesdays/blob/master/week_05_03_2019/week_05_03_2019.R","edugonzaloalmorox","tidy-tuesdays","week_05_03_2019/week_05_03_2019.R","##########################
# Tidytuesday 
# Week: 05/03/2019
# @ EdudinGonzalo
##########################


library(tidyverse)
library(gganimate)
library(gghighlight)
library(ggpubr)


earnings_female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"") 



rank_data <- earnings_female %>%
  group_by(Year) %>%
  mutate(ordering = rank(percent)*1.0) %>%
  ungroup() 


rank_data$Year = as.Date(as.character(rank_data$Year), format = ""%Y"")



p<-ggplot(rank_data,
          aes(ordering, group = group ,color= group,fill= group)) +
  geom_tile(aes(y = percent/2, 
                height = percent,
                width = 0.9), alpha = 0.75) +
  geom_text(aes(y = percent, label = group), hjust = -0.4) +
  geom_text(aes(y = 0, label = group), hjust = 2) +
  coord_flip(clip = ""off"", expand = FALSE) +
  scale_color_viridis_d(option = ""plasma"" )+
  scale_fill_viridis_d(option = ""plasma"")+
  scale_y_continuous(breaks = c(0,25, 50, 75, 100), limits = c(0,105))+
  theme_minimal(14,""Avenir"")+
  guides(color=F,fill=F)+
  labs(title =  ""Earnings female workers per age group, 1979 - 2011"",
       subtitle='Year {frame_time}',
       y = ""Female salary percent of male salary (%)"",
       x = """",
       caption =  ""Source: NBER | @EdudinGonzalo"") +
  theme(plot.title = element_text(hjust = 1, size = 22),
       axis.ticks.y = element_blank(),
      axis.text.y  = element_blank(), 
      panel.background  = element_blank(), 
      panel.grid = element_blank(),
      plot.background = element_blank(),
      legend.position=""bottom"") + 
  transition_time(Year)+
  ease_aes('cubic-in-out') +
  font(""title"", size = 22, color = ""#c66eef"", face = ""bold"") 


animate(p, nframes = 250, fps = 10, end_pause = 20, width = 1000)

anim_save(filename =  ""week_05_03_2019/output/tidytuesday_womenearnings.gif"", animation = p)





","2019"
"304",1026,"https://github.com/Christensen-David/TidyTuesday/tree/master/2019_7_30_Video_Games","Christensen-David","TidyTuesday","2019_7_30_Video_Games/2019_7_30_TidyTuesday_Video_Games.r","#by: David C
#TidyTuesday for 7/30/19
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(RColorBrewer)
video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

#formatting dates
  video_games$release_date<-as.Date(strftime(strptime(video_games$release_date,""%b %d, %Y""),""%Y-%m-%d""))
#viz of count of releases over time
ggplot(data=video_games, aes(x=release_date)) + geom_bar(aes(fill=..count..), stat=""bin"", binwidth=5)+labs(title = ""After SimCity"",subtitle = ""Count of video game releases over time"" )

#formating  owners to see games with 1M owners
video_games$owners<-as.factor(video_games$owners)
t<-unique(video_games$owners) #list of groupings
video_games$million.Owners<-""no""
video_games$million.Owners[which(video_games$owners %in% t[1:4])]<-""yes""
#list of games with 1M+ owners
blockbusters<-video_games[which(video_games$million.Owners ==""yes""),] 

#basic view of pricing for games with over 1,000,000 owners
p <- ggplot(data = blockbusters, aes(x = release_date, y=price,  na.rm = TRUE)) + 
  geom_col(color = ""#00AFBB"", size =1)
p +labs(title = ""It costs $x9.99"", subtitle = ""Hit video game pricing over time (games with over 1,000,000 owners)"") + scale_y_continuous(breaks=c(9.99,19.99, 29.99, 39.99,49.99,59.99,89.99))

#wordcloud of title words
text <- paste(video_games$game, collapse = '\n') 

#tokenize the individual words
words <- tokenizers::tokenize_words(text) #list of words from text
#add words to a table
tab <- table(words[[1]])
#turn obj into a data frame
tab <- data_frame(word = names(tab), count = as.numeric(tab))
#remove numbers & ULRS
tab$word <- tab$word %>% gsub('[0-9]', '', .) %>% gsub('http\\S+\\s*', '',.)%>% gsub('[a-z]+[.]+[a-z]', '', .)

#read in an English language word frequncy table (a local file)
wf <- read_csv('word_frequency.csv')
#join frequncy table to table of words
tab.jned<- inner_join(tab, wf)

#filter common words and stop words based on fequency and remove language columm
tab.flter<-filter(tab.jned, frequency < 0.3) %>% select(.,-language)
#find any words from original table that did not join to English language frequency table
t<-setdiff(tab$word,tab.jned$word)
tab.other<-tab %>% filter(word %in% t) %>%add_column(frequency=0) %>% arrange(., desc(count))
#of other possible words, short words removed
tab.other<- tab.other %>% filter(nchar(word)>3)

#add those word to the filtered word list
tab.final <-rbind(tab.flter,tab.other) 
#arrange by count of occurances
tab.final<-arrange(tab.final, desc(count))
head(tab.final,10)
#finally, the wordcloud
wordcloud::wordcloud(words = tab.final$word, freq = tab.final$count, scale=c(9,.5),min.freq = 1,
                     max.words=100, random.order=FALSE, rot.per=0.35, 
                     colors=brewer.pal(8, 'Dark2'))



","2019"
"305",1027,"https://github.com/ch-bu/tidytuesday/blob/master/2019-06-12/meteorites.R","ch-bu","tidytuesday","2019-06-12/meteorites.R","library(tidyverse)
library(lubridate)
library(hrbrthemes)
library(ggthemes)
library(cowplot)

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  mutate(
    log_mass = log(mass)
  )

mass_limit <- 10000000

small_impacts <- meteorites %>%
  filter(mass < mass_limit)

huge_impacts <- meteorites %>%
  filter(mass >= mass_limit)

world <- ggplot() + 
  borders(""world"", colour = ""#5b616b"", fill = ""#5b616b"") +
  theme_map() +
  coord_map(projection = ""mollweide"", orientation = c(90, 0, 0)) +
  geom_point(data = small_impacts, color = ""#f9e0de"",
             aes(x = long, y = lat, size = mass), alpha = .1) +
  annotate(""text"", x = -123 - 50, y = 45.4 - 30, color = ""#f1f1f1"", hjust = 0,
           fontface = ""italic"",
           label = ""In 1902 the meteorite\nWillamette crashed in the US.\nIt was 7.8 square meters long\nand weight 15.5 tons"") +
  geom_segment(aes(x = -123, y = 45.4, 
                   xend = -123 - 30, yend = 45.4 - 15), color = ""#f1f1f1"") +
  annotate(""text"", x = 17.9 + 20, y = -19.6 - 30, color = ""#f1f1f1"", hjust = 0,
           fontface = ""italic"",
           label = ""Huba is the biggest meteorite ever\nfound on earth. It weighs 60 tons\nand has landed around\n80,000 years ago"") +
  geom_segment(aes(x = 17.9, y = -19.6, 
                   xend = 17.9 + 30, yend = -19.6 - 15), color = ""#f1f1f1"") +
  geom_point(data = huge_impacts, color = ""#dd361c"",
             aes(x = long, y = lat, size = mass), alpha = .6) +
  theme(
    plot.title = element_text(color = ""#f1f1f1"", hjust = 0.5,
                              margin = margin(b = 15),
                              size = 30,
                              face = ""bold"",
                              family = ""Titillium Web""),
    plot.subtitle = element_text(color = ""#aeb0b5"", hjust = 0.5,
                              margin = margin(b = 35),
                              size = 20,
                              family = ""Titillium Web""),
    plot.background  = element_rect(fill  = ""#323a45"", color = NA),
    panel.background = element_rect(fill  = ""#323a45"", 
                                    color = ""#323a45"")
  ) +
  guides(
    size = ""none"",
    color = ""none""
  ) +
  labs(
    title = ""Meteorites falling on earth"",
    subtitle = ""Red dots indicate meteorite impacts with a mass\nbigger than 11 tons""
  )

ggdraw(world) +
  theme(
    plot.background = element_rect(fill = ""#323a45""),
    panel.background = element_rect(fill = ""#323a45"", color = ""#323a45""),
    plot.margin = unit(c(1, 1, 1, 1), ""cm"")
  ) 


","2019"
"306",1028,"https://github.com/ch-bu/tidytuesday/blob/master/2019-05-20/global_plastic_waste.R","ch-bu","tidytuesday","2019-05-20/global_plastic_waste.R","library(tidyverse)
library(janitor)
library(ggrepel)


coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

waste_data <- waste_vs_gdp %>%
  clean_names() %>%
  setNames(c(""entity"", ""code"", ""year"", ""waste"",
             ""gdp"", ""population"")) %>%
  drop_na(waste, gdp)

mismanaged_data <- mismanaged_vs_gdp %>%
  clean_names() %>%
  setNames(c(""entity"", ""code"", ""year"", ""mismanaged_plastic"",
             ""gdp"", ""population"")) %>%
  drop_na(mismanaged_plastic, gdp)

data <- waste_data %>%
  full_join(mismanaged_data) %>%
  mutate(
    waste_ratio = mismanaged_plastic / waste
  ) 

good_guys_data <- tibble(x = seq(0, 0.75, by = .001),
                          y = x * .4)
medium_guys_data <- tibble(x = seq(0, 0.75, by = .001),
                           ymin = x * .4,
                           ymax = x * .7)
bad_guys_data <- tibble(x = seq(0, 0.75, by = .001),
                           ymin = x * .7,
                           ymax = x * 1)

data_bad_countries <- data %>%
  filter(waste_ratio > .7, waste > 0.2)

data_good_guys <- data %>% 
  filter(waste_ratio < .4, waste > 0.5, waste < 0.8)

ggplot(data, aes(x = waste, y = mismanaged_plastic)) + 
  # geom_abline(slope = 1, color = ""#e5e5e5"") +
  # geom_abline(slope = .7, color = ""#E5E5E5"") +
  # geom_abline(slope = .4, color = ""#E5E5E5"") +
  geom_ribbon(mapping = aes(x = x, ymax = y, ymin = 0), fill = ""#fceaea"",
              data = good_guys_data, inherit.aes = FALSE,
              alpha = .6) +
  geom_ribbon(mapping = aes(x = x, ymax = ymax, ymin = ymin), fill = ""#f39696"",
              data = medium_guys_data, inherit.aes = FALSE,
              alpha = .6) +
  geom_ribbon(mapping = aes(x = x, ymax = ymax, ymin = ymin), fill = ""#e72d2d"",
              data = bad_guys_data, inherit.aes = FALSE,
              alpha = .7) +
  annotate(""segment"", x = 0.223, xend = 0.223, y = 0, yend = 0.178, 
           color = ""#515151"", linetype = 2) +
  annotate(""segment"", x = 0.223, xend = 0.75, y = 0.178, yend = 0.184, 
           color = ""#515151"", linetype = 2) +
  geom_point(show.legend = FALSE, alpha = .8, size = 3,
             color = ""#969696"", pch = 21, fill = ""#cacaca"") +
  annotate(""text"", family = ""Open Sans"", color = ""#2e0909"",
           x = 0.41, y = 0.39,  hjust = 0, fontface = 2, size = 7,
           label = ""70% to 100%"") +
  annotate(""text"", family = ""Open Sans"",
           x = 0.53, y = 0.30,  hjust = 0, fontface = 2, size = 7,
           label = ""40% to 70%"") +
  annotate(""text"", family = ""Open Sans"",
           x = 0.60, y = 0.15,  hjust = 0, fontface = 2, size = 7,
           label = ""0% to 40%"") +
  annotate(""segment"", x = 0.17, xend = 0.21, y = 0.22, yend = 0.19, 
           color = ""#515151"") +
  annotate(""text"", family = ""Open Sans"",
           x = 0.06, y = 0.25,  hjust = 0, size = 3.5,
           label = ""For example, a person in Tonga\nproduces 0.22 kg of\nplastic waste per day,\n0.18 kg of which is not\nproperly disposed of"") +
  geom_text_repel(family = ""Open Sans"", aes(label = entity), 
                  fontface = ""italic"",
                  data = data_bad_countries, color = ""#170404"") +
  geom_text_repel(family = ""Open Sans"", aes(label = entity), 
                  fontface = ""italic"",
                  data = data_good_guys, color = ""#170404"") +
  coord_cartesian(ylim = c(0, 0.5), xlim = c(0, 0.72)) +
  scale_x_continuous(labels = function(x) paste(x, ""kg"")) +
  scale_y_continuous(labels = function(x) paste(x, ""kg""), position = ""right"") +
  theme(
    plot.background = element_rect(fill = ""white""),
    panel.background = element_rect(fill = ""white""),
    plot.title = element_text(family = ""Open Sans"", face = ""bold"",
                              hjust = 0, margin = margin(t = 20, b = 10), size = 30),
    plot.subtitle = element_text(family = ""Open Sans"", color = ""#515151"",
                                 hjust = 0, margin = margin(b = -140), size = 23),
    plot.margin = unit(c(1, 2, 1, 1), ""cm""),
    axis.text.y.right = element_text(size = 10, family = ""Open Sans"", margin = margin(r = 20)),
    axis.text.x = element_text(size = 10, family = ""Open Sans""),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(margin = margin(t = 15, b = 15),
                                color = ""#515151"", hjust = 1,
                                size = 10, family = ""Open Sans""),
    axis.title.y = element_text(size = 10, family = ""Open Sans"", 
                                color = ""#515151"", hjust = 0)

  ) +
  labs(
    x = ""Amout of plastic waste per capita in kg/day"",
    y = ""Not properly disposed plastic waste per capita in kg/day"",
    title = ""Who doesn't care\nabout plastic waste?"",
    subtitle = ""Percentage of plastic waste\nthat is not properly disposed of,\nper country""
  )







","2019"
"307",1029,"https://github.com/ch-bu/tidytuesday/blob/master/2019-06-04/ramen.R","ch-bu","tidytuesday","2019-06-04/ramen.R","library(tidyverse)
library(broom)
library(hrbrthemes)

theme_set(theme_modern_rc(axis_title_size = 13))

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

ramen_ratings_processed <- ramen_ratings %>%
  mutate(
    style = fct_lump(style, 4),
    country = fct_lump(country, 12),
    brand = fct_lump(brand, 20)
  ) %>%
  drop_na(style)

model_terms <- lm(stars ~ brand + country + style, ramen_ratings_processed) %>%
  tidy(conf.int = TRUE) %>%
  filter(term != ""(Intercept)"") %>%
  arrange(desc(estimate)) %>%
  extract(term, c(""category"", ""term""), ""^([a-z]+)([A-Z].*)"") 

grey_color <- ""#e7e7e7""
soft_grey <- ""#7e7e7e""
supersoft_grey <- ""#dbdbdb""
text_color <- ""#22222b""
green_color <- ""#00c18d""

model_terms %>%
  filter(category == ""country"") %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  rename(country = term) %>%
  ggplot(aes(estimate, country)) +
  geom_point(color = green_color, size = 4) +
  geom_vline(xintercept = 0, lty = 2, color = soft_grey) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), 
                 color = green_color, height = .2) +
  annotate(""text"", color = ""#383840"", x = -0.45, y = 10.3,
           hjust = 0,
           fontface = ""italic"",
           label = ""The estimates to the right of\nthis value indicate an overall\npositive relationship with\nthe ramen rating.\nValues on the left indicate\nnegative relationship."") +
  geom_curve(aes(x = -0.02, y = 10.3, xend = -0.1, yend = 10.1),
             curvature = -0.2, color = soft_grey, size = 0.05) +
  labs(
    x = ""Regression estimates"",
    y = ""Country of origin"",
    title = ""How does the country of origin\naffects the rating of ramens?"",
    subtitle = ""Regression coefficients predicting ramen\nratings by country of origin""
  ) +
  scale_color_continuous() +
  theme(
    plot.title = element_text(margin = margin(b = 10), 
                              color = text_color,
                              size = 22,
                              family = ""Open Sans""),
    plot.subtitle = element_text(margin = margin(b = 45), 
                                 color = text_color,
                                 size = 17,
                                 family = ""Open Sans""),
    axis.title.x = element_text(margin = margin(t = 15),
                                color = soft_grey),
    axis.text.x    = element_text(color = text_color,
                                  margin = margin(t = 15)),
    axis.text.y    = element_text(color = text_color),
    axis.title.y = element_text(margin = margin(r = 15),
                                color = soft_grey),
    panel.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.major.y = element_line(color = supersoft_grey),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = grey_color),
    plot.margin = unit(c(1, 2, 1, 1), ""cm"")
  )



","2019"
"308",1030,"https://github.com/ch-bu/tidytuesday/blob/master/2019-05-14/nobel_prize.R","ch-bu","tidytuesday","2019-05-14/nobel_prize.R","library(tidyverse)
library(hrbrthemes)
library(lubridate)
library(gghighlight)

theme_set(theme_ipsum_rc())

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")


# Wie lange braucht es fr die Gewinner, einen Nobelpreis zu bekommen?

winners <- nobel_winners %>%
  filter(laureate_type == ""Individual"") %>%
  select(prize_year, category, full_name, birth_date) %>%
  mutate(
    birth_year = year(birth_date),
    age_won    = prize_year - birth_year
  ) %>%
  select(-birth_date)

peace_prices <- winners %>%
  filter(category == ""Peace"")


winners %>%
  ggplot(aes(x = prize_year, y = age_won)) +
  geom_point(color = ""#cccccc"") +
  geom_smooth(aes(group = category), color = ""#cccccc"", se = FALSE) +
  geom_point(data = peace_prices, 
             aes(x = prize_year, y = age_won), color = ""blue"") +
  geom_smooth(data = peace_prices, 
              aes(x = prize_year, y = age_won), color = ""blue"", se = FALSE) +
  labs(
    x = ""Prize year"",
    y = ""Age won""
  ) 








","2019"
"309",1031,"https://github.com/ch-bu/tidytuesday/blob/master/2019-06-18/christmas_bird_counts.R","ch-bu","tidytuesday","2019-06-18/christmas_bird_counts.R","library(tidyverse)
library(hrbrthemes)
library(emojifont)
library(stringr)

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

total_count_per_year <- bird_counts %>%
  mutate(
    year = year - year %% 5
  ) %>%
  group_by(year) %>%
  summarise(
    total_count = sum(how_many_counted_by_hour)
  )

european_starling <- bird_counts %>%
  mutate(
    year = year - year %% 5
  ) %>%
  filter(species %in% c(""European Starling"")) %>%
  group_by(year) %>%
  summarise(
    counted = sum(how_many_counted_by_hour)
  ) %>%
  left_join(total_count_per_year, by = ""year"") %>%
  mutate(
    label = fontawesome('fa-twitter')
  ) %>%
  drop_na()

text_color = ""#939599""

european_starling %>%
  ggplot(aes(x = year, y = total_count)) +
  geom_segment(
    aes(x = year, xend = year, y = counted, yend = total_count), colour = ""#52565c""
  ) +
  geom_text(aes(label = label), family='fontawesome-webfont', size = 10,
            color = ""#fcf594"") +
  geom_text(aes(x = year, y = total_count, label = round(total_count, 0)), 
            family='Open Sans', size = 5, nudge_x = 0, 
            nudge_y = 220, color = text_color) +
  geom_text(data = european_starling, aes(x = year, y = counted, label = label), 
            family='fontawesome-webfont', color = ""#ff7a8a"", size = 10) +
  geom_text(data = european_starling, aes(x = year, y = counted, label = round(counted, 0)), 
            family='Open Sans', size = 5, nudge_x = 0, 
            nudge_y = -220, color = text_color) +
  annotate(""text"", x = 1967, y = 2774,
           hjust = 0,
           fontface = ""italic"", label = ""Yellow birds indicate the total\nnumber of birds counted per\nhour in a given that year"",
           color = ""#fcf594"") +
  annotate(""text"", x = 1980, y = 200,
           hjust = 0,
           fontface = ""italic"", label = ""Red birds indicate the total number of\nEuropean Starlings counted per\nhour in a given that year"",
           color = ""#ff7a8a"") +
  labs(
    title = str_to_title(""The European Starling - the celebrity among the birds""),
    subtitle = ""The European Starling is one of the most common birds. In 2004 there were about\n310 million individuals occupying an area of 8,870,000 square kilometer. That is\nabout the largest size of the Roman Empire."",
    x = """",
    y = ""Average total count per hour""
  ) +
  scale_x_continuous(breaks = seq(from = 1950, to = 2015, by = 5 )) +
  theme_modern_rc() +
  theme(
    plot.background = element_rect(fill = ""#282c34""),
    panel.background = element_rect(fill = ""#282c34"", color = ""#282c34""),
    plot.title = element_text(margin = margin(b = 10), 
                              color = ""#ffffff"",
                              size = 23,
                              family = ""Open Sans""),
    plot.subtitle = element_text(margin = margin(b = 65), 
                                 color = ""#bebfc2"",
                                 size = 18,
                                 family = ""Open Sans""),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.text.x = element_text(color = ""#686b70"", margin = margin(t = 20)),
    axis.ticks.x = element_line(color = ""#3d4148"")
  )

         
  
  
  
  
  
  
  
  
  













","2019"
"310",1032,"https://github.com/ch-bu/tidytuesday/blob/master/2019-07-09/tidytuesday_world_cup_women.R","ch-bu","tidytuesday","2019-07-09/tidytuesday_world_cup_women.R","library(tidyverse)
library(ggthemes)
library(countrycode)
library(viridis)
library(rayshader)

wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

world <- map_data(""world"") %>%
  filter(region != ""Antarctica"") 

outcomes <- wwc_outcomes %>% 
  left_join(codes, by = ""team"") %>% 
  count(year, team) %>% 
  select(-n) %>% 
  count(team, sort = TRUE) %>% 
  left_join(codes, by = ""team"") %>% 
  mutate(
    country = gsub(""United States"", ""USA"", country) %>% 
      gsub(""China PR"", ""China"", .) %>% 
      gsub(""Ivory Coast (Cte d'Ivoire)"", ""Ivory Coast"", .)
  ) %>% 
  rename(region = country) %>% 
  left_join(world, by = ""region"")

(p <- ggplot() + 
  geom_map(data = world, map = world,
           aes(long, lat, group = group, map_id = region), 
           color = ""#2a2a2a"", fill = NA) +
  theme_map() +
  geom_map(data = participants, map = world,
           aes(fill = n, map_id = region),
           color = ""#282828"", size = 0.15, alpha = .8) +
  coord_map(xlim = c(-180, 180)) +
  scale_fill_viridis(option=""viridis"", breaks = c(1, 2, 3, 4, 5, 6, 7, 8)) +
  guides(
    fill = guide_legend(title.position = ""bottom"",
                        ncol = 2)
  ) +
  labs(
    title = str_to_title(""Which countries represent womens' soccer?""),
    fill = ""# of participations\nin World Cup"",
    caption = ""Source: data.world | Graphic: Christian Burkhart"",
    subtitle = str_to_title(""The higher a country, the more often it took\npart in the womens' World Cup"")
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 16,
                              color = ""black"",
                              face = ""bold"",
                              family = ""Lato"",
                              margin = margin(b = 7)),
    plot.subtitle = element_text(hjust = 0.5, 
                              size = 14,
                              color = ""black"",
                              family = ""Lato"",
                              margin = margin(b = 35)),
    plot.caption = element_text(
      size = 10, 
      color = ""#5f5f5f"",
      face = ""italic"",
      family = ""Lato""
    ),
    plot.margin = unit(c(1, 1, 1, 1), ""cm"")
    # legend.direction = ""horizontal""
  ))


plot_gg(p, width = 8, height = 5, multicore = TRUE, scale = 200,
        zoom = 0.55, theta = -10, phi = 60)
render_snapshot(clear = TRUE)



","2019"
"311",1047,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-02-12/US_R_and_D_Funding.Rmd","---
title: ""US R&D Funding - TidyTuesday 02-11-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---


```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

tt_data<-tt_load(""2019-02-12"")
tt_data
```


```{r visualize}

delta<-function(x,index){
  x<-x[order(index)]
  delta<-c(NA,(x[seq(2,length(x))]-x[seq(1,length(x)-1)]))
  delta[delta==Inf]<-0
  delta
}

tt_data$fed_r_d_spending%>%
  group_by(department)%>%
  mutate(delta_budget=delta(rd_budget,year)/1e9,
         delta_direction=ifelse(delta_budget>0,""green"",""red""))%>%
  mutate(delta_budget=ifelse(is.na(delta_budget)|is.nan(delta_budget),0,delta_budget),
         totalSum=cumsum(delta_budget))%>%
  ggplot()+
  geom_segment(aes(x=year,     xend = year,
                   y=totalSum, yend = totalSum-delta_budget,
                   color=I(delta_direction)),
               size=2) +
  facet_wrap(department~.,
             scales = ""free_y"",
             strip.position = ""top"",
             ncol = 3) +
  ggtitle(label = ""US R&D Dollars"") +
  ylab(""? in Research and Development Dollars (Billions)"") +
  xlab(""Year"")

ggsave(""US_R&D_Funding.png"")

```


","2019"
"312",1048,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-02-19/PhDs_Awarded_by_Field.Rmd","---
title: ""PhDs Awarded by Field - TidyTuesday 02-19-2019""
output:
  html_output: default
  word_output:
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

tt_data<-tt_load(2019,8)
tt_data
```

```{r visualize}
delta<-function(x,index){
  delta<-c(NA,(x[seq(2,length(x))]-x[seq(1,length(x)-1)]))
  delta[abs(delta)==Inf]<-0
  delta
}
total_delta<-function(x,index){
  x_sum<-vector(""numeric"",length(unique(index)))
  names(x_sum)<-as.character(unique(index))

  for(i in unique(index)){
    x_vals<-x[index==i]
    if(all(is.na(x_vals))){
      x_sum[as.character(i)]<-NA
    }else{
      x_sum[as.character(i)]<-sum(x_vals,na.rm = TRUE)
    }
  }
  MinYear<-min(names(x_sum)[!is.na(x_sum)])
  MaxYear<-max(names(x_sum)[!is.na(x_sum)])
  x_sum[MaxYear]-x_sum[MinYear]
}
cumsum_alt<-function(delta,dirval){
  #get first non-na location
  loc<-which(!is.na(dirval))[1]
  baseval<-dirval[loc]
  delta[loc]<-ifelse(is.na(delta[loc]),baseval,delta[loc]+baseval)
  cumsum(delta)
}
wrap_header <- function(text) {
  wtext <- paste(strwrap(text,width=30),collapse="" \n "")
  return(wtext)
}

tt_data$phd_by_field%>%
  #calculate values by field
  group_by(field)%>%
  mutate(delta_phds=delta(n_phds,year),
         delta_direction=ifelse(delta_phds>0,""blue"",""red""),
         totalSum=cumsum_alt(delta_phds,n_phds),
         total_delta_phds=total_delta(n_phds,year))%>%
  ungroup()%>%
  filter(total_delta_phds%in%sort(unique(total_delta_phds),decreasing = TRUE)[1:10])%>%
  mutate(field_alt=sapply(field,wrap_header))%>%
  arrange(desc(total_delta_phds))%>%
  ggplot()+
  geom_segment(aes(x=year,     xend = year,
                   y=totalSum, yend = totalSum-delta_phds,
                   color=I(delta_direction)),
               size=3) +
  facet_wrap(field_alt~.,
             scales = ""free"",
             strip.position = ""top"",
             ncol = 5) +
  scale_x_continuous(breaks = c(2010,2015),
                     minor_breaks = seq(2008,2017))+
  ggtitle(label = ""Graduation Rates"",
          subtitle = ""Fields with Greatest Increase in Graduates"") +
  ylab(""Number of PhD Graduates"") +
  xlab(""Year"")+
  theme_linedraw()

ggsave(""2019-02-19/PhD_Grad_Rates.png"")

```


","2019"
"313",1049,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-02-25/Train_delays_over_time.Rmd","---
title: ""Time to Grand Salami - TidyTuesday 04-10-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
library(lubridate)

tt_data<-tt_load(""2019-04-09"")
tt_data
```

```{r transform}


time_since_win<-function(dat){
  
  dat<-dat %>% arrange(rolling_win_count)
  
  df<-data.frame(dat[1,]) %>% 
    mutate(age=abs(floor(as.numeric(difftime(date_of_birth,tournament_date,units = ""days""))/365)),
           delta_days=0)
  
  if(nrow(dat)>1){
    win <-seq(2,nrow(dat))
    df_wins<-data.frame(dat[win,]) %>% 
        mutate(age=abs(floor(as.numeric(difftime(tournament_date,date_of_birth,units = ""days""))/365)),
               delta_days=floor(as.numeric(difftime(tournament_date,dat[win-1,""tournament_date""][[1]],units = ""days""))))
    df<-bind_rows(df,df_wins)
  }
  return(df)
}

# is there a relationship between  age and the time between next grand slam?

t_wins<-tt_data$grand_slams%>%
  left_join(tt_data$player_dob%>%select(name,date_of_birth))%>%
  group_by(name)%>%
  do({time_since_win(.)})


t_wins%>%
  filter(rolling_win_count>1) %>% 
  mutate(age_decile=cut(age,
                        breaks=c(0,20,30,40,50,Inf))) %>%
  group_by(name,age_decile)%>%
  summarize(rolling_win_count = max(rolling_win_count),
            mean_delta_days = mean(delta_days),
            gender = unique(gender),
            nwins_decile=n()) %>% 
  ggplot()+
  geom_jitter(aes(x=mean_delta_days,
                   y= nwins_decile,
                  color=rolling_win_count))+
  facet_grid(age_decile~gender)

```





","2019"
"314",1050,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-03-06/Gender_Employment_Percents.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=10)
tt_data
```

```{r transform}


#cluster groupings over the years

lp<-tt_data$employed_gender%>%
  plot_ly(  x = ~year, y = ~full_time_female, name = 'Full Time Female', type = 'scatter', mode = 'lines+marker', line=list(color =""orange"")) %>%
  add_trace(x = ~year, y = ~part_time_female, name = 'Part Time Female', mode = 'lines+marker', line=list(color =""orange"",  dash = 'dash')) %>%
  add_trace(x = ~year, y = ~full_time_male,   name = 'Full Time Male',   mode = 'lines+marker', line=list(color =""green"")) %>%
  add_trace(x = ~year, y = ~part_time_male,   name = 'Part Time Male',   mode = 'lines+marker', line=list(color =""green"",  dash = 'dash')) %>% 
  add_trace(x = ~year, y = ~total_full_time,  name = 'Total Full Time',  mode = 'lines+marker', line=list(color =""black"")) %>%
  add_trace(x = ~year, y = ~total_part_time,  name = 'Total Part Time',  mode = 'lines+marker', line=list(color =""black"",  dash = 'dash')) %>% 
  layout(title = 'Gender Employment Over time',
         xaxis =list(title = 'Year') ,
         yaxis = list(title = 'Percent Employed as Full or Part Time' ))%>%
  layout(showlegend = FALSE)

lp$sizingPolicy$padding <- ""0""

saveWidget(lp,
           ""Percent_Employed_by_Gender.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""Employment Types by Gender"")


```





","2019"
"315",1051,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-03-13/Boardgames.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=11)

# tt_data
```

```{r transform}


#cluster groupings over the years

three_d_boardgames<-tt_data$board_games %>%
  filter()
  mutate(labs=paste0(""<div><p>"",name,""</p><img href=\""https:"",image,""\""/a></div>"")) %>% 
  plot_ly(
    x = ~year_published,
    y = ~min_age,
    z = ~average_rating,
    color = ~ expansion, colors = c('#BF382A', '#0C4B8E'),
    hovertext = labs) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Publish Year'),
                     yaxis = list(title = 'Minimum Recommended Age'),
                     zaxis = list(title = 'Average Rating')),
         title = 'Board Games for All')

three_d_boardgames$sizingPolicy$padding <- ""0""

saveWidget(three_d_boardgames,
           ""BoardGame_Ratings.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""BoardGame Ratings cloud - TidyTuesday March 13, 2019"")


```





","2019"
"316",1052,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-04-10/Tennis_Stars.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=11)

# tt_data
```

```{r transform}


#cluster groupings over the years

three_d_boardgames<-tt_data$board_games %>%
  filter()
  mutate(labs=paste0(""<div><p>"",name,""</p><img href=\""https:"",image,""\""/a></div>"")) %>% 
  plot_ly(
    x = ~year_published,
    y = ~min_age,
    z = ~average_rating,
    color = ~ expansion, colors = c('#BF382A', '#0C4B8E'),
    hovertext = labs) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Publish Year'),
                     yaxis = list(title = 'Minimum Recommended Age'),
                     zaxis = list(title = 'Average Rating')),
         title = 'Board Games for All')

three_d_boardgames$sizingPolicy$padding <- ""0""

saveWidget(three_d_boardgames,
           ""BoardGame_Ratings.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""BoardGame Ratings cloud - TidyTuesday March 13, 2019"")


```





","2019"
"317",1053,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-04-24/ANIME.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=17)

# tt_data
```

```{r transform}


#cluster groupings over the years

tv_anime<-tt_data$tidy_anime %>%
  filter(type==""TV"") %>% 
  mutate(start_year=lubridate::year(start_date)) %>% 
  group_by(genre) %>% 
  filter(n()>2000) %>% 
  group_by(genre,start_year) %>% 
  summarise(mean_episodes=mean(episodes,na.rm=TRUE),
            mean_score=mean(score,na.rm=TRUE),
            n=n())%>% 
  group_by(start_year) %>% 
  mutate(perc= n / sum(n))


ggplot()+
  geom_bar(data=tv_anime,aes(x=start_year,
                y=perc,
                fill=genre,
                group=genre), stat=""identity"") + 
  scale_y_continuous(labels=scales::percent) + 
  scale_fill_brewer(palette=""Set3"")

  
  
### deep learning model to predict genres & score based on the description/year?


three_d_boardgames$sizingPolicy$padding <- ""0""

saveWidget(three_d_boardgames,
           ""BoardGame_Ratings.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""BoardGame Ratings cloud - TidyTuesday March 13, 2019"")


```





","2019"
"318",1054,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-01/bird_collisions.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=18)

tt_data
```

```{r transform}


#cluster groupings over the years

mp_birds<-tt_data$bird_collisions %>%
  filter(locality==""MP"") %>% 
  left_join(tt_data$mp_light) %>% 
  filter(!is.na(light_score))


summarized_collisions<-mp_birds %>% 
  group_by(habitat,stratum,date,flight_call) %>% 
  summarise(ncollisions=n(),
            light_score=mean(light_score))

ggplot(summarized_collisions)+
  geom_point(data=summarized_collisions,
             aes(x=date,
                 y=light_score,
                 size=ncollisions), alpha=.1) + 
  geom_point(aes(x=date,
                 y=light_score,
                 colour=habitat,
                 size=ncollisions)) +
  facet_grid(habitat~stratum)
  

```





","2019"
"319",1055,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-08/student_ratios.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
library(rvest)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=19)

tt_data
```

```{r transform}

#download wikipeida information
happiness_score<-read_html(""https://en.wikipedia.org/wiki/World_Happiness_Report"") %>% 
  html_nodes("".wikitable"") %>% 
  html_table(fill=TRUE) %>% 
  `[[`(2) %>% 
  janitor::clean_names() %>% 
  select(overall_rank,country,score,gdp_per_capita) %>% 
  mutate(overall_rank = as.integer(overall_rank),
         score = as.numeric(score),
         gdp_per_capita = as.numeric(gdp_per_capita))


#cluster groupings over the years
ratio_2017<-tt_data$student_teacher_ratio %>%
  filter(year==""2017"") %>% 
  filter(country %in% happiness_score$country) %>% 
  inner_join(happiness_score) %>% 
  arrange(overall_rank) %>% 
  mutate(country=factor(country,levels = unique(country))) %>% 
  mutate(indicator=factor(indicator,levels= c(
    ""Pre-Primary Education"",""Primary Education"",
    ""Lower Secondary Education"",""Upper Secondary Education"", ""Secondary Education"",
     ""Tertiary Education"", ""Post-Secondary Non-Tertiary Education"")))



#nothing too interesting, just that it appears as though there is a larger difference in student ratio among ""happier"" countries 
ggplot(ratio_2017)+
  geom_tile(aes(y=country,x=indicator, fill=student_ratio))
  

```





","2019"
"320",1056,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-15/nobels.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

```

```{r transform}

#download wikipeida information
nobel_laureate_locations<-nobel_winners %>% 
  group_by(birth_country,organization_country,death_country,category) %>% 
  summarize(n=n()) %>% 
  arrange(n=desc(n))




nobel_laureate_birth_locations<-nobel_winners %>% 
  group_by(birth_country,organization_country,category) %>% 
  summarize(n=n()) %>% 
  arrange(n=desc(n))

nobel_laureate_death_locations<-nobel_winners %>% 
  group_by(organization_country,death_country,category) %>% 
  summarize(n=n()) %>% 
  arrange(n=desc(n))


node_Labels<-c(unique(nobel_laureate_locations$birth_country),
               unique(nobel_laureate_locations$organization_country),
               unique(nobel_laureate_locations$death_country))


length_birth_country<-length(unique(nobel_laureate_locations$birth_country))
length_organization_country<-length(unique(nobel_laureate_locations$birth_country))
length_death_country<-length(unique(nobel_laureate_locations$death_country))

node_birth_country<-setNames(seq(0,length_birth_country-1),unique(nobel_laureate_locations$birth_country))
node_organization_country<-setNames(seq(length_birth,length_birth+length_organization_country-1),unique(nobel_laureate_locations$organization_country))
node_death_country<-setNames(seq(length_birth+length_organization_country,length_birth+length_organization_country+length_death_country-1),unique(nobel_laureate_locations$death_country))




link_to_the_past_birth<-data.frame(
  source = node_birth_country[nobel_laureate_birth_locations$birth_country],
  target = node_organization_country[nobel_laureate_birth_locations$organization_country],
  value  = nobel_laureate_birth_locations$n,
  label  = nobel_laureate_birth_locations$category
)

link_to_the_past_death<-data.frame(
  source = node_organization_country[nobel_laureate_death_locations$organization_country],
  target = node_death_country[nobel_laureate_death_locations$death_country],
  value  = nobel_laureate_death_locations$n,
  label  = nobel_laureate_death_locations$category
)

link_to_the_past<-bind_rows(list(link_to_the_past_birth,link_to_the_past_death))

p <- plot_ly(
    type = ""sankey"",
    
    node = list(
      label = node_Labels,
      color =rep(""blue"",length(node_Labels)),
      pad = 5,
      thickness = 20,
      line = list(
        color = ""black"",
        width = 0.5
      )
    ),

    link = list(
      source = link_to_the_past$source,
      target = link_to_the_past$target,
      value  = link_to_the_past$value,
      label  = link_to_the_past$label
    )
  ) %>% 
  layout(
    title = ""Nobel - Laureate Locations"",
    font = list(
      size = 10
    )
)

p
  

```





","2019"
"321",1057,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-21/garbage.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-05-21"")
tt
```

```{r transform}


outputdataset<-tt$`per-capita-mismanaged-plastic-waste-vs-gdp-per-capita` %>% 
  
  rename(mismanaged_plastic = `Per capita mismanaged plastic waste (kilograms per person per day)`,
         gdp=`GDP per capita, PPP (constant 2011 international $) (Rate)`,
         total_pop =`Total population (Gapminder)`) %>% 
  
  left_join(  tt$`per-capita-plastic-waste-vs-gdp-per-capita` %>% 
              rename(total_plastic = `Per capita plastic waste (kilograms per person per day)`,
                     total_pop =`Total population (Gapminder)`) %>% 
                select(-`GDP per capita, PPP (constant 2011 international $) (constant 2011 international $)`,
                       -total_pop),
            by = c(""Entity"",""Code"",""Year"")) %>% 
  mutate( ratio_plastic = mismanaged_plastic/total_plastic ) %>% 
  filter(!is.na(ratio_plastic),
         !is.na(gdp))


#dichotomize ratio by GDP?
  
gdp_ratio<-ggplot(outputdataset)+
  geom_point(aes(x=gdp,
                 y=ratio_plastic,
                 text=Entity))+
  ggtitle(""Ratio of Mismanaged Plastic to Total Plastic by GDP in 2010"")+
  ylab(""Mismanaged/Total Plastic Waste Ratio"")+
  xlab(""Log 10 of Per Capita GDP ($)"")+
  # geom_density(aes(x=ratio_plastic,fill=HighGDP))+
  scale_x_log10()+
  geom_rug()
  
gdp_ratio_plotly<-ggplotly(gdp_ratio)

gdp_ratio_plotly$sizingPolicy$padding <- ""0""

saveWidget(gdp_ratio_plotly,
           ""2019-05-21/Plastic_Ratio_vs_GDP.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""atio of Mismanaged Plastic to Total Plastic by GDP in 2010 - TidyTuesday May 22, 2019"")

ggsave(""2019-05-21/Plastic_Ratio_vs_GDP.png"",gdp_ratio)


```





","2019"
"322",1058,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-28/winery_overtime.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-05-28"")
tt
```

```{r transform}


wine_trends<-tt$`winemag-data-130k-v2` %>% 
  
  select(country,points,title,variety) %>% 
  
  mutate(year = gsub(""(.*)([12][90]\\d{2})(.*)"",""\\2"",title),
         year = as.numeric(year,format=""%Y"")) %>% 
  
  filter(!is.na(year)) %>% 
  
  group_by(variety) %>% 

  filter(n()>5000) %>%  #keep only the most common wines
  
  filter(year < 2019, year > 1995) %>% 
  
  ungroup



#dichotomize ratio by GDP?
  
wine_trend_plot <- ggplot(wine_trends)+
  geom_point(aes(x=year,
                 y=points,
                 color = variety,
                 text=title))+
  geom_smooth(aes(x=year,
                 y=points,
                 color = variety))


```





","2019"
"323",1059,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-06-03/ramen_ratings.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(janitor)
library(pause)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-06-04"")
tt
```

```{r transform}

ramen_ratings<-tt$ramen_ratings

join<-function(...,by){
  return(list(...,inner_join(...,by)))
}


ramen_bowl <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Bowl"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""bowl"")  %>%
  mutate(name=paste(brand,variety,sep="" - ""))
  
ramen_cup <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Cup"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""cup"")  %>>>%
  mutate(name=paste(brand,variety,sep="" - ""))

ramen<-bind_rows(ramen_bowl,ramen_cup)


ramen_plot<-ggplot(ramen) +
  geom_point(aes(x=pack_stars,y=alt_stars, color = altstyle, text=name))+
  geom_abline(aes(slope=1,intercept=0))+
  ylab(""Ramen Bowl/Cup Stars"")+
  xlab(""Ramen Pack Stars"")+
  ggtitle(""Pack or Bowl/Cup- Which to choose?"")+
  theme_bw()
  
  

ggplotly(ramen_plot)



```





","2019"
"324",1060,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-06-17/christmas_birds.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(rvest)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-06-18"")
tt
```

```{r transform}

get_wiki_info<-function(bird_name){
  print(bird_name)
  read_html(paste0(""https://en.wikipedia.org/wiki/"",bird_name)) %>% 
    html_nodes("".infobox"") %>% 
    html_table() %>% 
    `[[`(1) %>% 
    set_names(c(""desc"",""value"")) %>% 
    filter(grepl("":|(IUCN)"",desc)) %>% 
    pull(value) %>% 
    set_names(c(""Conservation_Status"",""Kingdom"",""Phylum"",""Class"",""Order"",""Family"",""Genus"",""Species""))
}

Bird_info<-tt$bird_counts %>% 
  pull(species_latin) %>% 
  unique() %>% 
  map(~try(get_wiki_info(.x),silent = TRUE))

Bird_info %>% 
  lapply(function(x){if(!inherits(x,""try-error"")){x}}) %>% 
  do.call('rbind',.)

  
bird_info<-tt$bird_counts %>% 
  pull()
  
  
join<-function(...,by){
  return(list(...,inner_join(...,by)))
}


ramen_bowl <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Bowl"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""bowl"")  %>%
  mutate(name=paste(brand,variety,sep="" - ""))
  
ramen_cup <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Cup"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""cup"")  %>>>%
  mutate(name=paste(brand,variety,sep="" - ""))

ramen<-bind_rows(ramen_bowl,ramen_cup)


ramen_plot<-ggplot(ramen) +
  geom_point(aes(x=pack_stars,y=alt_stars, color = altstyle, text=name))+
  geom_abline(aes(slope=1,intercept=0))+
  ylab(""Ramen Bowl/Cup Stars"")+
  xlab(""Ramen Pack Stars"")+
  ggtitle(""Pack or Bowl/Cup- Which to choose?"")+
  theme_bw()
  
  

ggplotly(ramen_plot)



```





","2019"
"325",1061,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-07-01/media_franchises.Rmd","---
title: ""Media Franchises- TidyTuesday 07-02-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

library(igraph)
library(htmlwidgets)

tt<-tt_load(""2019-07-02"")
tt
```

```{r transform}


revenue<-tt$media_franchises %>% 
  mutate(original_media=case_when(
                               original_media %in% 
                                 c(""Digital pet"") ~ ""Home Video/Entertainment"",
                               original_media %in% 
                                 c(""Animated film"",""Film"",""Musical theatre"") ~ ""Box Office"",
                               original_media %in%
                                 c(""Comic book"",""Comic strip"",""Manga"",""Visual novel"") ~ ""Comic or Manga"",
                               original_media %in%
                                 c(""Book"",""Novel"") ~ ""Book sales"",
                               original_media %in%
                                 c(""Greeting card"") ~ ""Merchandise, Licensing & Retail"",
                               original_media %in%
                                 c(""Video game"") ~ ""Video Games/Games"",
                               original_media %in%
                                 c(""Animated cartoon"",""Animated series"",""Anime"",""Cartoon"",
                                   ""Cartoon character"",""Television series"") ~ ""TV""
                               )) %>% 
  group_by(revenue_category,original_media) %>% 
  summarise(total_revenue=sum(revenue))

revenue_nodes<-graph_from_data_frame(revenue)
E(revenue_nodes)$width <- 1+E(revenue_nodes)$weight/12

plot(revenue_nodes,edge.curved=.2)


revenue_d3<-data.frame()

ggplotly(ramen_plot)



```





","2019"
"326",1062,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-07-09/Womens_world_cup.Rmd","---
title: ""Womens World Cup - TidyTuesday 07-09-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load(""2019-07-09"")
tt
```

```{r transform}


wwc_distance<-tt$wwc_outcomes %>%
  group_by(year,team) %>% 
  summarize(best_round = case_when(
    ""Final""               %in% round ~ ""Final"",
    ""Third Place Playoff"" %in% round ~""Third Place Playoff"",
    ""Semi Final""          %in% round ~ ""Semi Final"",
    ""Quarter Final""       %in% round ~ ""Quarter Final"",
    ""Round of 16""         %in% round ~ ""Round of 16"",
    ""Group""               %in% round ~ ""Group"")) %>%
  ungroup %>% 
  mutate(best_round=factor(best_round,c(""Final"",""Third Place Playoff"",""Semi Final"",""Quarter Final"",
                                       ""Round of 16"",""Group"")))

theme_bare <- theme(
  axis.line = element_blank(), 
  axis.ticks = element_blank(), 
  #axis.ticks.length = unit(0, ""lines""), # Error 
  axis.ticks.margin = unit(c(0,0,0,0), ""lines""), 
  legend.position = ""none"", 
  panel.background = element_rect(fill = ""black""), 
  panel.border = element_blank(), 
  panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank(), 
  plot.background = element_rect(fill = ""gray""))

ggplot(wwc_distance)+
  geom_line(aes(x=year,y=abs(as.numeric(best_round)-7),color=team,size=1.5))+
  theme_bare+
  scale_y_continuous(breaks=c(6:1),
                     labels=levels(wwc_distance$best_round))+
  ylab(""Best Round Achieved"")+
  xlab(""World Cup Year"")+
  ggtitle(""World Cup Finishes"")


ggsave(""Womens_World_Cup_Finishes.png"")


```





","2019"
"327",1063,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-07-15/Tidyest_of_tuesday.Rmd","---
title: ""Tidyest of Tuesdays - TidyTuesday 07-15-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load(""2019-07-16"")
tt
```

```{r transform}

wwc_distance<-tt$r4ds_members 

```





","2019"
"328",1064,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-08-28/tidy_simpsons.Rmd","---
title: ""Simpsons Guest Appearances""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load_gh(""2019-08-27"")
tt
```

```{r transform}

guest_appearances <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")



roles <- guest_appearances %>% 
  select(season,number,guest_star,role) %>% 
  rowwise() %>% 
  do(data.frame(season     = .$season,
                number     = .$number,
                guest_star = .$guest_star,
                role       = trimws(strsplit(.$role,"";"")[[1]])))


roles_ot <- roles %>% 
  distinct(season,guest_star,role) %>% 
  group_by(season,guest_star) %>% 
  summarize(nroles = n()) %>% 
  ungroup()


ggplot(roles_ot)+
  geom_density(aes(x=nroles))+
  facet_wrap(season~.)

  

```





","2019"
"329",1065,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-09-03/moores_law.Rmd","---
title: ""Moores Law""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)

tt<-tt_load(""2019-09-03"")
tt
```

```{r transform}

gpu_plot<-tt$gpu %>% 
  filter(!is.na(process)) %>% 
  mutate(details=paste(""Year Released:"",date_of_introduction,""<br>"",
                       ""Manufacturer:"",manufacturer_s,""<br>"",
                       ""Processor:"",processor)) %>% 
  ggplot() +
  scale_x_log10()+
  scale_y_log10()+
  geom_point(aes(x     = process,
                 y     = transistor_count,
                 color = designer_s,
                 label = details ))

ggplotly(gpu_plot)


roles_ot <- roles %>% 
  distinct(season,guest_star,role) %>% 
  group_by(season,guest_star) %>% 
  summarize(nroles = n()) %>% 
  ungroup()


ggplot(roles_ot)+
  geom_density(aes(x=nroles))+
  facet_wrap(season~.)

  

```





","2019"
"330",1066,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-09-10/Amusing_Injuries.Rmd","---
title: ""Amusing Injuries""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)
library(geofacet)

tt<-tt_load(""2019-09-10"")
tt
```

```{r transform}

injuries_by_state<-tt$saferparks %>% 
  select(state      = acc_state,
         industry   = industry_sector,
         operator   = op_error,
         mechanical = mechanical,
         employee   = employee,
         age        = age_youngest) %>% 
  mutate(operator = if_else(is.na(operator),0,1),
         mechanical = if_else(is.na(mechanical),0,1),
         employee = if_else(is.na(employee),0,1),
         other = as.numeric((operator + mechanical + employee) == 0 ))

injured_plots<-injuries_by_state %>% 
  gather(error_type,at_fault,operator,mechanical,employee,other) %>% 
  filter(at_fault == 1) %>% 
  ggplot(aes(x=age, fill = error_type)) +
  geom_density() +
  theme_bw() +
  facet_grid(industry~error_type)+
  theme(legend.position = NULL)


ggplotly(injured_plots)

```





","2019"
"331",1067,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-09-17/park_visits.Rmd","---
title: ""National Parks""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)
library(ggridges)
library(geofacet)

tt<-tt_load(""2019-09-17"")
tt
```

```{r transform}

top_state_park <- tt$national_parks %>% 
  filter(year==""Total"",
         !is.na(parkname)) %>% 
  group_by(state) %>% 
  summarise(bestPark=parkname[which.max(visitors)])


nparks<-tt$national_parks %>% 
  filter(year!=""Total"",
         !is.na(parkname)) %>% 
  mutate(year = as.Date(paste0(""01-01-"",year),format=""%m-%d-%Y"")) %>% 
  select(parkname,year,region,state,unit_type,visitors) %>% 
  filter(parkname %in% top_state_park$bestPark) %>% 
  group_by(region,parkname) %>% 
  mutate(regional_park_max = max(visitors)) %>% 
  group_by(parkname) %>% 
  mutate(visitors = visitors/max(visitors),
         age = min(year)) %>% 
  arrange(region,desc(age),year) %>% 
  ungroup %>% 
  mutate(
    region = factor(region,levels=unique(region)),
    parkname = factor(parkname,levels=unique(parkname))
  )

park_attendees<-nparks %>% 
  ggplot(aes(x = year,
           y = parkname,
           height=visitors,
           fill = region))+
  geom_ridgeline()+
  facet_grid(region~.,
             scales = ""free_y"",
             space = ""free_y"")+
  theme_minimal()+
  ggtitle(""Park Attendance Over Time (Normalized by maximal attendance)"")+
  theme(axis.text.y = element_text(vjust = -.25))
park_attendees

ggsave(filename = file.path(here::here(),""2019-09-17"",""Park_Attendance.png""),
       plot     = park_attendees,
       device   = ""png"",
       height   = 20,
       width    = 10)

```


```{r delta attendees percent}


delta<-function(x,index){
  x<-x[order(index)]
  delta<-c(NA,(x[seq(2,length(x))]-x[seq(1,length(x)-1)]))
  delta[delta==Inf]<-0
  delta
}

top_region_park <- tt$national_parks %>% 
  filter(year==""Total"",
         !is.na(parkname)) %>% 
    group_by(region) %>% 
  summarise(bestPark=parkname[which.max(visitors)])

tt$national_parks%>%
  filter(year!=""Total"",
         !is.na(parkname)) %>% 
  filter(parkname %in% top_region_park$bestpark) %>% 
  group_by(parkname)%>%
  arrange(year) %>% 
  mutate(delta_visitors=delta(visitors,year),
         delta_direction=ifelse(delta_visitors>0,""green"",""red""))%>%
  mutate(delta_visitors=ifelse(is.na(delta_visitors)|is.nan(delta_visitors),0,delta_visitors),
         totalSum=cumsum(delta_visitors))%>%
  ggplot()+
  geom_segment(aes(x=year,     xend = year,
                   y=totalSum, yend = totalSum-delta_visitors,
                   color=I(delta_direction)),
               size=2) +
  facet_wrap(department~.,
             scales = ""free_y"",
             strip.position = ""top"",
             ncol = 3) +
  ggtitle(label = ""US R&D Dollars"") +
  ylab(""? in visitors()"") +
  xlab(""Year"")



```
","2019"
"332",1068,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-01/pizza_party.Rmd","---
title: ""Pizza Party!!!""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(leaflet)
library(rvest)
library(htmlwidgets)

tt<-tt_load(""2019-10-01"")
tt
```

```{r transform}

pizzas <- tt$pizza_barstool %>% 
  filter(review_stats_community_average_score > 0) %>% 
  mutate(score_scaled = scale(review_stats_community_average_score)) %>% 
  select(name,
         address = address1,
         latitude,
         longitude,
         price = price_level,
         score = review_stats_community_average_score,
         score_scaled) %>% 
  rowwise() %>% 
  mutate(label=paste0(
    name,""<br>"",
    address,""<br>"",
    ""Score: "",round(score,2),""<br>"",
    ""Price: "",paste(rep(""$"",price+1),collapse=""""))
    )

```

```{r leaflet_plot}

calcColor<-function(x,colors,...,granularity=100){
  colfunc <- colorRampPalette(colors,...)
  colors<-colfunc(granularity)
  newx<-round((granularity-1 ) * ((x - min(x)) / (max(x) - min(x))))+1
  colors[newx]
}

calcRadius<-function(x,maxsize=100,minsize=5,method=scale_sigmoid){
    oneScaled<-((x - min(x)) / (max(x) - min(x)))
    (maxsize - minsize) * method(oneScaled)  + minsize;
}
scale_sigmoid<-function(x){
  (tanh((x-.5)*2*pi)+1)/2
}
scale_linear<-function(x){
  x
}

ll <- leaflet(pizzas) %>% 
  addTiles() %>%
  addCircleMarkers(
    lng= ~longitude,
    lat= ~latitude,
    radius = ~calcRadius(score_scaled,maxsize = 20,minsize=1,scale_sigmoid),
    popup = ~label,
    color = ~calcColor(price,color=c(""white"",""#ce0000"")),
    stroke = FALSE,
    fillOpacity = 0.5
  )

ll

```

","2019"
"333",1069,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-08/power_lifting_IPF.Rmd","---
title: ""The lift of POWER""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load(""2019-10-08"")
tt
```

Do doping have an effect?

```{r transform}

doping_competitors <- tt$ipf_lifts %>% 
  filter(place==""DD"") %>% 
  pull(name)
  

# first event of doping for each person and center at that event
center_first_dope_event <- tt$ipf_lifts %>% 
  filter(name %in% doping_competitors) %>% 
  group_by(name) %>% 
  arrange(date) %>% 
  mutate(
    first_dope = min(date[place==""DD""]),
    npriordope = sum(date < first_dope),
    npostdope  = sum(date > first_dope)
  ) %>% 
  filter(npriordope > 0, npostdope >0) %>% 
  mutate(days_centered_first_dope = as.numeric(date - first_dope)) %>% 
  gather(""lift"",""kg"",starts_with(""best"")) %>% 
  group_by(name,lift) %>% 
  arrange(days_centered_first_dope) %>% 
  mutate(best_prior_dope = max(kg[days_centered_first_dope<0]),na.rm=TRUE) %>% 
  mutate(normalized_kg = kg/best_prior_dope) %>% 
  group_by(name) %>% 
  mutate(caught_again = any(place[days_centered_first_dope>0]==""DD""),
         better_post_dope = all(normalized_kg[days_centered_first_dope>0]>1.01)) %>% 
  ungroup()
  

```

```{r plot}

center_first_dope_event %>% 
  filter(!is.na(kg)) %>% 
  mutate( `DQed for Doping` = place==""DD"") %>% 
  mutate( caught_again = factor(if_else(
    caught_again,""DQ'ed for doping again"",""Never caught doping again""),
    levels = c(""Never caught doping again"",""DQ'ed for doping again""))) %>% 
  ggplot(aes(
    x=days_centered_first_dope,
    y=normalized_kg
    ))+
  geom_point(
    aes(color=`DQed for Doping`),
    alpha = .5
    )+
  geom_line(
    aes(group=name),
    alpha = .5
    )+
  geom_smooth()+
  geom_hline(
    aes(yintercept=1)
    )+
  facet_grid(lift~sex+caught_again, scales = ""free_y"")+
  scale_y_continuous(
    breaks = c(.5,.75,.9,1,1.1,1.25,1.5)
  )+
  theme_bw()+
  theme(legend.position = ""bottom"")+
  ggtitle(""Straight Dope"",""Athletes caught for doping after first offense tended to increase\n their best 3 lifts unlike athletes that were not caught again on average. \nThis might lend itself to the idea of needing more testing \nfor the athletes that continued to trend up at a high rate."")

ggsave(""2019-10-08/doping_results.png"")


```


```{r}

center_first_dope_event %>% 
  select(name,date,place,event,days_centered_first_dope) %>% 
  mutate(post_dope = days_centered_first_dope>0) %>% 
  distinct() %>% 
  group_by(name,post_dope) %>% 
  summarise(rank = mean(as.numeric(place),na.rm = TRUE)) %>% 
  spread(post_dope,rank) %>% 
  mutate(better_post = `TRUE` < `FALSE`) %>% 
  gather(post_dope,rank,`TRUE`,`FALSE`) %>% 
  ggplot(aes(x=post_dope,y=rank))+
  geom_boxplot()+
  geom_jitter(height = 0)+
  facet_grid(~better_post)+
  geom_line(aes(group=name))+
  scale_y_continuous(breaks = 1:10)


```
","2019"
"334",1070,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-15/EPA_EPA.Rmd","---
title: ""EPA EPA""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-10-15"")
tt
```

Do doping have an effect?

```{r transform}

small_epa_cars <- tt$big_epa_cars %>% 
  select(highway08,co2,drive,fuelType,make,model,year,cylinders) %>% 
  distinct(make,model,fuelType,cylinders,.keep_all = TRUE) %>% 
  filter(co2>0) %>% 
  mutate( gco2pergallon = co2 * highway08 ) %>% 
  group_by(make) %>% 
  filter(n()>20) %>% 
  ungroup %>% 
  mutate(
    year = lubridate::as_date(paste0(year,""-01-01"")),
    drive = case_when(
      drive == ""All-Wheel Drive"" ~ ""4-Wheel Drive"",
      drive == ""Part-time 4-Wheel Drive"" ~ ""4-Wheel Drive"",
      TRUE ~ drive
    ),
    fuelType = case_when(
      grepl(""Gasoline"",fuelType) ~ ""Gasoline"",
      grepl(""Premium"",fuelType) ~ ""Premium"",
      grepl(""Regular"",fuelType) ~ ""Regular"",
      TRUE ~ fuelType
    ),
    cylinders = as.character(cylinders)
  )


```

```{r plot}

efficiency <- small_epa_cars %>% 
  mutate( year = lubridate::year(as.character(year))) %>% 
  mutate( Make = paste(make,""<br>Model:"",model,""<br>Year:"",year,""<br>Cylinders:"",cylinders)) %>%
  ggplot(aes(
    x=highway08,
    y=co2
    ))+
  geom_point(
    aes(color = drive,
        label = Make),
    alpha = .5
  )+
  facet_grid( ~ fuelType  )+
  theme_bw()+
  theme(legend.position = ""bottom"",legend.title = element_text(""Drivetrain Type"")) +
  ggtitle(""EPA EPA"",""Grams of CO2 produced vs Highway MPG, colored by make"")+
  ylab(""Tailpipe CO2 [grams/mile]"")+
  xlab(""Highway MPG"")



efficiency_plotly <- ggplotly(efficiency)%>%
  layout(legend = list(orientation = 'h',
                       x = 0.1, y = -0.1))

```


```{r}

efficiency_plotly$sizingPolicy$padding <- ""0""



saveWidget(efficiency_plotly,
           file.path(here::here(),""2019-10-15"",""bi_epa_mtcars.html""),     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""CO2 vs Highway MPG"")

ggsave(file.path(here::here(),""2019-10-15"",""bi_epa_mtcars.png""),
       efficiency)


```","2019"
"335",1071,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-29/squirrelly.Rmd","---
title: ""EPA EPA""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(lubridate)
library(plotly)

tt<-tt_load(""2019-10-29"")
tt
```

```{r transform}



git_squirrelly <- tt$nyc_squirrel %>% 
  group_by(hectare) %>% 
  count() %>% 
  ungroup %>% 
  mutate(NS = substring(hectare,0,2),
         EW = substring(hectare,3)) %>% 
  select(-hectare) %>% 
  spread(EW,n) %>% 
  gather(EW,n,-NS)
 


```

```{r plot}

squirrelly <- git_squirrelly %>% 
  mutate(EW = factor(EW,levels = rev(unique(EW)))) %>% 
  ggplot(aes(
    y=EW,
    x=NS
    ))+
  geom_tile(
    aes(fill = n),
    # shape = 15,
    # size = 5
    width = .9,
    height = .9
    )+
  coord_equal()+
  theme_minimal()+
  theme(legend.position = ""right"",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()
        ) +
  ggtitle(""Squirrel Observations in Central Park(NYC)"")+
  xlab(""Hectare ID (North-South)"")+
  ylab(""Hectare ID (East-West)"")+
  scale_fill_continuous(low=""lightgreen"",high=""darkgreen"")


squirrelly_plotly <- ggplotly(squirrelly)%>%
  layout(legend = list(orientation = 'h',
                       x = 0.1, y = -0.1))

```


```{r}

# squirrelly_plotly$sizingPolicy$padding <- ""0""
# 
# 
# saveWidget(squirrelly_plotly,
#            file.path(here::here(),""2019-10-29"",""squirrelly.html""),     
#            selfcontained = FALSE,
#            libdir = ""lib"",
           # title = ""Squirrel locations in "")

ggsave(file.path(here::here(),""2019-10-29"",""squirrelly.png""),
       squirrelly,
       width = 10,
       height = 3)


```","2019"
"336",1076,"https://github.com/ethantenison/TidyTuesday-","ethantenison","TidyTuesday-","2019-06-24/README.rmd","## Lessons from Tidy Tuesday 

******

Tidy Tuesday is a terrific opportunity to practice wrangling data and chart visualizations in R. Interesting data sets are available each week. Other R enthusiasts provide feedback and seeing their charts generates ideas.

Below are lessons that I have learned from my submissions.

| Week        | Data Set | Lesson                    | Function       | Package |
| :--:        |:--:      |:--:                       |:--:            |:--:     |
|`2019-06-24` | UFOs     | Customize legend position |legend.position |ggplot2  |","2019"
"337",1077,"https://github.com/ethantenison/TidyTuesday-","ethantenison","TidyTuesday-","2019-06-24/UFOs_Over_Texas.R","#First R submission 
library(tidyverse)
library(janitor)
library(lubridate)
library(extrafont)
library(ggdark)


        ufo_raw<- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"") 
        clean_names ()


        map_borders <-  map_data(""state"", region = NULL) %>% filter (region == ""texas"")  
        
        ufo <- ufo_raw %>% select (date_time, city_area, state, latitude, longitude, encounter_length) %>%
        
        filter (
                state == ""tx"",
                latitude > 25,      # remove borders erroneously listed as TX outside of state borders
                latitude < 38,      # remove borders erroneously listed as TX outside of state borders
                longitude < -90     # remove borders erroneously listed as TX outside of state borders
                )  %>%
        mutate(
                encounter_length = encounter_length/3600,              #convert seconds to hours
                date_time = as.Date(date_time, format = ""%m/%d/%Y"")
                ) 
                



        ggplot () +#plot Texas borders
                geom_polygon (data = map_borders, aes(x = long, y = lat, group = group), 
                color = ""black"", fill = ""#303030"", size = 1.15) +
                
        #plot UFO encounters
        geom_point (data = ufo, aes (x = longitude, y = latitude, size = encounter_length), color = ""green"") +
        
        #Clifton encounter annotation
        annotate(""text"",label = ""42 day encounter\nin Clifton in 1966."",size = 3, hjust = 0, color = ""magenta"", family = ""Rockwell"",
               x = -92.57639, y = 31.78222, xmax = -83.5) +
        
        geom_curve(
                aes(x = -92.5, y = 31.7, xend = -97.57639, yend = 31.78222),
                arrow = arrow(length = unit(0.2, ""cm"")), 
                size = 0.4, color = ""magenta"", curvature = -0.3
        ) +
        coord_fixed(1.3) +
        scale_size_continuous(breaks = c(1, 10, 100)) +
        dark_mode(theme_minimal()) +
        theme(text = element_text(family = ""Rockwell"", color = ""green""),
        plot.title = element_text(hjust = 0.5, size = 18),
        plot.caption = element_text(hjust = 0, size = 8),
        legend.title = element_text(size = 10, hjust = 0.5, vjust = 0.5),
        legend.text = element_text(size = 9, hjust = 0.5, vjust = 0.5),
        legend.position = c(0.82,0.18),
        legend.justification=c(0, 1), 
        legend.key.size = unit(0.1, 'lines'),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank()
        ) +
        labs(
        title = ""UFOs over Texas\n"",
        size = ""Encounter (hrs)"",
        caption = ""\nEach dot represents a reported UFO sighting between 1910 and 2014.  
                \nSource: National UFO Reporting Center  | Visualization: Ethan Tenison @sassyStatistics""
        ) +
ggsave(""ufo.png"", height =3.85)

        ","2019"
"338",1078,"https://github.com/ethantenison/TidyTuesday-","ethantenison","TidyTuesday-","2019-07-09/WWC_Top12.Rmd","---
title: ""WWC Wins""
author: ""Ethan Tenison""
date: ""7/12/2019""
output: html_document
---
### 1a. Source WWC data
```{r source, warning = TRUE, results = FALSE, message = FALSE}
library(dplyr)        ## data wrangling
library(tidyr)        ## data wrangling
library(purrr)        ## data wrangling and iteration
library(stringr)      ## data wrangling
library(rvest)        ## webscraping
library(polite)       ## webscraping (Github only pkg)
library(ggplot2)      ## plotting
library(scales)       ## plotting scales
library(ggimage)      ## images for flags
library(ggforce)      ## plotting text labels
library(cowplot)      ## plotting grid
library(glue)         ## text
library(ggrepel)      ## plotting text labels
library(magick)       ## plotting
library(ggtextures)   ## soccer ball emoji as geom_col()
library(extrafont)    ## fonts: Roboto Condensed

    wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
    squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
    codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
```

### 2.  Transform WWC data
```{r transform, message = F}
#separating the top 10 countrie 
top10_countries <- c(""USA"", ""GER"", ""NOR"", ""SWE"", ""BRA"", ""CHN"", ""ENG"", ""JPN"", ""FRA"", ""CAN"")
top10 <- filter(wwc_outcomes, team %in% top10_countries)

#creating an object that contains flag ISO codes to use with geom_flags
flag_data <- data.frame(
  image = c(""us"", ""de"", ""no"",  ""se"", ""br"", ""cn"", ""gb-eng"", ""jp"", ""fr"", ""ca""),
  x = c(10, 20,30,40,50,60, 70,80,90,100),
  y = c(-10, -10,-10,-10,-10,-10,-10,-10,-10,-10)
)

```

### 3. Visualize data
```{r plot}
   library (ggdark)
   library(ggimage)
   library(ggforce)

      #raw plot the win status of top 10 
      rawplot <- ggplot(data = top10, aes(x =factor(team), fill = factor(win_status))) 
              + geom_bar()+ coord_flip()+ geom_text(aes(label=..count..), stat = ""count"", position = position_stack(0.5)) 
              + scale_x_discrete(limits=c(""CAN"",""FRA"", ""ENG"", ""JPN"", ""CHN"", ""BRA"", ""SWE"", ""NOR"", ""GER"", ""USA"")) 
              + dark_theme_minimal() +theme(axis.title.x=element_blank(), line =     axis.text.x=element_blank(),axis.ticks.x=element_blank()) + theme(axis.title.y=element_blank()) 
              + theme(plot.title = element_text(size=18, hjust = 2)) 
              + theme(legend.title = element_blank()) 
              + labs(title = ""Women's World Cup: Top 10 Winners from 1991 to 2019\n"",caption = ""\nSource: data.world  |     Visualization: Ethan Tenison @SassyStatistics"") 
      
      #Add flags to y-axis
      axis_image <- axis_canvas(rawplot, axis = 'y') + 
  draw_image(""https://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg"", 
             y = 49.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/b/ba/Flag_of_Germany.svg"", 
             y = 44, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/d/d9/Flag_of_Norway.svg"", 
             y = 38.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/4/4c/Flag_of_Sweden.svg"", 
             y = 33, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/0/05/Flag_of_Brazil.svg"", 
             y = 27.5, scale = 3.5) +
   draw_image(""https://upload.wikimedia.org/wikipedia/commons/f/fa/Flag_of_the_People%27s_Republic_of_China.svg"", 
             y = 22, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/1/1b/Flag_of_Japan_%281870%E2%80%931999%29.svg"", 
             y = 16.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/b/be/Flag_of_England.svg"", 
             y = 11, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/c/c3/Flag_of_France.svg"", 
             y = 5.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/1/1f/Flag_of_Canada_%281964%29.svg"", 
             y = 0, scale = 3.5) 
  
     
        top10 <- ggdraw(insert_yaxis_grob(rawplot, 
  axis_image, position = ""left""))
        
      
```


### 4.  Save data
```{r}

ggsave(""wwc_top10_teams.png"", width = 14, height = 12)

```
","2019"
"339",1095,"https://github.com/cienciadedatos/datos-de-miercoles","cienciadedatos","datos-de-miercoles","datos/2019/2019-05-01/ejemplos_visualizacion.Rmd","---
title: ""Ejemplos de visualizacin""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
load(""comercio_hispanoamerica_mundo_agregado.rda"")

if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(tidyverse, treemapify)
```

```{r}
comercio_chile_mundo <- comercio_hispanoamerica_mundo_agregado %>% 
  filter(codigo_iso_origen == ""chl"")

comercio_chile_mundo %>% 
  mutate(
    region = ifelse(pais_destino_pertenece_a_hispanoamerica == 1, ""Hispanoam\u00e9rica"", ""Otras regiones"")
  ) %>% 
  group_by(anio, region) %>% 
  summarise(valor_exportado_dolares = sum(valor_exportado_dolares, na.rm = T)) %>% 
  ggplot(aes(x = anio, y = valor_exportado_dolares, fill = region)) +
    geom_col(position = ""dodge2"") +
    labs(
      x = ""A\u00f1o"", 
      y = ""Valor Exportado (D\u00f3lares)"", 
      title = ""Exportaciones de Chile por A\u00f1o y Regi\u00f3n""
    ) +
    coord_flip() +
    theme_bw() +
    theme(legend.position = ""bottom"")
```

```{r}
comercio_chile_mundo_2017 <- comercio_chile_mundo %>% 
  filter(anio == 2017) %>% 
  group_by(anio, nombre_comunidad_producto, color_comunidad_producto) %>% 
  summarise(valor_exportado_dolares = sum(valor_exportado_dolares, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(
    etiquetas = paste0(nombre_comunidad_producto, ""\n"", round(100*valor_exportado_dolares/sum(valor_exportado_dolares), 2), ""%"")
  )

comercio_chile_hispanoamerica_2017 <- comercio_chile_mundo %>% 
  filter(anio == 2017, pais_destino_pertenece_a_hispanoamerica == 1) %>% 
  group_by(anio, nombre_comunidad_producto, color_comunidad_producto) %>% 
  summarise(valor_exportado_dolares = sum(valor_exportado_dolares, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(
    etiquetas = paste0(nombre_comunidad_producto, ""\n"", round(100*valor_exportado_dolares/sum(valor_exportado_dolares), 2), ""%"")
  )
```

```{r}
ggplot(comercio_chile_mundo_2017, 
       aes(area = valor_exportado_dolares, fill = nombre_comunidad_producto, label = etiquetas)) +
  geom_treemap() +
  geom_treemap_text(colour = ""white"",
                    place = ""centre"",
                    grow = F,
                    reflow = T) +
  scale_fill_manual(values = comercio_chile_mundo_2017$color_comunidad_producto) +
  labs(title = ""Exportaciones de Chile a nivel Mundial (2017)"") +
  theme_bw() +
  theme(legend.position = ""none"")

ggplot(comercio_chile_hispanoamerica_2017, 
       aes(area = valor_exportado_dolares, fill = nombre_comunidad_producto, label = etiquetas)) +
  geom_treemap() +
  geom_treemap_text(colour = ""white"",
                    place = ""centre"",
                    grow = F,
                    reflow = T) +
  scale_fill_manual(values = comercio_chile_hispanoamerica_2017$color_comunidad_producto) +
  labs(title = ""Exportaciones de Chile a nivel de Hispanoam\u00e9rica (2017)"") +
  theme_bw() +
  theme(legend.position = ""none"")
```

","2019"
"340",1096,"https://github.com/cienciadedatos/datos-de-miercoles","cienciadedatos","datos-de-miercoles","datos/2019/2019-10-23/README.Rmd","---
title: 'Constitucin Abierta: Una Nueva Constitucin Para Chile'
author: ""Pach""
date: ""10/23/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduccin

Durante el ao 2016, en Chile se llev a cabo un proceso de consulta a los ciudadanos chilenos con la finalidad de conocer sus principales preocupaciones y cmo llevar estas a una nueva Constitucin Poltica de la Repblica.

Inicialmente el proceso de consulta fue llevado a cabo con poca transparencia, pero afortunadamente la presin de la sociedad civil llev a hacer disponibles pblicamente las actas de estos encuentros de debate ciudadano.

La forma de reunir las opiones fue registrar actas de encuentros en los cuales los vecinos de distintas comunas del pas se reunieron a debatir y manifiestar sus puntos de acuerdo y desacuerdo respecto de Derechos Humanos, Salud, Educacin, Pensiones, entre otros.

El sitio web del proyecto Constitucin Abierta (DCC UChile) estableca que: ""Los datos del Proceso Constituyente deben estar disponibles abiertamente para todas y todos los chilenos.""

Estos datos provienen de un proceso impulsado por el Departamento de Ciencias de la Computacin de la Universidad de Chile, el cual se dedic a reunir de manera paralela las actas de las instancias de participacin.

# Paquetes

Sugerimos usar el tidyverse para manipular y visualizar los datos. Para visualizar usando mapas, se podra usar el paquete `chilemaps` disponible en github.com/pachamaltese/chilemaps.

```{r}
library(tidyverse)
```

# Datasets

Contienen los conceptos clave discutidos y la justificacin de los acuerdos o desacuerdos.

## Conceptos

Resume los tpicos tratados durante las reuniones, si hubo acuerdo o no y su justificacin. Incluye los datos geogrficos (comuna y regin) del lugar de encuentro.

```{r}
load(""~/datos-de-miercoles/datos/2019/2019-10-23/01-conceptos.rdata"")
conceptos
```

La columna `idELA` permite unir con la tabla `memoria`.

## Memoria

Sintetiza el nimo sostenido durante el encuentro.

```{r}
load(""~/datos-de-miercoles/datos/2019/2019-10-23/02-memoria.rdata"")
memoria
```
","2019"
"341",1097,"https://github.com/cienciadedatos/datos-de-miercoles","cienciadedatos","datos-de-miercoles","datos/2019/2019-10-23/exportar-sql-a-rdata.R","library(RMariaDB)
library(tidyverse)

# sacar datos de sql ----

con <- dbConnect(RMariaDB::MariaDB(), group = ""constitucionabierta"")

dbListTables(con)

# comuna <- tbl(con, ""Comuna"") %>% collect() %>% as_tibble()
conceptos <- tbl(con, ""Conceptos"") %>% collect() %>% as_tibble()
ela <- tbl(con, ""ELA"") %>% collect() %>% as_tibble()
memoria <- tbl(con, ""Memoria"") %>% collect() %>% as_tibble()

# arreglar comunas ----

# este dataset viene de github.com/pachamaltese/chilemaps
load(""~/datos-de-miercoles/datos/2019/2019-10-23/territorial_codes.rda"")

conceptos <- conceptos %>% 
  left_join(ela) %>% 
  select(-c(id, tema, estado, numeroConcepto, esOtros)) %>% 
  mutate(
    comuna = iconv(comuna, from = ""UTF-8"", to = ""ASCII//TRANSLIT"", sub = """"),
    comuna = str_trim(comuna),
    comuna = str_replace_all(comuna, ""[^[:alnum:]|[:space:]]"", """"),
    comuna = str_to_title(comuna)
  ) %>%
  mutate(
    comuna = str_replace_all(comuna, "" De "", "" de ""),
    comuna = str_replace_all(comuna, "" Del "", "" del ""),
    comuna = str_replace_all(comuna, "" La "", "" la ""),
    comuna = str_replace_all(comuna, "" Las "", "" las ""),
    comuna = str_replace_all(comuna, "" Los "", "" los ""),
    comuna = str_replace_all(comuna, "" Y "", "" y ""),
    comuna = str_replace_all(comuna, ""Ohiggins"", ""OHiggins"")
  ) %>% 
  mutate(
    comuna = case_when(comuna == ""La Calera"" ~ ""Calera"",
                       comuna == ""Coyhaique"" ~ ""Coihaique"",
                       comuna == ""San Vicente de Tagua Tagua"" ~ ""San Vicente"",
                       comuna == ""Aysen"" ~ ""Aisen"",
                       comuna == ""Paihuano"" ~ ""Paiguano"",
                       TRUE ~ comuna)
  ) %>% 
  left_join(territorial_codes, by = c(""comuna"" = ""commune_name"")) %>% 
  # select(comuna:commune_id) %>% 
  # distinct() %>% 
  # filter(is.na(region_id))
  select(idELA:fecha, id_comuna = commune_id, comuna, id_region = region_id, region = region_name)

# guardar ----

# save(comuna, file = ""01-comuna.rdata"", compress = ""xz"")
save(conceptos, file = ""01-conceptos.rdata"", compress = ""xz"")
# save(ela, file = ""03-ela.rdata"", compress = ""xz"")
save(memoria, file = ""02-memoria.rdata"", compress = ""xz"")
","2019"
"342",1100,"https://github.com/benmoretti/tidytuesdays/tree/master/2019-03-26","benmoretti","tidytuesdays","2019-03-26/seattle_pet_names.R","#' tidytuesday 20-03-26
#' Seattle Pet Names


# Libraries ---------------------------------------------------------------

library(tidyverse)
library(lubridate)
library(zipcode)
library(timetk)
library(leaflet)
library(janitor)

# Gather ------------------------------------------------------------------

data(zipcode)

seattle_pets_tbl <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")


# Condition ---------------------------------------------------------------

seattle_pets_conditioned_tbl <- seattle_pets_tbl %>%
  clean_names() %>%
  mutate(
    license_issue_date = mdy(license_issue_date)
  ) %>%
  inner_join(zipcode, by = c(""zip_code""=""zip"")) %>%
  tk_augment_timeseries_signature()



# Visualise ---------------------------------------------------------------

# map the location of cats in 2018 by zip code
seattle_pets_conditioned_tbl %>%
  filter(
    species == ""Cat"",
    year == 2018
  ) %>%
  count(zip_code, latitude, longitude) %>%
  leaflet() %>% addTiles() %>% addCircleMarkers()


common_names_plot <- seattle_pets_tbl %>%
  count(animals_name, species) %>%
  spread(species, n) %>%
  filter(
    ! is.na(Cat),
    ! is.na(Dog),
    ! is.na(Pig)
  ) %>%
  select(-Goat) %>%
  mutate(total = Cat + Dog + Pig) %>%
  gather(species, count, -animals_name, -total) %>%
  drop_na(animals_name) %>%
  mutate(
    animals_name = fct_reorder(animals_name, total)
  ) %>%
  ggplot(aes(animals_name, count)) +
  geom_col(aes(fill=species)) +
  theme_light() +
  scale_fill_viridis_d() +
  coord_flip() +
  theme(legend.position = ""bottom"") +
  labs(
    title = ""Common Seattle Pet Names"",
    x = ""Animal Name"",
    y = ""Count"",
    fill = ""Animal Species"",
    subtitle = ""Source: Seattle Open Data"",
    caption = ""#tidytuesday / 2019-03-26 / @benmoretti""
  ) 

ggsave(""2019-03-26/common_names.png"", common_names_plot)  
  
  ","2019"
"343",1101,"https://github.com/benmoretti/tidytuesdays/blob/master/2019-03-12/boardgames.R","benmoretti","tidytuesdays","2019-03-12/boardgames.R","#' boardgames.R


# Libraries ---------------------------------------------------------------

library(tidyverse)
library(janitor)
library(vapoRwave)
library(extrafont)


# Gather ------------------------------------------------------------------

board_games_tbl <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"") %>% clean_names()


# Visualise -------------------------------------------------------------------


# Top 8 Board Games Mechanics vs Time ------------------------------------

# get a character array of the top 8 mechanics
top_8_mechanics <- board_games_tbl %>% 
  separate_rows(mechanic, sep = "","") %>% 
  count(mechanic) %>%
  arrange(desc(n)) %>%
  drop_na(mechanic) %>%
  slice(1:8) %>%
  pull(mechanic)

# just a simple line plot but using vapoRwave theme
board_games_tbl %>% 
  separate_rows(mechanic, sep = "","") %>%
  filter(mechanic %in% top_8_mechanics) %>%
  count(mechanic, year_published) %>%
  ggplot(aes(year_published, n)) +
  geom_line(aes(colour=mechanic), size=2) +
  floral_shoppe() + 
  scale_color_floralShoppe() +
  labs(
    title = ""Top 8 Board Games' Mechanics vs Time"",
    subtitle = ""Source: boardgamegeek.com / @benmoretti"",
    x = ""Year"",
    y = ""Number of Games""
  ) +
  theme(
    legend.position = ""bottom""
  )
  
ggsave(""2019-03-12/Growth_vs_time.png"")


# The average rating for the top game of each year vs time -------------------------------------

board_games_tbl %>%
  group_by(year_published) %>%
  arrange(desc(average_rating)) %>%
  slice(1) %>%
  ungroup() %>%
  ggplot(aes(year_published, average_rating)) +
  geom_point(aes(size=users_rated), colour=""#E3D26F"") +
  geom_smooth(se=FALSE, linetype=""dashed"", colour = ""#FAA275"") +
  floral_shoppe() + 
  scale_colour_floralShoppe() +
  labs(
    title = ""The average rating for the top game of each year vs time"",
    subtitle = ""Source: boardgamegeek.com / @benmoretti"",
    x = ""Year"",
    y = ""Average Rating""
  ) +
  theme(
    legend.position = ""bottom""
  )

ggsave(""2019-03-12/rating_vs_time.png"")

","2019"
"344",1102,"https://github.com/benmoretti/tidytuesdays/blob/master/2019-02-26/french_trains.R","benmoretti","tidytuesdays","2019-02-26/french_trains.R","#' french_trains.R
#'
#' @author Ben Moretti
#'
#' @description Reads data for the 26 Feb 2019 #tidytuesday - French Trains - and visualises using ggalluvial


# Libraries -----------------------------------------------------------------

library(tidyverse)
library(lubridate)
library(ggalluvial)
library(gganimate)

# Gather ------------------------------------------------------------------

trains_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")


# Condition ---------------------------------------------------------------

# select data for paris departures for july 2017
paris_2017_trips <- trains_raw %>% 
  filter(
    year == 2017,
    month == 7,
    str_detect(departure_station, ""PARIS"")
  ) %>% 
  select(departure_station, arrival_station, total_num_trips, month) 

# check that it's in alluvial format - should return true
is_alluvia_form(paris_2017_trips, axes = 1:2, silent = TRUE)  

# Plot --------------------------------------------------------------------

# create alluvial plot
paris_2017_trips %>%
  ggplot(aes(y = total_num_trips, axis1 = departure_station, axis2 = arrival_station)) +
  geom_alluvium(aes(fill = departure_station)) +
  guides(fill = FALSE) +
  geom_label(stat = ""stratum"",
             label.strata = TRUE,
             size = 2) +
  scale_x_discrete(limits = c(""Departure"", ""Arrival""),
                   expand = c(0.05, 0.05)) +
  scale_fill_viridis_d() +
  theme_minimal() +
  theme(legend.position = ""none"") +
  labs(
    title = ""Train trips departing from Paris stations in July 2017"",
    y = ""Total Number of Trips"",
    subtitle = ""Source: SNCF"",
    caption = ""#tidytuesday by @benmoretti""
  ) 


# Output ------------------------------------------------------------------


#save png
ggsave(""2019-02-26/paris_july_2017_trains.png"", units = ""mm"", width=297, height=210)
","2019"
"345",1103,"https://github.com/benmoretti/tidytuesdays/blob/master/2019-02-19/phds_by_field.R","benmoretti","tidytuesdays","2019-02-19/phds_by_field.R","#' phds_by_field.R
#' 
#' R script for 19 February 2019 #TidyTuesday 
#'


# Libraries ---------------------------------------------------------------

library(tidyverse)
library(collapsibleTree)
library(skimr)
library(magrittr)
library(tidyquant)


# Configuration -----------------------------------------------------------

# define source url
source_url <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv""


# Gather ------------------------------------------------------------------

# read + tidy
phd_by_field_tbl <- read_csv(source_url) %>%
  replace_na(list(n_phds = 0)) %>%
  mutate_if(is.character, factor)
  

# Visualise ---------------------------------------------------------------

# collapsible tree for top two levels in hierarchy
phd_by_field_tbl %>%
  group_by(broad_field, major_field) %>% 
  summarise(
    n_major_field_phds = sum(n_phds)
  ) %>%
  ungroup() %>%
  collapsibleTreeSummary(
    hierarchy = c(""broad_field"", ""major_field""),
    attribute = ""n_major_field_phds"",
    nodeSize = ""n_major_field_phds"",
    fillFun = colorspace::rainbow_hcl,
    collapsed = FALSE
  )

# heat map Heatmap for number of PhDs in Agricultural sciences and natural resources
phd_by_field_tbl %>%
  mutate(
    date = lubridate::make_date(year=year)
  ) %>%
  filter(major_field == ""Agricultural sciences and natural resources"") %>%
  arrange(field) %>%
  ggplot(aes(date, field)) +
  geom_raster(aes(fill=n_phds)) +
  theme_tq() +
  scale_fill_gradient(low = palette_light()[[1]], high = palette_light()[[5]]) +
  labs(
    title = ""#TidyTuesday, 19 February 2019"",
    subtitle = ""Heatmap for number of PhDs in Agricultural sciences and natural resources"",
    x = ""Year"",
    y = """",
    caption = ""By @benmoretti""
  )

# Annual relative difference plot of PhDs in Agricultural sciences and natural resources
phd_by_field_tbl %>%
  group_by(broad_field, major_field, field) %>%
  arrange(year) %>%
  mutate(
    previous_year_n_phds = lag(n_phds),
    annual_change_pc = (n_phds - previous_year_n_phds) / previous_year_n_phds
  ) %>%
  select(-previous_year_n_phds) %>%
  filter(! is.na(annual_change_pc)) %>%
  mutate(
    date = lubridate::make_date(year=year)
  ) %>%
  filter(major_field == ""Agricultural sciences and natural resources"") %>%
  ggplot(aes(date, annual_change_pc)) +
  geom_point() +
  geom_smooth(colour=palette_light()[[6]]) +
  geom_segment(aes(yend=annual_change_pc, xend=date)) +
  scale_y_continuous(labels=scales::percent) +
  theme_tq() +
  facet_wrap(vars(field), scales=""free_y"") +  
  labs(
    title = ""#TidyTuesday, 19 February 2019"",
    subtitle = ""Annual relative difference plot of PhDs in Agricultural sciences and natural resources"",
    x = ""Year"",
    y = ""Change"",
    caption = ""By @benmoretti""
  )

","2019"
"346",1117,"https://github.com/cpdavis/tidytuesday/tree/master/data/2019/2019-06-25","cpdavis","tidytuesday","data/2019/2019-06-25/tt_062519.Rmd","---
title: ""Tidy Tuesday: UFO Encounters""
author: ""Charles Davis""
date: ""6/25/2019""
output:
  html_document:
    toc: yes
  html_notebook:
    code_folding: hide
    df_print: paged
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)

setwd(""~/Desktop/tidytuesday/data/2019/2019-06-25"")
ufo = read.csv(""ufo_sightings.csv"")

```

OK. What can we ask with this dataset?

- Do the number of UFO sighting vary by country? Does the length of UFO encounter vary by country?

```{r country}

ufo %>% 
  group_by(country) %>%
  summarise(count=n())

ufo %>%
  group_by(country) %>%
  summarise(avg_length=mean(encounter_length, na.rm=TRUE))

```

So it's pretty clear that the US is the main UFO hotspot. Let's focus our attention there. Are there particularly good UFO-viewing spots in the US? 

```{r state n}

# first we need to load in some map data

state_map <- map_data(""state"")
stateInfo=cbind.data.frame(abb=tolower(state.abb), name=tolower(state.name))
state <- inner_join(state_map, stateInfo, by=c(""region""=""name""))

# let's check the counts of UFO sightings by state

state_n <- ufo %>%
  dplyr::filter(country == ""us"") %>%
  group_by(state) %>%
  summarise(count=n())

state_n <- inner_join(state, state_n, by=c(""abb""=""state""))
state_n$abb <- as.factor(state_n$abb)

ggplot(data=state, mapping=aes(x=long, y=lat, group=group)) + 
  geom_polygon(data=state_n, aes(fill=count), color=""white"") +
  theme_void() +
  labs(fill=""number of encounters"") +
  scale_fill_gradientn(colors=RColorBrewer::brewer.pal(name=""Greens"", n=48))

```

OK. That's kind of boring. Where more people live, more people see aliens. But maybe there are places where UFO encounters are particularly long. 

```{r state len}

ufo %>% 
  dplyr::filter(country == ""us"") %>% 
  ggplot(aes(x=as.factor(encounter_length))) + 
  geom_histogram(stat=""count"") +
  theme(axis.title.x = element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())

# since the data are clearly skewed, we'll do the rest of the analysis on log-transformed encounter length

state_len <- ufo %>%
  dplyr::filter(country == ""us"") %>%
  group_by(state) %>%
  summarise(avg_length=mean(log(encounter_length), na.rm=TRUE))

state_len <- inner_join(state, state_len, by=c(""abb""=""state""))
state_len$abb <- as.factor(state_len$abb)

length_plot <- ggplot(data=state, mapping=aes(x=long, y=lat, group=group)) + 
  geom_polygon(data=state_len, aes(fill=avg_length), color=""white"") +
  theme_void() +
  labs(fill=""encounter length in log(min)"") +
  scale_fill_gradientn(colors=RColorBrewer::brewer.pal(name=""Greens"", n=48)) +
  ggtitle(""Length of UFO encounters across the United States"") +
  theme(plot.title = element_text(size=32, face=""bold""), legend.position = ""bottom"") 
length_plot

alien_plot <- ggdraw() + 
  draw_plot(length_plot) +
  draw_image(""~/Desktop/tidytuesday/data/2019/2019-06-25/alien.jpg"", scale=0.3, width=1.8, height=0.5)
alien_plot
```

Aha! As we might expect, New Mexico and Arizona are right up there. The clear skies of Maine also seem conducive to UFO sightings. ","2019"
"347",1118,"https://github.com/baleb/Visualization/blob/master/tidytues2.7.2019.R","baleb","Visualization","tidytues2.7.2019.R","#loading the tidyverse package
library(tidyverse) 
#Importing the dataset
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

#Variation of book revenues by Year 
ggplot(media_franchises, aes(x = year_created, y = revenue)) +
  geom_line(stat = ""identity"", color = ""red"") +
geom_point() + 
  labs(title = ""How revenues have varied over the years"", y = ""Revenue($)"", x = ""Year"", caption = ""Source: Wikipedia"") 


#How costs have varied for each of the revenue categories
my_plot <- ggplot(data = media_franchises) +
  geom_smooth(mapping = aes(x = year_created, y = revenue, color = revenue_category)) +
  labs(title = ""How revenues have varied over the years by category"", y = ""Revenue($)"", x = ""Year"", caption = ""Source: Wikipedia"") 
  
# Out putting the graph with limits on the x and y axes
my_plot + coord_cartesian(xlim =c(1924, 2013), ylim = c(0, 85))

#+
 # labs(title = ""How revenues have varied over the years"", y = ""Revenue ($)"", x = ""Year"", caption = ""Source: Drowning Project Data"") 
  









","2019"
"348",1119,"https://github.com/Nicey80/tidytuesday/blob/master/2019-07-02/19-07-02.R","Nicey80","tidytuesday","2019-07-02/19-07-02.R","media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

library(tidyverse)

m2 <- media_franchises %>% 
    group_by(original_media, year_created) %>%
    summarise(revenue=sum(revenue)) %>% 
    as_tibble()

m2 %>% 
    filter(!original_media %in% c(""Cartoon"",""Cartoon character"",""Comic strip"", ""Digital pet"",""Greeting card"", ""Musical theatre"",""Visual novel"")) %>% 
    ggplot(aes(year_created,revenue))+
    geom_area(aes(group=original_media, fill=original_media))+
    facet_grid(original_media~.)+
    theme(strip.background = element_blank(), strip.text.y = element_blank())+#legend.position = 'none')+
    labs(title = ""The rise of visual media at the expense of imagination (book reading)"",
         subtitle = ""Animation/Visual stimuli have overtaken the need to visualise content from books"",
         x="""")

","2019"
"349",1120,"https://github.com/Nicey80/tidytuesday/blob/master/2019-06-25/2019-06-25.R","Nicey80","tidytuesday","2019-06-25/2019-06-25.R","library(tidyverse)
library(lubridate)
library(gganimate)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

ufo_sightings2 <- ufo_sightings %>% 
    mutate(date=as_date(date_time, format='%m/%d/%Y %H:%M', tz='utc')) %>% 
    mutate(YR=year(date))

library(maps)

world_map <- map_data(""world"")

p <- ggplot() + 
    geom_polygon(data=world_map,aes(x=long, y=lat,group=group), col=""gray50"") +
    theme_dark()+
    theme(axis.title = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.line = element_blank(),
          panel.grid = element_blank(),
          panel.background = element_rect(fill=""gray10""))+
    geom_point(data = ufo_sightings2, aes(longitude,latitude, group=YR), colour=""green"", size=0.1)+
    labs(title = 'UFO Sightings by Year: {frame_time}') +
    transition_time(YR) +
    ease_aes('linear')+
    shadow_mark(alpha=alpha/2)
p

p2 <- animate(p, end_pause = 10, duration=15, nframes=109)
p2

anim_save('UFO.gif')
","2019"
"350",1121,"https://github.com/cginer/tidytuesday/blob/master/20190618_birds.Rmd","cginer","tidytuesday","20190618_birds.Rmd","---
title: ""Tidy Tuesday 2019 week 25""
author: ""Carla Giner-Delgado""
date: ""18 June 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

This week's `#TidyTuesday` data is about BIRDS! And not only birds, but birds from North America. I happen to love birds and I've been living in the US East Coast for few months now. During this time I've learned about new species that have become my new bird friends in this part of the world. (With the help of patient birder friends from Brown University Birding Club, [Audubon Society of Rhode Island](https://twitter.com/RIAudubon) and Brooklyn Bird Club.) I have also found some old bird friends from Europe too, such as pigeons, house sparrows and starlings.

The data was cleaned by [Sharleen](https://twitter.com/_sharleen_w) from [Bird Studies Canada](https://twitter.com/BirdsCanada). It records the number of birds counted in a popular Christmas bird watching event held in Hamilton area of Ontario since 1921.

For my `#TidyTuesday` contribution I've added some personal annotations to the dataset. I have classified the birds in ""Old friends"" (birds I knewn from Europe), ""New friends"" (bird species that I now can identify fairly easily and know their common names) and ""Others"" (birds that I haven't seen or that I still can't identify easily or haven't learned their names).

```{r packages}
# To read the data set
library(readr)

# Data manipulation
library(dplyr)

# Visualization
library(ggplot2)
library(ggbeeswarm) # geom_quasirandom
```

## Get the data

```{r getdata}
bird_counts <- read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"",
    col_types = cols(col_integer(), col_character(), col_character(),
                     col_double(), col_double(), col_double())
    )
```

```{r explore, eval=FALSE}
# Quick look at the dataset and summaries by year
head(bird_counts)

bird_counts %>%
    group_by(year) %>%
    summarize(n = n(),
              num_species_listed = length(unique(species)),
              num_species_counted = length(unique(species[how_many_counted > 0])),
              total_counted = sum(how_many_counted),
              mean_counted_total = mean(how_many_counted),
              mean_counted = mean(how_many_counted[how_many_counted > 0]))

```

# Add my personal annotations

```{r annotations}
old_friends <- c(""Herring Gull"", ""European Starling"", ""House Sparrow"", ""Mallard"", ""Barn Swallow"", ""Rock Pigeon"")
new_friends <- c(""American Robin"", ""Blue Jay"", ""Downy Woodpecker"", ""Black-capped Chickadee"", ""Canada Goose"", ""Eastern Towhee"", ""House Finch"", ""Wood Duck"", ""Red-tailed Hawk"", ""Red-winged Blackbird"", ""Wild Turkey"", ""Spotted Sandpiper"", ""Northern Cardinal"", ""Double-crested Cormorant"", ""Northern Mockingbird"", ""American Goldfinch"", ""Mourning Dove"", ""American Crow"", ""Ring-billed Gull"")

bird_counts <- bird_counts %>%
    mutate(Class = factor(
        case_when(species %in% new_friends ~ ""New friends"",
                  species %in% old_friends ~ ""Old friends"",
                  TRUE ~ ""Others""),
        levels = c(""Others"", ""New friends"", ""Old friends"")))

```


```{r plot_annotations, fig.height=3}
ggplot(bird_counts %>% filter(year %in% ""1921""), aes("""", fill = Class)) +
    geom_bar() +
    coord_flip() +
    scale_fill_viridis_d(begin = 0.1, end = 0.8, direction =  -1) +
    labs(x = NULL, y = ""Number of species"", title = ""Personal classification of birds in the data"",
         subtitle = ""There are still many birds to learn about!"") +
    scale_x_discrete(expand = c(0, 0), breaks = NULL) +
    scale_y_continuous(expand = c(0, 0 ))
```

I still don't know most of the birds spotted in Hamilton at Christmas!

## Summarize data per bird

Are birds I know common? (must be)

```{r summary_birds}
summary_birds <- bird_counts %>%
    group_by(species, species_latin, Class) %>%
    summarize(
        mean_counted_by_hour = mean(how_many_counted_by_hour, na.rm = TRUE),
        variance_counted_by_hour = var(how_many_counted_by_hour, na.rm = TRUE),
        years_spotted = sum(how_many_counted > 0)) %>%
    mutate(
        Regularity = case_when(years_spotted < 5 ~ ""Rare"",
                               years_spotted < 94/2 ~ ""Less than half of the years"",
                               years_spotted < 95-5 ~ ""More than half of the years"",
                               years_spotted > 94-5 ~ ""Very common"")
    )

```

```{r mean_count}
ggplot(summary_birds %>% filter(mean_counted_by_hour > 0), aes(Class, mean_counted_by_hour)) +
    geom_quasirandom(aes(colour = Class), show.legend = FALSE, na.rm = TRUE) +
    geom_text(data = summary_birds %>% filter(species %in% c(""Wood Duck"", ""Spotted Sandpiper"", ""Barn Swallow"")),
              aes(label = species), size = 2.5, nudge_x = 0.28) +
    geom_text(data = summary_birds %>% filter(species %in% c(""Eastern Towhee"")),
              aes(label = species), size = 2.5, nudge_x = -0.33) +
    scale_y_log10(breaks = c(0.0001, 0.01, 1, 100),
                  labels = c(""0.0001"", ""0.01"", ""1"", ""100"")) +
    annotation_logticks(sides = ""l"") +
    scale_colour_viridis_d(begin = 0.1, end = 0.8, direction =  -1) +
    labs(x = NULL, y = ""Mean bird count per hour"", title = ""Bird abundance"",
         subtitle = ""Most birds I know are fairly common"") +
    theme_minimal()
```


## Look at abundance temporal trends (of friends)

```{r}
# Impute number of hours in years that have NAs (several years between 1921 and 1950)
# I'm going to use Downy Woodpecker as reference, because it's spotter every year at a similar rate
downys_per_hour_1929_1950 <- bird_counts %>%
    filter(species %in% ""Downy Woodpecker"" & year <= 1950) %>%
    pull(how_many_counted_by_hour) %>%
    mean(na.rm = TRUE)

bird_counts_imputed <- bird_counts %>%
    group_by(year) %>%
    # Use Downy woodpecker to estimate total_hours
    mutate(total_hours = if_else(
        is.na(total_hours),
        round(how_many_counted[species %in% ""Downy Woodpecker""] / downys_per_hour_1929_1950),
        total_hours)) %>%
    # Fill counts/h those years
    mutate(how_many_counted_by_hour = if_else(
        is.na(how_many_counted_by_hour),
        how_many_counted/total_hours,
        how_many_counted_by_hour))

# Order by mean abundance
bird_order <- summary_birds %>%
    arrange(mean_counted_by_hour) %>%
    pull(species)
bird_counts_imputed <- bird_counts_imputed %>%
    mutate(species = factor(species, levels = bird_order))
```


```{r}
ggplot(bird_counts_imputed %>%
           filter(Class %in% c(""New friends"", ""Old friends"") & how_many_counted_by_hour),
       aes(year, species, size = how_many_counted_by_hour, colour = Class)) +
    geom_point(show.legend = c(colour = FALSE)) +
    scale_size_area(max_size = 7, breaks = c(1, 10, 100, 400), name = ""Birds per hour"") +
    scale_colour_viridis_d(begin = 0.1, end = 0.8, direction =  -1, drop = FALSE) +
    scale_x_continuous(expand = c(0.04, 0)) +
    facet_grid(rows = vars(Class), scales = ""free"", space =""free"") +
    theme_minimal() +
    labs(title = ""Temporal trends"",
         subtitle = ""Downy Woodpecker sigthings are used to impute\nthe total counting hours for some years before 1950"")
```

","2019"
"351",1123,"https://github.com/florencevdubois/MyTidyTuesdays","florencevdubois","MyTidyTuesdays","march26-2019.R","## load packages ##
library(ggplot2)
library(tidyverse)
library(rgdal)
library(rmapshaper)
library(sp)
library(leaflet)

# load pet names data
seattle_pets <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")

# load seattle zip code shapefiles
# from http://data-seattlecitygis.opendata.arcgis.com/datasets/83fc2e72903343aabff6de8cb445b81c_2
seattle_zip <- readOGR(dsn = ""~/your-path"",
              layer = ""Zip_Codes"")

# plot shapefile
seattle_plot <- ms_simplify(input = seattle_zip, 
                         keep = 0.05, # keep only 5% of the original points
                         keep_shapes = TRUE) # make sure to keep all polygons

plot(seattle_plot)

# transform to a data frame
seattle_df <- broom::tidy(x = seattle_plot,
                     region = ""ZIPCODE"") # identifies lat and long of each zip code area
head(seattle_df)

# merge this new data frame with everything else in the shapefile 
seattle_df <- right_join(seattle_df, seattle_plot@data,
                    by = c(""id"" = ""ZIPCODE"")) # by id and zipcode (same variable)

# plot the map 
ggplot(seattle_df, aes(x = long,
                  y = lat,
                  group = group)) +
  geom_polygon() +
  coord_fixed() + 
  theme_void() 

# it is the whole Seattle area -- I want to keep only Seattle
class(seattle_df$ZIP)
seattle_df$ZIP <- as.numeric(levels(seattle_df$ZIP))[seattle_df$ZIP]

zip_list <- c(98101, 98102, 98103, 98104, 98105, 98106, 98107, 98108, 
              98109, 98112, 98115, 98116, 98117, 98118, 98119, 98121, 
              98122, 98125, 98126, 98133, 98134, 98136, 98144, 98146, 
              98154, 98164, 98174, 98177, 98178, 98195, 98199) # seattle zip codes

seattle_df <- seattle_df %>%
  filter(ZIP %in% zip_list)

# sum pet species by zip code, and make dog ratio
seattle_pets <- seattle_pets %>% 
  mutate(dogs = ifelse(species == ""Dog"", 1, 0), 
         cats = ifelse(species == ""Cat"", 1, 0)) %>% 
  group_by(zip_code) %>% 
  mutate(sum_dogs = sum(dogs),
         sum_cats = sum(cats),
         ratio_dog = sum_dogs/sum_cats) %>% 
  distinct(zip_code, .keep_all = TRUE)

# merge geo data with this new pet data 
class(seattle_pets$zip_code)
seattle_pets$zip_code <- as.numeric(seattle_pets$zip_code)

seattle_df <- left_join(seattle_df, seattle_pets,
                   c(""ZIP"" = ""zip_code""))
head(data_frame(seattle_df))

# plot Seattle with dog ratio 
ggplot(seattle_df,
       aes(x = long,
           y = lat,
           group = group,
           fill = ratio_dog)) +
  geom_polygon() +
  coord_fixed() +
  theme_void() +
  scale_fill_viridis_c(breaks=c(1,2,3),
                       labels=c(""1x"", ""2x"", ""3x"")) + 
  labs(x = """",
       y = """",
       title = ""Proportion of cats and dogs licensed in Seattle, by zip code"", 
       subtitle = ""Overall more licensed dogs; licensed cats more frequent in the city center"") +
  guides(fill = guide_colourbar(ticks = FALSE,
                                title=""Yellow means more dogs"")) 

ggsave(filename = ""pets_seattle.png"", plot = last_plot(), width = 7, height = 6.5)
","2019"
"352",1142,"https://github.com/LaineyJ/TidyTuesdays/tree/master/2019-06-11","LaineyJ","TidyTuesdays","2019-06-11/Meteorite Data Cleaning.Rmd","---
title: ""Meteorite Impacts""
output: html_notebook
---

```{r setup, include = FALSE}
library(""tidyverse"")
library(""mgcv"")
library(""maps"")
library(""extrafont"")
library(""ggrepel"")
library(""dummies"")
library(""corrplot"")
library(""grid"")
library(""gridExtra"")

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  filter(!is.na(lat))
```

## Filter to US and Iowa meteorites
```{r}
filter_meteorites <- function(boundaries) {
  met_filter <- in.out(as.matrix(boundaries[, c(""lat"",""long"")]),
                      as.matrix(meteorites[, c(""lat"", ""long"")]))
  met_filtered <- meteorites[met_filter, ]
}

us <- map_data(""state"")
iowa <- map_data(""state"", ""iowa"")

meteorites_us <- filter_meteorites(us)
meteorites_ia <- filter_meteorites(iowa)
```
***

## Plot Iowa meteorites
```{r}
plt_iowa <- meteorites_ia %>%
  ggplot(aes(x = long,
             y = lat,
             size = mass,
             color = fall)) + 
  geom_point(na.rm = TRUE) +
  borders(""state"", ""iowa"")

plt_iowa <- plt_iowa +
  scale_color_brewer(name = ""Falls vs. Finds"", palette = ""Dark2"") +
  scale_size_continuous(name = ""Mass (g)"",
                        labels = scales::comma) +
  geom_text_repel(aes(label = paste(name, year, sep = "", "")),
                  size = 3.5,
                  color = ""black"",
                  point.padding = 0.5,
                  min.segment.length = 5,
                  family = ""Segoe UI"") +
  labs(title = ""Meteorite Impacts in Iowa by Mass and Fall Type"",
       subtitle = ""Meteorite \""falls\"" were identified shortly after their fall;
Meteorite \""finds\"" were identified at a later date
"") +
  theme(text = element_text(family = ""Segoe UI""),
        plot.background = element_rect(fill = ""whitesmoke""),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(family = ""Franklin Gothic Medium""),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        legend.background = element_rect(fill = ""whitesmoke""))
plt_iowa
```
***

## Find proportion of falls vs. finds
```{r}
met_dummies <- function(df) {
  fall_dummies <- dummy(df$fall)
  df$fall_bin <- fall_dummies[, 1]
  df
}

meteorites_us <- suppressWarnings(met_dummies(meteorites_us))
meteorites_ia <- suppressWarnings(met_dummies(meteorites_ia))

us_mean <- mean(meteorites_us$fall_bin)
ia_mean <- mean(meteorites_ia$fall_bin)
```
Overall proportion of falls in the US is `r us_mean`, vs. `r ia_mean` in Iowa  

***

## Correlation of falls vs. mass
```{r}
cor_df <- meteorites_us[, c(5, 7, 11)]
cor_df <- rename(cor_df,
                 Year = year,
                 Mass = mass,
                 Fell = fall_bin)

cor_mat <- cor(cor_df, use = ""complete.obs"")
return_corrplot <- function() {
  correls <- corrplot(cor_mat,
                      method = ""color"",
                      type = ""upper"",
                      bg = ""whitesmoke"",
                      diag = FALSE,
                      outline = TRUE,
                      addCoef.col = ""black"",
                      tl.col = ""black"",
                      cl.pos = ""n"")
}
```
***

## Returning Graphs
```{r}
plt_iowa

return_corrplot()
```

","2019"
"353",1143,"https://github.com/LaineyJ/TidyTuesdays/tree/master/2019-06-11","LaineyJ","TidyTuesdays","2019-06-11/Meteorite Falls Script.R","library(""tidyverse"")
library(""mgcv"")
library(""maps"")
library(""extrafont"")
library(""ggrepel"")
library(""dummies"")
library(""corrplot"")
library(""grid"")
library(""gridExtra"")


# Read and Format Data ----------------------------------------------------

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  filter(!is.na(lat))

filter_meteorites <- function(boundaries) {
  met_filter <- in.out(as.matrix(boundaries[, c(""lat"",""long"")]),
                      as.matrix(meteorites[, c(""lat"", ""long"")]))
  met_filtered <- meteorites[met_filter, ]
}

us <- map_data(""state"")
iowa <- map_data(""state"", ""iowa"")

meteorites_us <- filter_meteorites(us)
meteorites_ia <- filter_meteorites(iowa)

plt_iowa <- meteorites_ia %>%
  ggplot(aes(x = long,
             y = lat,
             size = mass,
             color = fall)) + 
  geom_point(na.rm = TRUE) +
  borders(""state"", ""iowa"")


# Plot Iowa ---------------------------------------------------------------

plt_iowa <- plt_iowa +
  scale_color_brewer(name = ""Falls vs. Finds"", palette = ""Dark2"") +
  scale_size_continuous(name = ""Mass (g)"",
                        labels = scales::comma) +
  geom_text_repel(aes(label = paste(name, year, sep = "", "")),
                  size = 3.5,
                  color = ""black"",
                  point.padding = 0.5,
                  min.segment.length = 5,
                  family = ""Segoe UI"") +
  labs(title = ""Meteorite Impacts in Iowa by Mass and Fall Type"",
       subtitle = ""Meteorite \""falls\"" were identified shortly after their fall;
Meteorite \""finds\"" were identified at a later date
"") +
  theme(text = element_text(family = ""Segoe UI""),
        plot.background = element_rect(fill = ""whitesmoke""),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(family = ""Franklin Gothic Medium""),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        legend.background = element_rect(fill = ""whitesmoke""))

met_dummies <- function(df) {
  fall_dummies <- dummy(df$fall)
  df$fall_bin <- fall_dummies[, 1]
  df
}


# Correlations ------------------------------------------------------------

meteorites_us <- suppressWarnings(met_dummies(meteorites_us))
meteorites_ia <- suppressWarnings(met_dummies(meteorites_ia))

us_mean <- mean(meteorites_us$fall_bin)
ia_mean <- mean(meteorites_ia$fall_bin)

cor_df <- meteorites_us[, c(5, 7, 11)]
cor_df <- rename(cor_df,
                 Year = year,
                 Mass = mass,
                 Fell = fall_bin)

cor_mat <- cor(cor_df, use = ""complete.obs"")
return_corrplot <- function() {
  correls <- corrplot(cor_mat,
                      method = ""color"",
                      type = ""upper"",
                      bg = ""whitesmoke"",
                      diag = FALSE,
                      outline = TRUE,
                      addCoef.col = ""black"",
                      tl.col = ""black"",
                      cl.pos = ""n"")
}

plot(plt_iowa)

return_corrplot()

ggsave(""IowaMeteorites.jpeg"", plt_iowa, width = 11.5, height = 8, units = ""in"", dpi = 320)
","2019"
"354",1144,"https://github.com/s01ren/TidyTuesdaySubmissions/tree/master/20190625","s01ren","TidyTuesdaySubmissions","20190625/TT_20190625.R","# ------------------------------------------------------------------------
#
# TIDY TUESDAY 2019-06-25
#
# ------------------------------------------------------------------------


# load packages -----------------------------------------------------------
library(sp)
library(tidyverse)
library(viridis)


# mapping table -----------------------------------------------------------
mapping_city_district <- tribble(
  ~city, ~district,
  'aachen', 'Stdteregion Aachen',
  'ansbach', 'Ansbach (Kreisfreie Stadt)',
  'babenhausen', 'Darmstadt',
  'bad pyrmont', 'Hameln-Pyrmont',
  'bamberg', 'Bamberg (Kreisfreie Stadt)',
  'baumholder', 'Birkenfeld',
  'bensheim', 'Darmstadt',
  'berlin', 'Berlin',
  'bierenbachtal', 'Oberbergischer Kreis',
  'biesenthal', 'Barnim',
  'bitburg', 'Eifelkreis Bitburg-Prm',
  'bocholt', 'Borken',
  'bochum', 'Bochum',
  'bremen', 'Bremen',
  'buchholz', 'Heidekreis',
  'chemnitz', 'Chemnitz',
  'cologne', 'Kln',
  'darmstadt', 'Darmstadt',
  'dresden', 'Dresden',
  'elbingen', 'Westerwaldkreis',
  'emlichheim', 'Grafschaft Bentheim',
  'emmelshausen', 'Rhein-Hunsrck-Kreis',
  'erfurt', 'Erfurt',
  'erlangen', 'Erlangen',
  'frankfurt', 'Frankfurt (Oder)',
  'frankfurt am main', 'Frankfurt am Main',
  'freiburg', 'Freiburg im Breisgau',
  'fulda', 'Fulda',
  'gelsenkirchen', 'Gelsenkirchen',
  'grafenhausen', 'Waldshut',
  'hamburg', 'Hamburg',
  'hanau', 'Main-Kinzig-Kreis',
  'hannover', 'Region Hannover',
  'haus', 'Freyung-Grafenau',
  'heidelberg', 'Heidelberg',
  'heilbronn', 'Heilbronn',
  'kaiserlautern', 'Kaiserslautern (Kreisfreie Stadt)',
  'kassel', 'Kassel',
  'kelsterbach', 'Gro-Gerau',
  'kirchzell', 'Miltenberg',
  'lampertheim', 'Bergstrae',
  'langenleiten', 'Rhn-Grabfeld',
  'magdeburg', 'Magdeburg',
  'mainz', 'Mainz',
  'mannheim', 'Mannheim',
  'maugenhard', 'Lrrach',
  'miesau', 'Kaiserslautern',
  'mittenwald', 'Garmisch-Partenkirchen',
  'muenster', 'Mnster',
  'munich', 'Mnchen (Kreisfreie Stadt)',
  'neckarsulm', 'Heilbronn',
  'neumarkt', 'Neumarkt in der Oberpfalz',
  'neuseddin', 'Potsdam-Mittelmark',
  'neuruppin', 'Ostprignitz-Ruppin',
  'neuss', 'Bergstrae',
  'nurenburg', 'Nrnberg',
  'obernheim', 'Zollernalbkreis',
  'osnabruck', 'Osnabrck (Kreisfreie Stadt)',
  'ottersberg', 'Verden',
  'ramstein', 'Kaiserslautern',
  'ransbach-baumbach', 'Westerwaldkreis',
  'regensburg', 'Regensburg',
  'schafhausen', 'Alzey-Worms',
  'schwalmtal', 'Vogelsbergkreis',
  'schweinfurt', 'Schweinfurt',
  'schwetzingen', 'Rhein-Neckar-Kreis',
  'sembach', 'Kaiserslautern',
  'senftenberg', 'Oberspreewald-Lausitz',
  'siegen', 'Siegen-Wittgenstein',
  'staufen', 'Breisgau-Hochschwarzwald',
  'stuttgart', 'Stuttgart',
  'trier', 'Trier',
  'waldorf', 'Ahrweiler',
  'weiden', 'Weiden in der Oberpfalz',
  'weissenburg', 'Weienburg-Gunzenhausen',
  'werder', 'Potsdam-Mittelmark',
  'wildflecken', 'Bad Kissingen',
  'zehdenick', 'Oberhavel',
  'zirndorf', 'Frth (Kreisfreie Stadt)'
)

# import map of German Laender --------------------------------------------
shape_de_level_1 <- readRDS(url(""https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_DEU_1_sp.rds"", encoding = ""utf-8""))
tmp1 <- data.frame(id = rownames(shape_de_level_1@data), shape_de_level_1@data)
tmp1$id <- as.character(tmp1$id)
tmp2 <- fortify(shape_de_level_1)
LAENDER <- 
  tmp1 %>% 
  left_join(tmp2, by = ""id"")
rm(tmp1, tmp2)


# import map of German districts ------------------------------------------
shape_de_level_2 <- readRDS(url(""https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_DEU_2_sp.rds"", encoding = ""utf-8""))
tmp1 <- data.frame(id = rownames(shape_de_level_2@data), shape_de_level_2@data)
tmp1$id <- as.character(tmp1$id)
tmp2 <- fortify(shape_de_level_2)
DISTRICTS <- 
  tmp1 %>% 
  left_join(tmp2, by = ""id"") %>% 
  mutate(
    NAME_2 = str_replace(NAME_2, ""M?nchen"", ""Mnchen"") %>% 
      str_replace(""F?rth"", ""Frth"") %>% 
      str_replace(""Osnabr?ck"", ""Osnabrck"")
  )
rm(tmp1, tmp2)


# import UFO sightings ----------------------------------------------------
ufo_raw <- readr::read_csv(
  file = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv""
)

UFO_DISTR <- ufo_raw %>% 
  filter(country == ""de"") %>% 
  #filter(encounter_length <= 86400/2) %>% 
  mutate(encounter_length = case_when(encounter_length > 10000 ~ 10000, TRUE ~ encounter_length)) %>% 
  rowwise() %>% 
  mutate(city = trimws(str_split(city_area, ""\\("", n = 2)[[1]][1])) %>% 
  left_join(mapping_city_district, by = ""city"") %>% 
  select(district, encounter_length) %>% 
  ungroup() %>% 
  group_by(district) %>% 
  summarise(encounter_length = sum(encounter_length, na.rm = TRUE))
UFO_DISTR


# join plot data ----------------------------------------------------------
PLOT_DISTR_UFO <- DISTRICTS %>% 
  left_join(UFO_DISTR, by = c(""NAME_2"" = ""district"")) %>% 
  mutate(encounter_length = replace_na(encounter_length, 0))

# plot map ----------------------------------------------------------------
ggplot(data = PLOT_DISTR_UFO, aes(x = long, y = lat, group = group)) + 
  geom_polygon(aes(fill = encounter_length), col = ""white"") + 
  geom_polygon(data = LAENDER, aes(x = long, y = lat, group = group), col = ""black"", fill = NA) + 
  # STYLING -----------------------------------------------------------------
  theme_classic() + 
  theme(
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    axis.line = element_blank(),
    plot.title=element_text(size=14, face=""bold""),
    legend.position = ""bottom"",
    aspect.ratio = mapasp(shape_de_level_1)
  ) + 
  labs(
    title = ""UFO sightings in Germany by encounter length"",
    caption = ""TidyTuesday 2019-06-25""
  ) + 
  #scale_fill_gradient(low = ""#bdc3c7"", high = ""#3CD070"", name = ""Encounter length"")
  scale_fill_viridis(
    option = ""magma"", 
    direction = -1,
    name = ""Encounter length in seconds"",
    # here we use guide_colourbar because it is still a continuous scale
    guide = guide_colorbar(
      direction = ""horizontal"",
      barheight = unit(2, units = ""mm""),
      barwidth = unit(50, units = ""mm""),
      draw.ulim = F,
      title.position = 'top',
      # some shifting around
      title.hjust = 0.5,
      label.hjust = 0.5
    ))
ggsave(""./ufo_germany.png"")








","2019"
"355",1153,"https://github.com/KoningD/TidyTuesday/tree/master/2019_Week20","KoningD","TidyTuesday","2019_Week20/TidyTuesday_2019_Week20.R","#TidyTuesday 2019 - Week 19
#By: Dewi Koning
#Github: https://github.com/KoningD
#Twitter: https://twitter.com/DewiKoning

#load libraries 
library(tidyverse)
library(magrittr)
library(ggmap)
library(viridis)

#load data
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

#clean names 
colnames(coast_vs_waste) <- c(""Country"", ""Country_Code"", ""Year"", ""Mismanaged_Waste_Tonnes"", ""Coastal_Pop"", ""Total_Pop"")
colnames(mismanaged_vs_gdp) <- c(""Country"", ""Country_Code"", ""Year"", ""Mismanaged_Waste_Kg_Pp_Pd"", ""GDP"", ""Total_Pop"")
colnames(waste_vs_gdp) <- c(""Country"", ""Country_Code"", ""Year"", ""Per_Capita_Waste_Kg_Pp_Pd"", ""GDP"", ""Total_Pop"")

#get world map and join with dataset
world_map <- map_data(""world"")

#look at relationship between mismanaged waste and waste per capita

waste_vs_gdp_2010 <- waste_vs_gdp %>% filter(Year == 2010)
mismanaged_vs_gdp_2010 <- mismanaged_vs_gdp %>% filter(Year == 2010)

#make new dataset which combines the waste per capita and mismanagement per capita
generated_vs_mismanaged <- left_join(waste_vs_gdp, mismanaged_vs_gdp) %>% 
  filter(Year == 2010) %>% #there is only data for 2010, so filter out this year
  select(c(""Country"", ""Country_Code"", ""Mismanaged_Waste_Kg_Pp_Pd"",""Per_Capita_Waste_Kg_Pp_Pd"", ""GDP"")) %>% 
  filter(!is.na(Mismanaged_Waste_Kg_Pp_Pd) & !is.na(Per_Capita_Waste_Kg_Pp_Pd)) %>% 
  mutate(perc_mismanaged = (Mismanaged_Waste_Kg_Pp_Pd/Per_Capita_Waste_Kg_Pp_Pd)*100) %>%
  mutate(Country = ifelse(Country == ""United States"", ""USA"", Country)) %>% #both the US and the UK are coded differently, in order to be able to join, changed the name
  mutate(Country = ifelse(Country == ""United Kingdom"", ""UK"", Country)) %>% 
  right_join(world_map, by = c(""Country"" = ""region""))

#make a df with the 3 countries with the highest levels of mismanagement of plastic waste, in order to plot these as geom_label later
generated_vs_mismanaged_top_n <- generated_vs_mismanaged %>% 
  select(c(""Country"", ""perc_mismanaged"")) %>% 
  unique() %>% 
  filter(!is.na(perc_mismanaged)) %>% 
  top_n(3, perc_mismanaged) %>%
  left_join(world_map, by = c(""Country"" = ""region"")) %>% 
  group_by(Country) %>% 
  top_n(1, lat) %>% 
  mutate(label_text = paste0(Country, "": "", round(perc_mismanaged), ""%""))

#make a df with the 3 countries with the lowest levels of mismanagement of plastic waste, in order to plot these as geom_label later
generated_vs_mismanaged_bottom_n <- generated_vs_mismanaged %>% 
  select(c(""Country"", ""perc_mismanaged"")) %>% 
  unique() %>% 
  filter(!is.na(perc_mismanaged)) %>% 
  top_n(-3, perc_mismanaged) %>%
  left_join(world_map, by = c(""Country"" = ""region"")) %>% 
  group_by(Country) %>% 
  top_n(1, lat) %>% 
  mutate(label_text = paste0(Country, "": "", round(perc_mismanaged), ""%""))



#generate plot 
generated_vs_mismanaged %>%
  ggplot(aes(x=long, y = lat, group = group, fill = perc_mismanaged)) + 
  geom_polygon(color = ""lightyellow1"", size = 0.1) +
  scale_fill_viridis(option = ""E"") +
  theme(text = element_text(colour = ""darkblue"", family = ""mono""),
        axis.line=element_blank(),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        plot.title = element_text(size = 20),
        plot.background=element_rect(fill = ""lightyellow1""),
        panel.background = element_rect(fill = 'lightyellow1'),
        legend.background = element_rect(fill = ""lightyellow1""),
        legend.position = ""bottom""
  ) +
  labs(title = ""Plastic polution: how do countries handle the disposal of their plastic waste?"",
       subtitle = ~ atop(""The map shows the percentage of inadequately disposed plastic waste per country in the year 2010.                                                                                "",
                         ""The countries highlighted in light blue have the lowest percentage of mismanaged plastic waste, the countries highlighted in orange have the highest percentage of mismanagement.""),
       caption = ""By Dewi Koning for TidyTuesday - Week 20 2019 - Data: Our World in Data"", 
       fill = ""Percentage Mismanaged Plastic Waste"") +
  geom_label(data = generated_vs_mismanaged_bottom_n, aes(x=long, y = lat, label = label_text, group = group), fill = ""lightblue"", fontface = ""bold"", nudge_x = 12) + 
  geom_label(data = generated_vs_mismanaged_top_n, aes(x=long, y = lat, label = label_text, group = group), fill = ""orange"", fontface = ""bold"", nudge_y = 2)


ggsave(""./2019_Week20/Mismanaged_Plastic_Waste.png"")
","2019"
"356",1189,"https://github.com/carleshf/tidytuesday","carleshf","tidytuesday","2019-04-23/2019-04-23.Rmd","---
title: ""TidyTuesday / Anime Data (2019-04-23)""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(ggthemr)
library(cowplot)
```

# Download data

```{r, message=FALSE, warning=FALSE}
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")
```

# Create new variables and filter data-set

```{r}
tidy_anime <- tidy_anime %>% 
  mutate(start_date_lub = ymd(start_date)) %>% 
  mutate(year = floor_date(start_date_lub, unit = ""year"")) %>% 
  mutate(decade = year(floor_date(start_date_lub, unit = years(10)))) %>% 
  mutate(decade_fac = as.factor(decade)) %>% 
  filter(!is.na(decade), !is.na(score))
```

# Create plots

```{r, fig.width=10}
ggthemr(""flat dark"")
p1 <- ggplot(tidy_anime, aes(x = genre, y = decade_fac, fill = score)) +
  geom_tile() +
  scale_fill_distiller(palette = ""Spectral"", limits = c(0, 10), name = ""Score"") +
  theme(
    legend.position = ""none"",
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
  ) +
  xlab(""Genre"") + ylab(""Decade"") +
  ggtitle(""Score by genre and decade"")
p2 <- ggplot(tidy_anime, aes(x = source, y = decade_fac, fill = score)) +
  geom_tile() +
  scale_fill_distiller(palette = ""Spectral"", limits = c(0, 10)) +
  theme(
    legend.position = ""none"",
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  xlab(""Source"") + ylab("""") +
  ggtitle(""Score by source and decade"")

pg <- plot_grid(
  plot_grid(p1, p2, ncol = 2, rel_widths = c(0.66, 0.33)),
  plot_grid(get_legend(p1 + theme(legend.position = ""bottom"")), 
            ggdraw() + draw_label(""Source: MyAnimeList""),
            ncol = 2),
  ncol = 1, rel_heights = c(0.9, 0.1)
)
pg

ggsave(pg, file = ""anime_score_by_genre_source_decade.png"")
```","2019"
"357",1190,"https://github.com/carleshf/tidytuesday","carleshf","tidytuesday","2019-06-11/2019-06-11.Rmd","---
title: ""TidyTuesday / Meteorite Impacts (2019-06-11)""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(imager)
library(ggthemes)
```

# Download data

```{r, message=FALSE, warning=FALSE}
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")
```

```{r}
meteorites <- meteorites %>% mutate(log_mass = log(mass + 1))
```

# Prepare data and simple plot

```{r, fig.width=10}
world <- ggplot() +
  borders(""world"", colour = ""#353535"", fill = ""#353535"") +
  theme_map()

meteorites2 <- meteorites %>% filter(year >= 2010)

plot_meteor <- world + 
  geom_point(data = meteorites2, aes(x = long, y = lat, size = log_mass), color = ""#ffa500"", alpha = 0.7) +
  theme(legend.position = ""none"")

ggsave(plot_meteor, file = ""plot_meteor.jpg"")

plot_meteor
```

# Create ASCII plot

```{r, fig.width=10}
im <- load.image(""plot_meteor.jpg"") 

# Select characters to use
asc <- gtools::chr(38:126)

# Convert to grayscale
g.chr <- function(chr) implot(imfill(50, 50, val = 1),text(25, 25, chr, cex = 5)) %>% grayscale %>% mean

# Map characters to grayscale
g <- map_dbl(asc, g.chr)

char <- asc[order(g)]
#Convert image to grayscale, resize, convert to data.frame
d <- grayscale(im) %>% imresize(.1)  %>% as.data.frame
d <- d %>% mutate(qv = cut_width(value, 0.01) %>% as.integer) # Better is cut_number, but for real pictures only
d <- mutate(d,char=char[qv])

ascii_plot <- ggplot(d,aes(x,y)) + 
  geom_text(aes(label=char),size=1) + 
  scale_y_reverse() +
  theme_clean() +
  theme(
    panel.border = element_blank(),
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.line = element_blank(),
    axis.ticks = element_blank()
  )
ggsave(ascii_plot, file = ""ascii_meteor.png"")

ascii_plot
```
","2019"
"358",1191,"https://github.com/carleshf/tidytuesday","carleshf","tidytuesday","2019-06-18/2019-06-18.Rmd","---
title: ""TidyTuesday / Christmas Bird Counts (2019-06-18)""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(stringsAsFactors = FALSE)
```

# Load libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(cowplot)
library(ggthemes)
```

# Download data

```{r, message=FALSE, warning=FALSE}
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")
```

```{r}
dim(bird_counts)
bird_counts <- bird_counts %>% filter(how_many_counted > 0)
dim(bird_counts)
```

# Plot occurrences of birds (top and bottom)

```{r}
bird_species <- data.frame(table(bird_counts$species))
bird_species <- bird_species[order(bird_species$Freq, decreasing = TRUE), ]
head(bird_species, n = 25)
```

```{r, fig.width=12}
plot_species <- plot_grid(
  head(bird_species, n = 15) %>% 
    ggplot(aes(x= factor(Var1, levels = rev(Var1)), y = Freq)) + 
    geom_bar(stat = ""identity"") +
    theme_wsj() +
    coord_flip() +
    ggtitle(""Top 15 species\nobserved across years"") +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.caption = element_text(size = 10)
    ) +
    labs(caption = "" ""),
  bird_species %>% 
    filter(Freq > 1) %>% 
    tail(n = 15) %>% 
    ggplot(aes(x= factor(Var1, levels = rev(Var1)), y = Freq)) + 
    geom_bar(stat = ""identity"") +
    theme_wsj() +
    coord_flip() +
    ggtitle(""Bottom 15 species\nobserved across years"") +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.caption = element_text(size = 10)
    ) + 
    labs(caption = ""Source: Bird Studies Canada""),
  ncol = 2
)

ggsave(plot_species, file = ""plot_species_count.png"", width = 12)

plot_species
```



# Plot count per year and count per hour for top 3

```{r, fig.width=12}
plot_many_year <- function(dt, name, min, max) {
  dt %>% 
    filter(species == name) %>% 
    ggplot(aes(x = year, y = how_many_counted)) +
    geom_line() +
    ggtitle(name) +
    theme_wsj() + 
    ylim(min, max) +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      axis.title = element_text(family = ""mono"", size = 10)
    ) +
    xlab(""Year"") + ylab(""How many counted"")
}

plot_many_hour <- function(dt, name, min, max) {
  dt %>% 
    filter(species == name) %>%
    ggplot(aes(x = total_hours, y = how_many_counted_by_hour)) + 
    geom_point() +
    ggtitle(name) +
    theme_wsj() +
    ylim(min, max) +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      axis.title = element_text(family = ""mono"", size = 10),
      plot.caption = element_text(size = 10)
    ) +
    xlab(""Total hours"") + ylab(""How many counted by hour"")
}

plot_bird <- plot_grid(
  plot_many_year(bird_counts, ""American Tree Sparrow"", 0, 2700),
  plot_many_year(bird_counts, ""Blue Jay"", 0, 2700),
  plot_many_year(bird_counts, ""Downy Woodpecker"", 0, 2700),
  plot_many_hour(bird_counts, ""American Tree Sparrow"", 0, 15) +
    labs(caption = "" ""),
  plot_many_hour(bird_counts, ""Blue Jay"", 0, 4) + 
    labs(caption = "" ""),
  plot_many_hour(bird_counts, ""Downy Woodpecker"", 0, 2) + 
    labs(caption = ""Source: Bird Studies Canada""),
  ncol = 3
)

ggsave(plot_bird, file = ""plot_bird_count.png"", width = 12)

plot_bird
```

","2019"
"359",1198,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_2019_06_18_Code.R","#Tidy Tuesday Date 2019-06-18
#By Richard Johansen
#Twitter: @Johansen_PhD
#GitHub: RAJohansen

#load tidyverse!
library(tidyverse)

# Load Data
df <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_2019_06_18/bird_counts.csv"")

# Explore year and species grouping
df %>% group_by(year, species) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted))

# Still too many individual observations
# Group by just year or just species

df %>% group_by(year) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted))

df %>% group_by(species) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted))

# Create time series of counts
lims <- as.Date(strptime(c(""1921-06-17"",""2018-06-19""), format = ""%Y-%m-%d""))    

df$year <- as.character(df$year)
df$year <- as.Date(df$year, ""%Y"")
df %>% group_by(year) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted)) %>% 
ggplot(aes(year,count_mean))+
  geom_point(size = 2)+
  geom_smooth(se =FALSE) +
  labs(title = ""Christmas Bird Counts for \nHamilton, Ontario, Canada"",y = ""Bird Counts\n(mean)"", x = ""\n Year"") +
  scale_x_date(date_labels =""%Y"" , date_breaks = ""6 year"", limits =lims) +
  scale_y_continuous(name=""Cumulative\nTotal"", breaks = seq(0,600, by = 100)) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, size = 16),
        axis.text.x=element_text(angle=0,vjust = 0.5,size = 12),
        axis.text.y=element_text(size = 12),
        axis.title.y=element_text(angle = 0,size = 12, vjust = 0.5,face=""bold""),
        axis.title.x=element_text(face=""bold""))


jpeg(""jpegs/Xmas_Bird_Counts_2019_06_18.jpeg"", width = 12, height = 8, units = 'in', res = 600)
dev.off()

","2019"
"360",1321,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-05-07","allisonhorst","allison-tidy-tuesdays","2019-05-07/tidy_tuesday_5_7_19.R","# Tidy Tuesday 5/7/2019
# Student:teacher class size ratios (global)

# Attach packages
library(tidyverse)
library(janitor)
library(sf)

# Get data:

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

# Averaged across all indicators (levels) and years...

students_all <- student_ratio %>%
  group_by(country_code) %>%
  summarize(
      mean_ratio = mean(student_ratio, na.rm = TRUE)
    ) %>%
  ungroup() %>%
  rename(iso3 = country_code)

# Get global map data, join to student_2016 data:

globe <- st_read(dsn = ""2019-05-07"", layer = ""TM_WORLD_BORDERS_SIMPL-0.3"") %>%
  st_transform(4326) %>%
  clean_names() %>%
  full_join(students_all)

# Plot a single map...

ggplot() +
  geom_sf(data = globe,
          aes(fill = mean_ratio),
          color = ""white"",
          size = 0.1
          ) +
  coord_sf(datum = NA) +
  scale_fill_gradientn(colors = c(""royalblue1"",""magenta"",""orange"",""gold""),
                       name = ""Average student-teacher ratio"") +
  labs(title = ""#tidytuesday: student-teacher ratios\n(average across all years & levels in dataset)"") +
  theme_void() +
  theme(legend.position = c(0.2, 0.35), legend.direction = ""vertical"",
        plot.background = element_rect(fill = ""gray10"", color = NA),
        panel.background = element_rect(fill = ""gray10"", color = NA),
        legend.background = element_rect(fill = NA, color = NA),
        legend.key = element_rect(fill = ""gray10"", colour = NA),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8),
        text =  element_text(color = ""white""),
        title =  element_text(color = ""white""),
        plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 32)
  )

# plot.margin = margin(1, 1, 1, 1, ""cm"")

ggsave(""images/student_ratios_map.png"", width = 8, height = 5)

# Some extra code to test...
","2019"
"361",1322,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-04-23","allisonhorst","allison-tidy-tuesdays","2019-04-23/tidy_tuesday_4_23_19.R","# Tidy Tuesday 4/23/19
# Allison Horst
# Anime!

# Goals this week: fun!

#######
# Load packages
#######

library(tidyverse)
library(ggdark)
library(extrafont)

#######
# Get data
#######

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

########
# Go exploring
########

# Simplify with all shows:

all_shows <- tidy_anime %>%
  select(-synopsis, - background) %>%
  distinct(name, .keep_all = TRUE)

# Find and keep shows from the top 10 most common genres (by # of shows in genre):
top_genres <- tidy_anime %>%
  select(-synopsis, -background) %>%
  filter(genre != ""NA"") %>%
  group_by(genre) %>%
  tally() %>%
  arrange(-n) %>%
  head(6) %>%
  inner_join(tidy_anime)

# No real difference in scores for top genres:
ggplot(top_genres, aes(x = score)) +
  geom_density(aes(fill = genre)) +
  facet_wrap(~genre)

# Change in scores over time?
ggplot(top_genres, aes(x = start_date, y = score)) +
  geom_point() +
  geom_line(aes(color = genre))

# Cumulative sum over time?
time_df <- top_genres %>%
  mutate(show = 1) %>%
  arrange(genre, start_date) %>%
  select(genre, name, start_date, show) %>%
  group_by(genre) %>%
  mutate(totes = cumsum(show))

ggplot(time_df, aes(x = start_date, y = totes)) +
  geom_line(aes(color = genre))

# OK, actually that wasn't that exciting. I'll try something else.

ggplot(top_genres, aes(x = score, y = popularity)) +
  geom_point(aes(color = genre), alpha = 0.5) +
  facet_wrap(~genre) + # This is kind of weird
  theme_dark() +
  scale_color_manual(values = c(""red"",""orange"",""yellow"",""purple"",""black"",""white""))

# FINAL GRAPH STUFF: Relationship btwn popularity and score for all shows...

# Make function for nice scientific notation (help from: https://stackoverflow.com/questions/10762287/how-can-i-format-axis-labels-with-exponents-with-ggplot2-and-scales/45867076)

scientific_10 <- function(x) {
  parse(text=gsub(""e"", ""%*% 10^"", scales::scientific_format()(x)))
}

# Add: 'label = scientific_10' argument in scale_y_continuous for scientific notation

# Then a graph of score vs. popularity:

ggplot(all_shows, aes(x = score, y = popularity)) +
  geom_hex(bins = 50,
           binwidth = c(0.2, 430)) +
  scale_fill_gradientn(colors = c(""slateblue4"",
                                  ""brown1"",
                                  ""orange"",
                                  ""yellow"",
                                  ""white""),
                       name = ""Number of shows:"") +
  guides(fill = guide_colourbar(ticks = TRUE,
                                barwidth = 20,
                                barheight = 0.5,
                                direction = ""horizontal"",
                                title.position = ""top"")) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0,10),
                     breaks = seq(0,10, by = 2)) +
  scale_y_reverse() +
  labs(x = ""Score (higher = better)"",
       y = ""Popularity\n(lower = higher popularity)"",
       title = ""Anime (update)"") +
  ggdark::dark_theme_bw() +
  theme(text = element_text(family = ""Carrois Gothic SC""),
       # panel.spacing.x = unit(1.0, ""lines""),
       # panel.spacing.y = unit(1.0, ""lines""),
        legend.position = ""bottom"",
       plot.margin=unit(c(1,1,1,1),""cm"")
  )

ggsave(""anime.png"", width = 8, height = 7)
","2019"
"362",1323,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-04-09","allisonhorst","allison-tidy-tuesdays","2019-04-09/tidy_tuesday_4_9_19.R","# Tidy Tuesday 4/9/2019
# Allison Horst
# Tennis Grand Slam Champions

library(tidyverse)
library(RColorBrewer)
library(wesanderson)
library(ggpomological)
library(extrafont)
library(LaCroixColoR)
library(ggdark)

# font_import()

# Get data:
# player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

# grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

# This seems like excessive grouping and ungrouping, mer?

past_qual <- c(""Won"",""Finalist"",""Semi-finalist"",""Quarterfinalist"", ""4th Round"", ""3rd Round"", ""2nd Round"", ""1st Round"")

sum_table <- grand_slam_timeline %>%
  filter(!is.na(outcome), outcome %in% past_qual) %>%
  group_by(player, gender, outcome) %>%
    tally() %>%
  ungroup() %>%
  group_by(gender) %>%
  group_split() # This is pretty cool! First time using group_split()

# Access the separate tibbles (probably bad practice, but wanted to try using group_splitanyway...)

male_players <- sum_table[[2]]
female_players <- sum_table[[1]]


# Top 20 males by # appearances after qualification (doesn't include absence/retire data)
top_male_appear <- male_players %>%
  group_by(player) %>%
  summarize(
    appearances = sum(n)
  ) %>%
  arrange(-appearances) %>%
  head(20)

# Top females by # appearances after qualification (doesn't include absence/retire data)
top_female_appear <- female_players %>%
  group_by(player) %>%
  summarize(
    appearances = sum(n)
  ) %>%
  arrange(-appearances) %>%
  head(20)

vec_m <- unique(top_male_appear$player)
vec_f <- unique(top_female_appear$player)

# Joins to keep top 10 by total appearances beyond qualifying round

m_appear <- top_male_appear %>%
  inner_join(male_players) %>%
  mutate(player = as.factor(player)) %>%
  mutate(outcome = as.factor(outcome))

f_appear <- top_female_appear %>%
  inner_join(female_players) %>%
  mutate(player = as.factor(player)) %>%
  mutate(outcome = as.factor(outcome))

# Relevel by top players
f_appear$player <- fct_relevel(f_appear$player, vec_f)
m_appear$player <- fct_relevel(m_appear$player, vec_m)

# Relevel outcome
f_appear$outcome <- fct_relevel(f_appear$outcome,""Won"", ""Finalist"",""Semi-finalist"",""Quarterfinalist"",""4th Round"", ""3rd Round"",""2nd Round"",""1st Round"")

m_appear$outcome <- fct_relevel(m_appear$outcome,""Won"", ""Finalist"",""Semi-finalist"",""Quarterfinalist"",""4th Round"", ""3rd Round"",""2nd Round"",""1st Round"")

# Then make a graph that shows the level reached after qualifiers for each:

# pal <- wes_palette(8, name = ""FantasticFox1"", type = ""continuous"")
# Create palette:
pal <- lacroix_palette(""PassionFruit"", n = 8, type = ""continuous"")

# Graph of female top appearances:
ggplot(f_appear, aes(x = reorder(player, desc(player)), y = n)) +
  geom_col(aes(fill = outcome)) +
  dark_mode(theme_pomological(base_family = ""Courier New"", base_size = 12)) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,90)) +
  scale_fill_manual(values = pal, name = ""Outcome:"") +
  labs(x = """", y = ""Number of appearances\n(beyond qualifiers)"", title = ""Grand Slam appearances & outcomes"") +
  theme(legend.position = ""bottom"",
        axis.text.x=element_text(size=11, face = ""bold"", hjust = 1, color = ""deeppink""),
        axis.text.y = element_text(size = 10, color = ""chartreuse"", face = ""bold""),
        axis.title.x = element_text(color = ""cyan3"", face = ""bold""),
        legend.title = element_text(color = ""deeppink"", size = 12, face = ""bold""),
        legend.text = element_text(color = ""chartreuse"", face = ""bold""),
        plot.title = element_text(color = ""cyan3"", face = ""bold""),
        panel.border = element_rect(colour = ""cyan3"")) +
  coord_flip()

# Save it:
ggsave(""my_tennis_plot.png"", width = 8, height = 7)


# Male version:
ggplot(m_appear, aes(x = reorder(player, desc(player)), y = n)) +
  geom_col(aes(fill = outcome)) +
  theme_pomological(base_family = ""Courier New"",
                    base_size = 12) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0,80)) +
  scale_fill_manual(values = pal,
                    name = ""Outcome:"") +
  labs(x = """", y = ""Number of appearances\n(beyond qualifiers)"",
       title = ""Grand Slam Appearances Colorblast"") +
  theme(legend.position = ""bottom"",
        axis.text.x=element_text(size=10, face = ""bold"", angle = 50, hjust = 1),
        axis.text.y = element_text(size = 10, color = ""slateblue4"")) +
  coord_flip()

ggsave(""my_tennis_plot_m.png"", width = 8, height = 7)




","2019"
"363",1350,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-04-30","allisonhorst","allison-tidy-tuesdays","2019-04-30/tidy_tuesday_4_30_19.R","# Tidy Tuesday 4/30/19
# Allison Horst
# Bird collisions in Chicago

# Goals:
# Try circle packing?

#----------------
# Get data:

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

# mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

#----------------
# Get packages:

library(tidyverse)
library(lubridate)
library(ggmosaic)
library(packcircles)
library(ggrepel)

#----------------
# Some wrangling for exploration:

# Total collision counts by locality, flight_call, habitat, stratum:
bird_sum <- bird_collisions %>%
  filter(flight_call != ""Rare"") %>%
  group_by(locality, flight_call, habitat, stratum) %>%
  tally()

# Counts of collisions by year (Chicago):
bird_year <- bird_collisions %>%
  mutate(year = year(date)) %>%
  filter(locality == ""CHI"") %>%
  group_by(year, family, flight_call) %>%
  tally()

# Counts of collisions by family:
bird_tot <- bird_collisions %>%
  group_by(flight_call, family) %>%
  tally()

#----------------
# Some exploratory graphs:

# Plot collisions over years:
ggplot(bird_year, aes(x = year, y = n)) +
  geom_point(aes(color = family,
                 pch = flight_call))

# Mosaic plot by flight call (works, but not interesting)
ggplot(bird_sum) +
  geom_mosaic(aes(weight = n,
                  x = product(locality, habitat),
                  fill = flight_call))

#----------------
# Circle packing try...

# Make circles!

circles <- packcircles::circleProgressiveLayout(bird_tot$n, sizetype='area')

data <- data.frame(bird_tot, circles) %>%
  mutate(id = row_number())

data_vertices <- circleLayoutVertices(circles, npoints=100)
data_join <- full_join(data, data_vertices)
data_min_join <- left_join(data, data_vertices)

# Create final circle graph:

ggplot() +
  geom_polygon(data = data_join,
               aes(x, y,
                   group = id,
                   fill = factor(flight_call)),
               color = ""NA"") +
   geom_polygon(data = data_vertices,
               aes(x, y, group = id),
               size = 0.5,
               fill = NA,
               color = NA) +
  scale_fill_manual(values = c(""darkorange"",""cyan4"",""slateblue1""),
                    breaks = c(""No"",""Rare"", ""Yes""),
                    name = ""Flight call?"") +
  geom_text_repel(data = data_min_join,
                  aes(x, y, label = family, size = radius),
                  segment.size = 0.2,
                  min.segment.length = 0.4,
                  segment.color = ""black"",
                  color = ""black"",
                  force = 35,
                  family = ""Arial"",
                  fontface = ""italic""
                  ) +
  scale_radius(range = c(2,8), guide = ""none"") +
  labs(x = """", y = """",
       title = ""Bird collisions in Chicago by family"",
       subtitle = ""Circle areas ~ Number of collisions"") +
  theme_void() +
  theme(legend.position = ""bottom"",
        legend.text = element_text(color = ""black"", size = 10),
        legend.title = element_text(color = ""black"", size = 12),
        text = element_text(family = ""Arial"")
        ) +
  coord_equal()

ggsave(""2019-04-30/bird_collision_circles.png"")

#--------------
# Testing github update...



","2019"
"364",1351,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-05-20","allisonhorst","allison-tidy-tuesdays","2019-05-20/tidy_tuesday_5_20_19.R","# Tidy Tuesday 5/19/2019
# Global plastics
# Allison Horst

# Attache packages:
library(tidyverse)
library(janitor)
library(extrafont)
library(treemapify)

# Get the data:
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>% clean_names()

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>% clean_names()

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>% clean_names()

# Make df names and column names more manageable:
coastal <- coast_vs_waste %>%
  rename(mis_plastic = mismanaged_plastic_waste_tonnes,
         coast_pop = coastal_population,
         tot_pop_gm = total_population_gapminder)

mis_gdp <- mismanaged_vs_gdp %>%
  rename(mis_plastic_percap = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day,
         gdp_per_cap = gdp_per_capita_ppp_constant_2011_international_rate,
         tot_pop_gm = total_population_gapminder)

waste_gdp <- waste_vs_gdp %>%
  rename(plast_waste_percap = per_capita_plastic_waste_kilograms_per_person_per_day,
         gdp_per_cap = gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
         tot_pop_gm = total_population_gapminder)

# Join them together (only includes 2010 data when NAs removed...)
# NEED TO DOUBLE CHECK THESE JOINS, UNITS & CONVERSIONS...
all_join <- full_join(coastal, mis_gdp) %>% # join
  full_join(waste_gdp) %>% # again
  drop_na(mis_plastic) %>% # get rid of NAs (only keeps 2010)
  filter(entity != ""World"") %>% # No world total
  mutate(tot_plastic_2010 = tot_pop_gm*plast_waste_percap*365) %>% # calc totals (ANNUAL KG)
  mutate(mis_plastic_kg = mis_plastic*907.185) %>%  # Convert from tons to kg (1 ton = 907.185 kg)
  mutate(perc_mismanaged = mis_plastic_kg/tot_plastic_2010) %>%
  arrange(-tot_plastic_2010)

# Coastal pop vs. mismanaged plastics
ggplot(all_join, aes(x = coast_pop, y = mis_plastic)) +
  geom_point()

ggplot(all_join, aes(x = gdp_per_cap, y = perc_mismanaged)) +
  geom_point()

# Test log (base-10) scale?
ggplot(all_join, aes(x = log10(coast_pop), y = log10(mis_plastic))) +
  geom_point() # Eh. I think log scales are hard to think about.

# Treemap?

ggplot(all_join, aes(area = tot_plastic_2010, label = entity, fill = tot_plastic_2010)) +
  geom_treemap(color = ""white"", start = ""topleft"") +
  geom_treemap_text(min.size = 4, place = ""center"", family = ""Carrois Gothic"", color = ""white"", start = ""topleft"") +
  scale_fill_gradientn(colors = c(""black"",""green3"")) +
  theme(legend.position = ""NA"") +
  labs(title = ""Total plastics, 2010"") +
  theme(text = element_text(family = ""Carrois Gothic""))

ggsave(""2019-05-20/plastic_treemap.png"", width = 8, height = 8)
","2019"
"365",1352,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-04-16/tidy_tuesday_04_16_19.R","# Tidy Tuesday 4/16/19
# Allison Horst
# Take a decent graph, and make it an absolute abomination


#######
# Load packages
#######

library(tidyverse)
library(extrafont)
library(RColorBrewer)
library(lubridate)
library(ggdark)
library(cowplot)

#######
# Get data (needed here: brexit, corbyn, dogs)
#######

# Thanks to Sarah Leo and The Economist for these (""Mistakes, We've Drawn a Few"") data!

# brexit <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv"")

# corbyn <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/corbyn.csv"")

# dogs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

#eu_balance <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")

#pensions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/pensions.csv"")

#trade <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/trade.csv"")

#women_research <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")

#########
# Corbyn Facebook Abomination
#########

corbyn_graph <- ggplot(corbyn, aes(x = political_group, y = log(avg_facebook_likes))) +
  geom_bar(stat = ""identity"", width = 1, aes(fill = political_group), color = ""black"") +
  scale_fill_brewer(palette = ""Greens"",
                    name = ""Never give in, never relevel"") +
  theme(plot.title = element_text(size = 30,
                             family = ""Times New Roman"",
                             color = ""green"",
                             face = ""italic""),
        axis.text.x = element_blank(),
        axis.text.y = element_text(size = 8,
                                   color = ""white"",
                                   angle = 20,
                                   vjust = -0.5),
        axis.title.x = element_text(size = 20,
                                    family = ""Courier New"",
                                    color = ""black""),
        axis.title.y = element_text(size = 14,
                                    color = ""navy"",
                                    family = ""Impact""),
        panel.background = element_rect(color = ""black"",
                                        fill = ""yellow"",
                                        size = 2),
        legend.title = element_text(size = 12,
                                    color = ""brown4""),
        legend.text = element_text(family = ""Times New Roman"", size = 11),
        legend.background = element_rect(fill = ""tan""),
        panel.grid.major = element_line(color = ""red""),
        plot.background = element_rect(fill = ""hotpink""),
        strip.background = element_rect(fill = ""darkgreen""),
        strip.text = element_text(color = ""skyblue"",
                                  face = ""bold"",
                                  family = ""Arial Rounded MT Bold"",
                                  size = 8)
        ) +
  labs(x = ""must polar"",
       y = ""log scale\nsuch easy interpretation"",
       title = ""So good"",
       subtitle = ""Artisanal color palette"",
       caption = ""tag: dataviz comp submission"") +
  scale_y_continuous(limits = c(0,10)) +
  coord_polar() +
  facet_wrap(~political_group)


#########
# Brexit MaxGross
#########

# Some wrangling:
brexit_2 <- brexit %>%
  mutate(date = dmy(date)) %>% # YAY lubridate!
  gather(""response"",""percent"",-date) # 100th time I've had to learn gather this year...


# And another rave:
brexit_graph_1 <- ggplot(brexit_2, aes(x = date, y = percent, group = response)) +
  geom_area(position = ""identity"",
            aes(fill = response, color = response),
            alpha = 0.5,
            size = 0.7,
            lty = 1) +
  scale_fill_manual(values = c(""purple"",""yellow""),
                    name = ""Brexit:"",
                    breaks=c(""percent_responding_right"", ""percent_responding_wrong""),
                    labels=c(""It's right!"", ""It's wrong!"")) +
  scale_color_manual(values = c(""magenta"",""orange""),
                     name = ""Brexit:"",
                     breaks=c(""percent_responding_right"", ""percent_responding_wrong""),
                     labels=c(""It's right!"", ""It's wrong!"")) +
  coord_cartesian(ylim = c(40, 48)) +
  scale_x_date(expand = c(0,0),
               breaks = ""4 months"",
               date_labels = ""%b %Y"") +
  dark_mode(theme_pubclean()) +
  theme(
    legend.position = ""top"",
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  labs(x = ""Date"", y = ""Percentage Responding\n(Brexit right or wrong?)"")

# Also I want to make one like the better version...

# Wrangling for dates:
brexit_3 <- brexit %>%
  mutate(date = dmy(date))

brexit_graph <- ggplot(brexit_3) +
  geom_point(aes(x = date,
                 y = percent_responding_right),
             color = ""orange"",
             size = 3,
             pch = 6) +
  geom_point(aes(x = date,
                 y = percent_responding_wrong),
             color = ""purple"",
             size = 3,
             pch = 5) +
  dark_mode(theme_pubclean()) +
  theme(
    text = element_text(family = ""Tahoma""),
    legend.position = ""top""
  ) +
  geom_smooth(aes(x = date,
                  y = percent_responding_right),
              color = ""darkorange"",
              fill = ""orange"",
              span = 5,
              lty = 6) +
  geom_smooth(aes(x = date,
                  y = percent_responding_wrong),
              color = ""purple"",
              fill = ""magenta"",
              span = 5,
              lty = 11) +
  labs(x = ""Date"",
       y = ""Percent of respondents"",
       title = ""Brexit opinions"",
       subtitle = ""Who is Loess anyway?"") +
  scale_x_date(""Date"",
               date_labels = ""%b %Y"",
               date_breaks = ""6 months""
               )

brex_graph


###########
# And one more quick one just so I can practice with ggpubr (dogs)
###########

# Gather
dogs_2 <- dogs %>%
  gather(""param"", ""val"", -year)

dog_graph <- ggplot(dogs_2, aes(x = year, y = val, group = param)) +
  geom_point(aes(color = param, pch = param), size = 4) +
  geom_line(aes(color = param)) +
  scale_color_manual(values = c(""blue"",""black"")) +
  scale_x_continuous(limits = c(2005, 2016),
                     breaks = seq(2005, 2016),
                     expand = c(0,0)) +
  scale_y_continuous(limits = c(0,50),
                     minor_breaks = seq(0,50, by = 2),
                     expand = c(0,0)) +
  theme(legend.position = ""top"",
        plot.background = element_rect(fill = ""lightgoldenrod""),
        axis.text.x = element_text(angle = 90)
        ) +
  labs(x = ""Year"", y = ""Size-o-meter"", title = ""Adopt a shelter dog!"")


##########
# COWPLOT! Multiple graph layouts.
##########

ggdraw() +
  draw_plot(corbyn_graph, x = 0, y = 0.5, height = 0.5, width = 1) +
  draw_plot(dog_graph, x = 0, y = 0, width = 0.5, height = 0.5) +
  draw_plot(brexit_graph_1, x = 0.52, y = 0, width = 0.5, height = 0.5) +
  draw_plot_label(label = c(""A"", ""B"", ""C""), size = 20, colour = ""purple"",
                  x = c(0, 0, 0.52), y = c(0.98, 0.5, 0.5))

ggsave(""cowplot_test.png"", width = 8, height = 10, units = ""in"")

write_csv(dogs_2, ""my_dog_file.csv"")
","2019"
"366",1353,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-05-14/tidy_tuesday_5_14_19.R","# Nobel Prize Winners
# #tidytuesday 5/14/2019

# Allison Horst

# Goal: Create a timeline of women who've won the Nobel Prize

# Get data on Nobel Prize winners (more information here: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-05-14):

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

# Load packages:

library(tidyverse)
library(lubridate)
library(extrafont)

# Some wrangling

nobels <- nobel_winners %>%
  mutate(yrand = rnorm(969, mean = 0, sd = 1)) %>%
  filter(laureate_type == ""Individual"")


# Create random sequences for year jitter:

set.seed(1001)
r_seq <- rnorm(48, mean = 0, sd = 10)

set.seed(1002)
r_seq_2 <- rnorm(939, mean = 0, sd = 0)


# Add columns with jittered year (using sequences above)

women_nobels <- nobel_winners %>%
  filter(laureate_type == ""Individual"") %>%
  filter(gender == ""Female"") %>%
  mutate(f_yrand = 1) %>%
  mutate(year_jitter = prize_year + r_seq)

all_nobels <- nobels %>%
  mutate(all_rand = 1) %>%
  mutate(year_jitter_all = prize_year + r_seq_2) %>%
  mutate(gender = fct_relevel(gender, ""Male"", ""Female"")) %>%
  mutate(category = fct_relevel(category, ""Physics"",""Economics"",""Chemistry"",""Medicine"",""Literature"",""Peace""))

# Make text
text_df <- data.frame(
  label = c(""Physics: 2/222"",""Economics: 2/83"",""Chemistry: 4/194"", ""Medicine: 12/227"", ""Literature: 14/113"", ""Peace: 14/100""),
  category = c(""Physics"",""Economics"",""Chemistry"",""Medicine"",""Literature"",""Peace""),
  x = c(1905,1905,1905),
  y = c(1,2,3)
)

# Chemistry, Economics, Literature, Medicine, Peace, Physics

# women_nobels$rand_val <- r_seq
#
# women_nobels_jitteryear <- women_nobels %>%
# mutate(jitter_year = prize_year + rand_val)

# Physics: 2/222
#

# Trying geom_linerange

ggplot(women_nobels, aes(y = f_yrand, ymin = 0, x = year_jitter, ymax = f_yrand)) +
  geom_linerange(size = 1) +
  geom_text(aes(label = full_name),
            angle = 50,
            vjust = 0,
            hjust = -0.05,
            size = 2)

# This all looks hideous and the y-axis doesn't make sense.

# Trying with all nobel winners:

ggplot(all_nobels, aes(y = all_rand,
                       ymin = 0,
                       x = year_jitter_all,
                       ymax = all_rand)) +
  geom_linerange(size = 1.5,
                 aes(color = gender),
                 alpha = 0.4) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,1), limits = c(1901, 2016), breaks = c(1901,2016)) +
  scale_color_manual(values = c(""mediumorchid4"",""cyan"")) +
  facet_wrap(~category, ncol = 1, strip.position = ""left"") +
  theme_minimal() +
  labs(title = ""Individual Nobel Prize Winners\n1901 - 2016"") +
  theme(panel.background = element_rect(fill = ""black""),
        plot.background = element_rect(fill = ""black""),
        legend.position = ""bottom"",
        legend.title = element_blank(),
        legend.text = element_text(color = ""gray60"", size = 10),
        strip.text = element_text(color = ""gray60"", size = 9),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_text(color = ""gray70""),
        plot.margin=unit(c(1,1,1,1.2),""cm""),
        plot.title = element_text(color = ""gray60""),
        text = element_text(family = ""Trebuchet MS"")
  )


ggplot(all_nobels, aes(y = all_rand,
                       ymin = 0,
                       x = year_jitter_all,
                       ymax = all_rand)) +
  geom_linerange(size = 1.5,
                 aes(color = gender),
                 alpha = 0.4) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,1), limits = c(1901, 2016), breaks = c(1901,2016)) +
  scale_color_manual(values = c(""mediumorchid4"",""cyan"")) +
  facet_wrap(~category, ncol = 1, strip.position = ""left"") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = ""black""),
        plot.background = element_rect(fill = ""black""),
        legend.position = ""NA"",
        legend.title = element_blank(),
        legend.text = element_blank(),
        strip.text = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_blank(),
        plot.margin=unit(c(1,1,1,1.2),""cm""),
        plot.title = element_text(color = ""gray60""),
        text = element_text(family = ""Trebuchet MS"")
  )
ggsave(""2019-05-14/nobel_winners_vague.png"", width = 7, height = 7)

# Get some summary counts:

nobel_sum <- nobel_winners %>%
  filter(laureate_type == ""Individual"") %>%
  group_by(category, gender) %>%
  tally()

# Physics: 2/222
# Economics: 2/83
# Chemistry: 4/194
# Medicine: 12/227
# Literature: 14/113
# Peace: 14/100


","2019"
"367",1354,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-05-28/tidy_tuesday_5_28_19.R","#######
# Tidy Tuesday 5/28/2019
# Wine ratings
#######

# Attach packages
library(tidyverse)
library(extrafont)
library(ggdark)

# Get the data:
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

# A bunch of wrangling (much unnecessary) + exploration station:

# Find the points-to-price ratios:
wine_deal <- wine_ratings %>%
  select(points, price, title) %>% # Only keep these columns
  mutate(pp_ratio = points/price) %>% # Find the points:price ratio
  arrange(-pp_ratio) # Arrange by high-to-low ratio

# Checking counts for each wine type (don't really care):
wine_counts <- wine_ratings %>%
  group_by(title) %>%
  tally() %>%
  arrange(-n)

# Find the top 15 countries with them most reviews:
country_counts <- wine_ratings %>%
  group_by(country) %>%
  tally() %>%
  arrange(-n) %>%
  head(15) %>%
  select(country)

# Find the median point:price ratio for those 15 countries:
# Note: something is effed here. (not reproducible right now)
country_medians <- wine_deal %>%
  inner_join(wine_ratings) %>%
  inner_join(country_counts) %>%
  group_by(country) %>%
  summarize(
    med_ratio = median(pp_ratio, na.rm = TRUE)
  ) %>%
  arrange(-med_ratio)

# Join to have prices, number, ratio in single table, relevel by medians:
wine_all <- wine_deal %>%
  inner_join(wine_ratings) %>%
  inner_join(wine_counts) %>%
  inner_join(country_counts) %>%
  select(title, pp_ratio, country, variety,n) %>%
  drop_na(country) %>%
  mutate(country = as.factor(country)) %>% # Not necessary?
  mutate(country = fct_relevel(country, country_medians$country))

# Violin plot of points:price ratios by country
ggplot(wine_all, aes(x = reorder(country, desc(country)), y = pp_ratio)) +
  geom_violin(aes(color = country, fill = country), width = 1.0) +
  geom_boxplot(fill = NA, color = ""white"", width = 0.4, size = 0.3, outlier.color = NA) +
  labs(x = ""Country\n"",y = ""\nPoints-per-price ratio (higher = better)"", title = ""Wine points:price ratio (sweet deal metric) by country"", subtitle = ""*For the 15 countries with the highest number of reviews in Kaggle dataset"") +
  dark_mode(theme_minimal()) +
  theme(legend.position = ""NA"",
        text = element_text(family = ""Muli""),
        plot.subtitle = element_text(size = 8, face = ""italic"")) +
  coord_flip()

# ggsave(""2019-05-28/wine_deals.png"", width = 7, height = 5)
","2019"
"368",1355,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-06-04/tidy_tuesday_6_4_19.R","#################
# Tidy Tuesday 6/4/2019
# Allison Horst
# Ramen ratings!

# ""This week's dataset is a ramen ratings dataset from The Ramen Rater. H/t to Data is Plural.""
##################

# Attach packages
library(tidyverse)
library(LaCroixColoR)
library(extrafont)
library(ggbeeswarm)
library(ggridges)

# Get the data
ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

# Find the most commonly rated brands:
ramen_common <- ramen_ratings %>%
  group_by(brand) %>%
  tally() %>%
  arrange(-n) %>%
  head(20) %>%
  inner_join(ramen_ratings)

# Brand medians:
brand_medians <- ramen_common %>%
  group_by(brand) %>%
  summarize(
    medians = median(stars, na.rm = TRUE)
  ) %>%
  arrange(-medians)

# Relevel brand factor levels by median
ramen_common$brand <- fct_relevel(ramen_common$brand, levels = brand_medians$brand)

# Palette specs
pal <- lacroix_palette(""Berry"", n = 20, type = ""continuous"")

# Only keep those brands from the original df, plot
ramen_top_brands <- ramen_common %>%
  filter(brand %in% unique(ramen_common$brand))

ggplot(ramen_top_brands, aes(x = reorder(brand, desc(brand)), y = stars)) +
  # geom_quasirandom(aes(color = brand),
  #              alpha = 0.3,
  #              size = 1) +
  geom_jitter(size = 1,
              alpha = 0.3,
              aes(color = brand),
              width = 0.1) +
  geom_boxplot(size = 0.2,
               aes(fill = brand),
               alpha = 0.8,
               outlier.alpha = 0) +
  geom_point(data = brand_medians, aes(x = brand, y = medians),
             color = ""gray10"",
             fill = ""gray10"",
             size = 2,
             pch = 21) +
  coord_flip() +
  theme_minimal() +
  theme(text = element_text(family = ""Josefin Sans""),
        legend.position = ""NA"",
        panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_line(color = ""gray90""),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_line(color = ""gray90""),
        plot.subtitle = element_text(color = ""gray50""),
        plot.caption = element_text(color = ""gray50"")) +
  scale_color_manual(values = pal) +
  scale_fill_manual(values = pal) +
  labs(x = ""Ramen Brand"",
       y = ""Rating (5 = best)\n"",
       title = ""Ramen ratings by brand*"",
       subtitle = ""Data from The Ramen Rater"",
       caption =
         ""*for 20 brands with most observations (n) in dataset"")

ggsave(""2019-06-04/ramen_by_brand.png"", width = 6, height = 6 )

# Just more messing around...

pal_2 <- pal <- lacroix_palette(""Apricot"", n = 5, type = ""continuous"")

ramen_ratings %>%
  filter(brand %in% unique(ramen_common$brand)) %>%
  ggplot(., aes(brand, stars)) +
  geom_quasirandom(aes(color = brand), alpha = 0.5, size = 2) +
  coord_flip() +
  scale_color_manual(values = pal) +
  theme_light() +
  theme(
    text = element_text(family = ""Muli""),
    legend.position = ""NA""
  )

# Hm cool.
# Now investigating by country:

# Top 20 countries with most ratings
common_countries <- ramen_ratings %>%
  group_by(country) %>%
  tally() %>%
  arrange(-n) %>%
  head(20) %>%
  inner_join(ramen_ratings) # Join back. Cool.

# Find median order for factor releveling:
country_medians <- common_countries %>%
  group_by(country) %>%
  summarize(
    medians = median(stars, na.rm = TRUE)
  ) %>%
  arrange(-medians)

# Use that order to relevel the country factor levels in common_countries
common_countries$country <- fct_relevel(common_countries$country, levels = country_medians$country)


# Plot ramen by country

pal_3 <- lacroix_palette(""Berry"", n = 20, type = ""continuous"")


ggplot(common_countries, aes(x = reorder(country, desc(country)), y = stars)) +
  geom_quasirandom(alpha = 0.3,
                   aes(color = country)) +
  geom_boxplot(alpha = 0.6,
               size = 0.2,
               color = ""black"",
               aes(fill = country),
               outlier.color = NA) +
  geom_point(data = country_medians, aes(x = country, y = medians),
             color = ""gray20"",
             size = 3,
             pch = 19) + #124 is vertical line
  scale_y_continuous() +
  scale_fill_manual(values = pal_3) +
  scale_color_manual(values = pal_3) +
  theme_minimal() +
  coord_flip() +
  theme(
    legend.position = ""NA"",
    panel.grid.minor.x = element_blank(),
    text = element_text(family = ""Josefin Sans"")
  ) +
  labs(y = ""Rating (5 = better)"",
       x = ""Country Produced"",
       title = ""Ramen ratings by production country*"",
       subtitle = ""Data from The Ramen Rater"")

ggsave(""2019-06-04/ramen.png"", width = 5, height = 5)


# Switch side of axis labels (y)
# Add (n = #) to each row for number of observations
# Add caption with *Only 20 countries with highest # observations included

####################
# FINAL GGRIDGES GRAPH
####################
# Some other weird tests of things
# ggridges?
# Using the ramen_top_brands dataset

pal_4 <- lacroix_palette(""Coconut"", n = 20, type = ""continuous"")

ggplot(ramen_top_brands, aes(x = stars, y = brand)) +
  geom_density_ridges(scale = 7,
                      aes(fill = brand),
                      size = 0.3,
                      color = ""NA"") +
  scale_fill_manual(values = pal_4) +
  scale_color_manual(values = pal_4) +
  scale_x_continuous(breaks = c(0,1,2,3,4,5), limits = c(0,5), expand = c(0,0)) +
  theme_minimal() +
  theme(text = element_text(family = ""Carrois Gothic""),
        legend.position = ""NA"",
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_line(color = ""gray90""),
        panel.grid.major.x = element_line(color = ""gray90""),
        panel.grid.minor.y = element_blank(),
        plot.subtitle = element_text(color = ""gray50""),
        plot.caption = element_text(color = ""gray50""),
        plot.title = element_text(size = 18),
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 12)
        ) +
  labs(x = ""Rating (5 = best)\n"",
       y = ""Ramen Brand\n"",
       title = ""Ramen ratings by brand*"",
       subtitle = ""Data from The Ramen Rater"",
       caption =
         ""*for 20 brands with most observations (n) in dataset"")

ggsave(""2019-06-04/ramen_ggridges.png"", width = 7, height = 7)
","2019"
"369",1392,"https://github.com/l2nguyen/tidy_tues/blob/master/2019/April16/brexit.R","l2nguyen","tidy_tues","2019/April16/brexit.R","library(tidyverse)
library(ggthemes)

brexit <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv"")

brexit_manip <- brexit %>%
  gather(key = ""response"", value = ""percent"", -date) %>%
  mutate(date = lubridate::dmy(date),
         response = recode(response,
                           ""percent_responding_right"" =""Right"",
                           ""percent_responding_wrong"" = ""Wrong"")
         )

ggplot(brexit_manip, aes(x=date, y=percent, col=response)) +
  geom_point(alpha = 0.2) +
  geom_smooth(se=FALSE) +
  geom_text(data = filter(brexit_manip, date==max(date)),
             aes(label=response),
             nudge_y = -0.5) +
  scale_color_manual(values = c(""#2554C7"",""#B31423"")) +
  theme_economist() +
    scale_x_date(date_breaks = ""1 year"", date_labels=""%Y"") +
  scale_y_continuous(breaks=seq(38, 50, by=2),
                     limits = c(38,50)) +
  labs(
    title = ""Bremorse"",
    subtitle = ""In hindsight, do you think it was right or wrong to vote to leave the EU?"",
    y = ""% responding"",
    caption = ""Source: Economist""
  ) +
  theme(
    legend.position = ""none"",
    plot.title = element_text(size = 14, hjust=0),
    plot.caption = element_text(hjust = 0, face = ""bold""),
    axis.title.x = element_blank(),
    axis.title.y.left = element_text(size=9, face=""italic"", angle = 0,
                                     margin= margin(0,-55,0,0)
                                     ),
    axis.ticks.length = unit(0.2, ""cm"")
    )","2019"
"370",1393,"https://github.com/phillynerd/TidyTuesday/tree/master/RamenRatings_6-6-2019","phillynerd","TidyTuesday","RamenRatings_6-6-2019/BestRamenCountries.R","
#Data####
RamenRaw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

#Data Dictionary####
#review_number	integer	Ramen review number, increasing from 1
#brand-	character	Brand of the ramen
#variety-	character	The ramen variety, eg a flavor, style, ingredient
#style-	character	Style of container (cup, pack, tray,
#country-	character	Origin country of the ramen brand
#stars-	double	0-5 rating of the ramen, 5 is best, 0 is worst
 
#Libraries####                                   

#devtools::install_github(""dill/emoGG"") 
library(tidyverse)
library(tidylog)
library(skimr)
library(visdat)
library(emoGG)

emoGG::emoji_search(""ramen"")
emoGG::geom_emoji()
#exploring
vis_miss(RamenRaw) #remove those with no ratings, v small percent; can also remove those w no style listed.
skim(RamenRaw)

RamenClean<- RamenRaw %>% 
  filter(is.na(stars) == F, is.na(style) == F) %>% 
  mutate(style = factor(style),
         country = factor(country))

#which countries produce the highest rated ramen
RamenClean %>% 
  group_by(country) %>% 
  summarize(AvgRating = mean(stars),
            NReviews = n()) %>% 
  ggplot(aes(y = reorder(country, AvgRating),x = AvgRating)) +
  geom_segment(aes(x = 0, xend = AvgRating, yend = country), color = ""#e0dabc"", size = 1.5) +
  geom_emoji(emoji = ""1f365"", size = .03) +
  geom_vline(xintercept = mean(RamenClean$stars), color = ""red"")+
  geom_text(aes(label = NReviews), size = 3, hjust = -.5) +
  labs(title = ""Which Countries Produce the Best Ramen?"",
       x = ""Average Rating Across All Products (0-5)"",
       caption = ""Numbers represent total N of reviews per country\nData: TheRamenRater.com|Viz: @phillynerd"") +
  scale_x_continuous(limits = c(0,5)) +
  add_emoji(emoji = ""1f35c"") +
  theme(panel.grid = element_blank(),
       panel.background = element_rect(fill = ""#9b9999""),
       axis.title.y = element_blank() ) +
  annotate(geom = ""text"", 
           x = mean(RamenClean$stars), y = 0, 
           label = paste0(""Overall Avg: "", round(mean(RamenClean$stars),1)),
           angle = 90,
           hjust = -.2, vjust = -.5, size = 4)
 
 
","2019"
"371",1398,"http://github.com/bwenden/TidyTuesdays/tree/master/Wines_2019-05-28","bwenden","TidyTuesdays","Wines_2019-05-28/Script.R","library(tidyverse)
library(tidytext)
library(ggthemes)

#Import data
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
  select(-X1) %>%
  distinct()

###Extract flavors and taste characteristics
wine_words <- wine_ratings %>%
  unnest_tokens(description_word, description) %>%
  anti_join(stop_words, by = c(""description_word"" = ""word"")) %>%
  filter(!str_detect(description_word, ""[:digit:]"")) %>%
  add_count(description_word)

  
###Percentage of occurrences of the words in the review score range
###I used the classification system from WineEnthusiast

description_words <- wine_words %>%
  filter(n >= 20) %>%
  mutate(score = case_when((points<=82) ~ ""Acceptable"",
                           (points >= 83)&(points<= 86) ~ ""Good"",
                           (points >= 87)&(points<= 89) ~ ""Very Good"",
                           (points >= 90)&(points<= 93) ~ ""Excellent"",
                           (points >= 94)&(points<= 97) ~ ""Superb"",
                           (points >=98) ~ ""Classic"" )) %>%
  count(description_word, score, sort = TRUE) %>%
  group_by(description_word) %>%
  mutate(percent = n / sum(n)) 

###Enrichment analysis
wine_words_enrichment <- wine_words %>%
  filter(n >= 20) %>%
  mutate(score = case_when((points<=82) ~ ""Acceptable"",
                           (points >= 83)&(points<= 86) ~ ""Good"",
                           (points >= 87)&(points<= 89) ~ ""Very Good"",
                           (points >= 90)&(points<= 93) ~ ""Excellent"",
                           (points >= 94)&(points<= 97) ~ ""Superb"",
                           (points >=98) ~ ""Classic"" )) %>%
  select(description_word, score) %>%
  add_count(score, name = ""Total_word_number_in_score"") %>%
  add_count(description_word, name = ""Total_occurrence"") %>%
  add_count(description_word, score, name = ""word_occurrence_in_this_score"") %>%
  add_count(name = ""Total_words"") %>%
  distinct() %>%
  group_by(score) %>%
  mutate(
    pvalue = phyper(
      q = word_occurrence_in_this_score,
      m = Total_occurrence,
      n = Total_words - Total_occurrence,
      k = Total_word_number_in_score,
      lower.tail = F, log.p = FALSE),
    qvalue = p.adjust(pvalue, method = ""fdr"")
  )
  
wine_words_enrichment %>%
  group_by(score) %>%
  mutate(rank = rank(qvalue, ties.method = ""first"")) %>%
  filter(rank <= 10) %>%
  ungroup() %>%
  mutate(qvalue = ifelse(qvalue == 0, (min(qvalue[qvalue > 0])), qvalue)) %>%
  arrange(rank) %>% 
  ggplot(aes(y = qvalue, x = fct_reorder(description_word, -rank)))+
  geom_point(aes(color = qvalue, size = word_occurrence_in_this_score/Total_word_number_in_score), alpha = 0.5)+
  scale_color_gradient(low = ""#c03728"", high=""#f5c04a"", 
                       trans = ""log"",
                       breaks = c(1e-250, 1e-150,1e-50))+
  scale_size_continuous(labels = scales::percent_format(accuracy = 1))+
  coord_flip()+
  facet_wrap(~fct_relevel(score,c(""Classic"", ""Superb"", ""Excellent"", ""Very Good"", ""Good"",""Acceptable"")),
             scales = ""free"")+
  scale_y_log10()+
  theme_tufte()+
  labs(y = """", x = """", 
       color = ""Enrichment\nadjusted p.value"",
       size = ""Word occurrence"",
       title = ""Which words are preferentially used to describe superb or bad wines?"",
       caption = ""Source: Wine Enthusiast - 2017\nVisualization by Bndicte Wenden @cherrysearch"")+
  theme(legend.position = ""bottom"",
        legend.direction = ""horizontal"",
        title = element_text(color = ""#6f5438"", size = 14),
        strip.text = element_text(size = 12, face = ""italic"",color = ""#6f5438""),
        axis.text.y = element_text(size = 10, color = ""#6f5438""),
        plot.background = element_rect(fill = ""#fffeea""),
        axis.line.y.left = element_line(color = ""#6f5438""),
        axis.ticks.y.left = element_blank(),
        panel.spacing.x = unit(2, ""lines""),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.title = element_text(size = 12, color = ""#6f5438""),
        legend.text = element_text(size = 10,color = ""#6f5438"")
  )

ggsave(""TidyTuesday_wines.png"", width = 12, height = 7)
","2019"
"372",1399,"https://github.com/alyssamv/tidytuesdays/blob/master/2019/GlobalWaste_0521/GlobalWaste.Rmd","alyssamv","tidytuesdays","2019/GlobalWaste_0521/GlobalWaste.Rmd","---
title: ""GlobaPlasticWaste""
author: ""Alyssa Vanderbeek""
date: ""5/21/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(countrycode)
library(ggplot2)
library(ggalt)
library(ggthemes)
library(ggpubr)
library(gridExtra)
library(ggrepel)
```

This week's TidyTuesday dataset looks at global plastic waste disposal in 2010. We also get information about county 2011 GDP, and coastal and total population according to Gapminder. Below, I load in the data and create datasets to work with.

```{r data}
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>%
  janitor::clean_names() %>%
  filter(year == 2010)

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>%
  purrr::set_names(c(""entity"", ""code"", ""year"", ""mismanaged_waste_percap"", ""gdp_per_capita"", ""total_pop"")) %>%
  filter(year == 2010) %>%
  dplyr::select(entity, mismanaged_waste_percap, gdp_per_capita)

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>%
  purrr::set_names(c(""entity"", ""code"", ""year"", ""per_capita_plastic"", ""gdp_per_capita"", ""total_pop"")) %>%
  filter(year == 2010) %>%
  dplyr::select(entity, per_capita_plastic)

# code taken from https://github.com/meensrinivasan/tidytuesdaysubmissions/blob/master/nobel/nobel.R. Gets 'codelist' dataset from the countrycode package and 
codes <- codelist %>%
  select(iso3c, country.name.en, region, continent) %>%
  janitor::clean_names() %>%
  filter(!is.na(continent) & !is.na(region)) %>%
  left_join(CoordinateCleaner::countryref %>% 
              select(iso3, capital.lon, capital.lat), by = c(""iso3c"" = ""iso3"")) %>%
  distinct() %>%
  filter(!is.na(capital.lon) & !is.na(capital.lat))

# master data set of waste information for 2010 across three datasets
waste <- coast_vs_waste %>%
  left_join(mismanaged_vs_gdp, by = ""entity"") %>%
  left_join(waste_vs_gdp, by = ""entity"") %>%
  left_join(codes %>%
              dplyr::select(country_name_en, capital.lon, capital.lat, continent), by = c(""entity"" = ""country_name_en"")) %>% # left_join only the long/lat of capital city for each country
  mutate(total_gdp = gdp_per_capita*total_population_gapminder,
         entity = recode(entity, # recode country names in order to match map data below
                         ""United Kingdom"" = ""UK"",
                         ""United States"" = ""USA"",
                         ""Trinidad & Tobago"" = ""Trinidad"",
                         ""Cote d'Ivoire"" = ""Ivory Coast"",
                         ""Democratic Republic of Congo"" = ""Democratic Republic of the Congo"",
                         ""Congo"" = ""Republic of Congo"",
                         ""Hong Kong"" = ""China"",
                         ""British Virgin Islands"" = ""Virgin Islands"",
                         ""Saint Vincent and the Grenadines"" = ""Saint Vincent""),
         percent_mismanaged = mismanaged_waste_percap / per_capita_plastic,
         percent_global_contbn = mismanaged_plastic_waste_tonnes / sum(mismanaged_plastic_waste_tonnes, na.rm = T))

# map data from ggplot
world <- ggplot2::map_data(""world"") %>%
  filter(region != ""Antarctica"") %>%
  left_join(waste, by = c(""region"" = ""entity""))

countries = world %>%
  group_by(region) %>%
  slice(1) %>%
  mutate(percap_waste_cat = cut(mismanaged_waste_percap,
                                breaks = c(0, 0.01, 0.025, 0.05, 0.10, 0.30)),
         percap_waste_cat_rev = forcats::fct_rev(percap_waste_cat))
```

Let's take a look at some of the data.

```{r}
waste %>%
  select(-entity, -code, -capital.lon, -capital.lat, -year) %>%
  skimr::skim()
```

Based on this summary of selected variables (those related to GDP and waste), it looks like there are at least 50 countries with missing information. Let's see which they are.

```{r}
waste %>%
  select(-code, -capital.lon, -capital.lat, -year) %>%
  filter(is.na(mismanaged_plastic_waste_tonnes) | is.na(mismanaged_waste_percap) | is.na(per_capita_plastic)) %>%
  select(entity)
```

So the above countries are missing all information related to all the above areas of interest. I wonder where the countries with missing information fall in terms of GDP and total population. 

```{r}
gdp_quant50 = quantile(waste$total_gdp, na.rm = T)[3]
pop_quant50 = quantile(waste$total_population_gapminder, na.rm = T)[3]

gdp_vs_pop = waste %>%
  mutate(missing = ifelse(is.na(mismanaged_plastic_waste_tonnes) | 
                            is.na(mismanaged_waste_percap) | 
                            is.na(per_capita_plastic), ""Missing"", ""Available"")) %>% 
  ggplot( aes(x = total_population_gapminder, y = total_gdp, color = missing)) +
  geom_point(alpha = 0.8, size = 3) +
  viridis::scale_color_viridis(discrete = T) +
  coord_cartesian(xlim = c(0,25000000), ylim = c(0, 250000000000)) + # zoom in to exclude outliers
  geom_hline(yintercept = gdp_quant50, linetype = ""dashed"", size = 0.25) +
  annotate(""text"", label = ""50th percentile GDP"", x = 2.26*10^7, y = gdp_quant50 + 0.5*10^10, size = 3) +
  labs(
    x = ""Total population, according to Gapminder"",
    y = ""Total GDP (2011)"",
    subtitle = ""Among countries with available GDP, it seems that most of those with missing data on waste and waste\nmanagement (44/49) have annual GDP of $50 billion or less (50th percentile, designated by dashed line)."",
    color = ""Availability of waste data""
  ) +
  theme(axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        plot.title = element_text(size = 20),
        legend.position = ""bottom"",
        panel.background = element_rect(fill = 'grey', colour = ""black""),
        plot.background = element_rect(fill = 'white', colour = 'white'))


gdp_percap_hist = waste %>%
  mutate(missing = ifelse(is.na(mismanaged_plastic_waste_tonnes) | 
                            is.na(mismanaged_waste_percap) | 
                            is.na(per_capita_plastic), ""missing"", ""available"")) %>%
  ggplot(aes(x = gdp_per_capita, fill = missing)) +
  geom_histogram(position = ""dodge"") +
  viridis::scale_fill_viridis(discrete = T) +
  labs(
    x = ""GDP per capita"",
    y = ""Number of countries"",
    subtitle = ""Countries with missing waste and waste management data are skewed more to the left than those with data\navailable; the majority of them have lower GDP per capita."",
    caption = ""Source: Our World in Data \n@VanderbeekAM ""
  ) +
  theme(axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        plot.title = element_text(size = 20),
        legend.position = ""none"",
        panel.background = element_rect(fill = 'grey', colour = ""black""),
        plot.background = element_rect(fill = 'white', colour = 'white'))

cowplot::plot_grid(gdp_vs_pop, gdp_percap_hist, 
                   nrow = 2, 
                   rel_heights = c(2, 1),
                   labels = ""AUTO"")

ggsave(""./figures/GlobalWaste-pop_vs_gdp.png"", height = 12, width = 8)
```

This figure also gives us some information about the distribution of population and GDP across the world. There are some outliers in both, with significantly large population and GDP, not shown in the scatter plot (China, India, and the USA).

Now we can start to look at the waste information for countries where available.

```{r}
# relationship between per capita plastic waste (all) vs GDP per capita
ggplot(waste, aes(x = per_capita_plastic, y = gdp_per_capita)) +
  geom_point()

# relationship between per capita plastic waste (all) vs GDP per capita
ggplot(waste, aes(x = mismanaged_waste_percap, y = gdp_per_capita)) +
  geom_point()

## From this we cal see that there is a trend such that richer countries have less per capita waste (all waste and mismanaged).
```

Now I want to present the above information as a map

```{r}
# China is the leading contributer of mismanaged waste
china = world %>%
  filter(region == ""China"") %>%
  slice(1) %>%
  mutate(label = ""2nd in GDP\n1st in population"")

usa = world %>%
  filter(region == ""USA"") %>%
  slice(1) %>%
  mutate(label = ""1st in GDP\n3rd in population"")

india = world %>%
  filter(region == ""India"") %>%
  slice(1) %>%
  mutate(label = ""3rd in GDP\n2nd in population"")

# # world map
# world %>%
#   mutate(percap_waste_cat = cut(mismanaged_waste_percap,breaks = c(0, 0.01, 0.025, 0.05, 0.10, 0.30)),
#          gdppercap_levels = cut(gdp_per_capita, breaks = quantile(gdp_per_capita, na.rm = T))) %>% # create categorical variable that breaks down the mismanaged waste per cap into discrete intervals
#   ggplot() + 
#   geom_cartogram(
#     map = world,
#     aes(x = long, y = lat, map_id = region, fill = percap_waste_cat),
#     color = ""black"", size = 0.125#, alpha = 0.8
#   ) +
#   viridis::scale_fill_viridis(discrete = T)  +
#   labs(
#     x = NULL, y = NULL,
#     title = ""Mismanaged waste per capita (kg/day) in 2010"",
#     subtitle = """",
#     caption = ""Source: Our World in Data \n@VanderbeekAM "",
#     fill = """"
#     ) +
#   theme_void() +
#   theme(plot.title = element_text(hjust = 0.5, size = 15)) +
#   theme(plot.subtitle = element_text(hjust = 0.5)) +
#   theme(legend.position = ""bottom"") +
#   guides(fill = guide_legend(nrow = 2)) +
#   geom_text(data = china, 
#             aes(x = capital.lon, y = capital.lat, label = ""China""), 
#             nudge_x = -15, nudge_y = -5) + 
#   geom_label(data = china, 
#              aes(x = capital.lon, y = capital.lat, label = label), 
#              size = 2.5, nudge_x = 31, nudge_y = -19) +
#   annotate(""segment"", x = 130, xend = 115, y = 25, yend = 30, colour = ""black"", size = 1)
# 
# ggsave(""./2019/GlobalWaste_0521/mismanaged_waste.png"", width = 14, height = 8)



## create custom legend using geom_bar

# 
# waste_cat_count = countries %>%
#   group_by(percap_waste_cat_rev) %>%
#   summarise(freq = length(percap_waste_cat_rev))
# 
# waste_cat_count %>%
#   ggplot(aes(x = 1, y = freq, fill = percap_waste_cat_rev)) +
#   geom_bar(stat = ""identity"", width = 0.04, color = ""black"", size = 0.2) + 
#   viridis::scale_fill_viridis(direction = -1, discrete = T) +
#   scale_x_continuous(limits = c(0.5, 1.5)) +
#   #coord_flip() + 
#   #theme_void() + 
#   theme(legend.position = ""none"") +
#   geom_text(aes(label = rev(freq)), 
#             position = position_stack(vjust = 0.5)
#             #position = position_dodge(width = 0.1) 
#             #nudge_x = -0.05
# )
# 
# countries %>%
#   left_join(waste_cat_count, by = ""percap_waste_cat"") %>%
#   ggplot(aes(x = 1, y = percap_waste_cat_rev, fill = percap_waste_cat)) +
#   geom_bar(stat = ""identity"", width = 0.05) + 
#   viridis::scale_fill_viridis(discrete = T) +
#   scale_x_continuous(limits = c(0.5, 1.5)) +
#   coord_flip() + 
#   theme_void() + 
#   theme(legend.position = ""none"") +
#   geom_text(aes(label = unique(percap_waste_cat)), vjust=-1)
# 
# data.frame(breaks = c(rep(""0"", 4),
#                       rep(""0.01"", 5),
#                       rep(""0.025"", 6),
#                       rep(""0.05"", 10),
#                       rep(""0.10"", 20),
#                       rep(""0.30"", 60))) %>% # create categorical variable that breaks down the mismanaged waste per cap into discrete intervals
#   ggplot(aes(x = 1, y = breaks, fill = breaks)) +
#   geom_bar(stat = ""identity"", width = 0.05) + 
#   #theme_void() + 
#   viridis::scale_fill_viridis(discrete = T) +
#   scale_x_continuous(limits = c(0.5, 1.5))

```


```{r}
world %>%
  mutate(pct_global_mismanaged_cat = cut(percent_global_contbn, breaks = c(0, 0.0025, 0.005, 0.01, 0.02, 0.06, 0.14))) %>% 
  ggplot() + 
  geom_cartogram(
    map = world,
    aes(x = long, y = lat, map_id = region, fill = pct_global_mismanaged_cat),
    color = ""black"", size = 0.125#, alpha = 0.8
  ) +
  viridis::scale_fill_viridis(discrete = T)  +
  labs(
    x = NULL, y = NULL,
    title = ""In 2010, there was 63,709,265 tonnes of mismanaged plastic waste across the globe."",
    subtitle = ""The map below shows each country's level of contribution to this global total.\nChina stands out as contributing to 13.8% of all mismanaged plastic."",
    caption = ""Source: Our World in Data \n@VanderbeekAM "",
    fill = """"
    ) +
  theme_void() +
  theme(plot.title = element_text(size = 15, face = ""bold""),
        plot.subtitle = element_text(),
        legend.position = ""bottom"",
        plot.background = element_rect(fill = ""beige"")) +
  guides(fill = guide_legend(nrow = 1)) +
  geom_text(data = china, 
            aes(x = capital.lon, y = capital.lat, label = ""China (13.8%)""), 
            fontface = ""bold"", size = 3, nudge_x = -15, nudge_y = -5) + 
  geom_label(data = china, 
             aes(x = capital.lon, y = capital.lat, label = label), 
             size = 2.5, nudge_x = 20, nudge_y = -19) +
  geom_text(data = usa, 
            aes(x = capital.lon, y = capital.lat, label = ""USA (0.4%)""), 
            fontface = ""bold"", color = ""white"", size = 3, nudge_x = -22, nudge_y = 0) + 
  geom_label(data = usa, 
             aes(x = capital.lon, y = capital.lat, label = label), 
             size = 2.5, nudge_x = -50, nudge_y = -10) +
  geom_text(data = india, 
            aes(x = capital.lon, y = capital.lat, label = ""India (0.9%)""), 
            fontface = ""bold"", size = 3, nudge_x = 0, nudge_y = -10) + 
  geom_label(data = india, 
             aes(x = capital.lon, y = capital.lat, label = label), 
             size = 2.5, nudge_x = 0, nudge_y = -20)

ggsave(""./figures/GlobalWaste-pct_global_mismanaged_waste.png"", width = 14, height = 8)
```


```{r}
waste %>%
  select(per_capita_plastic,
         mismanaged_waste_percap,
         gdp_per_capita) %>%
  drop_na() %>% 
  cor() %>%
  corrplot::corrplot(method = ""ellipse"")

countries %>%
  mutate(gdp_cat = cut(gdp_per_capita, breaks = c(660.211, 3479.155, 9942.427, 22740.972, 125140.838))) %>%
  filter(!is.na(continent) & !is.na(gdp_cat)) %>%
  ggplot(aes(y = percent_mismanaged, x = continent, color = gdp_cat)) +
  geom_boxplot(fill = ""white"") +
  geom_point() +
  geom_jitter(width = 0.2, alpha = 0.8) +
  labs(
    x = """",
    y = ""Percent of country's plastic waste that is mismanaged"",
    title = ""Richer countries have more resources to put towards plastic waste management."",
    subtitle = ""We can see below how, globally, the higher a country's GDP per capita, the smaller portion of its plastic waste is mismanaged."",
    color = ""GDP per capita (percentiles)""
  ) +
  scale_color_colorblind(labels = c(""25th percentile"",
                                    ""50th percentile"",
                                    ""75th percentile"",
                                    ""100th percentile"")) +
  theme_bw() +
  theme(legend.position = ""right"",
        plot.title = element_text(size = 15, face = ""bold""))
  
ggsave(""./figures/GlobalWaste-country_pct_mismanaged_boxplot.png"", width = 10, height = 7)
```

","2019"
"373",1400,"https://github.com/alyssamv/tidytuesdays/blob/master/2019/WineRatings_0528/WineRatings.Rmd","alyssamv","tidytuesdays","2019/WineRatings_0528/WineRatings.Rmd","---
title: ""WineRatings""
author: ""Alyssa Vanderbeek""
date: ""5/28/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

library(tidyverse)
library(ggthemes)
library(treemapify)
library(kableExtra)
library(formattable)
library(condformat)
library(ggalluvial)
library(GGally)
```

```{r}
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
  select(-1)

# number of wines by country
n_wines = wine_ratings %>%
  group_by(country) %>%
  summarise(n_wines = n()) %>%
  arrange(desc(n_wines)) %>%
  mutate(tier = NA)

n_wines$tier[1:3] = 1
n_wines$tier[4:12] = 2
n_wines$tier[13:44] = 3

```

Lots of character variables in this dataset. I want to get an idea for the unique values available.

```{r}
unique(wine_ratings$country) # 44 countries
unique(wine_ratings$province) # 426 provinces
sort(unique(wine_ratings$region_1)) # 1230 regions (1). 
sort(unique(wine_ratings$region_2)) # 17 regions (2). 

sort(unique(wine_ratings$variety)) # 707 varieties 

unique(wine_ratings$taster_name) # 19 different tasters
```

Off the bat I know that I want to classify each wine as red, white, rose, or sparkling, but I will need some externl dataset for that. There are too many (707) individual varieties for me to manually classify. Perhaps I could take only the most well-known varieties and classify them manually.

Now to look at the distributions of the numeric values (price and points):

```{r}
wine_ratings %>%
  select(price, points) %>%
  skimr::skim() # points are approx normal. price seems skewed; closer look

prices = wine_ratings %>%
  group_by(country) %>%
  mutate(med_price = median(price, na.rm = T)) %>%
  ungroup() %>%
  filter(!is.na(med_price))  %>%
  left_join(n_wines %>% select(country, tier), by = ""country"") %>%
  mutate(country = fct_reorder(country, med_price))

global_median_price = median(prices$med_price)

prices %>%
  filter(country != ""NA"") %>%
  ggplot(aes(y = log(price), x = country, fill = ""grey"")) +
  geom_boxplot() +
  geom_hline(yintercept = log(global_median_price)) +
  scale_fill_identity() +
  scale_x_discrete()  +
#  annotate(""text"", y = 6, x = 30, label = ""test"") +
  facet_grid(tier~., scales = ""free_y"", space = ""free_y"") +
  theme_bw() +
  labs(
    x = NULL,
    y = ""Bottle price (log-scale)"",
    title = ""The global median price of a bottle of wine is $28."",
    subtitle = ""The distribution of wine price by country is shown below in log-scale. Note how the\nmajority of each country's price distribution falls below the global median, even in log-scale.\nThis suggests a highly skewed pricing, which is reflected in that out of 130k wines, only a\nhandful cost more than a few hundred dollars. Countries that produce more wine\n(Tiers 1, 2) are most responsible for this skew."",
    caption = ""Data Source: WineEnthusiast \nTwitter: @VanderbeekAM ""
  ) +
  coord_flip() +
  theme(plot.title = element_text(size = 15, face = ""bold""),
        plot.subtitle = element_text(size = 9),
        axis.text.y = element_text(size = 10, face = ""bold""),
        panel.grid = element_blank())

ggsave(""./figures/WineRatings_boxplot_countryprice.png"", height = 10, width = 7)
```

Price is pretty skewed, so I will either use a log-scale or create a categorical variable with intervals when using price in any analysis/viz.

Now I want to check how many wines fall into different categories:
```{r}
sort(table(wine_ratings$country)) # this could be displayed as a tree plot


# viz as treemap
ggplot(n_wines, aes(area = n_wines, fill = n_wines, label = country,
                    subgroup = tier)) +
  treemapify::geom_treemap() +
  geom_treemap_text(colour = ""white"", 
                    place = ""centre"", 
                    grow = TRUE) +
  geom_treemap_subgroup_border(color = ""black"") +
  scale_fill_gradient2(midpoint = 25000) +
  labs(fill = ""Number of wines"",
       title = ""The US, France, and Italy produce the majority of wines being rated."",
       subtitle = ""Out of 44 countries, the US leads with 54,504 wines, followed by France (22,093) and Italy (19,540).\nChina, Egypt, and Slovakia each produced one wine."",
    caption = ""Data Source: WineEnthusiast \nTwitter: @VanderbeekAM ""
    ) +
  theme(plot.title = element_text(size = 15, face = ""bold""))

ggsave(""./figures/WineRatings_treemap_nwines.png"", width = 8, height = 6)
```


The distribution of counts for wine variety are very skewed, even in log-scale.

```{r}
sort(table(wine_ratings$variety), decreasing = F)# top 3 varieties: Pinot Noir, Chardonnay, Cabernet Sauvignon
```


Looking at the different wine tasters, not all tasters try wines from all available countries. Some specialize, such as Alexander Peartree, who tried 415 wines only from the US. Roger Voss tried the most wines, at 25,514. 

```{r}
table(wine_ratings$taster_name, wine_ratings$country) %>% View

sort(table(wine_ratings$taster_name))

wine_ratings %>%
  filter(!is.na(taster_name)) %>%
  group_by(taster_name) %>%
  summarise(n_wines = n(),
            avg_rating = mean(points)) %>%
  arrange(desc(n_wines))


wine_ratings %>%
  filter(!is.na(taster_name)) %>%
  ggplot(aes(y = points, x = taster_name)) +
  geom_violin() +
  coord_flip()
```

What are the distribution of ratings for different countries?
```{r}

  
wine_ratings %>%
  filter(country %in% n_wines$country[1:10]) %>% 
  left_join(n_wines, by = ""country"") %>%
  arrange(desc(n_wines)) %>%
  mutate(country = reorder(as.factor(country), n_wines)) %>% # order countries by number of wines 
  ggplot(aes(y = points, x = country, fill = country)) +
  geom_violin() +
  geom_hline(yintercept = median(wine_ratings$points), linetype = ""dashed"") +
  viridis::scale_fill_viridis(discrete = T, alpha = 0.9) +
  labs(
    y = ""Rating"",
    x = NULL,
    title = ""Distribution of wine ratings for the top 10 wine producers."",
    subtitle = ""Countries are sorted by number of wines produced; US with the most (54,504),\nGermany with the least (2,165). The dashed line designates the global median rating (88)."",
    caption = ""Data Source: WineEnthusiast \nTwitter: @VanderbeekAM ""
    ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = ""none"",
        axis.text.y = element_text(size = 10, face = ""bold""),
        axis.text.x = element_text(size = 12),
        plot.title = element_text(size = 15, face = ""bold""))

ggsave(""./figures/WineRatings_country_rating_dist.png"", height = 10, width = 7)
```

I'm going to group countries into tiers, based on the number of wines produced. Then I can look at ratings by tier.

```{r}


taster_ratings_tier = wine_ratings %>%
  left_join(n_wines, by = ""country"") %>%
  group_by(taster_name, tier) %>%
  summarise(n = n(),
            avg_rating = mean(points)) 

plot_table = taster_ratings_tier %>%
  select(-avg_rating) %>%
  spread(key = tier, value = n, fill = ""--"") %>%
  left_join(taster_ratings_tier %>%
              select(-n) %>%
              mutate(avg_rating = round(avg_rating, 2)) %>%
              spread(key = tier, value = avg_rating, fill = ""--""), 
            by = ""taster_name"") %>%
  left_join(wine_ratings %>%
              left_join(n_wines, by = ""country"") %>%
              group_by(taster_name) %>%
              summarise(n = n(),
                        avg_rating = round(mean(points), 2)),
            by = ""taster_name"") %>%
  mutate(`1.x` = ifelse(`1.y` == ""--"", `1.y`, paste0(`1.y`, ""\n("", `1.x`, "")"")),
         `2.x` = ifelse(`2.y` == ""--"", `2.y`, paste0(`2.y`, ""\n("", `2.x`, "")"")),
         `3.x` = ifelse(`3.y` == ""--"", `3.y`, paste0(`3.y`, ""\n("", `3.x`, "")"")),
         n = ifelse(avg_rating == ""--"", avg_rating, paste0(avg_rating, ""\n("", n, "")""))) %>%
  `colnames<-`(c(""Taster"", ""Tier 1"", ""Tier 2"", ""Tier 3"", ""one"", ""two"", ""three"" , ""Overall average rating"", ""overall_r"")) 


# avg_row = data.frame(Taster = ""All tasters"", 
#             one = sum(as.numeric(plot_table$one), na.rm = T), 
#             two = sum(as.numeric(plot_table$two), na.rm = T), 
#             three = sum(as.numeric(plot_table$three), na.rm = T), 
#             'Tier_1' = mean(as.numeric(plot_table$`Tier_1`), na.rm = T), 
#             `Tier_2` = mean(as.numeric(plot_table$`Tier_2`), na.rm = T), 
#             `Tier_3` = mean(as.numeric(plot_table$`Tier_3`), na.rm = T), 
#             overall_n = sum(as.numeric(plot_table$overall_n)), 
#             Overall = mean(as.numeric(plot_table$Overall), na.rm = T))
# 
# do.call(cbind, c(as.data.frame(plot_table), avg_row)) %>% View

condformat(plot_table) %>%
  rule_fill_gradient(columns = `Tier 1`, 
                     expression = as.numeric(one), 
                     #limits = c(1, 25537), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  rule_fill_gradient(columns = `Tier 2`, 
                     expression = as.numeric(two), 
                     #limits = c(1, 25537), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  rule_fill_gradient(columns = `Tier 3`, 
                     expression = as.numeric(three), 
                     #limits = c(1, 25537), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  rule_fill_gradient(columns = `Overall average rating`, 
                     expression = as.numeric(overall_r), 
                     #limits = c(1, 26244), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  show_columns(columns = c(8, 1, 2:4)) %>%
  theme_htmlTable(caption = ""Average ratings by tasters. Tiers are defined by the number of wines contributed (by country). The number of wines tasted by the taster is given in parentheses. A total of 129,971 wines were rated in the dataset: 96,137 in Tier 1 (producing more than 10,000 wines); 31,267 in Tier 2 (producing between 1,000 and 10,000 wines); 2,567 in Tier 3 (producing less than 1,000 wines). Tier 1 wines seem to have higher average ratings than lower tiers, though these differences are slight."")

```

Last thing I will do today is make a parallel plot.

```{r}
ggplot(wine_ratings, aes(x = ))
```

","2019"
"374",1406,"https://github.com/kylie-foster/tidy_tuesday/tree/master/Week21_2019","kylie-foster","tidy_tuesday","Week21_2019/plastic_waste.R","library(tidyverse)
library(countrycode)
library(cowplot)
#### Importing and transforming data ####

# reading in file containing data for mismanaged plastic waste:
mismanaged_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>%
  # there are a lot of missing values and the variables need renaming
  set_names(c(""country"", ""code"", ""year"", ""mismanaged_waste"", ""GDP"", ""population"")) %>% # renaming variables
  mutate_if(is.character, as.factor) # converting characters to factors
mismanaged_vs_gdp <- mismanaged_vs_gdp[complete.cases(mismanaged_vs_gdp[ , 4]),] # removing any observations that contain N/A for mismanaged_waste


# reading in file containing data for all plastic waste:
waste_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>%
  set_names(c(""country"", ""code"", ""year"", ""waste"", ""GDP"", ""population"")) %>% # renaming variables
  mutate_if(is.character, as.factor) # converting characters to factors
waste_vs_gdp <- waste_vs_gdp[complete.cases(waste_vs_gdp[ , 4]),] # removing any observations that contain N/A for waste
# There is really only waste data available for 2010.


#### Transforming plastic waste data for lollipop chart ####
waste_vs_gdp <- filter(waste_vs_gdp, country != ""Trinidad and Tobago"") # removing Trinidad and Tobago because this outlier seems too large to be correct.

mean_country <- mean(waste_vs_gdp$waste) # mean value of plastic waste for all countries

waste_vs_gdp <- mutate(waste_vs_gdp, region = countrycode(country, origin = ""country.name"", 
                                                          destination = ""continent"")) # adding geographical regions
# Grouping and calculating average waste per region:
group_waste_vs_gdp <- group_by(waste_vs_gdp, region) %>%
  summarise(mean_region = mean(waste)) %>% # calculating mean waste per region 
  mutate(region = fct_reorder(region, mean_region)) %>% # sorting regions by mean waste
  mutate(region_cat = as.factor(case_when(mean_region < mean_country ~ ""below"",
                                          TRUE ~ ""above""))) # add category specifying if waste level is above or below average

# adding a category specifying if waste level is above or below average to the country level data
waste_vs_gdp <- mutate(waste_vs_gdp, country_cat = as.factor(case_when(waste < mean_country ~ ""below"", 
                                                                       TRUE ~ ""above"")))

#### Transforming mismanaged plastic waste data for lollipop chart ####
mismanaged_vs_gdp <- filter(mismanaged_vs_gdp, country != ""Trinidad and Tobago"") # removing Trinidad and Tobago

mean_mismanaged_country <- mean(mismanaged_vs_gdp$mismanaged_waste)# mean value of mismanaged plastic waste for all countries

mismanaged_vs_gdp <- mutate(mismanaged_vs_gdp, region = countrycode(country, origin = ""country.name"", 
                                                                    destination = ""continent"")) # adding geographical regions

# Grouping and calculating average mismanaged waste per region:
group_mismanaged_vs_gdp <- group_by(mismanaged_vs_gdp, region) %>%
  summarise(mean_mismanaged_region = mean(mismanaged_waste)) %>% # calculating mean mismanaged waste per region
  mutate(region = fct_reorder(region, mean_mismanaged_region)) %>% # sorting regions by mean mismanaged waste
  mutate(mis_region_cat = as.factor(case_when(mean_mismanaged_region < mean_mismanaged_country ~ ""below"",
                                              TRUE ~ ""above""))) # add category specifying if waste level is above or below average

# adding a category specifying if waste level is above or below average to the country level data
mismanaged_vs_gdp <- mutate(mismanaged_vs_gdp, mis_country_cat = as.factor(case_when(mismanaged_waste < mean_mismanaged_country ~ ""below"", 
                                                                                     TRUE ~ ""above"")))

#### Coordinates for arrow labels ####
arrows <- tibble(
  y1 = c(0.4, 0.35, 0.5),
  y2 = c(mean_country, 0.2, 0.38),
  x1 = c(0.8, 4.3, 2.7),
  x2 = c(0.6, 4, 2)
)

#### Lollipop chart of plastic waste ####
set.seed(1) # for jitter
plot_waste <- ggplot()+
  geom_point(data = filter(group_waste_vs_gdp, region != ""NA""),
             aes(x = region, y = mean_region, colour = region_cat), stat='identity', size=5)  +
  geom_segment(data = filter(group_waste_vs_gdp, region != ""NA""),
               aes(y = mean_country, 
                   x = region, 
                   yend = mean_region, 
                   xend = region,
                   color = region_cat),
               size = 1) +
  geom_jitter(data = filter(waste_vs_gdp, region != ""NA""),
              mapping = aes(x = region, y = waste, color = country_cat),
              stat = ""identity"",
              width = 0.2, size = 2, alpha = 0.25) + 
  scale_color_manual(name=""Plastic Waste"", 
                     labels = c(""Above Average"", ""Below Average""), 
                     values = c(""above""=""tan4"", ""below""=""green4"")) + 
  labs(title=""Per capita plastic waste"", 
       x = """",
       y = ""Mean regional per capita plastic waste \nminus mean for all countries \n(kg per person per day)"",
       caption = ""\n"") + 
  coord_flip() +
  theme_bw() +
  theme(legend.position = ""none"",
        axis.title.x = element_text(size = 10),
        plot.subtitle = element_text(size = 8),
        panel.grid = element_blank()) +
  geom_hline(yintercept = mean_country, linetype = ""dashed"", colour = ""black"") +
  annotate(""text"", y = 0.4, x = 0.9, size = 2.7, color = ""grey20"",
           label = ""Global average"") +
  annotate(""text"", y = 0.35, x = 4.5, size = 2.7, color = ""grey20"",
           label = ""Regional average"") +
  annotate(""text"", y = 0.5, x = 2.8, size = 2.7, color = ""grey20"",
           label = ""Individual countries"")+ 
  geom_curve(data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2),
             arrow = arrow(length = unit(0.07, ""inch"")), size = 0.4,
             color = ""grey20"", curvature = -0.3)

#### Lollipop chart of mismanaged plastic waste ####
set.seed(1) # for jitter
plot_mis_waste <- ggplot() + 
  geom_point(data = filter(group_mismanaged_vs_gdp, region != ""NA""), 
             aes(x = region, y = mean_mismanaged_region, colour = mis_region_cat), 
             stat='identity', size=5)  +
  geom_segment(data = filter(group_mismanaged_vs_gdp, region != ""NA""),
               aes(y = mean_mismanaged_country, 
                   x = region, 
                   yend = mean_mismanaged_region, 
                   xend = region,
                   color = mis_region_cat),
               size = 1) +
  geom_jitter(data = filter(mismanaged_vs_gdp, region != ""NA""),
              mapping = aes(x = region, y = mismanaged_waste, color = mis_country_cat),
              stat = ""identity"",
              width = 0.2, size = 2, alpha = 0.25) +
  scale_color_manual(name=""Plastic Waste"", 
                     labels = c(""Above \nAverage"", ""Below \nAverage""), 
                     values = c(""above""=""tan4"", ""below""=""green4"")) + 
  labs(title=""Per capita mismanaged plastic waste"", 
       x = """",
       y = ""Mean regional per capita mismanaged plastic \nwaste minus mean for all countries \n(kg per person per day)"",
       caption = ""Mismanaged waste is material that is littered or inadequately disposed of. \nSource of data: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-05-21"") + 
  coord_flip() +
  theme_bw() +
  theme(axis.title.x = element_text(size = 10),
        plot.subtitle = element_text(size = 8),
        panel.grid = element_blank()) +
  geom_hline(yintercept = mean_mismanaged_country, linetype = ""dashed"", colour = ""black"") +
  annotate(""text"", y = 0.23, x = 4.35, size = 2.7, color = ""grey20"",
           label = ""Regions with low overall \nplastic waste have high \nlevels of mismanaged \nplastic waste"") 

comb <- plot_grid(plot_waste, plot_mis_waste, rel_widths = c(1, 1.35))
ggsave(""Week21_2019/plastic_waste.png"", comb, width = 20, height = 12, units = ""cm"")

","2019"
"375",1407,"https://github.com/kylie-foster/tidy_tuesday/tree/master/Week20_2019","kylie-foster","tidy_tuesday","Week20_2019/app.R","library(shiny)
library(plotly) # for interactive plots
library(tidyverse)
library(tm) # for text mining
library(wordcloud) # word-cloud generator
library(RColorBrewer) # color palettes
library(shinycustomloader) # for loading symbols

## Importing data -----
nobel_winners <-
  read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv""
  ) %>%
  mutate_if(is.character, as.factor) # converting all character variables to factors

## Function to prepare text to generate wordcloud -----
# (Original source of code 
# http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know)
cloud_prep_function <- function(txt) {
  docs <- Corpus(VectorSource(txt))
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove english common stopwords
  docs <- tm_map(docs, removeWords, stopwords(""english""))
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  
  dtm <- TermDocumentMatrix(docs)
  m <- as.matrix(dtm)
  v <- sort(rowSums(m), decreasing = TRUE)
  d <- data.frame(word = names(v), freq = v)
  return(d)
}


# Define UI  -----
ui <- fluidPage(
  
  # App title -----
  titlePanel(strong(""Nobel Prize Winners and Gender"")),
  h2(
    ""Comparison of the number of male and female Nobel Prize winners over time""
  ),
  
  # First row containing slider, line plot and bar plot -----
  fluidRow(
    column(2,
           wellPanel(
             h4(""Far fewer women than men have been awarded a Nobel Prize.""),
             h4(
               ""The disparity between genders has only slightly decreased over time.""
             ),
             h4(
               ""The distribution of awards between categories also differs between genders.""
             ),
             h4(strong(
               ""Use the slide below to explore how this changes over time.""
             )),
             
             # Slider to select year for plots in top row -----
             sliderInput(
               inputId = ""year"",
               label = ""Year"",
               min = 1901,
               max = 2016,
               value = c(1901, 2016),
               step = 1,
               sep = """" # to remove comma seperator
             )
           )
    ),
    column(
      4,
      
      # inserting a plotly line chart -----
      withLoader(
        plotlyOutput( 
          outputId = ""line""
        ), 
        type=""html"", 
        loader=""loader6"")
      
    ),
    column(6,
           
           # inserting a bar chart with loading symbol -----
           withLoader(plotOutput(outputId = ""bar""), type=""html"", loader=""loader6"")
    )
  ),
  h2(
    ""Comparison of popular words used in the award motivation for females and males""
  ),
  
  # Second row containing selection boxes and two word clouds -----
  fluidRow(
    column(2,
           wellPanel(
             h4(
               ""The word clouds highlight the most popular words used in
                        the descriptions of why the recipients were awarded their Prize.""
             ),
             h4(
               strong(
                 ""Choose different categories below to compare popular words for a specific prize category.""
               )
             ),
             selectInput('prize_cat', 'Prize Category', c(""All"", as.character(unique(nobel_winners$category)))
             ),
             h4(
               ""'Discovery', 'discoveries' and 'work' were frequently used for both females and males.""
             ),
             h4(
               ""'Rights' and 'struggle' were frequently used for females but not males.""
             )
           )
    ),
    column(
      5,
      h3(""Female"", align = ""center""),
      
      # Inserting word cloud for words associated with females (including loading symbol)
      withLoader(
        plotOutput(
          outputId = ""cloud_female"",
          width = ""100%"",
          height = ""550px""
        ), 
        type=""html"", 
        loader=""loader6"")
      
    ),
    column(
      5,
      h3(""Male"", align = ""center""),
      
      # Inserting word cloud for words associated with males (including loading symbol)
      withLoader(
        plotOutput(
          outputId = ""cloud_male"",
          width = ""100%"",
          height = ""550px""
        ), 
        type=""html"", 
        loader=""loader6"")
      
    )
  )
)

# Define server logic ----
server <- function(input, output) {
  
  # Bar chart -----
  output$bar <- renderPlot({
    nobel_count <-
      filter(nobel_winners,
             between(prize_year, input$year[1], input$year[2])) %>%
      group_by(gender, category) %>%
      summarise(count_prize = n()) %>%
      na.omit()
    
    ggplot(data = nobel_count, aes(x = category, y = count_prize, fill = gender)) +
      geom_col() +
      facet_wrap( ~ gender) +
      theme_bw() +
      theme(text = element_text(size = 25),
            legend.position = ""left"") +
      labs(y = ""Number of Nobel Prizes"",
           x = ""Prize Category"",
           fill = ""Gender"") +
      scale_fill_manual(values = c(""#ff7f00"", ""#377eb8"")) +
      coord_flip()
    
    
  })
  
  # Interactive line chart -----
  output$line <-
    renderPlotly({
      nobel_winners_group <-
        filter(nobel_winners,
               between(prize_year, input$year[1], input$year[2])) %>%
        group_by(prize_year, gender) %>%
        summarise(count_prize = n()) %>%
        na.omit()
      
      nobel_winners_group_male <-
        filter(nobel_winners_group, gender == ""Male"")
      nobel_winners_group_female <-
        filter(nobel_winners_group, gender == ""Female"")
      
      #Need to add zeros for years with data for males but not females
      add_zero <-
        filter(nobel_winners,
               gender == ""Male"",
               between(prize_year, input$year[1], input$year[2])) %>%
        select(prize_year) %>%
        unique %>%
        mutate(gender = as.factor(""Female""), count_prize = 0)
      
      add_zero <-
        anti_join(add_zero, nobel_winners_group_female, by = ""prize_year"") # selecting columns that should be zero
      nobel_winners_group_female <-
        merge(add_zero,
              nobel_winners_group_female,
              all.x = TRUE,
              all.y = TRUE)
      
      p <- plot_ly(
        x = nobel_winners_group_male$prize_year,
        y = nobel_winners_group_male$count_prize,
        type = ""scatter"",
        mode = ""markers"",
        fill = ""tonexty"",
        name = 'Male'
      ) %>%
        add_trace(
          x = nobel_winners_group_female$prize_year,
          y = nobel_winners_group_female$count_prize,
          type = ""scatter"",
          mode = ""markers"",
          fill = ""tozeroy"",
          name = 'Female'
        ) %>%
        layout(
          xaxis = list(title = ""Year""),
          yaxis = list(title = ""Number of Nobel Prizes"")
        )
      hide_legend(p)
    })
  
  # Female word clouds -----
  output$cloud_female <- renderPlot({
    if (input$prize_cat == ""All"") {
      txt_female <- filter(nobel_winners, gender == ""Female"") %>%
        select(motivation) %>%
        .$motivation %>%
        as.character
    } else{
      txt_female <-
        filter(nobel_winners,
               category == input$prize_cat,
               gender == ""Female"") %>%
        select(motivation) %>%
        .$motivation %>%
        as.character
    }
    
    cloud_data_female <- cloud_prep_function(txt_female)
    
    set.seed(1234)
    col_orange <- brewer.pal(8, ""Oranges"")
    wordcloud(
      words = cloud_data_female$word,
      freq = cloud_data_female$freq,
      min.freq = 1,
      max.words = Inf,
      random.order = FALSE,
      rot.per = 0,
      colors = col_orange[4:8],
      fixed.asp = FALSE
    )
  })
  
  # Male word clouds -----
  output$cloud_male <- renderPlot({
    if (input$prize_cat == ""All"") {
      txt_male <- filter(nobel_winners, gender == ""Male"") %>%
        select(motivation) %>%
        .$motivation %>%
        as.character
    } else{
      txt_male <-
        filter(nobel_winners,
               category == input$prize_cat,
               gender == ""Male"") %>%
        select(motivation) %>%
        .$motivation %>%
        as.character
    }
    
    
    cloud_data_male <- cloud_prep_function(txt_male)
    set.seed(1234)
    col_blue <- brewer.pal(8, ""Blues"")
    wordcloud(
      words = cloud_data_male$word,
      freq = cloud_data_male$freq,
      min.freq = 1,
      max.words = Inf,
      random.order = FALSE,
      rot.per = 0,
      colors = col_blue[4:8],
      fixed.asp = FALSE
    )
  })
}

# Run the app ----
shinyApp(ui = ui, server = server)
","2019"
"376",1408,"https://github.com/kylie-foster/tidy_tuesday/tree/master/Week19_2019","kylie-foster","tidy_tuesday","Week19_2019/code_plot.R","library(tidyverse)
library(ggalt) # for ggalt
library(ggthemes)

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"") %>%
  mutate_if(is.character, as.factor) %>%# converting characters to factors
  filter(grepl('income', country)) %>% # selecting only those observations that include ""income""
  filter(year %in% c(2017, 2012)) %>% # selecting the highest and lowest years to use as endpoints of dumbbell plot
  rename(value = student_ratio) %>% # renaming student_ratio variable to prevent confusion with dataframe name
  select(indicator, country, year, value) %>%
  spread(key = year, value = value) %>%
  rename(year_2012 = ""2012"", year_2017 = ""2017"") %>%
  mutate(country = str_remove(country, ""income countries""))

student_ratio$indicator <- factor(student_ratio$indicator, 
                                  levels = c(""Pre-Primary Education"", ""Primary Education"",
                                             ""Lower Secondary Education"", ""Secondary Education"",
                                             ""Upper Secondary Education"")) # reordering 

student_ratio_long <- gather(student_ratio, year_2012, year_2017, key = year, value = value) %>%
  mutate_if(is.character, as.factor) # converting dataframe back to long form (required for legend)


# choosing colours:
col_line <- ""gray"" #line colour
col_2012 <- ""#a3c4dc"" #light blue, 2012 
col_2017 <- ""#0e668b"" # dark blue, 2017

# Plotting:
ggplot() +
  geom_dumbbell(data = student_ratio, 
                aes(y = fct_rev(fct_reorder(country, year_2012)), x = year_2012, xend = year_2017),
                colour = col_line, colour_x = col_2012, colour_xend = col_2017, size = 1.5) +
  geom_point(data = student_ratio_long, aes(x = value, y = country, colour = year), size = 3.5) + # required because 
  # geom_dumbell does not provide a legend option
  facet_wrap( ~ indicator, ncol = 2) +
  labs(title = ""Change in student to teacher ratios from 2012 to 2017"",
       subtitle = ""Some ratios increased between 2012 and 2017"",
       x = ""Student to Teacher Ratio (lower = fewer students per teacher)"",
       y = ""Country Income Level"",
       caption = ""Source of data: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-05-07"") +
  theme_bw(base_size = 15) +
  theme(legend.position = c(0.75, 0.15)) +
  scale_color_manual(values = c(""#a3c4dc"", ""#0e668b""), label = c(""2012"", ""2017""))

ggsave(""Week19_2019/student_teacher_ratios.png"", height = 10, width = 8)



","2019"
"377",1409,"https://github.com/kylie-foster/tidy_tuesday/tree/master/Week22_2019","kylie-foster","tidy_tuesday","Week22_2019/wine_ratings_ggridges_unused.R","library(tidyverse)
library(ggridges)

wine_ratings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
  mutate_if(is.character, as.factor) %>%
  mutate(value = points/price) 

wine_ratings_group <- group_by(wine_ratings, taster_name)
delay <- summarise(wine_ratings_group,
                   count = n(),
                   med_value = median(value, na.rm = TRUE)
                   )
delay <- filter(delay, count > 100) %>%
  na.omit() 

name_order <- levels(fct_reorder(factor(delay$taster_name), delay$med_value)) # extra factor() is required to remove 
# extra levels that are no longer present

# remove data points for reviewers with a small number of ratings
ggplot(data = filter(wine_ratings, taster_name %in% name_order), aes(x = value, y = fct_relevel(taster_name, name_order))) + 
  stat_density_ridges(quantile_lines = TRUE, quantiles = 2, scale = 2, rel_min_height = 0.01)+ 
  theme_ridges() +
  xlim(0, 15)

","2019"
"378",1410,"https://github.com/kylie-foster/tidy_tuesday/tree/master/Week22_2019","kylie-foster","tidy_tuesday","Week22_2019/wine_ratings_map.R","# TidyTuesday 2019 - Week 22
# Kylie Foster

# Loading libraries
library(tidyverse)
library(magrittr)
library(ggmap)
library(maps)
library(RColorBrewer)
library(viridis)
library(ggrepel)

# I found last weeks TidyTuesday code by Dewi Koning very useful: 
# https://github.com/KoningD/TidyTuesday/blob/master/2019_Week20/TidyTuesday_2019_Week20.R

# Loading data
wine_ratings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
  mutate_if(is.character, as.factor) %>%
  mutate(value = points/price) %>% #  creating new variable that represents value for money
  drop_na(country) #  removing any rows containing missing countries

# Calculating median value for each country
wine_ratings_country <- group_by(wine_ratings, country) %>%
  summarise(med_value = median(value, na.rm = TRUE)) %>%
  drop_na(med_value) %>% #  removing any rows containing missing values
  mutate(country = case_when(country == ""US"" ~ ""USA"", #  changing US to USA to match map_data
                             country == ""England"" ~ ""UK"", #  changing to match map_data (not quite equivalent)
                             TRUE ~ as.character(country))) 
  
# Loading world map and removing Antarctica
world_map <- map_data(""world"") %>% 
  filter(region != ""Antarctica"")

# Checking that all country names in wine_ratings_country and world_map match
test <- inner_join(wine_ratings_country, world_map, by = c(""country"" = ""region""))
length(unique(test$country))
length(unique(wine_ratings_country$country))

# Joining wine and world map data
wine_map <- right_join(wine_ratings_country, world_map, by = c(""country"" = ""region""))

# Make a dataframe with the country with the highest value for money in order to plot these as geom_label
wine_ratings_country_top <- wine_ratings_country %>% 
  top_n(1, med_value) %>%
  left_join(world_map, by = c(""country"" = ""region"")) %>% 
  group_by(country) %>% 
  top_n(1, lat) %>% 
  mutate(label_text = paste0(country, "": "", round(med_value, 1)))


# Make a dataframe with the country with the lowest value for money in order to plot these as geom_label
wine_ratings_country_bottom <- wine_ratings_country %>% 
  top_n(-1, med_value) %>%
  left_join(world_map, by = c(""country"" = ""region"")) %>% 
  group_by(country) %>% 
  top_n(1, lat) %>% 
  mutate(label_text = paste0(""England: "", round(med_value, 1)))

# Combining above two dataframes to that we can use ggrepel later
wine_ratings_country_both <- rbind(wine_ratings_country_top, wine_ratings_country_bottom)

# Manually binning and labelling data into discrete bins for different value ranges
wine_map$med_value_split <- factor(
  cut(wine_map$med_value, c(0, 3, 4, 5, 10)),
  labels = c(""Under 3"", ""3 to 4"", ""4 to 5"", ""5 to 10"")
)

# Choosing nice colors
col_purple <- c(""#b3cde3"", ""#8c96c6"", ""#8856a7"", ""#810f7c"", ""white"")

set.seed(1)
# Generate world map plot 
wine_map %>%
  ggplot(aes(x=long, y = lat, group = group, fill = med_value_split)) + 
  geom_polygon(color = ""grey10"", size = 0.01) +
  coord_fixed() +
  scale_fill_manual(values = col_purple) +
  theme_void() +
  theme(plot.title = element_text(size = 12, face = ""bold""),
        plot.margin = unit(c(0, 0.25, 0.0, 0.25), ""in""),
        panel.border = element_rect(fill = NA, colour = ""#cccccc""),
        legend.text = element_text(size = 8),
        legend.position = ""bottom"",
        plot.subtitle = element_text(lineheight = 0.5)) +
  labs(title = ""Which country of origin makes wine with the highest value for money?"",
     subtitle = ""This map shows the median value for money for wine from each country of origin calculated as the 
     \nnumber of points WineEnthusiast rated the wine divided by the price of the wine. 
     \nRomania makes wine with the highest value for money, while England makes wine with the lowest."",
     caption = ""By Kylie Foster. Source of data: Kaggle"", 
     fill = ""Median Value for Money \n(Wine Rating per $ Price)"") +
  geom_label_repel(data = wine_ratings_country_both, 
                   aes(x=long, y = lat, label = label_text, group = group), 
                   fill = c(col_purple[4], col_purple[1]), 
                   fontface = ""bold"", force = 10, size = 3,
                   nudge_y = 15)

ggsave(""./Week22_2019/wine_ratings_map.png"", dpi = 300, width = 20, height = 12, units = ""cm"")
 

","2019"
"379",1411,"https://github.com/andrewgeisler/tidytuesday-projects/blob/master/2019-05-21/global_plastic_waste_explore.R","andrewgeisler","tidytuesday-projects","2019-05-21/global_plastic_waste_explore.R","library(tidyverse)
library(lubridate)
library(ggplot2)
library(gganimate)
library(countrycode)
library(png)
library(ggridges)


### READ DATA SETS ---
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

####
# For Year 2010 Extract
# - Total population
# - Tonnes of Mismanaged Waste
# - Per Capita Mismanged Waste
# - Per Capita GPD
# - Per Capita Waste

df_total_pop_2010 <- coast_vs_waste %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Total population (Gapminder)`
  )

df_plaste_waste_tonnes_2010 <- coast_vs_waste %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Mismanaged plastic waste (tonnes)`
  )

df_mismanged_waste_2010 <- mismanaged_vs_gdp %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Per capita mismanaged plastic waste (kilograms per person per day)`
  )

df_gpd_2010 <- mismanaged_vs_gdp %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `GDP per capita, PPP (constant 2011 international $) (Rate)`
  )

df_waste_per_cap_2010 <- waste_vs_gdp %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Per capita plastic waste (kilograms per person per day)`
  )

### CREATE DF FOR JOINED 2010 DATA
df_2010 <- reduce(
  list(df_gpd_2010, df_mismanged_waste_2010, df_plaste_waste_tonnes_2010, df_total_pop_2010, df_waste_per_cap_2010),
  left_join
)

### LOOK UP COUNTRY CODE
df_2010 <- df_2010 %>%
  mutate(
    Continent = countrycode(Code, origin = ""iso3c"", destination = ""continent""),
    Continent = factor(Continent),
    Year = factor(Year)
  ) %>%
  filter(!is.na(Continent))

### FUNCTION TO REPLACE NA'S WITH MEIAN VALUES
f_replace_na_with_median <- function(x) {
  median <- median(x, na.rm = T)
  case_when(is.na(x) ~ median, TRUE ~ x)
}

### INPUT MISING VALUES STRATIFIED BY CONTINENT

df_2010 <- df_2010 %>%
  group_by(Continent) %>%
  mutate_if(is.numeric, f_replace_na_with_median)

## CODE TTO HAS AN EXTREMELY UNUSUAL PER CAPITA WASTE.
## REPLACING WITH CONTINENT MEDIA
df_2010 <- df_2010 %>%
  group_by(Continent) %>%
  mutate(`Per capita plastic waste (kilograms per person per day)` = case_when(
    Code == ""TTO"" ~ median(`Per capita plastic waste (kilograms per person per day)`),
    TRUE ~ `Per capita plastic waste (kilograms per person per day)`
  ))

## CALCULATE PERCENT OF WASTE THAT IS MISMANAGED
df_2010 <- df_2010 %>%
  mutate(
    `Per Capita Mismanged Waste Percent` =
      `Per capita mismanaged plastic waste (kilograms per person per day)` / `Per capita plastic waste (kilograms per person per day)`
  )

### CUT GDP INTO QUANTILES
df_2010 <- df_2010 %>%
  ungroup() %>%
  mutate(
    `GDP Quantile` = cut(`GDP per capita, PPP (constant 2011 international $) (Rate)`,
      breaks = quantile(`GDP per capita, PPP (constant 2011 international $) (Rate)`, probs = seq(0, 1, 0.2)),
      labels = c(
        ""0-20"",
        ""20-40"",
        ""40-60"",
        ""60-80"",
        ""80-100""
      ),
      right = FALSE,
      include.lowest = TRUE
    ),
    `GDP Quantile` = `GDP Quantile`
  )


p_percent_waste <- df_2010 %>%
  ggplot() +
  theme_minimal() +
  geom_density_ridges(
    aes(
      y = Continent, x = `Per Capita Mismanged Waste Percent`,
      fill = Continent, color = Continent
    ),
    alpha = 0.25, show.legend = F, jittered_points = TRUE
  ) +
  scale_y_discrete(limits = rev(levels(df_2010$Continent))) +
  scale_x_continuous(
    labels = scales::percent,
    limits = c(0, 1)
  ) +
  theme(axis.title = element_text(size = 8)) +
  labs(x = 'Percent of Total Plastic Waste', y = '')

p_animated <- p_percent_waste +
  transition_states(`GDP Quantile`,
    transition_length = 2,
    state_length = 0,
    wrap = F
  ) +
  ggtitle(""Mismanaged Plastic Waste - 2010\nPer Capita GDP Percentile: {closest_state}"")

## SAVE ANIMATION ---- 
animate(p_animated, height = 450, width =800)
anim_save(filename = '2019-05-21/percent_plastic_waste_animated.gif')




","2019"
"380",1412,"https://github.com/frm1789/tidytuesday/blob/master/2019_21_plastic_waste/2019_21_Plastic_waste.R","frm1789","tidytuesday","2019_21_plastic_waste/2019_21_Plastic_waste.R","library(GGally)
library(ggplot2)
library(janitor)
library(tidyverse)
library(countrycode)
library(ggalt)
library(dplyr)
library(viridis)
library(scales)

#Data
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") 
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

#clean names 
colnames(coast_vs_waste) <- c(""entity"", ""code"", ""year"", ""total_mismanaged_plastic"",""coastal_population"", ""population"")
colnames(mismanaged_vs_gdp) <- c(""entity"", ""code"", ""year"", ""per_capita_mismanaged_plastic"",""per_capita_gdp"", ""population"")
colnames(waste_vs_gdp) <- c(""entity"", ""code"", ""year"", ""per_capita_plastic_waste"",""per_capita_gdp"", ""population"")

#clean na
df_waste <- waste_vs_gdp %>%
  drop_na(per_capita_plastic_waste, per_capita_gdp, population)

df_mismanaged <- mismanaged_vs_gdp %>%
  drop_na(per_capita_mismanaged_plastic, per_capita_gdp, population)

df_coast <- coast_vs_waste %>%
  drop_na(total_mismanaged_plastic, coastal_population, population)


#Create a unique df
df_waste_misma <- df_waste %>%
  full_join(df_mismanaged, by = c(""entity"", ""code"", ""year"", ""per_capita_gdp"", ""population"")) %>%
  full_join(df_coast, by = c(""entity"", ""code"", ""year"", ""population""))%>%
  mutate(continent = countrycode(sourcevar = entity, 
                                 origin = ""country.name.en"", 
                                 destination = ""continent"")) %>%
  drop_na(per_capita_plastic_waste, per_capita_gdp)


#ggcorr looking for correlations
df_numbers <- df_waste_misma %>%
  select(per_capita_plastic_waste, per_capita_gdp, population, per_capita_mismanaged_plastic,
         total_mismanaged_plastic, coastal_population)

ggpairs(df_numbers, cardinality_threshold = 148) + 
  labs(title=""Plastic pollution in Our World"", 
       subtitle=""Correlation between variables"", 
       caption = ""Source: Our World in Data | by: Florencia Mangini"") +
  theme_minimal() 

#Colors
q_colors =  5 # for continents
v_colors =  viridis(q_colors, option = ""D"")


## 1) per_capita_mismanaged_plastic vs. coastal population: 0.783
top_vis1 <- df_waste_misma[df_waste_misma$coastal_population > 20000949 & 
                             df_waste_misma$coastal_population <= max(df_waste_misma$coastal_population) & 
                             df_waste_misma$total_mismanaged_plastic > 15466 & 
                             df_waste_misma$total_mismanaged_plastic <= max(df_waste_misma$total_mismanaged_plastic), ]


vis1 <- ggplot(df_waste_misma, aes(y=total_mismanaged_plastic, x=coastal_population)) + 
  geom_point(aes(col=continent, size=df_waste_misma$population)) + 
  scale_color_manual(values=c(""#440154FF"", ""#3B528BFF"", ""#21908CFF"", ""#5DC863FF"", ""#FDE725FF""))+
  geom_smooth(method=""loess"", se=T) + 
  geom_text(data=top_vis1,
            aes(label=entity))+
  labs(title=""Coastal population vs. Total mismanaged plastic"", 
       x=""Total mismanaged plastic"", 
       y=""Coastal population"", 
       caption = ""Source: Our World in Data | by: Florencia Mangini"")+
  theme_minimal()
plot(vis1)


## 2) per_capita_mismanaged_plastic vs. per_capita_gdp: -0.43
vis2 <- ggplot(df_waste_misma, aes(x=per_capita_mismanaged_plastic, y=per_capita_gdp)) + 
  geom_point(aes(col=continent, size=per_capita_mismanaged_plastic)) + 
  scale_color_manual(values=c(""#440154FF"", ""#3B528BFF"", ""#21908CFF"", ""#5DC863FF"", ""#FDE725FF""))+
  geom_smooth(method=""loess"", se=T) + 
  labs(title=""Waste Ratio vs. GDP"",
       x=""Mismanaged plastic (per capita)"", 
       y=""GDP (per capita)"", 
       caption = ""Source: Our World in Data | by: Florencia Mangini"")+
  theme_minimal()
plot(vis2)


","2019"
"381",1413,"https://github.com/frm1789/tidytuesday","frm1789","tidytuesday","2019_20_Nobel_prize.R","library(dplyr)
library(chorddiag)

## 1. Reading dataset 
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

## 2. Checking null values
sapply(nobel_winners, function(x) sum(is.na(x))) 
#The values ""null"" is equal to organizations laurated with the Nobel prize

## 3. Counting quantity of winners by gender
nobel_gender <- nobel_winners %>% 
  filter(!is.na(gender))%>% 
  group_by(category, gender)%>%
  summarise(count=n()) %>% 
  tidyr::spread(gender, count)

## 4. nobel_gender transformation to matrix
nobel_gender_mat <- as.matrix(nobel_gender[,-1])
row.names(nobel_gender_mat) <- as.array(nobel_gender$category)

## 5. Creating chord diagram
groupColors <- c(""#440154FF"", ""#482677FF"",""#2D708EFF"", ""#238A8DFF"", ""#55C667FF"", ""#95D840FF"",""#FDE725FF"", ""#39568CFF"") 
chorddiag(nobel_gender_mat, type = ""bipartite"", 
          groupColors = groupColors,
          tickInterval = 50)

","2019"
"382",1414,"https://github.com/frm1789/tidytuesday","frm1789","tidytuesday","2019_42_big_EPA_cars/bigCar.R","library(viridis)
library(ggridges)
library(tidyverse)

big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")


#Top 10 makers 
best_makers_cars <- big_epa_cars %>%
    group_by(make) %>%
    summarise(count = n()) %>%
    top_n(10) %>%
    arrange(desc(count))

#Visualization
big_epa_cars %>%
  right_join(best_makers_cars) %>%
  separate(trany, c(""transmission"", ""Type""), sep = "" "")%>%
  drop_na(transmission) %>% 
  ggplot(aes(y= make, color = youSaveSpend)) +
  geom_density_ridges(aes(x = year, fill = transmission), 
                          alpha = .8, color = ""white"") +
  theme_minimal()  +
  labs(
    title =""Automatic or Manual cars are better for thrifty consumers?"",
    subtitle = ""Considering the saving or spending over 5 years vs. an average car: automatic cars are more economical than manual."",
    caption = ""Florencia Mangini (@manginiflor)\nsource: BigCar for Tidytuesday"") +
  scale_fill_manual(
    name = ""Transmission"", guide = ""legend"",
    values=c(""#3B528BFF"", ""#29AF7FFF""), 
    labels = c(""Automatic"", ""Manual"")) +
  scale_color_manual(values = c(""#3B528B"", ""#29AF7F""), guide=""none"") + 
  scale_x_continuous(expand = c(0.01, 0)) +
  labs(x = 	""Evolution of the saving/spending by years"",
       y = ""Manufacturers"") 

#Double check
#Considering the top 10 of economical cars by 2019: are they manual or automatic?
big_epa_cars %>%
  select(make, model, year, VClass, youSaveSpend, trany) %>%  
  filter(youSaveSpend >0, year >= 2018)%>%  
  separate(trany, c(""transmission"", ""Type""), sep = "" "") %>%
  drop_na(transmission)  %>%
  select(-Type) %>%
  ggplot(mapping=aes(x=transmission, y=youSaveSpend)) + 
  geom_boxplot(colour = c(""#3B528BFF"", ""#29AF7FFF""), fill = ""white"") +
  geom_jitter(aes(colour = transmission)) +
  scale_color_manual(values = c(""#3B528B"", ""#29AF7F""), guide=""none"") +
  theme_minimal() +
  labs(
    title =""Savings for Automatic and Manual cars for models from 2018 & 2019"",
     caption = ""Florencia Mangini (@manginiflor)\nsource: BigCar for Tidytuesday"") +
  labs(x = 	""Types of transmission"",
       y = ""Total Saving Spend"") 


","2019"
"383",1415,"https://github.com/frm1789/tidytuesday","frm1789","tidytuesday","2019_43_Horror_Movies/code.R","library(tidyverse)
library(quantmod)
library(packcircles)
library(viridis)

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

#Tidy horror
tidy_horror <- horror_movies %>%
  filter(nchar(horror_movies$release_date) > 6, is.na(budget) != TRUE) %>% 
  dplyr::mutate(date = lubridate::dmy(release_date),
                month = lubridate::month(date, label = TRUE, abbr = FALSE)) 

# Convertion to the same currency
# This part of the code is from @ewbarba
tidy_horror$currency <- gsub(""[0-9,[:space:]]"", """", tidy_horror$budget) #strip currency
tidy_horror$currency <- gsub(""\\$"", ""USD"", tidy_horror$currency) #convert symbols to currency abbrvs
tidy_horror$currency <- gsub(""\\"", ""GBP"", tidy_horror$currency)
tidy_horror$currency <- gsub(""\\"", ""EUR"", tidy_horror$currency)
tidy_horror$currency <- gsub(""RUR"", ""RUB"", tidy_horror$currency) #1 RUB == 1000 RUR (Old Russian Ruble obsolete ca. 1998 - from coinmill.com) - change to get updated currency value
tidy_horror$currency <- gsub(""TRL"", ""TRY"", tidy_horror$currency) #1 TRY == 1000000 TRL (Old Turkis Lire obsolete ca. 2005 - from coinmill.com) - change to get updated currency value
tidy_horror$currency <- str_remove_all(tidy_horror$currency, ""\\s"") #compulsively remove the spaces
# End

currency = unique(tidy_horror$currency)[-1]

currencies <- data.frame(
                  currency = unique(tidy_horror$currency)[-1],
                  value = 1:27,
                  stringsAsFactors = FALSE)

#create table with all the currencies 
for(i in 1:nrow(currencies)){
  s_string <- paste0(currencies$currency[i],""/"" ,""USD"") 
  s_string2 <- paste0(currencies$currency[i] ,""USD"") 
  getFX(s_string)
  currencies$value[i] <- tail(eval(as.name(s_string2)),1)
}

#Adding USD
currencies <- rbind(currencies, data.frame(currency = 'USD', value = 1))

#removing just numbers
tidy_horror$budget.numbers <- gsub('[a-zA-Z$, ]', '',tidy_horror$budget)

#removing all white space, note the double brackets
tidy_horror$budget.numbers <- gsub(""[[:space:]]"", """", tidy_horror$budget.numbers)

#convert budgets to usd
for(i in 1:nrow(tidy_horror)){
  for(n in 1:nrow(currencies)){
      if(tidy_horror$currency[i] == currencies$currency[n] ){
        m <- n }
  }
  tidy_horror$budget.in.USD[i] <- as.double(tidy_horror$budget.numbers[i])*as.double(currencies$value[m])
}

#Top 10 by budget 
top_budget <- tidy_horror %>%
  group_by(release_country) %>%
  summarise(total = sum(budget.in.USD)) %>%
  top_n(10) %>%
  arrange(desc(total))

#Top 10 producer 
best_producer <- horror_movies %>%
  group_by(release_country) %>%
  summarise(count = n()) %>%
  top_n(10) %>%
  arrange(desc(count))

top_budget$total <- as.integer(top_budget$total/1000)

packing <- circleProgressiveLayout(top_budget$total, sizetype='area')
data <- cbind(top_budget, packing)
dat.gg <- circleLayoutVertices(packing, npoints=50)

ggplot() + 
  geom_polygon(data = dat.gg, aes(x, y, group = id, fill=as.factor(id)), colour = ""white"", alpha = 0.6) +
  scale_fill_manual(values = viridis(nrow(data))) +
  geom_text(data = data, aes(x, y, size=total, label = release_country)) +
  scale_size_continuous(range = c(1,24)) +
  theme_void() + 
  theme(legend.position=""none"") +
  coord_equal() +
  labs(
    title =""Which are the countries that spend more money producing horror movies?"",
    subtitle = ""The countries with majors inversions are the USA (3.287 M), UK (91M), and Spain(52)."",
    caption = ""Plot: Florencia Mangini (@manginiflor)\nsource: IMBd for Tidytuesday"")


top_budget$total1 = (top_budget$total/1000000) 

ggplot(top_budget,aes(x=reorder(release_country, -total1), y = total1, fill=release_country))+ 
  geom_bar(stat = ""identity"") +
  scale_fill_viridis_d() +
  theme_minimal() +
  theme(axis.text.x=element_text(angle=45,hjust=1),
        legend.position=""none"")+
  labs(
    title =""Total inversion in U$S by countries"",
    subtitle = ""The countries with majors inversions are the USA (3.287 M), UK (91M), and Spain(52)."",
    caption = ""Plot: Florencia Mangini (@manginiflor)\nsource: IMDb for Tidytuesday"",
    x=""Country"", y=""Total budgets per country (u$s Millons)"") 

","2019"
"384",1416,"https://github.com/frm1789/tidytuesday","frm1789","tidytuesday","2019_44_nyc_squirrels/code.R","library(tidyverse)
library(RColorBrewer)
library(reshape)

nyc_squirrels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")
tidy_sq <- nyc_squirrels

#tidy dataframe
tidy_sq <- transform(tidy_sq, hectare_v = substr(hectare, 1, 2), hectare_h = substr(hectare, 3,3))

tidy_sq_max <- tidy_sq %>%
  select(hectare_h, hectare_v, shift, date, hectare_squirrel_number,date) %>%
  group_by(hectare_h, hectare_v, shift, date) %>%
  summarise(max_value = max(hectare_squirrel_number)) %>%
  arrange(desc(date))

tidy_AMPM <- tidy_sq_max %>%
  group_by(hectare_h, hectare_v, shift, date) %>%
  summarise(total = sum(max_value)) %>% 
  arrange(desc(date))  %>% 
  group_by(hectare_h, hectare_v,date) %>% 
  summarize(totalAMPM = as.integer(sum(total))) 

# hectare_h hectare_v     date        totalAMPM
# <chr>     <chr>        <dbl>        <int>
# 1 A         01        10072018         4
# 2 A         01        10142018         7

saveGIF({
  for(i in c(10062018,10072018)){
    #    for(i in c(1997,2002,2007)){
    print(ggplot(tidy_AMPM %>% filter(date == 10062018),
                 aes(x = hectare_h, y = hectare_v)) +
            geom_tile(aes(fill = totalAMPM)) +
            theme_bw() +
            scale_y_discrete(drop = F) +
            theme(legend.position=""top"", plot.title = element_text(size=30, face=""bold"",hjust = 0.5))+
            coord_cartesian(xlim = c(20,85), ylim = c(0,21)) +
            ##scale_fill_manual(""%"",values = c(""#ffffcc"",""#ffeda0"",""#fed976"",""#feb24c"",""#fd8d3c"",""#fc4e2a"",""#e31a1c"",""#bd0026"",""#800026""),drop=FALSE)+
            annotate(x=80, y=3, geom=""text"", label=i, size = 7) +
            annotate(x=80, y=1, geom=""text"", label=""@iamreddave"", size = 5) +
            ylab(""Income"") +   # Remove x-axis label
            xlab(""Life Expenctancy"")+
            ggtitle(""Worldwide Life Expectancy and Income"")          
          
    )
  }
}, interval=1.0,ani.width = 900, ani.height = 600)

tidy_AMPM_wide <- cast(tidy_AMPM, hectare_h ~ hectare_v)

# heatmap requieres a numerical matrix, for that reason we will move the names of the team as row.names 
# and after that, we will delete the column ""Team""
row.names(tidy_AMPM_wide) <- tidy_AMPM_wide$hectare_h
tidy_AMPM_wide <- tidy_AMPM_wide[,-1]

#Creating the heatmap
#heatmap function requires a matrix as input
tidy_matrix <- data.matrix(tidy_AMPM_wide)

gplots::heatmap.2 (tidy_matrix,
                  Rowv = FALSE,
                  Colv = FALSE,
                  main = ""Squirrel Map"", # heat map title,
                  scale=""none"", 
                  key=FALSE,
                  dendrogram = ""none"",
                  margins =c(12,9),     # widens margins around plot
                  col= viridis::viridis_pal(),
                  density.info = ""none"",
                  colsep=1:ncol(tidy_matrix), # Add vertical grid lines
                  rowsep=1:nrow(tidy_matrix), # Add horizontal grid lines
                  sepcolor = ""white"", # Color gridlines black
                  trace = ""none"") 


library(ggplot2)
library(maps)
library(ggthemes)

world <- ggplot() +
  borders(""world"", colour = ""gray85"", fill = ""gray80"") +
  theme_map()

map <- world +
  geom_point(aes(x = lon, y = lat,
                 text = paste('city: ', location,
                              '<br /> created : ', created_at),
                 size = followers),
             data = rladies, colour = 'purple', alpha = .5) +
  scale_size_continuous(range = c(1, 8), breaks = c(250, 500, 750, 1000)) +
  labs(size = 'Followers')




#Function to create the polygon for each hexagon
Hexagon <- function (x, y, unitcell = 1, col = col) {
  polygon(c(x, x, x + unitcell/2, x + unitcell, x + unitcell,
            x + unitcell/2), c(y + unitcell * 0.125,
                               y + unitcell * 0.875,
                               y + unitcell * 1.125,
                               y + unitcell * 0.875,
                               y + unitcell * 0.125,
                               y - unitcell * 0.125),
          col = col, border=NA)
}#function

x <- as.vector(tidy_matrix)

#Number of rows and columns of your SOM
SOM_Rows <- dim(tidy_matrix)[1]
SOM_Columns <- dim(tidy_matrix)[2]

#To make room for the legend
par(mar = c(0.4, 2, 2, 7))

#Initiate the plot window but do show any axes or points on the plot
plot(0, 0, type = ""n"", axes = FALSE, xlim=c(0, SOM_Columns),
     ylim=c(0, SOM_Rows), xlab="""", ylab= """", asp=1)

ColRamp <- viridis::viridis(15)

ColorCode <- rep(""#FFFFFF"", length(x)) #default is all white
Bins <- seq(min(x, na.rm=T), max(x, na.rm=T), length=length(ColRamp))
for (i in 1:length(x))
  if (!is.na(x[i])) ColorCode[i] <- ColRamp[which.min(abs(Bins-x[i]))]

offset <- 0.5 #offset for the hexagons when moving up a row
for (row in 1:SOM_Rows) {
  for (column in 0:(SOM_Columns - 1))
    Hexagon(column + offset, row - 1, col = ColorCode[row + SOM_Rows * column])
  offset <- ifelse(offset, 0, 0.5)
}

dev.off()

#Add legend to the right if you want to
image.plot(legend.only=TRUE, col=ColRamp, zlim=c(min(x, na.rm=T), max(x, na.rm=T)))","2019"
"385",1417,"https://github.com/frm1789/tidytuesday","frm1789","tidytuesday","2019_45_acs_survey/code.R","commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

# Load Packages -----------------------------------------------------------

library(tidyverse)
library(readxl)
library(here)
library(glue)
library(janitor)

# Read in Data ------------------------------------------------------------

table_num <- 1:6

# Generic read function for this dataset

supp_read <- function(number, ...){
  read_excel(here(""2019_45_acs_survey"", glue::glue(""supplemental-table{number}.xlsx"")), ...)
}

# 3 datasets for bikes, each of which has a corresponding City Size

small_bike <- supp_read(1, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"", 
         percentage_of_workers = as.numeric(percentage_of_workers),
         margin_of_error_2 = as.numeric(margin_of_error_2))

medium_bike <- supp_read(2, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_bike <- supp_read(3, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_bike <- bind_rows(small_bike, medium_bike, large_bike) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Bike"")


# 3 datasets for walking, each of which has a corresponding City Size

small_walk <- supp_read(4, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"")

medium_walk <- supp_read(5, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_walk <- supp_read(6, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_walk <- bind_rows(small_walk, medium_walk, large_walk) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Walk"")

# Built in state-level datasets
state_df <- tibble(
  state = state.name,
  state_abb = state.abb,
  state_region = as.character(state.region)
)

# Combine bike and walk data in tidy setup

full_commute <- 
  bind_rows(full_bike, full_walk) %>% 
  filter(!is.na(n),
         # There are some government-related areas that don't align with cities
         !str_detect(tolower(city), ""government|goverment"")) %>% 
  separate(city, into = c(""city"", ""state""), sep = "", "") %>% 
  select(city, state, city_size, mode, everything()) %>% 
  left_join(state_df, by = c(""state""))

full_commute %>% 
  write_csv(here(""2019_45_acs_survey"", ""commute.csv""))

# ACS Data ----------------------------------------------------------------

acs_data <- read_csv(here(""2019_45_acs_survey"", ""table_3.csv""))

age_data <- acs_data %>% 
  slice(1:6)

gender_data <- acs_data %>% 
  slice(9:10) %>% 
  rename(""gender"" = age)

race_data <- acs_data %>% 
  slice(13:18) %>% 
  rename(""race"" = age)

children_data <- acs_data %>% 
  slice(20:24) %>% 
  rename(""children"" = age)

income_data <- acs_data %>% 
  slice(27:36) %>% 
  rename(""income"" = age)

education_data <- acs_data %>% 
  slice(39:43) %>% 
  rename(""education"" = age)
","2019"
"386",1418,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-04-23_Anime Dataset.R","### Load libraries 
library(tidyverse)
library(ggplot2)

### Read tidy *.csv
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

### Select variables
tidy_anime %>%
  select(name, type, source, studio, episodes, rating,
         scored_by, rank, popularity, members, favorites) %>%
  
  ### Extract unique elements  
  unique() %>%
  
  ### Arrange in descending order and select the first 10 elements
  arrange(desc(episodes)) %>% 
  head(10) %>%
  
    ### Plot
    ggplot(aes(x=reorder(name, episodes), y = episodes, fill = name)) +
    geom_col() +
    coord_flip() +
    labs(title = ""How many episodes?"",
         subtitle = ""Top 10"", 
         x = """", 
         y = ""Number of episodes"", 
         caption = ""Data source: MyAnimeList.net \n @_apuglisi_ #TidyTuesday Week 17"") +
    theme(legend.position = ""none"",
          plot.background = element_rect(fill = ""#000000""),
          plot.title = element_text(colour = ""#ffffff"", size = 16, hjust = 0.5), 
          plot.subtitle = element_text(colour = ""#ffffff"", size = 13, hjust = 0.5),
          plot.caption = element_text(colour = ""#ffffff""),
          panel.background = element_rect(fill = ""#edeaf2""),
          axis.title.x = element_text(colour = ""#ffffff""),
          axis.text = element_text(colour = ""#ffffff"", size = 14))

ggsave(""2019-04-23_Anime Dataset.png"")
","2019"
"387",1419,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-04-30_Chicago Bird Collisions.R","### Load libraries
library(tidyverse)
library(ggplot2)
library(RColorBrewer)

### Get the data
bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

### MP as locality + left join with mp_light
bird_collisions_complete <- bird_collisions %>%
  filter(locality == ""MP"") %>%
  left_join(mp_light, by = ""date"") %>%
  filter(!is.na(light_score))
  
### Plot       
bird_collisions_complete %>%
  ggplot(aes(flight_call, light_score, fill = flight_call)) +
  geom_violin() +
  annotate(""rect"", xmin = 1.8, xmax = 2.2, ymin = 7, ymax = 10.5, alpha = .2) +
  annotate(""text"", x = 2.3, y = 6, label = ""Why?"") +
  annotate(""segment"", x = 2.3, xend = 2.2, y = 6.4, yend = 7) +
  scale_fill_brewer(palette = ""Blues"") +
  labs(
    title = ""Flight call vs Light score @ McCormick Place, 2000-2016"",
    x = ""Flight call"",
    y = ""Light score"",
    caption = ""Source: https://doi.org/10.1098/rspb.2019.0364 \n @_apuglisi_ #TidyTuesday Week 18"") +
  theme(
    legend.position = ""none"",
    plot.title = element_text(size = 16),
    plot.caption = element_text(size = 10),
    plot.background = element_rect(fill = ""#f7d78c""),
    panel.background = element_rect(fill = ""#edeff2""))

ggsave(""2019-04-30_Chicago Bird Collisions.png"")
","2019"
"388",1420,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-07_Global Student to Teacher Ratios.R","### Load libraries
library(tidyverse)
library(ggplot2)
library(extrafont)
library(ggthemes)
loadfonts(device = ""win"")

### Get the data
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

### Subset student_ratio
ratio_all <- student_ratio %>%
  rename(ratio = student_ratio) %>%
  select(-c(edulit_ind, country_code, flag_codes, flags)) %>%
  na.omit()

### Plot
ratio_all %>%
  filter(country %in% c(""Italy"", ""Greece"", ""Spain"", ""Portugal"")) %>%
  
  ggplot(aes(x = year, y = ratio, color = indicator)) +
  geom_line(size = 1) +
  geom_point(size = 3.5) +
  facet_wrap(~ country, scales = ""free"") +
  labs(
    title = ""Student-teacher ratios in Greece, Italy, Portugal and Spain: 2012-2016"",
    x = ""Year"",
    y = ""Student-teacher ratio"",
    caption = ""Data source: UNESCO Institute of Statistics\n @_apuglisi #TidyTuesday Week 19"") +
  theme_solarized_2() +
  theme(
    axis.title = element_text(size = 15, family = ""Courier New"", face = ""bold""),
    axis.text = element_text(size = 13, family = ""Courier New""),
    legend.position = ""bottom"",
    legend.title = element_blank(),
    legend.spacing.x = unit(0.5, 'cm'),
    legend.text = element_text(size = 13, family = ""Courier New""),
    panel.spacing.x = unit(0.5, 'cm'),
    panel.spacing.y = unit(1, 'cm'),
    plot.margin = unit(c(0.5,1,0.5,1), 'cm'),
    plot.title = element_text(size = 17, family = ""Courier New"", face = ""bold""),
    strip.text.x = element_text(size = 15, family = ""Courier New"", face = ""bold"")
  )
  ","2019"
"389",1421,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-14_Nobel winners.R","### Load packages
library(tidyverse)
library(tidytext)
library(patchwork)

### Get the data
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

### Select distinct values of the column Motivation
motivations <- nobel_winners %>%
  filter(!is.na(motivation)) %>%
  select(motivation) %>%
  distinct()

### Tokenize motivations and remove stop words
motivations_tokenized <- motivations %>%
  unnest_tokens(word, motivation) %>%
  anti_join(stop_words)

### Plot 1 - Most used words
motivations_most_used_words <- motivations_tokenized %>%
  count(word) %>%
  arrange(desc(n)) %>%
  head(10) %>%
  
    ggplot(aes(x = reorder(word, n), y = n, fill = word, label = n)) +
    geom_col(show.legend = FALSE) +
    geom_text(aes(label = n), hjust = 1.2, color = ""white"") +
    coord_flip() +
    labs(
      title = ""10 most-used words"",
      x = """",
      y = ""Word frequency""
    ) +
    theme(
      panel.background = element_rect(color = ""#e6cb00"")
  )

### Plot 2 - Most used POS
motivations_pos <- motivations_tokenized %>%
  inner_join(parts_of_speech) %>%
  na.omit() %>%
  count(pos) %>%
  arrange(desc(n)) %>%
  head(3) %>%
  
    ggplot(aes(x = reorder(pos, n), y = n, fill = pos)) +
    geom_col(show.legend = FALSE) +
    geom_text(aes(label = n), vjust = 1.2, color = ""white"") +
    labs(
      title = ""3 most-used parts of speech"",
      x = ""Parts of speech"",
      y = """"
    ) +
  theme(
    panel.background = element_rect(color = ""#322bff"")
  )

### Plot 3 - Sentiment
motivations_sentiment <- motivations_tokenized %>%
  inner_join(sentiments) %>%
  filter(lexicon == ""nrc"") %>%
  count(sentiment) %>%
  arrange(desc(n)) %>%
  head(5) %>%
  
    ggplot(aes(x = reorder(sentiment, n), y = n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    geom_text(aes(label = n), vjust = 1.2, color = ""white"") +
    labs(
      title = ""Top 5 sentiments"",
      x = ""Sentiment"",
      y = """"
    ) +
    theme(
      panel.background = element_rect(color = ""#ff2f2b"")
    )

### Final plot
motivations_most_used_words + motivations_pos / motivations_sentiment +
  plot_annotation(
    title = ""Nobel Prize's motivations: a text analysis"",
    caption = ""Data source: The Nobel Foundation via Kaggle \n @_apuglisi_ #TidyTuesday Week 20""
  )
","2019"
"390",1422,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-21_Global Plastic Waste.R","## Load packages
library(tidyverse)
library(extrafont)

## Get the data
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

## Join dataframes, clean up column names, reorder columns and add a ratio
global_plastic_waste <- mismanaged_vs_gdp %>%
  left_join(waste_vs_gdp) %>%
  select(-c(Code, `GDP per capita, PPP (constant 2011 international $) (Rate)`)) %>%
  set_names(
    ~ str_to_lower(.) %>%
    str_remove_all(""(\\(.+$|,.+$)"") %>%
    str_remove_all("" $"") %>%
    str_replace_all("" "", ""_"")
  ) %>%
  na.omit() %>%
  select(entity, year, per_capita_mismanaged_plastic_waste, 
         per_capita_plastic_waste, gdp_per_capita, total_population) %>%
  mutate(mismanaged_plastic_waste_ratio = round(per_capita_mismanaged_plastic_waste/per_capita_plastic_waste, digits = 3), 
         gdp_per_capita = round(gdp_per_capita, digits = 2))

## Plot
ggplot(global_plastic_waste, aes(x = gdp_per_capita, y = mismanaged_plastic_waste_ratio, label = entity)) +
  geom_jitter(colour = ""#ce1e11"") +
  scale_x_continuous(breaks = seq(0, 120000, 20000)) +
  labs(
    title = ""(Mis)managing plastic waste around the world (2010)"",
    caption = ""Data source: https://ourworldindata.org/plastic-pollution \n @_apuglisi_ #TidyTuesday Week 21"",
    x = ""GDP per capita ($)"",
    y = ""Mismanaged plastic waste ratio""
  ) +
  theme(
    plot.margin = unit(c(0.5,0.5,0.3,0.5), 'cm'),
    plot.background = element_rect(fill = ""#ce1e11""),
    panel.background = element_rect(fill = ""#11ce44""),
    plot.title = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 17),
    plot.caption = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 10),
    axis.title.x =  element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 13, vjust = -0.5),
    axis.title.y = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 13, vjust = 2),
    axis.text = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff""),
    axis.ticks = element_line(colour = ""#ffffff"")
  )
","2019"
"391",1423,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-28_Wine ratings.R","## Load packages
library(tidyverse)
library(extrafont)
library(ggrepel)

## Get data
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

## Drop X1 column, drop NAs, group by tasters and summarize
wine_tasters <- wine_ratings %>%
  select(-X1) %>%
  drop_na(taster_name, description, points) %>%
  group_by(taster_name) %>%
  summarize(points_mean = mean(points), mean_description_length = mean(stringi::stri_length(description)))
  
## Plot
ggplot(wine_tasters, aes(x = points_mean, y = mean_description_length, color = taster_name, label = taster_name)) +
  geom_jitter() +
  geom_label_repel(family = ""Gabriola"", size = 5) +
  labs(
    title = ""Any correlation between points and description length?"",
    x = ""Points (mean)"",
    y = ""Description length (mean)""
  ) +
  theme(
    plot.background = element_rect(fill = ""#722F37""),
    plot.title = element_text(family = ""Gabriola"", color = ""#ffffff"", size = 18),
    axis.title = element_text(family = ""Gabriola"", color = ""#ffffff"", size = 15),
    axis.text = element_text(family = ""Gabriola"", color = ""#ffffff"", size = 15),
    axis.ticks = element_line(color = ""#ffffff""),
    legend.position = ""none""
  )
","2019"
"392",1424,"https://github.com/SteveRxD/TidyTuesday","SteveRxD","TidyTuesday","tidytuesday2019_05.R","# Load packages
library(tidyverse)
library(janitor)
library(cowplot)
library(ggrepel)
library(scales)

# Read data and clean with janitor:

coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>% clean_names()
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")  %>% clean_names()

# Reference:
  # Definitions of mismanaged plastic waste:
    #https://ourworldindata.org/grapher/mismanaged-plastic-waste?tab=chart

# Combine into a single dataframe:

waste <- waste_vs_gdp %>%
  left_join(coast_vs_waste, by = c(""entity"", ""code"", ""year"")) %>% 
  #filter to only show 2010, the only year with waste data
  filter(year == '2010') %>%    
  #exclude rows that are not counties
  filter(!is.na(code) & entity != 'World') %>% 
  #drop the duplicate column resulting from join
  select(-contains('.y')) 
  
# Tidy up names:

waste1 <- waste %>%
  rename(waste_capita = contains('per_capita_plastic'),
         income_capita = contains('gdp_per_capita'),
         mismanaged_total = contains('mismanaged_plastic'),
         total_pop = contains('total_pop'),
         coastal_pop = contains('coastal_pop')) 

# Calculate three new variables:

waste2 <- waste1 %>% 
  #mismanaged waste per capita (kg per day)
  mutate(mismanaged_capita = 
           mismanaged_total / 365 * 1000 / coastal_pop) %>% 
  #share of plastic waste that is mismanaged (%)
  mutate(share_mismanaged = mismanaged_capita / waste_capita *100) %>% 
  #total plastic waste (million tonnes)
  mutate(waste_total = waste_capita * 365 / 1000 / 10^6 * coastal_pop)

# Create plots:

  #set color and alpha for plot points
  mycolor1 <- ""#0070C0""
  myalpha1 <- 0.7
  
  #set color and alpha for the trend lines
  mycolor2 <- ""#FF9900""
  myalpha2 <- 0.15

  plot1 <- ggplot(data = waste2 %>% filter(), 
                  aes(x = income_capita, y = waste_capita, 
                      size = waste_total)) +
    geom_smooth(method = ""lm"", color = mycolor2, alpha = myalpha2, show.legend = FALSE) + 
    geom_point(color = mycolor1, alpha = myalpha1)  +   
    background_grid(major = ""xy"", minor = ""none"") +
    scale_x_continuous(trans=log10_trans(), labels = comma) +
    scale_y_continuous(trans=log10_trans()) +
    labs(title = ""Plastic waste tends to increase \nwith country income"",
         x = """",
         y = ""Plastic waste per capita (kg per day)"",
         size = ""Total plastic waste (million tonnes)"") +
    geom_text_repel(aes(label = entity),
      color         = ""red"",
      size          = 4,
      data          = subset(waste2, waste_capita > 1 | waste_capita < .015 | code %in% c(""USA"",""CHN"")
                        | (income_capita > 80000 & waste_capita < 0.1)),
      nudge_y       = .25,
      segment.color = ""grey50"",
      direction     = ""x"") 

  plot2 <- ggplot(data = waste2,
                  aes(x = income_capita, y = share_mismanaged,
                      size = waste_total)) +
    geom_smooth(color = mycolor2, alpha = myalpha2, show.legend = FALSE) + 
    geom_point(color = mycolor1, alpha = myalpha1)  +  
    background_grid(major = ""xy"", minor = ""none"") +
    scale_x_continuous(trans=log10_trans(), labels = comma) +
    scale_y_continuous(trans=log10_trans()) +
    labs(title = ""The proportion of mismanaged plastic \nwaste falls as incomes rise"",
         x = ""GDP per capita (log scale)"",
         y = ""Share of plastic waste that is mismanaged (%)"") +
    geom_text_repel(aes(label = entity),
      color         = ""red"",
      size          = 4,
      data          = subset(waste2, code %in% c(""USA"",""CHN"") | 
                        (income_capita < 10000 & share_mismanaged < 10)),
      nudge_y       = .25,
      segment.color = ""grey50"",
      direction     = ""x"") 

  plot3 <- ggplot(data = waste2, 
                  aes(x = income_capita, y = mismanaged_capita, 
                      size = waste_total)) +
    geom_smooth(color = mycolor2, alpha = myalpha2, show.legend = FALSE) + 
    geom_point(color = mycolor1, alpha = myalpha1)  +    
    background_grid(major = ""xy"", minor = ""none"") +
    scale_x_continuous(trans=log10_trans(), labels = comma) +
    scale_y_continuous(trans=log10_trans())  +
    labs(title = ""Mismanaged waste peaks \nfor middle-income countries"",
         x = """",
         y = ""Mismanaged plastic waste per capita (kg per day)"")  +
    geom_text_repel(aes(label = entity),
      color         = ""red"",
      size          = 4,
      data          = subset(waste2, code %in% c(""USA"",""CHN"") | 
                       mismanaged_capita > .16 | mismanaged_capita < .001),
      nudge_y       = .1,
      nudge_x       = .05,
      segment.color = ""grey50"",
      direction = ""x"") 

# Get legend from plot1 which will be given own panel:
l <- get_legend(plot1) 

# Final plot:
plot_grid(plot1 + theme(legend.position = ""none""), 
          plot2 + theme(legend.position = ""none""), 
          plot3 + theme(legend.position = ""none""),
          NULL,
          NULL,
          l,
          nrow = 2, rel_heights = c(6,1)
          )
  
","2019"
"393",1425,"https://github.com/ChrisWoodsSays/TidyTuesday/tree/master/2019/2019-05-20","ChrisWoodsSays","TidyTuesday","2019/2019-05-20/TidyTuesday19052019.R","library(tidyverse)
library(gganimate)
library(countrycode)
setwd(""~/Documents/GitHub/TidyTuesday"")

# Get Nobel Prize Winners
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

# Determine to 10 Countries
topCountries <- nobel_winners %>%
    group_by(birth_country) %>%
    summarise(n = n()) %>%
    na.omit() %>%
    top_n(10)

# Tidy Winners
# - Take just country in brackets where there is such
# - Change UK country names to UK
# - Get ISO country code
winnersTidy <-
    nobel_winners %>%
    mutate(birth_country = gsub("".*\\((.*)\\).*"", ""\\1"", birth_country),
           birth_country = gsub(""Scotland|Northern Ireland"", ""United Kingdom"", birth_country),
           birthCountryCode = countrycode(birth_country, 'country.name', 'iso3c')
    ) %>%
    select(prize_year, category,birth_date,birth_country,birthCountryCode) %>%
    filter(complete.cases(.))

# Count Prizes by Country, Category and Year
counts <- winnersTidy %>%
    filter(birth_country %in% topCountries$birth_country) %>%
    group_by(birthCountryCode, category, prize_year) %>%
    summarise(prizes = n()) %>%
    mutate(cumPrizes=cumsum(prizes),
           birthCountryName = countrycode(birthCountryCode, 'iso3c', 'country.name'))

# Plot Animated Chart
g = ggplot(counts, aes(x = birthCountryName, y = category, 
                       colour = birthCountryName)) + 
    geom_point(aes(size = cumPrizes), alpha=0.6) + 
    scale_size_continuous(range = c(2, 40)) +
    transition_reveal(prize_year) + 
    labs(title = 'Top 10 Nobel Prize Winning Countries', 
         subtitle = ""Year: {frame_along}"",
         y = 'Prize Category') + 
    theme_minimal() + 
    theme(
        plot.title = element_text(size=22),
        axis.title = element_blank()) +
    scale_color_brewer(palette = ""RdYlBu"") +
    theme(legend.position = ""none"") +
    theme(plot.margin = margin(5.5, 5.5, 5.5, 5.5))
animate(g, fps = 10, width = 750, height = 450)
anim_save(""nobelprizes.gif"")","2019"
"394",1426,"https://github.com/samprohaska/tidy-tuesday/blob/master/2019-04-16/tidy-tuesday_2019-04-16.R","samprohaska","tidy-tuesday","2019-04-16/tidy-tuesday_2019-04-16.R","# Import data

library(tidyverse)
women_research <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")

library(stringr)
women_research$field <-
  str_replace_all(women_research$field, 'Women inventores', 'Patent applications') %>%
  str_wrap(20)

# Plot 1: Grouped by field

library(plotly)

women_research %>%
  plot_ly(x = ~percent_women * 100, y = ~field, color = ~country, type = 'bar') %>%
  layout(title = 'Share of published women researchers, by field (2011-2015)',
         barmode = 'group',
         xaxis = list(title = ""Women's representation in academic publishing (2011-2015)"",
                      ticksuffix = ""%"",
                      range = c(0,100)),
         yaxis = list(title = ''),
         font = list(family = 'Raleway',
                     color = '#34495e'),
         annotations = list(
           text = 'Data: Elsevier, via The Economist',
           x = 80,
           y = -0.4,
           showarrow = FALSE
         ))

# Plot 2: Grouped by country

women_research %>%
  plot_ly(x = ~percent_women * 100, y = ~country, color = ~field, type = 'bar') %>%
  layout(title = ""Women's representation in academic publishing (2011-2015)"",
         barmode = 'group',
         xaxis = list(title = 'Women, as % of total published authors',
                      ticksuffix = ""%"",
                      range = c(0,100)),
         yaxis = list(title = ''),
         font = list(family = 'Raleway',
                     color = '#34495e'),
         annotations = list(
           text = 'Data: Elsevier, via The Economist',
           x = 80,
           y = -0.4,
           showarrow = FALSE
         ))
","2019"
"395",1427,"https://github.com/samprohaska/tidy-tuesday/blob/master/2019-05-21/tidy-tuesday_2019-05-21.Rmd","samprohaska","tidy-tuesday","2019-05-21/tidy-tuesday_2019-05-21.Rmd","---
title: ""Tidy Tuesday: Plastic Waste""
author: ""Samuel Prohaska""
date: ""5/21/2019""
output: html_document
---

First, import the data and clean up the column names.

```{r}
library(tidyverse)
library(readr)
library(janitor)
library(ggthemes)
library(wesanderson)

coast_vs_waste <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")

mismanaged_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

waste_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

dat <- list(coast_vs_waste, mismanaged_vs_gdp, waste_vs_gdp)
dat <- lapply(dat, clean_names)

mismanaged <- dat[[2]]
mismanaged <- rename(mismanaged, plastic_waste_misman = ""per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day"")

waste <- dat[[3]]
waste <- rename(waste, plastic_waste = ""per_capita_plastic_waste_kilograms_per_person_per_day"")
```

Now that the data's easier to work with, join the 'mismanaged' and 'waste' data. This is necessary in order to find the proportion of plastic mismanaged.

```{r}
df <- mismanaged %>%
  select(code, year, plastic_waste_misman) %>%
  left_join(waste, by = c(""code"", ""year""))

df <- rename(df, gdppc = ""gdp_per_capita_ppp_constant_2011_international_constant_2011_international"")
```

From there, set up the theme (done in advance as it's rather lengthy), slightly filter, data and create the plot.

```{r}
my_theme <- theme_classic() +
  theme(
    plot.background = element_rect(fill = ""#fbf8f4""),
    text = element_text(family = ""Raleway"", color = ""#34495e""),
    axis.title.x = element_text(color = ""#34495e"", face = ""bold""),
    axis.ticks.y = element_line(color = ""#34495e"", size = 0.2),
    axis.line.y = element_line(color = ""#34495e"", size = 0.5),
    axis.text = element_text(color = ""#34495e""),
    axis.ticks.x = element_line(color = ""#34495e"", size = 0.5),
    axis.line.x = element_line(color = ""#34495e"", size = 0.5),
    axis.title.y = element_text(color = ""#34495e"", face = ""bold""),
    plot.title = element_text(hjust = 0, color = ""#34495e"", face = ""bold""),
    plot.subtitle = element_text(hjust = 0, color = ""#34495e""),
    plot.caption = element_text(color = ""#34495e"", face = ""italic""),
    legend.title = element_text(colour = ""#34495e"", size = 9, face = ""bold""),
    legend.background = element_rect(fill = NA)
  )

# ggplot takes care of most of this filtering anyway
# (non-2010 values should be NA), but I wanted to be sure.
# `plastic_waste <1` was added to remove Trinidad and Tobago's
# whopping 3.6 tonnes per capita, as it threw off the scale.
df_plot <- df %>%
  filter(year == 2010, is.na(plastic_waste_misman) == FALSE, plastic_waste < 1)

df_plot %>%
  ggplot(aes(
    x = gdppc,
    y = (plastic_waste_misman / plastic_waste) * 100,
    color = plastic_waste
  )) +
  geom_point(size = 1, alpha = 0.9) +
  scale_color_gradient(low = wes_palette(""Zissou1"")[1], high = wes_palette(""Zissou1"")[5]) +
  stat_smooth(method = ""auto"",
              alpha = 0.2,
              color = ""#34495e"",
              size = 0.8,
              weight = 0.8,
              ullrange = TRUE,
              se = FALSE) +
  scale_x_log10() +
  ylim(0, 100) +
  my_theme +
  labs(
    title = ""Plastic Waste (Mis)management, by Country"",
    caption = ""Source: Our World in Data"",
    x = ""GDP per capita, logarithmic (2011 US $)"",
    y = ""Mismanaged waste, as % of total"",
    color = ""Plastic waste
(tonnes/capita)""
  )
```
","2019"
"396",1428,"https://github.com/samprohaska/tidy-tuesday/blob/master/2019-04-23/tidy-tuesday_2019-04-23.Rmd","samprohaska","tidy-tuesday","2019-04-23/tidy-tuesday_2019-04-23.Rmd","---
title: ""Tidy Tuesday 2019-04-23""
output: html_notebook
---

Data import and setup:

```{r}
library(tidyverse)
library(ggthemes)
library(lubridate)
library(gganimate)
library(gifski)
library(extrafont)
library(lemon)

tidy_anime <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

df_anime <- tidy_anime %>% distinct(animeID, .keep_all = TRUE)

df_anime <- df_anime %>% 
    filter(type != 'Unknown') %>%
    select(name, type, score, scored_by, start_date) %>% 
    mutate(year = year(start_date)) %>% 
    arrange(-year) %>% 
    na.omit()
```

Plotting with gganimate:

```{r}
gg <- df_anime %>% 
    ggplot(aes(x = score, y = scored_by, color = type, group = type)) +
    geom_point(size = 0.4, alpha = 0.5, aes(group = seq_along(start_date))) +
    theme(
        plot.background = element_rect(fill = '#fbf8f4'),
        text = element_text(family = 'Raleway', color = '#34495e'),
        axis.title.x = element_text(color = '#34495e', size = 18, face = 'bold'),
        axis.ticks.y = element_line(color = '#34495e', size = 0.2),
        axis.line.y = element_line(color = '#34495e', size = 0.5),
        axis.text = element_text(color = '#34495e', size = 16),
        axis.ticks.x = element_line(color = '#34495e', size = 0.5),
        axis.line.x = element_line(color = '#34495e', size = 0.5),
        legend.position = ""none"",
        panel.grid.major.y = element_line(color = '#34495e', size = 0.2),
        axis.title.y = element_text(color = '#34495e', size = 18, face = 'bold'),
        plot.title = element_text(hjust = 0, color = '#34495e', face = 'bold', size = 32),
        plot.subtitle = element_text(hjust = 0, color = '#34495e', size = 26),
        plot.caption = element_text(color = '#34495e', size = 16, face = 'italic')
    ) +
    scale_y_log10() +
    scale_color_manual(values = economist_pal()(7)) +
    facet_rep_wrap(~ type) +
    labs(title = 'Quantity & Quality', subtitle = 'MyAnimeList Ranking Frequency vs. Avg Score, by medium') +
    theme(
        strip.text.x = element_text(color = ""#34495e"", size = 22, face = 'bold'),
        strip.background = element_rect(fill = NA, colour = '#34495e')) +
    transition_reveal(start_date) +
    labs(caption = 'Released by: {frame_along}', x = 'Average Score',y = 'Number of Rankers (log)' ) +
    enter_fade()

animate(gg, height = 720, width = 1280, nframes = 110, end_pause = 5)
anim_save('mal_tidy-tuesday.gif')
```
","2019"
"397",1432,"https://github.com/leepingtay/tidytuesday_projects/tree/master/2019/2019-05-14","leepingtay","tidytuesday_projects","2019/2019-05-14/R_Nobel_LeePing_Tay.R","################################################################################################
# R TidyTuesday Data Exploratory Analysis
# Last Revision: 05/18/2019
#
# Author:
# Lee Ping Tay
#
# Description:
# Nobel Laureate Publications
#
# Introduction:
# The datasets can be obtained from github
# (https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-05-14)
# 
# The dataset contains information such as Nobel prize winners' name, country, prize 
# name, and category between 1901 and 2016.
#
#
# This script is used to explore Nobel prize winner dataset which comes from Kaggle
# and create data visualization.
#
# Contents: 
# Libraries and Environment
# Data Import and Preprocessing
# Data Wrangling / Data Visualization
#
################################################################################################
# Libraries and Environment
################################################################################################

#setwd(""/Users/leepingtay/Documents/Projects/Project_R"")

library(tidyverse)
library(circlize)


################################################################################################
# Data Import and Preprocessing
################################################################################################

# read csv files
nobel_winners <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

################################################################################################
#  Data Wrangling / Data Visualization
################################################################################################

dim(nobel_winners)   # 969  18

# Data cleaning on country
nobel_country <- nobel_winners %>%
  rename(country = death_country) %>% 
  mutate(country = ifelse(is.na(country), birth_country, country)) %>% 
  mutate(country = recode(country, 
                          `Canada` = 'CA',
                          `West Germany (Germany)` = 'Germany',
                          `Netherlands` = 'NL',
                          `Switzerland`= ""CHE"",
                          `United States of America` = 'USA', 
                          `United Kingdom`= 'UK'))

# top 10 nobel prize winners' countries
top10_nobel_country <- nobel_country %>%
  select(country, category) %>%
  filter(!is.na(country)) %>% 
  group_by(country, category) %>% 
  tally() %>% 
  mutate(sum_count = sum(n)) %>% 
  arrange(-sum_count) %>% 
  distinct(country, sum_count) %>% 
  head(10) %>% 
  select(country)

# data for the plot
data_nobel <- top10_nobel_country %>% 
  left_join(nobel_country, by=""country"") %>% 
  select(country, category) %>% 
  group_by(country, category)


# Percentage of top 10 Nobel winners by countries
nrow(data_nobel)/nrow(nobel_country)*100   # 74.4%


## circular network plot
grid.col = c(Japan = ""#1B9E77"", UK = ""#00008B"", Germany = ""#FFCE00"",
             USA = ""#E7298A"", France = ""#66A61E"", Sweden = ""#9370DB"",
             CHE = ""#FF3030"", Italy = ""#98F5FF"", CA= ""#104E8B"", NL = ""#EE7600"")

chordDiagram(data_nobel, 
             directional = 1, 
             diffHeight  = -0.04,
             grid.col=grid.col)

title(main = ""Top 10 Countries with the most Nobel Prize Winners"")



","2019"
"398",1433,"https://github.com/leepingtay/tidytuesday_projects/tree/master/2019/2019-04-23","leepingtay","tidytuesday_projects","2019/2019-04-23/R_Anime_WordCloud_LeePing_Tay.R","################################################################################################
# R TidyTuesday Data Exploratory Analysis
# Last Revision: 04/23/2019
#
# Author:
# Lee Ping Tay - joylp.tay@gmail.com
#
# Description:
#
# Introduction:
# The datasets can be obtained from github
# (https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-04-23)
# 
# The dataset contains information about animeID, name, genre, episodes, score, rank,
# popularity, favorites, and synopsis.
#
# This script is used to explore Anime dataset which comes from Kaggle and create data 
# visualization.
#
# Contents: 
# Libraries and Environment
# Data Import and Preprocessing
# Data Wrangling / Data Visualization
#
################################################################################################
# Libraries and Environment
################################################################################################

library(tidyverse)
library(tidytext)
library(ggwordcloud)

################################################################################################
# Data Import and Preprocessing
################################################################################################

# read csv files
tidy_anime <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

################################################################################################
#  Data Wrangling / Data Visualization
################################################################################################

dim(tidy_anime)  # 77911    28

# Extract synopsis
df_synopsis <- tidy_anime %>%
               select(synopsis)
  
dim(df_synopsis)  # 77911     1

# Extract words from df_synopsis
common_words <- df_synopsis %>%
                unnest_tokens(word, synopsis)  
  
# Remove common stopwords
data(stop_words)

common_words <- common_words %>%
                anti_join(stop_words) 


# Filter some extra stopwords
common_words <- common_words %>%
                filter(!(word %in% c(""source"", ""mal"", ""written"", ""rewrite"", ""named"", ""series"",
                                     ""begins"", ""called"")))

nrow(common_words)   # 3326867


# Generate top common words 
top_common_words <- common_words %>%
  count(word, sort = TRUE) %>%
  filter(n > 5000) %>%
  mutate(word = reorder(word, n))

dim(top_common_words)  # 32  2

dev.off()

# Word Cloud on top common words
p1 <- ggplot(top_common_words,
             aes(label = word,
                 size = n,
                 color = factor(sample.int(10, nrow(top_common_words), replace = TRUE)),
                 angle = 0)) +
             geom_text_wordcloud_area() +
             scale_size_area(max_size = 24) +
             theme_minimal() +
             labs(caption = ""\nSource: Kaggle | Graphic: Lee Ping Tay / @runjollyrun"")
p1

ggsave(filename = ""wordcloud_synopsis.png"", p1, width = 7, height = 5, dpi = 300, 
       units = ""in"", device='png')

dev.off()
","2019"
"399",1434,"https://github.com/leepingtay/tidytuesday_projects/tree/master/2019/2019-04-16","leepingtay","tidytuesday_projects","2019/2019-04-16/R_Economist_LeePing_Tay.R","################################################################################################
# R TidyTuesday Data Exploratory Analysis
# Last Revision: 04/16/2019
#
# Author:
# Lee Ping Tay - joylp.tay@gmail.com
#
# Description:
#
# Introduction:
# The datasets can be obtained from github
# (https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-04-16)
# 
# The dataset contains information about women in research with papers published between
# 2011 to 2015. Data include country name, field of study, and percentage of total 
# by field of study.
#
# This script is used to explore data on women in research and create data 
# visualization.
#
# Contents: 
# Libraries and Environment
# Data Import and Preprocessing
# Data Wrangling / Data Visualization
#
################################################################################################
# Libraries and Environment
################################################################################################

#setwd(""Documents/Projects/Project_R"")

library(tidyverse)
library(viridis)

################################################################################################
# Data Import and Preprocessing
################################################################################################

# read csv files
women_research <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")

################################################################################################
#  Data Wrangling / Data Visualization
################################################################################################

dim(women_research)  #60 3

# Rename some countries
women_research1 <- women_research %>% 
                   mutate(country = case_when(country==""United Kingdom""~""UK"",
                                              country==""United States""~""US"",
                                              TRUE~country))

# Create Bubble Chart
p1 <- ggplot(women_research1, aes(x = country, y = percent_women)) +
      geom_point(aes(size = percent_women, colour = field), alpha=.8) + 
      scale_size(range = c(1,6)) +
      scale_alpha(guide = 'none') +
      theme(panel.background = element_blank(), axis.line = element_line(colour = ""black""),
            text = element_text(size=9),
            legend.position=""bottom"", legend.box = ""horizontal"") +
      scale_color_viridis(discrete = TRUE, option = ""D"")+
      scale_fill_viridis(discrete = TRUE) +
      guides(colour = guide_legend(override.aes = list(size=3)), size=FALSE) +
      labs(title=""Women in Research with Papers Published 2011-15"",
           x = ""Country"",
           y = ""Percentage of total by field"",
           caption = ""\nSource: The Economist | Graphic: Joy Tay / @runjollyrun"")
p1

ggsave(filename = ""women_research.png"", p1, width = 7, height = 4, dpi = 300, 
       units = ""in"", device='png')

","2019"
"400",1435,"http://github.com/oranwutang/tidytuesdays_p/tree/master/14-5-2019","oranwutang","tidytuesdays_p","14-5-2019/Nobel.R","library(tidyverse)
library(magrittr)
# install.packages(""remotes"")
# remotes::install_github(""dgrtwo/drlib"") # drlibr includes the functions used for correctly sorting data within facets

nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

nobel_winner_all_pubs$journal<-gsub(""proceedings of the national academy of sciences of the united states of america"", ""PNAS"", nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$journal<-gsub(""journal of the chemical society chemical communications"", ""J Chem Soc, Chem Commun"", nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$journal<-gsub(""journal of the american chemical society"", ""J. Am. Chem. Soc."", nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$journal <- str_to_title(nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$category <- str_to_title(nobel_winner_all_pubs$category)

nobel_winner_all_pubs %>% 
  filter(is_prize_winning_paper==""YES"", !is.na(journal)) %>% 
  select(journal, category) %>% 
  group_by(category, journal) %>% 
  count() %>% 
  group_by(category) %>% 
  arrange(desc(n)) %>% 
  slice(1:15) %>% 
  ggplot(aes(drlib::reorder_within(x=journal, by=n, within=category), y=n))+
  geom_col(aes(fill=n))+ 
  drlib::scale_x_reordered() + 
  facet_wrap(~category, scales = ""free"")+ 
  labs(x="""", y="""", title = ""Top 15 Journals Publishing Laureate Articles"")+
  theme_minimal()+
  theme(plot.title = element_text(size=26))+
  scale_fill_viridis_c(option = ""inferno"")+
  coord_flip()
","2019"
"401",1437,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","April 23 2019/anime.R","library(tidyverse)
library(magrittr)
library(lubridate)
library(lisa)

raw_anime<-readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/raw_anime.csv"")
clean_raw<-raw_anime %>%   # Aired
  mutate(aired = str_remove(aired, ""\\{""),
         aired = str_remove(aired, ""\\}""),
         aired = str_remove(aired, ""'from': ""),
         aired = str_remove(aired, ""'to': ""),
         aired = word(aired, start = 1, 2, sep = "","")) %>% 
  separate(aired, into = c(""start_date"", ""end_date""), sep = "","") %>% 
  mutate(start_date = str_remove_all(start_date, ""'""),
         start_date = str_sub(start_date, 1, 10),
         end_date = str_remove_all(start_date, ""'""),
         end_date = str_sub(end_date, 1, 10)) %>%
  mutate(start_date = lubridate::ymd(start_date),
         end_date = lubridate::ymd(end_date)) %>% 
  # Drop unranked or unpopular series
  filter(rank != 0,
         popularity != 0)


clean_raw$start_date<-ymd(clean_raw$start_date)
clean_raw$end_date<-ymd(clean_raw$end_date)

# weight(x, weights, digits = 0)
clean_raw %>% filter(start_date>""1970-1-1"" & rating!=""None"") %>%
  ggplot(aes(x=start_date, y=score, color=rating)) + 
  geom_point(alpha=0.04) +
  geom_smooth(se = FALSE, size=1.4) + 
  scale_color_manual(values = rev(lisa$ReneMagritte)) + 
  theme_minimal() +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background=element_rect(fill=""transparent"",colour=NA),
        plot.background=element_rect(fill=""transparent"",colour=NA),
        legend.key = element_rect(fill = ""transparent"", colour = ""transparent""),
        legend.position = c(0.3, 0.15),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12), 
        plot.title = element_text(size = 18))+
  labs(x=""Start Date"", y= ""Score"", color=""Rating"",
       title = ""Score of anime\ncategories over time"",
       subtitle = ""Violence and profanity are on the rise"")

","2019"
"402",1438,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","April 29 2019 Birds/birds.R","library(tidyverse)
library(magrittr)

joined<-left_join(bird_collisions %>% filter(locality==""MP""), mp_light , by = ""date"")

joined %>%
  filter(!is.na(light_score)&family!=""Laniidae""&family!=""Icteridae"") %>% 
  group_by(family) %>% 
  mutate(MedianLight=median(light_score)) %>% 
  ggplot(aes(x=reorder(family, -light_score, FUN=median), y=light_score))+
  geom_boxplot(aes(fill=MedianLight))+
  scale_fill_gradient(low=""NA"", high=""steelblue"")+
  ggthemes::theme_solarized()+
  theme(panel.grid = element_blank(),
        legend.position = ""NA"")+
  coord_flip()+
  ylab(""Light Score"")+
  xlab(""Family"")+
  labs(title=""Birds' collisions vary according\nto Light Score"",
          caption=""Source:\nhttps://doi.org/10.1098/rspb.2019.0364\nhttps://doi.org/10.5061/dryad.8rr0498"")
","2019"
"403",1439,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","May 6 2019/Students_Teachers.R","library(tidyverse)
library(magrittr)
library(lubridate)
library(ggpubr)


student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

student_ratio$country <- str_replace(student_ratio$country, pattern = ""United Kingdom of Great Britain"", replacement = ""UK"")

# First Chart, grouping by year:

a <- student_ratio %>% 
  group_by(country, indicator, year) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
    geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point(aes(size=as.factor(year)), alpha=0.3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())


a<-set_palette(a, ""nejm"")

b <- student_ratio %>% 
  group_by(country, indicator, year) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(-25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
  geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point(aes(size=as.factor(year)), alpha=0.3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())

b <- set_palette(b, ""nejm"")


arranged<-ggarrange(a, b, common.legend = TRUE, legend = ""bottom"")

chartByYear<-annotate_figure(arranged,
                top = text_grob(""The 25 highest and lowest Student/Teacher Ratios\n by countries and year"", face = ""bold"", size = 14))

chartByYear
#Second Chart, not grouping by year

a <- student_ratio %>% 
  group_by(country, indicator) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
  geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point(alpha=0.3, size=3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())


a<-set_palette(a, ""nejm"")

b <- student_ratio %>% 
  group_by(country, indicator) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(-25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
  geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point( alpha=0.3, size=3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())

b <- set_palette(b, ""nejm"")


arranged<-ggarrange(a, b, common.legend = TRUE, legend = ""bottom"")

chartWOYear<-annotate_figure(arranged,
                             top = text_grob(""The 25 highest and lowest Student/Teacher Ratios\n by countries"", face = ""bold"", size = 14))

chartWOYear
","2019"
"404",1460,"https://github.com/brianehenyo/tidytuesday/tree/master/2019-17","brianehenyo","tidytuesday","2019-17/tt-2019-17.Rmd","---
title: ""TidyTuesday 17""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Data

```{r}
library(tidyverse)
library(lubridate)
library(paletteer)
library(harrypotter)
library(ghibli)

raw_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/raw_anime.csv"")
```

## Tidy dataset

```{r}
tidy_anime <- raw_anime %>% 
  mutate(producers = str_remove(producers, ""\\[""),
         producers = str_remove(producers, ""\\]"")) %>% 
  unnest(producers = strsplit(producers, "","")) %>% 
  mutate(producers = str_remove(producers, ""\\'""),
         producers = str_remove(producers, ""\\'"")) %>% 
  mutate(genre = str_remove(genre, ""\\[""),
         genre = str_remove(genre, ""\\]"")) %>% 
  unnest(genre = strsplit(genre, "","")) %>% 
  mutate(genre = str_remove(genre, ""\\'""),
         genre = str_remove(genre, ""\\'"")) %>% 
  mutate(studio = str_remove(studio, ""\\[""),
         studio = str_remove(studio, ""\\]"")) %>% 
  unnest(studio = strsplit(studio, "","")) %>% 
  mutate(studio = str_remove(studio, ""\\'""),
         studio = str_remove(studio, ""\\'"")) %>% 
  mutate(aired = str_remove(aired, ""\\{""),
         aired = str_remove(aired, ""\\}""),
         aired = str_remove(aired, ""'from': ""),
         aired = str_remove(aired, ""'to': ""),
         aired = word(aired, start = 1, 2, sep = "","")) %>% 
  separate(aired, into = c(""start_date"", ""end_date""), sep = "","") %>% 
  mutate(start_date = str_remove_all(start_date, ""'""),
         start_date = str_sub(start_date, 1, 10),
         end_date = str_remove_all(start_date, ""'""),
         end_date = str_sub(end_date, 1, 10)) %>%
  mutate(start_date = lubridate::ymd(start_date),
         end_date = lubridate::ymd(end_date)) %>% 
  # Drop unranked or unpopular series
  filter(rank != 0,
         popularity != 0) %>% 
  # Change text for ratings
  mutate(rating = case_when(rating == ""G - All Ages"" ~ ""G"", 
                             rating == ""None"" ~ ""None"",
                             rating == ""PG - Children"" ~ ""PG"",
                             rating == ""PG-13 - Teens 13 or older"" ~ ""PG-13"",
                             rating == ""R - 17+ (violence & profanity)"" ~ ""R"",
                             rating == ""R+ - Mild Nudity"" ~ ""R+"")) %>% 
  mutate(rating = as.character(rating)) %>% 
  mutate(rating = factor(rating, 
                          levels=c(""None"", ""G"", ""PG"",
                                   ""PG-13"",""R"",""R+"")))
```

## Scatter plot

```{r}
bg_color = paletteer_d(ghibli, MarnieLight1)[7]
text_color = paletteer_d(ghibli, MarnieLight1)[2]

tidy_anime %>% 
  filter(scored_by > 1000) %>%
  distinct(animeID, .keep_all = TRUE) %>% 
  ggplot(aes(x = favorites, y = score)) + 
  geom_point(alpha = 0.4, aes(color = type, size = scored_by)) +
  geom_text(aes(x = 215, 
                y = 2.32, 
                label = ""Hametsu no Mars performs \npoorly even with 1 episode.""), 
            size = 2, 
            colour = text_color, 
            hjust = 0, 
            family = ""Anime Ace v02"", 
            nudge_x = 0.05) +
  theme_tufte(ticks = FALSE) +
  scale_color_hp_d(option = ""Ravenclaw"", direction = -1) +
  scale_x_log10() +
  scale_size_continuous(breaks = seq(100000, 500000, 100000),
                        labels = paste0(seq(100, 500, 100), ""k"")) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2)) +
  labs(x = ""Favorites (# of fans)"", y = ""Score"",
       title = ""So bad, it's good"",
       subtitle = ""High scoring animes usually appear in many fans' favorite lists but Hametsu no Mars is still a favorite\ndespite its low score of 2. It is allegedly a rip-off of the Neon Genesis Evangelion. "",
       caption = ""Only included animes scored by >1,000 MyAnimeList members\nVis by Briane Samson"",
       size = ""Circles represent the number of scores received"") +
  theme(text = element_text(color = ""white"", family = ""Anime Ace v02""),
        plot.title = element_text(size = rel(1.25), colour = text_color),
        plot.subtitle = element_text(size = rel(.8), family = ""Avenir"", 
                                     colour = text_color),
        plot.background = element_rect(fill = bg_color),
        plot.caption = element_text(size = rel(.5), family = ""Avenir"", colour = text_color),
        panel.grid = element_line(color = ""white""),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        axis.title = element_text(color = text_color, size = rel(.6)),
        axis.text = element_text(color = text_color, size = rel(.6)),
        legend.position = ""bottom"",
        legend.direction = ""horizontal"",
        legend.background = element_rect(fill = bg_color, colour = text_color),
        legend.key = element_rect(fill = bg_color, colour = bg_color),
        legend.text = element_text(size = rel(0.5), colour = text_color),
        legend.title = element_text(size = rel(0.5), colour = text_color)) +
  guides(colour = FALSE,
         fill = FALSE,
         size = guide_legend(title.position = ""top"", title.hjust = 0.5, 
                             override.aes = list(colour = text_color, alpha = 1)))

ggsave(""score_vs_favorite.png"", width=8, height=5)
```


## Scatter plot

```{r}
bg_color = paletteer_d(ghibli, MarnieLight1)[2]

tidy_anime %>% 
  filter(scored_by > 1000) %>%
  distinct(animeID, .keep_all = TRUE) %>% 
  group_by(name) %>% 
  ggplot(aes(x = rating, y = score)) + 
  geom_jitter(aes(size = scored_by, fill = rating), 
              alpha = 0.3, width = 0.2, shape = 21, color = bg_color) +
  geom_boxplot(aes(fill = rating), colour = ""white"", show.legend = FALSE, 
               outlier.shape = NA, alpha = 0.4) +
  theme_tufte(ticks = FALSE) +
  scale_fill_hp_d(option = ""NewtScamander"") +
  scale_size_continuous(breaks = seq(100000, 500000, 100000),
                        labels = paste0(seq(100, 500, 100), ""k"")) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2)) +
  labs(x = """", y = ""Score"",
       title = ""A Slice of life and violence"",
       subtitle = ""PG-13 and R animes are scored more and rank high among fans"",
       caption = ""Only included animes scored by >1,000 MyAnimeList members\nVis by Briane Samson"",
       size = ""Circles represent the number of scores received"") +
  theme(text = element_text(color = ""white"", family = ""Anime Ace v02""),
        plot.title = element_text(size = rel(1.25)),
        plot.subtitle = element_text(size = rel(.8), family = ""Avenir""),
        plot.background = element_rect(fill = bg_color),
        plot.caption = element_text(size = rel(.5), family = ""Avenir""),
        panel.grid = element_line(color = ""gray20""),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        axis.title = element_text(color = ""white"", size = rel(.6)),
        axis.text = element_text(color = ""white"", size = rel(.6)),
        legend.position = c(0.5, 0.135),
        legend.direction = ""horizontal"",
        legend.background = element_rect(fill = bg_color, colour = ""gray40""),
        legend.key = element_rect(fill = bg_color, colour = bg_color),
        legend.text = element_text(size = rel(0.5)),
        legend.title = element_text(size = rel(0.5))) +
  guides(colour = FALSE,
         fill = FALSE,
         size = guide_legend(title.position = ""top"", title.hjust = 0.5, 
                             override.aes = list(colour = ""white"", alpha = 1)))

ggsave(""score_vs_rating.png"", width=8, height=5)
```

```{r}
bg_color = paletteer_d(ghibli, MarnieLight1)[7]
text_color = paletteer_d(ghibli, MarnieLight1)[2]

tidy_anime %>% 
  filter(scored_by > 1000) %>%
  distinct(animeID, .keep_all = TRUE) %>% 
  group_by(name) %>% 
  ggplot(aes(x = type, y = score)) + 
  geom_jitter(aes(size = scored_by, fill = type), 
              alpha = 0.3, width = 0.4, shape = 21, color = bg_color) +
  geom_boxplot(aes(fill = type), colour = text_color, show.legend = FALSE, 
               outlier.shape = NA, alpha = 0.4) +
  theme_tufte(ticks = FALSE) +
  scale_fill_hp_d(option = ""LunaLovegood"") +
  scale_size_continuous(breaks = seq(100000, 500000, 100000),
                        labels = paste0(seq(100, 500, 100), ""k"")) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2)) +
  labs(x = """", y = ""Score"",
       title = ""Movies and TV shows reign"",
       subtitle = """",
       caption = ""Only included animes scored by >1,000 MyAnimeList members\nVis by Briane Samson"",
       size = ""Circles represent the number of scores received"") +
  theme(text = element_text(color = text_color, family = ""Anime Ace v02""),
        plot.title = element_text(size = rel(1.25)),
        plot.subtitle = element_text(size = rel(.8)),
        plot.background = element_rect(fill = bg_color),
        plot.caption = element_text(size = rel(.5)),
        panel.grid = element_line(color = ""white""),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        axis.title = element_text(color = text_color, size = rel(.6)),
        axis.text = element_text(color = text_color, size = rel(.6)),
        legend.position = c(0.5, 0.135),
        legend.direction = ""horizontal"",
        legend.background = element_blank(),
        legend.key = element_rect(fill = bg_color, colour = bg_color),
        legend.text = element_text(size = rel(0.5)),
        legend.title = element_text(size = rel(0.5))) +
  guides(colour = FALSE,
         fill = FALSE,
         size = guide_legend(title.position = ""top"", title.hjust = 0.5, 
                             override.aes = list(colour = text_color, alpha = 1)))

ggsave(""score_vs_type.png"", width=8, height=5)
```","2019"
"405",1488,"https://github.com/mdonertas/tidytuesday","mdonertas","tidytuesday","20190416/20190416.Rmd","---
title: ""Economist's 'Mistakes, weve drawn a few'""
output: html_notebook
---

# Data description

Sarah Leo from The Economist went through the Economist's archives and found 7 examples of charts that were in need of improvement.

""I grouped our crimes against data visualisation into three categories: charts that are (1) misleading, (2) confusing and (3) failing to make a point. For each, I suggest an improved version that requires a similar amount of space??an important consideration when drawing charts to be published in print.""

She was nice enough to include the raw data as .csv files, where I have included both the raw and tidied formats for your graphing fun!

# Setup

```{r message=F, warning=F}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(ggpubr)
```

# Get the data

```{r message=FALSE, warning=FALSE}
brexit <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv"")

corbyn <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/corbyn.csv"")

dogs <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

eu_balance <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")

pensions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/pensions.csv"")

trade <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/trade.csv"")

women_research <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")
```

# Jeremy Corbyn Facebook Likes

## Original Post

![[link](https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368)](https://cdn-images-1.medium.com/max/2600/1*9QE_yL3boSLqopJkSBfL5A.png)

## Recreation

```{r}
corbyn_clean <- corbyn %>%
    rename(name = political_group) %>%
    na.omit()
corbyn_clean
```

```{r}
p_corbyn <- corbyn_clean %>%
    mutate(name = name %>% fct_reorder(avg_facebook_likes) %>% fct_rev()) %>%
    ggplot(aes(y = avg_facebook_likes, x = name, fill = factor(rank(avg_facebook_likes)))) +
    geom_bar(stat = 'identity') +
    coord_flip() +
    theme_economist(dkpanel = T, base_size = 12) +
    xlab('') + ylab('') +
    ggtitle('Left-click','Average number of likes per Facebook post, 2016') +
    scale_fill_brewer(type = 'seq', palette = 8) +
    guides(fill = F) +
    theme(axis.text.y = element_text(hjust = 1),
          panel.grid.major.y = element_blank(),
          panel.grid.major.x = element_line(),
          plot.title = element_text(color = 'darkred', face = 'bold'),
          plot.subtitle = element_text(color = 'gray40', face = 'italic')) +
    scale_y_continuous(labels = scales::comma) +
    labs(caption = 'Source: Facebook')
```

```{r, fig.align='centre'}
p_corbyn
```

```{r, echo = F}
ggsave('./corbyn.pdf', p_corbyn, units = 'cm', height = 8, width = 16)
ggsave('./corbyn.png', p_corbyn, units = 'cm', height = 8, width = 16)
```

# Dog Size

## Original Post

![[link](https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368)](https://cdn-images-1.medium.com/max/2600/1*H21mduPmvzot3oaMThNfFQ.png)

## Recreation

```{r}
head(dogs)
```

```{r}
p_dogs <- dogs %>%
    mutate(year = lubridate::ymd(dogs$year, truncated = 2L)) %>%
    ggplot(aes(x = year)) + 
    geom_line(aes(y = avg_neck, color = 'Neck Size'), size = 3) +
    geom_line(aes(y = (avg_weight+1)*2, color = 'Weight'), size = 3) +
    scale_y_continuous(sec.axis = sec_axis(~./2 - 1, name = ""Weight**, kg"",), 
                       limits = c(38,45)) +
    theme_economist(base_size = 12) +
    scale_x_date() + 
    scale_colour_manual(values = c(""darkred"", ""steelblue3"")) +
    ggtitle('Fit as a butcher\'s dog','Characteristics of registered with the UK\'s\nKennel Club, average when fully grown') +
    guides(color = F) +
    xlab('') +
    ylab('Neck Size*, cm') +
    labs(caption = '*Where at least 100 are registered per year\n**Where at least 50 are registered per year\nSources: Kennel Club; The Economist') +
    theme(axis.title.y.left = element_text(angle = 0, colour = 'darkred', 
                                           face = 'italic', hjust = 0, 
                                           margin = margin(0,-80,0,0)),
          axis.title.y.right = element_text(angle = 0, colour = 'steelblue3', 
                                            face = 'italic', hjust = 1, 
                                            margin = margin(0,0,0,-70), 
                                            vjust = 1),
          axis.text.y.right = element_text(margin = margin(0,0,0,10)),
          plot.subtitle = element_text(margin = margin(0,0,20,0)))
```

```{r, fig.align='centre'}
p_dogs
```

```{r, echo = F}
ggsave('./dogs.pdf', p_dogs, units = 'cm', height = 10, width = 10)
ggsave('./dogs.png', p_dogs, units = 'cm', height = 10, width = 10)
```

## My attempt

```{r}
p_dogs2 <- dogs %>%
  # mutate(year = lubridate::ymd(dogs$year, truncated = 2L)) %>%
  ggplot(aes(x = avg_weight, y = avg_neck, color = year)) +
  geom_point(size = 2) +
  geom_path(size = 1,arrow = arrow(length = unit(8,""pt""))) +
  geom_label(data = filter(dogs, year %in% c(2006, 2015)),
             aes(label = year, fill = year),
             color = 'white', nudge_y = -0.2) +
  theme_economist() +
  theme(legend.position = 'right') +
  ggtitle('Fit as a butcher\'s dog','Characteristics of registered with the UK\'s Kennel Club,\naverage when fully grown') +
  xlab('Weight**, kg') + ylab('Neck Size*, cm') +
  scale_y_continuous(breaks = 42:44, limits = c(42,44.4)) +
  scale_x_continuous(breaks = 18:20, limits = c(18,20.6)) +
  labs(caption = '*Where at least 100 are registered per year\n**Where at least 50 are registered per year\nSources: Kennel Club; The Economist') +
  scale_color_gradient(low = 'lightsteelblue3', high = 'steelblue4', breaks = c(2006,2015), guide = F) +
  scale_fill_gradient(low = 'lightsteelblue3', high = 'steelblue4', breaks = c(2006,2015), guide =F) +
  coord_fixed(ratio = 100*((max(dogs$avg_neck)-min(dogs$avg_neck))/max(dogs$avg_neck)) / (100*((max(dogs$avg_weight)-min(dogs$avg_weight))/max(dogs$avg_weight))))
```

```{r, fig.align='centre'}
p_dogs2
```

```{r, echo = F}
ggsave('./dogs2.pdf', p_dogs2, units = 'cm', height = 10, width = 12)
ggsave('./dogs2.png', p_dogs2, units = 'cm', height = 10, width = 12)
```

## Women research

```{r}
p_women <- women_research %>% 
    mutate(country = fct_reorder(country, percent_women)) %>%
    mutate(field = fct_reorder(field, percent_women)) %>%
    ggplot(aes(y = field, x = country, fill = percent_women)) +
    geom_tile() +
    scale_fill_gradient2(midpoint = 0.5, low = '#084594', high = '#99000D', 
                         mid = 'snow', breaks = c(0,0.5,1), limits = c(0,1)) +
    theme_economist(base_size = 12) +
    theme(legend.position = 'right',
          axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
          axis.text.y = element_text(hjust = 1),
          panel.grid = element_blank(),
          axis.ticks = element_blank()) +
    guides(fill = guide_colorbar('% Women')) +
    xlab('') + ylab('') +
    ggtitle('Still a man\'s world', 'Women among researchers with papers published*\n2011-15') +
    labs(caption = '*Indexed in Scopus\nSources: \'Gender in the Global Research Landscape\' by Elsevier; The Economist\nPlot by @melikedonertas')
```

```{r, fig.align='centre'}
p_women
```

```{r, echo = F}
ggsave('./women.pdf', p_women, units = 'cm', height = 10, width = 18)
ggsave('./women.png', p_women, units = 'cm', height = 10, width = 18)
```
","2019"
"406",1489,"https://github.com/j-stone/TidyTuesdayCode/blob/master/2019/W16_EconUpgrades/TidyTues-2019-wk16.R","j-stone","TidyTuesdayCode","2019/W16_EconUpgrades/TidyTues-2019-wk16.R","setwd(""2019/W16_EconUpgrades/"")
library(tidyverse)
library(gganimate)
women_research <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")

# https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368

head(women_research)

women_research <- women_research %>% 
    mutate(percent_men = 1 - percent_women) %>% 
    mutate(percent_women = percent_women * 100,
           percent_men = percent_men * 100,
           field = factor(field))

#################
# Bars
#################

plt <- ggplot(data = women_research) + 
    geom_bar(aes(x = country, 
                 y = -percent_women,
                 fill = ""female""),
             stat = ""identity"") + 
    geom_bar(aes(x = country, 
                 y = percent_men,
                 fill = ""male""),
             stat = ""identity"") + 
    labs(title = ""Gender composition of research authors"",
         x = """",
         y = ""Percent"",
         caption = ""Plot: @jmstone27"") + 
    scale_y_continuous(limits = c(-100,100),
                       breaks = c(-100, -50, 0, 50, 100),
                       labels = c(""100"",""50"",""0"",""50"",""100"")) + 
    scale_fill_manual(name = """", 
                      values = c(""female""=""#db0f2d"",""male""=""#42a3ca""),
                      labels = c(""Female"", ""Male"")) + 
    ggthemes::theme_economist() + 
    theme(
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10)
    ) + 
    coord_flip() +
    transition_states(field, 
                      transition_length = 1,
                      state_length = 3,
                      wrap = TRUE) + 
    labs(subtitle = ""Field: {closest_state}"")

animate(plt, width = 400, height = 600)

anim_save(""Bar-Research_Author_Gen_Composition.gif"")


######################################################
# Lollipop/Thermometer type slider
######################################################

plt <- ggplot(data = women_research) + 
    geom_segment(aes(y = 0,
                     yend = -percent_women,
                     x = country,
                     xend = country),
                 color = ""#db0f2d"",
                 size = 2) + #women-segment
    geom_point(aes(x = country, y = -percent_women, color = ""female""),
               size = 3) + #women-point
    geom_segment(aes(y = 0,
                     yend = percent_men,
                     x = country,
                     xend = country),
                 color = ""#42a3ca"",
                 size = 2) + #men-segment
    geom_point(aes(x = country, y = percent_men, color = ""male""),
               size = 3) + #men-point
    labs(title = ""Gender composition of \nresearch paper authors"",
         x = """",
         y = ""Percent"",
         caption = ""Plot: @jmstone27"") + 
    scale_y_continuous(limits = c(-100,100),
                       breaks = c(-100, -50, 0, 50, 100),
                       labels = c(""100"",""50"",""0"",""50"",""100"")) + 
    scale_color_manual(name = """", 
                      values = c(""female""=""#db0f2d"",""male""=""#42a3ca""),
                      labels = c(""Female"", ""Male"")) + 
    ggthemes::theme_economist() + 
    theme(
        plot.subtitle = element_text(size = 14),
        plot.caption = element_text(size = 10)
    ) + 
    coord_flip() + 
    transition_states(field, 
                      transition_length = 1,
                      state_length = 3,
                      wrap = TRUE) + 
    labs(subtitle = ""Field: {closest_state}"")

animate(plt, width = 400, height = 600)

anim_save(""Lollipop-Research_Author_Gen_Composition.gif"")
","2019"
"407",1500,"https://github.com/ArthurCheib/tidytuesday34","ArthurCheib","tidytuesday34","Week 15 - 2019/tenis_tt15.Rmd","---
title: ""Week 15 - Tennis""
author: ""Arthur Cheib""
date: ""10 de abril de 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages and data

```{r}
library(tidyverse)
library(ggrepel)

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

```


## PLOT

```{r}
outcome_wanted <- c(""Finalist"", ""Won"")

base_data <- grand_slam_timeline %>% 
  filter(outcome %in% outcome_wanted,
         gender == ""Female"") %>%
  group_by(player, outcome) %>% 
  summarize(finals_participations = as.numeric(n())) %>% ungroup() %>% 
  spread(outcome, finals_participations, fill = 0) %>% 
  mutate(finals_participations = (Won + Finalist),
         victories = Won,
         win_rate = round(victories/finals_participations*100, digits = 2)) %>% 
  select(-Won, -Finalist) %>% 
  filter(win_rate > 0,
         finals_participations >= 8)


mean_rate <- paste0(round(mean(base_data$win_rate), digits = 0), ""%"")

ggplot(base_data, aes(x = win_rate, y = finals_participations, label = player)) +
  theme_light() +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 100)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 40)) +
  labs(title = ""Tennis's Magic Quadrant - Most decisive Female players in Tennis History"",
       subtitle = ""Tennis players with more than 8 Grand Slams Finals appearance"",
       x=""WINNING RATE IN FINALS (%)"",
       y=""# FINALS APPEARANCE"") + 
  theme(axis.title.x = element_text(hjust = 0, vjust=2.5, colour=""darkgrey"",size=10,face=""bold""),
        axis.title.y = element_text(hjust = 0, vjust=0, colour=""darkgrey"",size=10,face=""bold"")) +
  theme(panel.border = element_rect(colour = ""lightgrey"", fill=NA, size=4)) +
  geom_hline(yintercept=20, color = ""lightgrey"", size=1.5) +
  geom_vline(xintercept=mean(base_data$win_rate), size = 1, color = ""orange"", linetype = ""longdash"") +
  geom_vline(xintercept=50, color = ""lightgrey"", size=1.5) +
  geom_label(aes(x = 25, y = 38, label = ""CALLENGERS""), 
                    label.padding = unit(2, ""mm""),  fill = ""red"", color=""white"") +
  geom_label(aes(x = 75, y = 38, label = ""LEADERS""), 
                    label.padding = unit(2, ""mm""), fill = ""lightgreen"", color=""white"") +
  geom_label(aes(x = 25, y = 2, label = ""NICHE PLAYERS""), 
                    label.padding = unit(2, ""mm""),  fill = ""lightgrey"", color=""white"") +
  geom_label(aes(x = 75, y = 2, label = ""VISIONARIES""), 
                    label.padding = unit(2, ""mm""), fill = ""lightblue"", color=""white"") +
  geom_point(colour=ifelse(base_data$win_rate >= 50 & base_data$finals_participations >=17, ""green"", ""#2896BA""), size=4.5, alpha=0.8) +
  geom_text_repel(colour=""#2896BA"") +
  geom_text(aes(x=50, y = 25), label = paste0(""Mean \n Win Rate:\n"", mean_rate), color=""orange"")

ggsave(filename = ""Gartner_magic_Players_02.jpg"", width=15, height=10, units=""cm"", scale=1.6)

```

","2019"
"408",1503,"https://github.com/ArthurCheib/tidytuesday34","ArthurCheib","tidytuesday34","Week 7 - 2019/TidyCode.Rmd","---
title: ""US R&D spending""
author: ""Arthur Cheib""
date: ""27 de maro de 2019""
output: html_document
---

## EDA

```{r echo=FALSE}
library(tidyverse)
library(knitr)
library(ggbeeswarm)
library(ggforce)
library(ggthemes)
library(carbonate)

carbonate::

fed_rd <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")

#save(... = fed_rd, file = ""bd_fed_rd.RData"")

summary(fed_rd)
```

## Data displayed by department and decade

```{r}

selected_deps <- c(""DOD"", ""NASA"", ""DOE"", ""DHS"")

fed_rd_by_decade <- fed_rd %>%
  mutate(decade = floor(year/10)*10) %>% 
  group_by(decade, department) %>% 
  summarize_at(vars(rd_budget, total_outlays, discretionary_outlays, gdp), sum)

fed_rd_by_decade %>%  
  filter(department %in% selected_deps) %>%
  ggplot(aes(x= decade, y = department, color = department)) +
    ggbeeswarm::geom_quasirandom(alpha=1,aes(size=rd_budget),groupOnX = FALSE, show.legend = FALSE) +
    theme_economist() +
    labs(title='Total Budget of R&D - by decade',
       subtitle='Displayed by four US departments',
       y='',
       x=""Decade"",
       caption='Data: New York Times')
```

## Did the US spending with militaries decrease after the end of the Cold War? Does it increase after the 09/11?

```{r}
fed_rd %>% 
  filter(department == ""DOD"") %>%
    ggplot(aes(x= year, y =rd_budget)) +
    geom_line(aes(colour = ""ff8080""), size = 1.5) +
    geom_point(aes(colour = department), size = 2.5) +
    theme_light() +
    geom_vline(xintercept=1989, color=""orange"", size=1) +
    geom_text(aes(x= 1989, y = 8e+10), label = ""End of Cold War"", color=""orange"") +
    geom_vline(xintercept=2001, color=""lightblue"", size=1.5) +
    geom_text(aes(x= 2004, y = 6e+10), label = ""Nine\nEleven"", color=""blue"") +
    labs(title='Total R&D Budget of the US Defense Department  - by year',
       subtitle='Some historical dates',
       y='',
       x=""Decade"",
       caption='Data: New York Times') +
    theme(legend.position = ""none"")
  

```

","2019"
"409",1504,"https://github.com/ArthurCheib/TidyTuesday","ArthurCheib","TidyTuesday","Week 15 - 2019/tenis_tt15.Rmd","---
title: ""Week 15 - Tennis""
author: ""Arthur Cheib""
date: ""10 de abril de 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages and data

```{r}
library(tidyverse)
library(ggrepel)

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

```


## PLOT

```{r}
outcome_wanted <- c(""Finalist"", ""Won"")

base_data <- grand_slam_timeline %>% 
  filter(outcome %in% outcome_wanted,
         gender == ""Female"") %>%
  group_by(player, outcome) %>% 
  summarize(finals_participations = as.numeric(n())) %>% ungroup() %>% 
  spread(outcome, finals_participations, fill = 0) %>% 
  mutate(finals_participations = (Won + Finalist),
         victories = Won,
         win_rate = round(victories/finals_participations*100, digits = 2)) %>% 
  select(-Won, -Finalist) %>% 
  filter(win_rate > 0,
         finals_participations >= 8)


mean_rate <- paste0(round(mean(base_data$win_rate), digits = 0), ""%"")

ggplot(base_data, aes(x = win_rate, y = finals_participations, label = player)) +
  theme_light() +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 100)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 40)) +
  labs(title = ""Tennis's Magic Quadrant - Most decisive Female players in Tennis History"",
       subtitle = ""Tennis players with more than 8 Grand Slams Finals appearance"",
       x=""WINNING RATE IN FINALS (%)"",
       y=""# FINALS APPEARANCE"") + 
  theme(axis.title.x = element_text(hjust = 0, vjust=2.5, colour=""darkgrey"",size=10,face=""bold""),
        axis.title.y = element_text(hjust = 0, vjust=0, colour=""darkgrey"",size=10,face=""bold"")) +
  theme(panel.border = element_rect(colour = ""lightgrey"", fill=NA, size=4)) +
  geom_hline(yintercept=20, color = ""lightgrey"", size=1.5) +
  geom_vline(xintercept=mean(base_data$win_rate), size = 1, color = ""orange"", linetype = ""longdash"") +
  geom_vline(xintercept=50, color = ""lightgrey"", size=1.5) +
  geom_label(aes(x = 25, y = 38, label = ""CALLENGERS""), 
                    label.padding = unit(2, ""mm""),  fill = ""red"", color=""white"") +
  geom_label(aes(x = 75, y = 38, label = ""LEADERS""), 
                    label.padding = unit(2, ""mm""), fill = ""lightgreen"", color=""white"") +
  geom_label(aes(x = 25, y = 2, label = ""NICHE PLAYERS""), 
                    label.padding = unit(2, ""mm""),  fill = ""lightgrey"", color=""white"") +
  geom_label(aes(x = 75, y = 2, label = ""VISIONARIES""), 
                    label.padding = unit(2, ""mm""), fill = ""lightblue"", color=""white"") +
  geom_point(colour=ifelse(base_data$win_rate >= 50 & base_data$finals_participations >=17, ""green"", ""#2896BA""), size=4.5, alpha=0.8) +
  geom_text_repel(colour=""#2896BA"") +
  geom_text(aes(x=50, y = 25), label = paste0(""Mean \n Win Rate:\n"", mean_rate), color=""orange"")

ggsave(filename = ""Gartner_magic_Players_02.jpg"", width=15, height=10, units=""cm"", scale=1.6)

```

","2019"
"410",1507,"https://github.com/ArthurCheib/TidyTuesday","ArthurCheib","TidyTuesday","Week 7 - 2019/TidyCode.Rmd","---
title: ""US R&D spending""
author: ""Arthur Cheib""
date: ""27 de maro de 2019""
output: html_document
---

## EDA

```{r echo=FALSE}
library(tidyverse)
library(knitr)
library(ggbeeswarm)
library(ggforce)
library(ggthemes)
library(carbonate)

carbonate::

fed_rd <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")

#save(... = fed_rd, file = ""bd_fed_rd.RData"")

summary(fed_rd)
```

## Data displayed by department and decade

```{r}

selected_deps <- c(""DOD"", ""NASA"", ""DOE"", ""DHS"")

fed_rd_by_decade <- fed_rd %>%
  mutate(decade = floor(year/10)*10) %>% 
  group_by(decade, department) %>% 
  summarize_at(vars(rd_budget, total_outlays, discretionary_outlays, gdp), sum)

fed_rd_by_decade %>%  
  filter(department %in% selected_deps) %>%
  ggplot(aes(x= decade, y = department, color = department)) +
    ggbeeswarm::geom_quasirandom(alpha=1,aes(size=rd_budget),groupOnX = FALSE, show.legend = FALSE) +
    theme_economist() +
    labs(title='Total Budget of R&D - by decade',
       subtitle='Displayed by four US departments',
       y='',
       x=""Decade"",
       caption='Data: New York Times')
```

## Did the US spending with militaries decrease after the end of the Cold War? Does it increase after the 09/11?

```{r}
fed_rd %>% 
  filter(department == ""DOD"") %>%
    ggplot(aes(x= year, y =rd_budget)) +
    geom_line(aes(colour = ""ff8080""), size = 1.5) +
    geom_point(aes(colour = department), size = 2.5) +
    theme_light() +
    geom_vline(xintercept=1989, color=""orange"", size=1) +
    geom_text(aes(x= 1989, y = 8e+10), label = ""End of Cold War"", color=""orange"") +
    geom_vline(xintercept=2001, color=""lightblue"", size=1.5) +
    geom_text(aes(x= 2004, y = 6e+10), label = ""Nine\nEleven"", color=""blue"") +
    labs(title='Total R&D Budget of the US Defense Department  - by year',
       subtitle='Some historical dates',
       y='',
       x=""Decade"",
       caption='Data: New York Times') +
    theme(legend.position = ""none"")
  

```

","2019"
"411",1511,"https://github.com/rladies-ames/tidytuesday/blob/master/data/2019/2019-01-29/r-ladies-ames-soln.Rmd","rladies-ames","tidytuesday","data/2019/2019-01-29/r-ladies-ames-soln.Rmd","---
title: ""Milk Production in the US""
author: ""R-Ladies Ames""
date: ""2/5/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For our first foray into #TidyTuesday, we went back in time. We felt cows were more appropos for R-Ladies Ames than mortgage data. 

```{r pkgs}
library(tidyverse)
library(janitor)
library(visdat)
library(sf)
library(USAboundaries)
# devtools::install_github('thomasp85/gganimate')
library(gganimate)
```

```{r getdat}
cheese <- read_csv(""clean_cheese.csv"")
fluid_milk <- read_csv(""fluid_milk_sales.csv"")
milkfacts <- read_csv(""milk_products_facts.csv"")
cowfacts <- read_csv(""milkcow_facts.csv"")
state_milk <- read_csv(""state_milk_production.csv"")
```

```{r glimpsedat}
glimpse(cheese)
glimpse(fluid_milk)
glimpse(cowfacts)
glimpse(milkfacts)
glimpse(state_milk)
```

## Make a map of milk

```{r usamap}
usa <- us_states()
usa <- usa %>% filter(name != ""Alaska"", name != ""Hawaii"", jurisdiction_type != ""territory"")

usa <- usa %>% filter(name != ""District of Columbia"")

usa_milk <- usa %>% left_join(state_milk, by = c(""name"" = ""state""))
# usa_milk %>% filter(year == 1970) %>% 
# ggplot() + 
#   geom_sf(aes(fill = milk_produced)) + 
#   scale_fill_distiller(name = paste(""Pounds of Milk Year"", i), palette = ""YlOrBr"", direction = 2) + 
#   coord_sf() + 
#   theme_void() + 
#   theme(panel.grid = element_line(color = 'white'))
```


# Now we animate over years

```{r ggani}

usa_milk %>% mutate(year = as.integer(year), milk_produced = milk_produced/10^9) %>% 
ggplot() +
  geom_sf(aes(fill = milk_produced)) +
  scale_fill_distiller(name = ""Billions of Pounds of\nMilk Produced"", palette = ""YlOrBr"", direction = 2) + 
  #facet_wrap(~year)
  labs(title = ""Milk Production in {frame_time}"") + 
   # Here comes the gganimate specific bits
  transition_time(year) 
# anim_save(filename = ""milk.gif"", animation = last_animation())
```




","2019"
"412",1515,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2018/2018-09-04/readme.rmd","# Fast food entree data

* Data from [fastfoodnutrition.com](https://fastfoodnutrition.org/mcdonalds/chart) 
* Please notice that I really only took entrees - feel free to select ALL food, sides, drinks, desserts, etc.

At the request of the website owner - I have removed web-scraping guide.
","2018"
"413",1516,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2018/2018-09-25/raw/invasive_species.R","library(tidyverse)

df <- read_csv(""afr_species.csv"") %>% 
        janitor::clean_names() %>% 
        select(species:origin)

df %>% write_csv(""africa_species.csv"")

df1 <- read_csv(""table1.csv"") %>% janitor::clean_names()
tab_1 <- df1 %>% 
        select(rank:o_tt) %>% 
        bind_rows(df1 %>% 
                          select(rank_1:o_tt_1) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        bind_rows(df1 %>% 
                          select(rank_2:o_tt_2) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        filter(!is.na(rank)) %>% 
        rename(""invasion_threat"" = o_tt)

df2 <- read_csv(""table2.csv"") %>% janitor::clean_names()
tab_2 <- df2 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df2 %>% 
                select(""country"" = x4, ""ti_ct"" = ti_ct_millions_1) %>% 
                        mutate(rank = parse_number(country),
                               country = str_extract(country, ""[:alpha:].*$""),
                               ti_ct = parse_number(ti_ct) * 1000000) %>% 
                        filter(!is.na(rank))
        ) %>% 
        bind_rows(df2 %>% 
                          select(""country"" = x7, ""ti_ct"" = ti_ct_millions_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000) %>% 
                          filter(!is.na(rank))
                
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df3 <- read_csv(""table3.csv"") %>% janitor::clean_names()
tab_3 <- df3 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions, 
               ""gdp_mean"" = x4, ""gdp_proportion"" = proportion_of) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000,
               gdp_mean = parse_number(gdp_mean) * 1000000,
               gdp_proportion = as.numeric(gdp_proportion)
        ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x6, ""ti_ct"" = ti_ct_millions_1, 
                                 ""gdp_mean"" = x9, ""gdp_proportion"" = proportion_of_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x11, ""ti_ct"" = ti_ct_millions_2, 
                                 ""gdp_mean"" = x14, ""gdp_proportion"" = proportion_of_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df4 <- read_csv(""table4.csv"") %>% janitor::clean_names()
tab_4 <- df4 %>% 
        select(""country"" = rank_country, ""ti_cs"" = ti_cs_millions_us) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_cs = parse_number(ti_cs) * 1000000
               ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_1, ""ti_cs"" = ti_cs_millions_us_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
                  ) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_2, ""ti_cs"" = ti_cs_millions_us_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_cs)

df6 <- read_csv(""table6.csv"") %>% janitor::clean_names()
tab_6 <- df6 %>% 
        select(species, ""max_impact_percent"" = maximum_reported_species) %>%
        filter(!is.na(species)) %>% 
        mutate(rank = 1:n(),
               species = species,
               max_impact_percent = parse_number(max_impact_percent)
        ) %>% 
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species, 
                                 ""max_impact_percent"" = maximum_reported_species_1) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>%
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species_1, 
                                 ""max_impact_percent"" = maximum_reported) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>% 
        filter(!is.na(species))

tab_list <- list(table_1 = tab_1, table_2 = tab_2, table_3 = tab_3, table_4 = tab_4, table_6 = tab_6)

tab_list %>% 
        names() %>% 
        walk(~ write_csv(tab_list[[.]], glue::glue(""{.}.csv"")))
","2018"
"414",1517,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2018/2018-09-25/raw/readme.rmd","# Raw tabular data

Table data extracted from supplementary PDF via [Tabula](https://tabula.technology/) open-source software. 

This ended up being super messy - cleaning script found below.

[Cleaning Script](https://github.com/rfordatascience/tidytuesday/blob/master/data/2018-09-25/raw/invasive_species.R)
","2018"
"415",1518,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-01-22/example_code.R","# Load Library
library(tidyverse)

# Read in raw data from Vera
df_raw <- read_csv(""https://raw.githubusercontent.com/vera-institute/incarceration_trends/master/incarceration_trends.csv"")

# Check out the data structure
df_raw %>% str()

# add a row id (for later joining)
df <- df_raw %>% 
  mutate(row_id = row_number())

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong

df_population <- df %>% 
  select(yfips:land_area, -total_pop, row_id) %>% 
  gather(pop_category, population, total_pop_15to64:white_pop_15to64) %>% 
  mutate(pop_category = case_when(str_detect(pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(pop_category, ""white"") ~ ""White"",
                                  str_detect(pop_category, ""black"") ~ ""Black"",
                                  str_detect(pop_category, ""female"") ~ ""Female"",
                                  str_detect(pop_category, ""male_pop"") ~ ""Male"",
                                  str_detect(pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(pop_category, ""total"") ~ ""Total"",
                                  str_detect(pop_category, ""native"") ~ ""Native American"",
                                  str_detect(pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong
df_prison_pop <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_prison_pop:white_prison_pop, row_id) %>% 
  gather(prison_pop_category, prison_population, total_prison_pop:white_prison_pop) %>% 
  mutate(prison_pop_category = case_when(str_detect(prison_pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(prison_pop_category, ""white"") ~ ""White"",
                                  str_detect(prison_pop_category, ""black"") ~ ""Black"",
                                  str_detect(prison_pop_category, ""female"") ~ ""Female"",
                                  str_detect(prison_pop_category, ""male_prison"") ~ ""Male"",
                                  str_detect(prison_pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(prison_pop_category, ""total"") ~ ""Total"",
                                  str_detect(prison_pop_category, ""native"") ~ ""Native American"",
                                  str_detect(prison_pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Left join the two dataframes together
# I used all the common columns including row_id

full_prison_pop_df <- left_join(df_population, df_prison_pop, 
          by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                 ""pop_category"" = ""prison_pop_category"", ""urbanicity"", ""region"",
                 ""division"", ""commuting_zone"", ""metro_area"", ""land_area"", ""row_id"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone)) 

# Summary data to get rate per 100000 by group

summ_prison <- full_prison_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(prison_population)/sum(population) * 100000) %>% 
  ungroup()

# Test plot looks good
ggplot(summ_prison, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category)

# More gathers to get pre-trial data
df_pretrial <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_jail_pretrial:male_jail_pretrial) %>% 
  gather(pretrial_category, pretrial_population, total_jail_pretrial:male_jail_pretrial) %>% 
  mutate(pretrial_category = case_when(str_detect(pretrial_category, ""asian"") ~ ""Asian"",
                                  str_detect(pretrial_category, ""white"") ~ ""White"",
                                  str_detect(pretrial_category, ""black"") ~ ""Black"",
                                  str_detect(pretrial_category, ""female"") ~ ""Female"",
                                  str_detect(pretrial_category, ""male_jail"") ~ ""Male"",
                                  str_detect(pretrial_category, ""latino"") ~ ""Latino"",
                                  str_detect(pretrial_category, ""total"") ~ ""Total"",
                                  str_detect(pretrial_category, ""native"") ~ ""Native American"",
                                  str_detect(pretrial_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Pretrial dataset joined with population numbers
pretrial_pop_df <- left_join(df_population, df_pretrial, 
                         by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                                ""pop_category"" = ""pretrial_category"", ""urbanicity"", ""region"",
                                ""division"", ""commuting_zone"", ""metro_area"", ""land_area"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone))

# Summary data to get rate per 100000 by group
summ_pretrial <- pretrial_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(pretrial_population)/sum(population) * 100000) %>% 
  ungroup()

# plot matches Vera plot
ggplot(summ_pretrial, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category) +
  labs(title = ""Rate per 100,000 by county type and population group"")

# Write files to .csv
write_csv(summ_prison, ""prison_summary.csv"")
write_csv(summ_pretrial, ""pretrial_summary.csv"")
write_csv(full_prison_pop_df, ""prison_population.csv"")
write_csv(pretrial_pop_df, ""pretrial_population.csv"")
","2019"
"416",1519,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-02-05/r-ladies-ames-soln.Rmd","---
title: ""R-Ladies Ames Do Tidy Tuesday""
author: ""Sam Tyner, Haley Jeppson, Annette O'Connor, Soyoung Park""
date: ""2/5/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r pkgs}
library(tidyverse)
```

```{r getdata}
mort <- read_csv(""mortgage.csv"")
recess <- read_csv(""recessions.csv"")
hpi <- read_csv(""state_hpi.csv"")
```

```{r glimpse}
glimpse(mort)
glimpse(recess)
glimpse(hpi)
```


## Start by tidying the mortgage data 

DO COW DATA INSTEAD!!!!!
","2019"
"417",1520,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-02-19/r-ladies-ames-soln.Rmd","---
title: ""R Ladies Ames Solution""
author: ""Sam Tyner, Kat Goode, Jing Zhao""
date: ""2/19/2019""
output: github_document
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Get data 

```{r dat}
library(tidyverse)
library(plotly)
phd_field <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")
phd_field %>% count(year)
head(phd_field)
```

## All PhDs 

```{r alldegress}
phd_field %>% group_by(year) %>% summarise(total = sum(n_phds, na.rm = T)) %>% 
  ggplot(aes(x = year,y = total)) + 
  geom_line() + 
  scale_x_continuous(breaks = 2008:2017)
```

## Most popular 

```{r popular}
phd_field %>% group_by(broad_field) %>% 
  summarize(total = sum(n_phds, na.rm = T)) %>% 
  arrange(desc(total))
```

```{r popular2}
phd_field %>% group_by(major_field) %>% 
  summarize(total = sum(n_phds, na.rm = T)) %>% 
  arrange(desc(total))
```

```{r popular3}
phd_field %>%group_by(field) %>% 
  summarize(total = sum(n_phds, na.rm = T)) %>% 
  arrange(desc(total))
```



```{r algebra}
phd_field %>% filter(field == ""Algebra"") %>% 
  ggplot(aes(year, n_phds)) + 
  geom_line()
```


```{r stats}
phd_field %>% filter(str_detect(field, ""Statistics""))  %>% 
  ggplot(aes(year, n_phds, color = field)) + 
  geom_line()
```


```{r alltime}
p <- phd_field %>% 
  ggplot(aes(year, n_phds, group = field)) + 
  geom_line(alpha = .3) + 
  facet_wrap(~broad_field)
p
#ggplotly(p)
```

```{r psych}
p <- phd_field %>% filter(broad_field == ""Psychology and social sciences"") %>% 
  ggplot(aes(year, n_phds, group = field)) + 
  geom_line(alpha = .5) + 
  facet_wrap(~major_field, scales = ""free_y"")
p
#ggplotly(p)
```

```{r byfield}
phd_field %>% group_by(year, broad_field) %>% summarise(total = sum(n_phds, na.rm = T)) %>% 
  ggplot(aes(x = year, y = total, color = broad_field)) +
  geom_line()
```

```{r byfield2}
phd_field %>% group_by(year, broad_field) %>% filter(!is.na(n_phds)) %>% count() %>% 
  ggplot(aes(year, n, color = broad_field)) + 
  geom_line() + 
  ggtitle(""How many subfields are included in the broad fields?"")
```


```{r byfield3}
p <- phd_field %>% filter(broad_field == ""Other"") %>% 
  ggplot(aes(year, n_phds, group = field)) + 
  geom_line() + 
  facet_wrap(~major_field)
p
#ggplotly(p)
```","2019"
"418",1521,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-05/r-ladies-ames-soln.Rmd","---
title: ""R Ladies Ames Solution""
author: ""Sam Tyner, Miranda Tilton""
date: ""3/5/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r getdat}
library(tidyverse)
jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")
earnings_female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"") 
employed_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"") 
```


```{r jobs}
head(jobs_gender)
head(earnings_female)
```

```{r earningsfemale}
earnings_female %>% mutate(total = str_detect(group, ""Total"")) %>% 
ggplot() + 
  geom_line(aes(x = Year, y = percent, group = group, color = group)) + 
  scale_color_brewer(palette = ""Reds"") + 
  facet_grid(total ~ ., space = ""free"", scales = ""free_y"")
```

```{r jobsgender}
head(jobs_gender)
jobs_gender %>% 
  ggplot() + 
  geom_line(aes(x = year, y=  percent_female, group =occupation, color = major_category))
```","2019"
"419",1522,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-12/r-ladies-ames-soln.Rmd","---
title: ""R Ladies Ames' Solution""
author: ""Sam Tyner""
date: ""3/12/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = ""center"", out.width = ""75%"", message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
bgdat <- read_csv(""board_games.csv"")
glimpse(bgdat)
```

What is the relationship between year and playing time? 

```{r}
ggplot(data = bgdat) + 
  geom_linerange(aes(x = year_published, y = (min_playtime + max_playtime)/2, ymin = min_playtime, ymax = max_playtime, group = game_id)) + 
  labs(x = ""Year Published"", y = ""Playtime (minutes)"")
```

Which games have playtime more than 20,000 minutes (about two weeks)?!? 

```{r}
bgdat %>% filter(min_playtime > 10000) %>% glimpse()
```
Wow, that's dedication. Let's remove those extremes.  

```{r}
bgdat <- bgdat %>% filter(min_playtime < 10000)
ggplot(data = bgdat) + 
  geom_linerange(aes(x = year_published, y = (min_playtime + max_playtime)/2, ymin = min_playtime, ymax = max_playtime, group = game_id)) + 
  labs(x = ""Year Published"", y = ""Playtime (minutes)"")
```

It would be nice to facet this by category, but the category variable is strange: 

```{r}
bgdat$category %>% head()
```

Let's clean this up a bit.

```{r}
bgdat$category %>% str_count("","") %>% max(na.rm=T)
```

One game has 14 categories! 

```{r}
bgdat %>% mutate(ncat = str_count(category, "","") + 1) %>% 
  arrange(desc(ncat)) %>% select(name, category, ncat) %>% head
```

Now, we'll split category up and only keep the first 2 categories for simplicity. 

```{r}
bgdat2 <- bgdat %>% separate(category, into = c(""firstcat"", ""secondcat""), sep = "","")
bgdat2 %>% count(firstcat)
```

There are still a lot of categories, but there are many different categories of war games. Let's make all of them just ""War"".

```{r out.width= ""100%""}
bgdat2 <- bgdat2 %>% mutate(firstcat = ifelse(str_detect(firstcat, ""War""), ""War"", firstcat), secondcat = ifelse(str_detect(secondcat, ""War""), ""War"", secondcat))
bgdat2 %>% count(firstcat)
bgdatcats <- bgdat2 %>% count(firstcat)
bgdatcats %>%  
  ggplot(aes(x = reorder(firstcat, n), weight = n)) + 
  geom_bar() + 
  coord_flip()
# only use categories with > 250 games (at least 2.5% of the games but have the category to be used)
bgdatcats2 <- bgdatcats %>% filter(n > 250)
bgdat3 <- bgdat2 %>% filter(firstcat %in% bgdatcats2$firstcat)
# facet by firstcat
ggplot(data = bgdat3) + 
  geom_linerange(aes(x = year_published, ymin = min_playtime, ymax = max_playtime, group = game_id)) + 
  labs(x = ""Year Published"", y = ""Playtime (minutes)"") + 
  facet_wrap(~firstcat, scales = ""free"")
# what about the mean of the min & max? 
ggplot(data = bgdat3) + 
  geom_point(aes(x=year_published , y = (min_playtime + max_playtime)/2, color = firstcat))
bgdat3 %>% mutate(mean_play = (min_playtime + max_playtime)/2) %>% 
  filter(mean_play < 1440) %>% # only look at games with less than a day of play time 
ggplot(aes(x = year_published, y = mean_play)) + 
  geom_point() + 
  geom_smooth() + 
  facet_wrap(~firstcat, scales = ""free"")
```

In the most popular games, it looks like the average game play has remained fairly stable over time. 
","2019"
"420",1523,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-19/r-ladies-ames-soln.Rmd","---
title:  ""R-Ladies Ames Solution""
author: ""Sam Tyner, Amanda Rae""
date: ""3/19/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r getdat}
library(tidyverse)
combined_data <- read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")
head(combined_data)
```

Since we're in Iowa, let's isolate the Iowa data 

```{r iowadat}
iowa <- filter(combined_data, state == ""IA"")
iowa
```

No Iowa. `r emo::ji(""sad"")`. 

Dowload Iowa data directly from [the SOPP website](https://openpolicing.stanford.edu/data/). (Not on Gitub because it's too large.) 

```{r iowadat2}
iowa <- read_rds(""iowa.rds"")
glimpse(iowa)
summary(iowa$date)
dim(iowa)
```

Lets only get the last 3 or so years in the data since there are over 2 million rows. 

```{r last5}
library(lubridate)
iowa %>% mutate(year = year(date)) %>% 
  filter(year >= 2013, !is.na(date)) -> iowa
head(iowa)
dim(iowa)
```

View the missingness with [`visdat`](http://dx.doi.org/10.21105/joss.00355). 

```{r miss}
library(visdat)
vis_dat(iowa, warn_large_data = FALSE)
```

```{r location}
count(iowa, location)
count(iowa, department_name)
```

","2019"
"421",1524,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-26/r-ladies-ames-soln.Rmd","---
title: ""R-Ladies Ames Solution""
date: ""March 26, 2019"" 
author: ""Sam Tyner, Stephanie Reinders""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align=""center"")
```

# Read the data in 

```{r getdat}
library(tidyverse)
pets <- read_csv(""seattle_pets.csv"")
head(pets)
```

Parsing dates & zip codes: 

```{r dates}
library(lubridate)
pets %>% 
  mutate(date = parse_date(license_issue_date, format = ""%B %d %Y""), 
         zip = parse_integer(zip_code)) -> pets
# check for missings 
pets %>% filter(is.na(date))
pets %>% filter(is.na(zip))
pets %>% filter(is.na(zip), !is.na(zip_code))

# if zip_code is not NA, only take the first 5 digits 
pets <- pets %>% 
  mutate(zip = ifelse((!is.na(zip_code) & is.na(zip)), parse_integer(str_sub(zip_code, 1, 5)), zip))
head(pets)
```

First letter of the animals' names by species. 

```{r lets}
pets %>% 
  mutate(first_letter = toupper(str_sub(animals_name, 1,1))) -> pets 
pets %>% 
  ggplot() + 
  geom_bar(aes(x = first_letter, fill = species)) 
```


```{r weird}
pets %>% filter(!(first_letter %in% LETTERS) , !(is.na(animals_name)))
# only 12 that are non-alpha
``` 

```{r lets2}
pets %>% filter(first_letter %in% LETTERS, species %in% c(""Cat"", ""Dog"")) %>% 
  ggplot() + 
  geom_bar(aes(x = first_letter, fill = species), position = ""dodge"")
pets %>% filter(first_letter %in% LETTERS, species %in% c(""Goat"", ""Pig"")) %>% 
  ggplot() + 
  geom_bar(aes(x = first_letter, fill = species), position = ""dodge"")
```

```{r goats}

filter(pets, species == ""Goat"") %>% 
  select(animals_name) %>% count(animals_name) %>% arrange(desc(n))

filter(pets, species == ""Pig"") %>% 
  select(animals_name) %>% count(animals_name) %>% arrange(desc(n))

```

Distribution of letters in Cats vs Dogs 

```{r chisq}
pets %>% filter(species %in% c(""Cat"", ""Dog""), first_letter %in% LETTERS) %>% 
  group_by(species, first_letter) %>% count() -> test

# ?chisq.test

cats <- (test %>% filter(species == ""Cat""))$n
dogs <- (test %>% filter(species == ""Dog""))$n

chisq.test(cats, dogs, correct = FALSE)
```

","2019"
"422",1525,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-04-09/tennis_pros.rmd","---
title: ""Men's and Women's Tennis""
author: ""Thomas Mock""
date: ""4/6/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
library(lubridate)
library(janitor)
```

### Get Women's Slams Records

I couldn't find a great source of historical dates for the grand slam winner's dates but they are consistently within a few days of each other based off my cursory examination. I fully ackowledge that the dates used for the tournament date are only estimations.

```{r}
raw_slams <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_women%27s_singles_champions"") %>% 
  html_table(fill = TRUE) %>% 
  .[[3]] %>% 
  janitor::clean_names()

clean_slams <- raw_slams %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove(name, """")),
         name = str_trim(str_remove(name, ""Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          TRUE ~ name)) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Female"") %>% 
  group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()
```


 
### Get Mens Slams Records

```{r}

raw_slams_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_men%27s_singles_champions"") %>% 
  html_nodes(xpath = '//*[@id=""mw-content-text""]/div/table[1]') %>% 
  html_table(fill = TRUE) %>% .[[1]] %>% janitor::clean_names()

clean_slams_men <- raw_slams_men %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  separate(col = winner, into = c(""country"", ""winner""), sep = "":"", fill = ""left"") %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove_all(name, ""|"")),
         name = str_trim(str_remove(name, ""Amateur era tennis ends|Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Male"") %>% 
  select(-country) %>% 
   group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()

```

### Get the Dates of Birth for women

This got the majority of women but I had to manually add birthdates for Ann and Chris.

```{r}
clean_dob <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[2]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          str_detect(name, ""Reid"") ~ ""Kerry Melville Reid"",
                          str_detect(name, ""Vicario"") ~ ""Arantxa Snchez Vicario"",
                          TRUE ~ name)) %>% 
  bind_rows(tibble(name = c(""Ann Haydon-Jones"",""Chris O'Neil""),
                   date_of_birth = c(lubridate::dmy(""7 October 1938""), lubridate::dmy(""19 March 1956""))))

dob_df <- clean_dob %>% 
  select(date_of_birth, name)
```

### Combine to get approx age at each tourney

```{r}
age_slams <- left_join(clean_slams, dob_df, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))
```

### MEN

```{r}
clean_dob_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  bind_rows(tibble(name = ""William Bowrey"",
                   date_of_birth = lubridate::dmy(""25 December 1943"")))

dob_df_men <- clean_dob_men %>% 
  select(date_of_birth, name)
```

### Combine

```{r}
age_slams_men <- left_join(clean_slams_men, dob_df_men, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

age_slams_men %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step()
```

### Total Combine

```{r}
grand_slams <- bind_rows(clean_slams, clean_slams_men) %>% 
  select(-total_win_count)
```

```{r}
player_dob <- bind_rows(clean_dob, clean_dob_men)
```

```{r}
age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age, gender) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

# test plot
age_slams_comb %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step() +
  facet_wrap(~gender)
```


```{r}
write_csv(grand_slams, ""grand_slams.csv"")
write_csv(player_dob, ""player_dob.csv"")
```


### Tennis Timeline Performance

I thought this was interesting data that could lead to some unique plots.

```{r}
yr_1968_1970 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[12]]
clean_1968_1970 <- yr_1968_1970 %>% 
  set_names(nm = paste0(names(yr_1968_1970), ""_"", yr_1968_1970[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1964_AUS`:`1970_USA`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year)) %>% 
  filter(year >= 1968)

yr_1971_1977 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[13]]

clean_1971_1977 <- yr_1971_1977 %>% 
  set_names(nm = paste0(names(yr_1971_1977), ""_"", yr_1971_1977[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1971_AUS`:`1977_AUSD`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year))

names(yr_1968_1970) %>% unique() %>% .[. != ""Player""] %>% as.integer()
```

I re-factored into a function but there were some gotchas in the data that limited where I could apply the function. Given I will never use it again I will somewhat break DRY principles for my own sake.

```{r}

get_timeline <- function(table_num){
  
  Sys.sleep(5)
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    filter(Player_Player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    rename(player = Player_Player) %>%
    mutate(year = as.integer(year))
}
```

# Collect women's timeline

```{r}

clean_1978_2012 <- 5:9 %>%
  map(get_timeline) %>%
  bind_rows()

```

```{r}
df_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[10]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}
final_timeline <- bind_rows(list(clean_1968_1970, clean_1971_1977, clean_1978_2012, clean_2013_2019)) %>% 
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Female"")

```

```{r}
final_timeline %>% group_by(tournament) %>% count(sort = TRUE)
```

### MENS Timeline

The function works a bit nicer here and I have further re-factored it.

```{r}
get_timeline_men <- function(table_num){
  Sys.sleep(5)
  
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>%
    na.omit() %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    janitor::clean_names(""all_caps"") %>% 
    select(-matches(""NA"")) %>% 
    select(player = PLAYER_PLAYER, matches(""AUS|FRA|WIM|USA"")) %>% 
    select(-matches(""NA|`NA`"")) %>% 
    filter(player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    mutate(year = as.integer(year))
}
```


```{r}
men_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[8]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}

clean_men_1967_2019 <- 3:10 %>% 
  map(get_timeline_men) %>% 
  bind_rows() %>% 
  filter(year > 1967)

final_timeline_men <- clean_men_1967_2019 %>%  
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Male"")

```


```{r}
both_timeline <- bind_rows(final_timeline, final_timeline_men) %>% 
  filter(str_length(player) > 4) %>% 
  filter(year <= 2019)

anti_timeline <- both_timeline %>% 
  filter(year == 2019 & tournament != ""Australian Open"")

combined_timeline <- anti_join(both_timeline, anti_timeline)
```

```{r}
write_csv(combined_timeline, ""grand_slam_timeline.csv"")
```

","2019"
"423",1526,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-04-16/economist-mistakes.R","library(tidyverse)
library(here)
library(janitor)

### Brexit Raw

brexit_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_brexit.csv""))

brexit_clean <- brexit_raw %>% 
  set_names(nm = .[3,]) %>% 
  clean_names() %>% 
  slice(4:nrow(.))

brexit_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""brexit.csv""))

### corbyn

corbyn_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_corbyn.csv""))

corbyn_clean <- corbyn_raw %>% 
  set_names(nm = ""political_group"", ""avg_facebook_likes"") %>% 
  na.omit()

corbyn_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""corbyn.csv""))

### dogs

dogs_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_dogs.csv""))

dogs_clean <- dogs_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""year"", ""avg_weight"", ""avg_neck""))

dogs_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""dogs.csv""))

### EU Balance

eu_balance_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_eu-balance.csv""))


names_eu <- eu_balance_raw %>% 
  .[1,] %>% 
  as.character()

datapasta::vector_paste_vertical(names_eu)  

clean_names_eu <- c(""country"",
              ""current_2009"",
              ""current_2010"",
              ""current_2011"",
              ""current_2012"",
              ""current_2013"",
              ""current_2014"",
              ""current_2015"",
              ""budget_2009"",
              ""budget_2010"",
              ""budget_2011"",
              ""budget_2012"",
              ""budget_2013"",
              ""budget_2014"",
              ""budget_2015"")

eu_current <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""current"")) %>% 
  select(-starts_with(""budget"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_budget <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""budget"")) %>% 
  select(-starts_with(""current"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_balance_clean <- bind_rows(eu_current, eu_budget)

eu_balance_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""eu_balance.csv""))

### Pensions

pensions_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_pensions.csv""))

pensions_clean <- pensions_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""country"", ""pop_65_percent"", ""gov_spend_percent_gdp""))

pensions_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""pensions.csv""))

### Trade

trade_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_us-trade-manufacturing.csv""))

trade_clean <- trade_raw %>% 
  set_names(nm = c(""year"", ""trade_deficit"", ""manufacture_employment"")) %>% 
  mutate(trade_deficit = trade_deficit * 1e9,
         manufacture_employment = manufacture_employment * 1e6) %>% 
  na.omit()

trade_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""trade.csv""))

### Women
women_research_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_women-research.csv""))

women_research_raw[1,] %>% 
  as.character() %>% 
  datapasta::vector_paste_vertical()

research_names <- c(""country"",
  ""Health sciences"",
  ""Physical sciences"",
  ""Engineering"",
  ""Computer science, maths"",
  ""Women inventores"")

women_research_clean <- women_research_raw %>% 
  na.omit() %>% 
  set_names(nm = research_names) %>% 
  filter(country != ""Country"") %>% 
  gather(field, percent_women, `Health sciences`:`Women inventores`)

women_research_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""women_research.csv""))

","2019"
"424",1527,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-05-14/nobel_winners.R","library(tidyverse)
library(here)
library(janitor)

# read in the specific category/field datasets and the overall winners

nobel_winners <- read_csv(here(""2019"", ""2019-05-14"", ""archive.csv"")) %>% 
  janitor::clean_names() %>% 
  rename(""prize_year"" = year,
         ""gender"" = sex)

chem_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Chemistry publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""chemistry"")

med_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Medicine publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""medicine"")

physics_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Physics publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""physics"")

all_pubs <- bind_rows(chem_pubs, med_pubs, physics_pubs)

all_pubs %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winner_all_pubs.csv""))

nobel_winners %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winners.csv""))




nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

nobel_winner_all_pubs %>% 
  distinct(category)","2019"
"425",1528,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-07-02/revenue.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/List_of_highest-grossing_media_franchises""

df <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE) %>% 
  .[[2]]

clean_money <- df %>% 
  set_names(nm = c(""franchise"", ""year_created"", ""total_revenue"", ""revenue_items"",
                   ""original_media"", ""creators"", ""owners"")) %>% 
  mutate(total_revenue = str_remove(total_revenue, ""est.""),
         total_revenue = str_trim(total_revenue),
         total_revenue = str_remove(total_revenue, ""[$]""),
         total_revenue = word(total_revenue, 1, 1),
         total_revenue = as.double(total_revenue))

clean_category <- clean_money %>% 
  separate_rows(revenue_items, sep = ""\\["") %>% 
  filter(str_detect(revenue_items, ""illion"")) %>% 
  separate(revenue_items, into = c(""revenue_category"", ""revenue""), sep = ""[$]"") %>% 
  mutate(revenue_category = str_remove(revenue_category, ""  ""),
         revenue_category = str_remove(revenue_category, regex("".*\\]"")),
         revenue_category = str_remove(revenue_category, ""\n"")) 

clean_df <- clean_category %>% 
  mutate(revenue_category = case_when(
    str_detect(str_to_lower(revenue_category), ""box office"") ~ ""Box Office"",
    str_detect(str_to_lower(revenue_category), ""dvd|blu|vhs|home video|video rentals|video sales|streaming|home entertainment"") ~ ""Home Video/Entertainment"",
    str_detect(str_to_lower(revenue_category), ""video game|computer game|mobile game|console|game|pachinko|pet|card"") ~ ""Video Games/Games"",
    str_detect(str_to_lower(revenue_category), ""comic|manga"") ~ ""Comic or Manga"",
    str_detect(str_to_lower(revenue_category), ""music|soundtrack"") ~ ""Music"",
    str_detect(str_to_lower(revenue_category), ""tv"") ~ ""TV"",
    str_detect(str_to_lower(revenue_category), ""merchandise|licens|mall|stage|retail"") ~ ""Merchandise, Licensing & Retail"",
    
    TRUE ~ revenue_category)) %>% 
  mutate(revenue = str_remove(revenue, ""illion""),
         revenue = str_trim(revenue),
         revenue = str_remove(revenue, "" ""),
         revenue = case_when(str_detect(revenue, ""m"") ~ paste0(str_extract(revenue, ""[:digit:]+""), ""e-3""),
                             str_detect(revenue, ""b"") ~ str_extract(revenue, ""[:digit:]+""),
                             TRUE ~ NA_character_),
         revenue = format(revenue, scientific = FALSE),
         revenue = parse_number(revenue)) %>%
  mutate(original_media = str_remove(original_media, ""\\[.+"")) 

sum_df <- clean_df %>%
  group_by(franchise, revenue_category) %>% 
  summarize(revenue = sum(revenue))

total_sum_df <- clean_df %>% 
  group_by(franchise) %>% 
  summarize(revenue = sum(revenue)) %>% 
  arrange(desc(revenue))

metadata_df <- clean_df %>% 
  select(franchise:revenue_category, original_media:owners, -total_revenue)

final_df <- left_join(sum_df, metadata_df, 
                      by = c(""franchise"", ""revenue_category"")) %>% 
  distinct(.keep_all = TRUE)

final_df
write_csv(final_df, ""media_franchises.csv"")
","2019"
"426",1529,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-07-09/wwc_cleaning.R","library(tidyverse)
library(here)

# read in the datasets
df <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""wwc_results.xlsx"")) %>% 
  mutate(Year = as.integer(Year))

df_2019 <- read_csv(here(""2019"", ""2019-07-09"", ""wwc_2019.csv""))

squads <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""Womens Squads.xlsx"")) %>% 
  janitor::clean_names()

# bind datasets to include 2019
df_all <- bind_rows(df, df_2019) %>% 
  janitor::clean_names()

# add win, tie status
df_both <- df_all %>% 
  group_by(year) %>% 
  mutate(yearly_game_id = row_number(),
         winner = case_when(score_1 > score_2 ~ ""Team 1 Win"",
                   score_2 > score_1 ~ ""Team 2 Win"",
                   score_1 == score_2 ~ ""Tie"",
                   TRUE ~ NA_character_)) 

# grab team 1/score 1
df_team_1 <- df_both %>% 
  select(year:score_1, round, yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 1)

# grab team2/score 2
df_team_2 <- df_both %>% 
  select(year, team_2:yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 2)

# attach team1/team2 datasets together
# Assign winner, loser, tie,
# Correct for shootout wins in knockout stages

df_tidy <- bind_rows(df_team_1, df_team_2) %>% 
  arrange(year, yearly_game_id) %>% 
  mutate(win_status = case_when(team_num == as.integer(str_extract(winner, ""[:digit:]"")) ~ ""Won"",
                            team == ""USA"" & round == ""Final"" & year == 1999 ~ ""Won"",
                            team == ""NOR"" & round == ""Round of 16"" & year == 2019 ~ ""Won"",
                            team == ""JPN"" & round == ""Final"" & year == 2011 ~ ""Won"",
                            team == ""CHN"" & round == ""Quarter Final"" & year == 1995 ~ ""Won"",
                            team == ""FRA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""USA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""GER"" & round == ""Quarter Final"" & year == 2015 ~ ""Won"",
                            team == ""BRA"" & round == ""Third Place Playoff"" & year == 1999 ~ ""Won"",
                            round == ""Group"" & winner == ""Tie"" ~ ""Tie"",
                            TRUE ~ ""Lost"")) %>% 
  select(-winner)

# confirm no double winners/losers
df_tidy %>% 
  filter(round != ""Group"") %>% 
  group_by(year, round, yearly_game_id) %>% 
  count(win_status, sort = TRUE) %>% 
  filter(n >1)

# output to csv
df_tidy %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""wwc_outcomes.csv""))

squads %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""squads.csv""))


# data dictionaries for TidyTuesday
tomtom::create_dictionary(df_tidy)
tomtom::create_dictionary(squads)
","2019"
"427",1530,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-09-03/moores_law.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/Transistor_count""

tables <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE)

df1 <- tables %>% chuck(1) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df1_clean <- df1 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = str_sub(date_of_introduction, 1, 4),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
    ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)


df1_clean %>%
  mutate() 
df2 <- tables %>% chuck(2) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df2_clean <- df2 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)

df3 <- tables %>% chuck(4) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df3

df3_clean <- df3 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = if_else(
      str_length(date_of_introduction) >= 5,
      str_sub(date_of_introduction, -4),
      str_sub(date_of_introduction, 1, 4)),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+""),
    bit_units = case_when(
      str_detect(capacity_bits, ""bit"") ~ ""Bits"",
      str_detect(capacity_bits, ""kb"") ~ ""kb"",
      str_detect(capacity_bits, ""Mb"") ~ ""Mb"",
      str_detect(capacity_bits, ""Gb"") ~ ""Gb"",
      TRUE ~ """"
                 )
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double) %>% 
  select(chip_name, capacity_bits, bit_units, everything()) %>% 
  mutate(capacity_bits = str_extract(capacity_bits, ""[:digit:]+""))

df3_clean

write_csv(df1_clean, here::here(""2019"", ""2019-09-03"", ""cpu.csv""))
write_csv(df2_clean, here::here(""2019"", ""2019-09-03"", ""gpu.csv""))
write_csv(df3_clean, here::here(""2019"", ""2019-09-03"", ""ram.csv""))

tomtom::create_dictionary(df1_clean)

cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")
gpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")
ram <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")

","2019"
"428",1531,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-09-17/parks.R","library(tidyverse)
library(rvest)

df_raw <- read_csv(here::here(""2019/2019-09-17/All National Parks Visitation 1904-2016.csv"")) 

df <- df_raw %>% 
  janitor::clean_names() %>%
  mutate(date = lubridate::mdy_hms(year)) %>% 
  select(date, gnis_id, geometry:year_raw)

df %>% 
  write_csv(here::here(""2019/2019-09-17/national_parks.csv""))


# Get pop data

url <- ""https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_historical_population""

raw_html <- url %>% 
  read_html() %>% 
  html_table()

pop_df <- raw_html %>% 
  chuck(5) %>% 
  gather(key = ""state"", value = ""pop"", AL:DC) %>% 
  rename(""year"" = 1) %>% 
  mutate(pop = str_remove_all(pop, "",""),
         pop = as.double(pop))

pop_df %>% 
  write_csv(here::here(""2019/2019-09-17"", ""state_pop.csv""))

# Get gas prices

url2 <- ""https://www.energy.gov/eere/vehicles/fact-915-march-7-2016-average-historical-annual-gasoline-pump-price-1929-2015""

raw_gas <- url2 %>% 
  read_html() %>% 
  html_table()

gas <- raw_gas %>% 
  chuck(1) %>% 
  set_names(nm = c(""year"", ""gas_current"", ""gas_constant"")) %>%   
  as_tibble() %>% 
  filter(!str_detect(year, ""Source"")) %>% 
  mutate(year = as.double(year),
         gas_current = as.double(gas_current),
         gas_constant = as.double(gas_constant))

gas %>% 
  write_csv(here::here(""2019/2019-09-17"", ""gas_price.csv""))
","2019"
"429",1532,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-09-24/RLA_solution.Rmd","---
title: ""TidyTuesday_9_24_19""
author: ""Stephanie Reinders""
date: ""9/24/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Load the data
```{r}
d <- read.csv('school_diversity.csv')
```

## Explore the data
```{r}
str(d)
```

```{r}
head(d)
```



```{r}
d %>% filter(SCHOOL_YEAR=='2016-2017') %>% group_by(SCHOOL_YEAR,ST,) %>% summarize(nasian = mean(Asian)) %>% arrange(desc(nasian))
```

## Gather racial group data into a single column
```{r}
d <- d %>% gather(""racial_group"",""value"",6:11)
```


```{r}
d %>% filter(SCHOOL_YEAR=='2016-2017') %>% group_by(racial_group,ST) %>% summarize(mean = mean(value))
```


","2019"
"430",1533,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-10-08/RLA_10_8_19_meeting.Rmd","---
title: ""RLA_10_8_19""
author: ""Stephanie Reinders""
date: ""10/8/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r}
d <- data.frame('ipf_lifts.csv')

```



","2019"
"431",1534,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-10-15/RLA_10_15_19.Rmd","---
title: ""RLA_10_15_19""
author: ""Stephanie Reinders""
date: ""10/15/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r get_data}
d <- read.csv('big_epa_cars.csv')
```

```{r basic_info}
dim(d)
str(d)
```

```{r explore_makes_and_models}

allmakes <- unique(d$make) %>% sort() 

d %>% 
  group_by(make,model,year) %>%
  select(make,model,year)

```

```{r}
t <- d %>% 
  filter(make==""Toyota"", model==""Corolla"") %>%
  select(year,make,model,trany,id,displ,youSaveSpend)

t_auto_1.6 <- t %>% filter(trany==""Automatic 4-spd"",displ==1.6)
```

```{r}
t %>% ggplot(aes(year,youSaveSpend,group=interaction(trany,displ),color=interaction(trany,displ))) +
  geom_point() +
  geom_hline(yintercept=0, linetype=""dashed"", color = ""red"") +
  ylab(""youSaveSpend ($)"") +
  labs(color=""transmition and engine displacement"")
```


```{r}
t %>% 
  filter(trany %in% c(""Automatic 3-spd"",""Automatic 4-spd"",""Automatic (AV-S10)"",""Automatic (S5)"",""Automatic (variable gear ratios)"")) %>%
      ggplot(aes(year,youSaveSpend)) +
        geom_point() +
        geom_hline(yintercept=0, linetype=""dashed"", color = ""red"") +
        facet_wrap(trany~displ) +
        ylab(""youSaveSpend ($)"") +
        theme(legend.position = ""none"")
```","2019"
"432",1535,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-10-22/RLA_10_22_19.Rmd","---
title: ""RLA_10_22_19""
author: ""Stephanie Reinders""
date: ""10/22/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r}
d <- read.csv('horror_movies.csv')
```

```{r}
summary(d)
```

```{r}
d %>% filter(language == ""Japanese"") %>% 
  ggplot(aes(review_rating)) +
  geom_histogram(binwidth=1)
```

```{r}
d2 <- separate(d,language, into = c(""language1"",""language2""), extra = ""merge"")
```

```{r}
rating <- d2 %>%
  group_by(language1) %>%
  summarize(n=n(),
            mean_rating = mean(review_rating))
rating
``` 

```{r}
d2 %>% filter(language1==""English"") %>%
  select(review_rating)
```



```{r}  
rating %>% 
  ggplot(aes(language1,mean_rating,fill=mean_rating)) +
  geom_bar(stat=""identity"",position=""dodge"") + 
  coord_flip()
```


","2019"
"433",1536,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-11-05/RLA_11_5_19.Rmd","---
title: ""RLA_11_5_19""
author: ""Stephanie Reinders""
date: ""11/5/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Data on Bicycling and Walking to Work in the US
```{r}
d <- read.csv('commute.csv')
```

```{r}
summary(d)
```

## Iowa Bicyclists and Walkers
```{r}
d %>% filter(state=='Iowa',mode=='Bike') %>% 
  ggplot(aes(x=as.factor(city),y=percent,color=city)) +
  geom_point() +
  coord_flip()
```


```{r}
d %>% filter(state=='Iowa',mode=='Walk') %>% 
  ggplot(aes(x=as.factor(city),y=percent,color=city)) +
  geom_point() +
  coord_flip()
```


","2019"
"434",1537,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-11-05/bike_walk.R","# Load Packages -----------------------------------------------------------

library(tidyverse)
library(readxl)
library(here)
library(glue)
library(janitor)

# Read in Data ------------------------------------------------------------

table_num <- 1:6

# Generic read function for this dataset

supp_read <- function(number, ...){
  read_excel(here(""2019"", ""2019-11-05"", glue::glue(""supplemental-table{number}.xlsx"")), ...)
}

# 3 datasets for bikes, each of which has a corresponding City Size

small_bike <- supp_read(1, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"", 
         percentage_of_workers = as.numeric(percentage_of_workers),
         margin_of_error_2 = as.numeric(margin_of_error_2))

medium_bike <- supp_read(2, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_bike <- supp_read(3, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_bike <- bind_rows(small_bike, medium_bike, large_bike) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Bike"")


# 3 datasets for walking, each of which has a corresponding City Size

small_walk <- supp_read(4, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"")

medium_walk <- supp_read(5, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_walk <- supp_read(6, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_walk <- bind_rows(small_walk, medium_walk, large_walk) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Walk"")

# Built in state-level datasets
state_df <- tibble(
  state = state.name,
  state_abb = state.abb,
  state_region = as.character(state.region)
)

# Combine bike and walk data in tidy setup

full_commute <- 
  bind_rows(full_bike, full_walk) %>% 
  filter(!is.na(n),
         # There are some government-related areas that don't align with cities
         !str_detect(tolower(city), ""government|goverment"")) %>% 
  separate(city, into = c(""city"", ""state""), sep = "", "") %>% 
  select(city, state, city_size, mode, everything()) %>% 
  left_join(state_df, by = c(""state""))

full_commute %>% 
  write_csv(here(""2019"", ""2019-11-05"", ""commute.csv""))

# ACS Data ----------------------------------------------------------------

acs_data <- read_csv(here(""2019"", ""2019-11-05"", ""table_3.csv""))

age_data <- acs_data %>% 
  slice(1:6)

gender_data <- acs_data %>% 
  slice(9:10) %>% 
  rename(""gender"" = age)

race_data <- acs_data %>% 
  slice(13:18) %>% 
  rename(""race"" = age)

children_data <- acs_data %>% 
  slice(20:24) %>% 
  rename(""children"" = age)

income_data <- acs_data %>% 
  slice(27:36) %>% 
  rename(""income"" = age)

education_data <- acs_data %>% 
  slice(39:43) %>% 
  rename(""education"" = age)

","2019"
"435",1538,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-15/space_shuttle.Rmd","trevinflick","tidytuesday","2019-01-15/space_shuttle.Rmd","---
title: ""Space Launches""
author: ""Trevin Flickinger""
date: ""1/16/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggthemes)

launches <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")

agencies <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/agencies.csv"")
```

```{r}
launches %>%
  count(type, sort = TRUE)
```

Let's take a look at the Space Shuttle

```{r}
space_shuttle <- launches %>%
  filter(type == ""Space Shuttle"")

space_shuttle <- space_shuttle %>%
  arrange(launch_date)

space_shuttle$launch_number <- c(1:135)
```

```{r}
days_between_launches <- tail(space_shuttle$launch_date, -1) - head(space_shuttle$launch_date, -1)

space_shuttle$days_til_next <- c(tail(space_shuttle$launch_date, -1) - head(space_shuttle$launch_date, -1), 0)

space_shuttle %>%
  filter(days_til_next > 0) %>%
  ggplot(aes(days_til_next)) +
  geom_freqpoly()

```

```{r}
space_shuttle %>%
  ggplot(aes(x = launch_date, y = launch_number)) +
  geom_line(size = 0.5) +
  geom_point() +
  annotate(""text"", x=as.Date(""1986-01-28""), y=40, 
           label = ""Challenger disaster"", size = 3.5) +
  annotate(""segment"", x=as.Date(""1986-01-28""), 
           xend=as.Date(""1986-01-28""),
           y=25, yend = 36, color = ""black"") +
  annotate(""text"", x=as.Date(""2003-01-16""), y=125, 
           label = ""Columbia disaster"", size = 3.5) +
  annotate(""segment"", x=as.Date(""2003-01-16""), 
           xend=as.Date(""2003-01-16""),
           y=113, yend = 121, color = ""black"") +
  labs(title = ""Space Shuttle Launches Over Time"",
       caption = ""TidyTuesday 01/08/2019, source:The Economist"") +
  theme_fivethirtyeight()
  
ggsave(""space_shuttle.png"")
  
```


","2019"
"436",1539,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-29/cheeses.R","trevinflick","tidytuesday","2019-01-29/cheeses.R","library(tidyverse)
library(gganimate)
library(ggthemes)

milk <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/state_milk_production.csv"")
cheese <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/clean_cheese.csv"")

cheese %>% 
  summarise_at(vars(2:13), sum, na.rm = TRUE) %>%
  gather(cheese, amount) %>%
  arrange(desc(amount))

## Make an 'other' category

cheese$Other <- rowSums(cheese[,c(""Other Dairy Cheese"", ""Muenster"", ""Blue"", ""Brick"",
                                  ""Swiss"", ""Cream and Neufchatel"")], na.rm = TRUE)

cheese %>% 
  select(Year,
         Cheddar,
         ""American"" = ""American Other"",
         Mozzarella,
         ""Italian"" = ""Italian other"",
         ""Processed"" = ""Processed Cheese"",
         ""Spreads"" = ""Foods and spreads"",
         Other) %>%
  gather(cheese, amount, -Year) %>%
  ggplot(aes(x = Year, y = amount, group = cheese)) +
  geom_path() +
  geom_text(aes(label = cheese), 
            nudge_x = 1,
            nudge_y = 0.3) +
  labs(x = """", y = ""Average Consumption in Pounds per Person"",
       title = ""What's causing Mozzarella's rise in consumption?"",
       subtile = ""Average American cheese consumption 1970-2017"",
       caption = ""TidyTuesday 01/29/19 source:USDA"") +
  theme_light() +
  transition_reveal(along = Year) +
  ease_aes('linear')

anim_save(""cheese.gif"", last_animation())
","2019"
"437",1540,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-09","trevinflick","tidytuesday","2018-10-09/plot.R","# install rstan and rethinking packages

# install.packages(""rstan"", repos = ""https://cloud.r-project.org/"", dependencies=TRUE)
# install.packages(c(""coda"",""mvtnorm"",""devtools"",""loo""))
# library(devtools)
# devtools::install_github(""rmcelreath/rethinking"")

library(rstan)
library(readr)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(rethinking)
library(ggthemes)

turnout <- read_csv(""voter_turnout.csv"")

turnout$pct <- turnout$votes / turnout$eligible_voters

# create new column if year is a midterm
midterm <- c(1982, 1986, 1990, 1994, 1998, 2002, 2006, 2010, 2014)
turnout$midterm <- ifelse(turnout$year %in% midterm, 1, 0)

us <- turnout %>%
  filter(state == ""United States"") %>%
  select(year, us_pct = pct)

turnout <- left_join(turnout, us, by = ""year"") %>%
  filter(year >= 1998)

# find the states with na values
state_na <- turnout %>%
  filter(is.na(votes))

# lag variable
turnout <- turnout %>%
  arrange(state, year) %>%
  group_by(state) %>%
  mutate(last_vote = lag(pct, n = 2))

# let's impute the missing data for minnesota
minnesota <- turnout %>%
  filter(state == ""Minnesota"")

# prep data
data_list <- list(
  usa = minnesota$us_pct,
  last_vote = minnesota$last_vote,
  pct = minnesota$pct
)

# model for missing data
m <- map2stan(
  alist(
    usa ~ dnorm(mu,sigma),
    mu <- a + bP*pct +bL*last_vote,
    pct ~ dnorm(nu,sigma_N),
    last_vote ~ dnorm(nu,sigma_N),
    a ~ dnorm(0,100),
    bP ~ dnorm(0,10),
    bL ~ dnorm(0,10),
    nu ~ dnorm(0.5,1),
    sigma_N ~ dcauchy(0,1),
    sigma ~ dcauchy(0,1)
  ),
  data = data_list, iter = 1e4, chains = 2
)

# extract imputed means
# precis(m, depth=2)

# drop columns from data frame
turnout <- turnout %>%
  select(year, state, pct)

imputed <- tibble(
  year = c(2000, 2002, 2004),
  state = c(""imp"", ""imp"", ""imp""),
  votes = c(2458303, NA, 2842912),
  eligible_voters = c(3506432, 3518184, 3609185),
  imputed_mean = c(NA, 0.57, NA),
  imputed_std = c(NA, 0.05, NA)
)

imputed$pct <- imputed$votes / imputed$eligible_voters
imputed <- imputed %>% replace_na(list(pct = 0.57))

imputed <- imputed %>%
  select(year, state, pct)

turnout <- rbind(turnout, imputed)

turnout %>%
  ggplot(aes(x = year, y = pct, group = state)) +
  geom_line(alpha = 0.15) +
  geom_line(data = filter(turnout, state == ""imp""), aes(x = year, y = pct), color = ""blue"", size = 1, linetype = 3) +
  geom_line(data = filter(turnout, state == ""United States""), aes(x = year, y = pct), color = ""black"", size = 1) +
  geom_line(data = filter(turnout, state == ""Minnesota""), aes(x = year, y = pct), color = ""blue"", size = 1) + 
  scale_x_continuous(limits = c(1998,2016), breaks = c(2000, 2004, 2008, 2012)) +
  scale_y_continuous(limits = c(0,1), labels = scales::percent) +
  geom_text(data = filter(turnout, year == 2014 & state == ""United States""),
            aes(label = state, x = year + 1.45, y = pct), size = 3.5, color = ""black"") +
  geom_text(data = filter(turnout, year == 2014 & state == ""Minnesota""),
            aes(label = state, x = year + 1.25, y = pct), size = 3.5, color = ""blue"") +
  annotate(geom = ""text"", x = 2012, y = 0.80, label = ""Presidential election"", size = 3.5) +
  annotate(geom = ""text"", x = 2010, y = 0.27, label = ""Midterm election"", size = 3.5) +
  labs(x = """", y = """", title = ""United States Voter Turnout: 1998-2014"",
       subtitle = ""Minnesota turnout imputed for 2002 election"",
       caption = ""TidyTuesday 10/09/18, source:data.world"") +
  theme_fivethirtyeight()
  
  





  



","2018"
"438",1541,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-16","trevinflick","tidytuesday","2018-10-16/college_majors.R","library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggthemes)

# read in the data
all_ages <- read_csv(""all-ages.csv"")
grad_students <- read_csv(""grad-students.csv"")
majors_list <- read_csv(""majors-list.csv"")
recent_grads <- read_csv(""recent-grads.csv"")
women_stem <- read_csv(""women-stem.csv"")

# drop missing values
recent_grads <- recent_grads %>%
  drop_na(Total)

# earnings by major category
recent_grads %>%
  group_by(Major_category) %>%
  summarize(
    count = n(),
    earnings = mean(Median),
    Max = max(Median)
  )

# filter out major categories with < 8 majors
big_category <- recent_grads %>%
  filter(Major_category != ""Interdisciplinary"" &
           Major_category != ""Communications & Journalism"" &
           Major_category != ""Law & Public Policy"" &
           Major_category != ""Industrial Arts & Consumer Services"") 

# plot
big_category %>%
  ggplot(aes(x = reorder(Major_category, -Median, mean),
             y = Median)
         ) +
  geom_dotplot(binaxis = ""y"", stackdir = ""center"", 
               dotsize = 0.5) +
  stat_summary(fun.y=mean, geom=""point"", shape = 18,
               size=3, color=""red"") +
  geom_text(data = filter(big_category, Major == ""PETROLEUM ENGINEERING""),
            aes(label = ""Petroleum Engineering""), size = 3, 
            hjust = -0.05, vjust = 0.3) +
  geom_text(data = filter(big_category, Major == ""PETROLEUM ENGINEERING""),
            aes(label = ""($110,000)""), size = 3, 
            hjust = -0.55, vjust = 2.5) +
  geom_text(data = filter(big_category, Major_category == ""Arts"" &
                            Median == 50000),
            aes(label = ""Miscellaneous Fine Arts""), size = 3, 
            hjust = -0.05, vjust = 0.3) +
  geom_text(data = filter(big_category, Major_category == ""Physical Sciences"" &
                            Median == 62000),
            aes(label = ""Astronomy and Astrophysics""), size = 3, 
            hjust = -0.05, vjust = 0.3) +
  labs(x = """", y = """",
       title = ""Earnings for Recent College Grads"",
       caption = ""TidyTuesday 10/16/18, source:fivethirtyeight"") +
  theme_fivethirtyeight() +
  theme(text = element_text(size = 10),
        axis.text.x = element_text(angle = 60, hjust = 1)) 









","2018"
"439",1542,"https://github.com/trevinflick/tidytuesday/blob/master/2019-03-26/seattle-pet-names.Rmd","trevinflick","tidytuesday","2019-03-26/seattle-pet-names.Rmd","---
title: ""Pet Names""
author: ""Trevin Flickinger""
date: ""3/26/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(ggthemes)
library(kableExtra)

seattle_pets <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")

seattle_pets$license_issue_date <- as.Date(seattle_pets$license_issue_date,
                                           ""%B %d %Y"")

seattle_pets$animals_name <- str_replace(seattle_pets$animals_name, "" \\(.*\\)"", """")
seattle_pets$animals_name <- str_replace(seattle_pets$animals_name, "" \\\"".*\\\"""", """")
seattle_pets$animals_name <- str_replace(seattle_pets$animals_name, "" \\\'.*\\\'"", """")

seattle_pets$name_length <- nchar(seattle_pets$animals_name)

pets_2018 <- seattle_pets %>% filter(year(license_issue_date) == 2018)
```

# Most popular names

```{r}
top_names <- pets_2018 %>% drop_na(animals_name) %>%
  count(animals_name, sort = TRUE) %>%
  head(20)
```

```{r}
top_names %>% 
  mutate(animals_name = fct_reorder(animals_name, n)) %>%
  ggplot() +
  geom_col(aes(x = animals_name, y = n)) +
  coord_flip() +
  labs(title = ""Most popular pet names in Seattle in 2018"",
       x = """", y = """") +
  theme_light()
```

# Most popular dog names

```{r}
dogs_2018 <- pets_2018 %>% drop_na(animals_name) %>%
  filter(species == ""Dog"")

top_dogs <- dogs_2018 %>%
  count(animals_name, sort = TRUE)
```

# Most popular cat names

```{r}
cats_2018 <- pets_2018 %>% drop_na(animals_name) %>%
  filter(species == ""Cat"")

top_cats <- cats_2018 %>%
  count(animals_name, sort = TRUE)
```


```{r}
top_dogs %>% 
  mutate(animals_name = fct_reorder(animals_name, n)) %>%
  head(20) %>%
  ggplot() +
  geom_col(aes(x = animals_name, y = n)) +
  coord_flip() +
  labs(title = ""Most popular dog names in Seattle in 2018"",
       x = """", y = """") +
  theme_light()
```

# Dogs names that end in y or ie

```{r}
dogs_y_ie <- dogs_2018[(str_ends(dogs_2018$animals_name, ""y"") |
          str_ends(dogs_2018$animals_name, ""ie"")), ]
```

# Cats that end in y or ie

```{r}
cats_y_ie <- cats_2018[(str_ends(cats_2018$animals_name, ""y"") |
          str_ends(cats_2018$animals_name, ""ie"")), ]
```

# 24% of cats and 30% of dogs end in y or ie

```{r}
dogs_y_ie %>% count(animals_name, sort = TRUE) %>% View()
cats_y_ie %>% count(animals_name, sort = TRUE) %>% View()
```

# comparing fenway vs wrigley

```{r}
pets_2018 %>% filter(animals_name == ""Fenway"" | 
                       animals_name == ""Wrigley"") %>%
  ggplot(aes(animals_name)) +
  geom_bar(aes(fill = animals_name)) +
  scale_fill_manual(values = c(""#BD3039"",""#0E3386""), guide = FALSE) +
  coord_flip() +
  labs(x = """", y = """",
       title = ""Pets in Seattle named after ballparks"",
       caption = ""@trevin_flick"") +
  theme_fivethirtyeight()
  
ggsave(""mlb-pets.png"")
```


# 10 longest dog names

```{r}
dogs_2018 %>% arrange(desc(name_length)) %>%
  head(10) %>%
  kable() %>% 
  kable_styling()
```

```{r}
cats_2018 %>% arrange(desc(name_length)) %>%
  head(10) %>%
  kable() %>% 
  kable_styling()
```


### Extra code


# Most popular cat names

```{r}
top_cats <- pets_2018 %>% filter(species == ""Cat"") %>% 
  drop_na(animals_name)
```

# Duplicate license numbers

```{r}
pets_2018 %>% 
  group_by(license_number) %>% 
  filter(n() > 1) %>%
  arrange(license_number) %>%
  View()
```

# Most popular type of pet

```{r}
pets_2018 %>% drop_na(species) %>%
  count(species, sort = TRUE)
```




","2019"
"440",1543,"https://github.com/trevinflick/tidytuesday/blob/master/2019-02-19/us_phd.Rmd","trevinflick","tidytuesday","2019-02-19/us_phd.Rmd","---
title: ""TidyTuesday Week 8""
author: ""Trevin Flickinger""
date: ""2/19/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)

phd_field <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")
```

```{r}
phd_field %>%
  group_by(field) %>%
  summarize(sd_phd = sd(n_phds, na.rm = TRUE)) %>%
  arrange(desc(sd_phd)) %>%
  View()

phd_field %>%
  group_by(year) %>%
  summarise(total_phd = sum(n_phds, na.rm = TRUE)) %>%
  ggplot(aes(year, total_phd)) +
  geom_line(size = 1.5, color = ""blue"") +
  scale_x_continuous(breaks = seq(2008, 2016, by = 4)) +
  labs(x = """", y = """", 
       title = ""Total number of PhD's awarded in the US per year"",
       subtitle = ""Data from 2008-2017 via NSF"") +
  theme_fivethirtyeight()
```

```{r}
ggsave(""total_phds.png"")
```


```{r}
phd_field %>%
  group_by(broad_field, year) %>%
  summarise(total_phd = sum(n_phds, na.rm = TRUE)) %>%
  ggplot(aes(year, total_phd, color = broad_field)) +
  geom_line(size = 1.5) +
  scale_x_continuous(breaks = seq(2008, 2016, by = 4)) +
  labs(x = """", y = """", 
       title = ""Total number of PhD's awarded in the US per year"",
       subtitle = ""Data from 2008-2017 via NSF"")
```

```{r}
phd_field %>%
  group_by(field, year) %>%
  summarise(total_phd = sum(n_phds, na.rm = TRUE)) %>%
  filter(field %in% c(""Social sciences"", ""Physics"", ""Computer science"", ""Clinical psychology"", ""Other economics"")) %>%
  ggplot(aes(year, total_phd, color = field)) +
  geom_point() +
  geom_line(size = 1.5) +
  scale_x_continuous(breaks = seq(2008, 2016, by = 4)) +
  labs(x = """", y = """", 
       title = ""Total number of PhD's awarded in the US per year"",
       subtitle = ""Data from 2008-2017 via NSF"")
```

```{r}

```

","2019"
"441",1544,"https://github.com/trevinflick/tidytuesday/blob/master/2019-03-05/women_workers.Rmd","trevinflick","tidytuesday","2019-03-05/women_workers.Rmd","---
title: ""tidy tuesday march 5""
author: ""Trevin Flickinger""
date: ""3/5/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(scales)
library(ggthemes)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")

jobs_2016 <- jobs_gender %>% filter(year == 2016)
```

# Top 20 occupations by percent of female workers

```{r}
jobs_2016 %>% select(occupation, percent_female, workers_female, total_earnings, total_earnings_female) %>% 
  arrange(desc(percent_female)) %>%
  top_n(20, wt = percent_female)
```

# Top 20 occupations by percent of male workers

```{r}
jobs_2016 %>% 
  mutate(percent_male = 100 - percent_female) %>%
  select(occupation, percent_male, workers_male, total_earnings, total_earnings_male) %>% 
  arrange(desc(percent_male)) %>%
  top_n(20, wt = percent_male)
```

# Jobs where female workers earn more compared to men

```{r}
jobs_2016 %>% mutate(pay_diff = total_earnings_female - total_earnings_male) %>% 
  filter(total_earnings_female > total_earnings_male) %>% 
  View()
```


```{r}
employed_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"")
```

```{r}
employed_gender %>%
  mutate(last_year_female = lag(full_time_female),
         last_year_male = lag(full_time_male),
         female_delta = full_time_female - last_year_female,
         male_delta = full_time_male - last_year_male) %>%
  View()
```


```{r}
employed_gender %>%
  ggplot(aes(year)) + 
  geom_line(aes(y = full_time_male, color = ""blue"")) +
  geom_line(aes(y = full_time_female, color = ""red"")) +
  geom_line(aes(y = total_full_time, color = ""black"")) +
  scale_y_continuous(labels = function(x) paste0(x, ""%"")) +
  scale_color_manual(name = """",
                     values = c(""red""=""red"",""blue""=""blue"",""black""=""black""),
                     labels = c(""Total"",""Male"",""Female"")) +
  labs(title = ""Percent of full time workers from 1968-2016"",
       x="""", y="""", caption = ""source: Census Bureau"") +
  annotate(""rect"", xmin = 1993, xmax = 1994, ymin = 70, ymax = 93,
        alpha = .2) +
  theme_fivethirtyeight()
```

```{r}
ggsave(""pct_workers.png"")
```


```{r}
employed_gender %>%
  ggplot(aes(year)) + 
  geom_line(aes(y = part_time_male, color = ""blue"")) +
  geom_line(aes(y = part_time_female, color = ""red"")) +
  scale_y_continuous(labels = function(x) paste0(x, ""%"")) +
  scale_color_manual(name = ""Gender"",
                     values = c(""red""=""red"",""blue""=""blue""),
                     labels = c(""Male"",""Female"")) +
  labs(title = ""Percent of part time workers from 1968-2016"",
       x="""", y="""") +
  theme_fivethirtyeight()
```


```{r}
earnings_female <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"")
```

```{r}
earnings_female %>%
  ggplot(aes(Year, percent, color = group)) +
  geom_line(size = ifelse(earnings_female$group == ""25-34 years"", 1.5, 1.0))
```





","2019"
"442",1545,"https://github.com/trevinflick/tidytuesday/blob/master/2019-02-05/home_price_index.Rmd","trevinflick","tidytuesday","2019-02-05/home_price_index.Rmd","---
title: ""Housing Info""
author: ""Trevin Flickinger""
date: ""2/4/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(prophet)
library(ggthemes)

hpi <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")
```

How do the states compare?

```{r}
# Max
hpi %>% group_by(state) %>%
  summarise(max_hpi = max(price_index)) %>%
  arrange(desc(max_hpi))

# Median
hpi %>% group_by(state) %>%
  summarise(avg_hpi = median(price_index)) %>%
  arrange(desc(avg_hpi)) %>%
  View()

# Mean
hpi %>% group_by(state, year) %>%
  summarise(avg_hpi = median(price_index)) %>%
  arrange(desc(avg_hpi)) %>%
  View()
```

```{r}
hpi_year <- hpi %>%
  group_by(state, year) %>%
  summarise(avg_hpi = mean(price_index))

us_year <- hpi %>%
  group_by(year) %>%
  summarise(avg_hpi = mean(us_avg))
```


# Let's do some plots

```{r}
hpi_year %>%
  ggplot() + 
  geom_line(aes(x = year, y = avg_hpi)) +
  facet_wrap( ~ state)
  
```

```{r}
midwest <- c(""OH"", ""MI"", ""IN"", ""IL"", ""WI"", ""MN"", ""ND"", ""SD"", ""NE"", ""KS"", ""MO"", ""IA"")

hpi_year %>%
  filter(state %in% midwest) %>%
  ggplot() + 
  geom_line(aes(x = year, y = avg_hpi)) +
  facet_wrap( ~ state) +
  labs(title = ""Midwest U.S. Price Index"")
```

Okay, let's do some predictions

```{r}
state_m <- hpi %>%
  mutate(year_month = as.Date(""0000-01-01"") + years(year) + months(month - 1)) %>%
  select(ds = year_month, state, y = price_index) %>%
  nest(-state) %>% 
  mutate(m = map(data, prophet))

state_future <- state_m %>%
  mutate(future = map(m, make_future_dataframe, periods = 120, freq = ""month""))

state_forecast <- state_future %>%
  mutate(forecast = map2(m, future, predict))

tidy_forecast <- state_forecast %>%
  unnest(forecast)

state_forecast %>%
  unnest(data) %>%
  ggplot() + 
  geom_line(aes(ds, y)) + 
  geom_ribbon(data = tidy_forecast, aes(as.Date(ds), ymin = yhat_lower, ymax = yhat_upper)) +
  facet_wrap( ~ state, scales = ""free_y"") 
```

```{r}
mw <- state_forecast %>%
  unnest(data) %>%
  filter(state %in% midwest)

mw_forecast <- tidy_forecast %>%
  filter(state %in% midwest)

mw$state <- state.name[match(mw$state,state.abb)]
mw_forecast$state <- state.name[match(mw_forecast$state,state.abb)]

mw %>%
  ggplot() + 
  geom_line(aes(ds, y)) + 
  geom_ribbon(data = mw_forecast, aes(as.Date(ds), ymin = yhat_lower, ymax = yhat_upper), alpha = 0.3,
              fill = ""blue"") +
  facet_wrap( ~ state, scales = ""free_y"") +
  labs(x = """", y = """", 
       title = ""Forecasted Midwest House Price Index"",
       subtitle = ""based on Freddie Mac data 1975-2018"") +
  theme_fivethirtyeight()
```

```{r}
mw %>%
  ggplot() + 
  geom_line(aes(ds, y)) + 
  geom_ribbon(data = mw_forecast, aes(as.Date(ds), ymin = yhat_lower, ymax = yhat_upper), alpha = 0.3,
              fill = ""blue"") +
  facet_wrap( ~ state, scales = ""free_y"") +
  labs(x = """", y = """", 
       title = ""Forecasted Midwest House Price Index"",
       subtitle = ""based on Freddie Mac data 1975-2018"") +
  theme_fivethirtyeight()

ggsave(""midwest_hpi.png"", plot = last_plot())
```


","2019"
"443",1546,"https://github.com/trevinflick/tidytuesday/tree/master/2019-03-12","trevinflick","tidytuesday","2019-03-12/board-games.Rmd","---
title: ""Board Games""
author: ""Trevin Flickinger""
date: ""3/13/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggthemes)
board_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")
```

# Do board games ratings change based on published date?

```{r}
board_games %>%
  group_by(year_published) %>%
  summarise(total = n(),
            total_ratings = sum(users_rated),
            average_ratings = sum(users_rated * average_rating) / sum(users_rated)) %>%
  filter(total > 20) %>%
  ggplot(aes(x = year_published, y = average_ratings)) +
  geom_point(aes(size = total)) +
  labs(x = ""Year Published"",
       y = ""Average Rating"",
       title = ""Board Games are getting better over time"",
       subtitle = ""based on years with at least 20 games"",
       size = ""Total games"",
       caption = ""Data source: Board Game Geek, by: @trevin_flick"") +
  theme_light()
```

```{r}
ggsave(""board-games.png"")
```


```{r}
board_games %>% 
  ggplot(aes(x = users_rated, y = average_rating)) +
  geom_point() +
  labs(x = ""Number of user ratings"",
         y = ""Average rating"",
         title = ""Good games have more ratings"")
```


```{r}
board_games %>%
  filter(playing_time < 1440) %>%
  ggplot(aes(x = playing_time, y = average_rating)) +
  geom_point() +
  labs(x = ""Playing time"",
         y = ""Average rating"",
         title = """")
```


# Let's look at how mechanics of a game effect the rating

```{r}
board_games_tidy <- board_games %>%
  separate(mechanic, sep = "","", into = paste(""mechanic"", 1:17, sep = ""_""))
```

```{r}
mechanics <- board_games_tidy %>%
  gather(game, name, mechanic_1:mechanic_17, na.rm = TRUE)
```

```{r}
mechanics %>%
  group_by(name) %>%
  summarise(total = n(),
            total_ratings = sum(users_rated),
            average_ratings = sum(users_rated * average_rating) / sum(users_rated)) %>%
  arrange(desc(total_ratings)) %>%
  View()
```



","2019"
"444",1547,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-23","trevinflick","tidytuesday","2018-10-23/movies.Rmd","---
title: ""#TidyTuesday: Horror Movies and Profit""
author: ""Trevin Flickinger""
date: ""10/23/2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(scales)
library(zoo)
library(ggthemes)
```

## Data Prep

```{r}
# read in the data
movies <- read_csv(""movie_profit.csv"")

# drop column of numbers from 1-3401
movies <- movies %>%
  select(-one_of(""X1""))

# convert column to date type
movies$release_date <- mdy(movies$release_date)

# create new columns for year, month, day
movies <- movies %>%
  separate(release_date, c(""year"", ""month"", ""day""), ""-"", remove = FALSE)

# filter out years with less than 100 movies and movies that made money in the US
filter_movies <- movies %>%
  filter(year >= 1998 & year <= 2016)

```

## Exploratory Data Analysis

# When do movies usually get released?

```{r}
by_year <- movies %>%
  group_by(year) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

movies %>%
  ggplot(aes(year)) +
  geom_bar() +
  theme(text = element_text(size = 10),
        axis.text.x = element_text(angle = 90, hjust = 1))

movies %>%
  ggplot(aes(month)) +
  geom_bar() +
  theme(text = element_text(size = 10),
        axis.text.x = element_text(angle = 90, hjust = 1))

```

## How much do movies make by genre?
```{r}
filter_movies %>%
  ggplot(aes(genre, worldwide_gross)) +
  geom_boxplot() +
  coord_flip() +
  scale_y_continuous(labels = dollar_format())
```


## How much do movies make by month?

```{r}
filter_movies %>%
  ggplot(aes(month, worldwide_gross)) +
  geom_boxplot() +
  coord_flip() +
  scale_y_continuous(labels = dollar_format())
```

## Movies by genre and month

# by total gross
```{r}
filter_movies %>%
  group_by(month, genre) %>%
  summarize(total_gross = sum(worldwide_gross)) %>%
  ggplot(aes(month, total_gross, fill = genre)) +
  geom_col(position = position_dodge()) +
  scale_fill_manual(""legend"", values = c(""Action"" = ""#F0E442"",
                                         ""Adventure"" = ""#009E73"",
                                         ""Comedy"" = ""#56B4E9"",
                                         ""Drama"" = ""#E69F00"",
                                         ""Horror"" = ""#000000"")) +
  scale_y_continuous(labels = dollar_format())
```

```{r}
by_distributor <- filter_movies %>%
  group_by(distributor) %>%
  summarize(count = n(),
            total = sum(worldwide_gross),
            avg = median(worldwide_gross)) %>%
  arrange(desc(total)) %>%
  head(10)
```

```{r}
movies_top_dis <- inner_join(filter_movies, by_distributor, by = ""distributor"")
```

```{r}
top_by_dis <- movies_top_dis %>%
  group_by(distributor) %>%
  top_n(1, worldwide_gross)
```


```{r}
movies_top_dis %>%
  mutate(distributor = fct_reorder(distributor, worldwide_gross)) %>%
  ggplot(aes(distributor, worldwide_gross, fill = distributor, position = 'dodge')) +
  geom_boxplot() +
  coord_flip() +
  scale_y_continuous(labels = dollar_format()) +
  expand_limits(y = c(0, 1600000000)) +
  geom_text(data = top_by_dis, aes(distributor, worldwide_gross, label = movie), 
            check_overlap = TRUE,
            position = position_dodge(width = 0.75),
            inherit.aes = TRUE,
            size = 2.5, 
            hjust = -0.25) +
  labs(x = """", y = """",
       title = ""Top 10 Film Distributors by Total Worldwide Gross Revenue"",
       subtitle = ""(from 1998-2016)"",
       caption = ""TidyTuesday 10/23/18, source:fivethirtyeight"") +
  theme_fivethirtyeight() +
  guides(fill=FALSE) +
  theme(text = element_text(size = 8),
        axis.text.x = element_text(angle = 30, hjust = 1))

ggsave(""movies.png"")
```


```{r}
knitr::knit_exit()
```

This is scrap work.



## Production cost vs Worldwide gross

```{r}
filter_movies %>%
  ggplot(aes(worldwide_gross, production_budget)) +
  geom_point() +
  scale_y_log10()
```

# by avg gross
```{r}
filter_movies %>%
  group_by(month, genre) %>%
  summarize(avg_gross = median(worldwide_gross)) %>%
  ggplot(aes(month, avg_gross, fill = genre)) +
  geom_col(position = position_dodge()) +
  scale_fill_manual(""legend"", values = c(""Action"" = ""#F0E442"",
                                         ""Adventure"" = ""#009E73"",
                                         ""Comedy"" = ""#56B4E9"",
                                         ""Drama"" = ""#E69F00"",
                                         ""Horror"" = ""#000000"")) +
  scale_y_continuous(labels = dollar_format())
```








","2018"
"445",1548,"https://github.com/trevinflick/tidytuesday/tree/master/2019-02-12","trevinflick","tidytuesday","2019-02-12/r_d_spending.Rmd","---
title: 'TidyTuesday: Week 7'
author: ""Trevin Flickinger""
date: ""2/13/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(scales)

fed_rd <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")

energy_spend <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/energy_spending.csv"")

climate_spend <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/climate_spending.csv"")
```

```{r}
fed_rd_year <- fed_rd %>%
  group_by(year) %>%
  summarise(rd_total = sum(rd_budget),
            total = mean(total_outlays),
            pct_of_tot = rd_total / total)

dod <- fed_rd %>%
  filter(department == ""DOD"") %>%
  mutate(pct_of_tot = rd_budget / total_outlays)

non_def <- fed_rd %>%
  filter(department != ""DOD"") %>%
  group_by(year) %>%
  summarise(rd_total = sum(rd_budget),
            total = mean(total_outlays),
            pct_of_tot = rd_total / total)

ggplot() +
  geom_line(data = fed_rd_year, aes(year, pct_of_tot, color = ""black"")) +
  geom_line(data = dod, aes(year, pct_of_tot, color = ""red"")) +
  geom_line(data = non_def, aes(year, pct_of_tot, color = ""blue"")) +
  scale_y_continuous(labels = percent_format()) + 
  scale_color_manual(name = """",
                     values = c(""black""=""black"",""red""=""red"",""blue""=""blue""),
                     labels = c(""Total"",""Nondefense"",""Defense"")) +
  labs(title = ""R&D budget as a percent of Total Federal Budget"",
       subtitle = ""Data from 1976-2017"",
       caption = ""@trevin_flick, source:AAAS"") +
  theme_fivethirtyeight()
  
ggsave(""rd_as_pct.png"")
```

","2019"
"446",1549,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-01/tidytuesday.R","trevinflick","tidytuesday","2019-01-01/tidytuesday.R","library(tidyverse)
library(lubridate)
library(scales)
library(ggthemes)

tidytuesday <- read_rds(""tidytuesday_tweets.rds"")

# What users get the most retweets and favorites?

tidytuesday %>%
  group_by(screen_name, followers_count) %>%
  summarise(retweet_total = sum(retweet_count),
            favorite_total = sum(favorite_count)) %>%
  arrange(desc(favorite_total)) %>% 
  View()
  

# How has the popularity of #TidyTuesday changed since it's inception?

tidytuesday$created_at <- ymd_hms(tidytuesday$created_at)
tidytuesday$week <- week(tidytuesday$created_at)

# When did David Robinson start his screencast?
tidytuesday %>%
  filter(screen_name == ""drob"") %>%
  View()

tidytuesday %>%
  filter(week == 30) %>%
  View()

tidy_by_week <- tidytuesday %>%
  group_by(week) %>%
  summarise(retweet_total = sum(retweet_count),
            favorite_total = sum(favorite_count)) %>%
  arrange(week)

tidy_by_week %>%
  mutate(week = week - 13) %>%
  ggplot(aes(x=week, y=favorite_total)) +
  annotate(""text"", x=29, y=1240, 
           label=""David Robinson's first screencast"") +
  annotate(""text"", x=17, y=40,
           label=""#rstats p-hackathon challenge"") +
  geom_line(size=1.5) +
  scale_x_continuous(breaks = c(1,10,20,30,38)) +
  labs(y="""", x="""",
       title = ""#TidyTuesday popularity over time"",
       subtitle = ""Total Twitter favorites each week"",
       caption = ""TidyTuesday 01/01/2019, source:rtweet"") +
  theme_fivethirtyeight()


","2019"
"447",1550,"https://github.com/trevinflick/tidytuesday/tree/master/2018-12-04","trevinflick","tidytuesday","2018-12-04/medium.Rmd","---
title: ""Medium Articles""
author: ""Trevin Flickinger""
date: ""12/4/2018""
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
```

Dataset from Kaggle:
[Original data](https://www.kaggle.com/harrisonjansma/medium-stories)


```{r}
medium <- read_csv(""Medium_Clean.csv"")
```

```{r}
medium %>%
  sample_n(10) %>%
  View()
```


```{r}
medium %>%
  sample_n(10000, replace = FALSE) %>%
  ggplot(aes(Reading_Time, Claps)) +
  geom_point() +
  labs(x = ""Reading Time in Minutes"",
       y = ""Claps"",
       title = ""There is a sweet spot around 5-10 minutes for number of claps"",
       subtitle = ""(Random sample of 10,000 articles)"") 
```

Number of tags for each topic

```{r}
n_tags <- medium %>%
  select(Tag_writing:Tag_ai) %>%
  summarise_all(sum) %>%
  gather()
```

```{r}
medium %>%
  filter(Tag_food == 1) %>%
  summarise(avg_reading_time = mean(Reading_Time),
            avg_claps = mean(Claps))
```

```{r}
medium$Reading_Time <- as.numeric(medium$Reading_Time) 
```


Gather avg. reading time and number of claps for each tag

(there's probably an easier way to do this)

```{r}
medium_tags <- medium %>%
  select(Reading_Time, Claps, Tag_ai:Tag_writing) %>%
  group_by_if(is.integer) %>%
  summarise(claps = mean(Claps),
            reading = mean(Reading_Time))

medium_tags$n_tags <- rowSums( medium_tags[,1:95] )

medium_tags <- medium_tags %>%
  filter(n_tags == 1) %>%
  select(-n_tags)

medium_tags[medium_tags == 0] <- NA

medium_tags <- medium_tags %>%
  select(Tag_writing:Tag_ai, claps, reading) %>%
  gather(na.rm = TRUE)

tag_data <- cbind(medium_tags[1:95,], medium_tags[96:190,])
tag_data <- cbind(tag_data, medium_tags[191:285,])

colnames(tag_data) <- c(""tag"", ""x"", ""y"", ""claps"", ""z"", ""reading"")

tag_data <- tag_data %>%
  select(tag, claps, reading)

tag_data <- cbind(tag_data, n_tags[1:95,2])

tag_data$claps <- round(tag_data$claps)
tag_data$reading <- round(tag_data$reading, digits = 2)

tag_data$tag <- gsub(""Tag_"", """", tag_data$tag)

names(tag_data)[4] <- ""Articles""
```


Plotting the data

```{r warning=FALSE, message=FALSE}
library(plotly)

p <- plot_ly(
  tag_data, x = ~reading, y = ~claps,
  text = ~paste(""Tag: "", tag,
                ""<br>Articles: "", Articles),
  size = ~Articles, color = ~Articles
) %>%
  layout(title = 'Engagement for Medium Articles',
         yaxis = list(title = 'Average number of claps'),
         xaxis = list(title = 'Average reading time'))
```

```{r}
api_create(p, filename = ""tidytuesday-medium"")
```

Link to an interactive plotly graph

[Plotly Graph](https://plot.ly/~trevin_flick/1/)








","2018"
"448",1551,"https://github.com/trevinflick/tidytuesday/tree/master/2018-12-11","trevinflick","tidytuesday","2018-12-11/nyc_restaurants.Rmd","---
title: 'TidyTuesday: NYC Restaurants'
author: ""Trevin Flickinger""
date: ""12/11/2018""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(janitor)
library(stringr)
library(lubridate)
library(ggthemes)
```

```{r}
restaurants <- read_csv(""NYC_Restaurant_Inspections.csv"")
```

Filter out restaurants that haven't been inspected yet.
```{r}
nyc_restaurants <- restaurants %>%
  janitor::clean_names() %>%
  select(-phone, -grade_date, -record_date, -building, -street) %>%
  filter(!is.na(action))

nyc_restaurants$inspection_date <- mdy(nyc_restaurants$inspection_date)
```

```{r}
nyc_restaurants %>%
  count(year(inspection_date))
```


```{r}
by_date <- nyc_restaurants %>%
  count(camis, inspection_date) %>%
  group_by(camis)

by_date <- by_date[order(by_date$inspection_date, by_date$n),]
```


```{r}
n_visits <- by_date %>% count(camis, sort = TRUE)

grades <- nyc_restaurants %>%
  select(camis, inspection_date, grade, cuisine_description) %>%
  filter(!is.na(grade))


```

```{r}
by_date_grade <- left_join(by_date, grades, by = c(""camis"" = ""camis"", ""inspection_date"" = ""inspection_date""))

by_date_grade <- filter(by_date_grade, !is.na(grade))

by_date_grade <- unique(by_date_grade)
```


```{r}
grade_2017 <- by_date_grade %>% 
  group_by(camis) %>% 
  filter(year(inspection_date) == 2017) %>%
  slice(which.max(inspection_date)) %>%
  data.frame()
```

```{r}
grade_2017 %>% count(cuisine_description, sort = TRUE) %>% View()
```

```{r}
grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = fct_lump(cuisine_description, n = 19))

grade_2017 <- grade_2017 %>%
  mutate(grade = fct_lump(grade, n = 3))
```

```{r}
grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = str_replace(cuisine_description, ""Caf/Coffee/Tea"", ""Coffee""))

grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = str_replace(cuisine_description, ""Latin \\(Cuban, Dominican, Puerto Rican, South & Central American\\)"", 
                                           ""Latin""))

grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = str_replace(cuisine_description, ""Juice, Smoothies, Fruit Salads"", ""Smoothies""))
```

```{r}
grade_2017 <- transform(grade_2017, cuisine_description = factor(cuisine_description,
                                                                 levels = c(""American"",
                                                                 ""Other"",
                                                                 ""Chinese"",
                                                                 ""Coffee"",
                                                                 ""Pizza"",
                                                                 ""Italian"",
                                                                 ""Mexican"",
                                                                 ""Latin"",
                                                                 ""Japanese"",
                                                                 ""Bakery"",
                                                                 ""Caribbean"",
                                                                 ""Donuts"",
                                                                 ""Spanish"",
                                                                 ""Pizza/Italian"",
                                                                 ""Chicken"",
                                                                 ""Hamburgers"",
                                                                 ""Sandwiches"",
                                                                 ""Smoothies"",
                                                                 ""Asian"",
                                                                 ""Jewish/Kosher"")))
```



```{r}
grade_2017 %>%
  ggplot(aes(cuisine_description, fill=grade)) + geom_bar() + coord_flip() + scale_y_log10() +
  labs(x="""", y="""", title=""2017 NYC Restaurant Health Grades by Cuisine"",
       subtitle=""x-axis count of restaurants on log-scale"",
       caption = ""TidyTuesday 12/11/18, source:fivethirtyeight"") +
  theme_fivethirtyeight()

ggsave(""nyc_grades.png"")
```



```{r}
by_date_grade %>% 
  filter(year(inspection_date) == 2017 & grade == ""B"") %>%
  ggplot(aes(inspection_date, n, group = camis)) + geom_step()
```


```{r}
by_date_grade %>%
  filter(grade == ""A"" | grade == ""B"" | grade == ""C"") %>%
  ggplot(aes(n, stat(count), fill=grade)) + geom_density(alpha = 0.6)
```






","2018"
"449",1552,"https://github.com/trevinflick/tidytuesday/tree/master/2018-09-25","trevinflick","tidytuesday","2018-09-25/clean.R","library(dplyr)
library(readr)
library(purrr)
library(tidyr)

table1 <- read_csv(""table1.csv"")
table2 <- read_csv(""table2.csv"")
table3 <- read_csv(""table3.csv"")
table4 <- read_csv(""table4.csv"")
table6 <- read_csv(""table6.csv"")

# clean table1

table_1 <- table1 %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, everything())

write_csv(table_1, ""table_1.csv"")

# clean table2

table2 <- table2[-1, ]
  
table_2 <- table2 %>%
  separate(X1, into = c(""Rank"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(X4, into = c(""Rank_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  separate(X7, into = c(""Rank_2"", ""Country_2""), sep = "" "", extra = ""merge"") %>%
  select_if(~sum(!is.na(.)) > 0) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, Country, TICt = ""TICt  (millions"")

write_csv(table_2, ""table_2.csv"")


# clean table3

table3 <- table3[-1, ]

table_3 <- table3 %>%
  separate(X1, into = c(""Rank"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(X6, into = c(""Rank_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  separate(X11, into = c(""Rank_2"", ""Country_2""), sep = "" "", extra = ""merge"") %>%
  select_if(~sum(!is.na(.)) > 0) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, Country, TICt = ""TICt  (millions"", meanGDP = ""X4"", propGDP = ""proportion of"")

write_csv(table_3, ""table_3.csv"")

# clean table4

table_4 <- table4 %>%
  separate(""Rank Country"", into = c(""Rank"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(""Rank Country_1"", into = c(""Rank_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  separate(""Rank Country_2"", into = c(""Rank_2"", ""Country_2""), sep = "" "", extra = ""merge"") %>%
  select_if(~sum(!is.na(.)) > 0) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, Country, TICs = ""TICs  (millions US$)"")

write_csv(table_4, ""table_4.csv"")

# clean table6

table6 <- table6[-1, ]

table_6 <- table6 %>%
  separate(""maximum reported Species"", into = c(""max_impact_pct"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(""maximum reported Species_1"", into = c(""max_impact_pct_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(species = Species, max_impact_pct)

write_csv(table_6, ""table_6.csv"")














","2018"
"450",1553,"https://github.com/trevinflick/tidytuesday/tree/master/2018-09-25","trevinflick","tidytuesday","2018-09-25/plot.R","library(ggplot2)
library(dplyr)
library(ggthemes)

table_3$TICt <- gsub(""\\$"", """", table_3$TICt)
table_3$TICt <- as.numeric(gsub("","", """", table_3$TICt))

table_3$meanGDP <- gsub(""\\$"", """", table_3$meanGDP)
table_3$meanGDP <- as.numeric(gsub("","", """", table_3$meanGDP))

table_3 %>%
  ggplot(aes(log(meanGDP), log(TICt), label = Country)) +
  geom_point(alpha = 0.5,
             color = ifelse(table_3$propGDP > 0.25, ""red"", ""black"")) +
  geom_text_repel(data = filter(table_3, log(TICt) > 11 | log(TICt) < 2 | propGDP > 0.25),
                  segment.color = ""grey50"",
                  segment.size = 0.5) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) + 
  ylab('Total Invasion Cost [log scale]') + 
  xlab('GDP [log scale]') +
  labs(caption = ""TidyTuesday 9/25/18, source:Paini et al, 2016"")


","2018"
"451",1554,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-08/imdb-dramas.R","trevinflick","tidytuesday","2019-01-08/imdb-dramas.R","library(tidyverse)
library(lubridate)
library(ggthemes)

imdb <- read_csv(""IMDb_Economist_tv_ratings.csv"")

# Shows with the most seasons
top_30 <- imdb %>%
  group_by(title) %>%
  summarise(n = n(),
            avg_rating = mean(av_rating)) %>%
  arrange(desc(n)) %>% 
  head(30)

# How are shows rated?
summary(imdb$av_rating)

# Shows with only one season
one_and_done <- imdb %>%
  group_by(title) %>%
  filter(n() == 1, seasonNumber == 1)

# Shows with multiple seasons
multiple_seasons <- imdb %>%
  group_by(title) %>%
  filter(n() > 1)

binded_data <- rbind(one_and_done, multiple_seasons)

# Plot how many seasons each show has
binded_data %>%
  count(title) %>%
  ggplot(aes(n)) +
  geom_bar() +
  theme_fivethirtyeight() +
  labs(x = ""Number of seasons"", y="""",
       title = ""Most dramas only have one season"")
  

binded_data$seasons <- c(rep(""one"",nrow(one_and_done)),
                         rep(""multiple"",nrow(multiple_seasons)))

# Plot shows with one season compared to multiple seasons
binded_data %>%
  ggplot(aes(av_rating, fill = seasons)) +
  geom_density(alpha = 0.4) +
  labs(x = ""Average rating"", y = """",
       subtitle = ""Comparing dramas with only one season to dramas with multiple"",
       caption = ""TidyTuesday 01/08/2019, source:IMDB"") +
  theme_fivethirtyeight()

rating_by_show <- binded_data %>%
  group_by(title) %>%
  summarise(seasons = n(),
            avg_rating = mean(av_rating),
            avg_share = mean(share))

rating_by_show %>%
  ggplot(aes(seasons, avg_rating)) +
  geom_boxplot(aes(group = cut_width(seasons, 1))) +
  labs(y = ""Average Rating"", x = ""Number of seasons"",
       title = ""Dramas with fewer seasons show more variability in avg. rating"") +
  theme_economist()
  
  

","2019"
"452",1555,"https://github.com/trevinflick/tidytuesday/tree/master/2018-11-27","trevinflick","tidytuesday","2018-11-27/maryland_bridges.R","library(readr)
library(dplyr)
library(forcats)
library(stringr)
library(ggplot2)
library(ggthemes)

#### CLEANING THE DATA ####
bridges <- read_csv(""baltimore_bridges.csv"")

bridges %>% count(responsibility, sort = TRUE)
bridges <- bridges %>%
  mutate(responsibility = fct_lump(responsibility, n = 4))

bridges$vehicles <- as.numeric(str_replace_all(bridges$vehicles, "" vehicles"", """"))


#### EXPLORING DATA WITH PLOTS ####

# avg_daily_traffic and vehicles are same column

bridges %>% ggplot(aes(avg_daily_traffic)) + geom_histogram()

bridges %>% ggplot(aes(vehicles)) + geom_histogram()

bridges %>% ggplot(aes(yr_built)) + geom_histogram()

bridges %>% filter(yr_built < 1900) %>% View()

# two extreme outliers for improvement costs $300,000,000
bridges %>% filter(total_improve_cost_thousands < 38000) %>%
  ggplot(aes(avg_daily_traffic, total_improve_cost_thousands)) + geom_point()

bridges %>%
  ggplot(aes(yr_built, avg_daily_traffic, color = bridge_condition)) + 
  geom_point(aes(fill=bridge_condition)) +
  scale_y_log10()

bridges %>%
  ggplot(aes(yr_built, stat(count), fill=bridge_condition)) + 
  geom_density(alpha = 0.6, position = ""stack"") +
  scale_fill_manual(values = c(""#ffffbf"", ""#91bfdb"", ""#fc8d59""), 
                    breaks=c(""Poor"",""Fair"",""Good""),
                    name=""Bridge Condition"") +
  labs(x="""", y="""",
       title = ""The State of Maryland Bridges"",
       subtitle = ""Year built factors into condition"",
       caption = ""TidyTuesday 11/27/18, source:Federal Highway Administration"") +
  theme_fivethirtyeight()


","2018"
"453",1556,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-02","trevinflick","tidytuesday","2018-10-02/easter.R","library(tidyverse)
library(readr)
library(ggplot2)
library(ggthemes)


us_births <- readr::read_csv(""us_births_2000-2014.csv"")
easter_dates <- readr::read_csv(""easter_dates.csv"")

easter_dates <- easter_dates %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 5)]) %>%
  map_df(simplify) %>%
  select(month_day = ""Easter Date"", year = ""Years"") %>%
  arrange(year)

easter_dates <- easter_dates %>%
  separate(month_day, c(""month"", ""date_of_month""), sep = "" "")

months <- c(""January"", ""February"", ""March"", ""April"", ""May"", ""June"",
            ""July"", ""August"", ""September"", ""October"", ""November"", ""December"")

easter_dates$month <- match(easter_dates$month, months)

easter_dates <- easter_dates %>%
  mutate(year = as.numeric(year),
         month = as.numeric(month),
         date_of_month = as.numeric(date_of_month)) %>%
  unite(day, c(""year"", ""month"", ""date_of_month""), sep = ""-"")


week_before <- apply(easter_dates, 1, function(x) {seq.Date(as.Date(x['day']), by = ""-1 day"", length.out = 14)})

week_after <- apply(easter_dates, 1, function(x) {seq.Date(as.Date(x['day']) + 1, by = ""+1 day"", length.out = 14)})

easter <- data.frame(week_before, week_after) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 30)]) %>%
  map_df(simplify) %>%
  select(day = ""X1"")

easter$day <- as.Date(easter$day, origin = ""1970-01-01"")

easter <- easter %>%
  separate(day, c(""year"", ""month"", ""date_of_month""), sep = ""-"") %>%
  mutate(year = as.numeric(year),
         month = as.numeric(month),
         date_of_month = as.numeric(date_of_month)) %>%
  arrange(year, month, date_of_month)

easter <- left_join(easter, us_births, by = c(""year"", ""month"", ""date_of_month""))

easter$day <- rep(c(1:28), 15)

easter_births <- easter %>%
  group_by(day) %>%
  summarise(
    avg_births = mean(births)
  ) 

# avg birth non easter sundays
easter_births %>%
  filter(day == 7 | day == 21 | day == 28) %>%
  summarise(
    avg_births = mean(avg_births)
  )

day_effect <- us_births %>%
  group_by(day_of_week) %>%
  summarise(
    avg_by_day = mean(births)
  ) %>%
  slice(rep(1:n(), times = 4))

easter_births <- easter_births %>%
  mutate(mult_adj_births = avg_births / day_effect$avg_by_day,
         add_adj_births = avg_births - day_effect$avg_by_day)

# unadjusted plot

easter_births %>%
  ggplot(aes(day, avg_births)) +
  geom_point() +
  geom_point(data = filter(easter_births, day == 14), color = ""yellow"") +
  geom_text(data = filter(easter_births, day == 14), label = ""Easter"", 
            nudge_x = 2, nudge_y = -100) +
  geom_line() +
  geom_hline(yintercept = 7285, color = ""red"") +
  geom_text(data = filter(easter_births, day == 7), label = ""non-Easter Sunday avg."", vjust = 1.5, 
            color = ""red"", size = 3) +
  labs(x = """", y = ""births"", title = ""Fewer babies are born on Easter"",
       subtitle = ""U.S. births: two weeks before and after Easter \n(average births 2000-2014)"") +
  labs(caption = ""TidyTuesday 10/02/18, source:Fivethirtyeight"") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text())

# adjusted for day of week

easter_births %>%
  ggplot(aes(day, add_adj_births)) +
  geom_point() +
  geom_point(data = filter(easter_births, day == 14), color = ""yellow"") +
  geom_text(data = filter(easter_births, day == 14), label = ""Easter"",
            nudge_y = -.01)  +
  geom_line() +
  labs(x = """", y = ""births"", title = ""Fewer babies are born on Easter"",
       subtitle = ""U.S. births: two weeks before and after Easter \n(average births 2000-2014)"") +
  labs(caption = ""TidyTuesday 10/02/18, source:Fivethirtyeight"") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text())










","2018"
"454",1557,"https://github.com/trevinflick/tidytuesday/tree/master/2019-02-26","trevinflick","tidytuesday","2019-02-26/trains.Rmd","---
title: ""Tidy Tuesday Week 9""
author: ""Trevin Flickinger""
date: ""2/26/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(ggthemes)
library(scales)

trains <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")
```

```{r}
trains$date <- paste(trains$year, trains$month, 01, sep=""-"") %>% ymd() %>% as.Date()
```


```{r}
trains %>% group_by(date) %>%
  summarise(total_trips = sum(total_num_trips)) %>%
  ggplot(aes(date, total_trips)) +
  geom_line() +
  labs(x = """", y = """", 
       title = ""Total number of train trips in France"") + 
  theme_fivethirtyeight()
```


```{r}
trains %>% group_by(date) %>%
  summarise(total_cancel = sum(num_of_canceled_trains)) %>%
  ggplot(aes(date, total_cancel)) +
  geom_line(size = 1.25) +
  labs(x = """", y = """", 
       title = ""Total number of canceled trains in France"",
       subtitle = ""2015-2018"",
       caption = ""TidyTuesday week 9, source: SNCF"") + 
  theme_fivethirtyeight()
  
# ggsave(""france_trains.png"")
```

```{r}
trains %>% group_by(date) %>%
  summarise(pct_cancel = sum(num_of_canceled_trains) / (sum(num_of_canceled_trains) + sum(total_num_trips))) %>%
  ggplot(aes(date, pct_cancel)) +
  geom_line(size = 1.25) +
  labs(x = """", y = """", 
       title = ""Percentage of trains canceled in France"",
       subtitle = ""2015-2018"",
       caption = ""TidyTuesday week 9, source: SNCF"") + 
  scale_y_continuous(labels = scales::percent) +
  theme_fivethirtyeight()
```

```{r}
ggsave(""canceled_pct.png"")
```


```{r}
trains %>% group_by(date) %>%
  summarise(avg_delay_depart = sum(avg_delay_all_departing),
            avg_delay_arrive = sum(avg_delay_all_arriving)) %>%
  ggplot() +
  geom_line(aes(date, avg_delay_depart), color = ""black"") +
  geom_line(aes(date, avg_delay_arrive), color = ""blue"")
  labs(x = """", y = """", 
       title = ""Avg delay trains in France"") + 
  theme_fivethirtyeight()
```





","2019"
"455",1560,"https://github.com/hmetcalfe1/tidytuesday","hmetcalfe1","tidytuesday","tidytues2019/tt_jan19/tt_08012019/tt08012019.R","#tidytuesday 08012019
library(tidyverse)

importfile<-""tidytues2019/tt_jan19/tt_08012019/IMDb_Economist_tv_ratings.csv""
exportfile<-""tidytues2019/tt_jan19/tt_08012019/08012019.pdf""
  
tvdata <- read_csv(importfile)
tvdata

ggplot(data = tvdata) +
  geom_point(mapping = aes(x=date,y=av_rating))
    
ggsave(exportfile)
","2019"
"456",1561,"https://github.com/hmetcalfe1/tidytuesday","hmetcalfe1","tidytuesday","tidytues2019/tt_jan19/tt_29012019/tt29012019.R","#tidytuesday 29012019
rm(list=ls())
library(tidyverse)

importfile<-""tidytues2019/tt_jan19/tt_29012019/clean_cheese.csv""
exportfile<-""tidytues2019/tt_jan19/tt_29012019/29012019.png""

chdata <- read_csv(importfile)

chdata<-mutate(chdata,
       OtherCheese=rowSums(chdata[6:11],na.rm = TRUE)
       )

ggplot(data = chdata,aes(x=Year)) +
  geom_line(mapping = aes(y=Cheddar), colour=""deepskyblue3"")+
  geom_line(mapping = aes(y=Mozzarella), colour=""deeppink3"")+
  geom_line(mapping = aes(y=`American Other`), colour=""yellow3"")+
  geom_line(mapping = aes(y=`Italian other`), colour=""forestgreen"")+
  geom_line(mapping = aes(y=OtherCheese), colour=""chocolate3"")+
  ylab(""Per capita consumption ofcheese / pounds"")+
  geom_text(aes(x = 2011, y = 11.5, label = ""Mozzarella""), color = ""deeppink3"") + 
  geom_text(aes(x = 2011, y = 9, label = ""Cheddar""), color = ""deepskyblue3"")+
  geom_text(aes(x = 2011, y = 4.5, label = ""Other American Type Cheeses""), color = ""yellow3"") + 
  geom_text(aes(x = 2011, y = 2, label = ""Other Italian Type Cheeses""), color = ""forestgreen"")+
  geom_text(aes(x = 2011, y = 6.5, label = ""Other Cheeses""), color = ""chocolate3"")+
  theme_bw()

ggsave(exportfile)
","2019"
"457",1562,"https://github.com/hmetcalfe1/tidytuesday","hmetcalfe1","tidytuesday","tidytues2019/tt_mar19/tt_12032019/tt12032019.R","#tidytuesday 12032019

# Load Packages -----------------------------------------------------------
library(tidyverse)
library(reshape2)
library(gridExtra)


# Read in data ------------------------------------------------------------

importfile<-""tidytues2019/tt_mar19/tt_12032019/board_games.csv""

bgdata <- read_csv(importfile)

bgcategories<-str_split(bgdata$category,"","")%>%
  unlist()%>%
  unique()

#Create new columns for each category  ------------------------------------------------------------------------
for (i in 1:length(bgcategories)){
  categoryis<-bgcategories[i]
  
  for (j in 1:nrow(bgdata)){
    cattrue<-grepl(categoryis, bgdata$category[j])
    if (isTRUE(cattrue)) {
      myval<-1
    } else {
      myval<-0
    }
    
    if(j==1){
      mycol<-myval
    }
    else{
      mycol<-rbind(mycol,myval)
    }
  }
  if(i==1){
    catcols<-as.data.frame(mycol)
  }
  else{
    catcols2<-as.data.frame(mycol)
    catcols<-cbind(catcols,catcols2)
  }
  
}
names(catcols)<-bgcategories
bgdata<-cbind(bgdata,catcols)


# create a new data frame with the game idsand a list of catergori --------

catsid <- cbind(catcols,bgdata$game_id)
long_cats <- melt(catsid, id=""bgdata$game_id"")
long_cats <- filter(long_cats,value==""1"")
names(long_cats)[1]<-""game_id""

valid_column_names <- make.names(names=names(bgdata), unique=TRUE, allow_ = TRUE)
names(bgdata) <- valid_column_names

bgratings<-select(bgdata,game_id,name,year_published,average_rating)

bg_catdata<-left_join(long_cats, bgratings, by = ""game_id"")

# Create graphics ---------------------------------------------------------

exportfile<-""tidytues2019/tt_mar19/tt_12032019/12032019.png""

a<-ggplot(data = bg_catdata%>%filter(variable==""Religious""|variable==""Political""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
b<-ggplot(data = bg_catdata%>%filter(variable==""Word Game""|variable==""Number""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
c<-ggplot(data = bg_catdata%>%filter(variable==""Pirates""|variable==""Science Fiction""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
d<-ggplot(data = bg_catdata%>%filter(variable==""Humor""|variable==""Horror""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
p<-grid.arrange(a,b,c,d)

ggsave(exportfile,p)
","2019"
"458",1585,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2018-11-27","tanyaberde","tidytuesday","data/2018-11-27/baltimoreBridges.R","# Tidy Tuesday 2018-11-27 Baltimore Bridges
# Constanza de Dios

# Read data
bridges <- read.csv(""baltimore_bridges.csv""
                 ,header=T)

dat <- bridges
library(tidyverse)

dat1 <- dat %>% 
  mutate(age = 2018 - yr_built, # Calculate age of each bridge as of year 2018
         time_insp = 18 - inspection_yr # Calculate time since last inspection
)



g <- ggplot(dat1) +
  aes(x = age
      , y = avg_daily_traffic/10^3
      # , alpha = bridge_condition
      , color = factor(time_insp)
      ) +
  geom_point(stat=""identity""
             , size = 1.5
             ) +
  # scale_alpha_discrete(breaks=c(""Good"",""Fair"",""Poor""), breaks=1:3) + # Reorder labels of bridge condition
  scale_color_brewer(type = ""qual"", palette=3) +
  labs(x = ""Age as of 2018"", y = ""Average Daily Traffic (thousands)""
       # , alpha = """"
       ,color = ""Years since last inspection""
       ) +
  facet_grid(vars(bridge_condition), vars(county)) +
  ggtitle(""Correlation between traffic and age of bridges across Maryland counties"") +
  theme_bw()


print(g)

ggsave(""MDbridges.png""
       ,plot = g
       ,width=12
       ,height=4)
","2018"
"459",1586,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-01-29","tanyaberde","tidytuesday","data/2019-01-29/dairy.R","require(tidyverse)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milk_products_facts.csv'
url2 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/fluid_milk_sales.csv'

milkProductsData <- read_csv(url1)
milkSalesData <- read_csv(url2)

# Get the data from the fluid_milk_sales dataset to get production
milkSales_df <- milkSalesData %>% 
  filter(milk_type==""Total Production"") %>% 
  mutate(millions_of_pounds = pounds/1000000)

# left_join this to milkProductsData
milkProdCons_df <- left_join(milkSales_df, milkProductsData,
                             by = c(""year""))

# Make the products into one column
milkProdRatio_df <- milkProdCons_df %>% 
  select(year:dry_whey) %>% 
  gather(product_type, ave_consump, fluid_milk:dry_whey) %>% 
  mutate(product_type = case_when(
                            str_detect(product_type, ""fluid_milk"") ~ ""Milk"",
                            str_detect(product_type, ""fluid_yogurt"") ~ ""Yogurt"",
                            # str_detect(product_type, ""butter"") ~ ""Butter"",
                            str_detect(product_type, ""cheese_american"") ~ ""American Cheese"",
                            str_detect(product_type, ""cheese_other"") ~ ""Other Cheese"",
                            str_detect(product_type, ""cheese_cottage"") ~ ""Cottage Cheese"",
                            str_detect(product_type, ""evap_cnd_canned_whole_milk"") ~ ""Evaporated/Canned Whole Milk"",
                            str_detect(product_type, ""evap_cnd_bulk_whole_milk"") ~ ""Evaporated/Canned Bulk Whole Milk"",
                            str_detect(product_type, ""evap_cnd_bulk_and_can_skim_milk"") ~ ""Evaporated/Canned Bulk and Can Skim Milk"",
                            str_detect(product_type, ""frozen_ice_cream_regular"") ~ ""Regular Ice Cream"",
                            str_detect(product_type, ""frozen_ice_cream_reduced_fat"") ~ ""Reduced-Fat Ice Cream"",
                            str_detect(product_type, ""frozen_sherbet"") ~ ""Sherbet"",
                            str_detect(product_type, ""frozen_other"") ~ ""Other Frozen Milk Product"",
                            str_detect(product_type, ""dry_whole_milk"") ~ ""Dry Whole Milk"",
                            str_detect(product_type, ""dry_nonfat_milk"") ~ ""Dry Nonfat Milk"",
                            str_detect(product_type, ""dry_buttermilk"") ~ ""Dry Buttermilk"",
                            str_detect(product_type, ""dry_whey"") ~ ""Dry Whey/Milk Protein"",
                            TRUE ~ NA_character_)) %>% 
  mutate(product_form = case_when(
    str_detect(product_type, ""Butter"") ~ ""Butter/Cheese"",
    str_detect(product_type, ""Cheese"") ~ ""Butter/Cheese"",
    str_detect(product_type, ""Yogurt"") ~ ""Fluid"",
    str_detect(product_type, ""Canned"") ~ ""Canned"",
    str_detect(product_type, ""Ice Cream"") ~ ""Frozen"",
    str_detect(product_type, ""Sherbet"") ~ ""Frozen"",
    str_detect(product_type, ""Frozen"") ~ ""Frozen"",
    str_detect(product_type, ""dry"") ~ ""Dry"",
    str_detect(product_type, ""Milk"") ~ ""Fluid"",
    TRUE  ~ NA_character_
  ))

milkRatio <- milkProdRatio_df %>%
  mutate(prop = ((ave_consump*10000)/millions_of_pounds)) 
  # select(-c(""milk_type"",""pounds""))

# Filter required rows for the labels
prodLabs <- milkRatio[milkRatio$year == 2016, ] # since 2016 gets plotted on the rightmost
prodLabs$label <- prodLabs$product_type


# Plot
g <- ggplot(milkRatio,
            aes(x = year, y = log10(prop)
                , color = product_type
                , linetype = product_form
                , label = product_type
                )) +
  geom_text_repel(data=prodLabs
            , aes(label=label)
            , size=4
            , direction = ""both""
  ) +
  geom_line(stat=""identity"", size = 1.1
            # ,show.legend = FALSE
  ) +
  labs(x = ""Year"", y = ""Ratio of ave. personal consumption to total milk production (.001 lb)""
       , linetype=""Form""
       , subtitle = ""*Ratio log-transformed""
       ) +
  guides(color=FALSE) +
  ggtitle(""Consumption-to-Production ratio of US Dairy Products"") +
  theme_minimal(base_size = 12)

print(g)

ggsave(""milkProducts.png""
       ,plot = g
       ,width=9
       ,height=7)
","2019"
"460",1587,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-01-15","tanyaberde","tidytuesday","data/2019-01-15/spaceLaunches.R","require(tidyverse)
require(ggplot2)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/agencies.csv'
dat1 <- read_csv(url1)
url2 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv'
dat2 <- read_csv(url2)

# Bin the years in decades (10)

## First make new variables
## Decade
dat2$decade = ifelse(1960 <= launch_year & launch_year <= 1969, 1960
                    ,ifelse(1970 <= launch_year & launch_year <= 1979, 1970
                            ,ifelse(1980 <= launch_year & launch_year <= 1989, 1980
                                    ,ifelse(1990 <= launch_year & launch_year <= 1999, 1990
                                            ,ifelse(2000 <= launch_year & launch_year <= 2009, 2000
                                                    ,2010)))))

## Get average number of successes every decade for each agency, just for state launch providers

### First count number of successes and failures for each agency & decade
categ <- dat2 %>% 
  filter(agency_type %in% c(""state"")) %>% 
  group_by(state_code, decade, category) %>%
  tally

### Then count total attempts
total <- dat2 %>% 
  filter(agency_type %in% c(""state"")) %>% 
  group_by(state_code, decade) %>% 
  tally

categ_total <- merge(categ,total,by=c(""state_code"",""decade"")) # Join the two tables 

categ_total <- categ_total %>%
  filter(category %in% c(""O"")) %>%  # Only include the successes
    mutate(success_rate = n.x/n.y)


# Plot
g <- ggplot(categ_total,
  aes(x = decade, y = success_rate, fill = state_code )) +
  geom_bar(stat=""identity"",size=1.5
            ) +
# scale_fill_brewer(type = ""qual"", palette=2) +
  facet_wrap(~state_code) +
  labs(x = ""Country"", y = ""Success Rate"") +
  ggtitle(""Success rate of state-sponsored launches relative to total attempts per decade"") +
  theme_minimal()

print(g)
","2019"
"461",1588,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-12","tanyaberde","tidytuesday","data/2019-02-12/fedSpending.R","require(tidyverse)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/climate_spending.csv'
url3 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv'

fed.dat <- read_csv(url3)
clim.dat <- read_csv(url1)

# Summarize using 5-year bins
fed.dat <- fed.dat %>% 
  mutate(bin = case_when (
    (year >= 1976 & year <= 1980) ~ ""1976-80"",
    (year >= 1981 & year <= 1985) ~ ""1981-85"",
    (year >= 1986 & year <= 1990) ~ ""1986-90"",
    (year >= 1991 & year <= 1995) ~ ""1991-95"",
    (year >= 1996 & year <= 2000) ~ ""1996-00"",
    (year >= 2001 & year <= 2005) ~ ""2001-05"",
    (year >= 2006 & year <= 2010) ~ ""2006-10"",
    (year >= 2011 & year <= 2015) ~ ""2011-15"",
    (year >= 2016 & year <= 2017) ~ ""2016-17"",
    TRUE ~ NA_character_)
    )

fed.ave.dat <- fed.dat %>% 
  group_by(department,bin) %>% 
  summarise(rd_budget=mean(rd_budget,na.rm=T),
            total_outlays=mean(total_outlays,na.rm=T),
            discretionary_outlays=mean(discretionary_outlays,na.rm=T),
            gdp=mean(gdp,na.rm=T)) %>% 
  na.omit()
  

g <- ggplot(fed.ave.dat,
            aes(x=gdp
                ,y=rd_budget
                ,colour=bin
                )) +
  geom_point() +
  facet_wrap(~department) +
  labs(x = ""GDP"", y = ""R&D Budget"",colour=""Years"",subtitle = ""* Note year correlates with GDP"") +
  ggtitle(""Research & Development budget as a function of GDP, allotted by department"") +
  theme_minimal()
g

#============================================================
total.outlays <- fed.dat %>% 
  select(year,total_outlays) %>% 
  distinct()

clim.total.dat  <- left_join(clim.dat,total.outlays,by=c(""year"")) %>% 
  mutate(prop.spending = (gcc_spending/total_outlays)*100)

h <- ggplot(clim.total.dat,
            aes(x=year
                ,y= prop.spending
                ,fill=department
                )) +
  geom_area(colour=""grey50"") +
  labs(x = ""Year"", y = ""Percent of total federal spending"",fill=""Department"") +
  ggtitle(""Proportion of R&D Climate Change spending to total federal government spending by department"") +
  theme_minimal()
h

#============================================================

ggsave(""deptBudgets.png"",g,width=9,height=7)

ggsave(""climateSpending.png"",h,width=9,height=7)
","2019"
"462",1589,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-01-22","tanyaberde","tidytuesday","data/2019-01-22/prisonHolds.R","
require(tidyverse)
require(ggplot2)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/incarceration_trends.csv'

incarc_dat <- read_csv(url1)

# Add a row ID for later joining if needed
d2 <- incarc_dat %>% 
  mutate(row_id = row_number())

# Have other_state coded above _state_ or else case_when will mislabel
holds <- d2 %>% 
  select(yfips:total_pop_15to64, urbanicity:land_area, jail_from_state_prison:jail_from_ice, row_id) %>% 
  gather(agency, pop_count, jail_from_state_prison:jail_from_ice) %>% 
  mutate(agency = case_when(str_detect(agency, ""other_state_prison"") ~ ""Out-of-State Prison"",
                                str_detect(agency, ""from_state_prison"") ~ ""State Prison"",
                                str_detect(agency, ""other_state_jail"") ~ ""Out-of-State Jail"",
                                str_detect(agency, ""from_state_jail"") ~ ""State Jail"",
                                str_detect(agency, ""_fed"") ~ ""All Federal Authorities"",
                                str_detect(agency, ""_ice"") ~ ""ICE or INS"",
                                TRUE ~ NA_character_))

holds2 <- holds %>% 
  mutate(ratio = (pop_count/total_pop_15to64)*100)


# Summary of number of individuals held for other agencies, depending on urbanicity and year

holds_summ <- holds2 %>% 
  na.omit() %>% 
  group_by(year, urbanicity, agency) %>% 
  summarize(average_prop = mean(ratio),
            average_total_pop = mean(total_pop_15to64),
            average_pop_count = mean(pop_count)) %>% 
  ungroup()


# Plot
g <- ggplot(holds_summ,
            aes(x = year, y = average_prop, color = agency )) +
  geom_line(stat=""identity"",size=1.1
  ) +
  scale_color_brewer(type = ""div"") +
  facet_wrap(~urbanicity) +
  labs(x = ""Year"", y = ""Proportion to facility population aged 15-64"", color=""Agency"") +
  ggtitle(""Prisoners being held for in-state or external authorities, per urbanicity category"") +
  theme_minimal(base_size = 12)


print(g)

ggsave(""holds.png""
       ,plot = g
       ,width=9
       ,height=7)
","2019"
"463",1590,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-19","tanyaberde","tidytuesday","data/2019-02-19/cleaningTimeData.R","rm(list=ls())

## Comment out one of the below lines as needed; adjust range of years in line 55 accordingly
# xfilename <- ""2017_031"" ## 2017
# xfilename <- ""2016_031"" ## 2016
# xfilename <- ""2015_031"" ## 2015
xfilename <- ""2014_031"" ## 2014
# xfilename <- ""2013_031"" ## 2013

#================================================================================
require(tidyverse)
df <- readxl::read_excel(paste(""data/"",xfilename,"".xlsx"",sep="""")
                         , skip=1) %>% ### skip=1 for 2014 and 2013 data
  rename(field_time = `Field of study and time to degree`) %>% # Rename the conjunctive column to something simpler
  filter(!is.na(field_time)) %>% 
  mutate( # Clean up weird names with superscripts
    field_time = case_when(field_time == ""Otherc"" ~ ""Other"",
                           field_time == ""Life sciencesb"" ~ ""Life sciences"",
                           field_time == ""Since starting doctoral programa"" ~ ""Since starting doctoral program"",
                            TRUE ~ field_time
                           ))

# Manually grabbed the broad fields (based on indentation)
major_fields <- c(""Life sciences"", 
                  ""Physical sciences and earth sciences"", 
                  ""Mathematics and computer sciences"",
                  ""Psychology and social sciences"", 
                  ""Engineering"",
                  ""Education"",
                  ""Humanities and arts"",
                  ""Other"",
                  ""All fields"")

# Manually grabbed time to degree
times_to_degree <- c(""Since bachelor's"",
                    ""Since starting graduate school"",
                    ""Since starting doctoral program"")


# Un-cross the first column which right now has time to degree AND field in one. Create new columns based on the matching of major and time to degree variables
df <- df %>% 
  mutate(time_to_degree = case_when(field_time %in% times_to_degree ~ field_time,
                                TRUE ~ NA_character_),
  major_field = case_when(field_time %in% major_fields ~ field_time,
                            TRUE ~ NA_character_))

# Use tidyr::fill() to fill in the repeats of each major/broad field
df_time <- df %>% 
  fill(major_field, .direction = ""down"") %>% 
  fill(time_to_degree, .direction = ""down"") %>%
  filter(!field_time %in% major_fields) ## Now take out the rows under field_time that have no values (since they're headers), 
                                        ## which happen to be the major_fields

# Gather the years, remove the commas, and rename to appropriate columns
df_clean <- df_time %>% 
  gather(year, md_years, `1990`:`2015`) %>% ## First gather the to-be-created vars on the left
  mutate(year = factor(parse_number(year)),
         md_years = parse_number(md_years)) %>% ## readr::parse_number() turns the character values into numeric values
  # rename(field = Field) %>% 
  select(major_field = major_field, time_to_degree, year, md_years)

# # Check to confirm numbers match
# df_clean %>% 
#   group_by(major_field, year) %>% 
#   summarize(sum(md_years, na.rm = TRUE))

# Write to .csv
df_clean  %>%
  write_csv(paste(xfilename,"".csv"",sep=""""))
","2019"
"464",1591,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-19","tanyaberde","tidytuesday","data/2019-02-19/phds.R","require(tidyverse)
require(ggrepel)

url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv'

phd_field_dat <- read_csv(url1)



## Get total Phds per year
total_phds <- phd_field_dat %>% 
  group_by(year) %>% 
  summarize(year_n_phds = sum(n_phds, na.rm=T))

## Left join this with the master dataset, and bin the years in case needed later
phd_field_dat2 <- left_join(phd_field_dat, total_phds, by=c(""year"")) %>% 
  mutate(percent = (n_phds/year_n_phds)*100,
         bin = case_when (
           (year >= 2008 & year <= 2010) ~ 2010,
           (year >= 2011 & year <= 2013) ~ 2013,
           (year >= 2014 & year <= 2016) ~ 2016,
           (year == 2017) ~ 2017,
           TRUE ~ NA_real_
           )
         )

# Quick summary by field and year/bin
broad_summ <- phd_field_dat2 %>% 
  group_by(year,broad_field) %>% 
  rename(fld = broad_field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))

major_summ <- phd_field_dat2 %>% 
  group_by(year,major_field,broad_field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))
            
socsci_summ <- phd_field_dat2 %>% 
  filter(broad_field==""Psychology and social sciences"") %>% 
  group_by(bin,major_field,field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))

psyc_summ <- phd_field_dat2 %>% 
  filter(major_field==""Psychology"") %>% 
  group_by(year,field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))

# Filter required rows for the labels in plot g
plotLabs <- major_summ[major_summ$year == 2008, ] # since 2008 gets plotted on the left
plotLabs$label <- plotLabs$major_field


# Plots

## Broad areas
g <- ggplot(major_summ
            ,aes(x=year
                 ,y=log(percent)
                 ,colour=major_field
                 )) +
  geom_line(size=0.8) +
  geom_point(size=0.8) +
  geom_label_repel(data=plotLabs,
                  aes(label=label,alpha=.9)
                  , size=3.5
                  , direction = ""both""
                  ) +
  facet_wrap(~broad_field) +
  scale_x_continuous(breaks=c(2008:2017)) +
  guides(colour=F,alpha=F) +
  ggtitle(""Proportion of PhDs in broad areas of study"") +
  labs(x=""Year"",y=""Share of total annual PhDs (%, log-transformed)"",
       caption = ""Data source: NSF National Center for Science and Engineering Statistics"") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=.5))

print(g)

## Psychology
i <- ggplot(psyc_summ
            ,aes(x=year
                 ,y=log(percent)
                 ,colour=field
            )) +
  geom_line(size=0.8) +
  geom_point(size=0.8) +
  # geom_label_repel(data=plotLabs3,
  #                  aes(label=label,alpha=.9)
  #                  , size=3.5
  #                  , direction = ""both""
  # ) +
  facet_wrap(~field) +
  scale_x_continuous(breaks=c(2008:2017)) +
  guides(colour=F) +
  ggtitle(""Proportion of PhDs in psychology"") +
  labs(x=""Year"",y=""Share of total annual PhDs (%, log-transformed)""
       , caption = ""Data source: NSF National Center for Science and Engineering Statistics"") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=.5))

print(i)

#============================================================

ggsave(""phdsBroadFields.png"",g,width=12,height=7)
ggsave(""phdsPsyc.png"",i,width=12,height=7)
","2019"
"465",1592,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-19","tanyaberde","tidytuesday","data/2019-02-19/timeAnalyses.R","rm(list=ls())

require(tidyverse)
dat1 <- ""cleaned_annual_data/2015_031.csv""
dat2 <- ""cleaned_annual_data/2016_031.csv""
dat3 <- ""cleaned_annual_data/2017_031.csv""

dat_15 <- read_csv(dat1)
dat_16 <- read_csv(dat2)
dat_17 <- read_csv(dat3)

dat_merge1 <- rbind(dat_15,dat_16)
dat_merge2 <- rbind(dat_merge1, dat_17)

master_dat <- dat_merge2 %>% 
  arrange(year,major_field,time_to_degree)
#=============================================
all_grad <- master_dat %>% 
  filter(time_to_degree %in% c(""Since starting graduate school"",""Since starting doctoral program"")) %>% 
  na.omit()
  
socsci_dat <- master_dat %>% 
  filter(major_field==""Psychology and social sciences"") %>% 
  arrange(year,time_to_degree)

socsci_grad <- socsci_dat %>% 
  filter(time_to_degree==""Since starting graduate school"") %>% 
  na.omit()

# Plots

g <- ggplot(data=socsci_grad,
            aes(x=year
                ,y=md_years
                # ,fill=time_to_degree
                )) +
  geom_bar(stat=""identity"")
print(g)

h <- ggplot(data=all_grad,
            aes(x=year
                ,y=md_years
                ,colour=time_to_degree
            )) +
  geom_line(stat=""identity"",size=0.8) +
  facet_wrap(~major_field) +
  scale_color_brewer(type=""qual"", palette=2) +
  labs(color=""Starting point"") +
  ggtitle(""Time to complete PhD across major fields"") +
  labs(x=""Year"",y=""Median number of years""
       , subtitle = ""Since beginning graduate school""
       , caption = ""Data source: NSF National Center for Science and Engineering Statistics from years 2015-2017"") +
  theme_minimal(base_size=12) +
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=.5))

print(h)

ggsave(""completionYears.png"",h,width=12,height=7)
","2019"
"466",1593,"https://github.com/dallinwebb/tidy_tuesday/blob/master/2019/06_house_morgage/code.R","dallinwebb","tidy_tuesday","2019/06_house_morgage/code.R","library(tidyverse)
library(USAboundaries)
library(sf)

hpi <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-02-05/state_hpi.csv"")

now <- hpi %>% 
  filter(year == 2001,
         month == 11) %>% 
  select(state,
         year_now = year,
         price_index_now = price_index)

joined <- hpi %>% 
  filter(year >= 2007) %>% 
  group_by(state) %>% 
  filter(price_index == min(price_index)) %>% 
  select(state,
         year_low = year,
         month_low = month,
         price_index_low = price_index) %>% 
  left_join(now, by = ""state"") %>%
  mutate(price_index_diff = price_index_now / price_index_low - 1,
         price_index_pct  = scales::percent(price_index_diff))

state_boundaries <- USAboundaries::us_states() %>% 
  left_join(joined, by = c(""stusps"" = ""state"")) %>% 
  filter(!(stusps %in% c(""AK"", ""DC"", ""HI"", ""PR"")))

ggplot(state_boundaries, aes(fill = price_index_diff)) +
  geom_sf(col = ""white"") +
  geom_sf_text(aes(label = price_index_pct),
               check_overlap = T) +
  coord_sf(crs = 5070) +
  scale_fill_gradient(low  = ""#87FA87"", 
                      high = ""#006400"") +
  labs(title = ""Western States had greater increases in HPI since lows"",
       subtitle = ""Should have invested in real estate in Nevada"",
       fill  = ""Pct. Increase"") +
  theme_void() +
  theme(panel.grid = element_line(color = ""white""))

","2019"
"467",1594,"https://github.com/vbfelix/tidytuesday","vbfelix","tidytuesday","2018/2018 - 001 - US Tuition/tt_001_tuition.R","
# Packages ----------------------------------------------------------------

library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)
library(ggmap)
library(fiftystater)
library(grid)

# Import ------------------------------------------------------------------

df_or<-read_xlsx(""us_avg_tuition.xlsx"")

df_or %>% 
  gather(Year,Value,-State)->df

minus<-function(x){
  c(NA,diff(x))
}
divide<-function(x,y){
  n<-length(x)
  c(NA,x[2:n]/y[1:(n-1)])
}

df %>% 
  group_by(State) %>%
  mutate(Dif = minus(Value)) %>% 
  mutate(Division = 100*divide(Dif,Value))->df

fifty_states %>% 
    left_join(df %>% 
                mutate(id = tolower(State))) %>% 
  filter(is.na(Year)==F) ->df_map


# Plot --------------------------------------------------------------------

df_map %>%
  ggplot(aes(fill = Division,x=long,y=lat))+
  facet_wrap(~Year, ncol= 4)+
  geom_polygon(aes(group = group),col=""black"")+
  viridis::scale_fill_viridis(breaks=seq(-9,24,by=3),
                              labels=seq(-9,24,by=3),
                              limits=c(-9,24))+
  theme_inset(base_size = 16)+
  theme(legend.position = ""bottom"",
        legend.key.width = unit(2.5,""cm""),
        plot.margin = unit(c(2,2,2,2), ""cm""))+
  labs(fill = ""Difference in tuition (%) relative to the previous year"")+
  coord_map()->p_all


df_map %>%
  filter(Year == ""2004-05"") %>% 
  ggplot(aes(fill = Value,x=long,y=lat))+
  facet_wrap(~Year, ncol= 1)+
  geom_polygon(aes(group = group),col=""black"")+
  viridis::scale_fill_viridis(breaks=seq(3500,13000,by=1500),
                              labels=seq(3500,13000,by=1500),
                              limits=c(3500,12500),option = ""A"",
                              direction = -1,alpha = .7)+
  theme_inset(base_size = 16)+
  theme(legend.position = ""top"",
        legend.key.width  = unit(2.5,""cm""))+
  labs(fill = ""Average\ntuition ($)"")+
  coord_map()->p_2004


# Union -------------------------------------------------------------------

grid1 <- viewport(width = 1, height = 1, x = 0.5, y = 0.5) 
grid2 <- viewport(width = 0.25, 
                 height = .327,
                 x = 0.178, y = .83) 

x11()
grid.newpage()
print(p_all , vp = grid1)
print(p_2004, vp = grid2)


","2018"
"468",1595,"https://github.com/vbfelix/tidytuesday","vbfelix","tidytuesday","2018/2018 - 002 - Average pay (NFL)/tt_002_NFL.R","# Packages ----------------------------------------------------------------

library(readxl)
library(tidyverse)


# Function ----------------------------------------------------------------

watermark<-function(logo){
  png::readPNG(logo)%>%
    grid::rasterGrob(image = ., interpolate = T)
}

# Import ------------------------------------------------------------------
list.files()
df_or<-read_xlsx(""tidy_tuesday_week2.xlsx"")

df_or %>% 
  mutate(Quarterback = Quarterback/10^6) %>% 
  group_by(year) %>% 
  top_n(16,Quarterback)->df

qb<- watermark(""quarterback.png"")

stadium <- watermark(""stadium.png"")


# Auxiliar data -----------------------------------------------------------

df %>% 
  group_by(year) %>% 
  summarise(mean = mean(Quarterback),
            max = max(Quarterback)) ->df_summ

df %>% 
  filter(year == 2011 | year == 2018) %>% 
  group_by(year) %>% 
  summarise(max = max(Quarterback),
            min = min(Quarterback),
            mean = mean(Quarterback)) ->df_ext


# Plot --------------------------------------------------------------------


df %>%
  ggplot(aes(year, Quarterback))+
  labs(x = ""Year"",y=""Salary ($ million)"",
       col="""",
       caption = ""Graphic: @H0Vinicius | Source: spotrac.com"",
       title = ""Top 16 quarterbacks (2011-2018)"",
       subtitle = ""Week 2 of #TidyTuesday"")+
  theme_minimal(16)+
  theme(legend.position = ""bottom"")+
  scale_x_continuous(breaks = 2011:2018,
                     labels = 2011:2018,
                     limits = c(2010,2018.5))+
  scale_y_continuous(breaks = seq(0,40,by=5),
                     labels = seq(0,40,by=5),
                     limits = c(-5,40) )+
  annotation_custom(qb,xmin = 2009.5,xmax = 2011,ymin = -5,ymax = 10)+
  ggrepel::geom_label_repel(data = df_ext,
                            aes(y= max,label = paste0(""$"",round(max,2))),
                            nudge_y = 4)+
  ggrepel::geom_label_repel(data = df_ext,
                            aes(y= min,label = paste0(""$"",round(min,2))),
                            nudge_y = -4)+
  ggrepel::geom_label_repel(data = df_ext,
                            aes(y= mean,label = paste0(""$"",round(mean,2))),
                            nudge_x = c(-.5,.5))+
  geom_point(size=2, alpha = .75)+
  geom_point(data = df_ext, aes(y = min, col = ""Minimum""),size=3)+
  geom_point(data = df_ext,aes(y = mean, col = ""Average""),size=3)+
  geom_point(data = df_ext, aes(y = max, col = ""Maximum""),size=3)+
  geom_curve(x = 2011+.15,
             xend = 2018-.15,
             y=df_ext$max[1]+2, yend = df_ext$max[2],
             curvature = -.2,
             arrow = arrow(length = unit(0.03, ""npc"")),
             size = 1.2,
             col = ""#CC0000"")+
  geom_curve(x = 2011+.15,
             xend = 2018-.15,
             y=df_ext$min[1]+.5, yend = df_ext$min[2],
             curvature = -.05,
             arrow = arrow(length = unit(0.03, ""npc"")),
             size = 1.2,
             col = ""#0066CC"")+
  geom_curve(x = 2011+.15,
             xend = 2018-.15,
             y=df_ext$mean[1]+.5, yend = df_ext$mean[2],
             curvature = -.15,
             arrow = arrow(length = unit(0.03, ""npc"")),
             size = 1.2,alpha=.6,
             col = ""#FF6600"")+
  scale_color_manual(values = c(""#FF6600"",""#CC0000"",""#0066CC""))
ggsave(""tt002.png"",scale = 2.5)


# Plot with back ground ----------------------------------------------------------------
qb2<- watermark(""quarterback2.png"")
df %>%
  ggplot(aes(year, Quarterback))+
  labs(x = ""Year"",y=""Salary ($ million)"",
       col="""",
       caption = ""Graphic: @H0Vinicius | Source: spotrac.com"",
       title = ""Top 16 quarterbacks (2011-2018)"",
       subtitle = ""Week 2 of #TidyTuesday"")+
  theme_minimal(16)+
  theme(legend.position = ""bottom"")+
  theme(plot.margin = unit(c(1,3,1,3), ""cm""),
        panel.grid.major = element_line(colour = NA),
        panel.grid.minor = element_line(colour = NA))+
  scale_x_continuous(breaks = 2011:2018,
                     labels = 2011:2018,
                     limits = c(2010,2018.5))+
  scale_y_continuous(breaks = seq(0,40,by=5),
                     labels = seq(0,40,by=5),
                     limits = c(-5,40) )+
  annotation_custom(stadium)+
  geom_hline(yintercept = seq(0,40,by=5),col=""white"",alpha=.45)+
  geom_vline(xintercept = 2011:2018,col=""white"",alpha=.45)+
  annotation_custom(qb2,xmin = 2009.5,xmax = 2011,ymin = -5,ymax = 10)+
  ggrepel::geom_label_repel(data = df_ext,
                            aes(y= max,label = paste0(""$"",round(max,2))),
                            nudge_x = c(-.25,.25))+
  ggrepel::geom_label_repel(data = df_ext,
                            aes(y= min,label = paste0(""$"",round(min,2))),
                            nudge_y = -2)+
  ggrepel::geom_label_repel(data = df_ext,
                            aes(y= mean,label = paste0(""$"",round(mean,2))),
                            nudge_x = c(-.25,.25))+
  geom_point(data = df_ext, aes(y = min, col = ""Minimum""),size=3)+
  geom_point(data = df_ext,aes(y = mean, col = ""Average""),size=3)+
  geom_point(data = df_ext, aes(y = max, col = ""Maximum""),size=3)+
  geom_curve(x = 2011+.15,
             xend = 2018-.15,
             y=df_ext$max[1]+2, yend = df_ext$max[2],
             curvature = -.2,
             arrow = arrow(length = unit(0.03, ""npc"")),
             size = 1.2,
             col = ""#CC0000"")+
  geom_curve(x = 2011+.15,
             xend = 2018-.15,
             y=df_ext$min[1]+.5, yend = df_ext$min[2],
             curvature = -.05,
             arrow = arrow(length = unit(0.03, ""npc"")),
             size = 1.2,
             col = ""#0066CC"")+
  geom_curve(x = 2011+.15,
             xend = 2018-.15,
             y=df_ext$mean[1]+.5, yend = df_ext$mean[2],
             curvature = -.15,
             arrow = arrow(length = unit(0.03, ""npc"")),
             size = 1.2,alpha=.6,
             col = ""#FF6600"")+
  scale_color_manual(values = c(""#FF6600"",""#CC0000"",""#0066CC""))

ggsave(""tt002-2.png"",scale = 2.5)
","2018"
"469",1596,"https://github.com/vbfelix/tidytuesday","vbfelix","tidytuesday","2019/2019_005_USDA.R","# libraries ---------------------------------------------------------------

library(tidyverse)
library(janitor)
library(showtext)


# import ------------------------------------------------------------------

url    <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/clean_cheese.csv""
df_or  <- read_csv(url)


# pre-plot ------------------------------------------------------------

glimpse(df_or)

summary(df_or)

df_or %>% 
  select(1,2,4) %>% 
  mutate(ratio = Cheddar/Mozzarella) %>% 
  clean_names() -> df

# plot --------------------------------------------------------------------

font_add_google(""Diplomata SC"")
font_families_google()
showtext_auto()

x11()

df %>% 
  mutate(change = if_else(ratio > 1, ""a"",""b"")) %>% 
  ggplot(aes(year, ratio))+
  annotate(""text"", x= 2005, y = 3, label = ""The Fall of\nCheddar"", col = ""#ff9522"", family = ""Diplomata SC"",
           size = 20)+
  # annotate(""rect"", xmin = 1970, xmax = 2017, ymin = 1, ymax = 5, fill = ""#ff9522"", alpha = .3)+
  # annotate(""rect"", xmin = 1970, xmax = 2017, ymin = 0, ymax = 1, fill = ""#fcf3d9"", alpha = .5)+
  geom_hline(yintercept = 1, col = ""royalblue3"",size = 1, alpha = .7)+
  geom_line(aes(col = change, group = 1),
            size = 1.5,
            show.legend = F)+
  # geom_point(aes(fill = change),
  #           shape = 21,
  #           size = 4,
  #           show.legend = F) +
  labs(x = ""Year"",
       y = ""Cheddar/Mozzarella"",
       col = ""Cheese:"",
       title = ""Ratio of cheddar/mozzarella consumption (lbs/person)"",
       subtitle = ""TidyTuesday - Week 5 : Dairy products"",
       caption = ""graphic: H0Vinicius | source: United States Department of Agriculture."")+
  theme_minimal(32)+
  theme(legend.position = ""bottom"",
        axis.text = element_text(colour = ""white""),
        text = element_text(colour = ""white""),
        panel.background = element_rect(fill = ""black""),
        plot.background = element_rect(fill = ""black""),
        panel.grid.major.x  = element_blank(),
        panel.grid.minor.x  = element_blank(),
        panel.grid.major.y  = element_line(size = 1 , colour = ""gray18""),
        panel.grid.minor.y  = element_line(size = 1 , colour = ""gray18""),
        plot.margin = unit( c(1,1,1,1),""cm""))+
  scale_colour_manual(values = c(""#ff9522"",""#fcf3d9""))+
  scale_x_continuous(breaks = c(seq(1970,2010, by = 10),2017),
                     expand = c(0,1.5))+
  scale_y_continuous(breaks = seq(1,5,by = 1), limits = c(0,5),
                     expand = c(0,0))+
  # geom_hline(col = ""royalblue2"",yintercept = 1, linetype = ""dashed"", size = 1)+
  NULL
  
  
","2019"
"470",1597,"https://github.com/vbfelix/tidytuesday","vbfelix","tidytuesday","2019/2019_006_mortgage.R","# libraries ---------------------------------------------------------------

library(tidyverse)
library(janitor)
library(fiftystater)
library(gganimate)
library(magrittr)
library(grid)
library(gridExtra)

# import ------------------------------------------------------------------

url    <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv""

df_or  <- read_csv(url) %>% filter(year > 2013)

abbr   <- read.table(col.names = c(""name"",""state""),
                     text = ""Alabama - AL
                     Alaska - AK
                     Arizona - AZ
                     Arkansas - AR
                     California - CA
                     Colorado - CO
                     Connecticut - CT
                     Delaware - DE
                     Florida - FL
                     Georgia - GA
                     Hawaii - HI
                     Idaho - ID
                     Illinois - IL
                     Indiana - IN
                     Iowa - IA
                     Kansas - KS
                     Kentucky - KY
                     Louisiana - LA
                     Maine - ME
                     Maryland - MD
                     Massachusetts - MA
                     Michigan - MI
                     Minnesota - MN
                     Mississippi - MS
                     Missouri - MO
                     Montana - MT
                     Nebraska - NE
                     Nevada - NV
                     New Hampshire - NH
                     New Jersey - NJ
                     New Mexico - NM
                     New York - NY
                     North Carolina - NC
                     North Dakota - ND
                     Ohio - OH
                     Oklahoma - OK
                     Oregon - OR
                     Pennsylvania - PA
                     Rhode Island - RI
                     South Carolina - SC
                     South Dakota - SD
                     Tennessee - TN
                     Texas - TX
                     Utah - UT
                     Vermont - VT
                     Virginia - VA
                     Washington - WA
                     West Virginia - WV
                     Wisconsin - WI
                     Wyoming - WY"",sep = ""-"",
                     stringsAsFactors = F) %>% 
  mutate_all(str_trim)

df_or %>% 
  group_by(state,year) %>% 
  summarise(price_index = mean(price_index)) %>% 
  left_join(abbr) %>% 
  right_join(fifty_states %>%  mutate(name = str_to_title(id))) -> df_map

# plot --------------------------------------------------------------------
df_map %>% 
  filter(is.na(year)==F) %$%
  summary(price_index)

df_map %>% 
  filter(is.na(year)==F) %>% 
  ggplot(aes(long,lat,fill = ))+
  geom_polygon(aes(group = group, fill= price_index),col = ""black"")+
  coord_map()+
  theme_void(18)+
  theme(legend.key.height = unit(1.5,""cm""),
        plot.margin = unit(c(.5,.5,.5,.5),""cm""),
        plot.caption = element_text(hjust = 0))+
  labs(fill = ""Price\nIndex"")+
  scale_fill_viridis_c(option = ""B"",limits = c(95,280),
                       breaks = seq(95,280, by = 30))+
  labs(title = ""TidyTuesday - Week 6 : House and Mortgage"",
       subtitle = """",
       caption = ""graphic: H0Vinicius | source: Freddie Mac."")+
  facet_wrap(.~year, ncol = 3) -> p1

df_or %>% 
  group_by(year) %>% 
  summarise(us_avg = mean(us_avg)) %>% 
  ggplot(aes(year, us_avg)) +
  theme_bw(12) +
  geom_col(aes(fill = us_avg), show.legend = F,col = ""black"")+
  geom_text(aes(label = us_avg %>% round(2), y = us_avg*.85),fontface = ""bold"",size = 5)+
  scale_x_continuous(breaks = 2014:2018)+
  scale_fill_viridis_c(option = ""B"",limits = c(95,280),
                       breaks = seq(95,280, by = 30))+
  scale_y_continuous(expand = c(0,0), breaks = seq(0,200,by = 50), limits =c(0,200))+
  labs(x = """",y = """",
       title = ""Price Index - Averaged at national level"") ->p2

x11()

grid1 <- viewport(width = 1, height = 1, x = 0.5, y = 0.5) 
grid2 <- viewport(width = 0.25, 
                  height = .33,
                  x = 0.77, y = .3) 

grid.newpage()
print(p1, vp = grid1)
print(p2, vp = grid2)
","2019"
"471",1598,"https://github.com/vbfelix/tidytuesday","vbfelix","tidytuesday","2019/2019_007_federal research.R","# libraries ---------------------------------------------------------------

library(tidyverse)
library(janitor)
library(showtext)
library(ggTimeSeries)

# import ------------------------------------------------------------------

url    <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv""

df_or  <- read_csv(url) %>% clean_names()

# pre-plot ------------------------------------------------------------

df_or %>% 
  select(-c(total_outlays,discretionary_outlays,gdp)) %>% 
  filter(department %in% c(""NASA"")) %>% 
  mutate(rd_bil = rd_budget/(10^9)) -> df

glimpse(df)

summary(df)

n <- df %>% nrow()


df %>% 
  mutate(rd1 = c(rd_bil[1:(n-1)],NA)) %>% 
  mutate(rd2 = c(rd_bil[2:n],NA)) %>% 
  mutate(raz = rd1/rd2) %>% 
  mutate(just = case_when(
    raz < 1 ~ 1.5,
    raz >= 1 ~  -1
  )) -> df

x_axis <- c(1980,1983,2000,1990,2011) 
x_labl <- c(""Shuttle Era\nBegins"",""Staff\nincrease"",""The 21st\nCentury"",
            ""A New\nName"",""SpaceX\nContract"")

# plot --------------------------------------------------------------------

df %>% 
  ggplot_waterfall(""year"",""rd_bil"")+
  geom_text(data = df,
            aes(x = year, y = rd1, label = year, vjust = just))+
  geom_text(data = df,
            aes(x = year, y = rd2, label = year +1,vjust = - (just-.25) ))+
  labs(x = """",
       y = ""Research and Development Budget (Billions/$)"",
       fill = """",
       title = ""NASA Timeline| R&D Budget | 1976-2017"",
       subtitle = ""TidyTuesday - Week 7: Federal R&D Spendings"",
       caption = ""graphic: H0Vinicius | source: AAAS & NASA."")+
  theme_bw(18)+
  theme(legend.position = ""none"",
        plot.margin = unit( c(.5,.5,.5,.5),""cm""),
        panel.grid = element_blank())+
  scale_x_continuous(limits = c(1975.5,2016.5),
                     breaks = x_axis,
                     labels = x_labl,
                     expand = c(0,0))+
  scale_y_continuous(expand = c(0,0),
                     breaks = seq(5,15,by =1),
                     limits = c(5,15))+
    NULL



","2019"
"472",1599,"https://github.com/vbfelix/tidytuesday","vbfelix","tidytuesday","2019/2019_008_PHD.R","# libraries ---------------------------------------------------------------

library(tidyverse)
library(janitor)
library(showtext)

# import ------------------------------------------------------------------

url    <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv""

df_or  <- read_csv(url) %>% clean_names()


# pre-plot ----------------------------------------------------------------

df_or %>% summary()

df_or$major_field %>% table()

df_or$broad_field %>% table()

df <- df_or %>% 
  mutate(year = as.factor(year)) %>% 
  mutate(broad_field = case_when(
    str_detect(broad_field,""Mathema"") == T ~ ""Math/C.S"",
    str_detect(broad_field,""Psycholog"") == T ~ ""Social"",
    str_detect(broad_field,""Humanities"") == T ~ ""Humanities"",
    T ~ broad_field
  )) %>% 
  group_by(broad_field, year) %>% 
  summarise(n = sum(n_phds,na.rm = T)) %>% 
  group_by(year) %>% 
  mutate(N = sum(n,na.rm = T),
         p = round(100*n/N,2) ) %>% 
  mutate(broad_field = fct_reorder(broad_field, p) %>% fct_rev()) %>%  
  mutate(broad_field = fct_relevel(broad_field, ""Other"", after = Inf))  
  

df %>% summary()

# plot --------------------------------------------------------------------

df %>% 
  ggplot(aes( x= year, p ))+
  geom_col(aes(fill = broad_field))+
  #coord_flip()+
  scale_y_continuous(expand = c(0,0))+
  scale_x_discrete(expand = c(0,0))+
  theme_bw(18)+
  labs(y = ""%"",
       x = ""Year"",
       fill = ""Field:"",
       title = ""% of PhD awarded by field | 2008-2017"",
       subtitle = ""TidyTuesday - Week 8: US PhD's Awarded"",
       caption = ""graphic: H0Vinicius | source: NSF."")+
  scale_fill_brewer(palette = ""Set1"")


df %>% 
  ggplot(aes(year, broad_field ))+
  geom_tile(aes(fill = p), col = ""black"")+
  scale_y_discrete(expand = c(0,0))+
  scale_x_discrete(expand = c(0,0))+
  theme_bw(18)+
  theme(legend.key.height = unit(1.25,""cm""))+
  labs(fill = ""%"",
       x = ""Year"",
       y = ""Field"",
       title = ""% of PhD awarded by field | 2008-2017"",
       subtitle = ""TidyTuesday - Week 8: US PhD's Awarded"",
       caption = ""graphic: H0Vinicius | source: NSF."")+
  scale_fill_gradient2(low = ""yellow"",
                       mid = ""darkorange1"",
                       high = ""firebrick1"",
                       midpoint = 21,
                       limits  = c(0,42))+
  geom_text(aes(label = p), fontface = ""bold"")
  
","2019"
"473",1600,"https://github.com/markswitajski/TidyTuesday","markswitajski","TidyTuesday","2019-02-12/2019-02-12.R","library(tidyverse)

funding <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"") %>% 
  filter(department == ""DOD"")

fund_plot =
  ggplot() +
  geom_line(data = funding, aes(x = year, y = rd_budget/1000000000), size = 1) +
  geom_rect(aes(xmin=2009, xmax=2017, ymin=0, ymax=Inf, fill = ""Democrat""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=2001, xmax=2009, ymin=0, ymax=Inf, fill = ""Republican""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1993, xmax=2001, ymin=0, ymax=Inf, fill = ""Democrat""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1981, xmax=1993, ymin=0, ymax=Inf, fill = ""Republican""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1977, xmax=1981, ymin=0, ymax=Inf, fill = ""Democrat""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1974, xmax=1977, ymin=0, ymax=Inf, fill = ""Republican""), color = NA, alpha = 0.25) +
  
  scale_fill_manual(""President's Party"",
                    values = c('blue', 'red'),  
                    guide = guide_legend(override.aes = list(alpha = 0.1))) +
  
  scale_x_continuous(breaks = seq(1976, 2017, 4)) +
  scale_y_continuous(breaks = seq(0, 100, 20)) +
  
  labs(
    title = ""Dept. of Defense Spending on\nResearch & Development vs Presidential Party"",
    x = ""Year"",
    y = ""Annual Budget (Billions USD)\n"") +
    
  theme_minimal(16) +
  theme(plot.title = element_text(size=16, hjust = 0.5),
        axis.text.y = element_text(hjust = 0),
        legend.position = ""right"",
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12)
  )


fund_plot

ggsave(filename = ""20190212_Federal_Budget_DOD_by_Party.jpg"", width=20, height=10, units=""cm"", scale=1.6)
","2019"
"474",1601,"https://github.com/markswitajski/TidyTuesday","markswitajski","TidyTuesday","2019-02-19/2019-02-19.R","library(tidyverse)
library(gganimate)

degrees <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"") %>% 
  filter(major_field == ""Mathematics and statistics"" & !is.na(n_phds))

phds <- 
  ggplot(degrees, aes(x = reorder(field, n_phds), y = n_phds)) +
  geom_bar(stat = ""identity"", fill= ""#810F7C"") +
  coord_flip() + 
  
  theme_minimal(16) +
  theme(plot.title = element_text(size = 18, face = ""bold""),
        plot.subtitle = element_text(size = 13.5, color = ""gray40"", face = ""bold""),
        axis.title.x = element_text(size = 15, color = ""gray40"", face = ""bold""),
        axis.title.y = element_text(size = 15, color = ""gray40"", face = ""bold"")) +

  labs(
    title = ""What Are Young\nMathematicians Studying?"",
    subtitle = 'Year: {frame_time}', x = 'Field of Study', y = 'Number of PhDs Awarded') +
    transition_time(year) +
    ease_aes('quintic-in-out')

phds

anim_save(filename = ""20190219_Mathematics_PhDs.gif"", width = 40)
","2019"
"475",1602,"https://github.com/markswitajski/TidyTuesday","markswitajski","TidyTuesday","2019-03-05/2019-03-05.R","setwd(""~/TidyTuesday/2019-03-05"")
library(tidyverse)
library(cowplot)

jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")
earnings_female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"") 
employed_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"") 

plot1 <- 
  ggplot(employed_gender, aes(x = year)) +
  geom_line(aes(y = full_time_female), color = ""darkgreen"", size = 2) +
  geom_line(aes(y = full_time_male), color = ""goldenrod"", size = 2) +
  geom_ribbon(aes(ymin = (full_time_female + 0.5), ymax = (full_time_male - 0.5)), fill = ""lightblue"", alpha = 0.5) +
  
  geom_text(aes(x = 1990, y = 95, label = ""Men""), color = ""goldenrod"") + 
  geom_text(aes(x = 1990, y = 70, label = ""Women""), color = ""darkgreen"") +
  
  ylim(0, 100) +
  
  theme_minimal(16) +
  theme(plot.title = element_text(size = 18, face = ""bold""),
        plot.subtitle = element_text(size = 13.5, color = ""gray40"", face = ""bold""),
        axis.title.x = element_text(size = 15, color = ""gray40"", face = ""bold""),
        axis.title.y = element_text(size = 15, color = ""gray40"", face = ""bold"")) +
  
  labs(
    x = '',
    y = 'Percent of Full-Time Workers'
  )
  

plot2 <- 
  ggplot(employed_gender, aes(x = year)) +
  geom_line(aes(y = part_time_female), color = ""darkgreen"", size = 2) +
  geom_line(aes(y = part_time_male), color = ""goldenrod"", size = 2) +
  geom_ribbon(aes(ymin = (part_time_male + 0.5), ymax = (part_time_female - 0.5)), fill = ""lightblue"", alpha = 0.5) +
  
  geom_text(aes(x = 1990, y = 7, label = ""Men""), color = ""goldenrod"") + 
  geom_text(aes(x = 1990, y = 32, label = ""Women""), color = ""darkgreen"") +
  
  ylim(0, 100) +
  
  theme_minimal(16) +
  theme(plot.title = element_text(size = 18, face = ""bold""),
        plot.subtitle = element_text(size = 13.5, color = ""gray40"", face = ""bold""),
        axis.title.x = element_text(size = 15, color = ""gray40"", face = ""bold""),
        axis.title.y = element_text(size = 15, color = ""gray40"", face = ""bold"")) +
  
  labs(
    x = '',
    y = 'Percent of Part-Time Workers'
  )

p <- plot_grid(plot1, plot2)

title <- ggdraw() + draw_label(""Gender gap between full-time and part-time employees"", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))


ggsave(filename = ""20190305_Full_and_Part_Time_Rates_by_Gender.png"", width=16, height=10, units=""cm"", scale=1.6)
","2019"
"476",1611,"https://github.com/kigtembu/Tidyverse/blob/master/week_10_2019.R","kigtembu","Tidyverse","week_10_2019.R","##---------------##
## Tidy Tuesday  ##
## Week 10 2019 ##
## 3/5/2019    ##

library(tidyverse)
library(scales)
library(gganimate)
library(magick)

url <-""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv""

jobs_women_raw <- read_csv(url)

comp_math <- jobs_women_raw %>% 
  filter(occupation %in% c(""Statisticians"",
                           ""Actuaries"",""Mathematicians"")) %>%
  select(year,occupation,total_earnings_male,total_earnings_female)%>%
  gather(gender,earnings,-c(year,occupation)) %>% 
  mutate(gender = if_else(str_detect(gender,""female""),""Female"",
                          ""Male"")) %>% 
  ggplot(aes(x = year, y = earnings,fill = gender))+
  geom_col(position = ""dodge"")+
  theme_light()+
  scale_y_continuous(labels = scales::comma)+
  labs(x = ""Year"",y = ""Estimated Median Earnings($)"",
       color = ""Gender"",
       caption = ""Source:Census Bureau\nPlot by @kigtembu"",
       title = ""Occupation:{closest_state}"")+
  transition_states(occupation)

animate_math <- animate(comp_math)

anim_save(""week_10_2019.gif"") 
","2019"
"477",1616,"https://github.com/kigtembu/Tidyverse/blob/master/week_1_2019.R","kigtembu","Tidyverse","week_1_2019.R","##---------------##
## Tidy Tuesday  ##
## Week 2 2019   ##
## 1/7/2019      ##


# packages ----------------------------------------------------------------

library(tidyverse)
library(skimr)


# Raw data ----------------------------------------------------------------

url <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv'
raw_tv_ratings <- read_csv(url)

#Get  10 longest running shows
longest_running <- raw_tv_ratings %>% count(title,sort = TRUE) %>% 
                   top_n(10)

#merge back to get ratings

longest_running_tv_ratings <- inner_join(longest_running,raw_tv_ratings,by = 'title') %>% 
                              select(title,av_rating)

#plot
plot_ratings <- ggplot(longest_running_tv_ratings,aes(x=title,y=av_rating,fill=title))+
                geom_boxplot()+
                theme_light()+
                guides(fill = FALSE)+
                coord_flip()+
                labs(
                  title = 'Boxplot of the Ratings of the 10 longest Running Shows',
                  x = 'Show Title',
                  y = 'Average Ratings',
                  caption = 'Source:The Economist\nPlot created by @kigtembu'
                )
ggsave('week_1_2019.png')
","2019"
"478",1623,"https://github.com/jasonmstevensphd/TidyTuesday_JMS","jasonmstevensphd","TidyTuesday_JMS","Tidy_Tuesday_2018_08_21.Rmd","---
title: ""Tidy Tuesday Week 21""
author: ""@jasonmstevens""
date: ""8/20/2018""
output:
  html_document:
    theme: journal
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## How A Booming Population And Climate Change Made Californias Wildfires Worse Than Ever

This is my take on the 2018 August 21 dataset provided by rfordatascience/tidytuesday.

<br>

The data for this study can be found here:

<p>

<https://github.com/rfordatascience/tidytuesday/tree/master/data/week21>

<br>

All the following code for this exercise can be found at my github repo here:

<p>

<https://github.com/jasonmstevensphd/tidytuesday/tree/2018_08_21>

<br>

Lastly, the corresponding article from Buzzfeed can be found here:

<p>

<https://www.buzzfeednews.com/article/peteraldhous/california-wildfires-people-climate>

<br>

Here we go!

###Initial Exploration of the Dataset

```{r Libraries, message=FALSE, warning=FALSE, EVAL=FALSE, include=FALSE}

# This is where we import our libraries and files. We'll also add some information to be included on our plots

library(knitr)
library(tidyverse)
library(RColorBrewer)
library(lubridate)

Cal_Fires <- read_csv(""week21_calfire_frap.csv"") %>%
  mutate(Alarm_Date = ymd(alarm_date)) %>%
  mutate(Contained_Date = ymd(cont_date)) %>%
  mutate(Year = year(Alarm_Date)) %>%
  rename(Fire_Name = fire_name) %>%
  mutate(cause2 = case_when(cause == 1 | cause == 17 ~ ""Natural"",
                            cause == 14 | is.na(cause) ~ ""Unknown"",
                            cause != 1 | cause != 14 | cause != 17 ~ ""Human""))

Time_of_Analysis <- now(tz = ""America/New_York"")
Analyst <- ""@jasonmstevens""

plot <-        theme(plot.background = element_rect(fill = ""white""))+
               theme(panel.background = element_rect(fill = ""white"",
                                                     colour=""grey50""))+
               theme(plot.title = element_text(face = ""bold"", 
                                  size = 18,
                                  color = ""navy""))+
               theme(axis.title = element_text(face = ""bold"", size = 16))+
               theme(aspect.ratio = 3.5/5)

```

<br>

To start, I imported the calfires_week21_frap.csv and I employed the case_when function that the original auther used to assign cause_2 as it's not explicitly clear what the numbers correlate to in the dataset. This was a nice example of ""case_when"" that I'll definitely add to my repretoire. 

```{r Barplot of California Wildfires, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Cal_Fires_Bar <- Cal_Fires %>%
  group_by(Year) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Year, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires"")+
  labs(x = ""Year"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Bar

```

Text

```{r California Wildfires by Month, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Cal_Fires_Month <- Cal_Fires %>%
  mutate(Month = month(Alarm_Date, label = TRUE)) %>%
  group_by(Month) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Month, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires\nby Month Since 1950"")+
  labs(x = ""Month"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Month
  

```

```{r Active Season California Wildfires, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Active_Season <- c(""Aug"", ""Sep"", ""Oct"")

Cal_Fires_Active <- Cal_Fires %>%
  mutate(Month = month(Alarm_Date, label = TRUE)) %>%
  filter(Month %in% Active_Season) %>%
  group_by(Year) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Year, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires\n During Active Season by Year"")+
  labs(x = ""Year"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Active
  
```

```{r Quiet Season California Wildfires, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Active_Season <- c(""Aug"", ""Sep"", ""Oct"")

Cal_Fires_Quiet <- Cal_Fires %>%
  mutate(Month = month(Alarm_Date, label = TRUE)) %>%
  filter(!(Month %in% Active_Season)) %>%
  group_by(Year) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Year, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires\n During Quiet Season by Year"")+
  labs(x = ""Year"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Quiet

ggsave(Cal_Fires_Quiet, filename = ""Cal_Fire_Quiet.png"")
  
```","2018"
"479",1626,"https://github.com/adanvers/tidyTuesday","adanvers","tidyTuesday","tidyTuesday_2019_1_8_tvDramas.Rmd","---
title: 'Tidy Tuesday Jan 8 2019: TV Dramas'
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(ggplot2)
```

This is the first contribution to Tidy Tuesdays of Alex Danvers.

The data set contains information on TV Dramas from 1990 to 2018, including ratings, shares, and secondary categorizations of the shows.

In this document I explore changes in the common secondary classifications of dramas over time. This may give insight into the kinds of dramas that have been popular across different decades--dramas mixed with action, or with comedy, etc.

# Read in the Data

```{r read and explore data}
# read in data
tvData <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"")

### examine basic characteristics of data
dim(tvData)
head(tvData)

# we should convert the date info from an integer to a date format
tvData$dateFormatted <- date(tvData$date)

# then we can save just the year, to simplify future viewing
tvData$year <- year(tvData$dateFormatted)

# what range does the data span?
range(tvData$dateFormatted)

# how many unique shows?
length(unique(tvData$title))

# how many genres?
length(unique(tvData$genres))
# 97! but this includes ""combo genres""
```

The data set had a single genre variable, saved as a string, that includes multiple categorizations, separated by commas. Each TV show can have 1, 2, or 3 categorizations. This means that assessments of the secondary categorizations of TV shows are not mutually exclusive: more action shows doesn't necessarily mean less of other shows, because the total number of secondary categories is not constant from year to year. 

```{r create genre categorizations}
# create list of all genres
genres <- unique(unlist(strsplit(as.character(tvData$genres), "","")))

# looping through each genre to create dummy codes
for (i in 1:length(genres)) {
  tvData[,genres[i]] <- as.numeric(grepl(genres[i], as.character(tvData$genres)))
}

# examine overall rates of all categories
colMeans(tvData[,genres])

# save the most common secondary categories
commonCats <- which(colMeans(tvData[,genres]) > .10)

# create a data set that contains the proportion of genre by year
genreProps <- tvData %>%
  group_by(year) %>%
  summarise_at(mean, .vars=genres) %>%
  gather(key=""genreCat"", value=""Proportion"", genres[2:length(genres)])
```

# Create the Final Plot

In the plot below, we plot the change over time in common secondary categorizations of TV dramas.

A red dotted line has been placed at the 25% mark, for ease of reference.

Plots also have a black loess line superimposed on them to track the shape of the data.

```{r plot}
ggplot(data=genreProps[which(genreProps$genreCat %in% names(commonCats)),], aes(y=Proportion, x=year))+
  geom_line(aes(color=genreCat))+
  geom_point(aes(color=genreCat))+
  geom_line(stat=""smooth"", method=""loess"", se=FALSE, color=""black"", lty=1, alpha=0.75)+
  theme_bw()+
  facet_grid(.~genreCat)+
  geom_hline(yintercept=0.25, lty=2, color=""red"")+
  theme(legend.position=""none"", plot.title=element_text(hjust=0.5))+
  labs(title=""Common Secondary Categorizations \n of Dramas from '90 to '18"")+
  scale_x_continuous(breaks=c(1990,2000,2010),
                     labels=c(""'90"",""'00"",""'10""))
```

This plot suggests that drama/comedies were most common in the early 90's, but declined to below 25% by ~95. Around 95 there was a brief spike in drama/action shows, but this trend was shortlived. From around 2000 to 2010 the number of drama/crime shows increased, but they have declined in recent years. 

There was also a small rise in drama/romance shows from 1990 to ~2005, but the proportion of these shows has declined in the last decade. There were small fluctuations in the proportion of drama/mysteries over this time period, and this genre is now in decline.

Currently the most popular secondary genre for a drama is crime.

","2019"
"480",1631,"https://github.com/grwllrnc/TidyTuesday/tree/master/2019-2-19","grwllrnc","TidyTuesday","2019-2-19/phd_by_field.Rmd","---
title: ""#TidyTuesday: PhDs Awarded by Field""
author: ""grwllrnc""
date: ""19 Februar 2019""
output: html_document
---

```{r}
library(tidyverse)

# set ggplot2 theme
theme_set(theme_light())
```

```{r}
# read data
data <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")

# clean that mess
data <- data %>%
  mutate(broad_field = str_to_title(broad_field),
         field = str_replace(field, ""Anthropology, generalj"", ""Anthropology, general""),
         field = str_to_title(field))
```

### Which fields of study have the highest change in number of graduates over time (greatest variance)?

```{r}
# Standard Deviation of Fields of Study
sd_top5 <- data %>%
  group_by(field) %>%
  mutate(sd_field = sd(n_phds, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(sd_field > quantile(sd_field, 0.95, na.rm = TRUE)) %>%
  mutate(field = fct_reorder(field, sd_field))

sd_top5 %>%
  ggplot(aes(field, sd_field, color = broad_field, size = n_phds)) +
  geom_point() +
  coord_flip() +
  scale_color_discrete(name = ""Broad Field"") +
  scale_size_continuous(name = ""# of Graduates"") +
  labs(title = ""Fields of Study with Highest Change in Number of Graduates over Time"",
       subtitle = ""Sorted by Standard Deviation, Top 5%"",
       caption = ""#tidytuesday, 2019-02-19 | @grwllrnc\nData source: National Science Foundation, nsf.gov"",
       x = ""Field of Study"",
       y = ""Standard Deviation of # of Awarded PhDs"")

ggsave(""../Tidy Tuesday/Variance 1.png"", units = ""cm"", width = 29.7, height = 21)
```


```{r}
# Fields of Study with Highest Change in Number of Graduates over Time (top 5%)
selected_fields <- as.character(unique(sd_top5$field))
  
# Change over time of each field (top 5%)
# Facet plot
data %>%
  filter(field %in% selected_fields) %>%
  group_by(field) %>%
  mutate(sd_field = sd(n_phds, na.rm = TRUE)) %>%
  ungroup() %>%
  ggplot(aes(year, n_phds)) +
  geom_line() +
  scale_x_continuous(breaks = c(2009, 2011, 2013, 2015, 2017)) +
  facet_wrap(~ fct_reorder(field, desc(sd_field)), scale = ""free_y"") +
  labs(title = ""Fields of Study with Highest Change in Number of Graduates over Time"",
       subtitle = ""Sorted by Standard Deviation, Top 5%"",
       caption = ""#tidytuesday, 2019-02-19 | @grwllrnc\nData source: National Science Foundation, nsf.gov"",
       x = ""Year"",
       y = ""# of Awarded PhDs"")

ggsave(""../Tidy Tuesday/Variance 2.png"", units = ""cm"", width = 21, height = 21)
```
","2019"
"481",1632,"https://github.com/dylanjm/tidy_tuesday/blob/master/tidy_2019/tidy_02/tidy_02.R","dylanjm","tidy_tuesday","tidy_2019/tidy_02/tidy_02.R","library(tidyverse)
library(ggrepel)
library(gganimate)

# Grab my predownloaded data
tv_dat <- read_csv(here::here(""data/data_2019/week02_tv_ratings.csv""))

# Shows we'll look at specifically
tv_shows <- c(""The Sopranos"", 
              ""Twin Peaks"", 
              ""Sex and the City"", 
              ""The Wire"", 
              ""The X-Files"", 
              ""Breaking Bad"", 
              ""Game of Thrones"")

# This will let us label our plot correctly
# also we need to account for the two reboots in our data
tv_show_dat <- tv_dat %>% 
  filter(title %in% tv_shows) %>% 
  mutate(title = case_when(
    title == ""Twin Peaks"" & date > as.Date(""2010-01-01"") ~ ""Twin Peaks\n(reboot)"", 
    title == ""The X-Files"" & date > as.Date(""2010-01-01"") ~ ""The X-Files\n(reboot)"",
    TRUE ~ title
  ))

# Without this we'll get a text label at each highlighted point
# We only want the text to show on the first point for each series
labs <- tv_show_dat %>% 
  group_by(title) %>% 
  filter(row_number(title) == 1)

# First Plot
# We are trying to make it _exactly_ as it is created on the article
# (sans interactive element)
tv_dat %>% 
  mutate(year = lubridate::year(date)) %>% 
  ggplot(aes(x = date, y = av_rating, size = share)) + 
  geom_point(color = ""#d7ebf2"", alpha = .8) + 
  geom_smooth(method = ""lm"", se = F, linetype = ""dashed"", 
              color = ""skyblue4"") + 
  annotate(geom = ""text"", x = as.Date(""2015-01-01""), y = 8.2, 
            label = ""TV drama trend"", color = ""skyblue4"", 
           fontface = ""bold"", size = 4) + 
  geom_point(data = tv_show_dat, aes(x = date, y = av_rating, size = share),
             color = ""#42bbd0"") + 
  geom_line(data = tv_show_dat, aes(x = date, y = av_rating, group = title), 
            color = ""#42bbd0"", inherit.aes = FALSE) + 
  geom_text_repel(data = labs, aes(x = date, y = av_rating, label = title), 
                  color = ""#42bbd0"", inherit.aes = FALSE, nudge_y = -.15,
                  fontface = ""bold"", size = rel(6)) + 
  coord_cartesian(ylim = c(5.5, 9.5)) + 
  scale_y_continuous(breaks = seq(5.5, 9.5, .5), position = ""right"")+
  scale_x_date(breaks = as.Date(c(""1990-01-01"",
                                       ""1995-01-01"", ""2000-01-01"",
                                       ""2005-01-01"", ""2010-01-01"",
                                       ""2015-01-01"", ""2018-01-01"")), 
               date_labels = ""%Y"") +
  scale_size_continuous(range = c(2,10)) + 
  labs(title = ""The end of channel surfing\nTV's golden age is real"", 
       subtitle = ""But for every Breaking Bad, more shows are just bad"",
       caption = ""*Seasons with at least 100 ratings on average\n*Size=Share of IMDb ratings for shows that year"") + 
  theme_minimal() + 
  theme(plot.title = element_text(hjust = .5, size = rel(2.5)),
        plot.subtitle = element_text(hjust = .5, face = ""italic"", size = rel(1.3)),
        plot.caption = element_text(face = ""italic"", color = ""grey60"", 
                                    size = rel(1)), 
        axis.title = element_blank(),
        axis.text = element_text(size = rel(1.2)),
        panel.grid.minor = element_blank(),
        panel.grid.major.y = element_blank(), 
        legend.position = ""none"")

# Unnesting all the genre data for each tv show
genre_dat <- tv_dat %>% 
  mutate(genres = str_split(genres, pattern = "","")) %>% 
  unnest()

# Grabbing the top five genres in the data-set
top_genres <- genre_dat %>% 
  count(genres) %>% 
  top_n(6, n) %>% 
  mutate(genres = fct_reorder(genres, n, max, .desc = T)) %>% 
  pull(genres)

# Visualization of how time effects ratings. 
genre_dat %>% 
  filter(genres %in% top_genres) %>%
  mutate(genres = fct_relevel(genres, c(""Drama"", ""Crime"", ""Mystery"",
                                        ""Comedy"", ""Action"", ""Romance""))) %>% 
  ggplot(aes(x = seasonNumber, y = av_rating, size = share)) + 
  geom_point(color = ""skyblue"", alpha = .3) + 
  geom_smooth(se = F, color = ""skyblue4"") + 
  scale_x_continuous(breaks = seq(1, 10, 2), 
                     limits = c(1, 10)) + 
  scale_y_continuous(breaks = seq(2, 9.5, .5), 
                     limits = c(4, 10), 
                     position = ""right"") + 
  scale_size_continuous(range = c(3, 9)) + 
  facet_wrap(~ genres) + 
  labs(title = ""Do Ratings Decline Over Time?"",
       subtitle = ""Most genres see a peak in ratings shortly after\na series begins and trends downward overtime."",
       x = ""Seasons"", y = ""Avg. Rating"") + 
  ggthemes::theme_fivethirtyeight() + 
  theme(legend.position = ""none"", 
        panel.grid.minor = element_blank(), 
        axis.text = element_text(size = rel(1.3)),
        strip.text = element_text(face = ""bold"", size = 14),
        plot.title = element_text(hjust = .5, size = rel(3)),
        plot.subtitle = element_text(hjust = .5, size = rel(1.5))
        )

# Throw away plot; making an animation, I don't think this has strong interpretative value. 
tv_dat %>% 
  mutate(year = lubridate::year(date)) %>% 
  ggplot(aes(x = share, y = av_rating, size = seasonNumber)) + 
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE, color = ""red"", linetype = ""dashed"", size = 1.9) +
  scale_y_continuous(limits = c(4, 10)) + 
  scale_x_sqrt() + 
  scale_size_continuous(range = c(2, 10)) + 
  ggthemes::theme_fivethirtyeight() +
  labs(title = 'Year: {round(frame_time,0)}', x = 'Share', y = 'Avg. Rating', 
       size = ""Season"") +
  transition_time(year) +
  ease_aes('linear')
  
","2019"
"482",1633,"https://github.com/dylanjm/tidy_tuesday/blob/master/tidy_2019/tidy_04/tidy_04.R","dylanjm","tidy_tuesday","tidy_2019/tidy_04/tidy_04.R","# Load Library
library(tidyverse)
library(USAboundaries)

raw_dat <- read_csv(here::here(""data/data_2019/week04_incarceration_trends.csv""))
pretrial_dat <- read_csv(here::here(""data/data_2019/week04_pretrial_summary.csv""))
prison_pop <- read_csv(here::here(""data/data_2019/week04_prison_population.csv""))


plot_1_colors <- ggthemes::ggthemes_data[[""fivethirtyeight""]] %>% 
  filter(name %in% c(""Red"", ""Blue"", ""Green"")) %>% 
  pull(value)

label_dat <- pretrial_dat %>% 
  group_by(urbanicity) %>% 
  filter(row_number() == n()) %>% 
  ungroup() %>% 
  mutate(lab_x = c(2017, 2017, 2017, 2016.5),
         lab_y = c(255, 252, 174, 173))

pretrial_dat %>% 
  filter(pop_category == ""Total"") %>% 
  ggplot(aes(x = year, y = rate_per_100000, 
             color = urbanicity, group = urbanicity)) + 
  geom_line(size = 4/.pt) + 
  ggrepel::geom_text_repel(data = label_dat,
                           aes(label = tools::toTitleCase(urbanicity),
                               x = lab_x, y = lab_y),
                           size = 14/.pt, fontface = ""bold"") + 
  scale_x_continuous(breaks = c(seq(1970, 2010, 10), 2016),
                     limits = c(1970, 2019)) +
  scale_y_continuous(breaks = seq(0, 300, 100), 
                     limits = c(0, 300)) + 
  scale_color_manual(values = c(""Gold3"", plot_1_colors)) +
  labs(title = ""Pretrial Incarceration by Urban-Rural Counties"", 
       y = expression(Rate[""(per 100,000 population)""])) +
  theme_classic() + 
  theme(panel.grid = element_blank(),
        axis.title.x = element_blank(), 
        axis.title.y = element_text(size = 16,
                                    family = ""IBMPlexSans-Light""),
        axis.text = element_text(size = 12,
                                 family = ""IBMPlexSans-Light""),
        plot.title = element_text(size = 18,
                                  family = ""IBMPlexSans-Light""),
        legend.position = ""none"", 
        plot.background = element_rect(fill = ""grey95""),
        panel.background = element_rect(fill = ""grey95""),
        aspect.ratio = .65)

ggsave(here::here(""tidy_2019/tidy_04/plot_01.png""), width = 10, height = 6)

test <- raw_dat %>% 
  filter(state == ""UT"", 
         year == ""2016"") %>% 
  gather(key = ""jail_pop"", value = ""pct_pop"", 
         asian_jail_pop:white_jail_pop) %>% 
  gather(key = ""race_pop"", value = ""race_pct_pop"", 
         asian_pop_15to64:white_pop_15to64) %>% 
  select(1:7, jail_pop, pct_pop, race_pop, race_pct_pop, total_prison_pop)

test_clean <- test %>% 
  mutate(race_jail_ratio = pct_pop/total_prison_pop,
         race_pop_ratio = race_pct_pop/total_pop_15to64,
         fips = str_pad(fips, 5, pad = ""0"")) %>% 
  left_join(us_counties(state = ""UT""), by = c(""fips"" = ""geoid"")) %>% 
  sf::st_as_sf()

ggplot(test_clean) +
  geom_sf(aes(fill = race_jail_ratio)) +
  theme_map()
  
","2019"
"483",1634,"https://github.com/dylanjm/tidy_tuesday/blob/master/tidy_2019/tidy_03/tidy_03.R","dylanjm","tidy_tuesday","tidy_2019/tidy_03/tidy_03.R","library(tidyverse)

agency_dat <- read_csv(here::here(""data/data_2019/week03_agencies.csv""))
launch_dat <- read_csv(here::here(""data/data_2019/week03_launches.csv""))

colors_four = rev(RColorBrewer::brewer.pal(5, ""PuBu"")[5:2])

colors_one = RColorBrewer::brewer.pal(5, ""PuBu"")[5:2]

launch_dat %>% 
  count(type, sort = T) %>% 
  top_n(10, n) %>% 
  mutate(type = fct_reorder(type, n, max)) %>% 
  ggplot(aes(x = type, y = n)) +
  geom_point(size = 8, color = ""steelblue4"") + 
  geom_text(aes(label = n), position = position_nudge(y = 25),
            size = 6, family = ""IBMPlexSans-Light"") + 
  scale_y_continuous(breaks = seq(100, 600, 100)) + 
  coord_flip() + 
  labs(title = ""Soyuz-U Takes The Top"",
       subtitle = ""Out of all 366 Flight Options, Soyuz-U (produced by the Soviet Union)\nhas the most flights, with the other top 9 vehicles trailing far behind."",
       y = ""Total Launches"") + 
  theme_light() + 
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = ""dashed""), 
        text = element_text(family = ""IBMPlexSans-Light""),
        axis.title.y = element_blank(),
        axis.title.x = element_text(size = 14, color = ""grey20"",
                                    face = ""italic"", hjust = 1),
        axis.text = element_text(size = 14),
        plot.title = element_text(size = 20, face = ""bold"",
                                  color = ""grey20"", family = ""IBMPlexSans-Bold""),
        plot.subtitle = element_text(size = 12, family = ""IBMPlexSans-Italic"", 
                                     face = ""italic"", color = ""grey30""),
        aspect.ratio = .5)

ggsave(""tidy_2019/tidy_03/plot_01.png"", width = 12, height = 6)

launch_dat %>%
  group_by(state_code, launch_year) %>% 
  summarize(count = n()) %>% 
  ungroup() %>% 
  mutate(state_code = fct_reorder(state_code, count)) %>% 
  complete(state_code, launch_year) %>% 
  ggplot(aes(x = launch_year, y = state_code, fill = count, linetype = """")) + 
  geom_tile(color = ""grey99"") + 
  scale_fill_gradientn(colors = colors_four, na.value = ""#dfe4ec"") + 
  scale_color_manual(values = NA) +
  scale_x_continuous(expand = c(0,0),
                     limits = c(1960, 2020),
                     breaks = c(seq(1960, 2010, 10), 2018)) + 
  coord_equal() + 
  labs(title = ""Agency Launches Since the 1960's"",
       fill = ""Count"") + 
  guides(fill = guide_colourbar(title.position=""top"", title.hjust = 0.5),
         linetype = guide_legend(""No Data"", title.position = ""top"",
                               override.aes=list(fill=""#dfe4ec""))) + 
  theme_minimal() + 
  theme(panel.grid = element_blank(),
        text = element_text(family = ""IBMPlexSans-Light""),
        axis.title = element_blank(),
        axis.text = element_text(size = 14),
        plot.title = element_text(size = 22, face = ""bold"",
                                  color = ""grey20"", family = ""IBMPlexSans-Bold""),
        plot.subtitle = element_text(size = 14, hjust = .5, color = ""firebrick3"",
                                     face = ""italic""),
        legend.key.size = unit(1.3, ""cm""),
        legend.text = element_text(size = 12),
        legend.position = ""bottom"")

ggsave(""tidy_2019/tidy_03/plot_02.png"", width = 12, height = 6)

prop <- function(df, ...) {
  out <- df %>% 
    group_by(...) %>% 
    summarise(n = n()) %>% 
    mutate(prop = n / sum(n))
  
  out
}

launch_dat %>% 
  prop(state_code, category) %>% 
  filter(category == ""O"") %>% 
  ungroup() %>% 
  mutate(state_code = fct_reorder(state_code, prop)) %>% 
  ggplot(aes(x = state_code, y = prop, size = n)) + 
  geom_point(color = ""#045A8D"") + 
  coord_flip() +
  scale_size_continuous(range = c(4, 12)) + 
  scale_y_continuous(labels = scales::percent) + 
  labs(title = ""Ground Control to Major Tom"",
       subtitle = ""Success rates computed among state agencies weighted by total number of launches from 1960-2018"",
       size = ""Total Launches"", y = ""Success Rate"") + 
  guides(size = guide_legend(title.position = ""top"", title.hjust = 0.5)) + 
  theme_minimal() + 
  theme(panel.grid.minor.x = element_blank(),
        text = element_text(family = ""IBMPlexSans-Light""),
        axis.title.y = element_blank(),
        axis.title.x = element_text(hjust = 1, family = ""IBMPlexSans-Light""),
        axis.text = element_text(size = 14),
        plot.title = element_text(size = 20, face = ""bold"",
                                  color = ""grey20"", family = ""IBMPlexSans-Bold""),
        plot.subtitle = element_text(size = 12, family = ""IBMPlexSans-Italic"", 
                                     face = ""italic"", color = ""grey30""),
        legend.key.size = unit(1.3, ""cm""),
        legend.text = element_text(size = 12),
        legend.position = ""bottom"",
        aspect.ratio = .5)

ggsave(""tidy_2019/tidy_03/plot_03.png"", width = 10, height = 6)

launch_dat %>% 
  prop(launch_year, state_code, category) %>% 
  filter(category == ""O"", 
         !state_code %in% c(""KR"", ""UK"", ""KP"")) %>% 
  ungroup() %>% 
  mutate(state_code = fct_reorder(state_code, n, .desc = T)) %>% 
  ggplot(aes(x = launch_year, y = prop)) + 
  geom_point() + 
  geom_line() + 
  scale_x_continuous(breaks = c(seq(1960, 2000, 20), 2018)) + 
  scale_y_continuous(breaks = seq(0, 1, .2),
                     labels = scales::percent_format(),
                     limits = c(0, 1),
                     position = ""right"") +
  facet_wrap(~ state_code, nrow = 4) + 
  labs(title = ""Success Rate of Agencies Over Time"",
       subtitle = """",
       x = ""Year"") + 
  theme_light() + 
  theme(panel.grid.minor.x = element_blank(),
        text = element_text(family = ""IBMPlexSans-Light""),
        axis.title.y = element_blank(),
        axis.title.x = element_text(hjust = 1, family = ""IBMPlexSans-Light""),
        axis.text = element_text(size = 14),
        plot.title = element_text(size = 20, face = ""bold"",
                                  color = ""grey20"", family = ""IBMPlexSans-Bold""),
        plot.subtitle = element_text(size = 12, family = ""IBMPlexSans-Italic"", 
                                     face = ""italic"", color = ""grey30""),
        strip.text = element_text(family = ""IBMPlexSans-Bold""))



","2019"
"484",1635,"https://github.com/robertopreste/MyTidyTuesday","robertopreste","MyTidyTuesday","2019/Week_1/Week_1.Rmd","---
title: 'TidyTuesday 2019 - Week 1 - #rstats and #TidyTuesday Tweets from rtweet'
author: ""Roberto Preste""
date: ""2019-01-02""
output: html_document
---

This is my work for week 1 (2019) of the [#TidyTuesday](https://thomasmock.netlify.com/post/tidytuesday-a-weekly-social-data-project-in-r/) project.  

This week's dataset contains tweets with [#rstats](https://twitter.com/hashtag/rstats) or [#TidyTuesday](https://twitter.com/hashtag/TidyTuesday) hashtags, collected using the [rtweet](https://rtweet.info/) package. Details can be found in the [original article](https://stackoverflow.blog/2017/10/10/impressive-growth-r/) published on Stack Overflow Blog.  

All code and data can be found in my dedicated GitHub repository [MyTidyTuesday](https://github.com/robertopreste/MyTidyTuesday).  

___

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width = 120)
```

## Overview  

For the first TidyTuesday of 2019, some sort of meta-datasets: tweets with [#rstats](https://twitter.com/hashtag/rstats) or [#TidyTuesday](https://twitter.com/hashtag/TidyTuesday) hashtags! These tweets were collected using the [rtweet](https://rtweet.info/) package, and some background can be found in the [original article](https://stackoverflow.blog/2017/10/10/impressive-growth-r/) on Stack Overflow Blog.  

I chose to use the #TidyTuesday dataset, which can be downloaded from the official [GitHub repo](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-01) of TidyTuesday.  

```{r, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(skimr)
library(wordcloud)
library(RColorBrewer)
library(caret)
```

```{r, eval=FALSE}
download.file(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-01/tidytuesday_tweets.rds"", ""data/tidytuesday_tweets.rds"")
```

```{r}
df <- read_rds(""data/tidytuesday_tweets.rds"")
```

Let's have an overview of these data using `skim`.  

```{r, message=FALSE, warning=FALSE}
skim(df)
```

Seems like quite a huge dataset, with lots of interesting variables.  

I chose something simple to celebrate a new year of TidyTuesday challenges, and to congratulate with all the people involved in this project, so I'll just use the `screen_name` feature, which contains the Twitter handler of each contributor.  

___  

## Word clouds  

As just said, for this week's dataset I decided to focus on people: let's create a word cloud with the most active people of TidyTuesday!  

```{r}
handlers <- df %>% 
    group_by(screen_name) %>% 
    summarise(n = n()) 
handlers
```

```{r, dpi=200}
set.seed(420)
wordcloud(words = handlers$screen_name, freq = handlers$n, 
          scale = c(2, 0.5))
```

### Most active contributors  

This doesn't look so good: the cloud is overcrowded, with [thomas_mock](https://twitter.com/thomas_mock) and [R4DScommunity](https://twitter.com/R4DScommunity) dominating it, since they are those actually sharing and spreading each week's dataset.  
Let's try to remove these handlers, as well as those with less than a few occurrences. The plot is also quite boring, with all this black all over the place, so we'll add some colours too.  

```{r, dpi=200}
top_handlers <- handlers %>% 
    filter(!screen_name %in% c(""thomas_mock"", ""R4DScommunity""),
           n >= 5)

set.seed(420)
wordcloud(words = top_handlers$screen_name, freq = top_handlers$n, 
          colors = brewer.pal(12, ""Paired""), random.order = F, 
          scale = c(2, 0.4))
```

### Less active contributors  

We should give some props also to the people who made few contributions to the TidyTuesday project, so let's wordcloud them too.  

```{r, dpi=200}
bott_handlers <- handlers %>% 
    filter(n < 5)

set.seed(420)
wordcloud(words = bott_handlers$screen_name, freq = bott_handlers$n, 
          colors = brewer.pal(12, ""Paired""), random.order = F, 
          scale = c(1, 0.1))
```

This cloud also doesn't look very nice, so we may have to rescale the number of contributions to a [0, 1] range, using the `caret` package.  

```{r, dpi=200}
preprocess_params <- preProcess(bott_handlers, method = c(""range""))
scaled_handlers <- predict(preprocess_params, bott_handlers)

set.seed(420)
wordcloud(words = scaled_handlers$screen_name, freq = scaled_handlers$n, 
          colors = brewer.pal(12, ""Paired""), random.order = F, 
          scale = c(1, 0.1))
```

## Conclusion  

I wanted to give some credits to all the people involved in [#TidyTuesday](https://twitter.com/hashtag/TidyTuesday), and I thought the best way was to plot their names (actually, Twitter usernames!) together with their fellow TidyTuesday-ers!  
Regardless of the number of TidyTuesday posts you made in 2018, congratulations for sharing your work and knowledge, and if you still aren't into it, you really should spend some time engaging in this community project!  

___  

```{r}
sessionInfo()
```



","2019"
"485",1642,"https://github.com/andrewsris/Tidy_Tuesday/blob/master/2019_01_29/doc/lab_notebook/EDA_2019_01_29.Rmd","andrewsris","Tidy_Tuesday","2019_01_29/doc/lab_notebook/EDA_2019_01_29.Rmd","---
title: ""EDA_2019_01_29""
author: ""Andrew Srisuwananukorn""
date: ""2/2/2019""
output: html_document
---

#Introduction
- exploration of cheese data provided by Thomas Mock of Tidy Tuesday
https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-29

- Also inspired by clustering methods DataCamp lesson by Dmitry 

#Import libraries
```{r}
library(tidyverse)
library(ggplot2)
library(purrr)
library(cluster)
library(dendextend)

```


#Import Data
```{r}
raw_cheese_df <- read_csv(""/Users/Andrewsris/Box/Tidy_Tuesday/2019_01_29/data/1_original/clean_cheese.csv"") 
cheese_df <- raw_cheese_df %>% 
  gather(key = Cheese, value = value, 2:ncol(raw_cheese_df)) %>% 
  spread(key = names(raw_cheese_df)[1], value = ""value"") %>% 
  filter(!str_detect(Cheese, ""Total""))
```

#Scale data
This is unneceesary for this specific data frame, as the scale is the same for each feature. However I am including this section for future datasets, when i use similar methods.

```{r}
scaled_cheese_df <- cheese_df %>% column_to_rownames(""Cheese"") %>% scale() 
scaled_dist_cheese <- scaled_cheese_df %>% dist()
```

#Hierarchical clustering
Distance = ""euclidian""
hierarchical clustering method = ""complete""
```{r}
hc_cheese <- hclust(scaled_dist_cheese, method = ""complete"")

#By visual inspection, optimal k=2
hc_cheese %>% as.dendrogram() %>% set(""branches_k_color"", h = 10) %>% plot()
par(mar = c(5,4,1,6)) #Reset margins: bottom, left, top, right
hc_cheese %>% as.dendrogram() %>% 
  set(""branches_k_color"", k = 2) %>% 
  set(""labels_cex"", 0.75) %>% 
  plot(horiz = TRUE,
       main = ""Hierarchical Clustering by Cheese Consumption"", 
       sub = ""k=2 by visual inspection"") %>% 
  abline(v = 15, lty = 2)

#Assign cluster groups
clusters_hc <- cutree(hc_cheese, k = 2)

```

#K-means analysis
```{r}
#We will use the elbow plot to determine optimal k
# Use map_dbl to run many models with varying value of k (centers)
tot_withinss <- map_dbl(1:10,  function(k){
  model <- kmeans(x = scaled_dist_cheese, centers = k)
  model$tot.withinss
})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:10 ,
  tot_withinss = tot_withinss
)
ggplot(elbow_df, aes(x = k , y = tot_withinss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:10) + 
  labs(title = ""Elbow Plot for K-means clustering of Cheese Consumption"",
       subtitle = ""Optimal k=2 by visual inspection of elbow point"",
       y = ""Total within squared sums"",
       x = ""k"") +
  geom_point(data = elbow_df %>% filter(k == 2), aes(x = k, y = tot_withinss, color = ""red"", size = 3), show.legend = FALSE)

#Optimal k = 2
km_cheese <- kmeans(scaled_dist_cheese, centers = 2)
clusters_km <- km_cheese$cluster


```

#PAM and silhouette
- pam is from the cluster pacakage
```{r}
#using the silhouette technique to determine optimal k

# Use map_dbl to run many models with varying value of k
sil_width <- map_dbl(2:10,  function(k){
  model <- pam(x = scaled_dist_cheese, k = k)
  model$silinfo$avg.width
})

# Generate a data frame containing both k and sil_width
sil_df <- data.frame(
  k = 2:10,
  sil_width = sil_width
)

# Plot the relationship between k and sil_width
ggplot(sil_df, aes(x = k, y = sil_width)) +
  geom_line() +
  scale_x_continuous(breaks = 2:10) +   
  labs(title = ""Silhouette Plot for K-means clustering of Cheese Consumption"",
       subtitle = ""Optimal k=2 by maximal silhouette width"",
       y = ""Average silhouette width"",
       x = ""k"") +
  geom_point(data = sil_df %>% filter(k == 2), aes(x = k, y = sil_width, color = ""red"", size = 3), show.legend = FALSE)

#Optimal k = 2
pam_cheese <- pam(scaled_dist_cheese, k = 2)
plot(silhouette(pam_cheese))

clusters_pam <- pam_cheese$clustering

```


#Merge df
```{r}
total_cheese <- mutate(cheese_df, 
               cluster_hc = clusters_hc,
               cluster_km = clusters_km,
               cluster_pam = clusters_pam) %>% gather(-c(""Cheese"",""cluster_km"", ""cluster_hc"", ""cluster_pam""), key = ""year"", value = ""eaten"")

total_cheese %>% ggplot(aes(x = year, y = eaten, color = factor(cluster_km))) + 
  geom_line(aes(group = Cheese),show.legend = FALSE) + 
  geom_smooth(aes(group = cluster_km), na.rm=TRUE, show.legend = FALSE) +
  geom_text(data = total_cheese %>% filter(year == 2013), 
            aes(label = Cheese), size = 2.5, nudge_y = 0.5, show.legend = FALSE) +
  scale_x_discrete(breaks = seq(1970,2015, 5)) +
  theme(axis.text.x = element_text(angle = 45)) +
  labs(title = ""Average cheese consumption from USDA"",
       subtitle = ""Optimal k=2 by Elbow method of K-means cluster analysis"",
       y = ""Average cheese consumption (lbs per person)"",
       x = ""Year""
       )
```

","2019"
"486",1644,"https://github.com/regiso/tidytuesday/blob/master/DairyJanuary2019tidytuesday.Rmd","regiso","tidytuesday","DairyJanuary2019tidytuesday.Rmd","---
title: ""US Dairy Trends 1980-2014""
author: ""Regis O'Connor""
date: ""January 30, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(RCurl)    # to load csv from git hub
library(ggthemes) # to get Tufte design
library(cowplot)  # to arrange 4 plots in a 2 x 2 arrangement
library(ggplot2)


x <- getURL(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milkcow_facts.csv"")
y <- read.csv(text=x)
```


```{r}
df1 <- y %>%
  filter(year == 1980 | year == 2014) %>%
  select(year, avg_milk_cow_number, avg_price_milk, milk_production_lbs, milk_per_cow) %>%
  gather(measure, metric, -year) %>%
  mutate(year = gsub("" "", """", paste(""AD"","""", as.character(year)))) %>%
  spread(year, metric) %>%
  mutate(change = (AD2014-AD1980)/AD1980) 

print(df1)

```

```{r}
g <- ggplot(y)
p1 <- g +  geom_point(aes(y=avg_milk_cow_number, x=year)) +
  geom_line(aes(y=avg_milk_cow_number, x=year)) +
  theme_tufte() +
  scale_x_continuous() + 
  scale_y_continuous(limits=c(0, 11059000)) +
  ylab(""Total # of Milk Cows"") + xlab(""Year"") +
  labs(title    = ""The number of milk cows dropped 14%"",
       subtitle = ""Total Milk Cows in the US, 1980-2014"")

# Annual pounds per cow produced
p2 <- g +  geom_point(aes(y=milk_per_cow, x=year)) +
  geom_line(aes(y=milk_per_cow, x=year)) +
  theme_tufte() +
  scale_x_continuous() + 
  scale_y_continuous(limits=c(0, 25000)) +
  ylab(""Average Milk in Pounds Per Cow"") + xlab(""Year"")+ 
  labs(title    = ""Milk cow productivity grew more than 87%"",
       subtitle = ""Pounds of Milk Produced / Cow Annually, 1980-2014"")

# Annual milk production
p3 <- g +  geom_point(aes(y=milk_production_lbs, x=year)) +
  geom_line(aes(y=milk_production_lbs, x=year)) +
  theme_tufte() +
  scale_x_continuous() + xlab(""Year"")  + 
  scale_y_continuous(limits=c(0, 2.0e+11)) +
    ylab(""Annual Total Milk Production"") +
  labs(title    = ""Overall milk production grew more than 60%"",
       subtitle = ""Total Pounds of Milk Produced, 1980-2014"",
       caption  = ""Source: USDA, github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-29"") + 
  theme(plot.caption=element_text(hjust=.1))

# How has the price of milk changed
p4 <- g +  geom_point(aes(year,avg_price_milk)) +
  geom_line(aes(year,avg_price_milk)) +
  theme_tufte() +
  scale_x_continuous() + xlab(""Year"")  + 
  scale_y_continuous(limits=c(0, .25)) +
  ylab(""Average Price for Milk"") +
  labs(title    = ""Meanwhile, the price of milk grew nearly 
       85%"",
       subtitle = ""$ / pound of Milk, 1980-2014"",
       caption = ""JANUARY 2019 | @REGISOCONNOR"") +
  theme(plot.caption=element_text(hjust=1))

 plot_grid(p1, p2, p3, p4)
```
","2019"
"487",1645,"https://github.com/regiso/tidytuesday/blob/master/tt2019w3_space_launches.R","regiso","tidytuesday","tt2019w3_space_launches.R","# Tidy Tuesday 2019 w3
# Space Launches

library(tidyverse)
library(cowplot)
library(magick)   # for image in final chart
library(RColorBrewer) # to get other colors


# First, load tidytuesday data and an image for the final chart
urlfilelaunch   <- 'https://raw.githubusercontent.com/TheEconomist/graphic-detail-data/master/data/2018-10-20_space-launches/launches.csv'
urlfileagency   <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/agencies.csv'
challengercrew  <- ""http://en.es-static.us/upl/2013/01/space_shuttle_challenger_crew.jpeg""


df      <- read_csv(url(urlfilelaunch))
dfa     <- read_csv(url(urlfileagency))

str(df)
summary(df)
table(df$tag)

# to start the cleaning, lets change the format of some of the character variables to factors

dfl1 <- df %>%
  mutate(type = as.factor(type),
         agency = as.factor(agency),
         state_code = as.factor(state_code),
         category = as.factor(category),
         agency_type = as.factor(agency_type))

# Now, let's filter information about the Space Shuttle flights and add a name for each shuttle


dfl2 <- dfl1 %>%
  filter(agency == ""US"", type == ""Space Shuttle"") %>%
  arrange(launch_date)

dfl2$name <- NA

for (i in 1:nrow(dfl2))
if (grepl(""OV-099"", dfl2[i, ""mission""]) == TRUE) {
  dfl2[i, ""name""] <- ""Challenger""
} else {
  if (grepl(""OV-102"", dfl2[i, ""mission""]) == TRUE) {
    dfl2[i, ""name""] <- ""Columbia""
  } else {
    if (grepl(""OV-103"", dfl2[i, ""mission""]) == TRUE) {
      dfl2[i, ""name""] <- ""Discovery"" 
      } else {
          if (grepl(""OV-104"", dfl2[i, ""mission""]) == TRUE) {
            dfl2[i, ""name""] <- ""Atlantis"" 
          } else {
            dfl2[i, ""name""] <-  ""Endeavor""
            }
          }
        }
      }


# convert name to a factor

dfl3 <- dfl2 %>%
  mutate(name = as.factor(name))

# Now, lets make the violin chart and add an image of the crew of the Challenger

g <- ggplot(dfl3, aes(name, launch_year, fill=name))
p <- g + geom_violin(scale = ""area"") + 
  scale_fill_brewer(palette = ""Blues"") + theme_minimal() +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = .4, fill=""black"") +
  labs(title =""Space Shuttle Launches"", subtitle= ""1981-2011"",
       caption = ""Source: raw.githubusercontent.com/TheEconomist/graphic-detail-data/master/data/2018-10-20_space-launches"",
       SIZE=8) +
  theme(plot.caption = element_text(hjust=.1)) +
  theme(legend.position = ""none"") +
  theme(axis.title.x=element_blank(),
        axis.title.y=element_blank())+
  scale_color_brewer(palette=""Blues"")

p2 <-  ggdraw() + draw_image(challengercrew, scale = 0.9) +
  draw_label(""In Memory of the Challenger Crew"", x=.5, y=.9, hjust=0.5, vjust=0.5)
p3 <- add_sub(p2, ""Perished January 28, 1986"", x=.5, y=3, hjust=0.5, vjust = 0.5)


  
    

plot_grid(p, p3)
print(p)

","2019"
"488",1647,"https://github.com/brfry/tidy_tuesday/blob/master/2019/tidy_tuesday_01152019_space.R","brfry","tidy_tuesday","2019/tidy_tuesday_01152019_space.R","# libraries
library(tidyverse)
library(RColorBrewer)

#===============================================================================

# read in data
agencies_df <- read_csv(""data/agencies.csv"")
launches_df <- read_csv(""data/launches.csv"")

#===============================================================================

# set colors and themes. idk which theme i like so there are two for now.
colors_four = RColorBrewer::brewer.pal(5, ""Dark2"")[5:2]

colors_space <- c(""#542788"", 
                  ""#35978f"",
                  ""#7f3b08"",
                  ""#bf812d"",
                  ""#9ebcda""
                   )
        
colors_space2 <- c(""#542788"", 
                   ""#35978f"",
                   ""#00441b"",
                   ""#006d2c"",
                   ""#b30000"",
                   ""#9ebcda""
)

# theme with custom colors
theme_space <- list(theme_bw(),  scale_color_manual(values = colors_space),
                    scale_fill_manual(values = colors_space))

theme_space2 <- list(theme_bw(),  scale_color_manual(values = colors_space2),
                     scale_fill_manual(values = colors_space2))
#===============================================================================

# explore launches
launches_df %>%
        count(type, sort = TRUE) %>%
        top_n(10, n) %>%
      #  mutae(launch_date = lubridate::ymd(launch_date))) %>%
      #  group_by(type) %>%
      #  summarise()
        ggplot(aes(x = type, y = n)) +
        geom_point()

#===============================================================================

# how have launches changed by agency type and number over time:
launches_df %>%
        group_by(launch_year, agency_type, type) %>%
        summarise(count = n()) %>%
        rename(Agency = agency_type) %>%
        ggplot(aes(x = launch_year, y = count, fill = Agency)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""The Changing Space Industry"", y = ""Number of Launches"",
             x = ""Year"") +
        theme_space

#===============================================================================

# filtering for state only:
launches_df %>%
        filter(agency_type == ""state"") %>%
        group_by(launch_year, state_code) %>%
        summarise(count = n()) %>%
        rename(State = state_code) %>%
        mutate(Nations = ifelse(State == ""US"", ""United States"",
                               ifelse(State == ""CN"", ""China"",
                                      ifelse(State == ""SU"", ""Soviet Union"",
                                             ifelse(State == ""RU"", ""Russia"",
                                                    ifelse(State == ""IN"", ""India"",
                                             ""Other"")))))) %>%
        mutate(Nations = factor(Nations, levels = c(""United States"", ""China"", 
                                                  ""Soviet Union"", ""Russia"", 
                                                  ""India"", ""Other""))) %>%
        ggplot(aes(x = launch_year, y = count, fill = Nations)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""Nation State Launches"", y = ""Number of Launches"",
             x = ""Year"") +
        theme_space2 

#===============================================================================

# just compare private vs startup
launches_df %>%
        filter(agency_type != ""state"") %>%
        group_by(launch_year, agency_type, state_code) %>%
        summarise(count = n()) %>%
        mutate(state_code = ifelse(state_code == ""US"", ""United States"",
                                   ifelse(state_code == ""RU"", ""Russia"",
                                          ifelse(state_code == ""J"", ""Japan"",
                                                 ifelse(state_code == ""F"", ""France"",
                                                        "" Cayman Islands""))))) %>%
        ggplot(aes(x = launch_year, y = count, fill = agency_type)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""Private and Startup Launches"", y = ""Number of Launches"",
             x = ""Year"") +
        facet_grid(state_code~.) +
        theme_space2 #+ scale_fill_viridis_d(name = "" "")

#===============================================================================

# filtering for private and startup only and comparing all companies
launches_df %>%
        filter(agency_type != ""state"") %>%
        group_by(launch_year, agency, state_code) %>%
        summarise(count = n()) %>%
        mutate(state_code = ifelse(state_code == ""US"", ""United States"",
                                   ifelse(state_code == ""RU"", ""Russia"",
                                          ifelse(state_code == ""J"", ""Japan"",
                                                 ifelse(state_code == ""F"", ""France"",
                                                        "" Cayman Islands""))))) %>%
        ggplot(aes(x = launch_year, y = count, fill = agency)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""Private and Startup Launches"", y = ""Number of Launches"",
             x = ""Year"") +
        facet_grid(state_code~.) +
        theme_space2 + scale_fill_viridis_d(name = ""Company Code"")


#===============================================================================
","2019"
"489",1650,"https://github.com/mpodell/tidytuesday/tree/master/2019-01-15","mpodell","tidytuesday","2019-01-15/space_race.R","## 2019-01-15 #TidyTuesday Project 
## Author: Michael O'Dell
## File create date: 2019-01-15
## Copyright 2019 Michael O'Dell
## License: MIT


# SET ENVIRONMENT ---------------------------------------------------------

library(tidyverse)



# LOAD DATA ---------------------------------------------------------------

agencies <- read_csv(""../../../tidytuesday/data/2019/2019-01-15/agencies.csv"")
launches <- read_csv(""../../../tidytuesday/data/2019/2019-01-15/launches.csv"")


# EXPLORE DATA ------------------------------------------------------------

dim(launches)
str(launches)
# check for missing values:
apply(apply(launches, 2, is.na), 2, sum)
# lots of missing agencies
# lots of missing variants--likely many vehicles do not have variants
# a few missing launch dates (but no missing years)
# some missing missions
apply(launches, 2, function(x) {length(unique(x))})
# tag has a unique entry for each row.
# launch and Julian dates are almost unique (several launches on some days)
# similarly missions map almost 1:1 with launches.
# the launch history spans 62 years
# there are 366 unique launch vehicles with 73 variants
# agency_type: private, startup, and state
# type: generic organization (O)
#       launch agency (LA), 
#       launch vehicle manufacturer (LV), 
#       satellite manufacturer (PL), 
#       rocket experimenter (RE), 
#       engine/motor manufacturer (E) 
#       launch site (LS)

apply(launches %>% select(-tag,
                          -JD,
                          -launch_date,
                          -mission), 2, table)

# all the missing agencies are state code SU (USSR)
launches %>% 
  filter(
    is.na(agency)
  ) %>% 
  select(
    state_code
  ) %>% table


dim(agencies)
str(agencies)
# check for missing values:
apply(apply(agencies, 2, is.na), 2, sum)
# nothing missing.
apply(agencies, 2, function(x) {length(unique(x))})
# INVESTIGATE: launches indicates 41 agencies. However, agencies list 74
# INVESTIGATE: agencies indicate 43 launches while launches indicates 5726
# agencies and launches agree on the number of state codes (17)
# USEFUL: agencies provide full names for agencies (launches$agency <> agencies$ucode)
# lots of missing short_english_names and english_names
# agency_type includes: private, startup, and state
# INVESTIGATE: do agencies and launches agency_types match?

apply(agencies, 2, table)
# lat and lon are blank so not very useful
# location looks to be the agency hq location-not the launch location.

# Why the discrepancy between files in agencies?
setdiff(launches$agency, agencies$ucode)  # US, BR, CH & others missing from agencies$ucode
agencies %>%
  filter(
    ucode %in% intersect(launches$agency, agencies$ucode)
  ) %>%
  select(
    ucode,
    name
  ) %>% print(n = Inf)
# commercial launch orgs are common to both files

agencies %>%
  select(
    ucode,
    name
  ) %>% print(n = Inf)

launches %>%
  select(
    agency,
    agency_type
  ) %>% unique %>% print(n = Inf)

## so launches seems to consolidate all agencies for a state under a single country code.
launches %>%
  filter(
    agency_type == ""state""
  ) %>%
  select(
    agency,
    state_code
  ) %>% table
# state code SU has no ocurrances of an agency as noted above.


# Why the discrepancy between files in number of launches?
sum(agencies$count) - nrow(launches) # agencies is missing 20 launches
with(launches, table(category))


# Do agencies and launches agency_type match?
table(launches$agency_type)
agencies %>% 
  group_by(
    agency_type
  ) %>%
  summarize(
    count = sum(count)
  )
# nope. agencies is missing 20 launches over all categories.
# agencies does not seem to add value. Just use launces.

launches %>% 
  filter(
    state_code == ""I-ESA""
  ) %>% select(type, mission, category, launch_year)


# POSE QUESTION AND PLOT FOR ANSWER ---------------------------------------

## Do different agency types have different learning curves?
## Hypothesis:  state agencies will be cautious and lead, 
##              private firms will build on state knowledge and contracts but will be
##                cautious given that they rely on state support
##              startups will be quick, move up the learning curve quickly but cut corners

# Over all states
launches %>%
  group_by(
    state_code,
    agency_type
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    # persistence = n(),
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>%
  ggplot(
    aes(experience, launch_success, color = agency_type)
  ) +
  geom_smooth(se = FALSE) +
  labs(title = ""Learning Curves by Agency Type\n(All Countries)"", 
       x = ""Experience (years)"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)


# Just states with state, private, and start-ups
varied <- launches %>%
  select(
    state_code, 
    agency_type
  ) %>%
  unique %>%
  group_by(
    state_code
  ) %>%
  summarize(
    eco = n()
  ) 


launches %>%
  filter(
    state_code %in% (varied %>% filter(eco > 2) %>% select(state_code))
  ) %>%
  group_by(
    state_code,
    agency_type
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    # persistence = n(),
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>%
  ggplot(
    aes(experience, launch_success, color = agency_type)
  ) +
  geom_smooth() +
  labs(title = paste0(""Learning Curves by Agency Type\n("", 
                      (varied %>% filter(eco > 2) %>% select(state_code)), "" only)""), 
       x = ""Experience (years)"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)



p <- launches %>%
  filter(
    state_code %in% (varied %>% filter(eco > 2) %>% select(state_code))
  ) %>%
  group_by(
    state_code,
    agency_type
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    # persistence = n(),
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>%
  ggplot(
    aes(launch_year, launch_success, color = agency_type)
  ) +
  geom_smooth() +
  labs(title = paste0(""Learning Curves by Agency Type\n("", 
                      (varied %>% filter(eco > 2) %>% select(state_code)), "" only)""), 
       x = ""Year"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)


# learning curve by countries with state only; state + private; & state, private, + startup
launches %>%
  left_join(., varied, by = ""state_code"") %>%
  group_by(
    state_code
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>% 
  ggplot(
    aes(experience, launch_success, color = factor(eco))
  ) +
  geom_smooth() +
  labs(title = ""Learning Curves by Agency Type Count\n(All Countries)"", 
       x = ""Experience (years)"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)

# by year
launches %>%
  left_join(., varied, by = ""state_code"") %>%
  group_by(
    state_code
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>% 
  ggplot(
    aes(launch_year, launch_success, color = factor(eco))
  ) +
  geom_smooth() +
  labs(title = ""Learning Curves by Agency Type Count\n(All Countries)"", 
       x = ""Year"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)

file_name <- ""tidytuesday_2019-01-15_mpo.jpeg""

jpeg(file = file_name, 
     width = 9, height = 6, units = ""in"", pointsize = 4, res = 300)

p

dev.off()


","2019"
"490",1651,"https://github.com/SamanthaToet/rstudioconf2019_twitter","SamanthaToet","rstudioconf2019_twitter","rstudioconf2019_twitter.R","
# Load packages
library(rtweet) # interface with Twitter API
library(tidytext) # sentiment analysis
library(tidyverse) # ggplot
library(wordcloud)


# Connect to Twitter
# *~* API witchcraft *~*

# Get tweets 
conf_tweets <- search_tweets(
    ""#rstudioconf"", n = 10000, include_rts = FALSE) #rstudioconf

conf19_tweets <- search_tweets(
    ""#rstudioconf2019"", n = 10000, include_rts = FALSE) #rstudiconf2019

conf <- rbind(conf_tweets, conf19_tweets) %>%
    select(created_at, text) %>%
    mutate(id = c(1:73), text = tolower(text))

# Tidy
conf_tidy <- conf %>%
    unnest_tokens(word, text)

data(stop_words)
stop_words <- data.frame(word = c(""https"", ""http"", ""amp"", ""t.co"", ""rstudioconf"", 
                                  ""rstudio"", ""rstudioconf2019"", ""conf"", ""2019""), 
                         lexicon = ""custom"") %>%
    bind_rows(stop_words)

conf_tidy <- conf_tidy %>%
    anti_join(stop_words) #small n

# Explore
conf_tidy %>%
    count(word, sort = TRUE)

conf_tidy %>%
    count(word, sort = TRUE) %>%
    filter(n > 2) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip() #rstats, goals, and preparation 

# NRC sentiments
# joy
nrc_joy <- get_sentiments(""nrc"") %>%
    filter(sentiment == ""joy"")

conf_tidy %>%
    inner_join(nrc_joy) %>%
    count(word, sort = TRUE) # fun, improve, excited 

# anticipation
nrc_anticipation <- get_sentiments(""nrc"") %>%
    filter(sentiment == ""anticipation"")

conf_tidy %>%
    inner_join(nrc_anticipation) %>%
    count(word, sort = TRUE) # preparation, improve, wait

#all nrc
nrc <- get_sentiments(""nrc"")

conf_tidy %>%
    inner_join(nrc) %>%
    count(word, sentiment, sort = TRUE) %>%
    filter(n > 1) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col(aes(fill = sentiment)) +
    xlab(NULL) +
    coord_flip() +
    ggtitle(""NRC sentiment counts"")# anticipation, joy, and positivity

# Bing sentiments
bing_sentiment <- conf_tidy %>%
    inner_join(get_sentiments(""bing"")) %>%
    count(id, created_at, sentiment) %>%
    spread(sentiment, n, fill = 0) %>%
    mutate(sentiment = positive - negative)

ggplot(bing_sentiment, aes(created_at, sentiment)) +
    geom_line() +
    labs(title = ""Bing sentiment scores over time"", 
         x = ""Date"", y = ""Sentiment"") # more neg spikes as we get closer to the date  

bing_word_counts <- conf_tidy %>%
    inner_join(get_sentiments(""bing"")) %>%
    count(word, sentiment, sort = TRUE) %>%
    ungroup()

bing_word_counts %>%
    group_by(sentiment) %>%
    top_n(10) %>%
    ungroup() %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~sentiment, scales = ""free_y"") +
    labs(x = NULL,
         y = ""Bing contribution to sentiment"") +
    coord_flip()

# Wordcloud bc why not?
conf_tidy %>%
    anti_join(stop_words) %>%
    count(word) %>%
    with(wordcloud(word, n, max.words = 100, ordered.colors = TRUE))

# next steps: n-grams, shiny app
","2019"
"491",1663,"https://github.com/katiesaund/tidy_tuesday/tree/master/2018-12-03_week_36","katiesaund","tidy_tuesday","2018-12-03_week_36/2018-12-03_medium_data_science_article_metadata.Rmd","---
title: ''
author: ""Katie Saund""
date: ""12/3/2018""
output:
  pdf_document: default
  html_document: default
  latex_engine: xelatex 
---

# Tiday Tuesday Week 36  
## Medium data science article metadata
### Goal is to work with the tidytext package.  

```{r, message = FALSE}
# LIBRARIES -------------------------------------------------------------------#
library(tidyverse)
library(tidytext)
library(lubridate)
```

```{r}
# IMPORT DATA -----------------------------------------------------------------#
raw_metadata <- read_csv(file =""medium_datasci.csv"", quote='""')
head(raw_metadata)
```
  
I noticed some duplicate names, articles without names, subtitles as duplicates of titles, etc... Which means it is time to clean.  

```{r}
# CLEAN -----------------------------------------------------------------------#
metadata <- raw_metadata %>% 
  distinct(title, author, .keep_all = TRUE) %>%
  drop_na(title) 
head(metadata)

dim(raw_metadata)
dim(metadata)
```
  
The data isn't perfect, but looking much better than before.  

Let's combine the three date columns into one.   
```{r}
metadata <- metadata %>%
  mutate(date = ymd(paste(year, month, day, sep= '-')), 
         weekday = wday(as.Date(date,'%Y-%m-%d'), label = TRUE, abbr = FALSE))
```
  
What is the trend in the number of data science articles published over the year? 
```{r}
# ANALYSIS --------------------------------------------------------------------#
metadata %>%
  ggplot(mapping = aes(x = date)) + 
  geom_line(stat = ""bin"", bins = 25) + 
  theme_bw() + 
  ggtitle(label = ""Medium's data science article publication output doubled in 1 year"")
```
  
Overall, the number of articles per day has doubled in a year.  
  
Is there a day of the week on which people tend to publish? 
```{r}
metadata %>%
  add_count(as.factor(weekday)) %>% 
  distinct(weekday, n) %>%
  ggplot(mapping = aes(x = weekday, y = n, fill = as.factor(weekday))) + 
  theme_bw() + 
  geom_bar(stat = ""identity"") +
  ggtitle(label = ""Medium's data science articles snooze on weekends"")
```
  
Monday's take a slight lead, with the weekends showing a huge dip in publications. 

  
Let's get a feel for the distribution of claps per article.  
```{r}
no_clap_percentage <- round(100 * sum(metadata$claps == 0)/nrow(metadata), 0)

metadata %>% 
  filter(claps < 250) %>% 
    ggplot(mapping = aes(x = claps)) + 
    theme_bw() + 
    geom_histogram(bins = 50) +
    ggtitle(label = paste(no_clap_percentage, ""% of data science articles go without applause"", sep = """"))
```
  

```{r}
metadata %>%
    ggplot(mapping = aes(x = reading_time, y = claps)) + 
    geom_point(na.rm = TRUE) + 
    geom_vline(xintercept = 7, 
               linetype = ""dashed"", 
               color = ""red"",
               size = 1) + 
    theme_bw() + 
    geom_jitter() + 
    ggtitle(label = ""Sweet spot for claps is a 7 minute read"")

```
  
I'm eye balling the read time for the above plot.  


I hypothesize that more prolific authors are (1) better writers and (2) write interesting content and therefore have more applause. Is this supported by the data?  
```{r}
metadata %>%
  add_count(as.factor(author)) %>%
    ggplot(mapping = aes(y = claps, x = n)) + 
    geom_point() + 
    theme_bw() +
    scale_colour_gradient(low = ""white"", high = ""red"") + 
    ggtitle(label = ""Writing more articles on Medium does not necessarily increase engagement"")
```
  
Nope! You don't have to write a lot of articles in the field to have a viral article. Perhaps highly prolific authors may be diluting their impact or prioritizing quantity over quality. 

Let's investigate what's different about the topics of the most popular and least popular articles. 
```{r}
metadata %>%
  filter(claps > 10000) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  filter(n > 3) %>%
  ggplot(mapping = aes(x = word, y = n/sum(n))) +
  theme_bw() + 
  geom_bar(stat = ""identity"") + 
  ylab(""Frequency"") + 
  ggtitle(label = ""Most common words in popular articles"")


metadata %>%
  filter(claps < 10) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1500) %>%
  ggplot(mapping = aes(x = word, y = n/sum(n))) +
  theme_bw() + 
  geom_bar(stat = ""identity"") + 
  ylab(""Frequency"") + 
  ggtitle(label = paste(""Most common words in unpopular articles""))

```
  
Wow, almost no difference. Maybe how-to articles (""guide"") have broad audiences because they are for amateurs?  
Perhaps some of the difference in popularity is not because unpopular articles exclude buzz words, but that they include words that drive away views.  


Per suggestion on twitter using forcats package (part of tidyverse) to order the bars in decreasing order to improve interpretability of the plot. 
```{r}
metadata %>%
  filter(claps > 10000) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  filter(n > 3) %>%
  ggplot(mapping = aes(x = fct_reorder(word, n, .desc = TRUE), y = n/sum(n))) +
  theme_bw() + 
  geom_bar(stat = ""identity"") + 
  ylab(""Frequency"") + 
  xlab(""word"") + 
  ggtitle(label = ""Most common words in popular articles"")


metadata %>%
  filter(claps < 10) %>%
  unnest_tokens(word, title) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  filter(n > 1500) %>%
  ggplot(mapping = aes(x = fct_reorder(word, n, .desc = TRUE), y = n/sum(n))) +
  theme_bw() + 
  geom_bar(stat = ""identity"") + 
  ylab(""Frequency"") + 
  xlab(""word"") + 
  ggtitle(label = ""Most common words in unpopular articles"")
```



# Learning moments
* TidyTuesday is great fun! I want to continue using this challenge to improve my speed & confidence using the tidyverse grammar and tools. 
* I used lubridate, distinct(), and add_cout() for the first time today. 


","2018"
"492",1679,"https://github.com/stevejburr/tidytuesday/tree/master/11092018","stevejburr","tidytuesday","11092018/code.r","library(tidyverse)

#read data
data <- read.csv(""cats_vs_dogs.csv"")

#get map data for US states
map <- map_data(""state"")

data %>% mutate(region=tolower(state),
                `Dogs` = dog_population/n_households,
                `Cats` = cat_population/n_households) %>%
  select(region,`Dogs`,`Cats`) %>%
  gather(key=""key"",value=`Avg per household`,-region) %>%
  ggplot(aes(map_id=region)) +
  facet_grid(key ~ ., switch=""y"") +
  geom_map(map=map,aes(fill=`Avg per household`),colour=""white"") +
  expand_limits(x = map$long, y = map$lat) +
  coord_map(""albers"", lat0 = 39, lat1 = 45) +
  scale_fill_distiller(""Average pets per household"",
                       type=""seq"",palette=""Purples"",direction=1,
                       breaks=c(0.25,0.45,0.65,0.85)) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        text = element_text(color=""grey50""),
        panel.grid = element_blank(),
        strip.text.y= element_text(colour=""grey50"",
                                   angle=180)) +
  labs(title=""Cats are most common in the North of the USA, while Dogs are prefered in South"",
       caption=""#TidyTuesday - Data from data.world/datanerd - Design by @stevejburr"")

ggsave(""plot.png"",dpi=""retina"",width=8,height=6)




","2018"
"493",1680,"https://github.com/stevejburr/tidytuesday/blob/master/04092018/code.r","stevejburr","tidytuesday","04092018/code.r","#setwd(""C:/Data/Personal/Tidy Tuesday/04092018"")

library(tidyverse)
library(ggrepel)

data <- read_csv(""fastfood_calories.csv"")

#scatter of sodium / sat fat
#sodium
#calories
#sat_fat

#grab top 7 products by sodium
#grab top 7 products by sat_fat
#label both of these on chart

data %>% arrange(-sodium) %>% top_n(7,sodium) %>% select(item) %>% pull() -> big_sodium
data %>% arrange(-sat_fat) %>% top_n(7,sat_fat) %>% select(item) %>% pull() -> big_sat_fat
data %>% filter(sodium>=2300 & sat_fat>=20) %>% select(item) %>% pull() -> danger_zone

labels <- c(big_sodium,big_sat_fat,danger_zone) %>% unique()

data %>% mutate(label=if_else(item %in% labels,item,"""")) -> data


#line at 20g of sat_fat = the recommended amount
#line at 2300 mg of sodium = the recommended amount

#colours

# Arbys - #d71921
# Burger King - #ec7801
# Chick Fil-A - #5b6770
# Dairy Queen - #009eb7
# Mcdonalds - #fcb827
# Sonic - #fcdd2a
# Subway - #0f9246
# Taco Bell - #682a8a

ourColours <- c(""#d71921"",""#ec7801"",""#5b6770"",""#009eb7"",""#fcb827"",""#fcdd2a"",""#0f9246"",""#682a8a"")

data %>% select(restaurant,label,sodium,calories,sat_fat) %>%
  ggplot(aes(x=sodium,y=sat_fat)) +
  geom_rect(data=data[1,],aes(ymin=20,ymax=55,xmin=0,xmax=2300),alpha=0.5,fill=""grey90"")+
  geom_rect(data=data[1,],aes(ymin=0,ymax=20,xmin=2300,xmax=6500),alpha=0.5,fill=""grey90"")+
  geom_rect(data=data[1,],aes(ymin=20,ymax=55,xmin=2300,xmax=6500),alpha=1,fill=""grey90"")+
  geom_point(aes(size=calories,col=as.factor(restaurant))) +
  geom_text_repel(aes(label=label),size=3,col=""grey50"") +
  geom_hline(yintercept = 20,col=""grey50"",linetype=""dashed"") +
  geom_label(data=data[1,],aes(x=6200,y=21,label=""Daily RDA""),alpha=1,size=3,fill=NA,hjust=1,col=""grey50"",label.size=NA) +
  geom_vline(xintercept= 2300,col=""grey50"",linetype=""dashed"") +
  geom_label(data=data[1,],aes(x=2310,y=1,label=""Daily RDA""),alpha=0.5,size=3,fill=NA,hjust=0,col=""grey50"",label.size=NA) +
  scale_y_continuous(""Saturated Fat (g)"")+
  scale_x_continuous(""Sodium (mg)"")+
  scale_size(""Total Calories"") +
  scale_colour_manual(""Restaurant"",values=ourColours)+
  guides(size = guide_legend(override.aes = list(colour=""grey50"", alpha = 1))) +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        text = element_text(colour=""grey50"")) +
  labs(title=""What are the unhealthiest fast food meals you can buy in the USA?"",
       subtitle=""Based on Saturated Fat and Sodium content"",
       caption=""Design by @stevejburr - Data from fastfoodnutrition.org - #TidyTuesday"")


ggsave(""plot.png"",width=10,height=10,dpi=""retina"")
","2018"
"494",1681,"https://github.com/stevejburr/tidytuesday/tree/master/18092018","stevejburr","tidytuesday","18092018/code.r","library(tidyverse)
library(gridExtra)
library(grid)

data1 <- read_csv(""hypoxia.csv"")
data2 <- read_csv(""us-airports.csv"")

#col 5/7/8- show cut off with >90% write commentary based on article

#create an altitude in ft column, duplicate on other side in mts

#drop first row which is just labelling
data <- data1[-1,c(6,7,9,10)]
data$heights <- c(0,10000,20000,30000,40000,50000)

#do % sat O2 with > 90
# and Alv pCO2 >35

dataO2 <- data[,c(1,3,5)]
dataCO2 <- data[,c(2,4,5)]

dataO2 %>% gather(key=""key"",value=""value"",-heights) %>%
  mutate(value=as.numeric(value),
         value=if_else(is.na(value),0,value)) %>%
  ggplot() +
  geom_hline(aes(yintercept=90),colour=""grey50"") +
  scale_x_continuous(""Height / ft"",sec.axis = sec_axis(~.*0.3048, name=""Height / m""),labels=scales::comma) +
  scale_y_continuous(""% of haemoglobin molecules saturated with O2"",breaks=c(25,50,75,90,100)) +
  scale_colour_manual("""",values=c(""#BCB6FF"",""#97F9F9""),labels=c(""Without oxygen"",""With oxygen"")) +
  geom_point(aes(y=value,x=heights,colour=key),size=3) +
  annotate(""text"",x=10000,y=83,label=""If flying without oxygen,\nabove 10,000ft the oxygen content \nof the blood drops dangerously low"",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=40000,y=75,label=""Even with a supply of pure oxygen, \nwithout a pressurised mask it \nbecomes dangerous to fly above 40,000ft"",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=48000,y=91,label=""Critical satuation value"",size=2,colour=""grey50"")+
  theme_minimal()+
  theme(text=element_text(colour=""grey50""),
        panel.grid = element_blank(),) +
  labs(title=""Using oxygen helps, but above about 40,000ft a pressurised mask is required"",
       subtitle=""This graph shows the % of haemoglobin molecules in the blood which are fully saturated with oxygen at different heights"") -> O2Plot




dataCO2 %>% gather(key=""key"",value=""value"",-heights) %>%
  mutate(value=as.numeric(value),
         value=if_else(is.na(value),0,value)) %>%
  ggplot() +
  geom_hline(aes(yintercept=35),colour=""grey50"") +
  scale_x_continuous(""Height / ft"",sec.axis = sec_axis(~.*0.3048, name=""Height / m""),labels=scales::comma) +
  scale_y_continuous(""Partial pressure of CO2 in the alveoli / mm Hg"",breaks=c(25,50,75,90,100)) +
  scale_colour_manual("""",values=c(""#BCB6FF"",""#97F9F9""),labels=c(""Without oxygen"",""With oxygen"")) +
  geom_point(aes(y=value,x=heights,colour=key),size=3) +
  annotate(""text"",x=10000,y=30,label=""If flying without oxygen,\nabove 10,000ft the CO2 pressure\nbecomes a problem"",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=40000,y=25,label=""Even with a supply of pure oxygen, \nwithout a pressurised mask it \nbecomes dangerous to fly above 40,000ft.\nWithout oxygen, the pressure of CO2\ndramatically falls further at this altitude."",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=48000,y=36,label=""Critical CO2 pressure"",size=2,colour=""grey50"")+
  theme_minimal()+
  theme(text=element_text(colour=""grey50""),
        panel.grid = element_blank(),) +
  labs(title=""The partial pressure of CO2 is also important, and this also falls with height."",
  subtitle=""If it is too low, then the blood vessels in the brain start to constrict, which negatively impacts cognition, while also hindering the release of\noxygen by your red blood cells. When it falls bellow 20mm Hg you start to feel mentally clouded (>35 is ideal), but this is not to do with lack of oxygen."") -> CO2plot

png(""plot.png"",height=1100,width=800,type=""cairo-png"")
grid.arrange(O2Plot,CO2plot,
           top = textGrob(
               ""The levels of both CO2 and O2 become important when flying above 10,000ft"",
               gp = gpar(fontface=2,fontsize=14,col=""grey50""),
               hjust=0.5
             ),
           bottom = textGrob(
             ""#TidyTuesday Design by - @stevejburr Data Source - Soaring Society of America/Nathan Cook"",
             gp = gpar(fontface = 3, fontsize = 9,col=""grey50""),
             hjust = 1,
             x = 1
           ),nrow=2,ncol=1,padding=unit(2,""lines""))
dev.off()
","2018"
"495",1721,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","data/2018-09-04/readme.rmd","# Fast food entree data

* Data from [fastfoodnutrition.com](https://fastfoodnutrition.org/mcdonalds/chart) 
* Please notice that I really only took entrees - feel free to select ALL food, sides, drinks, desserts, etc.

At the request of the website owner - I have removed web-scraping guide.
","2018"
"496",1722,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","data/2018-09-25/raw/invasive_species.R","library(tidyverse)

df <- read_csv(""afr_species.csv"") %>% 
        janitor::clean_names() %>% 
        select(species:origin)

df %>% write_csv(""africa_species.csv"")

df1 <- read_csv(""table1.csv"") %>% janitor::clean_names()
tab_1 <- df1 %>% 
        select(rank:o_tt) %>% 
        bind_rows(df1 %>% 
                          select(rank_1:o_tt_1) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        bind_rows(df1 %>% 
                          select(rank_2:o_tt_2) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        filter(!is.na(rank)) %>% 
        rename(""invasion_threat"" = o_tt)

df2 <- read_csv(""table2.csv"") %>% janitor::clean_names()
tab_2 <- df2 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:]+""),
               ti_ct = parse_number(ti_ct) * 1000000) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df2 %>% 
                select(""country"" = x4, ""ti_ct"" = ti_ct_millions_1) %>% 
                        mutate(rank = parse_number(country),
                               country = str_extract(country, ""[:alpha:]+""),
                               ti_ct = parse_number(ti_ct) * 1000000) %>% 
                        filter(!is.na(rank))
        ) %>% 
        bind_rows(df2 %>% 
                          select(""country"" = x7, ""ti_ct"" = ti_ct_millions_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_ct = parse_number(ti_ct) * 1000000) %>% 
                          filter(!is.na(rank))
                
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df3 <- read_csv(""table3.csv"") %>% janitor::clean_names()
tab_3 <- df3 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions, 
               ""gdp_mean"" = x4, ""gdp_proportion"" = proportion_of) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:]+""),
               ti_ct = parse_number(ti_ct) * 1000000,
               gdp_mean = parse_number(gdp_mean) * 1000000,
               gdp_proportion = as.numeric(gdp_proportion)
        ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x6, ""ti_ct"" = ti_ct_millions_1, 
                                 ""gdp_mean"" = x9, ""gdp_proportion"" = proportion_of_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x11, ""ti_ct"" = ti_ct_millions_2, 
                                 ""gdp_mean"" = x14, ""gdp_proportion"" = proportion_of_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df4 <- read_csv(""table4.csv"") %>% janitor::clean_names()
tab_4 <- df4 %>% 
        select(""country"" = rank_country, ""ti_cs"" = ti_cs_millions_us) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:]+""),
               ti_cs = parse_number(ti_cs) * 1000000
               ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_1, ""ti_cs"" = ti_cs_millions_us_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
                  ) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_2, ""ti_cs"" = ti_cs_millions_us_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_cs)

df6 <- read_csv(""table6.csv"") %>% janitor::clean_names()
tab_6 <- df6 %>% 
        select(species, ""max_impact_percent"" = maximum_reported_species) %>%
        filter(!is.na(species)) %>% 
        mutate(rank = 1:n(),
               species = species,
               max_impact_percent = parse_number(max_impact_percent)
        ) %>% 
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species, 
                                 ""max_impact_percent"" = maximum_reported_species_1) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:]+""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>%
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species_1, 
                                 ""max_impact_percent"" = maximum_reported) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:]+""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>% 
        filter(!is.na(species))

tab_list <- list(table_1 = tab_1, table_2 = tab_2, table_3 = tab_3, table_4 = tab_4, table_6 = tab_6)

tab_list %>% 
        names() %>% 
        walk(~ write_csv(tab_list[[.]], glue::glue(""{.}.csv"")))
","2018"
"497",1723,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","data/2018-09-25/raw/readme.rmd","# Raw tabular data

Table data extracted from supplementary PDF via [Tabula](https://tabula.technology/) open-source software. 

This ended up being super messy - cleaning script found below.

[Cleaning Script](https://github.com/rfordatascience/tidytuesday/blob/master/data/2018-09-25/raw/invasive_species.R)
","2018"
"498",1724,"https://github.com/fingertipsy/ggplot2_workshop","fingertipsy","ggplot2_workshop","ggplot_workshop_2018.Rmd","---
title: ""Data Visualizations""
author: ""Theresa Elise Wege""
subtitle: Intro to the ggplot2 package
output:
  html_notebook:
    theme: united
    toc: yes
    toc_float: yes
    toc_depth: 1
  toc: default
  html_document:
    toc: yes
    toc_float: yes
    toc_depth: 1
---


#Welcome to data visualization with ggplot!



## tidyverse recap
s
*ggplot2* is a R package build for data visualization. It is part of the *tidyverse*. If you haven't been to my Introduction to tidy data workshop, you can catch up on some of the background, checking out the [material](https://github.com/fingertipsy/tidyverse-introduction-workshop-2018) on my github.

When we install the tidyverse package, ggplot2 is actually already included and we don't have to install it additionally.
You can install the tidyverse package by running `install.packages('tidyverse')` in your Rstudio console. Remember you can run the line (or chunk) of code in your script by clicking on it and using the shortcut cmd+enter
After installing the package it is in our library. If we want to use it in a R script now, we need to load it from our library by running this code.

```{r}
library(tidyverse)
```


In the tidy data workshop I explained how working with the tidyverse and using the pipe operator is just like baking bread.

> The pipe operator allows you to build a pipeline of different operations and pipe your data through it. To understand this you can imagine baking bread. If you do it by hand you will go through different steps that all lead you to an interim result, which you use for the next step: you mix the ingredients and get dough -> you put the dough in a form and let it grow -> you shape the grown dough -> you put the shaped dough and the oven and bake it -> you take the bread out.

> Wouldn't it be great to just put the ingredients in a machine and you take the ready baked bread out? You won't be bothered with the interim results. This is basically what the pipe operator does to your code. You put an object like a dataset in and all the functions will be applied in order, but no intermin results are stored and the output is your final result. 

Here is an example to remind you how we can use the pipe operator to exectue a series of steps chained together to one piece of code.
We want to read in the dataset for today, rename a variable with a super long name and transform the variable on another scale. In green are some comments. The actual code is black. remember that you can add text within code by intialising a comment with `#`.

```{r, warning=FALSE, message=FALSE}
#without the pipe
data <- read_csv(""/Users/sctew/Desktop/week19_airline_safety.csv"") #import the .csv file and save it in an object called data. Of course your filepath will be different from this one.

data <- rename(data, seat_km = avail_seat_km_per_week) # rename the variable avail_seat_km_per_week in seat_km

data <- mutate(data, seat_km = seat_km/1000000000) #for readability: transform the count in billion seats per kilometer

#with saving each result again as data we are overwriting the previous dataset
```


```{r, warning=FALSE, message=FALSE}
#with the pipe

data <- 
  read_csv(""/Users/sctew/Desktop/week19_airline_safety.csv"") %>% #we take this as the input in our pipeline
  rename(seat_km = avail_seat_km_per_week) %>% #in this step of the pipeline we shorten the variable name
  mutate(seat_km = seat_km/1000000000) #we take the result from the previous step and apply for readability: transform the count in billion seats per kilometer

#the result of piping the original data through all the command is stored in data and we are not bothered with the interim results
```

## How ggplot works

To stick with the bread metaphor: ggplot comes to play after we piped our ingredients through a chain of commands and we got a nice bread. I like to think that using ggplot on our data is like taking the bread and making a sandwich. 

![](/Users/sctew/Downloads/sandwich-2708463_1280.png)
Let's have a look at this piece of code and the way in which it is like a sandwich:

```{r eval=FALSE, error=FALSE, message=FALSE, warning=FALSE, include=TRUE}
data %>% #this is our good old data wrangling with the pipe. We are putting ingredients in and then pufff BREAD!
  filter(...) %>% 
  summarize(...) %>% #now we take that bread and pipe it again (we could also save it as an object and then pipe that object)
  
ggplot(aes(x, y))  #we pipe it into ggplot, which is our sandwich maker. ggplot also wants to know what kind of sandwich we want. Specifying the aesthetics (basically what goes on the axis) is like saying we want a Tomato-Hoummus Sandwich. 

+ # Now ggplot knows the flavour of the sanwich, but we still need some instructions on how to make that sandwich. We add instruction with a + sign
  
  geom_bar() #a basic instruction is called a geom, which basically decides how the plot (sandwich) will look like in the end
```

We can add many more instructions to make more sophisticated and defined plots. Basically the difference between putting Tomato and Hoummus on bread at home and what they would do in a really nice restaurant.

Just like with making sandwiches the order in which we follow the instructions matters. ggplot puts new instructions on top of the last result. 

Now you are ready to make your first ggplot sandwiches!
You can find a set of all the basic instructions in the ggplot2 cheat sheet either online or in the help tab in RStudio: Help -> Cheatsheets

#Tasks {.tabset}

Here are some tasks in which you can use the tidyverse packages dplyr (to wrangle your data) and ggplot2 to recreate some plots. Start with Task 1 as the tasks build on each other and there are less and less detailed instructions. 

The data we loaded when doing a recap of the tidyverse is the data we will work with for these tasks. Make sure you have the object data in your environment and the variable name and scale has been changed. Just in case you can run the code to load the data again.

This dataset contains data about security incidents for 56 airlines between 1985-2014. We do have information on the availbale seat kilometers flown every week and how many incidents/ fatal accidents / fatalities happened in the year ranges '85-'99 and '00-'14. 
You should see all the variables, whenclicking on the blue arrow next to data in your environment. You can also inspect the dataset by doubleclicking on it or running `View(data)`. Make yourself familiar with the format of this data.

In the tasks you can try to recreate the different plots. Before starting the task, please scroll up to the top of the document and click the *code* button. Now select ""Hide all code"". This will minimize all code chunks in this document. If you want to see a code chunk again you can click on the buttons for each code chunk to display them again. 

For every task the code chunk with the code that produced the plot is now hidden. Try to write the code yourself! It will be most beneficial for your learning if you spend time to find the solution without checking the answer right away.

If you struggle to reproduce the code, you will also learn from trying to understand why the example code produces the code and why the plot from your own code looks different. Use the cheat sheet or any web resources and try to find out what specific arguments in the code do by changing them or disabeling them by turning them into a comment with adding a `#`.

##Task 1 

### Are there less fatal accidents in the more recent time than in the 80s-90s?

Take your data as the ingridient and create a pipeline where you 

1. `filter()` the data for *""fatal_accidents""* as the *type of event* (check the dplyer cheat sheet for more infos on how to do that)

2. command a `ggplot()` to have the *year_range* on the x axis and the *n_events* on the y axis (check the ggplot2 cheat sheet for more infos on how to do that)

  - add an instruction (geom)  to your ggplot, which creates a dotplot (`geom_dotplot()`) with the specifications `(binaxis= ""y"", stackdir = ""center"")`. See also on the cheat sheet.
  
```{r} 
data %>% 
  filter(type_of_event == ""fatal_accidents"") %>% 
ggplot (aes(year_range, n_events)) +
  geom_dotplot(binaxis= ""y"", stackdir = ""center"")

```

##Task 2 

### Is there a relationship between the available seats/km (in billions) and the number of incidents?

- What do you need to `filter()` for now?
- What order to you need to have for your variables in the *ggplot aesthetic* `ggplot(aes())`?
- This plot is made with adding two instructions / geoms. Which *geoms* need to be added to get this plot? How does the *order* of adding these geoms change the looks of the plot?
- Finally looking at the plot: Is there a relationship? Given the information is the plot: What might be an interesting follow-up question we could explore in this data?


```{r}
data %>% 
  filter(type_of_event == ""incidents"") %>% 
ggplot (aes(seat_km, n_events)) +
  geom_point() +
  geom_smooth()
```
## Task 3 

### How many events happend for each airline between '85-'14? Which airline had the most safety events?

To answer this question, we need to `summarize()` our data first, so that we get a new dataset containing all airlines and the total number of events. 

1. First, try to figure out how to achive this with using the `group_by()` and `summarize()` functions from the dplyr package and the `sum()` funtion to add up values in one variable. 
*Google is your friend!* A very important coding skill is using the resources around the web to find solutions yourself.
I'm here to point you in the right direction or help you with the code, but even better: ask the person next to you (aka your new friend) and figure it out together!


2. Well done for getting this result! Now pipe it in a *ggplot* function to plot the total events/airline and add a `geom_bar(stat = ""identity)` instruction

3. Why does this look weird? Check the ggplot2 cheat sheet to find out what next instruction to add to make your plot look like this one.

```{r}
data %>% 
  group_by(airline) %>% 
  summarize(total_events = sum(n_events)) %>% 
  print() %>% 
  ggplot(aes(airline, total_events)) +
  geom_bar(stat = ""identity"") +
  coord_flip()

# OR you maybe did it in two seperate steps and saved the summary dataset as a new object

# summary <-
 #  data %>% 
 #  group_by(airline) %>% 
 # summarize(total_events = sum(n_events)) %>% 
 # print() OR View() OR neither if you just click on summary in your environment to see what the dataframe looks like

# summary %>% 
  # ggplot(aes(airline, total_events)) +
  #  geom_bar(stat = ""identity"") +
  #  coord_flip()

```
## Task 4 

### How many of the different types of events happend within our two time periods?

Make a first more advanced plot. 

- Try to replicate this plot without any further instructions only using the ggplot2 cheat sheet. 

- You can do it!

```{r}
data %>% 
  ggplot(aes(year_range, n_events, fill = year_range)) +
  geom_violin() +
  facet_wrap(~type_of_event, scales = ""free_y"")
```

# What else is possible using ggplot2?

This dataset is taken from the [*FiveThirtyEight package*](https://cran.r-project.org/web/packages/fivethirtyeight/index.html).
FiveThirtyEight.com is a data journalism website, publishing data driven articles and analyses. 

You can find the article about the airline safety data [here.](https://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/)

These are some graphs that are included in this article and that can be replicated using ggplot:

![](/Users/sctew/Downloads/silver-datalab-airlines-safety-3.png) 

![](/Users/sctew/Downloads/silver-datalab-airlines-safety-21.png)

## More practice?!

If you want to practice data visualization with ggplot with interesting datasets every week and within a very supportive online community, check out #TidyTuesday on twitter or on their [github.](https://github.com/rfordatascience/tidytuesday)

Learners at every level from around the world create visualizations for a new datset every week and share their results, code and experience on twitter. 

Check out these tweets from people working with our airline security dataset:

<blockquote class=""twitter-tweet"" data-lang=""de""><p lang=""en"" dir=""ltr"">Bit tardy for this weeks <a href=""https://twitter.com/hashtag/tidytuesday?src=hash&amp;ref_src=twsrc%5Etfw"">#tidytuesday</a>! Apart from plotting, I learnt the names of each country&#39;s flag carrier ??I quickly divided the airlines by continent and alliance partnerships (because I can!). Travelling is safe these days, no matter which continent/alliance you choose! ?? <a href=""https://t.co/axLdzRoKte"">pic.twitter.com/axLdzRoKte</a></p>&mdash; Meenakshi Srinivasan ?? (@srini_meen) <a href=""https://twitter.com/srini_meen/status/1028448315208294400?ref_src=twsrc%5Etfw"">12. August 2018</a></blockquote> <script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""> </script> 



<blockquote class=""twitter-tweet"" data-lang=""de""><p lang=""en"" dir=""ltr""><a href=""https://twitter.com/hashtag/TidyTuesday?src=hash&amp;ref_src=twsrc%5Etfw"">#TidyTuesday</a> week 19 looking at airline safety from 1985-2014. The good news is airlines seem to be improving. Can&#39;t get enough of the <a href=""https://twitter.com/hashtag/paletteer?src=hash&amp;ref_src=twsrc%5Etfw"">#paletteer</a> package! So many cool palettes to choose from <a href=""https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw"">#rstats</a> <a href=""https://twitter.com/hashtag/SoDS18?src=hash&amp;ref_src=twsrc%5Etfw"">#SoDS18</a> <a href=""https://twitter.com/hashtag/tidyverse?src=hash&amp;ref_src=twsrc%5Etfw"">#tidyverse</a> <a href=""https://t.co/lXpfKRMQMF"">pic.twitter.com/lXpfKRMQMF</a></p>&mdash; David Smale (@committedtotape) <a href=""https://twitter.com/committedtotape/status/1027554137158893568?ref_src=twsrc%5Etfw"">9. August 2018</a></blockquote> <script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""></script> 


<blockquote class=""twitter-tweet"" data-lang=""de""><p lang=""en"" dir=""ltr"">Week 19 of <a href=""https://twitter.com/hashtag/TidyTuesday?src=hash&amp;ref_src=twsrc%5Etfw"">#TidyTuesday</a>! Didn&#39;t have too much time to spend on this week unfortunately. Don&#39;t fly American Airlines? <br><br>Feedback is welcome!<br><br>Data: <a href=""https://t.co/dZiveSoT3N"">https://t.co/dZiveSoT3N</a> <br>Article: <a href=""https://t.co/pnnbiYT7eO"">https://t.co/pnnbiYT7eO</a> <a href=""https://twitter.com/R4DScommunity?ref_src=twsrc%5Etfw"">@R4DScommunity</a> <a href=""https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw"">#rstats</a> <a href=""https://twitter.com/hashtag/dataviz?src=hash&amp;ref_src=twsrc%5Etfw"">#dataviz</a> <a href=""https://twitter.com/hashtag/ggplot?src=hash&amp;ref_src=twsrc%5Etfw"">#ggplot</a> <a href=""https://twitter.com/hashtag/DataScience?src=hash&amp;ref_src=twsrc%5Etfw"">#DataScience</a> <a href=""https://t.co/5QTFjIETFZ"">pic.twitter.com/5QTFjIETFZ</a></p>&mdash; Joe Stoica (@Joe_Stoica) <a href=""https://twitter.com/Joe_Stoica/status/1027671114665865216?ref_src=twsrc%5Etfw"">9. August 2018</a></blockquote> <script async src=""https://platform.twitter.com/widgets.js"" charset=""utf-8""></script> 

#Summary

- In this workshop you did a recap and extension of data wrangling with the tidyverse package. You know some functions of the dplyr package and how to apply them to your data and what results you can expect. 

- You can now also describe the general idea and functionalty of the ggplot2 package and the different code pieces that produce a plot. You know about the different function of the pieces and how to join them together

- If you want to practice more data vizualisation with ggplot, you now know where to find resources and community support.



This workshop was created by Theresa Elise Wege for R-Ladies Loughborough in August 2018 and is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.


","2018"
