"","id","url","username","repo","path","content","date"
"1",1,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week1/R/tw1_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(ggrepel)

tidy_data <- dir(here(""week1"", ""data""), full.names = TRUE, pattern = ""us_avg"") %>%
  read_excel() %>%
  gather(year, avg_tuition, -State) %>%
  rename(state = State)


nat_avg <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  group_by(year) %>%
  summarize(avg_tuition = mean(avg_tuition)) %>%
  mutate(state = ""National Average"")


plot_data <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  left_join(select(nat_avg, year, nat_avg = avg_tuition), by = ""year"") %>%
  bind_rows(nat_avg)

labels <- plot_data %>%
  group_by(state) %>%
  filter(all(avg_tuition > nat_avg)) %>%
  pull(state) %>%
  unique()

plot <- plot_data %>%
  ggplot(., aes(x = year, y = avg_tuition, group = state)) +
  geom_text_repel(data = filter(plot_data, state %in% labels, year == ""2015-16""), aes(label = state), direction = ""y"", nudge_x = 0.1, segment.size = 0.1, hjust = 0, family = ""Oxygen"", size = 3) +
  geom_path(color = ""grey50"", size = 0.5, alpha = 0.5) +
  geom_point(color = ""grey50"") +
  geom_path(data = nat_avg, color = ""red"", size = 1) +
  geom_point(data = nat_avg, color = ""red"") +
  scale_y_continuous(labels = scales::dollar) +
  labs(x = NULL, y = NULL, title = ""Comparison of the average US tuition growth between 2005 and 2015"", subtitle = ""Eastern and Northeastern students consistently face tutition above the national average, indicated by the red line."", caption = ""\nData: http://trends.collegeboard.org/ | Graphic: @jakekaupp"") +
  theme_minimal(base_family = ""Oswald Light"") +
  theme(panel.grid.minor = element_blank())

ggsave(plot, filename = glue('{here(""week1"")}/tidyweek-{Sys.Date()}.png'), height = 8, width = 6, dpi = 300)

","2018-1"
"2",2,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week11/R/tw11_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)

raw_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week11_fifa_audience.csv"") %>% 
  select(-X1)

font_add_google(""Oswald"",""Oswald-Light"", regular.wt = 300)
font_add_google(""Scope One"",""Scope One"")

showtext_auto()

vplayout <- function(x, y) viewport(width=11/3, height=8.5, layout.pos.row = x, layout.pos.col = y)

build_treemap <- function(x, y, size)  {
  
  title <- set_names(c(""Population Share"", ""TV Audience Share"", ""GDP Weighted Share""), c(""population_share"",""tv_audience_share"", ""gdp_weighted_share""))
  
  treemap(raw_data,
          index = c(""confederation"",""country""),
          vSize = size,
          vColor = ""confederation"",
          type = ""categorical"",
          title = title[size],
          title.legend = """",
          fontfamily.title = ""Oswald-Light"",
          fontsize.labels = c(20, 10),
          fontfamily.labels = ""Oswald-Light"",
          fontcolor.labels = ""#f0f0f0"",
          lowerbound.cex.labels = 1,
          bg.labels = 0,
          inflate.labels = FALSE,
          border.col = ""white"",
          border.lwds = 1,
          position.legend = ""none"",
          palette = nord(""baie_mouton""),
          align.labels = list(c(""left"",""top""), c(""right"",""bottom"")),
          drop.unused.levels = TRUE,
          vp = vplayout(x,y))
  
  
  
}

fifa_maps <- function() {
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(3, 3, heights = c(0.1, 0.8, 0.1))))
  par(mai=c(0,0,0,0))
  
  grid.text(""Comparing FIFA Share Differences by Confederation and Country"", x = 0.1, hjust = 0, vp = vplayout(1,1), gp = gpar(fontfamily = ""Oswald-Light"", fontsize = 30))
  build_treemap(2, 1, ""population_share"")
  build_treemap(2, 2, ""tv_audience_share"")
  build_treemap(2, 3, ""gdp_weighted_share"")
  grid.text(""Data: fivethirtyeight.com | Graphic: @jakekaupp"", x = 0.5, vp = vplayout(3,3), gp = gpar(fontfamily = ""Scope One"", fontsize = 10))
  
}

png(here(""week11"", ""Fifa Treemaps.png""), width = 11, height=8.5, units = ""in"", res = 100)
fifa_maps()
dev.off()

","2018-11"
"3",3,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week12/R/tw12_plot.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(ggridges)
library(nord)
library(here)
library(showtext)

font_add_google(""Oswald"", ""Oswald"", regular.wt = 400)
font_add_google(""Scope One"", ""Scope One"")

trend_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_google_trends.csv"", skip = 2, col_names = TRUE) %>% 
  set_names(str_extract(names(.), ""(?<=Hurricane )(\\w+)|(Day)"")) %>% 
  rename(Date = Day) %>% 
  mutate(source = ""Google Trends"") %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

mediacloud_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_mediacloud_hurricanes.csv"", col_names = TRUE) %>% 
  mutate(source = ""Online News"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_tv_hurricanes.csv"") %>% 
  mutate(source = ""TV"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

all_data <- bind_rows(trend_data, mediacloud_data, tv_data) %>%
  gather(hurricane, value, -Date, - source) %>% 
  set_names(tolower(names(.)))

showtext_auto()

plot <- ggplot(all_data, aes(x = date, y = source)) +
  geom_ridgeline(aes(height = value, fill = factor(hurricane)), size = 0.1, scale = 0.8, alpha = 0.8) +
  labs(title = ""On nearly every form of media, hurricanes that hit mainland US received more sustained coverage than Maria in Puerto Rico"",
       subtitle = ""Ridgeline plots of normalized media shares (TV, Online News and Google Trends)"",
       caption = ""Data: fivethirtyeight | Graphic: @jakekaupp"",
       y = NULL,
       x = NULL) +
  scale_x_date(expand = c(0,0)) +
  scale_fill_nord(name = ""Hurricane"", palette = ""lumina"") +
  theme_jk(plot_title_size = 28, subtitle_size = 24, base_size = 20, caption_size = 12,  grid = ""X"") +
  theme(axis.text.y = element_text(vjust = -2))

ggsave(plot, filename = here(""week12"", ""ROCK YOU LIKE A HURRICANE.png""), width = 6, height = 3)
","2018-12"
"4",4,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week18/R/tw18_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)
library(readxl)
library(ggalt)
library(jkmisc)


raw_data <- read_xlsx(here(""week18"", ""data"", ""week18_dallas_animals.xlsx""), sheet = 1)

data <- raw_data %>% 
  filter(animal_type %in% c(""CAT"",""DOG""), mo_year == ""2017"") %>% 
  count(animal_type, month, mo_year, outcome_type) %>% 
  group_by(animal_type, month, mo_year) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  select(-n) %>% 
  filter(outcome_type %in% c(""EUTHANIZED"",""ADOPTION"")) %>% 
  mutate_if(is.character, tolower) %>%
  spread(outcome_type, percent) %>% 
  mutate_if(is.character, tools::toTitleCase) %>% 
  mutate(month = ifelse(month == ""may"", ""May"", month)) %>% 
  arrange(month) %>% 
  complete(month = month.abb, mo_year, animal_type, fill = list(adoption = NA, euthanized = NA)) %>% 
  mutate(ratio = adoption/euthanized) %>% 
  mutate(month = factor(month, month.abb))



ggplot(data, aes(x = month, y = ratio, group = animal_type, color = animal_type)) +
  geom_hline(yintercept = 1.0, size = 0.1, color = ""firebrick"", linetype = ""dashed"") +
  geom_line(size = 0.5) +
  geom_text(data = filter(data, month == ""Sep""), aes(label = animal_type), nudge_x = 0.3, family = ""Oswald"") +
  theme_jk(grid = ""XY"") +
  scale_color_nord(""victory_bonds"") +
  labs(x = NULL, y = ""Ratio of Adopted/Euthanized"", title = ""2017 was a bad time to be a cat in a shelter"", subtitle = ""Cats in the shelters were euthanized more than adopted compared to dogs."") +
  theme(legend.position = ""none"")
  



","2018-18"
"5",5,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week2/R/tw2_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(janitor)
library(rvest)
library(nord)
library(jkmisc)
library(viridis)

# Function to scrape the top avg cap salary by player ----
pull_position_data <- function(year, position) {
  
  Sys.sleep(5)
  
  url <- glue(""http://www.spotrac.com/nfl/positional/{year}/{position}"")
  
  read_html(url) %>% 
    html_nodes(""#main > div.teams > table:nth-child(6)"") %>% 
    html_table() %>%
    flatten_df() %>% 
    set_names(c(""rank"",""player"",""cap_dollars"", ""cap_percent""))
}


# Formatter for 538 year labels 
labels_538 <- function(labels) {
  labels_out <- sprintf(""20%s"", str_sub(labels, 3, 4))
  labels_out <- c(labels_out[1], glue(""'{str_sub(labels_out[-1], 3, 4)}""))
  return(labels_out)
}

# Create the data scaffold 
years <- 2011:2018
positions <- c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"",""defensive-end"",""cornerback"",""defensive-tackle"", ""inside-linebacker"", ""outside-linebacker"", ""free-safety"", ""strong-safety"", ""kicker"",""punter"",""long-snapper"")

scaffold <- tibble(year = years,
                   position = list(positions)) %>% 
  unnest() 

# Populate the scaffold
if(!file.exists(here(""week2"", ""data"", ""position_cap_data_named.RDS""))) {
  
  scaffold <- scaffold %>% 
    mutate(data = map2(year, position, ~pull_position_data(.x, .y))) %>% 
    unnest() %>% 
    mutate_at(c(""cap_dollars"", ""cap_percent""), parse_number) %>% 
    mutate(side = case_when(position %in% c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"") ~ ""Offense"",
                            position %in% c(""kicker"",""punter"",""long-snapper"") ~ ""Special Teams"",
                            TRUE ~ ""Defense""))
  
  
  # Save it to avoid re-scraping 
  saveRDS(scaffold, file = here(""week2"", ""data"", ""position_cap_data_named.RDS""))
} else {
  
  scaffold <- readRDS(here(""week2"", ""data"", ""position_cap_data_named.RDS""))
  
}


# Make data for the plot
plot_data <- scaffold %>% 
  group_by(year, position, side) %>% 
  top_n(16, cap_dollars) %>% 
  summarize(avg_pay = mean(cap_dollars))
  
# Make a heatmap!
ggplot(plot_data, aes(x = year, y = position, fill = avg_pay)) +
  geom_tile(color = ""white"", size = 0.1) +
  coord_equal() +
  labs(x = NULL, y = NULL, title = ""The Fullback Gets No Respect"", subtitle = ""Average cap value of the 16 highest payed players in all positions"", caption = ""Data: http://www.spotrac.com/ | Graphic: @jakekaupp"") +
  scale_x_continuous(labels = labels_538, breaks = 2011:2018) +
  scale_y_discrete(labels = function(x) str_to_title(gsub(""[[:punct:]]"", "" "", x))) +
  scale_fill_viridis(discrete = FALSE, labels = scales::dollar, name = ""Average Salary"") +
  theme_jk(grid = FALSE, base_size = 14)

ggsave(here(""week2"", ""tw2_heatmap.png""), width = 8, height = 8)
","2018-2"
"6",6,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week3/R/tw3_plot.R","library(tidyverse)
library(here)
library(readxl)
library(jkmisc)

# Read in the data
mortality_data <- dir(here(""week3"",""data""), pattern = ""global"", full.names = TRUE) %>% 
  read_excel()


# Tidy up the data
tidy_mort <- mortality_data %>% 
  gather(cause_of_death, percentage, -country:-year) %>% 
  mutate(cause_of_death = trimws(str_remove(cause_of_death, ""\\(\\%\\)""))) %>% 
  mutate(percentage = ifelse(is.na(percentage), NA, percentage/100))

# Get just the data pertaining to suicides
suicide_data <- tidy_mort %>% 
  filter(cause_of_death == ""Suicide"", !is.na(country_code))

# Get the World percentage
global_rate <- suicide_data %>% 
  filter(country == ""World"") %>% 
  select(year, percentage)

# Get the top 40 problem countries, those with the suicide rate constantly over the world average (note the all statement in the filter)
problem_countries <- suicide_data %>% 
  filter(country != ""World"") %>% 
  left_join(global_rate, by = ""year"") %>% 
  group_by(country) %>% 
  filter(all(percentage.x > percentage.y)) %>% 
  summarize(percentage = mean(percentage.x, na.rm = TRUE)) %>% 
  top_n(40, percentage) %>% 
  arrange(desc(percentage)) %>% 
  pull(country)

# Create the data to make the plot, and arrange descending by the overall avg rate of suicide
plot_data <- suicide_data %>% 
  filter(country %in% problem_countries) %>% 
  mutate(country = factor(country, problem_countries))

# Create the sad plot
sad_plot <- ggplot(plot_data, aes(x = year, y = percentage)) +
  geom_segment(aes(x = min(year), xend = max(year), y = 0, yend = 0)) +
  geom_area(fill = ""steelblue4"") +
  geom_path(color = ""grey30"", size = 0.2) +
  geom_area(data = global_rate, fill = ""steelblue3"") +
  geom_path(data = global_rate, color = ""grey30"", size = 0.2) +
  facet_wrap(~country, nrow = 5) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = ""Countries Coping With the Tradgedy and Pain of Suicide"",
       subtitle = ""Dark blue indicates suicide rate by year, Light blue fill indicates the global average suicide rate by year."",
       x = NULL,
       y = NULL,
       caption = ""Data: ourworldindata.org | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"")

# Save the sad plot
ggsave(here(""week3"",""tw3_sad_plot.png""), sad_plot, width = 16, height = 10)
","2018-3"
"7",7,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week4/R/tw4_plot.R","library(tidyverse)
library(here)
library(jkmisc)
library(scales)
library(ggiraph)
library(glue)
library(waffle)

make_tooltip <- function(occupation, female, male, income_gap, ...) {
 
  glue('<div class=""tipchart"">
      <h3>{occupation}</h3>
      <h4>Mens taxable income {ifelse(income_gap <= 1, percent(1-round(income_gap, 2)), percent(round(income_gap, 2)))} {ifelse(income_gap <= 1, ""less"", ""more"")} than womens</h4>
      <table>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Male Taxable Income:</td>
      <td class=""tiptext"">{dollar(male)}</td>
      </tr>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Female Taxable Income:</td>
      <td class=""tiptext"">{dollar(female)}</td>
      </tr>
      </table>
      </div>')
  
}


# Read in the data
income_data <- dir(here(""week4"",""data""), pattern = ""salary"", full.names = TRUE) %>% 
  read_csv(locale = locale(""en""))
 
# Clean occupation up a bit.  Some rouge unicodes in there.
tidy_gap <- income_data %>% 
  mutate(occupation = iconv(occupation, ""UTF-8"", ""UTF-8"",sub='')) %>% 
  spread(gender, average_taxable_income) %>%
  set_names(tolower(names(.))) %>% 
  group_by(occupation) %>% 
  summarize_at(c(""female"", ""male""), sum, na.rm = TRUE) %>% 
  filter(female != 0, male != 0) %>% 
  mutate(income_gap = male/female)

plot_data <- tidy_gap %>% 
 mutate(fill = if_else(income_gap >= 1, ""grey80"", ""#ffd700""),
         alpha = if_else(income_gap >= 1, 0.2, 1)) %>% 
  mutate(tooltip = pmap(., make_tooltip)) %>% 
  mutate(tooltip = gsub(""\\\n"", """", tooltip)) %>% 
  mutate(tooltip = gsub(""'"", """", tooltip)) %>% 
  mutate(idx = row_number())

tooltip_css <- ""background-color:white;padding:10px;border-radius:20px 20px 20px 20px;border-color:black;border-style:solid;border-width:1px""

plot <- ggplot(plot_data, aes(x = female, y = male, fill = fill)) +
  geom_segment(x = 0, xend = 600000, y = 0, yend = 600000, size = 0.05, color = ""grey80"") +
  geom_point_interactive(aes(alpha = alpha, tooltip = tooltip, data_id = idx), shape = 21, color = ""grey30"", size = 3) +
  scale_y_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_x_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Gender Differences in Taxble Income in Australia"",
       subtitle = str_wrap(""Average male taxable income plotted against average female taxable income by occupation. Yellow dots indicate occupations where women have more taxable income than their male counterparts, 
       line indicates income equality. Hover over points for occupation, % difference and detailed income."", 100),
       caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme_jk()

ggiraph(ggobj = plot, width_svg = 9, width = 1, tooltip_extra_css = tooltip_css)

waffle_data <- tidy_gap %>% 
  ungroup() %>% 
  mutate(category = case_when(income_gap > 1 ~ ""Men have more income"",
                              income_gap < 1 ~ ""Women have more income""))%>% 
  count(category) %>% 
  pull(n) %>% 
  set_names(., c(""Men have more income"", ""Women have more income""))

waffle(waffle_data, 
       rows = 14,
       size = 1,
       colors = c(""dodgerblue3"", ""deeppink""), 
       legend_pos = ""bottom"", 
       title = ""Out of 1092 occupations on record, men have more taxable income than women in 1011 of them.  That's 92.5% of occupations for those counting at home."") + 
  theme_jk() +
  labs(caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme(axis.text = element_blank(),
        legend.position = ""bottom"")
","2018-4"
"8",8,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week5/R/tw_5plot.R","library(tidyverse)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)


census_data <- dir(here(""week5"", ""data""), full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

# Lets look at commuting!
commuting_data <- census_data %>% 
  select(census_id, state, county, total_pop, drive:mean_commute)

# Despacito is 3:47 in length
despacito_length <- 3 + 47/60

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") 

# Calculate the how many despacitos the average commute has
despacito_commute <- commuting_data %>% 
  mutate(despacitos = mean_commute/despacito_length,
         id = ifelse(str_length(as.character(census_id)) < 5, glue(""0{census_id}""), as.character(census_id))) %>% 
  right_join(us_map)


# Make the map!
map <- ggplot() +
 geom_map(data = us_map, map = us_map,
                    aes(x = long, y = lat, map_id = id),
                    color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = despacito_commute, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = despacitos),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis(name=""How many despactios?"", na.value = viridis(5, option = ""cividis"")[3], option = 'cividis', breaks = seq(1,12,2)) +
  labs(title = ""Just how much do you like your commute?"",
       subtitle = str_wrap(""What if your commute was defined by hearing a song on repeat?  
                           What if that song was the most streamed song on the planet, Despacito? 
                           Illustrated below is the average number of times you'd hear it on your way home across the US."", 80),
       caption = ""Data: census.gov | Graphic: @jakekaupp"") +
  coord_map() +
  theme_map(base_family=""Scope One"", 
            base_size = 16) +
  theme(legend.title = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        plot.caption = element_text(size = 10),
        legend.position = c(0.9,0.1))

ggsave(here(""week5"", ""tw5_choropleth map.png""), width = 10, height = 6)


","2018-5"
"9",9,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week6/R/tw_6plot.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(glue)
library(fuzzyjoin)
library(stringi)
library(ggalt)
library(jkmisc)
library(nord)



provinces <- set_names(c(""Alberta"", ""British Columbia"", ""Manitoba"", ""New Brunswick"", ""Newfoundland and Labrador"",
                         ""Nova Scotia"", ""Northwest Territories"", ""Nunavut"", ""Ontario"", ""Prince Edward Island"", ""Quebec"",
                         ""Saskatchewan"", ""Yukon""),
                       c(""AB"", ""BC"", ""MB"", ""NB"", ""NL"", ""NS"", ""NT"", ""NU"", ""ON"", ""PE"", ""QC"", ""SK"", ""YT""))

# Just get the Tims data just for Canada
tim_hortons <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""xlsx"") %>% 
  read_excel(sheet = ""timhorton"") %>% 
  filter(country == ""ca"") %>% 
  rename(province = state) 

# Counts at the City/Province level
tims_city_prov <- tim_hortons %>% 
  count(city, province)

# Counts at the National level
tims_national <- tim_hortons %>% 
  count(province) %>% 
  mutate(color = ifelse(province == ""ON"", nord(""victory_bonds"", 1), ""grey50""))

national <- ggplot(tims_national, aes(x = reorder(province,n), y = n)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0.01,0.05),  breaks = scales::pretty_breaks()) +
  scale_x_discrete(labels = function(x) provinces[x]) +
  coord_flip() +
  labs(x = NULL, y = NULL, title = ""Ontario, we have a problem...."", subtitle = ""The highest number of Tim Hortons per province goes to Ontario, a land where you can't even get an oat cake."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = national, here(""week6"", ""National Tims.png""), width = 10, height = 6)

census_2011 <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""2011 census"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  remove_empty(""rows"") %>% 
  select(city = geographic_name, population = population_2011) %>% 
  mutate(province = stri_extract_last_regex(city, ""\\(([A-Za-z\\.]+?)\\)""),
         city = stri_replace_all_regex(city, ""\\((.*?)\\)"", """"),
         province = gsub(""[[:punct:]]"", """", province)) %>% 
  mutate(province = case_when(province == ""Que"" ~ ""QC"",
                              province == ""Ont"" ~ ""ON"",
                              province == ""Man"" ~ ""MB"",
                              province == ""Sask"" ~ ""SK"",
                              province == ""Alta"" ~ ""AB"",
                              province == ""NWT"" ~ ""NT"",
                              province == ""Nvt"" ~ ""NU"",
                              province == ""PEI"" ~ ""PE"",
                              TRUE ~ province)) %>% 
  mutate_if(is.character, trimws)



tims_density <- regex_right_join(census_2011, tims_city_prov,  by = c(""city"", ""province""), ignore_case = TRUE) 


plot_data <- tims_density %>% 
  select(population, city = city.y, province = province.x, n) %>% 
  group_by(city, province) %>% 
  summarize_at(c(""n"", ""population""), sum, na.rm = TRUE) %>% 
  ungroup() %>% 
  filter(population != 0, n > 1, population > 10000) %>% 
  mutate(density = (n/(population/1000))) %>% 
  top_n(25, density) %>% 
  mutate(color = ifelse(density == max(density), nord(""victory_bonds"", 1), ""grey50""))


most_tims <- ggplot(plot_data, aes(x = reorder(city, density), y = density)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0,0.01),  breaks = scales::pretty_breaks(), limits = c(0,1.2)) +
  coord_flip() +
  labs(y = ""Number of Tim Hortons stores per 1,000 people"", x = NULL, title = ""However, the title of most Tim Hortons per capita belongs to Cold Lake, Alberta"", 
       subtitle = ""When looking at towns/cities with population > 10,000 and with more than two Tim Hortons. \nMy hometown of Truro, Nova Scotia comes in a puzzling fourth."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = most_tims, here(""week6"", ""Most Tims.png""), width = 10, height = 6)

","2018-6"
"10",10,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week7/R/tw_7plot.R","library(tidyverse)
library(here)
library(janitor)
library(likert)
library(jkmisc)
library(nord)

star_wars <- dir(here(""week7"", ""data""), pattern = ""StarWars"", full.names = TRUE) %>% 
  read_csv() 

clean_names <- stringi::stri_trans_general(names(star_wars), ""latin-ascii"") %>% 
  gsub(""[^\\x{00}-\\x{7f}]"", """", ., perl = TRUE) %>% 
  clean_names()

star_wars <- set_names(star_wars, clean_names) 

headers <- slice(star_wars, 1) %>% 
  flatten_chr()

clean_names <- gsub(""X\\d+"", NA_character_, clean_names) %>% 
  enframe() %>% 
  fill(value) %>% 
  pull(value)


shiny_clean_names <- paste(clean_names, headers, sep = ""|"")

long_star_wars <- set_names(star_wars, c(""RespondentID"", shiny_clean_names[-1])) %>% 
  slice(-1) %>% 
  gather(item, value, -1) %>% 
  separate(item, c(""question"", ""category""), sep = ""\\|"") %>% 
  mutate(category = if_else(category == ""Response"", NA_character_, category)) %>% 
  mutate(index = group_indices(., question))


plot_data <- long_star_wars %>% 
  filter(index == 12) %>% 
  replace_na(list(value = ""Unfamiliar (N/A)"")) %>% 
  filter(value != ""Unfamiliar (N/A)"") %>% 
  spread(category, value) %>% 
  mutate_at(vars(-RespondentID, -question, -index), function(x)
    factor(x, 
            levels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""),
            labels = 1:5
    )) 
            
            
likert_data <- plot_data %>% 
  select(-RespondentID, -question, -index) %>%
  as.data.frame() %>% 
  likert()


ggplot2::update_geom_defaults(""text"", list(family = ""Scope One"", size = 4))
  
plot <- likert.bar.plot(likert_data) + 
  scale_fill_nord(""mountain_forms"", labels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""), name = ""Response"") +
  labs(title = ""The Favorability Rankings of Star Wars Characters"", subtitle = ""People look favourably upon the scruffy nerf herder, and would give a ride to the EVIL RAISIN THAT SHOOTS LIGHTNING FROM HIS HANDS before the goofy gungan."") +
  theme_jk(grid = ""XY"") +
  theme(plot.title = element_text(family = ""Oswald""))

ggsave(here(""week7"", ""tw7_likert.png""), width = 16, height = 10)
  
  
 
","2018-7"
"11",11,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week1/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)


# week-of-month function
wom <- function(date) { 
  first <- wday(as.Date(paste(year(date),month(date),1,sep=""-"")))
  return((mday(date)+(first-2)) %/% 7+1)
}

# Get the TidyTuesday Tweets Data
tt_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""tidytuesday_tweets.rds""))

# Get the R tweet data 
r_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""rstats_tweets.rds""))

# Most that tweet about R tweet about the r4ds tidy tuesday.
no_rstats <- anti_join(tt_tweet_data, r_tweet_data, by = ""screen_name"") %>% 
  mutate(rstats_tag = case_when(grepl(""rstats"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""r4ds"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""visualization"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""data"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""code"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""plot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""chart"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""graph"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""drob"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""ggplot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""rstudio"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""model"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""median"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""average"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""week \\d+"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""@thomas_mock"", text, ignore.case = TRUE) ~ TRUE,
                                TRUE ~ FALSE)) %>% 
  mutate(rstats_tag = case_when(screen_name %in% c(""NosyOwl"", ""sebastianhwells"", ""JenniferCai7"", ""matthwong"",
                                                   ""scrite_jones"", ""jrosenblum123"", ""zlipp"") ~ TRUE,
                                TRUE ~ rstats_tag)) %>% 
  filter(rstats_tag == FALSE)
  

plot_data <- anti_join(tt_tweet_data, no_rstats, by = ""screen_name"") %>% 
  mutate(created_at = as_date(created_at)) %>% 
  mutate(day = wday(created_at, label = TRUE, abbr = FALSE),
         week = wom(created_at),
         iweek = isoweek(created_at),
         month = month(created_at, label =  TRUE, abbr = FALSE),
         year = year(created_at))


count(plot_data, day, iweek) %>% 
  complete(day, iweek = 1:52, fill = list(n = NA)) %>% 
  ggplot(aes(x = iweek, y = day, fill = n)) +
  geom_tile(color = ""white"", size = 0.1) +
  scale_fill_viridis_c(""Tweet Frequency"", option = ""cividis"", na.value = ""grey95"", labels = seq(0,25,5), breaks = seq(0,25,5), limits = c(0,25)) +
  coord_equal() +
  labs(title = ""Tidy Tuesday or Tardy Tuesday?"",
       subtitle = ""A glance at when the community decides to submit their work."",
       y = NULL,
       x = ""Week of the Year"",
       caption = ""Data: rtweet | Analysis: @jakekaupp"") +
  scale_x_continuous(limits = c(1, 53), breaks = c(1,10,20,30,40,50), expand = c(0, 0)) +
  theme_jk(grid = FALSE, ticks = FALSE) +
  theme(legend.position = c(0.5,-0.7),
        legend.direction = ""horizontal"",
        legend.title = element_text(family = ""Scope One"", vjust = 0.8))

ggsave(here(""2019"", ""week1"",""tidy_or_tardy.png""), width = 8, height = 4)
","2019-1"
"12",12,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week10/R/analysis.R","library(tidyverse)
library(jkmisc)
library(ggrepel)
library(here)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")


plot_data <- jobs_gender %>% 
  select(-year) %>% 
  group_by(occupation, major_category, minor_category) %>% 
  summarize_all(mean, na.rm = TRUE) %>% 
  filter(str_detect(occupation, ""engineer""), str_detect(major_category, ""Engineering"")) %>% 
  mutate(diff = if_else((total_earnings_female - total_earnings_male) > 0, ""firebrick"", ""grey80"")) %>% 
  mutate(alpha = if_else(diff == ""firebrick"", 1, 0.2)) %>% 
  gather(variable, value, starts_with(""total_earnings_"")) %>% 
  mutate(variable = factor(variable, c(""total_earnings_male"", ""total_earnings_female""), c(""Men"", ""Women"")))
 
slope_data <- build_slopegraph(plot_data, ""variable"", ""value"", ""occupation"") %>% 
  left_join(distinct(plot_data, occupation, diff, alpha), by = c(""group"" = ""occupation"")) %>% 
  mutate(group = case_when(str_detect(group, ""Mining"") ~ ""Mining Engineers"",
                                str_detect(group, ""Computer"") ~ ""Computer Engineers"",
                                str_detect(group, ""Electrical"") ~ ""Electrical Engineers"",
                                str_detect(group, ""Marine"") ~ ""Marine Engineers"",
                                str_detect(group, ""Industrial"") ~ ""Industrial Engineers"",
                           TRUE ~ str_to_title(group))) %>% 
  mutate(group = str_replace(group, ""Engineers"", ""Engineering""))


labels <- pretty(slope_data$y, 9)
breaks <- pretty(slope_data$ypos, 5)


plot <- ggplot(slope_data, aes(x = x, y = ypos, group = group, color = diff)) +
  geom_point() +
  geom_line() +
  geom_label_repel(data = filter(slope_data, x == ""Women""), aes(label = group), direction = ""y"", hjust = 0, nudge_x = 1, segment.alpha = 0.3, family = ""Oswald"", label.size = 0, fill = ""white"") +
  theme_jk(grid = ""XY"") +
  expand_limits(x = c(0, 5)) +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_y_continuous(labels = scales::dollar(labels), breaks = breaks, limits = range(breaks)) +
  theme(panel.grid.major.x = element_line(linetype = ""dashed"", color = ""black"")) +
  labs(x = NULL,
       y = NULL,
       title = ""The Unnecessary and Unethical Pay Disparity in Engineering."",
       subtitle = str_wrap(""A slopegraph presenting the average total earnings from 2014-2016 for men and women across engineering disciplines.  Mining Engineering is the only discipline with women earning more than men on average."", 70),
       caption = ""Data: Census Bureau | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week10"", ""tw10_plot.png""), plot, width = 6.5, height = 9, type = ""cairo"")
","2019-10"
"13",13,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week10/R/helpers.R","# Functions from an old friend.
# https://github.com/jkeirstead/r-slopegraph/blob/master/slopegraph.r

build_slopegraph <- function(df, x, y, group, min.space=0.05) {
  
  ## First rename the columns for consistency
  ids <- match(c(x, y, group), names(df))
  
  df <- df[,ids]
  
  names(df) <- c(""x"", ""y"", ""group"")
  
  ## Expand grid to ensure every combination has a defined value
  tmp <- expand.grid(x=unique(df$x), group=unique(df$group))
  
  tmp <- merge(df, tmp, all.y=TRUE)
  
  df <- mutate(tmp, y=ifelse(is.na(y), 0, y))
  
  spaced_sort(df, min.space=min.space)
  
}



spaced_sort <- function(df, min.space=0.05) {
  ## Define a minimum spacing (5% of full data range)
  min.space <- min.space*diff(range(df$y))
  
  ## Transform the data
  
  df <- split(df, ""x"") %>% 
    map_df(~calc_spaced_offset(.x, min.space))
  
  return(df)
}

##' Calculates the vertical offset between successive data points
##' 
##' @param df a data frame representing a single year of data
##' @param min.space the minimum spacing between y values
##' @return a data frame
calc_spaced_offset <- function(df, min.space) {
  
  ## Sort by value
  ord <- order(df$y, decreasing=T)
  ## Calculate the difference between adjacent values
  delta <- -1*diff(df$y[ord])
  ## Adjust to ensure that minimum space requirement is met 
  offset <- (min.space - delta)
  offset <- replace(offset, offset<0, 0)
  ## Add a trailing zero for the lowest value
  offset <- c(offset, 0)
  ## Calculate the offset needed to be added to each point
  ## as a cumulative sum of previous values
  offset <- rev(cumsum(rev(offset)))
  ## Assemble and return the new data frame
  df.new <- data.frame(group=df$group[ord],
                       x=df$x[ord],
                       y=df$y[ord],
                       ypos=offset+df$y[ord])
  return(df.new)
}
","2019-10"
"14",14,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week11/R/analysis.R","library(tidyverse)
library(jkmisc)
library(here)

board_games <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")

prolific <- board_games %>% 
  separate_rows(designer, sep = "","") %>% 
  filter(!str_detect(designer, ""Uncredited""), !str_detect(designer, ""Jr|III""), year_published >= 1990) %>% 
  group_by(designer) %>% 
  filter(n() >= 10) %>% 
  group_by(designer, year_published) %>% 
  summarize(year_avg_rating = mean(average_rating, na.rm = TRUE),
            games_published = n()) 

top_rated <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, overall_rating) %>% 
  pull(designer)

top_publishing <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, total_games) %>% 
  pull(designer)

overall_avg <- prolific %>% 
  group_by(year_published) %>% 
  summarize(year_avg_rating = mean(year_avg_rating, na.rm = TRUE),
            designer = ""Overall"")


plot_data <- prolific %>%
  bind_rows(overall_avg) %>% 
  mutate(color = case_when(designer == top_rated ~ ""#eebd31"" ,
                           designer == ""Overall"" ~ ""firebrick"",
                           designer == top_publishing ~ ""dodgerblue"",
                           TRUE ~ ""black""),
         alpha = case_when(designer == top_rated ~ 1,
                           designer == ""Overall"" ~ 1,
                           designer == top_publishing ~ 1,
                           TRUE ~ 0.05),
         size = case_when(designer == top_rated ~ 0.5,
                           designer == ""Overall"" ~ 0.5,
                           designer == top_publishing ~ 0.5,
                           TRUE ~ 0.3),
         point_size = case_when(designer == top_rated ~ 2,
                          designer == ""Overall"" ~ 2,
                          designer == top_publishing ~ 2,
                          TRUE ~ 1),
         line = case_when(designer == top_rated ~ ""solid"",
                           designer == ""Overall"" ~ ""dashed"",
                           designer == top_publishing ~ ""solid"",
                           TRUE ~ ""solid""))

plot <- ggplot(plot_data, aes(x = year_published, y = year_avg_rating, group = designer)) +
  geom_path(aes(color = color, alpha = alpha, linetype = line, size = size)) +
  geom_point(aes(fill = color, alpha = alpha, size = point_size), color = ""white"", shape = 21) +
  annotate(""label"", x = 1989.8, y = 2, label = ""Most Prolific: Reiner Knizia with 229 published games."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""dodgerblue"", hjust = 0) +
  annotate(""segment"", x = 1990, xend = 1990, y = 2.3, yend = 5.5, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""dodgerblue"") +
  annotate(""label"", x = 2002, y = 9, label = ""Highest Average Rating: Mark H. Walker with a 7.70 rating."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""#eebd31"") +
  annotate(""segment"", x = 2002, xend = 2002.8, y = 8.8, yend = 7.7, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""#eebd31"") +
  scale_y_continuous(limits = c(0, 10), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_color_identity() +
  scale_linetype_identity() +
  scale_size_identity() +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL,
       title = ""It's Not A Habit, It's Cool, I'm a Prolific Game Designer"",
       subtitle = str_wrap(""A comparison from 1990 to 2016 of the the top rated and top published designer amongst those with 10 or more published games. Red dashed line represents the overall average designer rating."", 150),
       caption = ""Data: Board Game Geek | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"")

ggsave(here(""2019"",""week11"", ""tw11_plot.png""), width = 12, height = 6)
","2019-11"
"15",15,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week13/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(fs)
library(janitor)
library(jkmisc)

pet_licenses <- here(""2019"", ""week13"", ""data"") %>% 
  dir_ls(regexp = ""Seattle"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  mutate_at(""license_issue_date"", mdy)

burst_name <- function(df) { 
  
  df %>% 
    distinct(license_issue_date) %>% 
    pull(license_issue_date) %>% 
    kleinberg()
    
  }

out <- pet_licenses %>% 
  filter(!is.na(animals_name)) %>% 
  mutate(animals_name = str_to_lower(animals_name)) %>% 
  group_by(animals_name) %>% 
  filter(n() >= 100) %>% 
  nest() %>% 
  mutate(bursts = map(data, burst_name)) %>% 
  unnest(bursts) %>% 
  arrange(desc(animals_name), level) %>% 
  mutate(id = ntile(animals_name, 1)) %>%
  mutate(color = case_when(level == 1 ~ ""grey50"",
                           level == 2 ~ ""#6baed6"",
                           level == 3 ~ ""#3182bd"",
                           level == 4 ~ ""#08519c""),
         alpha = case_when(level == 1 ~ 0.5,
                           level == 2 ~ 1,
                           level == 3 ~ 1,
                           level == 4 ~ 1)) %>% 
  ungroup()

facet_labels <- out %>% 
  group_by(id) %>% 
  summarize(label = sprintf(""%s to %s"", last(str_sub(animals_name, 1, 1)), first(str_sub(animals_name, 1, 1)))) %>% 
  pull(label) %>% 
  set_names(., sort(unique(out$id)))

order <- out %>% 
  filter(level == 1) %>% 
  arrange(desc(start)) %>% 
  pull(animals_name)

plot <- ggplot(out) +
  geom_segment(aes(x = start, xend = end, y = factor(animals_name, order), yend = factor(animals_name, order), color = color, alpha = alpha), size = 4, lineend = ""square"") +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_x_date(limits = c(ymd(""2006/01/01""),ymd(""2019/01/01"")),  date_breaks = ""1 year"", date_labels = ""%Y"", expand = c(0.02, 0)) +
  scale_y_discrete(position = ""right"") +
  theme_jk(grid = ""XY"") +
  labs(x = NULL,
       y = NULL,
       title = ""What is it, Lassie? 'Bark! Bark-bark-bark! Bark-bark!' What, Timmy's fallen in the well?"",
       subtitle = str_wrap(""Illustrated below is the recorded use of and bursts in popularity of registered pet names (frequency of use > 100) in Seattle from 2006 to 2019.  The grey bar indicates the duration the name is in use, and the blue segments indicate bursts of increased use of the name.  Darker blue segments represent repeated bursts indicating an increased intensity of use."", 100),
       caption = ""Data: seattle.gov | Graphic: @jakekaupp"")

ggsave(here(""2019"",""week13"",""tw13_plot.png""), plot, width = 8, height = 10, type = ""cairo-png"")
","2019-13"
"16",16,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week14/R/analysis.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(here)
library(patchwork)

bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

clean_bikes <- bike_traffic %>% 
  mutate(date = mdy_hms(date),
         month = month(date),
         year = year(date)) %>% 
  filter(between(year, 2014, 2018))

by_year <- clean_bikes %>% 
  group_by(year, month, crossing) %>% 
  summarize(total_bikes = sum(bike_count, na.rm = TRUE)) 

glyph <- ggplot(by_year, aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 1, aes(color = crossing)) +
  facet_grid(year ~ month, labeller = labeller(.cols = set_names(month.abb, 1:12)), switch = ""y"") +
  scale_color_manual(values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
  labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180),
        legend.position = ""none"")

main <- by_year %>% 
  filter(year == 2015, month == 1) %>% 
  ggplot(aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 3, aes(color = crossing)) +
  scale_color_manual(""Crossing"", values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
   labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180))

plot <- wrap_plots(list(main, glyph), widths = c(0.25, 0.75)) +
  plot_annotation(title = ""Annual Patterns in Seatle Bicycle Traffic"", 
                  subtitle = str_wrap(""This chart is glyph plot using multiple parallel coordinates plots to illustrate the monthly bike traffic at Seattle crossings.  A  colored dot represents each crossing and vertical position represents the total number of riders counted each month.  You can observe the year over year trends, as well as see which crossings experience cyclical patterns and which remain stable."", 155),
                  theme = theme_jk())

ggsave(here(""2019"", ""week14"", ""tw14_plot.png""), plot, width = 12, height = 6)
","2019-14"
"17",17,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week15/R/analysis.R","library(tidyverse)
library(lubridate)
library(ggbeeswarm)
library(here)
library(jkmisc)
library(nord)

player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")


plot_data <- player_dob %>% 
  select(name, date_of_birth) %>% 
  left_join(grand_slams, by = ""name"") %>% 
  mutate(age = interval(date_of_birth, tournament_date)/years(1)) %>% 
  group_by(name) %>% 
  filter(n()>1)
  

order <- plot_data %>% 
  group_by(name) %>% 
  filter(rolling_win_count == max(rolling_win_count)) %>% 
  arrange(rolling_win_count) %>% 
  pull(name)
  

plot <- ggplot(plot_data, aes(x = age, y = factor(name, order), size = rolling_win_count, color = gender, alpha = rolling_win_count)) +
  geom_point(aes(group = name)) + 
  facet_wrap(~gender, scales = ""free_y"") +
  scale_color_manual(values = c(""#C01E65"",""#117AB3"")) +
  scale_size_area(""Rolling Win Count"") +
  guides(size = guide_legend(override.aes = list(shape = 21, color = ""black"")), color = FALSE, alpha = FALSE) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  labs(x = NULL,
       y = NULL,
       title = ""Bright Stardom or Fading Obscurity: Looking at Players Major Wins Across their Careers."",
       subtitle = str_wrap(""The chart plots cumulative major wins against player age. Size and transparency of each point are mapped to the cumulative number of majors won.  Looking at the data, we can see the hot streaks in individual players, as well as the dominance of certain champions."", 110),
       caption = ""Data: wikipedia | Graphic: @jakekaupp"")
  
ggsave(here(""2019"",""week15"",""tw15_plot.png""), type = ""cairo"", width = 10, height = 12)
","2019-15"
"18",18,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week16/R/analysis.R","library(tidyverse)
library(here) 
library(jkmisc)
library(ggalt)
library(grid)
library(Cairo)

dogs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

png(file = here(""2019"", ""week16"", ""tw16_plot.png""), width = 4, height = 4, units = ""in"", res = 300, type = ""cairo"")
                       
ggplot(dogs, aes(x = avg_weight, y = avg_neck)) +
  geom_xspline(size = 1) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 0.5, size = 2) +
  geom_text(data = filter(dogs, year == min(year)), aes(label = year), hjust = 0, nudge_x = 0.1, nudge_y = 0.01, family = ""Oswald"", size = 3) +
  geom_text(data = filter(dogs, year == max(year)), aes(label = year), hjust = 1, nudge_x = -0.1, family = ""Oswald"", size = 3) +
  annotate(""segment"", arrow = arrow(length = unit(0.2, ""cm""), type = ""closed""), x = 20.48, xend = 20.2, y = 44.3, yend = 44.03) +
  scale_y_continuous(limits = c(42, 45), breaks = 42:45) +
  expand_limits(x = c(17.5, 21)) +
  labs(title = ""Fit as a butcher's dog"",
       subtitle = ""Characteristics of dogs registered with the UK's\nKennel Club, average when fully grown"",
       x = bquote(""Weight*, kg""),
       y = NULL,
       caption = ""Sources: Kennel Club;\n The Economist "") +
  theme_jk(grid = ""XY"") +
  theme(plot.caption = element_text(hjust = -0.1))

grid.text(expression(paste(Neck~size, "", "", cm^""\u2020"")), x = 0.1, y = 0.78, gp = gpar(fontfamily = ""Oswald"", cex = 0.8))
grid.text(bquote(""* Where at leat 50 are registered per year""), x = 0.98, y = 0.075, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)
grid.text(expression(""\u2020""~Where~at~least~100~are~registered~per~year), x = 0.98, y = 0.040, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)

dev.off()
","2019-16"
"19",19,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week17/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

plot_data <- tidy_anime %>% 
  mutate(title = coalesce(title_english, name)) %>% 
  mutate(end_date = if_else(is.na(end_date), as.Date(""2019-04-01""), end_date)) %>% 
  mutate(interval = interval(start_date, end_date)) %>% 
  filter(type != ""Unknown"") %>% 
  distinct(animeID, .keep_all = TRUE) 


scaffold <- tibble(year = rep(1917:2019, each = 6),
       type = rep(c(""Movie"", ""Music"", ""ONA"", ""OVA"", ""Special"", ""TV""), length(1917:2019))) 

timeline <- scaffold %>% 
  mutate(count = map2_dbl(year, type, ~nrow(filter(plot_data, ymd(sprintf(""%s/01/01"", .x)) %within% interval , type == .y))))

order <- timeline %>% 
  filter(year == last(year)) %>% 
  arrange(desc(count)) %>% 
  pull(type)

# Area ----
area <- timeline %>% 
  mutate(type = factor(type, order, order)) %>% 
  ggplot(aes(x = year, y = count)) +
  geom_area(aes(fill = type)) +
  scale_fill_manual(""Anime Type"", values = tol6qualitative) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_y_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Fourty Years of Growth: The Rapid Rise of Anime"",
       subtitle = str_wrap(""The area chart below presents the number of anime titles released from 1919 to the present by release type.  Anime releases have increased over 400% since the 1980s, to meet the increasing demand driven by the invention of the VCR, the internet and the rise of streaming media services."", 95),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE))

# Popularity vs Score Hexbin ----
hex <- ggplot(plot_data, aes(x = popularity, y = score)) +
  geom_hex() +
  facet_wrap(~type, nrow = 1) +
  scale_fill_viridis_c(option = ""plasma"") +
  scale_x_continuous(trans = ""reverse"", breaks = scales::pretty_breaks(), labels = c("""","""",""Higher\nPopularity"", """", ""Lower\nPopularity"", """")) +
  scale_y_continuous(breaks = scales::pretty_breaks(), limits = c(0,10)) +
  guides(fill = guide_colorbar(title = ""Titles per Hex""), alpha =""none"") +
  labs(x = NULL, 
       y = NULL,
       title = ""The Relationship Between Ratings and Popularity on MyAnimeList"",
       subtitle = str_wrap(""The chart below plots the ratings score (out of 10) against popularity (rank) for all anime titles and anime types.  The data were hexangonally binned to illustrate areas of high occurance. It appears that a relationship may exist between ratings and popularity, warranting further analysis."", 100),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"",""week17"",""tw17_hex.png""), hex, width = 8, height = 6)

ggsave(here(""2019"",""week17"",""tw17_area.png""), area, width = 8, height = 6)

","2019-17"
"20",20,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week18/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


flower <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.2) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar()) +
  coord_polar() +
  labs(x = NULL,
       y = NULL,
       title = ""Overall"") +
  theme_jk(dark = FALSE, grid = ""X"", strip_text_size = 10, plot_title_size = 14) +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

petals <- flower +
  aes(group = year) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  labs(title = ""By Species"") +
  facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7) 

legend <- plot_data %>% 
  filter(binomial_name == ""Setophaga fusca"") %>% 
  ggplot(aes(x = month, y = percent, fill = binomial_name, group = year)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.1) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  annotate(""text"", x = 11, y = 0.8, label = ""One year of\ncollisions in October"", family = ""Scope One"", size = 3, hjust = 0) +
  annotate(""segment"", x = 10.8, y = 0.8, xend = 10, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  annotate(""text"", x = 3.5, y = 0.8, label = ""Multiple years of\ncollisions in May"", family = ""Scope One"", size = 3) +
  annotate(""segment"", x = 3.8, y = 0.8, xend = 5, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""How to Interpret This Chart"",
       subtitle = str_wrap(""A flower represents the recorded total collisions of each bird species with the individual petals representing the normalized events during each year (from 0-1).  The position of the petals indicates the month or months collisions occur, with overlaps indicating repeated year-over-year collisions."", 70)) +
  guides(fill = guide_colorbar()) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- wrap_plots(flower / legend, petals, ncol = 2, widths = c(1, 2)) +
  plot_annotation(title = ""Seasonality of Bird Collisions in Chicago"",
                  subtitle = str_wrap(""Presented below is a petal chart of of bird collisions, with instructions on how to interpret this chart in the lower left.  The upper left flower represents collisions recorded across all years and species, with individual species presented as small multiple flowers on the right."", 220),
                  caption = ""Data: Winger et al. (2019) Nocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. Proceedings of the Royal Society B 286(1900): 20190364. https://doi.org/10.1098/rspb.2019.0364 | Graphic: @jakekaupp"",
      theme = theme_jk())

ggsave(here(""2019"",""week18"", ""tw18_plot.png""), out, width = 16, height = 10, type = ""cairo"")



","2019-18"
"21",21,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week18/R/experiment.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)


bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))

petals <- plot_data %>% 
  filter(n != 0) %>% 
  split(list(.$year, .$month, .$binomial_name), drop = TRUE) %>% 
  map(~complete(.x, year, binomial_name, month = 1:12, fill = list(n = 0, percent = 0))) %>% 
  map(~geom_area(data = .x, aes(color = binomial_name), size = 0.2, alpha = 0.1))


base_plot <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- base_plot + petals + facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7)


ggsave(here(""2019"",""week18"", ""test.png""), plot = out)

","2019-18"
"22",22,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week19/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(fs)
library(jkmisc)
library(janitor)
library(countrycode)
library(patchwork)

ratio_data <- here(""2019"", ""week19"", ""data"") %>% 
  dir_ls(regexp = ""student_teacher_ratio"") %>% 
  read_excel(na = c("".."")) %>% 
  set_names(tolower(names(.))) %>% 
  gather(year, ratio, -1:-2,convert = TRUE)



plot_region <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, group = region, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~region, nrow = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") 
  
  }

plot_continent <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~continent, ncol = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    scale_shape_identity() +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") +
    theme(strip.text = element_blank())
  
}

plot_data <- ratio_data %>% 
  filter(type == ""Countries"") %>% 
  mutate(country_code = countrycode(country, ""country.name"", ""iso3c"")) %>% 
  mutate(region = countrycode(country_code, ""iso3c"", ""region"")) %>% 
  mutate(continent = countrycode(country_code, ""iso3c"", ""continent"")) %>% 
  filter(!is.na(region))

colors <- set_names(c(""#171635"", ""#00225D"", ""#763262"", ""#CA7508"", ""#E9A621""), c(unique(plot_data$continent)))

individual <- plot_data %>% 
  group_by(year, region, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_region) 

summary <- plot_data %>% 
  group_by(year, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_continent) 
  
plots <- map2(summary, individual, ~wrap_plots(.x, .y, nrow = 1, widths = c(1, 1)))
  
out <- wrap_plots(plots, ncol = 1) +
  plot_annotation(title = ""Working to Two Sigma: Student Teacher Ratios Improving Since the 1970s"",
                  subtitle = str_wrap(""Illustrated below is the average student to teacher ratio across each continent (left column) and region (right column).  Continent and region assigned from iso3c coding of country name and are consistent with the World Bank Dvelopment Indicators."", 210),
                  caption = ""Data: UNESCO Institute of Statistics | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"",""week19"",""tw19_plot.png""), out, width = 16, height = 10)
","2019-19"
"23",23,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week2/R/analysis.R","library(tidyverse)
library(ggraph)
library(tidygraph)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)
library(nord)

set.seed(42)

source(here(""2019"", ""week2"", ""R"", ""functions.R""))

# Read data from github repo
tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"") %>% 
  rename(title_id = titleId,
         season_number = seasonNumber) %>% 
  mutate(year = year(date))

# Make this into a nodes tibble
list <- tv_data %>% 
  split(.$year) %>% 
  map(share_packed_circle)

out <- wrap_plots(list, ncol = 10, nrow = 3) +
  plot_annotation(title = ""The Evolution and Differentiation of Dramas Across the Golden Age of Television"",
                  subtitle = str_wrap(""This chart presents a time series of circle-packed network representations of the television dramas.  
                                      The larger dark blue circle represents the year, light blue represents the genre (Action, Comedy, etc.) and the pale pink represents the individual program. 
                                      The area of each circle (node) is porportional to the sum of the audience share of the smaller circles within (child nodes)."", 180),
                  caption = ""data: IMDb | graphic: @jakekaupp"",
                  theme = theme_jk(plot_title_size  = 22, subtitle_size = 14) %+replace% theme(plot.background = element_rect(fill =""#2E3440""),
                                                      text = element_text(color = ""white"")))
 
ggsave(here(""2019"",""week2"", ""tt_week2.png""), out, width = 16, height = 8)
","2019-2"
"24",24,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week2/R/functions.R","share_packed_circle <- function(df) {
 
  nodes <- make_nodes(df)
  
  edges <- make_edges(df)
 
  mygraph <- tbl_graph(nodes = nodes, edges = edges)
  
  # Make the plot
  plot <- ggraph(mygraph, layout = 'circlepack', weight = ""size"") + 
    geom_node_circle(aes(fill = depth)) +
    theme_void() +
    labs(title = unique(df$year)) +
    coord_equal() +
    scale_fill_nord(""lumina"", discrete = FALSE, reverse = TRUE) +
    #scale_fill_viridis(option = ""plasma"") +
    theme(legend.position = ""none"", 
          plot.background = element_rect(fill = ""#4C566A""),
          plot.title = element_text(family = ""Oswald"", hjust = 0.5, color = ""white""),
          )
  
  return(plot)
}


make_nodes <- function(df) {
  
  size <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    distinct(genres, title, share) %>% 
    rename(name = title, size = share)
  
  genre_size <- size %>% 
    group_by(genres) %>% 
    summarize(size = sum(size)) %>% 
    rename(name = genres)
  
  title_size <- size %>% 
    ungroup() %>% 
    distinct(name, size) %>% 
    mutate(size = size)
  
  total_size <- df %>% 
    distinct(title, share) %>% 
    summarize(name = as.character(unique(df$year)),
              size = sum(share))
  
  sizes <- bind_rows(genre_size, title_size, total_size)
  
  nodes <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    gather(variable, name, title, genres, year) %>% 
    arrange(variable, name) %>% 
    distinct(name) %>% 
    left_join(sizes, by = ""name"") %>% 
    mutate(size = if_else(size == 0, 0.001, size)) %>% 
    arrange(size)
  
  return(nodes)
  
  
}

make_edges <- function(df) {
  
  base <- tibble(from = as.character(unique(df$year)), to = unique(df$genres))
  
  inner <- df %>% 
    select(from = genres, to = title) %>% 
    distinct() 
  
  edges <- bind_rows(base, inner) 
  
  return(edges)
  
}
","2019-2"
"25",25,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week20/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(rcrossref)
library(ggbeeswarm)
library(jkmisc)


# Not re-downloading things, the citation count pulls take 2hrs.
if (length(dir_ls(here(""2019"", ""week20"", ""data""))) <= 0) {
 
  nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
  nobel_winners_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")
  
  saveRDS(nobel_winners, here(""2019"", ""week20"", ""data"", ""nobel_winners.RDS""))
  
  saveRDS(nobel_winners_all_pubs, here(""2019"", ""week20"", ""data"", ""nobel_winners_all_pubs.RDS""))

  
} else {
  
  nobel_winners <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners.RDS"") %>% 
    readRDS()
  
  nobel_winners_all_pubs <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners_all_pubs.RDS"") %>% 
    readRDS()
 
}


if (length(dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""cite_count"")) <= 0) {

  dois <- nobel_winners_all_pubs$doi

  list  <- split(dois, rep(1:ceiling(length(dois)/50), each=50)[1:length(dois)])

wait_cr_citation_count <- function(doi, index, list_len) {
  
  print(sprintf(""%s complete"", scales::percent(index/list_len)))
  
  Sys.sleep(1)
  
  cr_citation_count(doi)
  
}

cite_count <- imap_dfr(list, ~wait_cr_citation_count(.x, .y, length = length(list)))

saveRDS(cite_count, here(""2019"", ""week20"", ""data"", ""cite_count.RDS"")) 

} else {
  
cite_count <- readRDS(here(""2019"", ""week20"", ""data"", ""cite_count.RDS""))
  
}

highlights <- c(""einstein, a"", ""hill, av"", ""heeger, a"")

plot_data <- nobel_winners_all_pubs %>%
  left_join(cite_count) %>%
  distinct(laureate_id, paper_id, .keep_all = TRUE) %>%
  select(pub_year, laureate_name, is_prize_winning_paper, count, category) %>% 
  replace_na(list(count = 0)) %>% 
  group_by(laureate_name, pub_year, category) %>%
  summarize(count = sum(count)) %>% 
  group_by(laureate_name) %>% 
  mutate(rolling_sum = cumsum(count)) %>% 
  mutate(color = if_else(laureate_name %in% highlights, ""#F24534"", ""#21344F""),
         alpha = if_else(laureate_name %in% highlights, 1, 0.2))


everyone <- filter(plot_data, laureate_name %notin% highlights)

focus <- filter(plot_data, laureate_name %in% highlights) %>% 
  ungroup() %>% 
  mutate(laureate_name = case_when(laureate_name == ""einstein, a"" ~ ""Einstein, A"",
                                   laureate_name == ""hill, av"" ~ ""Hill, AV"",
                                   laureate_name == ""heeger, a"" ~ ""Heeger, A"")) %>% 
  group_by(laureate_name)


plot <- ggplot(plot_data, aes(x = pub_year, y = rolling_sum, group = laureate_name)) +
  geom_step(aes(color = color, alpha = alpha)) +
  geom_step(data = focus, aes(color = color, alpha = alpha)) +
  geom_text(data = filter(focus, pub_year == last(pub_year)), aes(color = color, alpha = alpha, label = laureate_name), x = 2018, family = ""Oswald"", hjust = 0) +
  scale_x_continuous(limits = c(1900, 2100), breaks = c(1900, 1925, 1950, 1975, 2000, 2018)) +
  scale_y_continuous(breaks = scales::pretty_breaks(), labels = scales::number) +
  scale_color_identity() +
  scale_alpha_identity() +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  labs(x = NULL,
       y = NULL,
       title = ""Growth Patterns in How Often Nobel Prize Winning Researchers Are Cited"",
       subtitle = str_wrap(""Cummulative citation count by year (1900-2018).  Highlighted are A. Heeger (conductive polymers), A.V. Hill (heat and work in muscle) and A. Einstein (photoelecric effect). Each exhibit different citation patterns, likely attributed to the continued relevance and impact of their work."", 150),
       caption = ""Data: Li, Jichao; Yin, Yian; Fortunato, Santo; Wang Dashun, 2018, 'A dataset of publication records for Nobel laureates', https://doi.org/10.7910/DVN/6NJ5RN, Harvard Dataverse. | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"", ""week20"", ""tw20_plot.png""), plot, width = 12, height = 6)

","2019-20"
"26",26,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week21/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(fs)
library(janitor)
library(jkmisc)
library(patchwork)


# Plotting Function to make separate ordered stacked bars by group----
make_bars <- function(df, pals) {
  
  order <- df %>% 
    arrange(desc(other)) %>% 
    pull(country)
  
  labs <- c(""HIC"" = ""High Income Group"",
            ""UMI"" = ""Upper Middle Income Group"",
            ""LMI"" = ""Lower Middle Income Group"",
            ""LI"" = ""Low Income Group"")
  
  
  df %>% 
    gather(type, value, c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste"")) %>% 
    mutate(type = factor(type, c(""other"", ""inadequate_waste"", ""plastic_waste"", ""littered_waste""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
    mutate(country = factor(country, order)) %>% 
    mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
    ggplot() +
    geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
    coord_flip() +
    scale_fill_manual("""", values = pals) +
    scale_alpha_identity() +
    scale_y_continuous(expand = c(0,0.05), labels = scales::percent) +
    labs(x = NULL, y = NULL) +
    facet_wrap(~economic_status, scales = ""free_y"", labeller = as_labeller(labs)) +
    theme_jk(grid = FALSE) +
    theme(legend.direction = ""horizontal"")
  
}


# Function to extract ggplot legends ----
extract_legend <- function(ggp){
  
  tmp <- ggplot_gtable(ggplot_build(ggp))
  
  leg <- which(map_lgl(tmp$grobs, function(x) x$name == ""guide-box""))
  
  legend <- tmp$grobs[[leg]]
  
  return(legend)}


# Read in Coastal Waste Data----
# Plastic waste inputs from land into the ocean
# BY JENNA R. JAMBECK, ROLAND GEYER, CHRIS WILCOX, THEODORE R. SIEGLER, MIRIAM PERRYMAN, ANTHONY ANDRADY, RAMANI NARAYAN, KARA LAVENDER LAW
# 
# SCIENCE13 FEB 2015 : 768-771

coastal_waste <- here(""2019"", ""week21"", ""data"") %>% 
  dir_ls(regexp = ""xlsx"") %>% 
  read_excel() %>% 
  clean_names() %>% 
  set_names(str_remove(names(.), ""_*[0-9]$"")) %>% 
  mutate(country = str_remove(country, ""[0-9]"")) %>% 
  mutate(country = case_when(str_detect(country, ""Palestine"") ~ ""Palestine"",
                             str_detect(country, ""Korea, South"") ~ ""South Korea"",
                             str_detect(country, ""Korea, North"") ~ ""North Korea"",
                             str_detect(country, ""Congo"") ~ ""Congo"",
                             TRUE ~ country)) %>% 
  filter(!grepl(""Burma"", country)) %>% 
  filter(complete.cases(.)) %>% 
  mutate(other = 100 - (percent_plastic_in_waste_stream + percent_inadequately_managed_waste + percent_littered_waste)) %>% 
  rename(plastic_waste = percent_plastic_in_waste_stream, inadequate_waste  = percent_inadequately_managed_waste, littered_waste = percent_littered_waste) %>% 
  mutate_at(c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste""), function(x) x/100) %>% 
  mutate(other = if_else(other < 0, 0, other)) %>% 
  mutate(total_waste = waste_generation_kg_day * 365/1000,
         total_plastic_waste = total_waste * plastic_waste,
         total_inadequate_waste = total_waste * inadequate_waste,
         total_littered =  total_waste * littered_waste,
         other_waste = total_waste * other)


# Palette for plot----
pal <- c(""#F5F0F6"", ""#629460"", ""#385F71"", ""#2B4162"")

avg <- coastal_waste %>% 
  summarize(total_waste = mean(total_waste, na.rm = TRUE),
            other_waste  = mean(other_waste, na.rm = TRUE),
            total_plastic_waste  = mean(total_plastic_waste, na.rm = TRUE),
            total_inadequate_waste = mean(total_inadequate_waste, na.rm = TRUE),
            total_littered = mean(total_littered, na.rm = TRUE)) %>% 
  mutate(country = ""Global Average"")


order <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  pull(country) 



overall_mismanaged <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  gather(type, value, c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered"")) %>% 
  mutate(type = factor(type,  c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
  mutate(country = factor(country, rev(order))) %>% 
  mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
  mutate(strip = ""Top 50 Producers & Global Average of Total Indequately Managed Waste (kg)"") %>% 
  ggplot() +
  geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
  coord_flip() +
  scale_fill_manual("""", values = pal) +
  scale_alpha_identity() +
  scale_y_continuous(expand = c(0,0.05), labels = scales::comma) +
  labs(x = NULL, y = NULL) +
  facet_wrap(~strip) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""none"")


# Make plots----
list <- coastal_waste %>% 
  split(.$economic_status) %>% 
  map(make_bars, pal)

# Extract legend----
legend <- extract_legend(list[[1]])

# Remove legend from list of plots----
list <- map(list, ~.x + theme(legend.position = ""none""))
  
# Finish plot----
out <- (overall_mismanaged + wrap_plots(list[c(""HIC"", ""UMI"", ""LMI"", ""LI"")], nrow = 1) + plot_layout(widths = c(0.3, 0.7))) / legend + plot_layout(heights = c(0.95, 0.05)) +
  plot_annotation(title = ""The Relationship Between World Bank Income Classification and Mismanaged Waste"",
                  subtitle = str_wrap(""Illustrated below is the percentage of waste by category for each country by World Bank income classification.  The lower the classification, the higher the mismanaged waste.  Much of this mismanaged waste (especially plastics) ends up in waterways that ultimately lead to our oceans, suggesting that global income inequality plays a role in ocean pollution by hampering the implementation of effective waste management strategies."", 240),
                  caption = ""Data: Jambeck, Jenna R., et al. 'Plastic waste inputs from land into the ocean.' Science 347.6223 (2015): 768-771. | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"", ""week21"", ""tw21_plot.png""), out, width = 19, height = 12)



","2019-21"
"27",27,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week22/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(ggridges)
library(tidytext)
library(countrycode)
library(ggwordcloud)
library(patchwork)

source(here(""2019"", ""week22"", ""R"", ""packed_bars.R""))

wine_ratings <- here(""2019"", ""week22"", ""data"", ""winemag-data-130k-v2.csv"") %>% 
  read_csv()

wine_counts <- wine_ratings %>% 
  count(country) %>% 
  mutate(max_rel_val = n/sum(n)) %>% 
  filter(!is.na(country))
 
summary_ratings <- wine_ratings %>% 
  group_by(country) %>% 
  summarize_at(c(""points"",""price""), mean, na.rm = TRUE) %>% 
  filter(!is.na(country))

summary_data <- left_join(wine_counts, summary_ratings)

plot_data <- pack_bars(summary_data, number_rows = 4, max_rel_val)

packed_bar <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"") +
  geom_text(data = filter(plot_data, fill == ""#4B384C""), aes(x = xmin, y = (ymin + ymax)/2, label = country), family = ""Oswald"", color = ""white"", nudge_x = 0.01, hjust = 0) +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

word_counts <- wine_ratings %>%
  select(country, description) %>%
  group_by(country) %>% 
  filter(n() > 2) %>% 
  filter(!is.na(country)) %>% 
  unnest_tokens(word, description) %>% 
  anti_join(stop_words) %>% 
  count(country, word) %>% 
  mutate(word = trimws(word)) %>% 
  filter(!str_detect(word, ""[0-9]""), !str_detect(word, ""aroma|wine|note|nose|notes|aromas|drink|drinks|feel|feels|finish"")) %>% 
  group_by(country) %>% 
  top_n(300, n) 

clouds <- word_counts %>% 
  ungroup() %>% 
  mutate(iso2 = tolower(countrycode(country, ""country.name"", ""iso2c"")),
         iso2 = if_else(country == ""England"", ""gb"", iso2)) %>% 
  filter(country %in%  c(""US"", ""France"", ""Italy"", ""Spain"")) %>% 
  mutate(country = factor(country, levels = c(""US"", ""France"", ""Italy"", ""Spain"")),
         iso2 = factor(iso2, levels = c(""us"",""fr"", ""it"", ""es""))) %>% 
  group_by(iso2) %>% 
  nest() %>% 
  arrange(iso2) %>% 
  mutate(clouds =  map2(iso2, data, create_wc))

word_clouds <- wrap_plots(clouds$clouds, ncol = 1) 

out <- packed_bar + word_clouds +
  plot_annotation(title = ""Wine-ing: The Top 4 Countries and What Reviewers Say About Their Wines"",
                  subtitle = str_wrap(""On the left, a packed bar chart showing the % of reviewed wines by country.  On the right, wordclouds of the top 300 most frequent terms used in reviews."", 100),
                  caption = ""Data: Kaggle via WineEnthusiast | Graphic: @jakekaupp"",
                  theme = theme_jk()
                  )

ggsave(here('2019', ""week22"", ""tw22_plot.png""), out, width = 8, height = 12)

ggsave(here('2019', ""week22"", ""packed_bar.png""), packed_bar + labs(title = ""Top 4 Countries Reviewed as Packed Bar Chart"",
                                                                   subtitle = str_wrap(""The visualizion below is a packed bar chart, developed by Xan Gregg.  It combines the ordered nature of a bar chart with the total view and condensed nature of a treemap.  Colour denotes the focus, while the each gray sections represents each other reviwed country. This gives a sense of how many secondary categories there are, their magnitude and distribution. Additionally, since they are on the same scale of the focused bars we can even estimate some of the values from the length they span on the axis."", 100)), width = 8, height = 6)
","2019-22"
"28",28,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week22/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- summary_data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- summary_data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}


create_wc <- function(iso2, data) {
  
  cntry_mask <- png::readPNG(here(""2019"", ""week22"", ""data"", ""png maps"", iso2, ""1024.png""))
  
  ggplot(data, aes(label = word, size = n)) +
    geom_text_wordcloud(family = ""Oswald"", mask = cntry_mask, rm_outside = TRUE) +
    scale_radius(range = c(0, 40)) +
    theme_jk() 
  
  
}
","2019-22"
"29",29,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week23/R/analysis.R","library(tidyverse)
library(glue)
library(rvest)
library(xml2)
library(lubridate)
library(here)
library(jkmisc)



#Scraping functions----

get_urls <- function(sitemap_url) {
  
  read_xml(sitemap_url) %>%
    xml_children() %>% 
    xml_children() %>% 
    xml_text() %>% 
    keep(~str_detect(.x, ""https://www.theramenrater.com/[0-9]{4}/[0-9]{2}/[0-9]{1,}/\\w+""))
  
}

get_post_title <- function(url, idx, rows) {
  
  print(sprintf(""Progress: %s/%s"", idx, rows))
  
  read_html(url) %>% 
    html_node("".entry-title"") %>% 
    html_text()
  
  
}

slowly_get_post_title <- slowly(~ get_post_title(.x, .y, rows), rate = rate_delay(pause = 0.5), quiet = TRUE)

#Week of month
wom <- function(date) { # week-of-month
  first <- wday(as.Date(paste(year(date), month(date), 1, sep=""-"")))
  return((mday(date) + (first - 2)) %/% 7 + 1)
}

#Plotting functions----
month_outline <- function(df) {
  
  top1 <- with(df, tibble(x = min(wmonth) - 0.5,
                          xend = wday[day == min(day)] - 0.5,
                          y = wmonth[day == min(day)] + 0.5,
                          yend = wmonth[day == min(day)] + 0.5,
                          line = ""top1"")) 
  
  top2 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                          xend = max(wday) + 0.5,
                          y = min(wmonth) - 0.5,
                          yend = min(wmonth) - 0.5,
                          line = ""top2"")) 
  
  left1 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                           xend = wday[day == min(day)] - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = min(wmonth) - 0.5,
                           line = ""left1""))
  
  left2 <- with(df, tibble(x = min(wmonth) - 0.5,
                           xend = min(wmonth) - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = wmonth[day == max(day)] + 0.5,
                           line = ""left2""))
  

  right1 <- with(df, tibble(x = max(wday) + 0.5,
                            xend = max(wday) + 0.5,
                            y = min(wmonth) - 0.5,
                            yend = wmonth[day == max(day)] - 0.5,
                            line = ""right1""))
  
  right2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                            xend = wday[day == max(day)] + 0.5,
                            y = wmonth[day == max(day)] - 0.5,
                            yend = wmonth[day == max(day)] + 0.5,
                            line = ""right2""))

  
  bottom1 <- with(df, tibble(x = min(wmonth) - 0.5,
                             xend = wday[day == max(day)] + 0.5,
                             y = wmonth[day == max(day)] + 0.5,
                             yend = wmonth[day == max(day)] + 0.5,
                             line = ""bottom1""))
  
  bottom2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                             xend = max(wday) + 0.5,
                             y = wmonth[day == max(day)] - 0.5,
                             yend = wmonth[day == max(day)] -0.5,
                             line = ""bottom2""))
  
  top <- bind_rows(top1, top2)
  left <- bind_rows(left1, left2)
  bottom <- bind_rows(bottom1, bottom2) 
  right <- bind_rows(right1, right2) 
    
    bind_rows(top, left, right, bottom) %>% 
      mutate(year = unique(df$year),
             month = unique(df$month)) 
    
  
}


if(!file.exists(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))) {
  
  # Add Recent ratings #3181-319
  recent_ratings <- tibble(review_number = c(3181:3189, 1676, 2745, 2991),
                           stars = c(3.75, 3.25, 4.0, 3.25, 2.0, 3.75, 3.75, 3.5, 2.25, 4.25, 5, 3.25),
                           brand = c(""Nissin Yakisoba"", ""Maruchan"", ""Uni-President"", ""Maruchan"", ""Sakruai Foods"", ""Nissin Mago"", ""Big Bon"", ""Sapporo Ichiban"", ""Canton"", ""A1"", ""Nissin"", ""Big Bon""),
                           variety = c(""Instant Panict Savory Beef Flavour"", ""Maruchan Ramen Noodle Soup Roast Beef Flavour"", ""Imperial Big Meal Super Hot Pot Beef Flavour"",
                                       ""Ramen Noodle Soup Pork Beef Flavour"", ""Vegetarian Stir Fry Noodles"", ""Nissin Lamen Light Legumes "", ""Spice Mix Piquant"", ""Momosan Ramen Tokyo Chicken"", ""Instant Noodles Spicy Tomato"",
                                       ""Emperor Herbs Chicken Noodle"", ""U.F.O. Big Wasabi-Mayo Yakisoba"", ""Chicken & Salsa Sauce Instant Noodles""),
                           country = c(""Phillipines"", ""United States"", ""Taiwan"", ""United States"", ""Japan"", ""Brazil"", ""Russia"" , ""United States"", ""India"", ""Malaysia"", ""Japan"", ""Russia""),
                           style = c(""Cup"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack""))
  
  # Read tidytesday data----
  ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"") %>% 
    bind_rows(recent_ratings)
  
  out <- tibble(sitemap_url = glue(""https://www.theramenrater.com/post-sitemap{1:5}.xml""),
                contents = map(sitemap_url, get_urls)) %>% 
    unnest() 
  
  rows <- nrow(out)
  
  # Scrapin der web purges----
  out <-  out %>% 
    mutate(title = imap(contents, ~slowly_get_post_title(.x, .y, rows))) %>% 
    mutate(date = parse_date(str_extract(contents, ""[0-9]{4}/[0-9]{2}/[0-9]{1,}""), ""%Y/%m/%d""),
           review_number = as.numeric(str_extract(title, ""(?!#)[0-9]{1,4}(?=\\:)""))) %>% 
    filter(!is.na(review_number)) %>% 
    left_join(ramen_ratings) %>% 
    filter(review_number < 4000) %>% 
    select(-sitemap_url)
  
  # Saving the new dataset----
  saveRDS(out, here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
} else {
  
  ramen_data <- readRDS(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
}

#Make months
all_dates <- tibble(date = seq.Date(from = ymd(""2009/01/01""), to =ymd(""2019/12/31""), by =""day"")) %>% 
  mutate(day = day(date),
         month = month(date),
         year = year(date))

plot_data <- ramen_data %>%
  mutate(day = day(date),
         month = month(date),
         year = year(date)) %>% 
  group_by(year, month, day) %>% 
  summarize(brands = toString(sprintf(""%s: %s"", brand, variety)),
            count = n(),
            avg_stars = mean(stars)) %>% 
  right_join(all_dates) %>% 
  ungroup() %>% 
  mutate(wday = wday(date, label = TRUE, week_start = 7),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date))
  
outlines <- all_dates %>% 
  mutate(wday_label = wday(date, label = TRUE),
         wday = wday(date),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date)) %>% 
  split(list(.$year, .$month), drop = TRUE) %>% 
  map_df(month_outline)



plot <- ggplot(data = plot_data, aes(x = wday, y = wmonth, fill = avg_stars)) +
  geom_tile(color = ""grey80"", size = 0.1) +
  geom_segment(data = outlines, aes(x = x, xend = xend, y = y, yend = yend, group = line), color = ""grey30"", inherit.aes = FALSE) +
  scale_y_continuous(trans = ""reverse"", labels = NULL) +
  scale_x_discrete(labels = NULL) +
  scale_fill_gradientn(""Average Stars"", colors = rev(parula(100)), na.value = ""grey95"") +
  facet_grid(month ~ year, switch = ""y"") +
  labs(x = NULL,
       y = NULL,
       title = ""The Prolfic Nature of the Ramen Rater and a Birds-Eye View of Ramen Quality"",
       subtitle = str_wrap(""Below is a heatmap calendar of the all the Ramen Raters ramen ratings by the published date of the review.  In the early days, multiple reviews were posted in a single day, until reaching the usual pattern of a single review per day.  However, there are still some reviews that get posted en masse."", 100),
       caption = ""Data: The Ramen Rater | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE) +
  theme(strip.text.y = element_text(angle = 180),
        panel.spacing.y = unit(-0.2, ""lines""),
        legend.position = ""bottom"")

ggsave(here(""2019"", ""week23"", ""tw23_plot.png""), height = 11, width = 8.5, type = ""cairo"")





  
","2019-23"
"30",30,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week24/R/analysis.R","library(nord)
library(tidyverse)
library(ggmap)
library(here)
library(countrycode)
library(jkmisc)
library(patchwork)

source(here(""2019"", ""week24"", ""R"", ""packed_bars.R""))

if (!file.exists(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))) {
  
  slow_revgeocode <- slowly(~revgeocode(.x, output = ""address""), rate = rate_delay(0.03), quiet = TRUE)
  
  reverse_geocoded <- meteorites %>% 
    distinct(long, lat) %>% 
    mutate(location = map2_chr(long, lat, ~slow_revgeocode(c(.x, .y))))
  
  saveRDS(reverse_geocoded, here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
} else {
  
  meteorite_locations <- readRDS(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
}

meteorites <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

meteorites <- left_join(meteorites, meteorite_locations) %>% 
  mutate(country_code = countrycode(location, ""country.name"", ""iso3c"")) %>% 
  mutate(country_code = case_when(str_detect(location, ""UK"") ~ ""GBR"",
                                  str_detect(location, ""USA"") ~ ""USA"",
                                  str_detect(location, ""China"") ~ ""CHN"",
                                  str_detect(location, ""Philippines"") ~ ""PHL"",
                                  str_detect(location, ""Serbia"") ~ ""RUS"",
                                  str_detect(location, ""Australia"") ~ ""AUS"",
                                  str_detect(location, ""Chile"") ~ ""CHL"",
                                  str_detect(location, ""Shopian"") ~ ""IND"",
                                  str_detect(location, ""Argentina"") ~ ""ARG"",
                                  str_detect(location, ""Bass Strait"") ~ ""AUS"",
                                  TRUE ~ country_code)) %>% 
  mutate(country_code = case_when(str_detect(name, ""Indarch"") ~ ""AZE"",
                                  str_detect(name, ""Oum Dreyga"") ~ ""ESH"",
                                  str_detect(name, ""Zag"") ~ ""ESH"",
                                  str_detect(name, ""Al Haggounia"") ~ ""ESH"",
                                  str_detect(name, ""Bou Kra"") ~ ""ESH"",
                                  TRUE ~ country_code)) %>% 
  rename(iso3c = country_code) %>% 
  filter(!is.na(iso3c)) 


world_tile_grid <- read_csv(""https://gist.githubusercontent.com/maartenzam/787498bbc07ae06b637447dbd430ea0a/raw/9a9dafafb44d8990f85243a9c7ca349acd3a0d07/worldtilegrid.csv"")

meteorite_wtg <- meteorites %>% 
  group_by(iso3c) %>% 
  summarize(n = n(),
            mass = sum(mass, na.rm = TRUE)/1000) %>%
  mutate(per_meteorite = mass/n) %>% 
  right_join(world_tile_grid, by = c(""iso3c"" = ""alpha.3"")) %>% 
  mutate(text_color = if_else(per_meteorite < 1, ""white"", ""black"")) %>% 
  replace_na(list('alpha.2' = ""NA"",
                  ""text_color"" = ""black"")) 


meteorite_map <- ggplot(meteorite_wtg, aes(x, y, fill = odds, group = iso3c)) +
  geom_tile(color = ""grey30"", size = 0.1) +
  geom_text(aes(label = alpha.2, color = text_color), family = ""Oswald"") +
  labs(x = NULL,
       y = NULL) +
  scale_y_reverse() +
  scale_fill_viridis_c(name = ""Average Metorite Mass (kg, log scale)"",option = ""cividis"", na.value = ""white"", breaks = c(1, 10, 100, 1000, 10000, 100000), guide = guide_colourbar(title.position = ""top"", title.hjust = 0)) +
  scale_color_identity() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.direction = ""horizontal"",
        legend.key.width = unit(2, ""lines""),
        legend.position = c(0.2, 0.05))


plot_data <- meteorite_wtg %>%
  select(alpha.2, n) %>% 
  mutate(n = log10(n)) %>% 
  replace_na(list(n = 0)) %>% 
  pack_bars(10, value_column = n, fill_color = last(nord(""lumina"", 5)))


packed_bars <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"", size = 0.1) +
  geom_text(data = filter(plot_data, (xmax - xmin) > 0.1), aes(x = (xmin + xmax)/2, y = (ymin + ymax)/2, label = alpha.2), family = ""Oswald"", color = ""white"") +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())


out <- packed_bars + meteorite_map  + plot_annotation(title = ""You May Need More Than An Umbrella in Russia:  Where the Most, and Heaviest, Meteorites fall"",
                                                subtitle = str_wrap(""On the left is a packed bar chart showing the top 10 regions struck by the most meteorites, while the tile map on the right shows the average meteorite mass across all regions.  Both measures have been scaled logathrimically to aid in comparability."", 180),
                                                caption = ""Data: NASA | Graphic: @jakekaupp"",
                                              theme = theme_jk())

ggsave(here(""2019"", ""week24"", ""tw24_plot.png""), out, width = 14, height = 7)
","2019-24"
"31",31,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week24/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}

","2019-24"
"32",32,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week25/R/analysis.R","library(tidyverse)
library(waffle)
library(jkmisc)
library(here)

bird_counts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

top_10 <- bird_counts %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  group_by(genus) %>% 
  summarize(total = sum(how_many_counted_by_hour, na.rm = TRUE)) %>% 
  top_n(10, total) %>% 
  pull(genus)

by_genus <- filter(bird_counts, year >= 2000) %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  filter(genus %in% top_10) %>% 
  group_by(year, genus) %>% 
  summarize(counts_by_hour = sum(how_many_counted_by_hour, na.rm = TRUE))

colors <- set_names(gray.colors(10), top_10)

colors[""Anas""] <- ""#ffd45c""

ducks <- ggplot(by_genus, aes(values = counts_by_hour, fill = genus)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, nrow = 1, strip.position = ""bottom"") +
  coord_equal() +
  labs(title = str_to_title(""The Duck is one of the most noble, agile and intelligent creatures in the animal kingdom.""),
       subtitle = str_wrap(""Total counts per hour, of the top 10 genera from since 2000.  Duck counts (genus Anas) are highlighted in yellow, because if it looks like a duck, and quacks like a duck, we have at least to consider the possibility that we have a small aquatic bird of the family anatidae on our hands."", 120),
       caption = ""Data: www.birdscanada.org/ | Graphic: @jakekaupp"") +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  scale_fill_manual(values = colors) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(strip.text = element_text(size = rel(0.8)))

cobra_chicken <- bird_counts %>% 
  filter(year >=1950) %>% 
  group_split(species) %>% 
  map_dfr(~mutate(.x, color = if_else(species == ""Canada Goose"", ""#CB181D"", sample(gray.colors(255), 1)),
                  alpha = if_else(species == ""Canada Goose"", 1, 0.25))) %>%   
  ggplot(aes(x = year, y = how_many_counted_by_hour, group = fct_relevel(species, ""Canada Goose"", after = Inf), fill = color, alpha = alpha), color = ""grey30"") +
  geom_area() +
  scale_y_continuous(expand = c(0.01, 0.1), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = c(seq(1950, 2010, 10), 2017)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Rise Of The Cobra Chicken, the Scourge of the Hamilton Waterfront"",
       subtitle = str_wrap(""The Canada Goose, hilarious and aptly referred to as a 'Cobra Chicken' has been a threat to the delicate ecosystem of Hamilton's Harbor."", 120),
       caption = ""Data: www.birdscanada.org | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE, ticks = TRUE)
  

ggsave(here(""2019"", ""week25"", ""tw25_ducks.png""), ducks, width = 10, height = 4)
ggsave(here(""2019"", ""week25"", ""tw25_canada_goose.png""), cobra_chicken, width = 10, height = 4)
","2019-25"
"33",33,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week26/R/analysis.R","library(sf)
library(albersusa)
library(here)
library(jsonlite)
library(RCurl)
library(janitor)
library(jkmisc)
library(cowplot)
library(tidyverse)



# Get ufo  & pop. density data----
ufo_sightings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

pop_density <- read_csv(here(""2019"", ""week26"", ""data"", ""pop_density.csv""), skip = 1) %>% 
  clean_names() %>% 
  filter(target_geo_id2 > 1000) %>% 
  mutate(fips = str_pad(target_geo_id2, 5, side = ""left"", pad = ""0"")) %>% 
  select(fips, density = contains(""density""))

# Get alberusa us county sf object----
us_counties <- counties_sf()

# Conver the us ufo sightings to an sf object and join with the alberusa to the the county fips----
usa_sightings_fips <- ufo_sightings %>% 
  filter(country == 'us') %>% 
  st_as_sf(crs = 4326, coords = c(""longitude"", ""latitude"")) 

cont_usa_sightings <- st_join(us_counties, usa_sightings_fips) 



# Some are missing!----
missing <- st_join(usa_sightings_fips, us_counties)  %>% 
  filter(is.na(fips)) %>% 
  semi_join(ufo_sightings,.)

# Make a function to call to the fcc census block API----
geocode_fips <- function(latitude, longitude, index) {
  
  url <- sprintf(""https://geo.fcc.gov/api/census/block/find?latitude=%f&longitude=%f&format=json"",  latitude, longitude)
  
  response <- getURL(url)
  
  json <- fromJSON(response)
  
  print(index)
  
  as.character(json$County['FIPS'])
}

# Make this work insistently----
insistent_geocode <- insistently(~geocode_fips(..1, ..2, ..3), rate = rate_backoff())

# Make it return NA if it fails ----
poss_insistent_geocode <- possibly(~insistent_geocode(..1, ..2, ..3), otherwise = NA_character_)

# Get the missing fips ----

if(!file.exists(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))) {
  missing_fips <- missing %>% 
    distinct(latitude, longitude) %>% 
    mutate(index = row_number()) %>% 
    mutate(fips = pmap_chr(list(latitude, longitude, index), poss_insistent_geocode)) } else {
      
      missing_fips <- readRDS(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))
      
    }

# Join it back to missing to fill in fips ----
missing <- left_join(missing, missing_fips) %>% 
  dplyr::select(-index) 

# Bind rows back to cont_usa_sightings for full_usa data ----
full_usa <- cont_usa_sightings %>% 
  left_join(missing, by = c(names(ufo_sightings)[c(1:2,4:9)], ""state.x"" = ""state"")) %>% 
  mutate_at(vars(contains(""fips"")), as.character) %>% 
  mutate(fips = coalesce(`fips.x`, `fips.y`)) %>% 
  select(-fips.x, -fips.y, -state_fips, -county_fips, -latitude, -longitude)

# Summarize sightings, create a ratio and add in population densities----
plot_data <- full_usa %>% 
  group_by_at(.vars = vars(fips, name, lsad, census_area, state.y, iso_3166_2)) %>% 
  summarize(sightings = n()) %>% 
  ungroup() %>% 
  mutate(sightings_ratio = 100*sightings/sum(sightings)) %>% 
  left_join(pop_density)


# create 3 buckets for variables ---
quantiles_sightings <- plot_data %>%
  pull(sightings_ratio) %>%
  quantile(probs = seq(0, 1, length.out = 4))

quantiles_density <- plot_data %>%
  pull(density) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# create color scale that encodes two variables
# red for sightings and blue for population density
bivariate_color_scale <- tibble(
  ""3 - 3"" = ""#3F2949"", # high sightings, high density
  ""2 - 3"" = ""#435786"",
  ""1 - 3"" = ""#4885C1"", # low sightings, high density
  ""3 - 2"" = ""#77324C"",
  ""2 - 2"" = ""#806A8A"", # medium sightings, medium density
  ""1 - 2"" = ""#89A1C8"",
  ""3 - 1"" = ""#AE3A4E"", # high sightings, low density
  ""2 - 1"" = ""#BC7C8F"",
  ""1 - 1"" = ""#CABED0"" # low sightings, low density
) %>%
  gather(""group"", ""fill"")


# Assign each fips area to their correct group and assign the fill from the bivariate scale ----
plot_data <- plot_data %>%
  mutate(sightings_quantiles = cut(sightings_ratio,
                              breaks = quantiles_sightings,
                              include.lowest = TRUE),
    density_quantiles = cut(density,
                            breaks = quantiles_density,
                            include.lowest = TRUE),
    group = paste(as.numeric(sightings_quantiles), ""-"", as.numeric(density_quantiles))) %>%
  left_join(bivariate_color_scale, by = ""group"")


# Making ze plot ----
plot <- ggplot(plot_data) +
  geom_sf(aes(fill = fill), size = 0.05, color = ""#2b2b2b"") +
  scale_fill_identity() +
  labs(title = ""If A UFO Flew Over The Desert And No One Was Around To See It, Would Senators Be Briefed?"",
       subtitle = str_wrap(""Below is a bivariate choropleth map by county illustrating the relationship between the UFO sightings (% of recorded sightings since 1911) and population density (people per sq. mile circa 2010).  Densely populated coastal and lakeside areas along with the sparsely populated southwest have the highest sightings, whereas the less populous midwest and Alaska have lower percentages of sightings."", 110),
       caption = ""Data: NUFORC & 2010 US Census | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank()) +
  coord_sf(clip = ""off"")

# Making ze legend ---
bivariate_legend <- bivariate_color_scale %>% 
  separate(group, into = c(""sightings"", ""density""), sep = "" - "") %>%
  mutate_at(c(""sightings"", ""density""), as.integer)

legend <- ggplot(bivariate_legend) +
  geom_tile( aes(x = sightings, y = density, fill = fill)) +
  scale_fill_identity() +
  labs(x = expression(paste(""More Sightings "", symbol('\256'))),
       y = expression(paste(""More People "", symbol('\256')))) +
  theme_jk(grid = FALSE) +
  theme(axis.title = element_text(size = 6),
        axis.text = element_blank()) +
  coord_fixed(clip = ""off"")

finished_plot <- ggdraw() +
  draw_plot(plot, 0, 0, 1, 1) +
  draw_plot(legend, 0.75, 0.075, 0.2, 0.2)


ggsave(here(""2019"", ""week26"", ""tw26_plot.png""), plot = finished_plot, width = 10, height = 6)
","2019-26"
"34",34,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week28/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(glue)


squads <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")


data <- squads %>% 
  mutate(idx = goals/caps) %>% 
  filter(pos != ""GK"", caps > 0, goals > 0) %>% 
  mutate(pos = case_when(pos == ""DF"" ~ ""Defense"",
                         pos == ""FW"" ~ ""Forward"",
                         pos == ""MF"" ~ ""Mid-Field"")) %>% 
  mutate(desc = glue(""{club}\n{caps} Matches, {goals} Goals"")) %>% 
  mutate(pos = factor(pos, c(""Defense"", ""Mid-Field"", ""Forward"")))

means <- data %>% 
  group_by(pos) %>% 
  summarize(idx = mean(idx))

plot <- ggplot(data, aes(x = age, y = idx)) +
  geom_point(color = ""grey20"") +
  geom_mark_circle(aes(label = player, description = desc, filter = player == ""Khadija Shaw""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Lea Schller""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Ainon Phancha""), expand = unit(4, ""mm"")) +
  geom_hline(data = means, aes(yintercept = idx), color = ""firebrick"") +
  theme_jk() +
  facet_wrap(~pos, nrow = 1) +
  labs(y = NULL,
       x = ""Age"",
       title = ""Efficient Scorers Competing in the Womens World Cup by Position and Age"",
       subtitle = str_wrap(""Goals per games played in international play by player age.  Red line illustrates the average goals per game at each position.  The highly efficient players at each position are a mix of newcomers and seasoned veterans, illustrating consistency in some players through their career."", 120),
       caption = ""Data: data.world | Graphic : @jakekaupp"")

ggsave(here(""2019"", ""week28"", ""tw28_plot.png""), plot = plot, width = 10, height = 6)

","2019-28"
"35",35,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week29/R/analysis.R","library(tidyverse)
library(tricolore)
library(ggtern)
library(here)
library(jkmisc)
library(magick)

r4ds_members <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")


tern_plot <- Tricolore(r4ds_members, ""percent_of_messages_public_channels"",
          ""percent_of_messages_private_channels"",
          ""percent_of_messages_d_ms"", breaks = 5, show_data = FALSE)

legend <- tern_plot$key +
  labs(title = ""Color Legend"",
       x       = ""Public\nChannels"",
       y       = ""Private\nChannels"",
       z       = ""Direct\nMessages"") +
  theme_hidetitles() +
  theme_hidelabels() +
  theme_hideticks() +
  theme(plot.title = element_text(hjust = 0.5, family = ""Scope One"", size = 40),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One""))

png(here(""2019"", ""week29"", ""legend.png"")) 
legend
dev.off()

legend <- image_read(here(""2019"", ""week29"", ""legend.png""))

plot <- r4ds_members %>% 
  mutate(color = tern_plot$rgb,
         year = lubridate::year(date)) %>% 
  ggtern(aes(x = percent_of_messages_public_channels, y = percent_of_messages_private_channels, z = percent_of_messages_d_ms, color = color)) +
  geom_point(size = 3) +
  scale_color_identity() +
  labs(title = str_to_title(""The Dialogue in the R4DS Slack indicates an Open and Inclusive Learning Community""),
       subtitle = str_wrap(""Below is a ternary digram presenting the message composition in public channels, private channels and direct messages as a percentage.  Each day is represented by a point with the composition represented by position relative to each axes.  Composition is additionally encoded by color as illustrated on the inset legend."", 100),
       x       = ""Public\nChannels"",
       xarrow  = ""More Public Channel Messages"",
       y       = ""Private\nChannels"",
       yarrow  = ""More Private Channel Messages"",
       z       = ""Direct\nMessages"",
       zarrow  = ""More Direct Messages"",
       caption = ""Data: R4DS Community | Graphic: @jakekaupp"") +
  theme(panel.background = element_rect(fill = ""#2E3440""),
        panel.grid = element_line(color = ""#ffffff"", size = 0.1),
        panel.grid.minor = element_blank(),
        text = element_text(family = ""Oswald""),
        plot.subtitle = element_text(family = ""Scope One""),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One"")) +
  theme_showarrows() +
  theme_arrowlong() 


png(here(""2019"", ""week29"", ""tw29_plot.png""), width = 10, height = 8, units = ""in"", res = 200)
grid::grid.newpage()
plot
grid::grid.raster(legend, width = 0.18, height = 0.2, x = 0.75, y = 0.7)
dev.off()
","2019-29"
"36",36,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week3/R/analysis.R","library(tidyverse)
library(here)
library(nord)
library(jkmisc)
library(ggbeeswarm)
library(ggrepel)

agencies <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/agencies.csv"")

launches <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/launches.csv"")


us_launch_data <- launches %>% 
  filter(agency == ""US"" | state_code == ""US"") %>% 
  mutate(type = gsub(""Zenit-"", ""Zenit "", type),
         type = gsub(""/"", "" "", type),
         type = gsub(""Minotaur-"", ""Minotaur "", type)) %>% 
  separate(type, ""type"", sep = "" "", extra = ""drop"") %>% 
  mutate(type = if_else(type == ""Space"", ""Space Shuttle"", sprintf(""%s Program"",type))) %>% 
  mutate(label = if_else(type == ""Space Shuttle"" & category == ""F"", ""Challenger Disaster"", NA_character_)) %>% 
  group_by(type) %>% 
  filter(n() > 10)

plot <- ggplot(us_launch_data, aes(x = launch_year, y = type), size = 4) +
  geom_quasirandom(data = filter(us_launch_data, category == ""O""), alpha = 0.2, fill = nord(""polarnight"", 2)[2], shape = 21, groupOnX = FALSE) +
  geom_quasirandom(data = filter(us_launch_data, category == ""F""), fill = nord(""victory_bonds"", 5)[1], shape = 21, groupOnX = FALSE, color = ""grey30"", stroke = 0.2) +
  theme_jk(grid = ""XY"", dark = FALSE) +
  labs(x = NULL,
       y = NULL,
       title = ""From the Space Race to Space-X: 1548 Successes and 101 Failures of US Launch Vehicles from 1958-2018."",
       subtitle = str_wrap(""A beeswarm plot illustrating the success or failure of a launch vehicle program over time. Red dots indicate failed launches, grey dots indicate success.  Deeper grey colors indicate a higher frequency of success in a given year due to multiple launches. Only includes programs with more than 10 launches"", 120),
       caption = ""Data: JSR Launch Vehicle Database | Analysis: @jakekaupp"")

plot <- plot + annotate(""segment"", x = 1987, xend = 1986.2, y = 8.7, yend = 8.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1986, y = 9, label = ""Challenger Disaster"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1]) +
  annotate(""segment"", x = 1959, xend = 1958.2, y = 1.7, yend = 1.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1959, y = 2.5, label = ""First Communication\nSatellite Protoype"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0) +
  annotate(""segment"", x = 2015, xend = 2015, y = 5.5, yend = 3.1, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 2013, y = 6.5, label = ""SpaceX Falcon 9\nStrut Failure"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0)

ggsave(here(""2019"", ""week3"", ""tt_week3.png""), plot, width = 11, height = 5)

","2019-3"
"37",37,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week30/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  #mutate(airport_type = if_else(str_detect(airport, ""INTL""), ""INT"", ""DOM"")) %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  complete(incident_year = 1990:2018, state,  incident_month = 1:12, fill = list(n = 0)) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


state_flower_grid <- plot_data %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, 
       y = NULL) +
  coord_polar() +
  facet_geo(~ state, grid = ""us_state_grid2"") +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""))

flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Single colour petal represents a single collison event during this month"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1, breaks = c(seq(1990, 2020, by = 5))) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar(), color = ""none"") +
  labs(x = NULL, y = NULL) +
  coord_polar(clip = ""off"") +
  theme_jk(grid = ""XY"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())

finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.17, 0.4, 0.4)

out <- wrap_plots(finished_legend, state_flower_grid,  nrow = 1, widths = c(0.85, 1.2)) +
   plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                   subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft, with an inset legend showing assisting interpretation.  Wildlife collisions by state are presented as small multiples, geographically arranged.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                   caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                   theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot.png""), out, width = 16, height = 10, type = ""cairo"")


","2019-30"
"38",38,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week30/R/experiment.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent)) %>% 
  mutate(angle = 90 - (incident_month-1)*30,
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
         
         
big_flower <- ggplot(plot_data) +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.2, size = 0, color = ""white"") +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  theme_jk(grid = FALSE, plot_title_size = 12) +
  labs(x = NULL, y = NULL, title = ""National"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""),
        plot.title = element_text(hjust = 0.5)) +
  coord_equal() 

state_flower <- big_flower +
  facet_geo(~ state, grid = ""us_state_grid2"")


flower_axes_lines <- tibble(idx = 1:12,
                            angle = 90 - (idx-1)*30,
                            angle2 = ifelse(angle < 0, 360 + angle, angle),
                            radians = angle2*pi/180)

axes_lines <- function(radius) {
  
  tibble(segment = 1:6,
                     x = c(0, radius*cos(pi/3), radius*cos(pi/6), radius, radius*cos(pi/6), radius*cos(pi/3)),
                     xend = c(0, -radius*cos(pi/3), -radius*cos(pi/6), -radius, -radius*cos(pi/6), -radius*cos(pi/3)),
                     y = c(radius, radius*sin(pi/3), radius*sin(pi/6), 0, -radius*sin(pi/6), -radius*sin(pi/3)),
                     yend = c(-radius, -radius*sin(pi/3), -radius*sin(pi/6), 0, radius*sin(pi/6), radius*sin(pi/3))) 
  }

axes_labels <- function(radius) {
  tibble(month = 1:12,
                      label = month.abb[month],
                      x = c(axes_lines(radius)$x, axes_lines(radius)$xend),
                      y = c(axes_lines(radius)$y, axes_lines(radius)$yend))  }


flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_segment(data = axes_lines(2), aes(x = x, xend = xend, y = y , yend = yend), size = 0.1, color = ""#cccccc"", inherit.aes = FALSE) +
  geom_circle(aes(x0 = 0, y0 = 0, r = 2), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_circle(aes(x0 = 0, y0 = 0, r = 1), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.5, size = 0.1, color = ""white"") +
  geom_mark_circle(aes(x = 2*x0, y = 2*y0, label = glue(""{month.name[incident_month]}, {incident_year}""), description = ""Single colour long petal represents 100% of collison event during this month and year"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_mark_circle(aes(x = x0, y = y0, label = glue(""{month.name[incident_month]}, Multiple years""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_text(data = filter(axes_labels(2.15), label != ""Feb""), aes(x = x, y = y, label = label), inherit.aes = FALSE, family = ""Oswald"") +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  coord_fixed(clip = ""off"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())


finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.175, 0.4, 0.4)

state_flower_grid <- ggdraw() +
  draw_plot(state_flower, 0, 0, 1, 1) + 
  draw_plot(big_flower, 0.75, 0.15, 0.25, 0.25)

out <- wrap_plots(finished_legend, state_flower_grid, nrow = 1, widths = c(0.85, 1.2)) +
  plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                  subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft across the US from 1990-2018. Below this is an inset legend showing assisting interpretation of the plots.  On the right are wildlife-aircraft collisions by state presented as small multiples, geographically arranged, with an inset flower representing the National data. Petal length is the annual proportion of collisions in a given month.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                  caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                  theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot_remix.png""), out, width = 16, height = 10, type = ""cairo"")
","2019-30"
"39",39,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week31/R/analysis.R","library(tidyverse)
library(here)
library(ggbeeswarm)
library(jkmisc)

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")  
 
all_games <- video_games %>% 
  filter(!is.na(game), !is.na(metascore))  %>% 
  mutate(developer = tolower(developer),
         idx = row_number())

plot_data <- tibble(facet = c(""bioware"", ""valve"", ""ubisoft"", ""rockstar"", ""square enix""),
       data = list(all_games)) %>% 
  mutate(filtered = map2(data, facet, ~mutate(.x, option = case_when(str_detect(tolower(developer), .y) ~ ""selected"", 
                                                                     TRUE ~ ""other"")))) %>% 
  unnest(filtered) %>% 
  mutate(facet = case_when(facet == ""bioware"" ~ ""BioWare"",
                           facet == ""valve"" ~ ""Valve"",
                           facet == ""ubisoft"" ~ ""Ubisoft"",
                           facet == ""rockstar"" ~ ""Rockstar"",
                           facet == ""square enix"" ~ ""Square Enix"")) %>% 
  mutate(option = factor(option, c(""other"", ""selected""))) %>% 
  arrange(facet, option)



mean <- all_games %>% 
  summarize(metascore = mean(metascore, na.rm = TRUE)) %>% 
  pull(metascore)

min_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == min(metascore))

max_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == max(metascore)) %>% 
  mutate(game = if_else(str_detect(""FINAL FANTASY"", game), ""Final Fantasy IX"", game)) %>% 
  slice(1)

plot <- ggplot(plot_data) +
  geom_quasirandom(aes(y = metascore, x = 0, alpha = option, fill = option, size = option), shape = 21, method = ""tukey"", show.legend = FALSE) +
  geom_label(data = min_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = -2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_label(data = max_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = +2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_hline(yintercept = mean, color = ""firebrick"", size = 0.5, linetype = ""dashed"") +
  labs(x = NULL, 
       y = NULL,
       title = ""How Do The Big Developers Score Against The Competition on Steam?"",
       subtitle = str_wrap(""Presented below is a jittered strip plot of metascore by developer.  Titles worked on by that developer are highlighted in yellow, the average metascore (72) is shown as a dashed red line. Annotations show the top an bottom rated titles for each developer.  Sqaure and Ubisoft have the most titles with less than average reviews amongst the large developers."", 180),
       caption = ""Data: SteamSpy | Graphic: @jakekaupp"") +
  scale_size_manual(values = c(""other"" = 2, ""selected"" = 2)) +
  scale_y_continuous(limits = c(20, 100), breaks = seq(20, 100, 20)) +
  scale_fill_manual(values = c(""other"" = ""#E5E4E2"", ""selected"" = ""#ffd644"")) +
  scale_alpha_manual(values = c(""other"" = 0.05, ""selected"" = 1)) +
  theme_jk(grid = ""Y"", dark = TRUE) +
  facet_wrap(~facet, nrow = 1) +
  theme(strip.text = element_text(color = ""white""),
      axis.text.x = element_blank())

ggsave(here(""2019"", ""week31"", ""tw31_plot.png""), plot, width = 14, height = 8)
","2019-31"
"40",40,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week32/R/analysis.R","library(tidyverse)
library(ggforce)
library(here)
library(jkmisc)
library(patchwork)

bob_ross_paintings <- here(""2019"", ""week32"", ""data"", ""tidytuesday_201932_bob_ross_paintings.csv"")

data <- read_csv(bob_ross_paintings, col_names = c('episode', 'title', 'color', 'color_name')) %>% 
  mutate(season = parse_number(str_extract(episode, ""S\\d+"")),
         color = if_else(color == ""#FFFFFF"", ""grey80"", color))


plot_data <- data %>% 
  count(season, title, color_name, color) %>% 
  group_by(season, title) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  mutate(color_number = as.numeric(factor(color_name))) %>% 
  mutate(angle = (color_number-1)*(360/15),
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
  

plot_spiros <- function(data) {
  
season <- sprintf(""Season %s"",unique(data$season))
  
ggplot(data) +
  geom_spiro(aes(R = ifelse(percent == 1, 0.1, 1 - percent), r = percent, d = radians, color = color, group = color), size = 0.1) +
  scale_color_identity() +
  theme_jk(grid = FALSE, plot_title_size = 8, strip_text_size = 8) +
  facet_wrap(~ title, ncol = 1, labeller = label_wrap_gen(15)) +
  labs(x = NULL, y = NULL, title = season) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines"")) +
  coord_equal()  }


plots <- plot_data %>% 
  split(.$season) %>% 
  map(plot_spiros)


all_seasons <- wrap_plots(plots, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = ""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."",
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot.png""), plot = all_seasons, width = 30, height = 15, type = ""cairo"")

twitter <- map(plots, ~.x + theme(strip.text = element_blank()))


all_seasons_twitter <- wrap_plots(twitter, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = str_wrap(""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."", 265),
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot_for_twitter.png""), plot = all_seasons_twitter, width = 20, height = 7)


","2019-32"
"41",41,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week33/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)


emperors <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"") 

ad_births <- c(""Augustus"", ""Tiberius"", ""Claudius"", ""Galba"")

emp_numeric_years <- emperors %>% 
  mutate_if(is.Date, list(year = year)) %>% 
  mutate(birth_year = if_else(name %in% ad_births, -birth_year, birth_year),
         reign_start_year = if_else(name == ""Augustus"", -reign_start_year, reign_start_year))


missing_birth_estimates <- emp_numeric_years %>% 
  filter(is.na(birth_year)) %>% 
  mutate(birth_year = case_when(name == ""Florian"" ~ 202,
                                name == ""Numerian"" ~ 248,
                                name == ""Carinus"" ~ 245,
                                name == ""Severus II"" ~ 260,
                                name == ""Vetranio"" ~ 325))


plot_data <- emp_numeric_years %>% 
  filter(!is.na(birth_year)) %>% 
  bind_rows(missing_birth_estimates)


dynasties <- plot_data %>% 
  group_by(dynasty) %>% 
  summarize(reign_start_year = min(reign_start_year),
               reign_end_year = max(reign_end_year))

roman_palette <- set_names(colorRampPalette(c(""#191970"", ""#FF7F50""))(8), unique(plot_data$dynasty))


overall <- ggplot(plot_data, aes(y = 0)) +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = 0, color = dynasty), size = 4) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, y = NULL,
       caption = ""Data: Wikipedia via @geokaramanis | Graphic: @jakekaupp"") +
  theme_jk(grid = ""X"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

bars <- ggplot(plot_data, aes(y = reorder(name, reign_start_year))) +
  geom_segment(aes(x = birth_year, xend = death_year, yend = name), size = 2, color = ""grey90"") +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = name, color = dynasty), size = 2) +
  geom_segment(data = filter(plot_data, reign_start_year == reign_end_year), aes(x = reign_start_year - 0.5, xend = reign_start_year + 0.5, y = name, yend = name, color = dynasty), size = 2) +
  geom_text(aes(x = death_year, label = name), hjust = 0, family = ""Scope One"", size = 2, nudge_x = 3) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, 
       y = NULL,
       title = str_to_title(""When in Rome: The Game of Imperial Thrones. You Win or You Die.""),
       subtitle = str_wrap(""Illustrated below is a timeline of the life and reigns of Roman Emperors from 62 BC to 395 AD.  The light grey bar depicts the liftime of the emperor, the colored bar (by dynasty) indicates the duration of their reign. An overall timeline by dynasty is shown near the horizontal axis. Unsurprisingly, the majority of emperors reign ending also coincides with the end of their life."", 100)) +
  theme_jk(grid = ""X"") +
  theme(axis.text = element_blank(),
        legend.position = c(0.2, 0.7),
        legend.background = element_rect(fill = ""white"", size = 0))


out <- wrap_plots(bars, overall, ncol = 1, heights = c(0.9, 0.1))

ggsave(here(""2019"", ""week33"", ""tw33_plot.png""), out, width = 7.5, height = 8)
","2019-33"
"42",42,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week34/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggtext)
library(jkmisc)
library(waffle)
library(ggforce)
library(glue)
library(ragg)

nuclear_explosions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")




plot_data <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  group_by(country, date_long) %>% 
  summarize(n = n(),
            total_yield = sum(yield_upper, na.rm = TRUE)) %>% 
  group_by(country) %>% 
  mutate(c_sum = cumsum(n),
         c_yield = cumsum(total_yield)/1000) %>% 
  filter(country %in% c(""USSR"", ""USA""))

items <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  group_by(country) %>% 
  top_n(1, yield_upper) %>% 
  slice(1) %>%
  semi_join(plot_data, .) %>% 
  mutate(date_long = ymd(date_long) - 1) %>% 
  mutate(name = if_else(country == ""USA"", ""March 1954: Castle Bravo"", ""October 1961: Tsar Bomba""),
         description  = if_else(country == ""USA"", ""2nd most powerful nuclear test explosion, 3 times over the predicted 5 MT yield."", ""Most powerful nuclear test explosion, twice the predicted yield of 25 MT.""))

explosions <- ggplot(plot_data, aes(x = c_sum, y = c_yield, color = country)) +
  geom_step(linetype = ""solid"", size = 1, direction = ""hv"") +
  geom_point(data = filter(plot_data, date_long %in% range(date_long))) +
  geom_text(data = filter(plot_data, date_long == last(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", hjust = -0.5) +
  geom_text(data = filter(plot_data, date_long == first(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", nudge_y = c(10, -10)) +
  geom_mark_circle(data = items, aes(color = country, label = name, description = description), expand = unit(3, ""mm""), label.margin = margin(5, 5, 5, 5, ""mm""), con.colour = c(""#0052A5"", ""#FF2400""), label.family = c(""Oswald"",""Scope One""), label.fill = NA, label.minwidth = unit(50, ""mm""), label.fontsize = 10, con.type = ""straight"") +
  scale_color_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_fill_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_y_continuous(labels = function(x) scales::comma(x, suffix = "" MT"")) +
  labs(x = 'Cumulative Number of Explosions',
       y = ""Cumulative Yield (MT)"",
       title = ""Nuclear Weapons Research Race During And After The Cold War"",
       subtitle = ""Illustrated below is a step chart showing the number and yield of nuclear explosions for weapons research for <span style='color:#0052A5'>**USA**</span> and <span style='color:#FF2400'>**USSR**</span>.  During this race nearly<br>500 MT of nuclear explosions and accompanying fallout blanketed the world. The effects are still being dealt with to this date."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(plot.title = element_markdown(), 
        plot.subtitle = element_markdown(),
        legend.position = ""none"")
  
ggsave(here(""2019"", ""week34"", ""tw34_plot_2.png""), plot = explosions, width = 12, height = 6, device = agg_png())


# Waffle ----

waffle_data <- nuclear_explosions %>% 
  mutate(purpose = case_when(grepl(""WR"", purpose) ~ ""WR"",
                             grepl(""WE"", purpose) ~ ""WE"",
                             grepl(""PNE"", purpose) ~ ""PNE"",
                             TRUE ~ purpose)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  count(year, purpose) %>% 
  group_by(purpose) %>% 
  mutate(c_sum = cumsum(n))


pal <- set_names(sample(grey.colors(50),10), unique(waffle_data$purpose))

pal[""WR""] <- ""#8A0303""

waffle <- ggplot(waffle_data, aes(fill = purpose, values = c_sum)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, strip.position = ""bottom"", nrow = 1) +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  coord_equal() +
  scale_fill_manual(values = pal) +
  labs(y = ""Cumulative Number of Explosions"",
       title = ""Nuclear Weapons Research Testing During the Cold War Was the Primary Driver of Controlled  Nuclear Explosions"",
       subtitle = ""Illustrated below is a timeline of waffle charts showing the distribution of cumulative explosions from <span style='color:#8A0303'>**weapons research**</span> or <span style='color:#4D4D4D'>**other purposes**</span>. Widescale Nuclear testing ceased in the mid-'90's. The only active country<br>conducting nuclear testing in this era is North Korea, weathering the disapproval and ire of the global community."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(strip_text_size = 10,
           subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(panel.grid = element_blank(), 
        axis.ticks.y = element_line(),
        strip.text = element_text(hjust = 0.5),
        plot.title = element_markdown(), 
        plot.subtitle = element_markdown())
  
ggsave(here(""2019"", ""week34"", ""tw34_plot.png""), plot = waffle, width = 18, height = 6, device = agg_png())
","2019-34"
"43",43,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week35/R/analysis.R","library(tidyverse)
library(tidygraph)
library(ggraph)
library(colorspace)
library(glue)
library(jkmisc)
library(ggtext)
library(ragg)
library(here)


html_string <- glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'. {subtitle_names} are the most frequent guest stars in the series."")

str_break <- function (html_string, width = 80, indent = 0, exdent = 0) {

tags <- str_extract_all(html_string, ""<.*?>"") %>% 
  flatten_chr() 

index <- sprintf(""tag_%s"", seq_along(tags))

string <- str_replace_all(html_string, set_names(index, tags))

  if (width <= 0) 
    width <- 1
  
  out <- stringi::stri_wrap(string, width = width, indent = indent, 
                   exdent = exdent, simplify = FALSE)
  
  broken <- vapply(out, str_c, collapse = ""<br>"", character(1))
  
  str_replace_all(broken, set_names(tags, index))
  
}

text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


simpsons <- read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")

nodes <- count(simpsons, guest_star) 

top5 <- top_n(nodes, 5, n) %>% 
  arrange(desc(n)) %>% 
  rownames_to_column(var = ""color"") %>% 
  select(-n)

nodes <- nodes %>% 
  left_join(top5) %>% 
  replace_na(list(color = 7)) %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  mutate(alpha = if_else(color < 7, 1, 0.5)) 


edges <- simpsons %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  group_by(production_code) %>% 
  mutate(co_stars = map(guest_star, ~str_subset(guest_star, .x, negate = TRUE))) %>%
  ungroup() %>% 
  mutate(co_stars = map(co_stars, ~ifelse(length(.x) == 0, NA_character_,.x))) %>% 
  unnest(co_stars) %>% 
  count(guest_star, co_stars) %>% 
  filter(!is.na(n), !is.na(co_stars)) %>% 
  set_names(c(""from"", ""to"", ""n"")) %>% 
  left_join(top5, by = c(""from"" = ""guest_star"")) %>% 
  left_join(top5, by = c(""to"" = ""guest_star"")) %>% 
  mutate(color = coalesce(color.x, color.y)) %>% 
  replace_na(list(color = ""grey80"")) 

  
colors <- set_names(tol6qualitative, top5$guest_star)  

subtitle_names <- imap(colors[1:5], ~text_bc(.y, .x)) %>% 
  glue_collapse(sep = ', ') %>% 
  glue("" and {imap(colors[6], ~text_bc(.y, .x))}"")

co_star_graph <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)

co_star_plot <- co_star_graph %>% 
  activate(nodes) %>% 
  arrange(n) %>% 
  mutate(degree = centrality_degree()) %>% 
  filter(degree > 1) %>%  
  ggraph(layout = ""fr"") + 
  geom_edge_arc(edge_width = 0.5, curvature = 0.2, aes(alpha = stat(index), edge_colour = color)) +
  geom_node_point(aes(size = n, color = color, alpha = alpha, fill = color), shape = 21) +
  scale_color_manual(values = c(darken(tol6qualitative), ""grey80"")) + 
  scale_alpha_identity() +
  scale_edge_color_manual(values = c(tol6qualitative, ""grey85"")) +
  scale_fill_manual(values = c(tol6qualitative, ""grey80"")) + 
  scale_size(range = c(2,6)) +
  labs(x = NULL,
       y = NULL,
       title = ""The Guest Star Backbone Of A Simpsons Co-Star Network"",
       subtitle = glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'.<br> {subtitle_names} <br>are the most frequent guest stars in the series.""),
       caption = ""**Data**: Wikipedia via @datawookie | **Graphic**: @jakekaupp"") +
  theme_jk(grid = FALSE,
           subtitle_family = ""Lora"",
           caption_family = ""Lora"",
           markdown = TRUE) +
  theme(legend.position = ""none"",
        axis.text = element_blank())

ggsave(here(""2019"", ""week35"", ""tw35_plot.png""), plot = co_star_plot, device = agg_png(), width = 9, height = 8)

ggplot(mtcars, aes(x = mpg, y = disp)) +
  geom_point() +
  labs(title = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't""),
       subtitle = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't"")) +
  theme_jk() +
  theme(plot.title = ggtext::element_markdown(),
        plot.subtitle = ggtext::element_markdown())
","2019-35"
"44",44,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week36/R/analysis.R","library(tidyverse)
library(jkmisc)
library(nord)
library(glue)
library(here)
library(ragg)

cpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")

gpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")

ram <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")


plot_data <- list(cpu = cpu, gpu = gpu) %>% 
  imap_dfr(~select(.x, date_of_introduction, transistor_count, area, process) %>% 
             mutate(type = .y)) %>% 
  group_by(date_of_introduction, type) %>% 
  summarize_at(vars(transistor_count, area, process), mean, na.rm = TRUE) %>% 
  arrange(date_of_introduction, type)

strip_labels <- tibble(type = c(""cpu"", ""gpu""))

plot <- ggplot(plot_data, aes(x = area, y = transistor_count)) +
  geom_text(data = strip_labels, aes(label = toupper(type)), x = 400, y = 4, family = ""Oswald Bold"", size = 18, color = ""grey90"") +
  geom_smooth(method = ""auto"", formula = y ~ log10(x), se = FALSE, size = 0.5,  color = nth(nord_palettes$victory_bonds, 3)) +
  geom_hline(aes(yintercept = 10^10), linetype = ""dotted"", color = first(nord_palettes$victory_bonds)) +
  geom_point(aes(color = log10(process)), size = 3) +
  scale_color_nord(name = ""Process Size"",
                        discrete = FALSE,
                        palette = ""lumina"",
                        reverse = TRUE,
                        labels = function(x) glue(""{scales::comma(10^x)} nm""),
                        breaks = c(1, 2, 3, 4)) +
  scale_y_log10(breaks = c(1, 10^4, 10^6, 10^8, 10^10),
                labels = c(""1"", ""10K"", ""1M"", ""100M"", ""10B"")) +
  scale_x_continuous(labels = function(x) glue(""{x} {expression(mm^2)}"")) +
  facet_wrap(~type) +
  labs(x = NULL, 
       y = NULL,
       title = ""Moore's Law May Be Dead, Killed By The Tension Between Manufacturing and Transistor Density"",
       subtitle = ""*Moore's law*, the observation that the **number of transistors** on integrated circuits **doubles every two years**<br>
       hasn't held.  Transistor density is reaching a plateau, requiring manufacturing changes of an increase in available<br>
       chip size or a decrease in process size."",
       caption = ""**Data:** Wikipedia | **Graphic:** @jakekaupp"") +
  theme_jk(grid = ""XY"",
          markdown = TRUE) +
  theme(strip.text = element_blank())

ggsave(here(""2019"", ""week36"", ""tw36_plot.png""), plot = plot, device = agg_png(), width = 10, height = 6)
","2019-36"
"45",45,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week37/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(tidygraph)
library(ggraph)
library(ggforce)
library(janitor)
library(jkmisc)
library(glue)
library(ggtext)
library(colorspace)
library(ragg)

legacy_data <- here(""2019"", ""week37"", ""data"", ""Saferparks-dataset-legacy.csv"") %>% 
  read_csv() %>% 
  mutate(year = year(mdy(acc_date))) %>% 
  filter(between(year, 1999, 2007))

device_type <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .75),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .75),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .75))) %>% 
  select(name = device_type, size, color)

device_category <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .25),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .25),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .25))) %>% 
  select(name = device_category, size, color) 

sector <-  legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ ""#251351"",
                           industry_sector == ""recreation"" ~ ""#7d2e68"",
                           industry_sector == ""water park"" ~""#41658a"")) %>% 
  select(name = industry_sector, size, color)

nodes <- bind_rows(sector, device_category, device_type)

edge_one <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(industry_sector, device_category) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edge_two <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(device_category, device_type) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edges <- bind_rows(edge_one, edge_two)

graph <- tbl_graph(nodes = nodes, edges = edges) 

labels <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  group_by(industry_sector) %>% 
  top_n(1 , size) %>% 
  filter(size > 1) %>% 
  pull(device_type) 
 
text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


plot <- ggraph(graph, 'circlepack', weight = size) + 
  geom_node_circle(aes(fill = color)) + 
  geom_node_text(aes(label = glue(""{str_remove(name, ' - undefined')}:\n{size}""), filter = name %in% labels, family = ""Oswald"")) +
  scale_fill_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Attractions With The Most Reported Injuries from 1999-2007"",
       caption = ""Data: **SaferParks** | Graphic: **@jakekaupp**"",
       subtitle = glue(""Shown below is a packed circle representation of reported accidents in the SaferParks database from 1999-2007.<br>Circles are organized by {highlight_text('Amusement rides', '#251351', 'b')}, {highlight_text('Recreation', '#7d2e68', 'b')} and {highlight_text('Water Park', '#41658a', 'b')}. Device category and device type are the<br>middle and lightest hues, respectively."")) +
  theme_jk(grid = FALSE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.subtitle = element_markdown(),
        plot.caption = element_markdown()) 


ggsave(here(""2019"", ""week37"", ""tw_37plot.png""), plot, width = 9, height = 10, dev = agg_png())


","2019-37"
"46",46,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week38/R/analysis.R","library(tidyverse)
library(rvest)
library(janitor)
library(here)
library(fuzzyjoin)
library(jkmisc)
library(ragg)

# Get park fees
fees_page <- ""https://www.nps.gov/aboutus/entrance-fee-prices.htm""

parks <- read_html(fees_page) %>% 
  html_nodes(""h3"") %>% 
  html_text() %>% 
  .[-1:-2]

park_fees <- read_html(fees_page) %>% 
  html_nodes("".table-wrapper > table"") %>% 
  html_table() %>% 
  map(~set_names(.x, c(""date"", ""park_specific_annual_pass"", ""per_vehicle"", ""per_person"", 
                       ""per_motorcycle""))) %>% 
  map2(parks, ~mutate(.x, park = .y)) %>% 
  bind_rows() %>% 
  filter(date == ""Current"") %>% 
  rename(park_name = park) %>% 
  mutate(park_name = stringi::stri_trans_general(park_name, id = ""Latin-ASCII""),
         park_name = str_replace(park_name, ""Hawai'i"", ""Hawaii""))



#udpated data
summary_report <- here(""2019"", ""week38"", ""data"", ""annual_summary_report.csv"") %>% 
  read_csv() %>% 
  clean_names()

plot_data <- summary_report %>% 
  filter(year == 2018) %>% 
  mutate(visitors = recreation_visitors + non_recreation_visitors) %>% 
  select(year, park_name, visitors) %>% 
  mutate(park_name = str_remove(park_name, ""[A-Z]{2,}""),
         park_name = str_remove(park_name, ""& PRES""),
         park_name = trimws(park_name)) %>% 
  regex_left_join(park_fees, ., ignore_case = TRUE) %>% 
  distinct(year, park_name.x, .keep_all = TRUE) %>% 
  filter(str_detect(park_name.x, ""Park""), !str_detect(park_name.x, ""Great Falls"")) %>% 
  mutate(revenue = visitors * parse_number(per_person)) %>% 
  rename(park_name = park_name.x) %>% 
  select(-park_name.y)
  

plot <- ggplot(plot_data, aes(x = fct_reorder(park_name, revenue), y = revenue)) +
  geom_col(fill = ""#5e81ac"", size = 0.1) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar, expand = c(0.01,0)) +
  labs(title = ""Estimated National Park Revenue from Fees for 2018"",
       subtitle = str_wrap(""Illustrated below is a bar chart of fee revenue from US National Parks in 2018.  Estimated Revenue calculated using per person admittance rates and total park visitors."", 95),
       caption = ""Data: www.nps.gov | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = ""X"") +
  theme(plot.background = element_rect(fill = ""#2e3440""),
        text = element_text(color = ""#eceff4""),
        panel.grid = element_line(color = ""#e5e9f0""),
        axis.text.x = element_text(color = ""#eceff4""),
        axis.text.y = element_text(color = ""#eceff4""))

ggsave(here(""2019"", ""week38"", ""tw_38plot.png""), plot, width = 10, height = 8, device = agg_png())

","2019-38"
"47",47,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week39/R/analysis.R","library(tidyverse)
library(janitor)
library(tidycensus)
library(glue)
library(here)
library(sf)
library(tigris)
library(jkmisc)
library(ggtext)

school_diversity <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv"")

## Getting the ACS Survey data ----
acs_var <- load_variables(2017, ""acs1"", cache = TRUE)

race_vars <- filter(acs_var, concept == ""RACE"") %>% 
  select(name, label) %>% 
  separate(label, c(""estimate"", ""total"", ""type""), sep = ""!!"") %>% 
  mutate(type = coalesce(type, total)) %>% 
  select(name, label = type)

if (!file.exists(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))) {
  
  acs_race <- map_df(state.abb, ~get_acs(geography = ""school district (unified)"", 
                                         variables = race_vars$name,
                                         state = .x))
  
  saveRDS(acs_race, here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
  
} else {
  
  acs_race <- readRDS(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
}





# Recoding ACS and aggregating data, sadly not easy to determine Hispanic origin ----
# Following methodology from WaPo repo, recoding Native Hawaiian and Pacifici Islander into Asian.
diversity_data <- acs_race %>% 
  left_join(race_vars, by = c(""variable"" = ""name"")) %>% 
  mutate(label = case_when(label == ""White alone"" ~ ""White"",
                           label == ""Black or African American alone"" ~ ""Black"",
                           label == ""American Indian and Alaska Native alone"" ~ ""AIAN"",
                           label == ""Native Hawaiian and Other Pacific Islander alone"" ~ ""Asian"",
                           label == ""Asian alone"" ~ ""Asian"",
                           label == ""Two or more races"" ~ ""Multi"",
                           label == ""Some other race alone"" ~ ""Other"",
                           TRUE ~ label)) %>% 
  group_by(GEOID, NAME, label) %>% 
  summarize_at(vars(estimate), sum) 


# Using Simpson's Diversity Index instead of max race metrics for diversity----
totals <- diversity_data %>% 
  summarize(total = sum(estimate)*(sum(estimate)-1))

dvs_score <- diversity_data %>% 
  filter(label != ""Total"") %>% 
  mutate(es_minus = estimate-1) %>% 
  summarize(numerator = sum(estimate*es_minus)) %>% 
  left_join(totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID, NAME, diversity) 
  
acs_diversity <- diversity_data %>% 
  spread(label, estimate) %>% 
  select(-Total) %>% 
  left_join(dvs_score) %>% 
  rename(acs_diversity = diversity) %>% 
  ungroup() %>% 
  mutate(NAME = tolower(NAME),
         NAME = str_remove(NAME, ""\\(.+\\)""),
         NAME = str_replace_all(NAME, "";"", "","")) %>% 
  separate(NAME, c(""NAME"", ""state""), sep = "","") %>% 
  mutate(NAME = str_remove_all(NAME, ""school district*+"")) %>% 
  select(GEOID, acs_diversity)

# Use WaPo data and calculate Simpson's Diversity Index
upd_school <- school_diversity %>% 
  filter(SCHOOL_YEAR == ""2016-2017"") %>% 
  select(LEAID, LEA_NAME, ST, SCHOOL_YEAR, AIAN:Total) %>% 
  pivot_longer(AIAN:Multi, ""race"", ""value"") %>% 
  mutate(n = floor(Total * value))

school_totals <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  summarize(total = sum(n)*(sum(n)-1))
  
upd_school_dvs <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  mutate(n_minus = n-1) %>% 
  summarize(numerator = sum(n*n_minus)) %>% 
  left_join(school_totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID = LEAID, NAME = LEA_NAME, ST, school_diversity = diversity) 

# Environment Cleanup---
remove(list = ls()[str_which(ls(), ""upd_school_dvs|acs_diversity"", negate = TRUE)])

# Comparing the two diversity measures and creating the ratio ----
overall_diversity <- upd_school_dvs %>% 
  left_join(acs_diversity, by = ""GEOID"") %>% 
  mutate(ratio = school_diversity/acs_diversity) %>% 
  filter(!is.na(acs_diversity))

# Get School District maps ----

if (!file.exists(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))) {
  
  district_maps <- map(state.abb, ~school_districts(.x, class = ""sf""))
  
  saveRDS(district_maps, here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
  
} else {
  
  district_maps <- readRDS(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
}



# One do.call to keep them all, and in the shallows bind them----
maps <- do.call(sf:::rbind.sf, district_maps)

plot <- overall_diversity %>%
  right_join(maps, ., by = ""GEOID"") %>%
  filter(!ST %in% c(""HI"", ""AK"")) %>%
  ggplot() +
  geom_sf(aes(fill = ratio), color = 'white', size = 0.01) +
  scale_fill_viridis_c(""Alignment Ratio"", option = ""cividis"", limits = c(0, 1), labels = scales::percent, na.value = ""white"") +
  coord_sf(crs = 26915) +
  labs(title = ""Is Diversity In School Districts Reflected In The Diversity Of The General Population?"",
       subtitle = glue(""Shown below is a choropleth map illustrating the ratio between the Diversity Index of a School Population and the Diversity Index of the General Population in that School District in 2017.<br>
       The more {highlight_text('yellow', '#FFEA46', 'b')} an area, the greater alignment between diversity indices.  The more {highlight_text('blue', '#00204D', 'b')} an area, the greater the difference between the diversity of the school and the general populace.<br> 
       This analysis focused on unified school districts and available data on race from the ACS Survey.  Diversity was calculated using Simpson's Diversity Index.""),
       caption = ""Data: **Washington Post via @dataKateR & American Community Survey** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
          markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week39"", ""tw39_plot.png""), width = 16, height = 10, device = ragg::agg_png())
","2019-39"
"48",48,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week4/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)



incar_data <- here(""2019"",""week4"",""data"") %>% 
  dir(full.names = TRUE, pattern = ""incarceration"") %>% 
  read_excel()

fix_null <- function(x) if_else(is.nan(x), NA_real_, x)

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") %>% 
  mutate_at(""id"", as.numeric)

ratio_data <- incar_data %>% 
  group_by(year, fips, state, county_name) %>% 
  transmute(black_pop_ratio = black_pop_15to64/total_pop_15to64,
         black_prison_ratio = black_prison_pop/total_prison_pop,
         asian_pop_ratio = asian_pop_15to64/total_pop_15to64,
         asian_prison_ratio = asian_prison_pop/total_prison_pop,
         latino_pop_ratio = latino_pop_15to64/total_pop_15to64,
         latino_prison_ratio = latino_prison_pop/total_prison_pop,
         native_pop_ratio = native_pop_15to64/total_pop_15to64,
         native_prison_ratio = native_prison_pop/total_prison_pop,
         white_pop_ratio = white_pop_15to64/total_pop_15to64,
         white_prison_ratio = white_prison_pop/total_prison_pop) %>% 
  group_by(fips, state, county_name) %>% 
  summarize_at(vars(contains(""ratio"")), mean, na.rm = TRUE) %>% 
  mutate_at(vars(contains(""ratio"")), fix_null)


map_data <- left_join(us_map, ratio_data, by = c(""id"" = ""fips""))  %>% 
  ungroup() %>% 
  gather(""variable"",""percentage"", contains(""ratio"")) %>% 
  separate(variable, c(""ethnicity"", ""category""), sep = ""_"")

plot <- ggplot() +
  geom_map(data = us_map, map = us_map,
           aes(x = long, y = lat, map_id = id),
           color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = map_data, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = percentage),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis_c("""", na.value = ""white"", option = 'cividis', labels = scales::percent) +
  coord_map() +
  labs(title = ""Differences between the General and Prison Population by County and Ethnic Group from 1970 to 2016"",
       subtitle = str_wrap(""Non-white and non-Asian ethnic groups in the South-Eastern United States have a higher average representation in prison than in the overall population.  Missing data indicated by no fill color."",  90),
       caption = ""Data: Vera Institute of Justice | Graphic: @jakekaupp"") +
  facet_grid(category ~ ethnicity , labeller = labeller(category = c(""pop"" = ""Total\nPopulation"", ""prison"" = ""Prison\nPopulation""),
                                                       ethnicity = str_to_title)) +
  theme_map(base_family = ""Scope One"", 
            base_size = 16) +
  theme(plot.caption = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        legend.position = ""bottom"",
        legend.justification = ""center"",
        legend.direction = ""horizontal"",
        legend.key.height = unit(0.2, ""cm""),
        legend.key.width = unit(1, ""cm""),
        strip.background = element_blank(),
        strip.text.y = element_text(angle = 0))

ggsave(here(""2019"",""week4"",""tw4_choro.png""), width = 11, height = 5)

","2019-4"
"49",49,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week40/R/analysis.R","library(tidyverse)
library(sf)
library(tigris)
library(glue)
library(colorspace)
library(jkmisc)
library(ggforce)
library(ragg)
library(here)

# Get TidyTuesday data
pizza_datafiniti <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_datafiniti.csv"") %>% 
  filter(province == ""NY"") %>% 
  distinct(name, latitude, longitude)

pizza_barstool <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_barstool.csv"") %>% 
  distinct(name, latitude, longitude) %>% 
  filter(!is.na(latitude))

# Get all New York County road maps
counties <- c(""New York County"", ""Kings County"", ""Bronx County"", ""Richmond County"",  ""Queens County"")

roads_data <- map(counties, ~roads(""NY"", .x, class = ""sf"")) %>% 
  do.call(sf:::rbind.sf, .)

# Build plot colors as a named vector and as a tibble
plotcolors <- c('Other' = '#cccccc',
                'Ave' = '#59c8e5',
                'St' = '#fed032',
                'Tunl' = '#fed032',
                'Brg' = '#fed032',
                'N' = '#fed032',
                'S' = '#fed032',
                'E' = '#fed032',
                'W' = '#fed032',
                'Rd' = '#4cb580',
                'Dr' = '#0a7abf', 
                'Hwy' = '#ff9223', 
                'Plz' = '#ff9223',
                'Viaduct' = '#ff9223', 
                'Expy' = '#ff9223', 
                'Pkwy' = '#ff9223',
                'Thruway' = '#ff9223',
                'State Hwy' = '#ff9223',
                'State' = '#ff9223',
                'US Hwy' = '#ff9223',
                'Blvd'= '#2e968c')

pc_tibble <- tibble(street_type = names(plotcolors),
                    color = plotcolors)

# Assign street types to roads
roads <- roads_data %>% 
  filter(!is.na(RTTYP)) %>% 
  mutate(street_type = map_chr(FULLNAME, ~first(names(plotcolors)[str_which(.x, glue(""{names(plotcolors)}\\b""))]))) %>% 
  mutate(street_type = if_else(str_detect(FULLNAME, ""I-""), 'I-', street_type)) %>% 
  mutate(street_type = case_when(is.na(street_type) & MTFCC == ""S1100"" ~ 'Expy',
                                 is.na(street_type) & MTFCC == ""S1200"" ~ 'St',
                                 is.na(street_type) & !MTFCC %in% c(""S1100"", ""S1200"") ~ ""Other"",
                                 TRUE ~ street_type)) %>% 
  left_join(pc_tibble, by = ""street_type"")

# Get Counties shapefiles to determine which pizza places are in the areas I want
counties_sf <- counties(""NY"", class = ""sf"") %>% 
  filter(NAMELSAD %in% counties)

# Use st_intersects and filter to remove out of bounds pizza places
pizza_sf_df <- st_as_sf(pizza_datafiniti, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
pizza_sf_bs <- st_as_sf(pizza_barstool, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
  
  
# Filter to pizza places in the five boroughs
ny_pizza_df <-  filter(pizza_sf_df, map_lgl(st_intersects(pizza_sf_df, counties_sf), ~!is_empty(.x)))

ny_pizza_bs <-  filter(pizza_sf_bs, map_lgl(st_intersects(pizza_sf_bs, counties_sf), ~!is_empty(.x)))

ny_pizza <- sf:::rbind.sf(ny_pizza_bs, ny_pizza_df) %>% 
  distinct(geometry)

# Construct the color legend
legend <- pc_tibble %>% 
  filter(street_type %in% c(""Other"",""Ave"",""St"", ""Rd"", ""Dr"", ""Hwy"", ""Blvd"")) %>% 
  mutate(street_type = factor(street_type, levels = c(""Other"", ""Ave"", ""Dr"", ""Rd"", ""Blvd"", ""St"", ""Hwy""), labels = c(""Other"", ""Avenue"", ""Drive"", ""Road"", ""Boulevard "", ""Street"", ""Highway""))) %>%
  arrange(street_type) %>% 
  mutate(x0 = seq(3, by = 4.5, length.out = 7),
         r = 1.75,
         y0 = 0) %>% 
  ggplot(aes(x0 = x0, y0 = y0, r = r)) +
  geom_circle(aes(fill = color, color = darken(color))) +
  geom_text(aes(label = street_type, x = x0, y = 0), family = ""Lora"", size = 3) +
  annotate(""text"", family = ""Oswald"", x = -2, y = 0, label = ""Legend"", size = 6) +
  scale_fill_identity() +
  scale_color_identity() +
  expand_limits(y = c(-0.5, 4),
                x = c(-4, 24)) +
  labs(x = NULL,
       y = NULL) +
  coord_equal(clip = ""off"") +
  theme_jk(grid = FALSE, plot_title_size = 30) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 

legend_grob <- ggplotGrob(legend)

subtitle <- ""Shown on this map are the roads and the pizza places of the Five Boroughs of New York City.  
Pizza places are distinct locations almagamated from the DataFiniti and Barstool datasets, and a represented by purple dots.  Manhattan is the most represented borough in the dataset, unsurprising given the relative population, and it being the home of the Teenage Mutant Ninja Turtles.
The map style of plotting the colored roads were inspired by Erin Davis (erdavis1 on github), and her series of circular maps of World Cities.""

caption <- ""Data: DataFiniti, Barstool, US Census Shapefiles\nGraphic: @jakekaupp""


# Plot the Street maps and Pizza place data
pizza_map <- ggplot() +
  geom_sf(data = filter(roads, street_type != ""Other""), aes(color = color), size = 0.25) + 
  geom_sf(data = filter(roads, street_type == ""Other""), aes(color = color), size = 0.35) + 
  geom_sf(data = ny_pizza, color = darken(""#963484""), fill = ""#963484"", shape = 21, size = 2, alpha = 0.5) +
  annotate(""text"", label = ""Pizza Places of the Five Boroughs"", family = ""Oswald"", x = -74.3, y = 40.91, size = 6, hjust = 0) +
  annotate(""text"", family = ""Lato"", label = str_wrap(subtitle, 60), x = -74.3, y = 40.89, hjust = 0, vjust = 1) +
  annotate(""text"", family = ""Lato"", label = caption, x = -74.3, y = 40.78, hjust = 0, vjust = 1) +
  annotation_custom(legend_grob, xmin = -74.2, xmax = Inf, ymin = 40.49, ymax = 40.55) +
  scale_color_identity() +
  scale_size_identity() +
  coord_sf(clip = ""off"") +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 


ggsave(here('2019', 'week40', 'tw40_plot.png'), width = 12, height = 9, dev = agg_png())","2019-40"
"50",50,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week41/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(janitor)
library(jkmisc)
library(ggforce)
library(ggtext)
library(nord)
library(glue)
library(ragg)

# It's 250mb, can't put it into git, you're going to have to go get it
# from https://openpowerlifting.org/data and stick it in data.
pl_data <- here(""2019"", ""week41"", ""data"") %>% 
  dir(pattern = ""openpowerlifting"", full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

plot_data <- pl_data %>%
  filter_at(vars(starts_with(""best"")), all_vars(. > 0)) %>% 
  filter(str_detect(place, ""1"")) %>% 
  mutate(year = year(date)) %>%
  select(-date) %>%
  mutate_at(vars(starts_with(""best"")), ~./bodyweight_kg) %>% 
  pivot_longer(starts_with(""best""), names_to = ""lift"") %>% 
  group_by(year, sex, lift) %>%
  filter(value == max(value, na.rm = TRUE)) %>% 
  arrange(lift, sex, year)

labels <- tibble(label = c(""Bench Press"", ""Deadlift"", ""Squat""),
                 lift = c(""best3bench_kg"", ""best3deadlift_kg"", ""best3squat_kg""),
                 year = 2020,
                 value = 1)

annotations <- plot_data %>% 
  group_by(sex, lift) %>% 
  filter(value == max(value, na.rm = TRUE)) %>% 
  mutate(description = glue(""Weight: {bodyweight_kg} kg\nLifted: {bodyweight_kg*value} kg\n{federation}: {meet_name}""),
         name = str_remove(name, ""\\#[0-9]""))

plot <- ggplot(plot_data, aes(x = year, y = value)) +
  geom_path(aes(color = sex)) +
  geom_point(aes(fill = sex), shape = 21, color = ""#2E3440"") +
  geom_text(data = labels, aes(label = label), color = ""#E5E9F0"", family = ""Oswald"", fontface = ""bold"", size = 10, hjust = 1) +
  geom_mark_circle(data = filter(annotations, sex == ""M""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  geom_mark_circle(data = filter(annotations, sex == ""F""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  facet_wrap(~lift) +
  scale_color_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_fill_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_x_continuous(breaks = seq(1970, 2020, 10)) +
  theme_jk(dark = TRUE, 
           grid = ""XY"",
           markdown = TRUE) +
  labs(x = NULL,
       y = NULL,
       title = ""Evolution of Power: How the Ratio of Bodyweight to Lifted Weight Has Progressed"",
       subtitle = glue(""Illustrated below is the maximum of the ratio of bodyweight to lifted weight for winning lifts in each year and event for both {highlight_text('Men', '#314cb6', 'b')} and {highlight_text('Women', '#DD2A7B', 'b')} for all meets recorded by Open Powerlifting.""),
       caption = ""Data: **openpowerlifting.org** | Graphic: **@jakekaupp**"") +
  theme(legend.position = ""none"",
        panel.grid.major = element_line(size = 0.01),
        strip.text = element_blank())

ggsave(here('2019', 'week41', 'tw41_plot.png'), plot, width = 15, height = 8, device = agg_png())","2019-41"
"51",51,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week42/R/analysis.R","library(tidyverse)
library(here)
library(janitor)
library(jkmisc)
library(ggalt)
library(ggtext)
library(glue)
library(ragg)

big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")

top <- big_epa_cars %>% 
  clean_names() %>% 
  count(make, year) %>% 
  count(make) %>% 
  filter(n == 37)

plot_data <- big_epa_cars %>% 
  clean_names() %>% 
  select(make, v_class, year, you_save_spend) %>% 
  semi_join(top) %>% 
  group_by(year, make) %>% 
  summarize(total_save_spend = mean(you_save_spend)) %>%
  group_by(year) %>% 
  mutate(rank = min_rank(desc(total_save_spend))) %>% 
  ungroup() %>% 
  mutate(size = if_else(make == ""Ford"", 1, 0.5),
         make = factor(make, pull(top, make)),
         make = fct_relevel(make, ""Ford"", after = Inf),
         make = fct_recode(make, ""**Ford**"" = ""Ford""))


grid <- tibble(rank = 1:22)

colors <- set_names(grey.colors(22), pull(top, make) %>%
                      factor() %>%
                      fct_recode(""**Ford**"" = ""Ford""))

colors[[""**Ford**""]] <- ""#DD2A7B""


plot <- ggplot(plot_data, aes(x = year, y = rank)) +
  geom_segment(data = grid, aes(x = 1983, xend = 2021, y = rank, yend = rank), color = ""#cccccc"", alpha = 0.5, size = 0.1) +
  geom_xspline(aes(color = make, size = size), show.legend = FALSE) +
  geom_point(aes(fill = make), shape = 21, color = ""white"", show.legend = FALSE) +
  geom_richtext(data = filter(plot_data, year == 2020), aes(label = as.character(make), x = 2021, color = make), hjust = 0, family = ""Lora"", size = 4, show.legend = FALSE,  fill = NA, label.color = NA, 
                label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_text(data = filter(plot_data, year == 1984), aes(label = rank, x = 1983), hjust = 1, family = ""Oswald"", size = 4) +
  labs(x = NULL,
       y = NULL,
       title = ""From Chugging to Sipping: Fuel Cost Savings of Major Automakers since 1984"",
       subtitle = glue(""Shown below is a rankings chart of average fuel cost savings, measured over 5 years, from 1984 to 2020.  {highlight_text('Ford','#DD2A7B', 'b')} has had quite the journey, battling from the bottom<br>of the list to the second-best North American manufacturer."")) +
  scale_color_manual(values = colors) +
  scale_fill_manual(values = colors) +
  scale_size_identity() +
  scale_x_continuous(breaks = 1984:2020) +
  scale_y_continuous(trans = ""reverse"", breaks = NULL) +
  expand_limits(x = 2025) +
  theme_jk(grid = ""X"", 
           markdown = TRUE)

ggsave(here(""2019"", ""week42"", ""tw42_plot.png""), plot = plot, width = 13, height = 6)
","2019-42"
"52",52,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week43/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggraph)
library(tidygraph)
library(glue)
library(jkmisc)
library(colorspace)
library(ggforce)
library(ggtext)

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

movie_cast <- distinct(horror_movies, title, release_date, review_rating, .keep_all = TRUE) %>% 
  mutate(year = str_extract(title, ""\\((\\d{4})\\)""),
         year = parse_number(year),
         title = str_remove(title, ""(\\s\\(\\d{4}\\))""),
         date = dmy(release_date)) %>% 
  arrange(title) %>% 
  separate_rows(cast, sep = ""\\|"") %>% 
  mutate(cast = trimws(cast)) %>% 
  select(title, year, review_rating, cast)

cast_df <- left_join(movie_cast, movie_cast, by = c(""title"", ""year"", ""review_rating"")) %>% 
  rename(from = cast.x,
         to = cast.y) %>% 
  filter(from != to) 

nodes <- cast_df %>% 
  group_by(from) %>% 
  summarize(node_size = n_distinct(title)) %>% 
  distinct(from, .keep_all = TRUE) 

focus <- ""Eric Roberts""

edges <- cast_df %>% 
  count(from, to, sort = TRUE, name = ""edge_size"") %>% 
  distinct(from, to, .keep_all = TRUE) %>% 
  mutate(color = if_else(from == focus | to == focus, ""#bb0a1e"", ""#373e40""),
         alpha = if_else(from == focus | to == focus, 1, 0.2),
         size = if_else(from == focus | to == focus, 1, 0.1))

connected <- filter(edges, from == focus) %>% 
  distinct() %>% 
  pull(to) 

cast_network <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE) %>% 
  activate(nodes) %>% 
  mutate(degree = centrality_eigen(),
         alpha = if_else(from %in% c(focus, connected),  1, 0.2)) %>% 
  top_n(500, degree) %>% 
  mutate(fill = if_else(from %in% c(focus, connected), ""#bb0a1e"", ""#373e40""),
         color = if_else(from %in% c(focus, connected), darken(""#bb0a1e""), darken(""#373e40"")))

plot <- ggraph(cast_network, layout = ""graphopt"") + 
  geom_edge_link(aes(alpha = stat(index), edge_colour = color, edge_width = size), show.legend = FALSE) + 
  geom_node_point(aes(size = node_size, fill = fill, color = color), shape = 21, show.legend = FALSE) +
  #geom_mark_circle(aes(x, y, filter = from == focus, label = from, description = ""Legendary B-Movie Actor""), expand = unit(0, ""mm""), label.family = c(""Oswald"", ""Lora"")) +
  scale_edge_color_identity() +
  scale_alpha_identity() +
  scale_fill_identity() +
  scale_edge_width_identity() +
  scale_color_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Horror Movie Co-Star Networks of the Top 500 Prolific Performers"",
       subtitle = glue(""The reach of B-movie legend {highlight_text('Eric Roberts', '#bb0a1e', 'b')} is featured below across his 27 films. Prolific performers determined by the top 500<br>actors by eigenvalue centrality.""),
       caption = ""Data: **IMDB** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
           markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week43"", ""tw43_plot.png""), plot, width = 10, height = 6, device = ragg::agg_png())

  
","2019-43"
"53",53,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week44/R/analysis.R","library(tidyverse)
library(waffle)
library(lubridate)
library(jkmisc)
library(scales)
library(colorspace)
library(patchwork)
library(ggtext)
library(glue)
library(here)

#Get the data ----
nyc_squirrels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

# Process the data ----
activity_data <- nyc_squirrels %>% 
  mutate(date = mdy(date)) %>% 
  pivot_longer(names_to = ""activity"", running:foraging) %>%
  group_by(date, activity) %>% 
  summarize(value = sum(as.numeric(value))) %>% 
  mutate(activity = factor(activity, labels = unique(activity)),
         activity = fct_reorder(activity, value, .fun = sum)) %>% 
  arrange(date, desc(activity))

# Make my palette

slate_ramp <- colorRampPalette(c(""#3B454A"", lighten(""#3B454A"", 0.8)))(5) 

grey_ramp <- grey.colors(5, 0.5, 0.9)

pal <- set_names(slate_ramp, unique(activity_data$activity))

pal[""foraging""] <- ""#DD2A7B""

partition_waffle <- function(x, start, nrows, flip = FALSE) {
  
   offset <- start - x
  
   offset_rows <- offset %/% nrows
   
   offset_blocks <- offset %% nrows
   
  
   comp_blocks <- nrows - offset_blocks
   
   if (comp_blocks != nrows) {
     
     rows <- (x - comp_blocks) %/% nrows
     
     blocks <- (x - comp_blocks) %% nrows
     
     start_row <- offset_rows + rows + 1
     
     if (blocks == 0) {
       
       end_row <- start_row
       
     } else {
       
       end_row <- start_row + 1 
       
     }
     
   } else {
     
     rows <- x %/% nrows
     
     blocks <- x %% nrows
     
     start_row <- rows + offset_rows
     
     end_row <- rows + offset_rows + 1
     
   }
   
   
   if (flip) {
     
     tibble(y = c(start_row, start_row, end_row),
            yend = c(start_row, end_row, end_row),
            x = c(blocks, blocks, 0),
            xend = c(nrows, blocks, blocks))
     
     
   } else {
     
     tibble(x = c(start_row, start_row, end_row),
            xend = c(start_row, end_row, end_row),
            y = c(blocks, blocks, 0 -1),
            yend = c(nrows + 1, blocks, blocks))
   }
     
     

   
  
} 

# Waffles by activity ----

activity_outlines <- activity_data %>% 
  ungroup() %>% 
  arrange(desc(activity), date) %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, flip = FALSE, nrows = 20)) %>% 
  unnest(lines) %>% 
  filter(date == last(date))

activity_labels <- activity_data %>% 
  group_by(activity) %>% 
  summarize(total = sum(value)) %>%
  left_join(filter(activity_outlines, yend == 21), by = ""activity"")

waffle_by_activity <- activity_data %>% 
  arrange(desc(activity), date) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = activity_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""black"", size = 0.5) +
  geom_richtext(data = activity_labels, aes(label = glue(""<b>{str_to_title(activity)}</b>""), x = x, y = yend, color = activity), fill = ""white"", hjust = 1, vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = activity_labels, aes(label = glue(""{total}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_color_manual(values = pal) +
  coord_equal() +
  labs(x = NULL, 
       y = NULL) +
  theme_jk(grid = FALSE) +
  scale_x_continuous(expand = c(0,0)) +
  expand_limits(y = c(-5, 25), x = c(0, 200)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffles by day ----

by_day_outlines <- activity_data %>% 
  ungroup() %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE)) %>% 
  unnest(lines) %>% 
  filter(activity == ""chasing"")

by_day_labels <- activity_data %>% 
  group_by(date) %>% 
  summarize(total = sum(value)) %>% 
  left_join(filter(by_day_outlines, yend == 21))

waffle_by_day <- activity_data %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = by_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{month.abb[month(date)]} {day(date)}""), x = x, y = yend), fill = ""white"", color = ""black"", hjust = c(rep(1,10), 0), vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{total}""), x = x, y = -1), fill = ""white"", color = ""black"", hjust = c(rep(0,9),1,0), vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_x_continuous(expand = c(0,0)) +
  coord_equal(clip = ""off"") +
  labs(x = NULL, 
       y = NULL) +
  expand_limits(y = c(-5, 25), x = c(0, 205)) +
  theme_jk(grid = FALSE) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffle bars by day ----

waffle_day_outlines  <- activity_data %>% 
  arrange(desc(date)) %>% 
  filter(activity == ""foraging"") %>% 
  ungroup() %>%
  group_split(date) %>% 
  map(~mutate(.x, cum_sum = cumsum(value))) %>%
  map_dfr(~mutate(.x, lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE))) %>%
  unnest(lines) 

waffle_labels <- waffle_day_outlines %>% 
  filter(y == -1)

mday_label <- function(x) {
  
  glue(""{month.abb[month(x)]} {day(x)}"")
  
}

split_waffle_by_day <- activity_data %>% 
  arrange(desc(date)) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = waffle_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = waffle_labels, aes(label = glue(""{value}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  coord_equal() +
  scale_color_manual(values = pal) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  facet_wrap(~date, nrow = 1, as.table = FALSE, strip.position = ""top"", labeller = labeller(date = mday_label)) +
  expand_limits(y = c(-5, 20)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

out <- wrap_plots(waffle_by_activity, waffle_by_day, split_waffle_by_day, ncol = 1) +
  plot_annotation(title = ""Breakdown of Observed Squirrel Activity from the 2018 NYC Squirrel Census"",
                  subtitle = glue(""Below are  waffle charts of activity totals (I), daily totals (II) and exploded daily activity (III) views of observed squirrel activity.<br>{highlight_text('Foraging', '#DD2A7B', 'b')} is the most frequently observed activity recorded in the census, not surprising for squirrels in the fall.""),
                  caption = ""Data: **NYC Data Portal** | Graphic: **@jakekaupp**"",
                  tag_levels = ""I"",
                  theme = theme_jk(markdown = TRUE))

ggsave(here(""2019"", ""week44"", ""tw44_plot.png""), out, width = 11, height = 8, dev = ragg::agg_png(), dpi = ""print"")

","2019-44"
"54",54,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week45/R/analysis.R","library(tidyverse)
library(jkmisc)
library(glue)

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

total_avg <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  mutate(state = ""US"",
         state_abb = ""US"")

slope_data <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(state, state_abb, mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  ungroup() %>% 
  mutate(state_abb = ifelse(is.na(state_abb), ""DC"", state_abb))

direct_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(-3:-6)

direct_labels_bike <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  top_n(5, avg)

mid_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(3:6) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
    avg = mean(.$avg),
    y = min(.$avg),
    yend = max(.$avg))
  
lower_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  arrange(-avg) %>% 
  slice(9:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))

lower_bike_labels <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  arrange(-avg) %>% 
  slice(6:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))


ggplot(slope_data, aes(x = mode, y = avg)) +
  geom_line(aes(group = state), size = 0.2) +
  geom_line(data = total_avg, aes(group = state), color = ""#DD2A7B"", size = 1) +
  geom_point(shape = 21, color = ""white"", stroke = 0.2, fill = ""black"", size = 2) +
  geom_text(data = direct_labels, aes(label = state_abb),  nudge_x = 0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = direct_labels_bike, aes(label = state_abb),  nudge_x = -0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = mid_labels, aes(label = state_abb),  nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_bike_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = -0.5, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.95, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.91, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL,
       title = ""Bicycling and Walking to Work in the United States: 2008-2012"",
       subtitle = glue(""Illustrated below is a slopegraph contrasting the percentage of population that bikes to work and the percentage<br>that bikes to work as well as {highlight_text('the US average', '#DD2A7B', 'b')}"")) +
  scale_x_discrete(labels = c(""Bike to Work"", ""Walk to Work"")) +
  theme_jk(grid = ""XY"",
           markdown = TRUE) +
  theme(panel.grid.major = element_line(linetype = ""dashed""))
  
","2019-45"
"55",55,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week5/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(here)
library(scales)

milk_cow_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milkcow_facts.csv"")

milk_product_facts <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milk_products_facts.csv"")

us_pop <- read_csv(here(""2019"", ""week5"", ""data"",""us-population-1990-to-2016.csv""))

totals <- milk_product_facts %>% 
  mutate(total_consumption = rowSums(select(., -year))) %>% 
  select(year, total_consumption)

full_data <- left_join(milk_cow_data, totals) %>% 
  left_join(us_pop) %>% 
  mutate(total_consumption_lbs = total_consumption * population)


ggplot(full_data, aes(y = total_consumption_lbs, x = milk_production_lbs)) +
  geom_xspline2(aes(s_open = TRUE, s_shape = 0.5)) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 1) +
  scale_y_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  scale_x_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  labs(x = ""US Milk Production (lbs)"",
       y = ""US Average Dairy Consumption (lbs)"",
       title = ""100 Slices of American Cheese or, the Fable of Supply Management"",
       subtitle = str_wrap(""The connected scatterplot below illustrates the relationship between total average dairy consumption and total milk production over the past 25 years.
                           US supply far exceeds the demand, highlighting overproduction and a case for supply management."", 120)) +  
  theme_jk()
","2019-5"
"56",56,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week6/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(lubridate)
library(here)
library(scales)
library(janitor)
library(ggrepel)
library(patchwork)

state_hpi <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")

prime_rates <- read_csv(here(""2019"",""week6"",""data"",""MPRIME.csv"")) %>% 
  clean_names() %>% 
  mutate(year = year(date)) %>% 
  select(-date) %>% 
  group_by(year) %>% 
  summarize_all(mean) %>% 
  filter(year %in% min(state_hpi$year):max(state_hpi$year))

highs <- filter(prime_rates, mprime %in% range(mprime)) %>% 
  distinct(mprime, .keep_all = TRUE)

plot_data <- state_hpi %>% 
  group_by(year, state) %>% 
  summarize_all(mean, na.rm = TRUE) 

prime <- ggplot(prime_rates, aes(x = year, y = mprime)) +
  geom_line(color = viridis_pal()(1), size = 0.5) +
  geom_point(data = highs, color = viridis_pal()(1)) +
  geom_text_repel(data = highs, aes(label = paste0(mprime, ""%"")), color = viridis_pal()(1), nudge_x = 2, nudge_y = 2, family = ""Oswald"", segment.size = 0) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  theme_jk(grid = ""XY"") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Interest Rates Fall, Housing Prices on the Rise"",
       subtitle = str_wrap(""The top chart shows the average prime interest rate by year since 1975.  The bottom heatmap illustrates the yearly average housing price index by State since 1975."", 100))


heatmap <- ggplot(plot_data, aes(x = year, y = fct_reorder(state, price_index, .fun = mean), fill = price_index)) +
  geom_tile(color = ""white"", size = 0.05) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  scale_fill_viridis_c(""House Price Index"", option = ""viridis"", direction = 1, breaks = pretty_breaks(5)) +
  scale_color_identity() +
  labs(x = NULL, y = NULL, caption = ""Data: FRED | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"",
        legend.key.width = unit(1, ""cm""))


out <- patchwork::wrap_plots(prime, heatmap, heights = c(0.2,1), ncol = 1)

ggsave(here(""2019"", ""week6"", ""tw6_plot.png""), out, width = 8, height = 10)
","2019-6"
"57",57,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week7/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(janitor)
library(jkmisc)
library(nord)

oecd_data <- here(""2019"", ""week7"", ""data"", ""OECD--1.xlsx"") %>% 
  read_excel(skip = 1, na = c(""na"")) %>% 
  clean_names() %>% 
  filter(!is.na(x1995)) %>% 
  rename(country = x1) %>% 
  gather(year, intensity, -country) %>% 
  arrange(country, year) %>% 
  fill(intensity, .direction =  ""down"") %>% 
  mutate(year = parse_number(year)) %>% 
  group_by(year) %>% 
  arrange(year, intensity) %>% 
  mutate(rank = row_number(-intensity)) %>% 
  ungroup() %>% 
  mutate(color = if_else(country == ""Canada"", nord(""victory_bonds"")[2], nord(""snowstorm"", 1)),
         text_color = if_else(country == ""Canada"", nord(""snowstorm"", 1), ""black""))




plot <- ggplot(oecd_data, aes(x = year, y = -rank, group = country)) +
  geom_line(aes(color = color)) +
  geom_point(aes(color = color)) +
  geom_text(data = filter(oecd_data, year == min(year)), aes(label = rank, color = color), x = 1994, hjust = 0, family = ""Oswald"") +
  geom_text(data = filter(oecd_data, year == max(year)), aes(label = country, color = color), x = 2016.5, hjust = 0, family = ""Oswald"") +
  expand_limits(x = c(1994, 2019)) +
  scale_x_continuous(breaks = 1995:2016) +
  scale_color_identity() +
  theme_jk(dark = TRUE, grid = FALSE) +
  theme(axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Canada is Losing a Step In the Global Research Race."",
       subtitle = str_wrap(""Shown below is the ranking of research intensity (% of Gross Domestic Product devoted to Research) from 1995-2016. Canada has been on a decline since hitting a peak in 2001.  Most notably is 2009-2016, which coincides with the systematic defunding of Canadian research scientists by the Conservative Harper Government."", 120),
       caption = ""Data: OECD | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week7"", ""tw7_plot.png""), plot, width = 9, height = 4.5)
","2019-7"
"58",58,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week8/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(readxl)
library(janitor)
library(jkmisc)
library(scales)
library(egg)

parse_table31 <- function(file) {
  
  df <- file %>% 
    read_excel(na = ""na"") %>% 
    clean_names()
  
  start <- min(str_which(df$x3,""\\d{4}""))
  
  end <- pull(df, 1) %>% 
    str_which(""Since"") %>% 
    max()
  
  df <- slice(df, start:end)
  
  field_idx <- select(df, -1) %>% 
    map_df(is.na) %>% 
    pmap_lgl(all)
  
  labels <- select(df, 1) %>%
    filter(field_idx) %>% 
    na.omit() %>% 
    pull() %>% 
    str_remove(""[abcd]$"")
  
  years <- slice(df, 1) %>% 
    select(-1) %>% 
    flatten_chr() %>% 
    str_remove(""\\.0+$"")
  
 rep <- filter(df, !field_idx) %>% 
    slice(-1) %>% 
    select(1) %>% 
    n_distinct()
  
  filter(df, !field_idx) %>% 
    slice(-1) %>% 
    mutate(discipline = rep(labels, each = rep)) %>% 
    set_names(c(""category"", years, ""discipline"")) %>% 
    gather(year, value, matches(""[0-9]{4}"")) %>% 
    mutate_at(vars(-category, -discipline), as.numeric) %>% 
    mutate_at(""category"", function(x) str_remove(x, ""[abcd]$""))
  
  
}


files <- here(""2019"",""week8"",""data"") %>% 
  dir_ls() 

data <- map_df(files, parse_table31) %>% 
  ungroup() %>% 
  distinct()

plot_data <- data %>% 
  filter(discipline != ""Other"", !str_detect(category, ""doctoral"")) %>% 
  filter(!str_detect(discipline, ""and (?!computer)"")) %>% 
  filter(!str_detect(discipline, ""Physical"")) %>% 
  arrange(year) %>% 
  group_by(category, discipline, year) %>% 
  summarize(value = mean(value, na.rm = TRUE)) %>% 
  ungroup()

plot <- ggplot(plot_data, aes(x = year, y = value, color = discipline)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(breaks = pretty_breaks(), limits = c(0, 25)) +
  scale_color_manual(""Discipline"", values = tol7qualitative) +
  scale_x_continuous(limits = c(1985, 2017)) +
  expand_limits(x = c(1985, 2025)) +
  facet_wrap(~category, labeller = as_labeller(str_to_title), nrow = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""Median Completion Time for Doctoral Degrees Are Getting Shorter"",
       subtitle = str_wrap(""Median completion time in years from 1985 to 2017 contrasting selected disciplines for both University and Graduate School experience.  Education, Humanities and Social Sciences doctoral candidates have a higher than average time to completion in both categories compared to other disciplines. "", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

ggsave(here('2019','week8',""tw8_plot.png""), plot, width = 10, height = 7)


bonus_plot_data <- plot_data %>% 
  filter(discipline == ""All fields"") %>% 
  rename(overall = value) %>% 
  select(-discipline) %>% 
  left_join(filter(plot_data, discipline != ""All fields"")) %>% 
  mutate(diff = abs(value - overall)/2) %>%
  filter(between(year, 1990, 2011))


order <- c(""Education"", ""Mathematics and computer sciences"",  ""Engineering"", ""Humanities"",""Life sciences"", 
   ""Social sciences"")

bonus_plot <- ggplot(bonus_plot_data, aes(ymin = -diff, ymax = diff, x = year, fill = fct_relevel(discipline, order))) +
  geom_ribbon(color = ""white"", size = 0.2, alpha = 0.8) +
  geom_segment(data = filter(bonus_plot_data, year == 2000, category == ""Since bachelor's"", discipline == ""Education""), aes(y = -diff, yend = diff, x = year, xend = year), color = ""grey20"", arrow = arrow(length = unit(0.25, ""cm""), ends = ""both"", type = ""closed"")) +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  scale_fill_viridis_d(""Discipline"") +
  scale_y_continuous(breaks = c(-5, -2.5, -1, 0, 1, 2.5, 5), labels = c(""10 Years"", ""5 Years"", ""2 Years"", ""Group Median"", ""2 Years"", ""5 Years"", ""10 Years"")) +
  labs(x = NULL,
       y = NULL,
       title = ""Relative Differences in Median Doctoral Completion Time from the Group Median by Discipline and Interval"",
       subtitle = str_wrap(""The streamgraph below presents the difference between discipline median completion time and the group median completion time (All Fields) as the width of each colored band (discipline) from 1990 to 2011."", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

bonus_plot <- tag_facet(bonus_plot, x = 1996, y = 5.5, open = """", close = """", tag_pool = c(""Difference from Group Median = 9.1 years"", """"),  fontface = 1, family = ""Oswald"") 



ggsave(here('2019','week8',""tw8_bonus_plot.png""), bonus_plot, width = 12, height = 6)
","2019-8"
"59",59,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week9/R/analysis.R","library(tidyverse)
library(here)
library(ggforce)
library(jkmisc)
library(sf)
library(osmdata)

full_trains <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

available_tags(""railway"")

railways <- st_read(here(""2019"", ""week9"", ""data"", ""railways.shp""))

q <- getbb(""fr"") %>%
  opq(timeout=25*1000)%>%
  add_osm_feature(""railway"")

stations <- osmdata_sf(q)

ggplot(stations$osm_lines) +
  geom_sf()

railways$geometry[[1]] %>% st_coordinates() %>% as_tibble -> line

ggplot(line, aes(x = X, y = Y)) +
  geom_link2() +
  coord_sf(datum=NA)

nat_trains <- full_trains %>% 
  filter(service == ""National"") %>% 
  group_by(year, departure_station, arrival_station) %>% 
  summarize_at(vars(journey_time_avg, total_num_trips, avg_delay_late_at_departure, avg_delay_late_on_arrival), mean, na.rm = TRUE)


# Orbit test

centre <- ""PARIS LYON""

test_data <- filter(nat_trains, departure_station == centre | arrival_station == centre) %>% 
  arrange(departure_station)



positions <- test_data %>% 
  filter(arrival_station == centre) %>% 
  group_by(arrival_station, departure_station) %>% 
  summarize(dist = mean(journey_time_avg)) 


circles <- test_data %>% 
  group_by(departure_station) %>% 
  summarize(centre_radius = mean(avg_delay_late_at_departure)) %>% 
  left_join(positions)

main <- circles %>% 
  filter(departure_station == centre)

circles <- circles %>% 
  filter(departure_station != centre) %>% 
  mutate(fraction = nrow(.) - (nrow(.) - seq_along(departure_station)),
         delta = 360/nrow(.)*fraction) %>% 
  bind_rows(main) %>% 
  mutate(x0 = if_else(departure_station == centre, 0, dist*cos((delta*pi/180))),
         y0 = if_else(departure_station == centre, 0, dist*sin((delta*pi/180)))) 


link_coords <- function(dept, arr, lnk) {
  
  circles %>% 
    filter(departure_station == dept | departure_station == arr) %>%
    summarise(x = ifelse(lnk == ""from"", x0[x0 != 0], 0),
           xend = ifelse(lnk == ""from"", 0, x0[x0 != 0]),
           y = ifelse(lnk == ""from"", y0[y0 != 0], 0),
           yend = ifelse(lnk == ""from"", 0, y0[y0 != 0]))
  
  
  
}

links <- test_data %>% 
  group_by(departure_station, arrival_station) %>% 
  mutate(total_delay = ((avg_delay_late_at_departure + avg_delay_late_on_arrival)/journey_time_avg),
         total_trips = sum(total_num_trips)) %>% 
  summarize(size = mean(total_delay),
            alpha = mean(total_num_trips)/max(total_num_trips)) %>% 
  mutate(link = if_else(departure_station == centre, ""to"", ""from"")) %>% 
  ungroup() %>% 
  mutate(links = pmap(list(departure_station, arrival_station, link), ~link_coords(..1, ..2, ..3))) %>% 
  unnest() %>% 
  arrange(link, departure_station)




ggplot() +
  geom_curve(data = links, aes(x = x, xend = xend, y = y, yend = yend, size = size, color = link, alpha = alpha), lineend = ""round"", angle = 270) +
  geom_circle(data = circles, aes(x0 = x0, y0 = y0, group = departure_station, r = 5), fill = ""white"", color = ""#2b41a7"") +
  scale_size(range = c(1,6)) +
  scale_color_manual(values = c(""#2b41a7"", ""#c7ad24"")) +
  scale_fill_distiller(palette = ""Greys"")+
  scale_alpha_identity() +
  labs(x = NULL, y = NULL) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank())

","2019-9"
"60",60,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week1/R/tw1_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(ggrepel)

tidy_data <- dir(here(""week1"", ""data""), full.names = TRUE, pattern = ""us_avg"") %>%
  read_excel() %>%
  gather(year, avg_tuition, -State) %>%
  rename(state = State)


nat_avg <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  group_by(year) %>%
  summarize(avg_tuition = mean(avg_tuition)) %>%
  mutate(state = ""National Average"")


plot_data <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  left_join(select(nat_avg, year, nat_avg = avg_tuition), by = ""year"") %>%
  bind_rows(nat_avg)

labels <- plot_data %>%
  group_by(state) %>%
  filter(all(avg_tuition > nat_avg)) %>%
  pull(state) %>%
  unique()

plot <- plot_data %>%
  ggplot(., aes(x = year, y = avg_tuition, group = state)) +
  geom_text_repel(data = filter(plot_data, state %in% labels, year == ""2015-16""), aes(label = state), direction = ""y"", nudge_x = 0.1, segment.size = 0.1, hjust = 0, family = ""Oxygen"", size = 3) +
  geom_path(color = ""grey50"", size = 0.5, alpha = 0.5) +
  geom_point(color = ""grey50"") +
  geom_path(data = nat_avg, color = ""red"", size = 1) +
  geom_point(data = nat_avg, color = ""red"") +
  scale_y_continuous(labels = scales::dollar) +
  labs(x = NULL, y = NULL, title = ""Comparison of the average US tuition growth between 2005 and 2015"", subtitle = ""Eastern and Northeastern students consistently face tutition above the national average, indicated by the red line."", caption = ""\nData: http://trends.collegeboard.org/ | Graphic: @jakekaupp"") +
  theme_minimal(base_family = ""Oswald Light"") +
  theme(panel.grid.minor = element_blank())

ggsave(plot, filename = glue('{here(""week1"")}/tidyweek-{Sys.Date()}.png'), height = 8, width = 6, dpi = 300)

","2018-1"
"61",61,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week11/R/tw11_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)

raw_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week11_fifa_audience.csv"") %>% 
  select(-X1)

font_add_google(""Oswald"",""Oswald-Light"", regular.wt = 300)
font_add_google(""Scope One"",""Scope One"")

showtext_auto()

vplayout <- function(x, y) viewport(width=11/3, height=8.5, layout.pos.row = x, layout.pos.col = y)

build_treemap <- function(x, y, size)  {
  
  title <- set_names(c(""Population Share"", ""TV Audience Share"", ""GDP Weighted Share""), c(""population_share"",""tv_audience_share"", ""gdp_weighted_share""))
  
  treemap(raw_data,
          index = c(""confederation"",""country""),
          vSize = size,
          vColor = ""confederation"",
          type = ""categorical"",
          title = title[size],
          title.legend = """",
          fontfamily.title = ""Oswald-Light"",
          fontsize.labels = c(20, 10),
          fontfamily.labels = ""Oswald-Light"",
          fontcolor.labels = ""#f0f0f0"",
          lowerbound.cex.labels = 1,
          bg.labels = 0,
          inflate.labels = FALSE,
          border.col = ""white"",
          border.lwds = 1,
          position.legend = ""none"",
          palette = nord(""baie_mouton""),
          align.labels = list(c(""left"",""top""), c(""right"",""bottom"")),
          drop.unused.levels = TRUE,
          vp = vplayout(x,y))
  
  
  
}

fifa_maps <- function() {
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(3, 3, heights = c(0.1, 0.8, 0.1))))
  par(mai=c(0,0,0,0))
  
  grid.text(""Comparing FIFA Share Differences by Confederation and Country"", x = 0.1, hjust = 0, vp = vplayout(1,1), gp = gpar(fontfamily = ""Oswald-Light"", fontsize = 30))
  build_treemap(2, 1, ""population_share"")
  build_treemap(2, 2, ""tv_audience_share"")
  build_treemap(2, 3, ""gdp_weighted_share"")
  grid.text(""Data: fivethirtyeight.com | Graphic: @jakekaupp"", x = 0.5, vp = vplayout(3,3), gp = gpar(fontfamily = ""Scope One"", fontsize = 10))
  
}

png(here(""week11"", ""Fifa Treemaps.png""), width = 11, height=8.5, units = ""in"", res = 100)
fifa_maps()
dev.off()

","2018-11"
"62",62,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week12/R/tw12_plot.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(ggridges)
library(nord)
library(here)
library(showtext)

font_add_google(""Oswald"", ""Oswald"", regular.wt = 400)
font_add_google(""Scope One"", ""Scope One"")

trend_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_google_trends.csv"", skip = 2, col_names = TRUE) %>% 
  set_names(str_extract(names(.), ""(?<=Hurricane )(\\w+)|(Day)"")) %>% 
  rename(Date = Day) %>% 
  mutate(source = ""Google Trends"") %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

mediacloud_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_mediacloud_hurricanes.csv"", col_names = TRUE) %>% 
  mutate(source = ""Online News"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_tv_hurricanes.csv"") %>% 
  mutate(source = ""TV"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

all_data <- bind_rows(trend_data, mediacloud_data, tv_data) %>%
  gather(hurricane, value, -Date, - source) %>% 
  set_names(tolower(names(.)))

showtext_auto()

plot <- ggplot(all_data, aes(x = date, y = source)) +
  geom_ridgeline(aes(height = value, fill = factor(hurricane)), size = 0.1, scale = 0.8, alpha = 0.8) +
  labs(title = ""On nearly every form of media, hurricanes that hit mainland US received more sustained coverage than Maria in Puerto Rico"",
       subtitle = ""Ridgeline plots of normalized media shares (TV, Online News and Google Trends)"",
       caption = ""Data: fivethirtyeight | Graphic: @jakekaupp"",
       y = NULL,
       x = NULL) +
  scale_x_date(expand = c(0,0)) +
  scale_fill_nord(name = ""Hurricane"", palette = ""lumina"") +
  theme_jk(plot_title_size = 28, subtitle_size = 24, base_size = 20, caption_size = 12,  grid = ""X"") +
  theme(axis.text.y = element_text(vjust = -2))

ggsave(plot, filename = here(""week12"", ""ROCK YOU LIKE A HURRICANE.png""), width = 6, height = 3)
","2018-12"
"63",63,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week18/R/tw18_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)
library(readxl)
library(ggalt)
library(jkmisc)


raw_data <- read_xlsx(here(""week18"", ""data"", ""week18_dallas_animals.xlsx""), sheet = 1)

data <- raw_data %>% 
  filter(animal_type %in% c(""CAT"",""DOG""), mo_year == ""2017"") %>% 
  count(animal_type, month, mo_year, outcome_type) %>% 
  group_by(animal_type, month, mo_year) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  select(-n) %>% 
  filter(outcome_type %in% c(""EUTHANIZED"",""ADOPTION"")) %>% 
  mutate_if(is.character, tolower) %>%
  spread(outcome_type, percent) %>% 
  mutate_if(is.character, tools::toTitleCase) %>% 
  mutate(month = ifelse(month == ""may"", ""May"", month)) %>% 
  arrange(month) %>% 
  complete(month = month.abb, mo_year, animal_type, fill = list(adoption = NA, euthanized = NA)) %>% 
  mutate(ratio = adoption/euthanized) %>% 
  mutate(month = factor(month, month.abb))



ggplot(data, aes(x = month, y = ratio, group = animal_type, color = animal_type)) +
  geom_hline(yintercept = 1.0, size = 0.1, color = ""firebrick"", linetype = ""dashed"") +
  geom_line(size = 0.5) +
  geom_text(data = filter(data, month == ""Sep""), aes(label = animal_type), nudge_x = 0.3, family = ""Oswald"") +
  theme_jk(grid = ""XY"") +
  scale_color_nord(""victory_bonds"") +
  labs(x = NULL, y = ""Ratio of Adopted/Euthanized"", title = ""2017 was a bad time to be a cat in a shelter"", subtitle = ""Cats in the shelters were euthanized more than adopted compared to dogs."") +
  theme(legend.position = ""none"")
  



","2018-18"
"64",64,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week2/R/tw2_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(janitor)
library(rvest)
library(nord)
library(jkmisc)
library(viridis)

# Function to scrape the top avg cap salary by player ----
pull_position_data <- function(year, position) {
  
  Sys.sleep(5)
  
  url <- glue(""http://www.spotrac.com/nfl/positional/{year}/{position}"")
  
  read_html(url) %>% 
    html_nodes(""#main > div.teams > table:nth-child(6)"") %>% 
    html_table() %>%
    flatten_df() %>% 
    set_names(c(""rank"",""player"",""cap_dollars"", ""cap_percent""))
}


# Formatter for 538 year labels 
labels_538 <- function(labels) {
  labels_out <- sprintf(""20%s"", str_sub(labels, 3, 4))
  labels_out <- c(labels_out[1], glue(""'{str_sub(labels_out[-1], 3, 4)}""))
  return(labels_out)
}

# Create the data scaffold 
years <- 2011:2018
positions <- c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"",""defensive-end"",""cornerback"",""defensive-tackle"", ""inside-linebacker"", ""outside-linebacker"", ""free-safety"", ""strong-safety"", ""kicker"",""punter"",""long-snapper"")

scaffold <- tibble(year = years,
                   position = list(positions)) %>% 
  unnest() 

# Populate the scaffold
if(!file.exists(here(""week2"", ""data"", ""position_cap_data_named.RDS""))) {
  
  scaffold <- scaffold %>% 
    mutate(data = map2(year, position, ~pull_position_data(.x, .y))) %>% 
    unnest() %>% 
    mutate_at(c(""cap_dollars"", ""cap_percent""), parse_number) %>% 
    mutate(side = case_when(position %in% c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"") ~ ""Offense"",
                            position %in% c(""kicker"",""punter"",""long-snapper"") ~ ""Special Teams"",
                            TRUE ~ ""Defense""))
  
  
  # Save it to avoid re-scraping 
  saveRDS(scaffold, file = here(""week2"", ""data"", ""position_cap_data_named.RDS""))
} else {
  
  scaffold <- readRDS(here(""week2"", ""data"", ""position_cap_data_named.RDS""))
  
}


# Make data for the plot
plot_data <- scaffold %>% 
  group_by(year, position, side) %>% 
  top_n(16, cap_dollars) %>% 
  summarize(avg_pay = mean(cap_dollars))
  
# Make a heatmap!
ggplot(plot_data, aes(x = year, y = position, fill = avg_pay)) +
  geom_tile(color = ""white"", size = 0.1) +
  coord_equal() +
  labs(x = NULL, y = NULL, title = ""The Fullback Gets No Respect"", subtitle = ""Average cap value of the 16 highest payed players in all positions"", caption = ""Data: http://www.spotrac.com/ | Graphic: @jakekaupp"") +
  scale_x_continuous(labels = labels_538, breaks = 2011:2018) +
  scale_y_discrete(labels = function(x) str_to_title(gsub(""[[:punct:]]"", "" "", x))) +
  scale_fill_viridis(discrete = FALSE, labels = scales::dollar, name = ""Average Salary"") +
  theme_jk(grid = FALSE, base_size = 14)

ggsave(here(""week2"", ""tw2_heatmap.png""), width = 8, height = 8)
","2018-2"
"65",65,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week3/R/tw3_plot.R","library(tidyverse)
library(here)
library(readxl)
library(jkmisc)

# Read in the data
mortality_data <- dir(here(""week3"",""data""), pattern = ""global"", full.names = TRUE) %>% 
  read_excel()


# Tidy up the data
tidy_mort <- mortality_data %>% 
  gather(cause_of_death, percentage, -country:-year) %>% 
  mutate(cause_of_death = trimws(str_remove(cause_of_death, ""\\(\\%\\)""))) %>% 
  mutate(percentage = ifelse(is.na(percentage), NA, percentage/100))

# Get just the data pertaining to suicides
suicide_data <- tidy_mort %>% 
  filter(cause_of_death == ""Suicide"", !is.na(country_code))

# Get the World percentage
global_rate <- suicide_data %>% 
  filter(country == ""World"") %>% 
  select(year, percentage)

# Get the top 40 problem countries, those with the suicide rate constantly over the world average (note the all statement in the filter)
problem_countries <- suicide_data %>% 
  filter(country != ""World"") %>% 
  left_join(global_rate, by = ""year"") %>% 
  group_by(country) %>% 
  filter(all(percentage.x > percentage.y)) %>% 
  summarize(percentage = mean(percentage.x, na.rm = TRUE)) %>% 
  top_n(40, percentage) %>% 
  arrange(desc(percentage)) %>% 
  pull(country)

# Create the data to make the plot, and arrange descending by the overall avg rate of suicide
plot_data <- suicide_data %>% 
  filter(country %in% problem_countries) %>% 
  mutate(country = factor(country, problem_countries))

# Create the sad plot
sad_plot <- ggplot(plot_data, aes(x = year, y = percentage)) +
  geom_segment(aes(x = min(year), xend = max(year), y = 0, yend = 0)) +
  geom_area(fill = ""steelblue4"") +
  geom_path(color = ""grey30"", size = 0.2) +
  geom_area(data = global_rate, fill = ""steelblue3"") +
  geom_path(data = global_rate, color = ""grey30"", size = 0.2) +
  facet_wrap(~country, nrow = 5) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = ""Countries Coping With the Tradgedy and Pain of Suicide"",
       subtitle = ""Dark blue indicates suicide rate by year, Light blue fill indicates the global average suicide rate by year."",
       x = NULL,
       y = NULL,
       caption = ""Data: ourworldindata.org | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"")

# Save the sad plot
ggsave(here(""week3"",""tw3_sad_plot.png""), sad_plot, width = 16, height = 10)
","2018-3"
"66",66,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week4/R/tw4_plot.R","library(tidyverse)
library(here)
library(jkmisc)
library(scales)
library(ggiraph)
library(glue)
library(waffle)

make_tooltip <- function(occupation, female, male, income_gap, ...) {
 
  glue('<div class=""tipchart"">
      <h3>{occupation}</h3>
      <h4>Mens taxable income {ifelse(income_gap <= 1, percent(1-round(income_gap, 2)), percent(round(income_gap, 2)))} {ifelse(income_gap <= 1, ""less"", ""more"")} than womens</h4>
      <table>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Male Taxable Income:</td>
      <td class=""tiptext"">{dollar(male)}</td>
      </tr>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Female Taxable Income:</td>
      <td class=""tiptext"">{dollar(female)}</td>
      </tr>
      </table>
      </div>')
  
}


# Read in the data
income_data <- dir(here(""week4"",""data""), pattern = ""salary"", full.names = TRUE) %>% 
  read_csv(locale = locale(""en""))
 
# Clean occupation up a bit.  Some rouge unicodes in there.
tidy_gap <- income_data %>% 
  mutate(occupation = iconv(occupation, ""UTF-8"", ""UTF-8"",sub='')) %>% 
  spread(gender, average_taxable_income) %>%
  set_names(tolower(names(.))) %>% 
  group_by(occupation) %>% 
  summarize_at(c(""female"", ""male""), sum, na.rm = TRUE) %>% 
  filter(female != 0, male != 0) %>% 
  mutate(income_gap = male/female)

plot_data <- tidy_gap %>% 
 mutate(fill = if_else(income_gap >= 1, ""grey80"", ""#ffd700""),
         alpha = if_else(income_gap >= 1, 0.2, 1)) %>% 
  mutate(tooltip = pmap(., make_tooltip)) %>% 
  mutate(tooltip = gsub(""\\\n"", """", tooltip)) %>% 
  mutate(tooltip = gsub(""'"", """", tooltip)) %>% 
  mutate(idx = row_number())

tooltip_css <- ""background-color:white;padding:10px;border-radius:20px 20px 20px 20px;border-color:black;border-style:solid;border-width:1px""

plot <- ggplot(plot_data, aes(x = female, y = male, fill = fill)) +
  geom_segment(x = 0, xend = 600000, y = 0, yend = 600000, size = 0.05, color = ""grey80"") +
  geom_point_interactive(aes(alpha = alpha, tooltip = tooltip, data_id = idx), shape = 21, color = ""grey30"", size = 3) +
  scale_y_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_x_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Gender Differences in Taxble Income in Australia"",
       subtitle = str_wrap(""Average male taxable income plotted against average female taxable income by occupation. Yellow dots indicate occupations where women have more taxable income than their male counterparts, 
       line indicates income equality. Hover over points for occupation, % difference and detailed income."", 100),
       caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme_jk()

ggiraph(ggobj = plot, width_svg = 9, width = 1, tooltip_extra_css = tooltip_css)

waffle_data <- tidy_gap %>% 
  ungroup() %>% 
  mutate(category = case_when(income_gap > 1 ~ ""Men have more income"",
                              income_gap < 1 ~ ""Women have more income""))%>% 
  count(category) %>% 
  pull(n) %>% 
  set_names(., c(""Men have more income"", ""Women have more income""))

waffle(waffle_data, 
       rows = 14,
       size = 1,
       colors = c(""dodgerblue3"", ""deeppink""), 
       legend_pos = ""bottom"", 
       title = ""Out of 1092 occupations on record, men have more taxable income than women in 1011 of them.  That's 92.5% of occupations for those counting at home."") + 
  theme_jk() +
  labs(caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme(axis.text = element_blank(),
        legend.position = ""bottom"")
","2018-4"
"67",67,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week5/R/tw_5plot.R","library(tidyverse)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)


census_data <- dir(here(""week5"", ""data""), full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

# Lets look at commuting!
commuting_data <- census_data %>% 
  select(census_id, state, county, total_pop, drive:mean_commute)

# Despacito is 3:47 in length
despacito_length <- 3 + 47/60

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") 

# Calculate the how many despacitos the average commute has
despacito_commute <- commuting_data %>% 
  mutate(despacitos = mean_commute/despacito_length,
         id = ifelse(str_length(as.character(census_id)) < 5, glue(""0{census_id}""), as.character(census_id))) %>% 
  right_join(us_map)


# Make the map!
map <- ggplot() +
 geom_map(data = us_map, map = us_map,
                    aes(x = long, y = lat, map_id = id),
                    color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = despacito_commute, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = despacitos),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis(name=""How many despactios?"", na.value = viridis(5, option = ""cividis"")[3], option = 'cividis', breaks = seq(1,12,2)) +
  labs(title = ""Just how much do you like your commute?"",
       subtitle = str_wrap(""What if your commute was defined by hearing a song on repeat?  
                           What if that song was the most streamed song on the planet, Despacito? 
                           Illustrated below is the average number of times you'd hear it on your way home across the US."", 80),
       caption = ""Data: census.gov | Graphic: @jakekaupp"") +
  coord_map() +
  theme_map(base_family=""Scope One"", 
            base_size = 16) +
  theme(legend.title = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        plot.caption = element_text(size = 10),
        legend.position = c(0.9,0.1))

ggsave(here(""week5"", ""tw5_choropleth map.png""), width = 10, height = 6)


","2018-5"
"68",68,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week6/R/tw_6plot.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(glue)
library(fuzzyjoin)
library(stringi)
library(ggalt)
library(jkmisc)
library(nord)



provinces <- set_names(c(""Alberta"", ""British Columbia"", ""Manitoba"", ""New Brunswick"", ""Newfoundland and Labrador"",
                         ""Nova Scotia"", ""Northwest Territories"", ""Nunavut"", ""Ontario"", ""Prince Edward Island"", ""Quebec"",
                         ""Saskatchewan"", ""Yukon""),
                       c(""AB"", ""BC"", ""MB"", ""NB"", ""NL"", ""NS"", ""NT"", ""NU"", ""ON"", ""PE"", ""QC"", ""SK"", ""YT""))

# Just get the Tims data just for Canada
tim_hortons <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""xlsx"") %>% 
  read_excel(sheet = ""timhorton"") %>% 
  filter(country == ""ca"") %>% 
  rename(province = state) 

# Counts at the City/Province level
tims_city_prov <- tim_hortons %>% 
  count(city, province)

# Counts at the National level
tims_national <- tim_hortons %>% 
  count(province) %>% 
  mutate(color = ifelse(province == ""ON"", nord(""victory_bonds"", 1), ""grey50""))

national <- ggplot(tims_national, aes(x = reorder(province,n), y = n)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0.01,0.05),  breaks = scales::pretty_breaks()) +
  scale_x_discrete(labels = function(x) provinces[x]) +
  coord_flip() +
  labs(x = NULL, y = NULL, title = ""Ontario, we have a problem...."", subtitle = ""The highest number of Tim Hortons per province goes to Ontario, a land where you can't even get an oat cake."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = national, here(""week6"", ""National Tims.png""), width = 10, height = 6)

census_2011 <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""2011 census"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  remove_empty(""rows"") %>% 
  select(city = geographic_name, population = population_2011) %>% 
  mutate(province = stri_extract_last_regex(city, ""\\(([A-Za-z\\.]+?)\\)""),
         city = stri_replace_all_regex(city, ""\\((.*?)\\)"", """"),
         province = gsub(""[[:punct:]]"", """", province)) %>% 
  mutate(province = case_when(province == ""Que"" ~ ""QC"",
                              province == ""Ont"" ~ ""ON"",
                              province == ""Man"" ~ ""MB"",
                              province == ""Sask"" ~ ""SK"",
                              province == ""Alta"" ~ ""AB"",
                              province == ""NWT"" ~ ""NT"",
                              province == ""Nvt"" ~ ""NU"",
                              province == ""PEI"" ~ ""PE"",
                              TRUE ~ province)) %>% 
  mutate_if(is.character, trimws)



tims_density <- regex_right_join(census_2011, tims_city_prov,  by = c(""city"", ""province""), ignore_case = TRUE) 


plot_data <- tims_density %>% 
  select(population, city = city.y, province = province.x, n) %>% 
  group_by(city, province) %>% 
  summarize_at(c(""n"", ""population""), sum, na.rm = TRUE) %>% 
  ungroup() %>% 
  filter(population != 0, n > 1, population > 10000) %>% 
  mutate(density = (n/(population/1000))) %>% 
  top_n(25, density) %>% 
  mutate(color = ifelse(density == max(density), nord(""victory_bonds"", 1), ""grey50""))


most_tims <- ggplot(plot_data, aes(x = reorder(city, density), y = density)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0,0.01),  breaks = scales::pretty_breaks(), limits = c(0,1.2)) +
  coord_flip() +
  labs(y = ""Number of Tim Hortons stores per 1,000 people"", x = NULL, title = ""However, the title of most Tim Hortons per capita belongs to Cold Lake, Alberta"", 
       subtitle = ""When looking at towns/cities with population > 10,000 and with more than two Tim Hortons. \nMy hometown of Truro, Nova Scotia comes in a puzzling fourth."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = most_tims, here(""week6"", ""Most Tims.png""), width = 10, height = 6)

","2018-6"
"69",69,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week7/R/tw_7plot.R","library(tidyverse)
library(here)
library(janitor)
library(likert)
library(jkmisc)
library(nord)

star_wars <- dir(here(""week7"", ""data""), pattern = ""StarWars"", full.names = TRUE) %>% 
  read_csv() 

clean_names <- stringi::stri_trans_general(names(star_wars), ""latin-ascii"") %>% 
  gsub(""[^\\x{00}-\\x{7f}]"", """", ., perl = TRUE) %>% 
  clean_names()

star_wars <- set_names(star_wars, clean_names) 

headers <- slice(star_wars, 1) %>% 
  flatten_chr()

clean_names <- gsub(""X\\d+"", NA_character_, clean_names) %>% 
  enframe() %>% 
  fill(value) %>% 
  pull(value)


shiny_clean_names <- paste(clean_names, headers, sep = ""|"")

long_star_wars <- set_names(star_wars, c(""RespondentID"", shiny_clean_names[-1])) %>% 
  slice(-1) %>% 
  gather(item, value, -1) %>% 
  separate(item, c(""question"", ""category""), sep = ""\\|"") %>% 
  mutate(category = if_else(category == ""Response"", NA_character_, category)) %>% 
  mutate(index = group_indices(., question))


plot_data <- long_star_wars %>% 
  filter(index == 12) %>% 
  replace_na(list(value = ""Unfamiliar (N/A)"")) %>% 
  filter(value != ""Unfamiliar (N/A)"") %>% 
  spread(category, value) %>% 
  mutate_at(vars(-RespondentID, -question, -index), function(x)
    factor(x, 
            levels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""),
            labels = 1:5
    )) 
            
            
likert_data <- plot_data %>% 
  select(-RespondentID, -question, -index) %>%
  as.data.frame() %>% 
  likert()


ggplot2::update_geom_defaults(""text"", list(family = ""Scope One"", size = 4))
  
plot <- likert.bar.plot(likert_data) + 
  scale_fill_nord(""mountain_forms"", labels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""), name = ""Response"") +
  labs(title = ""The Favorability Rankings of Star Wars Characters"", subtitle = ""People look favourably upon the scruffy nerf herder, and would give a ride to the EVIL RAISIN THAT SHOOTS LIGHTNING FROM HIS HANDS before the goofy gungan."") +
  theme_jk(grid = ""XY"") +
  theme(plot.title = element_text(family = ""Oswald""))

ggsave(here(""week7"", ""tw7_likert.png""), width = 16, height = 10)
  
  
 
","2018-7"
"70",70,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week1/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)


# week-of-month function
wom <- function(date) { 
  first <- wday(as.Date(paste(year(date),month(date),1,sep=""-"")))
  return((mday(date)+(first-2)) %/% 7+1)
}

# Get the TidyTuesday Tweets Data
tt_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""tidytuesday_tweets.rds""))

# Get the R tweet data 
r_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""rstats_tweets.rds""))

# Most that tweet about R tweet about the r4ds tidy tuesday.
no_rstats <- anti_join(tt_tweet_data, r_tweet_data, by = ""screen_name"") %>% 
  mutate(rstats_tag = case_when(grepl(""rstats"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""r4ds"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""visualization"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""data"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""code"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""plot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""chart"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""graph"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""drob"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""ggplot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""rstudio"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""model"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""median"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""average"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""week \\d+"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""@thomas_mock"", text, ignore.case = TRUE) ~ TRUE,
                                TRUE ~ FALSE)) %>% 
  mutate(rstats_tag = case_when(screen_name %in% c(""NosyOwl"", ""sebastianhwells"", ""JenniferCai7"", ""matthwong"",
                                                   ""scrite_jones"", ""jrosenblum123"", ""zlipp"") ~ TRUE,
                                TRUE ~ rstats_tag)) %>% 
  filter(rstats_tag == FALSE)
  

plot_data <- anti_join(tt_tweet_data, no_rstats, by = ""screen_name"") %>% 
  mutate(created_at = as_date(created_at)) %>% 
  mutate(day = wday(created_at, label = TRUE, abbr = FALSE),
         week = wom(created_at),
         iweek = isoweek(created_at),
         month = month(created_at, label =  TRUE, abbr = FALSE),
         year = year(created_at))


count(plot_data, day, iweek) %>% 
  complete(day, iweek = 1:52, fill = list(n = NA)) %>% 
  ggplot(aes(x = iweek, y = day, fill = n)) +
  geom_tile(color = ""white"", size = 0.1) +
  scale_fill_viridis_c(""Tweet Frequency"", option = ""cividis"", na.value = ""grey95"", labels = seq(0,25,5), breaks = seq(0,25,5), limits = c(0,25)) +
  coord_equal() +
  labs(title = ""Tidy Tuesday or Tardy Tuesday?"",
       subtitle = ""A glance at when the community decides to submit their work."",
       y = NULL,
       x = ""Week of the Year"",
       caption = ""Data: rtweet | Analysis: @jakekaupp"") +
  scale_x_continuous(limits = c(1, 53), breaks = c(1,10,20,30,40,50), expand = c(0, 0)) +
  theme_jk(grid = FALSE, ticks = FALSE) +
  theme(legend.position = c(0.5,-0.7),
        legend.direction = ""horizontal"",
        legend.title = element_text(family = ""Scope One"", vjust = 0.8))

ggsave(here(""2019"", ""week1"",""tidy_or_tardy.png""), width = 8, height = 4)
","2019-1"
"71",71,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week10/R/analysis.R","library(tidyverse)
library(jkmisc)
library(ggrepel)
library(here)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")


plot_data <- jobs_gender %>% 
  select(-year) %>% 
  group_by(occupation, major_category, minor_category) %>% 
  summarize_all(mean, na.rm = TRUE) %>% 
  filter(str_detect(occupation, ""engineer""), str_detect(major_category, ""Engineering"")) %>% 
  mutate(diff = if_else((total_earnings_female - total_earnings_male) > 0, ""firebrick"", ""grey80"")) %>% 
  mutate(alpha = if_else(diff == ""firebrick"", 1, 0.2)) %>% 
  gather(variable, value, starts_with(""total_earnings_"")) %>% 
  mutate(variable = factor(variable, c(""total_earnings_male"", ""total_earnings_female""), c(""Men"", ""Women"")))
 
slope_data <- build_slopegraph(plot_data, ""variable"", ""value"", ""occupation"") %>% 
  left_join(distinct(plot_data, occupation, diff, alpha), by = c(""group"" = ""occupation"")) %>% 
  mutate(group = case_when(str_detect(group, ""Mining"") ~ ""Mining Engineers"",
                                str_detect(group, ""Computer"") ~ ""Computer Engineers"",
                                str_detect(group, ""Electrical"") ~ ""Electrical Engineers"",
                                str_detect(group, ""Marine"") ~ ""Marine Engineers"",
                                str_detect(group, ""Industrial"") ~ ""Industrial Engineers"",
                           TRUE ~ str_to_title(group))) %>% 
  mutate(group = str_replace(group, ""Engineers"", ""Engineering""))


labels <- pretty(slope_data$y, 9)
breaks <- pretty(slope_data$ypos, 5)


plot <- ggplot(slope_data, aes(x = x, y = ypos, group = group, color = diff)) +
  geom_point() +
  geom_line() +
  geom_label_repel(data = filter(slope_data, x == ""Women""), aes(label = group), direction = ""y"", hjust = 0, nudge_x = 1, segment.alpha = 0.3, family = ""Oswald"", label.size = 0, fill = ""white"") +
  theme_jk(grid = ""XY"") +
  expand_limits(x = c(0, 5)) +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_y_continuous(labels = scales::dollar(labels), breaks = breaks, limits = range(breaks)) +
  theme(panel.grid.major.x = element_line(linetype = ""dashed"", color = ""black"")) +
  labs(x = NULL,
       y = NULL,
       title = ""The Unnecessary and Unethical Pay Disparity in Engineering."",
       subtitle = str_wrap(""A slopegraph presenting the average total earnings from 2014-2016 for men and women across engineering disciplines.  Mining Engineering is the only discipline with women earning more than men on average."", 70),
       caption = ""Data: Census Bureau | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week10"", ""tw10_plot.png""), plot, width = 6.5, height = 9, type = ""cairo"")
","2019-10"
"72",72,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week10/R/helpers.R","# Functions from an old friend.
# https://github.com/jkeirstead/r-slopegraph/blob/master/slopegraph.r

build_slopegraph <- function(df, x, y, group, min.space=0.05) {
  
  ## First rename the columns for consistency
  ids <- match(c(x, y, group), names(df))
  
  df <- df[,ids]
  
  names(df) <- c(""x"", ""y"", ""group"")
  
  ## Expand grid to ensure every combination has a defined value
  tmp <- expand.grid(x=unique(df$x), group=unique(df$group))
  
  tmp <- merge(df, tmp, all.y=TRUE)
  
  df <- mutate(tmp, y=ifelse(is.na(y), 0, y))
  
  spaced_sort(df, min.space=min.space)
  
}



spaced_sort <- function(df, min.space=0.05) {
  ## Define a minimum spacing (5% of full data range)
  min.space <- min.space*diff(range(df$y))
  
  ## Transform the data
  
  df <- split(df, ""x"") %>% 
    map_df(~calc_spaced_offset(.x, min.space))
  
  return(df)
}

##' Calculates the vertical offset between successive data points
##' 
##' @param df a data frame representing a single year of data
##' @param min.space the minimum spacing between y values
##' @return a data frame
calc_spaced_offset <- function(df, min.space) {
  
  ## Sort by value
  ord <- order(df$y, decreasing=T)
  ## Calculate the difference between adjacent values
  delta <- -1*diff(df$y[ord])
  ## Adjust to ensure that minimum space requirement is met 
  offset <- (min.space - delta)
  offset <- replace(offset, offset<0, 0)
  ## Add a trailing zero for the lowest value
  offset <- c(offset, 0)
  ## Calculate the offset needed to be added to each point
  ## as a cumulative sum of previous values
  offset <- rev(cumsum(rev(offset)))
  ## Assemble and return the new data frame
  df.new <- data.frame(group=df$group[ord],
                       x=df$x[ord],
                       y=df$y[ord],
                       ypos=offset+df$y[ord])
  return(df.new)
}
","2019-10"
"73",73,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week11/R/analysis.R","library(tidyverse)
library(jkmisc)
library(here)

board_games <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")

prolific <- board_games %>% 
  separate_rows(designer, sep = "","") %>% 
  filter(!str_detect(designer, ""Uncredited""), !str_detect(designer, ""Jr|III""), year_published >= 1990) %>% 
  group_by(designer) %>% 
  filter(n() >= 10) %>% 
  group_by(designer, year_published) %>% 
  summarize(year_avg_rating = mean(average_rating, na.rm = TRUE),
            games_published = n()) 

top_rated <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, overall_rating) %>% 
  pull(designer)

top_publishing <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, total_games) %>% 
  pull(designer)

overall_avg <- prolific %>% 
  group_by(year_published) %>% 
  summarize(year_avg_rating = mean(year_avg_rating, na.rm = TRUE),
            designer = ""Overall"")


plot_data <- prolific %>%
  bind_rows(overall_avg) %>% 
  mutate(color = case_when(designer == top_rated ~ ""#eebd31"" ,
                           designer == ""Overall"" ~ ""firebrick"",
                           designer == top_publishing ~ ""dodgerblue"",
                           TRUE ~ ""black""),
         alpha = case_when(designer == top_rated ~ 1,
                           designer == ""Overall"" ~ 1,
                           designer == top_publishing ~ 1,
                           TRUE ~ 0.05),
         size = case_when(designer == top_rated ~ 0.5,
                           designer == ""Overall"" ~ 0.5,
                           designer == top_publishing ~ 0.5,
                           TRUE ~ 0.3),
         point_size = case_when(designer == top_rated ~ 2,
                          designer == ""Overall"" ~ 2,
                          designer == top_publishing ~ 2,
                          TRUE ~ 1),
         line = case_when(designer == top_rated ~ ""solid"",
                           designer == ""Overall"" ~ ""dashed"",
                           designer == top_publishing ~ ""solid"",
                           TRUE ~ ""solid""))

plot <- ggplot(plot_data, aes(x = year_published, y = year_avg_rating, group = designer)) +
  geom_path(aes(color = color, alpha = alpha, linetype = line, size = size)) +
  geom_point(aes(fill = color, alpha = alpha, size = point_size), color = ""white"", shape = 21) +
  annotate(""label"", x = 1989.8, y = 2, label = ""Most Prolific: Reiner Knizia with 229 published games."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""dodgerblue"", hjust = 0) +
  annotate(""segment"", x = 1990, xend = 1990, y = 2.3, yend = 5.5, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""dodgerblue"") +
  annotate(""label"", x = 2002, y = 9, label = ""Highest Average Rating: Mark H. Walker with a 7.70 rating."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""#eebd31"") +
  annotate(""segment"", x = 2002, xend = 2002.8, y = 8.8, yend = 7.7, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""#eebd31"") +
  scale_y_continuous(limits = c(0, 10), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_color_identity() +
  scale_linetype_identity() +
  scale_size_identity() +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL,
       title = ""It's Not A Habit, It's Cool, I'm a Prolific Game Designer"",
       subtitle = str_wrap(""A comparison from 1990 to 2016 of the the top rated and top published designer amongst those with 10 or more published games. Red dashed line represents the overall average designer rating."", 150),
       caption = ""Data: Board Game Geek | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"")

ggsave(here(""2019"",""week11"", ""tw11_plot.png""), width = 12, height = 6)
","2019-11"
"74",74,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week13/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(fs)
library(janitor)
library(jkmisc)

pet_licenses <- here(""2019"", ""week13"", ""data"") %>% 
  dir_ls(regexp = ""Seattle"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  mutate_at(""license_issue_date"", mdy)

burst_name <- function(df) { 
  
  df %>% 
    distinct(license_issue_date) %>% 
    pull(license_issue_date) %>% 
    kleinberg()
    
  }

out <- pet_licenses %>% 
  filter(!is.na(animals_name)) %>% 
  mutate(animals_name = str_to_lower(animals_name)) %>% 
  group_by(animals_name) %>% 
  filter(n() >= 100) %>% 
  nest() %>% 
  mutate(bursts = map(data, burst_name)) %>% 
  unnest(bursts) %>% 
  arrange(desc(animals_name), level) %>% 
  mutate(id = ntile(animals_name, 1)) %>%
  mutate(color = case_when(level == 1 ~ ""grey50"",
                           level == 2 ~ ""#6baed6"",
                           level == 3 ~ ""#3182bd"",
                           level == 4 ~ ""#08519c""),
         alpha = case_when(level == 1 ~ 0.5,
                           level == 2 ~ 1,
                           level == 3 ~ 1,
                           level == 4 ~ 1)) %>% 
  ungroup()

facet_labels <- out %>% 
  group_by(id) %>% 
  summarize(label = sprintf(""%s to %s"", last(str_sub(animals_name, 1, 1)), first(str_sub(animals_name, 1, 1)))) %>% 
  pull(label) %>% 
  set_names(., sort(unique(out$id)))

order <- out %>% 
  filter(level == 1) %>% 
  arrange(desc(start)) %>% 
  pull(animals_name)

plot <- ggplot(out) +
  geom_segment(aes(x = start, xend = end, y = factor(animals_name, order), yend = factor(animals_name, order), color = color, alpha = alpha), size = 4, lineend = ""square"") +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_x_date(limits = c(ymd(""2006/01/01""),ymd(""2019/01/01"")),  date_breaks = ""1 year"", date_labels = ""%Y"", expand = c(0.02, 0)) +
  scale_y_discrete(position = ""right"") +
  theme_jk(grid = ""XY"") +
  labs(x = NULL,
       y = NULL,
       title = ""What is it, Lassie? 'Bark! Bark-bark-bark! Bark-bark!' What, Timmy's fallen in the well?"",
       subtitle = str_wrap(""Illustrated below is the recorded use of and bursts in popularity of registered pet names (frequency of use > 100) in Seattle from 2006 to 2019.  The grey bar indicates the duration the name is in use, and the blue segments indicate bursts of increased use of the name.  Darker blue segments represent repeated bursts indicating an increased intensity of use."", 100),
       caption = ""Data: seattle.gov | Graphic: @jakekaupp"")

ggsave(here(""2019"",""week13"",""tw13_plot.png""), plot, width = 8, height = 10, type = ""cairo-png"")
","2019-13"
"75",75,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week14/R/analysis.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(here)
library(patchwork)

bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

clean_bikes <- bike_traffic %>% 
  mutate(date = mdy_hms(date),
         month = month(date),
         year = year(date)) %>% 
  filter(between(year, 2014, 2018))

by_year <- clean_bikes %>% 
  group_by(year, month, crossing) %>% 
  summarize(total_bikes = sum(bike_count, na.rm = TRUE)) 

glyph <- ggplot(by_year, aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 1, aes(color = crossing)) +
  facet_grid(year ~ month, labeller = labeller(.cols = set_names(month.abb, 1:12)), switch = ""y"") +
  scale_color_manual(values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
  labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180),
        legend.position = ""none"")

main <- by_year %>% 
  filter(year == 2015, month == 1) %>% 
  ggplot(aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 3, aes(color = crossing)) +
  scale_color_manual(""Crossing"", values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
   labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180))

plot <- wrap_plots(list(main, glyph), widths = c(0.25, 0.75)) +
  plot_annotation(title = ""Annual Patterns in Seatle Bicycle Traffic"", 
                  subtitle = str_wrap(""This chart is glyph plot using multiple parallel coordinates plots to illustrate the monthly bike traffic at Seattle crossings.  A  colored dot represents each crossing and vertical position represents the total number of riders counted each month.  You can observe the year over year trends, as well as see which crossings experience cyclical patterns and which remain stable."", 155),
                  theme = theme_jk())

ggsave(here(""2019"", ""week14"", ""tw14_plot.png""), plot, width = 12, height = 6)
","2019-14"
"76",76,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week15/R/analysis.R","library(tidyverse)
library(lubridate)
library(ggbeeswarm)
library(here)
library(jkmisc)
library(nord)

player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")


plot_data <- player_dob %>% 
  select(name, date_of_birth) %>% 
  left_join(grand_slams, by = ""name"") %>% 
  mutate(age = interval(date_of_birth, tournament_date)/years(1)) %>% 
  group_by(name) %>% 
  filter(n()>1)
  

order <- plot_data %>% 
  group_by(name) %>% 
  filter(rolling_win_count == max(rolling_win_count)) %>% 
  arrange(rolling_win_count) %>% 
  pull(name)
  

plot <- ggplot(plot_data, aes(x = age, y = factor(name, order), size = rolling_win_count, color = gender, alpha = rolling_win_count)) +
  geom_point(aes(group = name)) + 
  facet_wrap(~gender, scales = ""free_y"") +
  scale_color_manual(values = c(""#C01E65"",""#117AB3"")) +
  scale_size_area(""Rolling Win Count"") +
  guides(size = guide_legend(override.aes = list(shape = 21, color = ""black"")), color = FALSE, alpha = FALSE) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  labs(x = NULL,
       y = NULL,
       title = ""Bright Stardom or Fading Obscurity: Looking at Players Major Wins Across their Careers."",
       subtitle = str_wrap(""The chart plots cumulative major wins against player age. Size and transparency of each point are mapped to the cumulative number of majors won.  Looking at the data, we can see the hot streaks in individual players, as well as the dominance of certain champions."", 110),
       caption = ""Data: wikipedia | Graphic: @jakekaupp"")
  
ggsave(here(""2019"",""week15"",""tw15_plot.png""), type = ""cairo"", width = 10, height = 12)
","2019-15"
"77",77,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week16/R/analysis.R","library(tidyverse)
library(here) 
library(jkmisc)
library(ggalt)
library(grid)
library(Cairo)

dogs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

png(file = here(""2019"", ""week16"", ""tw16_plot.png""), width = 4, height = 4, units = ""in"", res = 300, type = ""cairo"")
                       
ggplot(dogs, aes(x = avg_weight, y = avg_neck)) +
  geom_xspline(size = 1) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 0.5, size = 2) +
  geom_text(data = filter(dogs, year == min(year)), aes(label = year), hjust = 0, nudge_x = 0.1, nudge_y = 0.01, family = ""Oswald"", size = 3) +
  geom_text(data = filter(dogs, year == max(year)), aes(label = year), hjust = 1, nudge_x = -0.1, family = ""Oswald"", size = 3) +
  annotate(""segment"", arrow = arrow(length = unit(0.2, ""cm""), type = ""closed""), x = 20.48, xend = 20.2, y = 44.3, yend = 44.03) +
  scale_y_continuous(limits = c(42, 45), breaks = 42:45) +
  expand_limits(x = c(17.5, 21)) +
  labs(title = ""Fit as a butcher's dog"",
       subtitle = ""Characteristics of dogs registered with the UK's\nKennel Club, average when fully grown"",
       x = bquote(""Weight*, kg""),
       y = NULL,
       caption = ""Sources: Kennel Club;\n The Economist "") +
  theme_jk(grid = ""XY"") +
  theme(plot.caption = element_text(hjust = -0.1))

grid.text(expression(paste(Neck~size, "", "", cm^""\u2020"")), x = 0.1, y = 0.78, gp = gpar(fontfamily = ""Oswald"", cex = 0.8))
grid.text(bquote(""* Where at leat 50 are registered per year""), x = 0.98, y = 0.075, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)
grid.text(expression(""\u2020""~Where~at~least~100~are~registered~per~year), x = 0.98, y = 0.040, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)

dev.off()
","2019-16"
"78",78,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week17/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

plot_data <- tidy_anime %>% 
  mutate(title = coalesce(title_english, name)) %>% 
  mutate(end_date = if_else(is.na(end_date), as.Date(""2019-04-01""), end_date)) %>% 
  mutate(interval = interval(start_date, end_date)) %>% 
  filter(type != ""Unknown"") %>% 
  distinct(animeID, .keep_all = TRUE) 


scaffold <- tibble(year = rep(1917:2019, each = 6),
       type = rep(c(""Movie"", ""Music"", ""ONA"", ""OVA"", ""Special"", ""TV""), length(1917:2019))) 

timeline <- scaffold %>% 
  mutate(count = map2_dbl(year, type, ~nrow(filter(plot_data, ymd(sprintf(""%s/01/01"", .x)) %within% interval , type == .y))))

order <- timeline %>% 
  filter(year == last(year)) %>% 
  arrange(desc(count)) %>% 
  pull(type)

# Area ----
area <- timeline %>% 
  mutate(type = factor(type, order, order)) %>% 
  ggplot(aes(x = year, y = count)) +
  geom_area(aes(fill = type)) +
  scale_fill_manual(""Anime Type"", values = tol6qualitative) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_y_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Fourty Years of Growth: The Rapid Rise of Anime"",
       subtitle = str_wrap(""The area chart below presents the number of anime titles released from 1919 to the present by release type.  Anime releases have increased over 400% since the 1980s, to meet the increasing demand driven by the invention of the VCR, the internet and the rise of streaming media services."", 95),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE))

# Popularity vs Score Hexbin ----
hex <- ggplot(plot_data, aes(x = popularity, y = score)) +
  geom_hex() +
  facet_wrap(~type, nrow = 1) +
  scale_fill_viridis_c(option = ""plasma"") +
  scale_x_continuous(trans = ""reverse"", breaks = scales::pretty_breaks(), labels = c("""","""",""Higher\nPopularity"", """", ""Lower\nPopularity"", """")) +
  scale_y_continuous(breaks = scales::pretty_breaks(), limits = c(0,10)) +
  guides(fill = guide_colorbar(title = ""Titles per Hex""), alpha =""none"") +
  labs(x = NULL, 
       y = NULL,
       title = ""The Relationship Between Ratings and Popularity on MyAnimeList"",
       subtitle = str_wrap(""The chart below plots the ratings score (out of 10) against popularity (rank) for all anime titles and anime types.  The data were hexangonally binned to illustrate areas of high occurance. It appears that a relationship may exist between ratings and popularity, warranting further analysis."", 100),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"",""week17"",""tw17_hex.png""), hex, width = 8, height = 6)

ggsave(here(""2019"",""week17"",""tw17_area.png""), area, width = 8, height = 6)

","2019-17"
"79",79,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week18/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


flower <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.2) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar()) +
  coord_polar() +
  labs(x = NULL,
       y = NULL,
       title = ""Overall"") +
  theme_jk(dark = FALSE, grid = ""X"", strip_text_size = 10, plot_title_size = 14) +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

petals <- flower +
  aes(group = year) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  labs(title = ""By Species"") +
  facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7) 

legend <- plot_data %>% 
  filter(binomial_name == ""Setophaga fusca"") %>% 
  ggplot(aes(x = month, y = percent, fill = binomial_name, group = year)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.1) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  annotate(""text"", x = 11, y = 0.8, label = ""One year of\ncollisions in October"", family = ""Scope One"", size = 3, hjust = 0) +
  annotate(""segment"", x = 10.8, y = 0.8, xend = 10, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  annotate(""text"", x = 3.5, y = 0.8, label = ""Multiple years of\ncollisions in May"", family = ""Scope One"", size = 3) +
  annotate(""segment"", x = 3.8, y = 0.8, xend = 5, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""How to Interpret This Chart"",
       subtitle = str_wrap(""A flower represents the recorded total collisions of each bird species with the individual petals representing the normalized events during each year (from 0-1).  The position of the petals indicates the month or months collisions occur, with overlaps indicating repeated year-over-year collisions."", 70)) +
  guides(fill = guide_colorbar()) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- wrap_plots(flower / legend, petals, ncol = 2, widths = c(1, 2)) +
  plot_annotation(title = ""Seasonality of Bird Collisions in Chicago"",
                  subtitle = str_wrap(""Presented below is a petal chart of of bird collisions, with instructions on how to interpret this chart in the lower left.  The upper left flower represents collisions recorded across all years and species, with individual species presented as small multiple flowers on the right."", 220),
                  caption = ""Data: Winger et al. (2019) Nocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. Proceedings of the Royal Society B 286(1900): 20190364. https://doi.org/10.1098/rspb.2019.0364 | Graphic: @jakekaupp"",
      theme = theme_jk())

ggsave(here(""2019"",""week18"", ""tw18_plot.png""), out, width = 16, height = 10, type = ""cairo"")



","2019-18"
"80",80,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week18/R/experiment.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)


bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))

petals <- plot_data %>% 
  filter(n != 0) %>% 
  split(list(.$year, .$month, .$binomial_name), drop = TRUE) %>% 
  map(~complete(.x, year, binomial_name, month = 1:12, fill = list(n = 0, percent = 0))) %>% 
  map(~geom_area(data = .x, aes(color = binomial_name), size = 0.2, alpha = 0.1))


base_plot <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- base_plot + petals + facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7)


ggsave(here(""2019"",""week18"", ""test.png""), plot = out)

","2019-18"
"81",81,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week19/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(fs)
library(jkmisc)
library(janitor)
library(countrycode)
library(patchwork)

ratio_data <- here(""2019"", ""week19"", ""data"") %>% 
  dir_ls(regexp = ""student_teacher_ratio"") %>% 
  read_excel(na = c("".."")) %>% 
  set_names(tolower(names(.))) %>% 
  gather(year, ratio, -1:-2,convert = TRUE)



plot_region <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, group = region, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~region, nrow = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") 
  
  }

plot_continent <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~continent, ncol = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    scale_shape_identity() +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") +
    theme(strip.text = element_blank())
  
}

plot_data <- ratio_data %>% 
  filter(type == ""Countries"") %>% 
  mutate(country_code = countrycode(country, ""country.name"", ""iso3c"")) %>% 
  mutate(region = countrycode(country_code, ""iso3c"", ""region"")) %>% 
  mutate(continent = countrycode(country_code, ""iso3c"", ""continent"")) %>% 
  filter(!is.na(region))

colors <- set_names(c(""#171635"", ""#00225D"", ""#763262"", ""#CA7508"", ""#E9A621""), c(unique(plot_data$continent)))

individual <- plot_data %>% 
  group_by(year, region, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_region) 

summary <- plot_data %>% 
  group_by(year, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_continent) 
  
plots <- map2(summary, individual, ~wrap_plots(.x, .y, nrow = 1, widths = c(1, 1)))
  
out <- wrap_plots(plots, ncol = 1) +
  plot_annotation(title = ""Working to Two Sigma: Student Teacher Ratios Improving Since the 1970s"",
                  subtitle = str_wrap(""Illustrated below is the average student to teacher ratio across each continent (left column) and region (right column).  Continent and region assigned from iso3c coding of country name and are consistent with the World Bank Dvelopment Indicators."", 210),
                  caption = ""Data: UNESCO Institute of Statistics | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"",""week19"",""tw19_plot.png""), out, width = 16, height = 10)
","2019-19"
"82",82,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week2/R/analysis.R","library(tidyverse)
library(ggraph)
library(tidygraph)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)
library(nord)

set.seed(42)

source(here(""2019"", ""week2"", ""R"", ""functions.R""))

# Read data from github repo
tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"") %>% 
  rename(title_id = titleId,
         season_number = seasonNumber) %>% 
  mutate(year = year(date))

# Make this into a nodes tibble
list <- tv_data %>% 
  split(.$year) %>% 
  map(share_packed_circle)

out <- wrap_plots(list, ncol = 10, nrow = 3) +
  plot_annotation(title = ""The Evolution and Differentiation of Dramas Across the Golden Age of Television"",
                  subtitle = str_wrap(""This chart presents a time series of circle-packed network representations of the television dramas.  
                                      The larger dark blue circle represents the year, light blue represents the genre (Action, Comedy, etc.) and the pale pink represents the individual program. 
                                      The area of each circle (node) is porportional to the sum of the audience share of the smaller circles within (child nodes)."", 180),
                  caption = ""data: IMDb | graphic: @jakekaupp"",
                  theme = theme_jk(plot_title_size  = 22, subtitle_size = 14) %+replace% theme(plot.background = element_rect(fill =""#2E3440""),
                                                      text = element_text(color = ""white"")))
 
ggsave(here(""2019"",""week2"", ""tt_week2.png""), out, width = 16, height = 8)
","2019-2"
"83",83,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week2/R/functions.R","share_packed_circle <- function(df) {
 
  nodes <- make_nodes(df)
  
  edges <- make_edges(df)
 
  mygraph <- tbl_graph(nodes = nodes, edges = edges)
  
  # Make the plot
  plot <- ggraph(mygraph, layout = 'circlepack', weight = ""size"") + 
    geom_node_circle(aes(fill = depth)) +
    theme_void() +
    labs(title = unique(df$year)) +
    coord_equal() +
    scale_fill_nord(""lumina"", discrete = FALSE, reverse = TRUE) +
    #scale_fill_viridis(option = ""plasma"") +
    theme(legend.position = ""none"", 
          plot.background = element_rect(fill = ""#4C566A""),
          plot.title = element_text(family = ""Oswald"", hjust = 0.5, color = ""white""),
          )
  
  return(plot)
}


make_nodes <- function(df) {
  
  size <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    distinct(genres, title, share) %>% 
    rename(name = title, size = share)
  
  genre_size <- size %>% 
    group_by(genres) %>% 
    summarize(size = sum(size)) %>% 
    rename(name = genres)
  
  title_size <- size %>% 
    ungroup() %>% 
    distinct(name, size) %>% 
    mutate(size = size)
  
  total_size <- df %>% 
    distinct(title, share) %>% 
    summarize(name = as.character(unique(df$year)),
              size = sum(share))
  
  sizes <- bind_rows(genre_size, title_size, total_size)
  
  nodes <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    gather(variable, name, title, genres, year) %>% 
    arrange(variable, name) %>% 
    distinct(name) %>% 
    left_join(sizes, by = ""name"") %>% 
    mutate(size = if_else(size == 0, 0.001, size)) %>% 
    arrange(size)
  
  return(nodes)
  
  
}

make_edges <- function(df) {
  
  base <- tibble(from = as.character(unique(df$year)), to = unique(df$genres))
  
  inner <- df %>% 
    select(from = genres, to = title) %>% 
    distinct() 
  
  edges <- bind_rows(base, inner) 
  
  return(edges)
  
}
","2019-2"
"84",84,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week20/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(rcrossref)
library(ggbeeswarm)
library(jkmisc)


# Not re-downloading things, the citation count pulls take 2hrs.
if (length(dir_ls(here(""2019"", ""week20"", ""data""))) <= 0) {
 
  nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
  nobel_winners_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")
  
  saveRDS(nobel_winners, here(""2019"", ""week20"", ""data"", ""nobel_winners.RDS""))
  
  saveRDS(nobel_winners_all_pubs, here(""2019"", ""week20"", ""data"", ""nobel_winners_all_pubs.RDS""))

  
} else {
  
  nobel_winners <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners.RDS"") %>% 
    readRDS()
  
  nobel_winners_all_pubs <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners_all_pubs.RDS"") %>% 
    readRDS()
 
}


if (length(dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""cite_count"")) <= 0) {

  dois <- nobel_winners_all_pubs$doi

  list  <- split(dois, rep(1:ceiling(length(dois)/50), each=50)[1:length(dois)])

wait_cr_citation_count <- function(doi, index, list_len) {
  
  print(sprintf(""%s complete"", scales::percent(index/list_len)))
  
  Sys.sleep(1)
  
  cr_citation_count(doi)
  
}

cite_count <- imap_dfr(list, ~wait_cr_citation_count(.x, .y, length = length(list)))

saveRDS(cite_count, here(""2019"", ""week20"", ""data"", ""cite_count.RDS"")) 

} else {
  
cite_count <- readRDS(here(""2019"", ""week20"", ""data"", ""cite_count.RDS""))
  
}

highlights <- c(""einstein, a"", ""hill, av"", ""heeger, a"")

plot_data <- nobel_winners_all_pubs %>%
  left_join(cite_count) %>%
  distinct(laureate_id, paper_id, .keep_all = TRUE) %>%
  select(pub_year, laureate_name, is_prize_winning_paper, count, category) %>% 
  replace_na(list(count = 0)) %>% 
  group_by(laureate_name, pub_year, category) %>%
  summarize(count = sum(count)) %>% 
  group_by(laureate_name) %>% 
  mutate(rolling_sum = cumsum(count)) %>% 
  mutate(color = if_else(laureate_name %in% highlights, ""#F24534"", ""#21344F""),
         alpha = if_else(laureate_name %in% highlights, 1, 0.2))


everyone <- filter(plot_data, laureate_name %notin% highlights)

focus <- filter(plot_data, laureate_name %in% highlights) %>% 
  ungroup() %>% 
  mutate(laureate_name = case_when(laureate_name == ""einstein, a"" ~ ""Einstein, A"",
                                   laureate_name == ""hill, av"" ~ ""Hill, AV"",
                                   laureate_name == ""heeger, a"" ~ ""Heeger, A"")) %>% 
  group_by(laureate_name)


plot <- ggplot(plot_data, aes(x = pub_year, y = rolling_sum, group = laureate_name)) +
  geom_step(aes(color = color, alpha = alpha)) +
  geom_step(data = focus, aes(color = color, alpha = alpha)) +
  geom_text(data = filter(focus, pub_year == last(pub_year)), aes(color = color, alpha = alpha, label = laureate_name), x = 2018, family = ""Oswald"", hjust = 0) +
  scale_x_continuous(limits = c(1900, 2100), breaks = c(1900, 1925, 1950, 1975, 2000, 2018)) +
  scale_y_continuous(breaks = scales::pretty_breaks(), labels = scales::number) +
  scale_color_identity() +
  scale_alpha_identity() +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  labs(x = NULL,
       y = NULL,
       title = ""Growth Patterns in How Often Nobel Prize Winning Researchers Are Cited"",
       subtitle = str_wrap(""Cummulative citation count by year (1900-2018).  Highlighted are A. Heeger (conductive polymers), A.V. Hill (heat and work in muscle) and A. Einstein (photoelecric effect). Each exhibit different citation patterns, likely attributed to the continued relevance and impact of their work."", 150),
       caption = ""Data: Li, Jichao; Yin, Yian; Fortunato, Santo; Wang Dashun, 2018, 'A dataset of publication records for Nobel laureates', https://doi.org/10.7910/DVN/6NJ5RN, Harvard Dataverse. | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"", ""week20"", ""tw20_plot.png""), plot, width = 12, height = 6)

","2019-20"
"85",85,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week21/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(fs)
library(janitor)
library(jkmisc)
library(patchwork)


# Plotting Function to make separate ordered stacked bars by group----
make_bars <- function(df, pals) {
  
  order <- df %>% 
    arrange(desc(other)) %>% 
    pull(country)
  
  labs <- c(""HIC"" = ""High Income Group"",
            ""UMI"" = ""Upper Middle Income Group"",
            ""LMI"" = ""Lower Middle Income Group"",
            ""LI"" = ""Low Income Group"")
  
  
  df %>% 
    gather(type, value, c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste"")) %>% 
    mutate(type = factor(type, c(""other"", ""inadequate_waste"", ""plastic_waste"", ""littered_waste""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
    mutate(country = factor(country, order)) %>% 
    mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
    ggplot() +
    geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
    coord_flip() +
    scale_fill_manual("""", values = pals) +
    scale_alpha_identity() +
    scale_y_continuous(expand = c(0,0.05), labels = scales::percent) +
    labs(x = NULL, y = NULL) +
    facet_wrap(~economic_status, scales = ""free_y"", labeller = as_labeller(labs)) +
    theme_jk(grid = FALSE) +
    theme(legend.direction = ""horizontal"")
  
}


# Function to extract ggplot legends ----
extract_legend <- function(ggp){
  
  tmp <- ggplot_gtable(ggplot_build(ggp))
  
  leg <- which(map_lgl(tmp$grobs, function(x) x$name == ""guide-box""))
  
  legend <- tmp$grobs[[leg]]
  
  return(legend)}


# Read in Coastal Waste Data----
# Plastic waste inputs from land into the ocean
# BY JENNA R. JAMBECK, ROLAND GEYER, CHRIS WILCOX, THEODORE R. SIEGLER, MIRIAM PERRYMAN, ANTHONY ANDRADY, RAMANI NARAYAN, KARA LAVENDER LAW
# 
# SCIENCE13 FEB 2015 : 768-771

coastal_waste <- here(""2019"", ""week21"", ""data"") %>% 
  dir_ls(regexp = ""xlsx"") %>% 
  read_excel() %>% 
  clean_names() %>% 
  set_names(str_remove(names(.), ""_*[0-9]$"")) %>% 
  mutate(country = str_remove(country, ""[0-9]"")) %>% 
  mutate(country = case_when(str_detect(country, ""Palestine"") ~ ""Palestine"",
                             str_detect(country, ""Korea, South"") ~ ""South Korea"",
                             str_detect(country, ""Korea, North"") ~ ""North Korea"",
                             str_detect(country, ""Congo"") ~ ""Congo"",
                             TRUE ~ country)) %>% 
  filter(!grepl(""Burma"", country)) %>% 
  filter(complete.cases(.)) %>% 
  mutate(other = 100 - (percent_plastic_in_waste_stream + percent_inadequately_managed_waste + percent_littered_waste)) %>% 
  rename(plastic_waste = percent_plastic_in_waste_stream, inadequate_waste  = percent_inadequately_managed_waste, littered_waste = percent_littered_waste) %>% 
  mutate_at(c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste""), function(x) x/100) %>% 
  mutate(other = if_else(other < 0, 0, other)) %>% 
  mutate(total_waste = waste_generation_kg_day * 365/1000,
         total_plastic_waste = total_waste * plastic_waste,
         total_inadequate_waste = total_waste * inadequate_waste,
         total_littered =  total_waste * littered_waste,
         other_waste = total_waste * other)


# Palette for plot----
pal <- c(""#F5F0F6"", ""#629460"", ""#385F71"", ""#2B4162"")

avg <- coastal_waste %>% 
  summarize(total_waste = mean(total_waste, na.rm = TRUE),
            other_waste  = mean(other_waste, na.rm = TRUE),
            total_plastic_waste  = mean(total_plastic_waste, na.rm = TRUE),
            total_inadequate_waste = mean(total_inadequate_waste, na.rm = TRUE),
            total_littered = mean(total_littered, na.rm = TRUE)) %>% 
  mutate(country = ""Global Average"")


order <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  pull(country) 



overall_mismanaged <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  gather(type, value, c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered"")) %>% 
  mutate(type = factor(type,  c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
  mutate(country = factor(country, rev(order))) %>% 
  mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
  mutate(strip = ""Top 50 Producers & Global Average of Total Indequately Managed Waste (kg)"") %>% 
  ggplot() +
  geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
  coord_flip() +
  scale_fill_manual("""", values = pal) +
  scale_alpha_identity() +
  scale_y_continuous(expand = c(0,0.05), labels = scales::comma) +
  labs(x = NULL, y = NULL) +
  facet_wrap(~strip) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""none"")


# Make plots----
list <- coastal_waste %>% 
  split(.$economic_status) %>% 
  map(make_bars, pal)

# Extract legend----
legend <- extract_legend(list[[1]])

# Remove legend from list of plots----
list <- map(list, ~.x + theme(legend.position = ""none""))
  
# Finish plot----
out <- (overall_mismanaged + wrap_plots(list[c(""HIC"", ""UMI"", ""LMI"", ""LI"")], nrow = 1) + plot_layout(widths = c(0.3, 0.7))) / legend + plot_layout(heights = c(0.95, 0.05)) +
  plot_annotation(title = ""The Relationship Between World Bank Income Classification and Mismanaged Waste"",
                  subtitle = str_wrap(""Illustrated below is the percentage of waste by category for each country by World Bank income classification.  The lower the classification, the higher the mismanaged waste.  Much of this mismanaged waste (especially plastics) ends up in waterways that ultimately lead to our oceans, suggesting that global income inequality plays a role in ocean pollution by hampering the implementation of effective waste management strategies."", 240),
                  caption = ""Data: Jambeck, Jenna R., et al. 'Plastic waste inputs from land into the ocean.' Science 347.6223 (2015): 768-771. | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"", ""week21"", ""tw21_plot.png""), out, width = 19, height = 12)



","2019-21"
"86",86,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week22/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(ggridges)
library(tidytext)
library(countrycode)
library(ggwordcloud)
library(patchwork)

source(here(""2019"", ""week22"", ""R"", ""packed_bars.R""))

wine_ratings <- here(""2019"", ""week22"", ""data"", ""winemag-data-130k-v2.csv"") %>% 
  read_csv()

wine_counts <- wine_ratings %>% 
  count(country) %>% 
  mutate(max_rel_val = n/sum(n)) %>% 
  filter(!is.na(country))
 
summary_ratings <- wine_ratings %>% 
  group_by(country) %>% 
  summarize_at(c(""points"",""price""), mean, na.rm = TRUE) %>% 
  filter(!is.na(country))

summary_data <- left_join(wine_counts, summary_ratings)

plot_data <- pack_bars(summary_data, number_rows = 4, max_rel_val)

packed_bar <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"") +
  geom_text(data = filter(plot_data, fill == ""#4B384C""), aes(x = xmin, y = (ymin + ymax)/2, label = country), family = ""Oswald"", color = ""white"", nudge_x = 0.01, hjust = 0) +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

word_counts <- wine_ratings %>%
  select(country, description) %>%
  group_by(country) %>% 
  filter(n() > 2) %>% 
  filter(!is.na(country)) %>% 
  unnest_tokens(word, description) %>% 
  anti_join(stop_words) %>% 
  count(country, word) %>% 
  mutate(word = trimws(word)) %>% 
  filter(!str_detect(word, ""[0-9]""), !str_detect(word, ""aroma|wine|note|nose|notes|aromas|drink|drinks|feel|feels|finish"")) %>% 
  group_by(country) %>% 
  top_n(300, n) 

clouds <- word_counts %>% 
  ungroup() %>% 
  mutate(iso2 = tolower(countrycode(country, ""country.name"", ""iso2c"")),
         iso2 = if_else(country == ""England"", ""gb"", iso2)) %>% 
  filter(country %in%  c(""US"", ""France"", ""Italy"", ""Spain"")) %>% 
  mutate(country = factor(country, levels = c(""US"", ""France"", ""Italy"", ""Spain"")),
         iso2 = factor(iso2, levels = c(""us"",""fr"", ""it"", ""es""))) %>% 
  group_by(iso2) %>% 
  nest() %>% 
  arrange(iso2) %>% 
  mutate(clouds =  map2(iso2, data, create_wc))

word_clouds <- wrap_plots(clouds$clouds, ncol = 1) 

out <- packed_bar + word_clouds +
  plot_annotation(title = ""Wine-ing: The Top 4 Countries and What Reviewers Say About Their Wines"",
                  subtitle = str_wrap(""On the left, a packed bar chart showing the % of reviewed wines by country.  On the right, wordclouds of the top 300 most frequent terms used in reviews."", 100),
                  caption = ""Data: Kaggle via WineEnthusiast | Graphic: @jakekaupp"",
                  theme = theme_jk()
                  )

ggsave(here('2019', ""week22"", ""tw22_plot.png""), out, width = 8, height = 12)

ggsave(here('2019', ""week22"", ""packed_bar.png""), packed_bar + labs(title = ""Top 4 Countries Reviewed as Packed Bar Chart"",
                                                                   subtitle = str_wrap(""The visualizion below is a packed bar chart, developed by Xan Gregg.  It combines the ordered nature of a bar chart with the total view and condensed nature of a treemap.  Colour denotes the focus, while the each gray sections represents each other reviwed country. This gives a sense of how many secondary categories there are, their magnitude and distribution. Additionally, since they are on the same scale of the focused bars we can even estimate some of the values from the length they span on the axis."", 100)), width = 8, height = 6)
","2019-22"
"87",87,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week22/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- summary_data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- summary_data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}


create_wc <- function(iso2, data) {
  
  cntry_mask <- png::readPNG(here(""2019"", ""week22"", ""data"", ""png maps"", iso2, ""1024.png""))
  
  ggplot(data, aes(label = word, size = n)) +
    geom_text_wordcloud(family = ""Oswald"", mask = cntry_mask, rm_outside = TRUE) +
    scale_radius(range = c(0, 40)) +
    theme_jk() 
  
  
}
","2019-22"
"88",88,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week23/R/analysis.R","library(tidyverse)
library(glue)
library(rvest)
library(xml2)
library(lubridate)
library(here)
library(jkmisc)



#Scraping functions----

get_urls <- function(sitemap_url) {
  
  read_xml(sitemap_url) %>%
    xml_children() %>% 
    xml_children() %>% 
    xml_text() %>% 
    keep(~str_detect(.x, ""https://www.theramenrater.com/[0-9]{4}/[0-9]{2}/[0-9]{1,}/\\w+""))
  
}

get_post_title <- function(url, idx, rows) {
  
  print(sprintf(""Progress: %s/%s"", idx, rows))
  
  read_html(url) %>% 
    html_node("".entry-title"") %>% 
    html_text()
  
  
}

slowly_get_post_title <- slowly(~ get_post_title(.x, .y, rows), rate = rate_delay(pause = 0.5), quiet = TRUE)

#Week of month
wom <- function(date) { # week-of-month
  first <- wday(as.Date(paste(year(date), month(date), 1, sep=""-"")))
  return((mday(date) + (first - 2)) %/% 7 + 1)
}

#Plotting functions----
month_outline <- function(df) {
  
  top1 <- with(df, tibble(x = min(wmonth) - 0.5,
                          xend = wday[day == min(day)] - 0.5,
                          y = wmonth[day == min(day)] + 0.5,
                          yend = wmonth[day == min(day)] + 0.5,
                          line = ""top1"")) 
  
  top2 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                          xend = max(wday) + 0.5,
                          y = min(wmonth) - 0.5,
                          yend = min(wmonth) - 0.5,
                          line = ""top2"")) 
  
  left1 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                           xend = wday[day == min(day)] - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = min(wmonth) - 0.5,
                           line = ""left1""))
  
  left2 <- with(df, tibble(x = min(wmonth) - 0.5,
                           xend = min(wmonth) - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = wmonth[day == max(day)] + 0.5,
                           line = ""left2""))
  

  right1 <- with(df, tibble(x = max(wday) + 0.5,
                            xend = max(wday) + 0.5,
                            y = min(wmonth) - 0.5,
                            yend = wmonth[day == max(day)] - 0.5,
                            line = ""right1""))
  
  right2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                            xend = wday[day == max(day)] + 0.5,
                            y = wmonth[day == max(day)] - 0.5,
                            yend = wmonth[day == max(day)] + 0.5,
                            line = ""right2""))

  
  bottom1 <- with(df, tibble(x = min(wmonth) - 0.5,
                             xend = wday[day == max(day)] + 0.5,
                             y = wmonth[day == max(day)] + 0.5,
                             yend = wmonth[day == max(day)] + 0.5,
                             line = ""bottom1""))
  
  bottom2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                             xend = max(wday) + 0.5,
                             y = wmonth[day == max(day)] - 0.5,
                             yend = wmonth[day == max(day)] -0.5,
                             line = ""bottom2""))
  
  top <- bind_rows(top1, top2)
  left <- bind_rows(left1, left2)
  bottom <- bind_rows(bottom1, bottom2) 
  right <- bind_rows(right1, right2) 
    
    bind_rows(top, left, right, bottom) %>% 
      mutate(year = unique(df$year),
             month = unique(df$month)) 
    
  
}


if(!file.exists(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))) {
  
  # Add Recent ratings #3181-319
  recent_ratings <- tibble(review_number = c(3181:3189, 1676, 2745, 2991),
                           stars = c(3.75, 3.25, 4.0, 3.25, 2.0, 3.75, 3.75, 3.5, 2.25, 4.25, 5, 3.25),
                           brand = c(""Nissin Yakisoba"", ""Maruchan"", ""Uni-President"", ""Maruchan"", ""Sakruai Foods"", ""Nissin Mago"", ""Big Bon"", ""Sapporo Ichiban"", ""Canton"", ""A1"", ""Nissin"", ""Big Bon""),
                           variety = c(""Instant Panict Savory Beef Flavour"", ""Maruchan Ramen Noodle Soup Roast Beef Flavour"", ""Imperial Big Meal Super Hot Pot Beef Flavour"",
                                       ""Ramen Noodle Soup Pork Beef Flavour"", ""Vegetarian Stir Fry Noodles"", ""Nissin Lamen Light Legumes "", ""Spice Mix Piquant"", ""Momosan Ramen Tokyo Chicken"", ""Instant Noodles Spicy Tomato"",
                                       ""Emperor Herbs Chicken Noodle"", ""U.F.O. Big Wasabi-Mayo Yakisoba"", ""Chicken & Salsa Sauce Instant Noodles""),
                           country = c(""Phillipines"", ""United States"", ""Taiwan"", ""United States"", ""Japan"", ""Brazil"", ""Russia"" , ""United States"", ""India"", ""Malaysia"", ""Japan"", ""Russia""),
                           style = c(""Cup"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack""))
  
  # Read tidytesday data----
  ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"") %>% 
    bind_rows(recent_ratings)
  
  out <- tibble(sitemap_url = glue(""https://www.theramenrater.com/post-sitemap{1:5}.xml""),
                contents = map(sitemap_url, get_urls)) %>% 
    unnest() 
  
  rows <- nrow(out)
  
  # Scrapin der web purges----
  out <-  out %>% 
    mutate(title = imap(contents, ~slowly_get_post_title(.x, .y, rows))) %>% 
    mutate(date = parse_date(str_extract(contents, ""[0-9]{4}/[0-9]{2}/[0-9]{1,}""), ""%Y/%m/%d""),
           review_number = as.numeric(str_extract(title, ""(?!#)[0-9]{1,4}(?=\\:)""))) %>% 
    filter(!is.na(review_number)) %>% 
    left_join(ramen_ratings) %>% 
    filter(review_number < 4000) %>% 
    select(-sitemap_url)
  
  # Saving the new dataset----
  saveRDS(out, here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
} else {
  
  ramen_data <- readRDS(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
}

#Make months
all_dates <- tibble(date = seq.Date(from = ymd(""2009/01/01""), to =ymd(""2019/12/31""), by =""day"")) %>% 
  mutate(day = day(date),
         month = month(date),
         year = year(date))

plot_data <- ramen_data %>%
  mutate(day = day(date),
         month = month(date),
         year = year(date)) %>% 
  group_by(year, month, day) %>% 
  summarize(brands = toString(sprintf(""%s: %s"", brand, variety)),
            count = n(),
            avg_stars = mean(stars)) %>% 
  right_join(all_dates) %>% 
  ungroup() %>% 
  mutate(wday = wday(date, label = TRUE, week_start = 7),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date))
  
outlines <- all_dates %>% 
  mutate(wday_label = wday(date, label = TRUE),
         wday = wday(date),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date)) %>% 
  split(list(.$year, .$month), drop = TRUE) %>% 
  map_df(month_outline)



plot <- ggplot(data = plot_data, aes(x = wday, y = wmonth, fill = avg_stars)) +
  geom_tile(color = ""grey80"", size = 0.1) +
  geom_segment(data = outlines, aes(x = x, xend = xend, y = y, yend = yend, group = line), color = ""grey30"", inherit.aes = FALSE) +
  scale_y_continuous(trans = ""reverse"", labels = NULL) +
  scale_x_discrete(labels = NULL) +
  scale_fill_gradientn(""Average Stars"", colors = rev(parula(100)), na.value = ""grey95"") +
  facet_grid(month ~ year, switch = ""y"") +
  labs(x = NULL,
       y = NULL,
       title = ""The Prolfic Nature of the Ramen Rater and a Birds-Eye View of Ramen Quality"",
       subtitle = str_wrap(""Below is a heatmap calendar of the all the Ramen Raters ramen ratings by the published date of the review.  In the early days, multiple reviews were posted in a single day, until reaching the usual pattern of a single review per day.  However, there are still some reviews that get posted en masse."", 100),
       caption = ""Data: The Ramen Rater | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE) +
  theme(strip.text.y = element_text(angle = 180),
        panel.spacing.y = unit(-0.2, ""lines""),
        legend.position = ""bottom"")

ggsave(here(""2019"", ""week23"", ""tw23_plot.png""), height = 11, width = 8.5, type = ""cairo"")





  
","2019-23"
"89",89,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week24/R/analysis.R","library(nord)
library(tidyverse)
library(ggmap)
library(here)
library(countrycode)
library(jkmisc)
library(patchwork)

source(here(""2019"", ""week24"", ""R"", ""packed_bars.R""))

if (!file.exists(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))) {
  
  slow_revgeocode <- slowly(~revgeocode(.x, output = ""address""), rate = rate_delay(0.03), quiet = TRUE)
  
  reverse_geocoded <- meteorites %>% 
    distinct(long, lat) %>% 
    mutate(location = map2_chr(long, lat, ~slow_revgeocode(c(.x, .y))))
  
  saveRDS(reverse_geocoded, here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
} else {
  
  meteorite_locations <- readRDS(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
}

meteorites <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

meteorites <- left_join(meteorites, meteorite_locations) %>% 
  mutate(country_code = countrycode(location, ""country.name"", ""iso3c"")) %>% 
  mutate(country_code = case_when(str_detect(location, ""UK"") ~ ""GBR"",
                                  str_detect(location, ""USA"") ~ ""USA"",
                                  str_detect(location, ""China"") ~ ""CHN"",
                                  str_detect(location, ""Philippines"") ~ ""PHL"",
                                  str_detect(location, ""Serbia"") ~ ""RUS"",
                                  str_detect(location, ""Australia"") ~ ""AUS"",
                                  str_detect(location, ""Chile"") ~ ""CHL"",
                                  str_detect(location, ""Shopian"") ~ ""IND"",
                                  str_detect(location, ""Argentina"") ~ ""ARG"",
                                  str_detect(location, ""Bass Strait"") ~ ""AUS"",
                                  TRUE ~ country_code)) %>% 
  mutate(country_code = case_when(str_detect(name, ""Indarch"") ~ ""AZE"",
                                  str_detect(name, ""Oum Dreyga"") ~ ""ESH"",
                                  str_detect(name, ""Zag"") ~ ""ESH"",
                                  str_detect(name, ""Al Haggounia"") ~ ""ESH"",
                                  str_detect(name, ""Bou Kra"") ~ ""ESH"",
                                  TRUE ~ country_code)) %>% 
  rename(iso3c = country_code) %>% 
  filter(!is.na(iso3c)) 


world_tile_grid <- read_csv(""https://gist.githubusercontent.com/maartenzam/787498bbc07ae06b637447dbd430ea0a/raw/9a9dafafb44d8990f85243a9c7ca349acd3a0d07/worldtilegrid.csv"")

meteorite_wtg <- meteorites %>% 
  group_by(iso3c) %>% 
  summarize(n = n(),
            mass = sum(mass, na.rm = TRUE)/1000) %>%
  mutate(per_meteorite = mass/n) %>% 
  right_join(world_tile_grid, by = c(""iso3c"" = ""alpha.3"")) %>% 
  mutate(text_color = if_else(per_meteorite < 1, ""white"", ""black"")) %>% 
  replace_na(list('alpha.2' = ""NA"",
                  ""text_color"" = ""black"")) 


meteorite_map <- ggplot(meteorite_wtg, aes(x, y, fill = odds, group = iso3c)) +
  geom_tile(color = ""grey30"", size = 0.1) +
  geom_text(aes(label = alpha.2, color = text_color), family = ""Oswald"") +
  labs(x = NULL,
       y = NULL) +
  scale_y_reverse() +
  scale_fill_viridis_c(name = ""Average Metorite Mass (kg, log scale)"",option = ""cividis"", na.value = ""white"", breaks = c(1, 10, 100, 1000, 10000, 100000), guide = guide_colourbar(title.position = ""top"", title.hjust = 0)) +
  scale_color_identity() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.direction = ""horizontal"",
        legend.key.width = unit(2, ""lines""),
        legend.position = c(0.2, 0.05))


plot_data <- meteorite_wtg %>%
  select(alpha.2, n) %>% 
  mutate(n = log10(n)) %>% 
  replace_na(list(n = 0)) %>% 
  pack_bars(10, value_column = n, fill_color = last(nord(""lumina"", 5)))


packed_bars <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"", size = 0.1) +
  geom_text(data = filter(plot_data, (xmax - xmin) > 0.1), aes(x = (xmin + xmax)/2, y = (ymin + ymax)/2, label = alpha.2), family = ""Oswald"", color = ""white"") +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())


out <- packed_bars + meteorite_map  + plot_annotation(title = ""You May Need More Than An Umbrella in Russia:  Where the Most, and Heaviest, Meteorites fall"",
                                                subtitle = str_wrap(""On the left is a packed bar chart showing the top 10 regions struck by the most meteorites, while the tile map on the right shows the average meteorite mass across all regions.  Both measures have been scaled logathrimically to aid in comparability."", 180),
                                                caption = ""Data: NASA | Graphic: @jakekaupp"",
                                              theme = theme_jk())

ggsave(here(""2019"", ""week24"", ""tw24_plot.png""), out, width = 14, height = 7)
","2019-24"
"90",90,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week24/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}

","2019-24"
"91",91,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week25/R/analysis.R","library(tidyverse)
library(waffle)
library(jkmisc)
library(here)

bird_counts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

top_10 <- bird_counts %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  group_by(genus) %>% 
  summarize(total = sum(how_many_counted_by_hour, na.rm = TRUE)) %>% 
  top_n(10, total) %>% 
  pull(genus)

by_genus <- filter(bird_counts, year >= 2000) %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  filter(genus %in% top_10) %>% 
  group_by(year, genus) %>% 
  summarize(counts_by_hour = sum(how_many_counted_by_hour, na.rm = TRUE))

colors <- set_names(gray.colors(10), top_10)

colors[""Anas""] <- ""#ffd45c""

ducks <- ggplot(by_genus, aes(values = counts_by_hour, fill = genus)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, nrow = 1, strip.position = ""bottom"") +
  coord_equal() +
  labs(title = str_to_title(""The Duck is one of the most noble, agile and intelligent creatures in the animal kingdom.""),
       subtitle = str_wrap(""Total counts per hour, of the top 10 genera from since 2000.  Duck counts (genus Anas) are highlighted in yellow, because if it looks like a duck, and quacks like a duck, we have at least to consider the possibility that we have a small aquatic bird of the family anatidae on our hands."", 120),
       caption = ""Data: www.birdscanada.org/ | Graphic: @jakekaupp"") +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  scale_fill_manual(values = colors) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(strip.text = element_text(size = rel(0.8)))

cobra_chicken <- bird_counts %>% 
  filter(year >=1950) %>% 
  group_split(species) %>% 
  map_dfr(~mutate(.x, color = if_else(species == ""Canada Goose"", ""#CB181D"", sample(gray.colors(255), 1)),
                  alpha = if_else(species == ""Canada Goose"", 1, 0.25))) %>%   
  ggplot(aes(x = year, y = how_many_counted_by_hour, group = fct_relevel(species, ""Canada Goose"", after = Inf), fill = color, alpha = alpha), color = ""grey30"") +
  geom_area() +
  scale_y_continuous(expand = c(0.01, 0.1), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = c(seq(1950, 2010, 10), 2017)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Rise Of The Cobra Chicken, the Scourge of the Hamilton Waterfront"",
       subtitle = str_wrap(""The Canada Goose, hilarious and aptly referred to as a 'Cobra Chicken' has been a threat to the delicate ecosystem of Hamilton's Harbor."", 120),
       caption = ""Data: www.birdscanada.org | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE, ticks = TRUE)
  

ggsave(here(""2019"", ""week25"", ""tw25_ducks.png""), ducks, width = 10, height = 4)
ggsave(here(""2019"", ""week25"", ""tw25_canada_goose.png""), cobra_chicken, width = 10, height = 4)
","2019-25"
"92",92,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week26/R/analysis.R","library(sf)
library(albersusa)
library(here)
library(jsonlite)
library(RCurl)
library(janitor)
library(jkmisc)
library(cowplot)
library(tidyverse)



# Get ufo  & pop. density data----
ufo_sightings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

pop_density <- read_csv(here(""2019"", ""week26"", ""data"", ""pop_density.csv""), skip = 1) %>% 
  clean_names() %>% 
  filter(target_geo_id2 > 1000) %>% 
  mutate(fips = str_pad(target_geo_id2, 5, side = ""left"", pad = ""0"")) %>% 
  select(fips, density = contains(""density""))

# Get alberusa us county sf object----
us_counties <- counties_sf()

# Conver the us ufo sightings to an sf object and join with the alberusa to the the county fips----
usa_sightings_fips <- ufo_sightings %>% 
  filter(country == 'us') %>% 
  st_as_sf(crs = 4326, coords = c(""longitude"", ""latitude"")) 

cont_usa_sightings <- st_join(us_counties, usa_sightings_fips) 



# Some are missing!----
missing <- st_join(usa_sightings_fips, us_counties)  %>% 
  filter(is.na(fips)) %>% 
  semi_join(ufo_sightings,.)

# Make a function to call to the fcc census block API----
geocode_fips <- function(latitude, longitude, index) {
  
  url <- sprintf(""https://geo.fcc.gov/api/census/block/find?latitude=%f&longitude=%f&format=json"",  latitude, longitude)
  
  response <- getURL(url)
  
  json <- fromJSON(response)
  
  print(index)
  
  as.character(json$County['FIPS'])
}

# Make this work insistently----
insistent_geocode <- insistently(~geocode_fips(..1, ..2, ..3), rate = rate_backoff())

# Make it return NA if it fails ----
poss_insistent_geocode <- possibly(~insistent_geocode(..1, ..2, ..3), otherwise = NA_character_)

# Get the missing fips ----

if(!file.exists(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))) {
  missing_fips <- missing %>% 
    distinct(latitude, longitude) %>% 
    mutate(index = row_number()) %>% 
    mutate(fips = pmap_chr(list(latitude, longitude, index), poss_insistent_geocode)) } else {
      
      missing_fips <- readRDS(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))
      
    }

# Join it back to missing to fill in fips ----
missing <- left_join(missing, missing_fips) %>% 
  dplyr::select(-index) 

# Bind rows back to cont_usa_sightings for full_usa data ----
full_usa <- cont_usa_sightings %>% 
  left_join(missing, by = c(names(ufo_sightings)[c(1:2,4:9)], ""state.x"" = ""state"")) %>% 
  mutate_at(vars(contains(""fips"")), as.character) %>% 
  mutate(fips = coalesce(`fips.x`, `fips.y`)) %>% 
  select(-fips.x, -fips.y, -state_fips, -county_fips, -latitude, -longitude)

# Summarize sightings, create a ratio and add in population densities----
plot_data <- full_usa %>% 
  group_by_at(.vars = vars(fips, name, lsad, census_area, state.y, iso_3166_2)) %>% 
  summarize(sightings = n()) %>% 
  ungroup() %>% 
  mutate(sightings_ratio = 100*sightings/sum(sightings)) %>% 
  left_join(pop_density)


# create 3 buckets for variables ---
quantiles_sightings <- plot_data %>%
  pull(sightings_ratio) %>%
  quantile(probs = seq(0, 1, length.out = 4))

quantiles_density <- plot_data %>%
  pull(density) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# create color scale that encodes two variables
# red for sightings and blue for population density
bivariate_color_scale <- tibble(
  ""3 - 3"" = ""#3F2949"", # high sightings, high density
  ""2 - 3"" = ""#435786"",
  ""1 - 3"" = ""#4885C1"", # low sightings, high density
  ""3 - 2"" = ""#77324C"",
  ""2 - 2"" = ""#806A8A"", # medium sightings, medium density
  ""1 - 2"" = ""#89A1C8"",
  ""3 - 1"" = ""#AE3A4E"", # high sightings, low density
  ""2 - 1"" = ""#BC7C8F"",
  ""1 - 1"" = ""#CABED0"" # low sightings, low density
) %>%
  gather(""group"", ""fill"")


# Assign each fips area to their correct group and assign the fill from the bivariate scale ----
plot_data <- plot_data %>%
  mutate(sightings_quantiles = cut(sightings_ratio,
                              breaks = quantiles_sightings,
                              include.lowest = TRUE),
    density_quantiles = cut(density,
                            breaks = quantiles_density,
                            include.lowest = TRUE),
    group = paste(as.numeric(sightings_quantiles), ""-"", as.numeric(density_quantiles))) %>%
  left_join(bivariate_color_scale, by = ""group"")


# Making ze plot ----
plot <- ggplot(plot_data) +
  geom_sf(aes(fill = fill), size = 0.05, color = ""#2b2b2b"") +
  scale_fill_identity() +
  labs(title = ""If A UFO Flew Over The Desert And No One Was Around To See It, Would Senators Be Briefed?"",
       subtitle = str_wrap(""Below is a bivariate choropleth map by county illustrating the relationship between the UFO sightings (% of recorded sightings since 1911) and population density (people per sq. mile circa 2010).  Densely populated coastal and lakeside areas along with the sparsely populated southwest have the highest sightings, whereas the less populous midwest and Alaska have lower percentages of sightings."", 110),
       caption = ""Data: NUFORC & 2010 US Census | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank()) +
  coord_sf(clip = ""off"")

# Making ze legend ---
bivariate_legend <- bivariate_color_scale %>% 
  separate(group, into = c(""sightings"", ""density""), sep = "" - "") %>%
  mutate_at(c(""sightings"", ""density""), as.integer)

legend <- ggplot(bivariate_legend) +
  geom_tile( aes(x = sightings, y = density, fill = fill)) +
  scale_fill_identity() +
  labs(x = expression(paste(""More Sightings "", symbol('\256'))),
       y = expression(paste(""More People "", symbol('\256')))) +
  theme_jk(grid = FALSE) +
  theme(axis.title = element_text(size = 6),
        axis.text = element_blank()) +
  coord_fixed(clip = ""off"")

finished_plot <- ggdraw() +
  draw_plot(plot, 0, 0, 1, 1) +
  draw_plot(legend, 0.75, 0.075, 0.2, 0.2)


ggsave(here(""2019"", ""week26"", ""tw26_plot.png""), plot = finished_plot, width = 10, height = 6)
","2019-26"
"93",93,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week28/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(glue)


squads <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")


data <- squads %>% 
  mutate(idx = goals/caps) %>% 
  filter(pos != ""GK"", caps > 0, goals > 0) %>% 
  mutate(pos = case_when(pos == ""DF"" ~ ""Defense"",
                         pos == ""FW"" ~ ""Forward"",
                         pos == ""MF"" ~ ""Mid-Field"")) %>% 
  mutate(desc = glue(""{club}\n{caps} Matches, {goals} Goals"")) %>% 
  mutate(pos = factor(pos, c(""Defense"", ""Mid-Field"", ""Forward"")))

means <- data %>% 
  group_by(pos) %>% 
  summarize(idx = mean(idx))

plot <- ggplot(data, aes(x = age, y = idx)) +
  geom_point(color = ""grey20"") +
  geom_mark_circle(aes(label = player, description = desc, filter = player == ""Khadija Shaw""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Lea Schller""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Ainon Phancha""), expand = unit(4, ""mm"")) +
  geom_hline(data = means, aes(yintercept = idx), color = ""firebrick"") +
  theme_jk() +
  facet_wrap(~pos, nrow = 1) +
  labs(y = NULL,
       x = ""Age"",
       title = ""Efficient Scorers Competing in the Womens World Cup by Position and Age"",
       subtitle = str_wrap(""Goals per games played in international play by player age.  Red line illustrates the average goals per game at each position.  The highly efficient players at each position are a mix of newcomers and seasoned veterans, illustrating consistency in some players through their career."", 120),
       caption = ""Data: data.world | Graphic : @jakekaupp"")

ggsave(here(""2019"", ""week28"", ""tw28_plot.png""), plot = plot, width = 10, height = 6)

","2019-28"
"94",94,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week29/R/analysis.R","library(tidyverse)
library(tricolore)
library(ggtern)
library(here)
library(jkmisc)
library(magick)

r4ds_members <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")


tern_plot <- Tricolore(r4ds_members, ""percent_of_messages_public_channels"",
          ""percent_of_messages_private_channels"",
          ""percent_of_messages_d_ms"", breaks = 5, show_data = FALSE)

legend <- tern_plot$key +
  labs(title = ""Color Legend"",
       x       = ""Public\nChannels"",
       y       = ""Private\nChannels"",
       z       = ""Direct\nMessages"") +
  theme_hidetitles() +
  theme_hidelabels() +
  theme_hideticks() +
  theme(plot.title = element_text(hjust = 0.5, family = ""Scope One"", size = 40),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One""))

png(here(""2019"", ""week29"", ""legend.png"")) 
legend
dev.off()

legend <- image_read(here(""2019"", ""week29"", ""legend.png""))

plot <- r4ds_members %>% 
  mutate(color = tern_plot$rgb,
         year = lubridate::year(date)) %>% 
  ggtern(aes(x = percent_of_messages_public_channels, y = percent_of_messages_private_channels, z = percent_of_messages_d_ms, color = color)) +
  geom_point(size = 3) +
  scale_color_identity() +
  labs(title = str_to_title(""The Dialogue in the R4DS Slack indicates an Open and Inclusive Learning Community""),
       subtitle = str_wrap(""Below is a ternary digram presenting the message composition in public channels, private channels and direct messages as a percentage.  Each day is represented by a point with the composition represented by position relative to each axes.  Composition is additionally encoded by color as illustrated on the inset legend."", 100),
       x       = ""Public\nChannels"",
       xarrow  = ""More Public Channel Messages"",
       y       = ""Private\nChannels"",
       yarrow  = ""More Private Channel Messages"",
       z       = ""Direct\nMessages"",
       zarrow  = ""More Direct Messages"",
       caption = ""Data: R4DS Community | Graphic: @jakekaupp"") +
  theme(panel.background = element_rect(fill = ""#2E3440""),
        panel.grid = element_line(color = ""#ffffff"", size = 0.1),
        panel.grid.minor = element_blank(),
        text = element_text(family = ""Oswald""),
        plot.subtitle = element_text(family = ""Scope One""),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One"")) +
  theme_showarrows() +
  theme_arrowlong() 


png(here(""2019"", ""week29"", ""tw29_plot.png""), width = 10, height = 8, units = ""in"", res = 200)
grid::grid.newpage()
plot
grid::grid.raster(legend, width = 0.18, height = 0.2, x = 0.75, y = 0.7)
dev.off()
","2019-29"
"95",95,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week3/R/analysis.R","library(tidyverse)
library(here)
library(nord)
library(jkmisc)
library(ggbeeswarm)
library(ggrepel)

agencies <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/agencies.csv"")

launches <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/launches.csv"")


us_launch_data <- launches %>% 
  filter(agency == ""US"" | state_code == ""US"") %>% 
  mutate(type = gsub(""Zenit-"", ""Zenit "", type),
         type = gsub(""/"", "" "", type),
         type = gsub(""Minotaur-"", ""Minotaur "", type)) %>% 
  separate(type, ""type"", sep = "" "", extra = ""drop"") %>% 
  mutate(type = if_else(type == ""Space"", ""Space Shuttle"", sprintf(""%s Program"",type))) %>% 
  mutate(label = if_else(type == ""Space Shuttle"" & category == ""F"", ""Challenger Disaster"", NA_character_)) %>% 
  group_by(type) %>% 
  filter(n() > 10)

plot <- ggplot(us_launch_data, aes(x = launch_year, y = type), size = 4) +
  geom_quasirandom(data = filter(us_launch_data, category == ""O""), alpha = 0.2, fill = nord(""polarnight"", 2)[2], shape = 21, groupOnX = FALSE) +
  geom_quasirandom(data = filter(us_launch_data, category == ""F""), fill = nord(""victory_bonds"", 5)[1], shape = 21, groupOnX = FALSE, color = ""grey30"", stroke = 0.2) +
  theme_jk(grid = ""XY"", dark = FALSE) +
  labs(x = NULL,
       y = NULL,
       title = ""From the Space Race to Space-X: 1548 Successes and 101 Failures of US Launch Vehicles from 1958-2018."",
       subtitle = str_wrap(""A beeswarm plot illustrating the success or failure of a launch vehicle program over time. Red dots indicate failed launches, grey dots indicate success.  Deeper grey colors indicate a higher frequency of success in a given year due to multiple launches. Only includes programs with more than 10 launches"", 120),
       caption = ""Data: JSR Launch Vehicle Database | Analysis: @jakekaupp"")

plot <- plot + annotate(""segment"", x = 1987, xend = 1986.2, y = 8.7, yend = 8.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1986, y = 9, label = ""Challenger Disaster"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1]) +
  annotate(""segment"", x = 1959, xend = 1958.2, y = 1.7, yend = 1.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1959, y = 2.5, label = ""First Communication\nSatellite Protoype"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0) +
  annotate(""segment"", x = 2015, xend = 2015, y = 5.5, yend = 3.1, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 2013, y = 6.5, label = ""SpaceX Falcon 9\nStrut Failure"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0)

ggsave(here(""2019"", ""week3"", ""tt_week3.png""), plot, width = 11, height = 5)

","2019-3"
"96",96,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week30/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  #mutate(airport_type = if_else(str_detect(airport, ""INTL""), ""INT"", ""DOM"")) %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  complete(incident_year = 1990:2018, state,  incident_month = 1:12, fill = list(n = 0)) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


state_flower_grid <- plot_data %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, 
       y = NULL) +
  coord_polar() +
  facet_geo(~ state, grid = ""us_state_grid2"") +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""))

flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Single colour petal represents a single collison event during this month"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1, breaks = c(seq(1990, 2020, by = 5))) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar(), color = ""none"") +
  labs(x = NULL, y = NULL) +
  coord_polar(clip = ""off"") +
  theme_jk(grid = ""XY"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())

finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.17, 0.4, 0.4)

out <- wrap_plots(finished_legend, state_flower_grid,  nrow = 1, widths = c(0.85, 1.2)) +
   plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                   subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft, with an inset legend showing assisting interpretation.  Wildlife collisions by state are presented as small multiples, geographically arranged.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                   caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                   theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot.png""), out, width = 16, height = 10, type = ""cairo"")


","2019-30"
"97",97,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week30/R/experiment.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent)) %>% 
  mutate(angle = 90 - (incident_month-1)*30,
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
         
         
big_flower <- ggplot(plot_data) +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.2, size = 0, color = ""white"") +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  theme_jk(grid = FALSE, plot_title_size = 12) +
  labs(x = NULL, y = NULL, title = ""National"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""),
        plot.title = element_text(hjust = 0.5)) +
  coord_equal() 

state_flower <- big_flower +
  facet_geo(~ state, grid = ""us_state_grid2"")


flower_axes_lines <- tibble(idx = 1:12,
                            angle = 90 - (idx-1)*30,
                            angle2 = ifelse(angle < 0, 360 + angle, angle),
                            radians = angle2*pi/180)

axes_lines <- function(radius) {
  
  tibble(segment = 1:6,
                     x = c(0, radius*cos(pi/3), radius*cos(pi/6), radius, radius*cos(pi/6), radius*cos(pi/3)),
                     xend = c(0, -radius*cos(pi/3), -radius*cos(pi/6), -radius, -radius*cos(pi/6), -radius*cos(pi/3)),
                     y = c(radius, radius*sin(pi/3), radius*sin(pi/6), 0, -radius*sin(pi/6), -radius*sin(pi/3)),
                     yend = c(-radius, -radius*sin(pi/3), -radius*sin(pi/6), 0, radius*sin(pi/6), radius*sin(pi/3))) 
  }

axes_labels <- function(radius) {
  tibble(month = 1:12,
                      label = month.abb[month],
                      x = c(axes_lines(radius)$x, axes_lines(radius)$xend),
                      y = c(axes_lines(radius)$y, axes_lines(radius)$yend))  }


flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_segment(data = axes_lines(2), aes(x = x, xend = xend, y = y , yend = yend), size = 0.1, color = ""#cccccc"", inherit.aes = FALSE) +
  geom_circle(aes(x0 = 0, y0 = 0, r = 2), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_circle(aes(x0 = 0, y0 = 0, r = 1), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.5, size = 0.1, color = ""white"") +
  geom_mark_circle(aes(x = 2*x0, y = 2*y0, label = glue(""{month.name[incident_month]}, {incident_year}""), description = ""Single colour long petal represents 100% of collison event during this month and year"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_mark_circle(aes(x = x0, y = y0, label = glue(""{month.name[incident_month]}, Multiple years""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_text(data = filter(axes_labels(2.15), label != ""Feb""), aes(x = x, y = y, label = label), inherit.aes = FALSE, family = ""Oswald"") +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  coord_fixed(clip = ""off"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())


finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.175, 0.4, 0.4)

state_flower_grid <- ggdraw() +
  draw_plot(state_flower, 0, 0, 1, 1) + 
  draw_plot(big_flower, 0.75, 0.15, 0.25, 0.25)

out <- wrap_plots(finished_legend, state_flower_grid, nrow = 1, widths = c(0.85, 1.2)) +
  plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                  subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft across the US from 1990-2018. Below this is an inset legend showing assisting interpretation of the plots.  On the right are wildlife-aircraft collisions by state presented as small multiples, geographically arranged, with an inset flower representing the National data. Petal length is the annual proportion of collisions in a given month.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                  caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                  theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot_remix.png""), out, width = 16, height = 10, type = ""cairo"")
","2019-30"
"98",98,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week31/R/analysis.R","library(tidyverse)
library(here)
library(ggbeeswarm)
library(jkmisc)

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")  
 
all_games <- video_games %>% 
  filter(!is.na(game), !is.na(metascore))  %>% 
  mutate(developer = tolower(developer),
         idx = row_number())

plot_data <- tibble(facet = c(""bioware"", ""valve"", ""ubisoft"", ""rockstar"", ""square enix""),
       data = list(all_games)) %>% 
  mutate(filtered = map2(data, facet, ~mutate(.x, option = case_when(str_detect(tolower(developer), .y) ~ ""selected"", 
                                                                     TRUE ~ ""other"")))) %>% 
  unnest(filtered) %>% 
  mutate(facet = case_when(facet == ""bioware"" ~ ""BioWare"",
                           facet == ""valve"" ~ ""Valve"",
                           facet == ""ubisoft"" ~ ""Ubisoft"",
                           facet == ""rockstar"" ~ ""Rockstar"",
                           facet == ""square enix"" ~ ""Square Enix"")) %>% 
  mutate(option = factor(option, c(""other"", ""selected""))) %>% 
  arrange(facet, option)



mean <- all_games %>% 
  summarize(metascore = mean(metascore, na.rm = TRUE)) %>% 
  pull(metascore)

min_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == min(metascore))

max_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == max(metascore)) %>% 
  mutate(game = if_else(str_detect(""FINAL FANTASY"", game), ""Final Fantasy IX"", game)) %>% 
  slice(1)

plot <- ggplot(plot_data) +
  geom_quasirandom(aes(y = metascore, x = 0, alpha = option, fill = option, size = option), shape = 21, method = ""tukey"", show.legend = FALSE) +
  geom_label(data = min_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = -2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_label(data = max_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = +2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_hline(yintercept = mean, color = ""firebrick"", size = 0.5, linetype = ""dashed"") +
  labs(x = NULL, 
       y = NULL,
       title = ""How Do The Big Developers Score Against The Competition on Steam?"",
       subtitle = str_wrap(""Presented below is a jittered strip plot of metascore by developer.  Titles worked on by that developer are highlighted in yellow, the average metascore (72) is shown as a dashed red line. Annotations show the top an bottom rated titles for each developer.  Sqaure and Ubisoft have the most titles with less than average reviews amongst the large developers."", 180),
       caption = ""Data: SteamSpy | Graphic: @jakekaupp"") +
  scale_size_manual(values = c(""other"" = 2, ""selected"" = 2)) +
  scale_y_continuous(limits = c(20, 100), breaks = seq(20, 100, 20)) +
  scale_fill_manual(values = c(""other"" = ""#E5E4E2"", ""selected"" = ""#ffd644"")) +
  scale_alpha_manual(values = c(""other"" = 0.05, ""selected"" = 1)) +
  theme_jk(grid = ""Y"", dark = TRUE) +
  facet_wrap(~facet, nrow = 1) +
  theme(strip.text = element_text(color = ""white""),
      axis.text.x = element_blank())

ggsave(here(""2019"", ""week31"", ""tw31_plot.png""), plot, width = 14, height = 8)
","2019-31"
"99",99,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week32/R/analysis.R","library(tidyverse)
library(ggforce)
library(here)
library(jkmisc)
library(patchwork)

bob_ross_paintings <- here(""2019"", ""week32"", ""data"", ""tidytuesday_201932_bob_ross_paintings.csv"")

data <- read_csv(bob_ross_paintings, col_names = c('episode', 'title', 'color', 'color_name')) %>% 
  mutate(season = parse_number(str_extract(episode, ""S\\d+"")),
         color = if_else(color == ""#FFFFFF"", ""grey80"", color))


plot_data <- data %>% 
  count(season, title, color_name, color) %>% 
  group_by(season, title) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  mutate(color_number = as.numeric(factor(color_name))) %>% 
  mutate(angle = (color_number-1)*(360/15),
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
  

plot_spiros <- function(data) {
  
season <- sprintf(""Season %s"",unique(data$season))
  
ggplot(data) +
  geom_spiro(aes(R = ifelse(percent == 1, 0.1, 1 - percent), r = percent, d = radians, color = color, group = color), size = 0.1) +
  scale_color_identity() +
  theme_jk(grid = FALSE, plot_title_size = 8, strip_text_size = 8) +
  facet_wrap(~ title, ncol = 1, labeller = label_wrap_gen(15)) +
  labs(x = NULL, y = NULL, title = season) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines"")) +
  coord_equal()  }


plots <- plot_data %>% 
  split(.$season) %>% 
  map(plot_spiros)


all_seasons <- wrap_plots(plots, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = ""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."",
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot.png""), plot = all_seasons, width = 30, height = 15, type = ""cairo"")

twitter <- map(plots, ~.x + theme(strip.text = element_blank()))


all_seasons_twitter <- wrap_plots(twitter, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = str_wrap(""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."", 265),
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot_for_twitter.png""), plot = all_seasons_twitter, width = 20, height = 7)


","2019-32"
"100",100,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week33/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)


emperors <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"") 

ad_births <- c(""Augustus"", ""Tiberius"", ""Claudius"", ""Galba"")

emp_numeric_years <- emperors %>% 
  mutate_if(is.Date, list(year = year)) %>% 
  mutate(birth_year = if_else(name %in% ad_births, -birth_year, birth_year),
         reign_start_year = if_else(name == ""Augustus"", -reign_start_year, reign_start_year))


missing_birth_estimates <- emp_numeric_years %>% 
  filter(is.na(birth_year)) %>% 
  mutate(birth_year = case_when(name == ""Florian"" ~ 202,
                                name == ""Numerian"" ~ 248,
                                name == ""Carinus"" ~ 245,
                                name == ""Severus II"" ~ 260,
                                name == ""Vetranio"" ~ 325))


plot_data <- emp_numeric_years %>% 
  filter(!is.na(birth_year)) %>% 
  bind_rows(missing_birth_estimates)


dynasties <- plot_data %>% 
  group_by(dynasty) %>% 
  summarize(reign_start_year = min(reign_start_year),
               reign_end_year = max(reign_end_year))

roman_palette <- set_names(colorRampPalette(c(""#191970"", ""#FF7F50""))(8), unique(plot_data$dynasty))


overall <- ggplot(plot_data, aes(y = 0)) +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = 0, color = dynasty), size = 4) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, y = NULL,
       caption = ""Data: Wikipedia via @geokaramanis | Graphic: @jakekaupp"") +
  theme_jk(grid = ""X"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

bars <- ggplot(plot_data, aes(y = reorder(name, reign_start_year))) +
  geom_segment(aes(x = birth_year, xend = death_year, yend = name), size = 2, color = ""grey90"") +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = name, color = dynasty), size = 2) +
  geom_segment(data = filter(plot_data, reign_start_year == reign_end_year), aes(x = reign_start_year - 0.5, xend = reign_start_year + 0.5, y = name, yend = name, color = dynasty), size = 2) +
  geom_text(aes(x = death_year, label = name), hjust = 0, family = ""Scope One"", size = 2, nudge_x = 3) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, 
       y = NULL,
       title = str_to_title(""When in Rome: The Game of Imperial Thrones. You Win or You Die.""),
       subtitle = str_wrap(""Illustrated below is a timeline of the life and reigns of Roman Emperors from 62 BC to 395 AD.  The light grey bar depicts the liftime of the emperor, the colored bar (by dynasty) indicates the duration of their reign. An overall timeline by dynasty is shown near the horizontal axis. Unsurprisingly, the majority of emperors reign ending also coincides with the end of their life."", 100)) +
  theme_jk(grid = ""X"") +
  theme(axis.text = element_blank(),
        legend.position = c(0.2, 0.7),
        legend.background = element_rect(fill = ""white"", size = 0))


out <- wrap_plots(bars, overall, ncol = 1, heights = c(0.9, 0.1))

ggsave(here(""2019"", ""week33"", ""tw33_plot.png""), out, width = 7.5, height = 8)
","2019-33"
"101",101,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week34/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggtext)
library(jkmisc)
library(waffle)
library(ggforce)
library(glue)
library(ragg)

nuclear_explosions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")




plot_data <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  group_by(country, date_long) %>% 
  summarize(n = n(),
            total_yield = sum(yield_upper, na.rm = TRUE)) %>% 
  group_by(country) %>% 
  mutate(c_sum = cumsum(n),
         c_yield = cumsum(total_yield)/1000) %>% 
  filter(country %in% c(""USSR"", ""USA""))

items <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  group_by(country) %>% 
  top_n(1, yield_upper) %>% 
  slice(1) %>%
  semi_join(plot_data, .) %>% 
  mutate(date_long = ymd(date_long) - 1) %>% 
  mutate(name = if_else(country == ""USA"", ""March 1954: Castle Bravo"", ""October 1961: Tsar Bomba""),
         description  = if_else(country == ""USA"", ""2nd most powerful nuclear test explosion, 3 times over the predicted 5 MT yield."", ""Most powerful nuclear test explosion, twice the predicted yield of 25 MT.""))

explosions <- ggplot(plot_data, aes(x = c_sum, y = c_yield, color = country)) +
  geom_step(linetype = ""solid"", size = 1, direction = ""hv"") +
  geom_point(data = filter(plot_data, date_long %in% range(date_long))) +
  geom_text(data = filter(plot_data, date_long == last(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", hjust = -0.5) +
  geom_text(data = filter(plot_data, date_long == first(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", nudge_y = c(10, -10)) +
  geom_mark_circle(data = items, aes(color = country, label = name, description = description), expand = unit(3, ""mm""), label.margin = margin(5, 5, 5, 5, ""mm""), con.colour = c(""#0052A5"", ""#FF2400""), label.family = c(""Oswald"",""Scope One""), label.fill = NA, label.minwidth = unit(50, ""mm""), label.fontsize = 10, con.type = ""straight"") +
  scale_color_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_fill_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_y_continuous(labels = function(x) scales::comma(x, suffix = "" MT"")) +
  labs(x = 'Cumulative Number of Explosions',
       y = ""Cumulative Yield (MT)"",
       title = ""Nuclear Weapons Research Race During And After The Cold War"",
       subtitle = ""Illustrated below is a step chart showing the number and yield of nuclear explosions for weapons research for <span style='color:#0052A5'>**USA**</span> and <span style='color:#FF2400'>**USSR**</span>.  During this race nearly<br>500 MT of nuclear explosions and accompanying fallout blanketed the world. The effects are still being dealt with to this date."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(plot.title = element_markdown(), 
        plot.subtitle = element_markdown(),
        legend.position = ""none"")
  
ggsave(here(""2019"", ""week34"", ""tw34_plot_2.png""), plot = explosions, width = 12, height = 6, device = agg_png())


# Waffle ----

waffle_data <- nuclear_explosions %>% 
  mutate(purpose = case_when(grepl(""WR"", purpose) ~ ""WR"",
                             grepl(""WE"", purpose) ~ ""WE"",
                             grepl(""PNE"", purpose) ~ ""PNE"",
                             TRUE ~ purpose)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  count(year, purpose) %>% 
  group_by(purpose) %>% 
  mutate(c_sum = cumsum(n))


pal <- set_names(sample(grey.colors(50),10), unique(waffle_data$purpose))

pal[""WR""] <- ""#8A0303""

waffle <- ggplot(waffle_data, aes(fill = purpose, values = c_sum)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, strip.position = ""bottom"", nrow = 1) +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  coord_equal() +
  scale_fill_manual(values = pal) +
  labs(y = ""Cumulative Number of Explosions"",
       title = ""Nuclear Weapons Research Testing During the Cold War Was the Primary Driver of Controlled  Nuclear Explosions"",
       subtitle = ""Illustrated below is a timeline of waffle charts showing the distribution of cumulative explosions from <span style='color:#8A0303'>**weapons research**</span> or <span style='color:#4D4D4D'>**other purposes**</span>. Widescale Nuclear testing ceased in the mid-'90's. The only active country<br>conducting nuclear testing in this era is North Korea, weathering the disapproval and ire of the global community."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(strip_text_size = 10,
           subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(panel.grid = element_blank(), 
        axis.ticks.y = element_line(),
        strip.text = element_text(hjust = 0.5),
        plot.title = element_markdown(), 
        plot.subtitle = element_markdown())
  
ggsave(here(""2019"", ""week34"", ""tw34_plot.png""), plot = waffle, width = 18, height = 6, device = agg_png())
","2019-34"
"102",102,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week35/R/analysis.R","library(tidyverse)
library(tidygraph)
library(ggraph)
library(colorspace)
library(glue)
library(jkmisc)
library(ggtext)
library(ragg)
library(here)


html_string <- glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'. {subtitle_names} are the most frequent guest stars in the series."")

str_break <- function (html_string, width = 80, indent = 0, exdent = 0) {

tags <- str_extract_all(html_string, ""<.*?>"") %>% 
  flatten_chr() 

index <- sprintf(""tag_%s"", seq_along(tags))

string <- str_replace_all(html_string, set_names(index, tags))

  if (width <= 0) 
    width <- 1
  
  out <- stringi::stri_wrap(string, width = width, indent = indent, 
                   exdent = exdent, simplify = FALSE)
  
  broken <- vapply(out, str_c, collapse = ""<br>"", character(1))
  
  str_replace_all(broken, set_names(tags, index))
  
}

text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


simpsons <- read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")

nodes <- count(simpsons, guest_star) 

top5 <- top_n(nodes, 5, n) %>% 
  arrange(desc(n)) %>% 
  rownames_to_column(var = ""color"") %>% 
  select(-n)

nodes <- nodes %>% 
  left_join(top5) %>% 
  replace_na(list(color = 7)) %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  mutate(alpha = if_else(color < 7, 1, 0.5)) 


edges <- simpsons %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  group_by(production_code) %>% 
  mutate(co_stars = map(guest_star, ~str_subset(guest_star, .x, negate = TRUE))) %>%
  ungroup() %>% 
  mutate(co_stars = map(co_stars, ~ifelse(length(.x) == 0, NA_character_,.x))) %>% 
  unnest(co_stars) %>% 
  count(guest_star, co_stars) %>% 
  filter(!is.na(n), !is.na(co_stars)) %>% 
  set_names(c(""from"", ""to"", ""n"")) %>% 
  left_join(top5, by = c(""from"" = ""guest_star"")) %>% 
  left_join(top5, by = c(""to"" = ""guest_star"")) %>% 
  mutate(color = coalesce(color.x, color.y)) %>% 
  replace_na(list(color = ""grey80"")) 

  
colors <- set_names(tol6qualitative, top5$guest_star)  

subtitle_names <- imap(colors[1:5], ~text_bc(.y, .x)) %>% 
  glue_collapse(sep = ', ') %>% 
  glue("" and {imap(colors[6], ~text_bc(.y, .x))}"")

co_star_graph <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)

co_star_plot <- co_star_graph %>% 
  activate(nodes) %>% 
  arrange(n) %>% 
  mutate(degree = centrality_degree()) %>% 
  filter(degree > 1) %>%  
  ggraph(layout = ""fr"") + 
  geom_edge_arc(edge_width = 0.5, curvature = 0.2, aes(alpha = stat(index), edge_colour = color)) +
  geom_node_point(aes(size = n, color = color, alpha = alpha, fill = color), shape = 21) +
  scale_color_manual(values = c(darken(tol6qualitative), ""grey80"")) + 
  scale_alpha_identity() +
  scale_edge_color_manual(values = c(tol6qualitative, ""grey85"")) +
  scale_fill_manual(values = c(tol6qualitative, ""grey80"")) + 
  scale_size(range = c(2,6)) +
  labs(x = NULL,
       y = NULL,
       title = ""The Guest Star Backbone Of A Simpsons Co-Star Network"",
       subtitle = glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'.<br> {subtitle_names} <br>are the most frequent guest stars in the series.""),
       caption = ""**Data**: Wikipedia via @datawookie | **Graphic**: @jakekaupp"") +
  theme_jk(grid = FALSE,
           subtitle_family = ""Lora"",
           caption_family = ""Lora"",
           markdown = TRUE) +
  theme(legend.position = ""none"",
        axis.text = element_blank())

ggsave(here(""2019"", ""week35"", ""tw35_plot.png""), plot = co_star_plot, device = agg_png(), width = 9, height = 8)

ggplot(mtcars, aes(x = mpg, y = disp)) +
  geom_point() +
  labs(title = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't""),
       subtitle = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't"")) +
  theme_jk() +
  theme(plot.title = ggtext::element_markdown(),
        plot.subtitle = ggtext::element_markdown())
","2019-35"
"103",103,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week36/R/analysis.R","library(tidyverse)
library(jkmisc)
library(nord)
library(glue)
library(here)
library(ragg)

cpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")

gpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")

ram <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")


plot_data <- list(cpu = cpu, gpu = gpu) %>% 
  imap_dfr(~select(.x, date_of_introduction, transistor_count, area, process) %>% 
             mutate(type = .y)) %>% 
  group_by(date_of_introduction, type) %>% 
  summarize_at(vars(transistor_count, area, process), mean, na.rm = TRUE) %>% 
  arrange(date_of_introduction, type)

strip_labels <- tibble(type = c(""cpu"", ""gpu""))

plot <- ggplot(plot_data, aes(x = area, y = transistor_count)) +
  geom_text(data = strip_labels, aes(label = toupper(type)), x = 400, y = 4, family = ""Oswald Bold"", size = 18, color = ""grey90"") +
  geom_smooth(method = ""auto"", formula = y ~ log10(x), se = FALSE, size = 0.5,  color = nth(nord_palettes$victory_bonds, 3)) +
  geom_hline(aes(yintercept = 10^10), linetype = ""dotted"", color = first(nord_palettes$victory_bonds)) +
  geom_point(aes(color = log10(process)), size = 3) +
  scale_color_nord(name = ""Process Size"",
                        discrete = FALSE,
                        palette = ""lumina"",
                        reverse = TRUE,
                        labels = function(x) glue(""{scales::comma(10^x)} nm""),
                        breaks = c(1, 2, 3, 4)) +
  scale_y_log10(breaks = c(1, 10^4, 10^6, 10^8, 10^10),
                labels = c(""1"", ""10K"", ""1M"", ""100M"", ""10B"")) +
  scale_x_continuous(labels = function(x) glue(""{x} {expression(mm^2)}"")) +
  facet_wrap(~type) +
  labs(x = NULL, 
       y = NULL,
       title = ""Moore's Law May Be Dead, Killed By The Tension Between Manufacturing and Transistor Density"",
       subtitle = ""*Moore's law*, the observation that the **number of transistors** on integrated circuits **doubles every two years**<br>
       hasn't held.  Transistor density is reaching a plateau, requiring manufacturing changes of an increase in available<br>
       chip size or a decrease in process size."",
       caption = ""**Data:** Wikipedia | **Graphic:** @jakekaupp"") +
  theme_jk(grid = ""XY"",
          markdown = TRUE) +
  theme(strip.text = element_blank())

ggsave(here(""2019"", ""week36"", ""tw36_plot.png""), plot = plot, device = agg_png(), width = 10, height = 6)
","2019-36"
"104",104,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week37/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(tidygraph)
library(ggraph)
library(ggforce)
library(janitor)
library(jkmisc)
library(glue)
library(ggtext)
library(colorspace)
library(ragg)

legacy_data <- here(""2019"", ""week37"", ""data"", ""Saferparks-dataset-legacy.csv"") %>% 
  read_csv() %>% 
  mutate(year = year(mdy(acc_date))) %>% 
  filter(between(year, 1999, 2007))

device_type <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .75),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .75),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .75))) %>% 
  select(name = device_type, size, color)

device_category <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .25),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .25),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .25))) %>% 
  select(name = device_category, size, color) 

sector <-  legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ ""#251351"",
                           industry_sector == ""recreation"" ~ ""#7d2e68"",
                           industry_sector == ""water park"" ~""#41658a"")) %>% 
  select(name = industry_sector, size, color)

nodes <- bind_rows(sector, device_category, device_type)

edge_one <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(industry_sector, device_category) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edge_two <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(device_category, device_type) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edges <- bind_rows(edge_one, edge_two)

graph <- tbl_graph(nodes = nodes, edges = edges) 

labels <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  group_by(industry_sector) %>% 
  top_n(1 , size) %>% 
  filter(size > 1) %>% 
  pull(device_type) 
 
text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


plot <- ggraph(graph, 'circlepack', weight = size) + 
  geom_node_circle(aes(fill = color)) + 
  geom_node_text(aes(label = glue(""{str_remove(name, ' - undefined')}:\n{size}""), filter = name %in% labels, family = ""Oswald"")) +
  scale_fill_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Attractions With The Most Reported Injuries from 1999-2007"",
       caption = ""Data: **SaferParks** | Graphic: **@jakekaupp**"",
       subtitle = glue(""Shown below is a packed circle representation of reported accidents in the SaferParks database from 1999-2007.<br>Circles are organized by {highlight_text('Amusement rides', '#251351', 'b')}, {highlight_text('Recreation', '#7d2e68', 'b')} and {highlight_text('Water Park', '#41658a', 'b')}. Device category and device type are the<br>middle and lightest hues, respectively."")) +
  theme_jk(grid = FALSE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.subtitle = element_markdown(),
        plot.caption = element_markdown()) 


ggsave(here(""2019"", ""week37"", ""tw_37plot.png""), plot, width = 9, height = 10, dev = agg_png())


","2019-37"
"105",105,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week38/R/analysis.R","library(tidyverse)
library(rvest)
library(janitor)
library(here)
library(fuzzyjoin)
library(jkmisc)
library(ragg)

# Get park fees
fees_page <- ""https://www.nps.gov/aboutus/entrance-fee-prices.htm""

parks <- read_html(fees_page) %>% 
  html_nodes(""h3"") %>% 
  html_text() %>% 
  .[-1:-2]

park_fees <- read_html(fees_page) %>% 
  html_nodes("".table-wrapper > table"") %>% 
  html_table() %>% 
  map(~set_names(.x, c(""date"", ""park_specific_annual_pass"", ""per_vehicle"", ""per_person"", 
                       ""per_motorcycle""))) %>% 
  map2(parks, ~mutate(.x, park = .y)) %>% 
  bind_rows() %>% 
  filter(date == ""Current"") %>% 
  rename(park_name = park) %>% 
  mutate(park_name = stringi::stri_trans_general(park_name, id = ""Latin-ASCII""),
         park_name = str_replace(park_name, ""Hawai'i"", ""Hawaii""))



#udpated data
summary_report <- here(""2019"", ""week38"", ""data"", ""annual_summary_report.csv"") %>% 
  read_csv() %>% 
  clean_names()

plot_data <- summary_report %>% 
  filter(year == 2018) %>% 
  mutate(visitors = recreation_visitors + non_recreation_visitors) %>% 
  select(year, park_name, visitors) %>% 
  mutate(park_name = str_remove(park_name, ""[A-Z]{2,}""),
         park_name = str_remove(park_name, ""& PRES""),
         park_name = trimws(park_name)) %>% 
  regex_left_join(park_fees, ., ignore_case = TRUE) %>% 
  distinct(year, park_name.x, .keep_all = TRUE) %>% 
  filter(str_detect(park_name.x, ""Park""), !str_detect(park_name.x, ""Great Falls"")) %>% 
  mutate(revenue = visitors * parse_number(per_person)) %>% 
  rename(park_name = park_name.x) %>% 
  select(-park_name.y)
  

plot <- ggplot(plot_data, aes(x = fct_reorder(park_name, revenue), y = revenue)) +
  geom_col(fill = ""#5e81ac"", size = 0.1) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar, expand = c(0.01,0)) +
  labs(title = ""Estimated National Park Revenue from Fees for 2018"",
       subtitle = str_wrap(""Illustrated below is a bar chart of fee revenue from US National Parks in 2018.  Estimated Revenue calculated using per person admittance rates and total park visitors."", 95),
       caption = ""Data: www.nps.gov | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = ""X"") +
  theme(plot.background = element_rect(fill = ""#2e3440""),
        text = element_text(color = ""#eceff4""),
        panel.grid = element_line(color = ""#e5e9f0""),
        axis.text.x = element_text(color = ""#eceff4""),
        axis.text.y = element_text(color = ""#eceff4""))

ggsave(here(""2019"", ""week38"", ""tw_38plot.png""), plot, width = 10, height = 8, device = agg_png())

","2019-38"
"106",106,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week39/R/analysis.R","library(tidyverse)
library(janitor)
library(tidycensus)
library(glue)
library(here)
library(sf)
library(tigris)
library(jkmisc)
library(ggtext)

school_diversity <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv"")

## Getting the ACS Survey data ----
acs_var <- load_variables(2017, ""acs1"", cache = TRUE)

race_vars <- filter(acs_var, concept == ""RACE"") %>% 
  select(name, label) %>% 
  separate(label, c(""estimate"", ""total"", ""type""), sep = ""!!"") %>% 
  mutate(type = coalesce(type, total)) %>% 
  select(name, label = type)

if (!file.exists(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))) {
  
  acs_race <- map_df(state.abb, ~get_acs(geography = ""school district (unified)"", 
                                         variables = race_vars$name,
                                         state = .x))
  
  saveRDS(acs_race, here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
  
} else {
  
  acs_race <- readRDS(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
}





# Recoding ACS and aggregating data, sadly not easy to determine Hispanic origin ----
# Following methodology from WaPo repo, recoding Native Hawaiian and Pacifici Islander into Asian.
diversity_data <- acs_race %>% 
  left_join(race_vars, by = c(""variable"" = ""name"")) %>% 
  mutate(label = case_when(label == ""White alone"" ~ ""White"",
                           label == ""Black or African American alone"" ~ ""Black"",
                           label == ""American Indian and Alaska Native alone"" ~ ""AIAN"",
                           label == ""Native Hawaiian and Other Pacific Islander alone"" ~ ""Asian"",
                           label == ""Asian alone"" ~ ""Asian"",
                           label == ""Two or more races"" ~ ""Multi"",
                           label == ""Some other race alone"" ~ ""Other"",
                           TRUE ~ label)) %>% 
  group_by(GEOID, NAME, label) %>% 
  summarize_at(vars(estimate), sum) 


# Using Simpson's Diversity Index instead of max race metrics for diversity----
totals <- diversity_data %>% 
  summarize(total = sum(estimate)*(sum(estimate)-1))

dvs_score <- diversity_data %>% 
  filter(label != ""Total"") %>% 
  mutate(es_minus = estimate-1) %>% 
  summarize(numerator = sum(estimate*es_minus)) %>% 
  left_join(totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID, NAME, diversity) 
  
acs_diversity <- diversity_data %>% 
  spread(label, estimate) %>% 
  select(-Total) %>% 
  left_join(dvs_score) %>% 
  rename(acs_diversity = diversity) %>% 
  ungroup() %>% 
  mutate(NAME = tolower(NAME),
         NAME = str_remove(NAME, ""\\(.+\\)""),
         NAME = str_replace_all(NAME, "";"", "","")) %>% 
  separate(NAME, c(""NAME"", ""state""), sep = "","") %>% 
  mutate(NAME = str_remove_all(NAME, ""school district*+"")) %>% 
  select(GEOID, acs_diversity)

# Use WaPo data and calculate Simpson's Diversity Index
upd_school <- school_diversity %>% 
  filter(SCHOOL_YEAR == ""2016-2017"") %>% 
  select(LEAID, LEA_NAME, ST, SCHOOL_YEAR, AIAN:Total) %>% 
  pivot_longer(AIAN:Multi, ""race"", ""value"") %>% 
  mutate(n = floor(Total * value))

school_totals <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  summarize(total = sum(n)*(sum(n)-1))
  
upd_school_dvs <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  mutate(n_minus = n-1) %>% 
  summarize(numerator = sum(n*n_minus)) %>% 
  left_join(school_totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID = LEAID, NAME = LEA_NAME, ST, school_diversity = diversity) 

# Environment Cleanup---
remove(list = ls()[str_which(ls(), ""upd_school_dvs|acs_diversity"", negate = TRUE)])

# Comparing the two diversity measures and creating the ratio ----
overall_diversity <- upd_school_dvs %>% 
  left_join(acs_diversity, by = ""GEOID"") %>% 
  mutate(ratio = school_diversity/acs_diversity) %>% 
  filter(!is.na(acs_diversity))

# Get School District maps ----

if (!file.exists(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))) {
  
  district_maps <- map(state.abb, ~school_districts(.x, class = ""sf""))
  
  saveRDS(district_maps, here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
  
} else {
  
  district_maps <- readRDS(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
}



# One do.call to keep them all, and in the shallows bind them----
maps <- do.call(sf:::rbind.sf, district_maps)

plot <- overall_diversity %>%
  right_join(maps, ., by = ""GEOID"") %>%
  filter(!ST %in% c(""HI"", ""AK"")) %>%
  ggplot() +
  geom_sf(aes(fill = ratio), color = 'white', size = 0.01) +
  scale_fill_viridis_c(""Alignment Ratio"", option = ""cividis"", limits = c(0, 1), labels = scales::percent, na.value = ""white"") +
  coord_sf(crs = 26915) +
  labs(title = ""Is Diversity In School Districts Reflected In The Diversity Of The General Population?"",
       subtitle = glue(""Shown below is a choropleth map illustrating the ratio between the Diversity Index of a School Population and the Diversity Index of the General Population in that School District in 2017.<br>
       The more {highlight_text('yellow', '#FFEA46', 'b')} an area, the greater alignment between diversity indices.  The more {highlight_text('blue', '#00204D', 'b')} an area, the greater the difference between the diversity of the school and the general populace.<br> 
       This analysis focused on unified school districts and available data on race from the ACS Survey.  Diversity was calculated using Simpson's Diversity Index.""),
       caption = ""Data: **Washington Post via @dataKateR & American Community Survey** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
          markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week39"", ""tw39_plot.png""), width = 16, height = 10, device = ragg::agg_png())
","2019-39"
"107",107,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week4/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)



incar_data <- here(""2019"",""week4"",""data"") %>% 
  dir(full.names = TRUE, pattern = ""incarceration"") %>% 
  read_excel()

fix_null <- function(x) if_else(is.nan(x), NA_real_, x)

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") %>% 
  mutate_at(""id"", as.numeric)

ratio_data <- incar_data %>% 
  group_by(year, fips, state, county_name) %>% 
  transmute(black_pop_ratio = black_pop_15to64/total_pop_15to64,
         black_prison_ratio = black_prison_pop/total_prison_pop,
         asian_pop_ratio = asian_pop_15to64/total_pop_15to64,
         asian_prison_ratio = asian_prison_pop/total_prison_pop,
         latino_pop_ratio = latino_pop_15to64/total_pop_15to64,
         latino_prison_ratio = latino_prison_pop/total_prison_pop,
         native_pop_ratio = native_pop_15to64/total_pop_15to64,
         native_prison_ratio = native_prison_pop/total_prison_pop,
         white_pop_ratio = white_pop_15to64/total_pop_15to64,
         white_prison_ratio = white_prison_pop/total_prison_pop) %>% 
  group_by(fips, state, county_name) %>% 
  summarize_at(vars(contains(""ratio"")), mean, na.rm = TRUE) %>% 
  mutate_at(vars(contains(""ratio"")), fix_null)


map_data <- left_join(us_map, ratio_data, by = c(""id"" = ""fips""))  %>% 
  ungroup() %>% 
  gather(""variable"",""percentage"", contains(""ratio"")) %>% 
  separate(variable, c(""ethnicity"", ""category""), sep = ""_"")

plot <- ggplot() +
  geom_map(data = us_map, map = us_map,
           aes(x = long, y = lat, map_id = id),
           color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = map_data, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = percentage),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis_c("""", na.value = ""white"", option = 'cividis', labels = scales::percent) +
  coord_map() +
  labs(title = ""Differences between the General and Prison Population by County and Ethnic Group from 1970 to 2016"",
       subtitle = str_wrap(""Non-white and non-Asian ethnic groups in the South-Eastern United States have a higher average representation in prison than in the overall population.  Missing data indicated by no fill color."",  90),
       caption = ""Data: Vera Institute of Justice | Graphic: @jakekaupp"") +
  facet_grid(category ~ ethnicity , labeller = labeller(category = c(""pop"" = ""Total\nPopulation"", ""prison"" = ""Prison\nPopulation""),
                                                       ethnicity = str_to_title)) +
  theme_map(base_family = ""Scope One"", 
            base_size = 16) +
  theme(plot.caption = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        legend.position = ""bottom"",
        legend.justification = ""center"",
        legend.direction = ""horizontal"",
        legend.key.height = unit(0.2, ""cm""),
        legend.key.width = unit(1, ""cm""),
        strip.background = element_blank(),
        strip.text.y = element_text(angle = 0))

ggsave(here(""2019"",""week4"",""tw4_choro.png""), width = 11, height = 5)

","2019-4"
"108",108,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week40/R/analysis.R","library(tidyverse)
library(sf)
library(tigris)
library(glue)
library(colorspace)
library(jkmisc)
library(ggforce)
library(ragg)
library(here)

# Get TidyTuesday data
pizza_datafiniti <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_datafiniti.csv"") %>% 
  filter(province == ""NY"") %>% 
  distinct(name, latitude, longitude)

pizza_barstool <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_barstool.csv"") %>% 
  distinct(name, latitude, longitude) %>% 
  filter(!is.na(latitude))

# Get all New York County road maps
counties <- c(""New York County"", ""Kings County"", ""Bronx County"", ""Richmond County"",  ""Queens County"")

roads_data <- map(counties, ~roads(""NY"", .x, class = ""sf"")) %>% 
  do.call(sf:::rbind.sf, .)

# Build plot colors as a named vector and as a tibble
plotcolors <- c('Other' = '#cccccc',
                'Ave' = '#59c8e5',
                'St' = '#fed032',
                'Tunl' = '#fed032',
                'Brg' = '#fed032',
                'N' = '#fed032',
                'S' = '#fed032',
                'E' = '#fed032',
                'W' = '#fed032',
                'Rd' = '#4cb580',
                'Dr' = '#0a7abf', 
                'Hwy' = '#ff9223', 
                'Plz' = '#ff9223',
                'Viaduct' = '#ff9223', 
                'Expy' = '#ff9223', 
                'Pkwy' = '#ff9223',
                'Thruway' = '#ff9223',
                'State Hwy' = '#ff9223',
                'State' = '#ff9223',
                'US Hwy' = '#ff9223',
                'Blvd'= '#2e968c')

pc_tibble <- tibble(street_type = names(plotcolors),
                    color = plotcolors)

# Assign street types to roads
roads <- roads_data %>% 
  filter(!is.na(RTTYP)) %>% 
  mutate(street_type = map_chr(FULLNAME, ~first(names(plotcolors)[str_which(.x, glue(""{names(plotcolors)}\\b""))]))) %>% 
  mutate(street_type = if_else(str_detect(FULLNAME, ""I-""), 'I-', street_type)) %>% 
  mutate(street_type = case_when(is.na(street_type) & MTFCC == ""S1100"" ~ 'Expy',
                                 is.na(street_type) & MTFCC == ""S1200"" ~ 'St',
                                 is.na(street_type) & !MTFCC %in% c(""S1100"", ""S1200"") ~ ""Other"",
                                 TRUE ~ street_type)) %>% 
  left_join(pc_tibble, by = ""street_type"")

# Get Counties shapefiles to determine which pizza places are in the areas I want
counties_sf <- counties(""NY"", class = ""sf"") %>% 
  filter(NAMELSAD %in% counties)

# Use st_intersects and filter to remove out of bounds pizza places
pizza_sf_df <- st_as_sf(pizza_datafiniti, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
pizza_sf_bs <- st_as_sf(pizza_barstool, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
  
  
# Filter to pizza places in the five boroughs
ny_pizza_df <-  filter(pizza_sf_df, map_lgl(st_intersects(pizza_sf_df, counties_sf), ~!is_empty(.x)))

ny_pizza_bs <-  filter(pizza_sf_bs, map_lgl(st_intersects(pizza_sf_bs, counties_sf), ~!is_empty(.x)))

ny_pizza <- sf:::rbind.sf(ny_pizza_bs, ny_pizza_df) %>% 
  distinct(geometry)

# Construct the color legend
legend <- pc_tibble %>% 
  filter(street_type %in% c(""Other"",""Ave"",""St"", ""Rd"", ""Dr"", ""Hwy"", ""Blvd"")) %>% 
  mutate(street_type = factor(street_type, levels = c(""Other"", ""Ave"", ""Dr"", ""Rd"", ""Blvd"", ""St"", ""Hwy""), labels = c(""Other"", ""Avenue"", ""Drive"", ""Road"", ""Boulevard "", ""Street"", ""Highway""))) %>%
  arrange(street_type) %>% 
  mutate(x0 = seq(3, by = 4.5, length.out = 7),
         r = 1.75,
         y0 = 0) %>% 
  ggplot(aes(x0 = x0, y0 = y0, r = r)) +
  geom_circle(aes(fill = color, color = darken(color))) +
  geom_text(aes(label = street_type, x = x0, y = 0), family = ""Lora"", size = 3) +
  annotate(""text"", family = ""Oswald"", x = -2, y = 0, label = ""Legend"", size = 6) +
  scale_fill_identity() +
  scale_color_identity() +
  expand_limits(y = c(-0.5, 4),
                x = c(-4, 24)) +
  labs(x = NULL,
       y = NULL) +
  coord_equal(clip = ""off"") +
  theme_jk(grid = FALSE, plot_title_size = 30) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 

legend_grob <- ggplotGrob(legend)

subtitle <- ""Shown on this map are the roads and the pizza places of the Five Boroughs of New York City.  
Pizza places are distinct locations almagamated from the DataFiniti and Barstool datasets, and a represented by purple dots.  Manhattan is the most represented borough in the dataset, unsurprising given the relative population, and it being the home of the Teenage Mutant Ninja Turtles.
The map style of plotting the colored roads were inspired by Erin Davis (erdavis1 on github), and her series of circular maps of World Cities.""

caption <- ""Data: DataFiniti, Barstool, US Census Shapefiles\nGraphic: @jakekaupp""


# Plot the Street maps and Pizza place data
pizza_map <- ggplot() +
  geom_sf(data = filter(roads, street_type != ""Other""), aes(color = color), size = 0.25) + 
  geom_sf(data = filter(roads, street_type == ""Other""), aes(color = color), size = 0.35) + 
  geom_sf(data = ny_pizza, color = darken(""#963484""), fill = ""#963484"", shape = 21, size = 2, alpha = 0.5) +
  annotate(""text"", label = ""Pizza Places of the Five Boroughs"", family = ""Oswald"", x = -74.3, y = 40.91, size = 6, hjust = 0) +
  annotate(""text"", family = ""Lato"", label = str_wrap(subtitle, 60), x = -74.3, y = 40.89, hjust = 0, vjust = 1) +
  annotate(""text"", family = ""Lato"", label = caption, x = -74.3, y = 40.78, hjust = 0, vjust = 1) +
  annotation_custom(legend_grob, xmin = -74.2, xmax = Inf, ymin = 40.49, ymax = 40.55) +
  scale_color_identity() +
  scale_size_identity() +
  coord_sf(clip = ""off"") +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 


ggsave(here('2019', 'week40', 'tw40_plot.png'), width = 12, height = 9, dev = agg_png())","2019-40"
"109",109,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week41/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(janitor)
library(jkmisc)
library(ggforce)
library(ggtext)
library(nord)
library(glue)
library(ragg)

# It's 250mb, can't put it into git, you're going to have to go get it
# from https://openpowerlifting.org/data and stick it in data.
pl_data <- here(""2019"", ""week41"", ""data"") %>% 
  dir(pattern = ""openpowerlifting"", full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

plot_data <- pl_data %>%
  filter_at(vars(starts_with(""best"")), all_vars(. > 0)) %>% 
  filter(str_detect(place, ""1"")) %>% 
  mutate(year = year(date)) %>%
  select(-date) %>%
  mutate_at(vars(starts_with(""best"")), ~./bodyweight_kg) %>% 
  pivot_longer(starts_with(""best""), names_to = ""lift"") %>% 
  group_by(year, sex, lift) %>%
  filter(value == max(value, na.rm = TRUE)) %>% 
  arrange(lift, sex, year)

labels <- tibble(label = c(""Bench Press"", ""Deadlift"", ""Squat""),
                 lift = c(""best3bench_kg"", ""best3deadlift_kg"", ""best3squat_kg""),
                 year = 2020,
                 value = 1)

annotations <- plot_data %>% 
  group_by(sex, lift) %>% 
  filter(value == max(value, na.rm = TRUE)) %>% 
  mutate(description = glue(""Weight: {bodyweight_kg} kg\nLifted: {bodyweight_kg*value} kg\n{federation}: {meet_name}""),
         name = str_remove(name, ""\\#[0-9]""))

plot <- ggplot(plot_data, aes(x = year, y = value)) +
  geom_path(aes(color = sex)) +
  geom_point(aes(fill = sex), shape = 21, color = ""#2E3440"") +
  geom_text(data = labels, aes(label = label), color = ""#E5E9F0"", family = ""Oswald"", fontface = ""bold"", size = 10, hjust = 1) +
  geom_mark_circle(data = filter(annotations, sex == ""M""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  geom_mark_circle(data = filter(annotations, sex == ""F""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  facet_wrap(~lift) +
  scale_color_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_fill_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_x_continuous(breaks = seq(1970, 2020, 10)) +
  theme_jk(dark = TRUE, 
           grid = ""XY"",
           markdown = TRUE) +
  labs(x = NULL,
       y = NULL,
       title = ""Evolution of Power: How the Ratio of Bodyweight to Lifted Weight Has Progressed"",
       subtitle = glue(""Illustrated below is the maximum of the ratio of bodyweight to lifted weight for winning lifts in each year and event for both {highlight_text('Men', '#314cb6', 'b')} and {highlight_text('Women', '#DD2A7B', 'b')} for all meets recorded by Open Powerlifting.""),
       caption = ""Data: **openpowerlifting.org** | Graphic: **@jakekaupp**"") +
  theme(legend.position = ""none"",
        panel.grid.major = element_line(size = 0.01),
        strip.text = element_blank())

ggsave(here('2019', 'week41', 'tw41_plot.png'), plot, width = 15, height = 8, device = agg_png())","2019-41"
"110",110,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week42/R/analysis.R","library(tidyverse)
library(here)
library(janitor)
library(jkmisc)
library(ggalt)
library(ggtext)
library(glue)
library(ragg)

big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")

top <- big_epa_cars %>% 
  clean_names() %>% 
  count(make, year) %>% 
  count(make) %>% 
  filter(n == 37)

plot_data <- big_epa_cars %>% 
  clean_names() %>% 
  select(make, v_class, year, you_save_spend) %>% 
  semi_join(top) %>% 
  group_by(year, make) %>% 
  summarize(total_save_spend = mean(you_save_spend)) %>%
  group_by(year) %>% 
  mutate(rank = min_rank(desc(total_save_spend))) %>% 
  ungroup() %>% 
  mutate(size = if_else(make == ""Ford"", 1, 0.5),
         make = factor(make, pull(top, make)),
         make = fct_relevel(make, ""Ford"", after = Inf),
         make = fct_recode(make, ""**Ford**"" = ""Ford""))


grid <- tibble(rank = 1:22)

colors <- set_names(grey.colors(22), pull(top, make) %>%
                      factor() %>%
                      fct_recode(""**Ford**"" = ""Ford""))

colors[[""**Ford**""]] <- ""#DD2A7B""


plot <- ggplot(plot_data, aes(x = year, y = rank)) +
  geom_segment(data = grid, aes(x = 1983, xend = 2021, y = rank, yend = rank), color = ""#cccccc"", alpha = 0.5, size = 0.1) +
  geom_xspline(aes(color = make, size = size), show.legend = FALSE) +
  geom_point(aes(fill = make), shape = 21, color = ""white"", show.legend = FALSE) +
  geom_richtext(data = filter(plot_data, year == 2020), aes(label = as.character(make), x = 2021, color = make), hjust = 0, family = ""Lora"", size = 4, show.legend = FALSE,  fill = NA, label.color = NA, 
                label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_text(data = filter(plot_data, year == 1984), aes(label = rank, x = 1983), hjust = 1, family = ""Oswald"", size = 4) +
  labs(x = NULL,
       y = NULL,
       title = ""From Chugging to Sipping: Fuel Cost Savings of Major Automakers since 1984"",
       subtitle = glue(""Shown below is a rankings chart of average fuel cost savings, measured over 5 years, from 1984 to 2020.  {highlight_text('Ford','#DD2A7B', 'b')} has had quite the journey, battling from the bottom<br>of the list to the second-best North American manufacturer."")) +
  scale_color_manual(values = colors) +
  scale_fill_manual(values = colors) +
  scale_size_identity() +
  scale_x_continuous(breaks = 1984:2020) +
  scale_y_continuous(trans = ""reverse"", breaks = NULL) +
  expand_limits(x = 2025) +
  theme_jk(grid = ""X"", 
           markdown = TRUE)

ggsave(here(""2019"", ""week42"", ""tw42_plot.png""), plot = plot, width = 13, height = 6)
","2019-42"
"111",111,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week43/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggraph)
library(tidygraph)
library(glue)
library(jkmisc)
library(colorspace)
library(ggforce)
library(ggtext)

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

movie_cast <- distinct(horror_movies, title, release_date, review_rating, .keep_all = TRUE) %>% 
  mutate(year = str_extract(title, ""\\((\\d{4})\\)""),
         year = parse_number(year),
         title = str_remove(title, ""(\\s\\(\\d{4}\\))""),
         date = dmy(release_date)) %>% 
  arrange(title) %>% 
  separate_rows(cast, sep = ""\\|"") %>% 
  mutate(cast = trimws(cast)) %>% 
  select(title, year, review_rating, cast)

cast_df <- left_join(movie_cast, movie_cast, by = c(""title"", ""year"", ""review_rating"")) %>% 
  rename(from = cast.x,
         to = cast.y) %>% 
  filter(from != to) 

nodes <- cast_df %>% 
  group_by(from) %>% 
  summarize(node_size = n_distinct(title)) %>% 
  distinct(from, .keep_all = TRUE) 

focus <- ""Eric Roberts""

edges <- cast_df %>% 
  count(from, to, sort = TRUE, name = ""edge_size"") %>% 
  distinct(from, to, .keep_all = TRUE) %>% 
  mutate(color = if_else(from == focus | to == focus, ""#bb0a1e"", ""#373e40""),
         alpha = if_else(from == focus | to == focus, 1, 0.2),
         size = if_else(from == focus | to == focus, 1, 0.1))

connected <- filter(edges, from == focus) %>% 
  distinct() %>% 
  pull(to) 

cast_network <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE) %>% 
  activate(nodes) %>% 
  mutate(degree = centrality_eigen(),
         alpha = if_else(from %in% c(focus, connected),  1, 0.2)) %>% 
  top_n(500, degree) %>% 
  mutate(fill = if_else(from %in% c(focus, connected), ""#bb0a1e"", ""#373e40""),
         color = if_else(from %in% c(focus, connected), darken(""#bb0a1e""), darken(""#373e40"")))

plot <- ggraph(cast_network, layout = ""graphopt"") + 
  geom_edge_link(aes(alpha = stat(index), edge_colour = color, edge_width = size), show.legend = FALSE) + 
  geom_node_point(aes(size = node_size, fill = fill, color = color), shape = 21, show.legend = FALSE) +
  #geom_mark_circle(aes(x, y, filter = from == focus, label = from, description = ""Legendary B-Movie Actor""), expand = unit(0, ""mm""), label.family = c(""Oswald"", ""Lora"")) +
  scale_edge_color_identity() +
  scale_alpha_identity() +
  scale_fill_identity() +
  scale_edge_width_identity() +
  scale_color_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Horror Movie Co-Star Networks of the Top 500 Prolific Performers"",
       subtitle = glue(""The reach of B-movie legend {highlight_text('Eric Roberts', '#bb0a1e', 'b')} is featured below across his 27 films. Prolific performers determined by the top 500<br>actors by eigenvalue centrality.""),
       caption = ""Data: **IMDB** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
           markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week43"", ""tw43_plot.png""), plot, width = 10, height = 6, device = ragg::agg_png())

  
","2019-43"
"112",112,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week44/R/analysis.R","library(tidyverse)
library(waffle)
library(lubridate)
library(jkmisc)
library(scales)
library(colorspace)
library(patchwork)
library(ggtext)
library(glue)
library(here)

#Get the data ----
nyc_squirrels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

# Process the data ----
activity_data <- nyc_squirrels %>% 
  mutate(date = mdy(date)) %>% 
  pivot_longer(names_to = ""activity"", running:foraging) %>%
  group_by(date, activity) %>% 
  summarize(value = sum(as.numeric(value))) %>% 
  mutate(activity = factor(activity, labels = unique(activity)),
         activity = fct_reorder(activity, value, .fun = sum)) %>% 
  arrange(date, desc(activity))

# Make my palette

slate_ramp <- colorRampPalette(c(""#3B454A"", lighten(""#3B454A"", 0.8)))(5) 

grey_ramp <- grey.colors(5, 0.5, 0.9)

pal <- set_names(slate_ramp, unique(activity_data$activity))

pal[""foraging""] <- ""#DD2A7B""

partition_waffle <- function(x, start, nrows, flip = FALSE) {
  
   offset <- start - x
  
   offset_rows <- offset %/% nrows
   
   offset_blocks <- offset %% nrows
   
  
   comp_blocks <- nrows - offset_blocks
   
   if (comp_blocks != nrows) {
     
     rows <- (x - comp_blocks) %/% nrows
     
     blocks <- (x - comp_blocks) %% nrows
     
     start_row <- offset_rows + rows + 1
     
     if (blocks == 0) {
       
       end_row <- start_row
       
     } else {
       
       end_row <- start_row + 1 
       
     }
     
   } else {
     
     rows <- x %/% nrows
     
     blocks <- x %% nrows
     
     start_row <- rows + offset_rows
     
     end_row <- rows + offset_rows + 1
     
   }
   
   
   if (flip) {
     
     tibble(y = c(start_row, start_row, end_row),
            yend = c(start_row, end_row, end_row),
            x = c(blocks, blocks, 0),
            xend = c(nrows, blocks, blocks))
     
     
   } else {
     
     tibble(x = c(start_row, start_row, end_row),
            xend = c(start_row, end_row, end_row),
            y = c(blocks, blocks, 0 -1),
            yend = c(nrows + 1, blocks, blocks))
   }
     
     

   
  
} 

# Waffles by activity ----

activity_outlines <- activity_data %>% 
  ungroup() %>% 
  arrange(desc(activity), date) %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, flip = FALSE, nrows = 20)) %>% 
  unnest(lines) %>% 
  filter(date == last(date))

activity_labels <- activity_data %>% 
  group_by(activity) %>% 
  summarize(total = sum(value)) %>%
  left_join(filter(activity_outlines, yend == 21), by = ""activity"")

waffle_by_activity <- activity_data %>% 
  arrange(desc(activity), date) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = activity_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""black"", size = 0.5) +
  geom_richtext(data = activity_labels, aes(label = glue(""<b>{str_to_title(activity)}</b>""), x = x, y = yend, color = activity), fill = ""white"", hjust = 1, vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = activity_labels, aes(label = glue(""{total}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_color_manual(values = pal) +
  coord_equal() +
  labs(x = NULL, 
       y = NULL) +
  theme_jk(grid = FALSE) +
  scale_x_continuous(expand = c(0,0)) +
  expand_limits(y = c(-5, 25), x = c(0, 200)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffles by day ----

by_day_outlines <- activity_data %>% 
  ungroup() %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE)) %>% 
  unnest(lines) %>% 
  filter(activity == ""chasing"")

by_day_labels <- activity_data %>% 
  group_by(date) %>% 
  summarize(total = sum(value)) %>% 
  left_join(filter(by_day_outlines, yend == 21))

waffle_by_day <- activity_data %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = by_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{month.abb[month(date)]} {day(date)}""), x = x, y = yend), fill = ""white"", color = ""black"", hjust = c(rep(1,10), 0), vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{total}""), x = x, y = -1), fill = ""white"", color = ""black"", hjust = c(rep(0,9),1,0), vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_x_continuous(expand = c(0,0)) +
  coord_equal(clip = ""off"") +
  labs(x = NULL, 
       y = NULL) +
  expand_limits(y = c(-5, 25), x = c(0, 205)) +
  theme_jk(grid = FALSE) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffle bars by day ----

waffle_day_outlines  <- activity_data %>% 
  arrange(desc(date)) %>% 
  filter(activity == ""foraging"") %>% 
  ungroup() %>%
  group_split(date) %>% 
  map(~mutate(.x, cum_sum = cumsum(value))) %>%
  map_dfr(~mutate(.x, lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE))) %>%
  unnest(lines) 

waffle_labels <- waffle_day_outlines %>% 
  filter(y == -1)

mday_label <- function(x) {
  
  glue(""{month.abb[month(x)]} {day(x)}"")
  
}

split_waffle_by_day <- activity_data %>% 
  arrange(desc(date)) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = waffle_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = waffle_labels, aes(label = glue(""{value}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  coord_equal() +
  scale_color_manual(values = pal) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  facet_wrap(~date, nrow = 1, as.table = FALSE, strip.position = ""top"", labeller = labeller(date = mday_label)) +
  expand_limits(y = c(-5, 20)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

out <- wrap_plots(waffle_by_activity, waffle_by_day, split_waffle_by_day, ncol = 1) +
  plot_annotation(title = ""Breakdown of Observed Squirrel Activity from the 2018 NYC Squirrel Census"",
                  subtitle = glue(""Below are  waffle charts of activity totals (I), daily totals (II) and exploded daily activity (III) views of observed squirrel activity.<br>{highlight_text('Foraging', '#DD2A7B', 'b')} is the most frequently observed activity recorded in the census, not surprising for squirrels in the fall.""),
                  caption = ""Data: **NYC Data Portal** | Graphic: **@jakekaupp**"",
                  tag_levels = ""I"",
                  theme = theme_jk(markdown = TRUE))

ggsave(here(""2019"", ""week44"", ""tw44_plot.png""), out, width = 11, height = 8, dev = ragg::agg_png(), dpi = ""print"")

","2019-44"
"113",113,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week45/R/analysis.R","library(tidyverse)
library(jkmisc)
library(glue)

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

total_avg <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  mutate(state = ""US"",
         state_abb = ""US"")

slope_data <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(state, state_abb, mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  ungroup() %>% 
  mutate(state_abb = ifelse(is.na(state_abb), ""DC"", state_abb))

direct_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(-3:-6)

direct_labels_bike <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  top_n(5, avg)

mid_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(3:6) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
    avg = mean(.$avg),
    y = min(.$avg),
    yend = max(.$avg))
  
lower_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  arrange(-avg) %>% 
  slice(9:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))

lower_bike_labels <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  arrange(-avg) %>% 
  slice(6:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))


ggplot(slope_data, aes(x = mode, y = avg)) +
  geom_line(aes(group = state), size = 0.2) +
  geom_line(data = total_avg, aes(group = state), color = ""#DD2A7B"", size = 1) +
  geom_point(shape = 21, color = ""white"", stroke = 0.2, fill = ""black"", size = 2) +
  geom_text(data = direct_labels, aes(label = state_abb),  nudge_x = 0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = direct_labels_bike, aes(label = state_abb),  nudge_x = -0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = mid_labels, aes(label = state_abb),  nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_bike_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = -0.5, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.95, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.91, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL,
       title = ""Bicycling and Walking to Work in the United States: 2008-2012"",
       subtitle = glue(""Illustrated below is a slopegraph contrasting the percentage of population that bikes to work and the percentage<br>that bikes to work as well as {highlight_text('the US average', '#DD2A7B', 'b')}"")) +
  scale_x_discrete(labels = c(""Bike to Work"", ""Walk to Work"")) +
  theme_jk(grid = ""XY"",
           markdown = TRUE) +
  theme(panel.grid.major = element_line(linetype = ""dashed""))
  
","2019-45"
"114",114,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week5/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(here)
library(scales)

milk_cow_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milkcow_facts.csv"")

milk_product_facts <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milk_products_facts.csv"")

us_pop <- read_csv(here(""2019"", ""week5"", ""data"",""us-population-1990-to-2016.csv""))

totals <- milk_product_facts %>% 
  mutate(total_consumption = rowSums(select(., -year))) %>% 
  select(year, total_consumption)

full_data <- left_join(milk_cow_data, totals) %>% 
  left_join(us_pop) %>% 
  mutate(total_consumption_lbs = total_consumption * population)


ggplot(full_data, aes(y = total_consumption_lbs, x = milk_production_lbs)) +
  geom_xspline2(aes(s_open = TRUE, s_shape = 0.5)) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 1) +
  scale_y_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  scale_x_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  labs(x = ""US Milk Production (lbs)"",
       y = ""US Average Dairy Consumption (lbs)"",
       title = ""100 Slices of American Cheese or, the Fable of Supply Management"",
       subtitle = str_wrap(""The connected scatterplot below illustrates the relationship between total average dairy consumption and total milk production over the past 25 years.
                           US supply far exceeds the demand, highlighting overproduction and a case for supply management."", 120)) +  
  theme_jk()
","2019-5"
"115",115,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week6/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(lubridate)
library(here)
library(scales)
library(janitor)
library(ggrepel)
library(patchwork)

state_hpi <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")

prime_rates <- read_csv(here(""2019"",""week6"",""data"",""MPRIME.csv"")) %>% 
  clean_names() %>% 
  mutate(year = year(date)) %>% 
  select(-date) %>% 
  group_by(year) %>% 
  summarize_all(mean) %>% 
  filter(year %in% min(state_hpi$year):max(state_hpi$year))

highs <- filter(prime_rates, mprime %in% range(mprime)) %>% 
  distinct(mprime, .keep_all = TRUE)

plot_data <- state_hpi %>% 
  group_by(year, state) %>% 
  summarize_all(mean, na.rm = TRUE) 

prime <- ggplot(prime_rates, aes(x = year, y = mprime)) +
  geom_line(color = viridis_pal()(1), size = 0.5) +
  geom_point(data = highs, color = viridis_pal()(1)) +
  geom_text_repel(data = highs, aes(label = paste0(mprime, ""%"")), color = viridis_pal()(1), nudge_x = 2, nudge_y = 2, family = ""Oswald"", segment.size = 0) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  theme_jk(grid = ""XY"") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Interest Rates Fall, Housing Prices on the Rise"",
       subtitle = str_wrap(""The top chart shows the average prime interest rate by year since 1975.  The bottom heatmap illustrates the yearly average housing price index by State since 1975."", 100))


heatmap <- ggplot(plot_data, aes(x = year, y = fct_reorder(state, price_index, .fun = mean), fill = price_index)) +
  geom_tile(color = ""white"", size = 0.05) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  scale_fill_viridis_c(""House Price Index"", option = ""viridis"", direction = 1, breaks = pretty_breaks(5)) +
  scale_color_identity() +
  labs(x = NULL, y = NULL, caption = ""Data: FRED | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"",
        legend.key.width = unit(1, ""cm""))


out <- patchwork::wrap_plots(prime, heatmap, heights = c(0.2,1), ncol = 1)

ggsave(here(""2019"", ""week6"", ""tw6_plot.png""), out, width = 8, height = 10)
","2019-6"
"116",116,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week7/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(janitor)
library(jkmisc)
library(nord)

oecd_data <- here(""2019"", ""week7"", ""data"", ""OECD--1.xlsx"") %>% 
  read_excel(skip = 1, na = c(""na"")) %>% 
  clean_names() %>% 
  filter(!is.na(x1995)) %>% 
  rename(country = x1) %>% 
  gather(year, intensity, -country) %>% 
  arrange(country, year) %>% 
  fill(intensity, .direction =  ""down"") %>% 
  mutate(year = parse_number(year)) %>% 
  group_by(year) %>% 
  arrange(year, intensity) %>% 
  mutate(rank = row_number(-intensity)) %>% 
  ungroup() %>% 
  mutate(color = if_else(country == ""Canada"", nord(""victory_bonds"")[2], nord(""snowstorm"", 1)),
         text_color = if_else(country == ""Canada"", nord(""snowstorm"", 1), ""black""))




plot <- ggplot(oecd_data, aes(x = year, y = -rank, group = country)) +
  geom_line(aes(color = color)) +
  geom_point(aes(color = color)) +
  geom_text(data = filter(oecd_data, year == min(year)), aes(label = rank, color = color), x = 1994, hjust = 0, family = ""Oswald"") +
  geom_text(data = filter(oecd_data, year == max(year)), aes(label = country, color = color), x = 2016.5, hjust = 0, family = ""Oswald"") +
  expand_limits(x = c(1994, 2019)) +
  scale_x_continuous(breaks = 1995:2016) +
  scale_color_identity() +
  theme_jk(dark = TRUE, grid = FALSE) +
  theme(axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Canada is Losing a Step In the Global Research Race."",
       subtitle = str_wrap(""Shown below is the ranking of research intensity (% of Gross Domestic Product devoted to Research) from 1995-2016. Canada has been on a decline since hitting a peak in 2001.  Most notably is 2009-2016, which coincides with the systematic defunding of Canadian research scientists by the Conservative Harper Government."", 120),
       caption = ""Data: OECD | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week7"", ""tw7_plot.png""), plot, width = 9, height = 4.5)
","2019-7"
"117",117,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week8/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(readxl)
library(janitor)
library(jkmisc)
library(scales)
library(egg)

parse_table31 <- function(file) {
  
  df <- file %>% 
    read_excel(na = ""na"") %>% 
    clean_names()
  
  start <- min(str_which(df$x3,""\\d{4}""))
  
  end <- pull(df, 1) %>% 
    str_which(""Since"") %>% 
    max()
  
  df <- slice(df, start:end)
  
  field_idx <- select(df, -1) %>% 
    map_df(is.na) %>% 
    pmap_lgl(all)
  
  labels <- select(df, 1) %>%
    filter(field_idx) %>% 
    na.omit() %>% 
    pull() %>% 
    str_remove(""[abcd]$"")
  
  years <- slice(df, 1) %>% 
    select(-1) %>% 
    flatten_chr() %>% 
    str_remove(""\\.0+$"")
  
 rep <- filter(df, !field_idx) %>% 
    slice(-1) %>% 
    select(1) %>% 
    n_distinct()
  
  filter(df, !field_idx) %>% 
    slice(-1) %>% 
    mutate(discipline = rep(labels, each = rep)) %>% 
    set_names(c(""category"", years, ""discipline"")) %>% 
    gather(year, value, matches(""[0-9]{4}"")) %>% 
    mutate_at(vars(-category, -discipline), as.numeric) %>% 
    mutate_at(""category"", function(x) str_remove(x, ""[abcd]$""))
  
  
}


files <- here(""2019"",""week8"",""data"") %>% 
  dir_ls() 

data <- map_df(files, parse_table31) %>% 
  ungroup() %>% 
  distinct()

plot_data <- data %>% 
  filter(discipline != ""Other"", !str_detect(category, ""doctoral"")) %>% 
  filter(!str_detect(discipline, ""and (?!computer)"")) %>% 
  filter(!str_detect(discipline, ""Physical"")) %>% 
  arrange(year) %>% 
  group_by(category, discipline, year) %>% 
  summarize(value = mean(value, na.rm = TRUE)) %>% 
  ungroup()

plot <- ggplot(plot_data, aes(x = year, y = value, color = discipline)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(breaks = pretty_breaks(), limits = c(0, 25)) +
  scale_color_manual(""Discipline"", values = tol7qualitative) +
  scale_x_continuous(limits = c(1985, 2017)) +
  expand_limits(x = c(1985, 2025)) +
  facet_wrap(~category, labeller = as_labeller(str_to_title), nrow = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""Median Completion Time for Doctoral Degrees Are Getting Shorter"",
       subtitle = str_wrap(""Median completion time in years from 1985 to 2017 contrasting selected disciplines for both University and Graduate School experience.  Education, Humanities and Social Sciences doctoral candidates have a higher than average time to completion in both categories compared to other disciplines. "", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

ggsave(here('2019','week8',""tw8_plot.png""), plot, width = 10, height = 7)


bonus_plot_data <- plot_data %>% 
  filter(discipline == ""All fields"") %>% 
  rename(overall = value) %>% 
  select(-discipline) %>% 
  left_join(filter(plot_data, discipline != ""All fields"")) %>% 
  mutate(diff = abs(value - overall)/2) %>%
  filter(between(year, 1990, 2011))


order <- c(""Education"", ""Mathematics and computer sciences"",  ""Engineering"", ""Humanities"",""Life sciences"", 
   ""Social sciences"")

bonus_plot <- ggplot(bonus_plot_data, aes(ymin = -diff, ymax = diff, x = year, fill = fct_relevel(discipline, order))) +
  geom_ribbon(color = ""white"", size = 0.2, alpha = 0.8) +
  geom_segment(data = filter(bonus_plot_data, year == 2000, category == ""Since bachelor's"", discipline == ""Education""), aes(y = -diff, yend = diff, x = year, xend = year), color = ""grey20"", arrow = arrow(length = unit(0.25, ""cm""), ends = ""both"", type = ""closed"")) +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  scale_fill_viridis_d(""Discipline"") +
  scale_y_continuous(breaks = c(-5, -2.5, -1, 0, 1, 2.5, 5), labels = c(""10 Years"", ""5 Years"", ""2 Years"", ""Group Median"", ""2 Years"", ""5 Years"", ""10 Years"")) +
  labs(x = NULL,
       y = NULL,
       title = ""Relative Differences in Median Doctoral Completion Time from the Group Median by Discipline and Interval"",
       subtitle = str_wrap(""The streamgraph below presents the difference between discipline median completion time and the group median completion time (All Fields) as the width of each colored band (discipline) from 1990 to 2011."", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

bonus_plot <- tag_facet(bonus_plot, x = 1996, y = 5.5, open = """", close = """", tag_pool = c(""Difference from Group Median = 9.1 years"", """"),  fontface = 1, family = ""Oswald"") 



ggsave(here('2019','week8',""tw8_bonus_plot.png""), bonus_plot, width = 12, height = 6)
","2019-8"
"118",118,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week9/R/analysis.R","library(tidyverse)
library(here)
library(ggforce)
library(jkmisc)
library(sf)
library(osmdata)

full_trains <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

available_tags(""railway"")

railways <- st_read(here(""2019"", ""week9"", ""data"", ""railways.shp""))

q <- getbb(""fr"") %>%
  opq(timeout=25*1000)%>%
  add_osm_feature(""railway"")

stations <- osmdata_sf(q)

ggplot(stations$osm_lines) +
  geom_sf()

railways$geometry[[1]] %>% st_coordinates() %>% as_tibble -> line

ggplot(line, aes(x = X, y = Y)) +
  geom_link2() +
  coord_sf(datum=NA)

nat_trains <- full_trains %>% 
  filter(service == ""National"") %>% 
  group_by(year, departure_station, arrival_station) %>% 
  summarize_at(vars(journey_time_avg, total_num_trips, avg_delay_late_at_departure, avg_delay_late_on_arrival), mean, na.rm = TRUE)


# Orbit test

centre <- ""PARIS LYON""

test_data <- filter(nat_trains, departure_station == centre | arrival_station == centre) %>% 
  arrange(departure_station)



positions <- test_data %>% 
  filter(arrival_station == centre) %>% 
  group_by(arrival_station, departure_station) %>% 
  summarize(dist = mean(journey_time_avg)) 


circles <- test_data %>% 
  group_by(departure_station) %>% 
  summarize(centre_radius = mean(avg_delay_late_at_departure)) %>% 
  left_join(positions)

main <- circles %>% 
  filter(departure_station == centre)

circles <- circles %>% 
  filter(departure_station != centre) %>% 
  mutate(fraction = nrow(.) - (nrow(.) - seq_along(departure_station)),
         delta = 360/nrow(.)*fraction) %>% 
  bind_rows(main) %>% 
  mutate(x0 = if_else(departure_station == centre, 0, dist*cos((delta*pi/180))),
         y0 = if_else(departure_station == centre, 0, dist*sin((delta*pi/180)))) 


link_coords <- function(dept, arr, lnk) {
  
  circles %>% 
    filter(departure_station == dept | departure_station == arr) %>%
    summarise(x = ifelse(lnk == ""from"", x0[x0 != 0], 0),
           xend = ifelse(lnk == ""from"", 0, x0[x0 != 0]),
           y = ifelse(lnk == ""from"", y0[y0 != 0], 0),
           yend = ifelse(lnk == ""from"", 0, y0[y0 != 0]))
  
  
  
}

links <- test_data %>% 
  group_by(departure_station, arrival_station) %>% 
  mutate(total_delay = ((avg_delay_late_at_departure + avg_delay_late_on_arrival)/journey_time_avg),
         total_trips = sum(total_num_trips)) %>% 
  summarize(size = mean(total_delay),
            alpha = mean(total_num_trips)/max(total_num_trips)) %>% 
  mutate(link = if_else(departure_station == centre, ""to"", ""from"")) %>% 
  ungroup() %>% 
  mutate(links = pmap(list(departure_station, arrival_station, link), ~link_coords(..1, ..2, ..3))) %>% 
  unnest() %>% 
  arrange(link, departure_station)




ggplot() +
  geom_curve(data = links, aes(x = x, xend = xend, y = y, yend = yend, size = size, color = link, alpha = alpha), lineend = ""round"", angle = 270) +
  geom_circle(data = circles, aes(x0 = x0, y0 = y0, group = departure_station, r = 5), fill = ""white"", color = ""#2b41a7"") +
  scale_size(range = c(1,6)) +
  scale_color_manual(values = c(""#2b41a7"", ""#c7ad24"")) +
  scale_fill_distiller(palette = ""Greys"")+
  scale_alpha_identity() +
  labs(x = NULL, y = NULL) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank())

","2019-9"
"119",969,"https://github.com/deepshamenghani/tidytuesday/tree/master/tt_07_29_2019_week31_videogames","deepshamenghani","tidytuesday","tt_07_29_2019_week31_videogames/video_games.R","library(tidyverse)
library(lubridate)
library(plotly)
library(ggrepel)
library(cowplot)
library(ggforce)

vg_df <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

# Clean dates
vg_edited <- vg_df %>% 
    mutate(release_date = as.Date(release_date, format = '%b %d, %Y')) %>%
    mutate(release_year  = as_factor(year(release_date))) %>% 
    drop_na(release_year) %>% 
    mutate(label_text = str_glue(""Game: {game}
                                 Year: {release_year}
                                 Price: {price}""))

# Create text for annotations by playtime
annotations_playtime <- vg_edited %>% 
    arrange(desc(median_playtime)) %>% 
    filter(row_number() < 5) %>% 
    mutate(log_price = log(price)) %>% 
    mutate(game_label = str_glue(""{game}\n{release_year}\n{scales::dollar(price)}"")) %>% # Create label text for plot
    select(game_label, median_playtime, log_price) %>% 
    mutate(y = c(median_playtime[1] + 400, median_playtime[2] - 200, median_playtime[3] + 150, median_playtime[4] - 400),  # Define annotations location
           x = c(log_price[1], log_price[2] + 0.85, log_price[3] - 0.85, log_price[4])) %>% 
    mutate(y_arrow = c(median_playtime[1] + 200, median_playtime[2] + 50, median_playtime[3] - 50, median_playtime[4] - 200)) # Define arrow location

# Create text for annotations by price
annotations_price <- vg_edited %>% 
    arrange(desc((price))) %>% 
    filter(row_number() < 3) %>% 
    mutate(log_price = log(price)) %>% 
    mutate(game_label = str_glue(""{game}\n{release_year}\n{scales::dollar(price)}"")) %>%
    select(game_label, median_playtime, log_price) %>% 
    mutate(y = c(median_playtime[1] + 550, median_playtime[2] + 450), # Define annotations location
           x = c(log_price[1] - 0.2, log_price[2] - 0.75)) %>% 
    mutate(y_arrow = c(median_playtime[1] + 300, median_playtime[2] + 200))  # Define arrow location
    

# Plot with annotations and arrows
pc_games_plot <- ggplot(data = vg_edited, 
                        aes(x = log(price), 
                            y = median_playtime)) +
    geom_point(aes(color = median_playtime, 
                   size  = median_playtime), 
                   alpha = 0.8) +
    scale_color_gradient(low  = ""blue2"", 
                         high = ""darkgreen"") +
    annotate(""text"", 
             x        = annotations_playtime$x, 
             y        = annotations_playtime$y, 
             fontface = ""bold"", 
             label    = annotations_playtime$game_label, 
             size     = 5, 
             color    = ""darkgreen"") + 
    geom_curve(data      = annotations_playtime, 
               aes(x     = log_price, 
                   y     = median_playtime, 
                   xend  = x, 
                   yend  = y_arrow),
               arrow     = arrow(length = unit(0.07, ""inch"")), 
               size      = 1,
               color     = ""gray20"", 
               curvature = -0.25)+
    annotate(""text"", 
             x        = annotations_price$x, 
             y        = annotations_price$y, 
             fontface = ""bold"", 
             label    = annotations_price$game_label, 
             size     = 5, color = ""blue2"") + 
    geom_curve(data      = annotations_price, 
               aes(x     = log_price, 
                   y     = median_playtime, 
                   xend  = x, 
                   yend  = y_arrow),
               arrow     = arrow(length = unit(0.07, ""inch"")), 
               size      = 1,
               color     = ""gray20"", 
               curvature = -0.25) + 
    geom_mark_circle(data       = annotations_price, 
                     aes(x      =log_price[1] ,
                         y      =median_playtime[1]), 
                     color      ='blue2', 
                     label.fill = NA, 
                     expand     = unit(3, ""mm"")) + 
    geom_mark_circle(data       = annotations_price, 
                     aes(x      =log_price[2] ,
                         y      =median_playtime[2]), 
                     color      ='blue2', 
                     label.fill = NA, 
                     expand     = unit(3, ""mm"")) +
    labs(
        x     = ""price (logarithmic scale)"",
        y     = ""Median playtime"",
        title = ""Playtime vs Price""
    ) +
    theme_minimal() +
    scale_y_continuous(breaks = seq(from = 0, to = 4000, by = 500))  +
    scale_x_continuous(breaks = seq(from = -1, to = 7, by = 1)) +
    theme(
        axis.title.x     = element_text(size = 20),
        axis.title.y     = element_text(size = 20, vjust = 1.5),
        axis.text.x      = element_text(size = 15),
        axis.text.y      = element_text(size = 15),
        plot.title       = element_text(size = 25),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()
    ) 

ggsave(""PC_Games.png"", plot = pc_games_plot, width = 60, height =25, units = ""cm"")
","2019-31"
"120",1080,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week21/plastic_waste.R","AmandaRP","tidytuesday","2019/week21/plastic_waste.R","library(tidyverse)
library(janitor)
library(inspectdf)
library(cowplot)
library(ggrepel)


#Read data and clean with janitor:
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>% clean_names()
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")  %>% clean_names()
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")  %>% clean_names()

#Put data together in one df:
waste <- left_join(waste_vs_gdp, coast_vs_waste, by = c(""entity"", ""code"", ""year""))
(waste <- left_join(waste, mismanaged_vs_gdp, by = c(""entity"", ""code"", ""year"")))

View(waste)

#Clean names a bit more
(waste <- waste %>%
  select(-total_population_gapminder.y, -total_population_gapminder.x, -gdp_per_capita_ppp_constant_2011_international_rate) %>%
  rename(mismng_pl_waste_tons = mismanaged_plastic_waste_tonnes,
        mismng_pl_waste_per_cap = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day,
        plastic_waste_per_cap = per_capita_plastic_waste_kilograms_per_person_per_day,
        coast_pop = coastal_population,
        gdp_per_cap = gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
        population = total_population_gapminder))
View(waste)


#Look for correlations using the inspectdf package:
inspect_cor(waste, show_plot = TRUE) 
inspect_na(waste, show_plot = TRUE) #Looks like we only have 2010 waste data

#Plots:
data4plot <- waste %>% filter(year == 2010) %>% filter(entity != ""World"")
plt1 <- ggplot(data4plot, aes(x = log(gdp_per_cap), 
             y = log(plastic_waste_per_cap), 
             size = mismng_pl_waste_tons)) +
  geom_smooth(method = ""lm"") +
  geom_point(color = ""#333333"", alpha = 0.7) +
  geom_text_repel(aes(label = entity),
    color         = ""red"",
    size          = 4,
    data          = subset(data4plot, log(plastic_waste_per_cap) > 0 | log(plastic_waste_per_cap) < -4.5 | (log(gdp_per_cap) < 7 & log(plastic_waste_per_cap) < -4) | code %in% c(""USA"",""CHN"")),
    nudge_y       = .8,
    segment.size  = 0.2,
    segment.color = ""grey50"",
    direction     = ""x""
  ) +
  labs(title = ""Richer nations tend to produce more plastic waste"",
       x = ""GDP Per Capita (log scale)"",
       y = ""Per Capita Plastic Waste in kg/day (log scale)"",
       size = ""Mismanagement of \nPlastic Waste (tons)"")  +
  theme(legend.position = ""none"") 


#Richer nations manage their plastic waste better
plt2 <- ggplot(data4plot, aes(x = log(gdp_per_cap), 
             y = mismng_pl_waste_per_cap, 
             size = mismng_pl_waste_tons)) +
  geom_smooth(show.legend = FALSE) + 
  geom_point(color = ""#333333"", alpha = 0.7) + 
  geom_text_repel(aes(label = entity), 
    color         = ""red"",
    size          = 4,
    data          = subset(data4plot, mismng_pl_waste_per_cap > .14 | code %in% c(""USA"",""CHN"")),
    nudge_y       = .025,
    nudge_x       = .1,
    segment.size  = 0.2,
    segment.color = ""grey50"",
    direction     = ""x""
  ) + 
  ylim(0, NA) +
  labs(title = ""Many countries having mid-range GDP are\nbad at management of their plastic waste "",
       x = ""GDP Per Capita (log scale)"",
       y = ""Per Capita Mismanaged Plastic Waste in kg/day"",
       size = ""Mismanaged\nPlastic Waste (tons)"") 

#Get the legend from plot 2 so that I can put it in its own plot grid panel:
l <- get_legend(plt2) 

#Final plot
plot_grid(plt1, 
          plt2 + theme(legend.position = ""none""), 
          l,
          nrow = 1)

","2019-21"
"121",1081,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week24/meteorites.R","AmandaRP","tidytuesday","2019/week24/meteorites.R","library(tidyverse)
library(ggdark)
library(gganimate)

#read data:
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

#Get rid of outliers:
meteorites %<>% filter(long<180 & year <= 2013)

#map:
mapWorld <- borders(""world"", colour=""gray50"", fill=""gray50"") # create a layer of borders

ggplot(meteorites) +   
  mapWorld + 
  geom_point(aes(x=long, y=lat) ,color=""green"", size=1, alpha = .1) +
  dark_mode() +
  theme(panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank()) + 
  labs(caption = ""Data from the Meteoritical Society (and shared by NASA)"") +
  labs(title = ""Meteorite Crashes on Earth"") 
    
      
# Experimentation with animation:  
#transition_states(year,
#                    transition_length = 2,
#                    state_length = 1) +
#    ggtitle(""Meteorites"", subtitle = ""Year:  {frame_time}"") 
  

#Time series plot:
meteorites %>% 
  filter(year > 1950 & year < 2013) %>%
  group_by(year) %>% 
  count() %>% 
  arrange(desc(n)) %>%
  ggplot(aes(year, n)) +
  geom_line(color = ""green"") + 
  dark_mode() + 
  labs(title = ""Meteorites by Year (1950 - 2012)"",
       x = ""Year"",
       y = ""Count"") +
  geom_curve(aes(x = 1979 + 5, y = 3000, xend = 1979.5, yend = 3046), curvature = 0.3, arrow = arrow(length=unit(2,""mm"")), color = ""white"") +
  annotate(""text"", x = 1979 + 7, y = 2950, label = ""1979"")
  


","2019-24"
"122",1082,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week19/R/20190507.Rmd","AmandaRP","tidytuesday","2019/week19/R/20190507.Rmd","---
title: ""Week 19""
output: html_notebook
---

```{r}
library(tidyverse)
library(here)
library(rworldmap)
library(ggthemes)
```

Read data:

```{r}
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

```

Clean data and calculate median:

```{r}

med_ratios <- student_ratio %>% 
  filter(!is.na(student_ratio)) %>%      # remove NAs
  group_by(country_code, indicator) %>%
  filter(year == max(year)) %>%          # grab the most recent data for each country and education level
  ungroup() %>%
  group_by(country_code, country) %>%
  summarise(median_ratio = median(student_ratio)) 

```

Check names in med_ratios compared to map_data(""world"")

```{r}
anti_join(med_ratios, map_data(""world""), by = c(""country"" = ""region"")) %>% View()
```


Need to recode some country names to match map_data:

```{r}
med_ratios_fixed <- med_ratios %>%
  mutate(country = recode(country,
                                ""United States of America"" = ""USA"",
                                ""Viet Nam"" = ""Vietnam"",
                                ""British Virgin Islands"" = ""Virgin Islands"",
                                ""United Republic of Tanzania"" = ""Tanzania"",
                                ""Syrian Arab Republic"" = ""Syria"",
                                ""Russian Federation"" = ""Russia"",
                                ""Democratic People's Republic of Korea"" = ""North Korea"",
                                ""The former Yugoslav Republic of Macedonia"" = ""Macedonia"",
                                ""Republic of Moldova"" = ""Moldova"",
                                ""Republic of Korea"" = ""South Korea"",
                                ""Cte d'Ivoire"" = ""Ivory Coast"",
                                ""Iran (Islamic Republic of)"" = ""Iran"",
                                ""United Kingdom of Great Britain and Northern Ireland"" = ""UK"",
                                ""Micronesia (Federated States of)"" = ""Micronesia"",
                                ""Czechia"" = ""Czech Republic"",
                                ""Cabo Verde"" = ""Cape Verde"",
                                ""Congo"" = ""Democratic Republic of the Congo"",
                                ""Brunei Darussalam"" = ""Brunei"",
                                ""Bolivia (Plurinational State of)"" = ""Bolivia""))
                                
```

Join median student teacher ratio data with map data:

```{r}
my_map_data <- med_ratios_fixed %>%
  full_join(map_data(""world""), by = c(""country"" = ""region"")) %>% 
  filter(!grepl(""Antarctica"",country)) #don't need Antarctica
```


Plot:

```{r}
ggplot(my_map_data, aes(x = long, y = lat)) +
     geom_polygon(aes(fill = median_ratio, group = group), color = ""black"", size = 0.2) +
     scale_fill_gradient2(low = ""blue"", high = ""red"", midpoint = 17.428480) +
     theme_fivethirtyeight() + 
     theme(axis.line=element_blank(),
           axis.text.x=element_blank(),
           axis.text.y=element_blank(),
          panel.grid.major=element_blank(),
          panel.grid.minor=element_blank()) +
     labs(fill = ""ratio"",
          title = ""Median Student to Teacher Ratios"",
          caption = str_c(str_wrap(""Median student-to-teacher ratio calculated across all education levels using the most recent data for each level. White indicates a median ratio close to the world median. Countries shown in blue have a smaller ratio, while countries shown in red have a larger (less favorable) ratio. Grey indicates missing data."", width = 120),""\nData Source: UNESCO\nVisualization: @AmandaRPlunkett"")) 
  
```



```{r}
ggsave(""studentTeacherRatios.png"", width = 7.4, height = 4.5, dpi = ""retina"")
```

","2019-19"
"123",1083,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week28/fifa.R","AmandaRP","tidytuesday","2019/week28/fifa.R","library(tidyverse)
library(ggimage)

#Get the data
wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

#get alternative country codes
more_codes <- countrycode::codelist_panel %>% 
  group_by(country.name.en) %>% 
  top_n(1, year) %>%
  select(country.name.en, ioc, iso2c, iso3c, genc3c, fips)

#join data with codes
wwc_outcomes_wcodes <- dplyr::left_join(wwc_outcomes, codes, by = ""team"") %>%
  select(year, team, score, country) %>%
  left_join(more_codes, by = c(""team"" = ""ioc"")) %>%
  mutate(year = as.character(year))
#Fix England:
wwc_outcomes_wcodes[wwc_outcomes_wcodes$country == ""England"", ""iso2c""] <- ""GB""

#Limit plot to top scoring countries 
top_countries <- wwc_outcomes %>%
  group_by(team) %>%
  summarize(total_score = sum(score)) %>%
  top_n(11, total_score) 

#plot
ggplot(inner_join(wwc_outcomes_wcodes, top_countries), 
       aes(reorder(country, total_score), score, fill = year)) + 
  geom_col(position = position_stack(reverse = TRUE)) + #adjusted position_stack to have years increase from left to right
  ggthemes::scale_fill_tableau(name=""Year"") +           #nice colors
  coord_flip() +
  labs(
    title = ""Womens World Cup Soccer: Total Goals (1991 - 2019)"",
    caption = ""Data from https://data.world/sportsvizsunday/womens-world-cup-data""
  ) +
  geom_flag(y = -5, aes(image = iso2c)) +
  expand_limits(y = -5) +
  geom_image(aes(x = ""France"", y = 120, 
                 image = ""~/tidytuesday/2019/week28/soccer2.png""),
             size = 0.15) +
  theme_minimal() +
  theme(title = element_text(size=14),
        panel.grid = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.title = element_blank(),
        strip.text.y = element_text(angle = 180)) + 
  guides(fill = guide_legend(reverse = TRUE))  #put 2019 at top of legend

","2019-28"
"124",1084,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week22/wine.R","AmandaRP","tidytuesday","2019/week22/wine.R","library(tidyverse)
library(showtext)

#read data:
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

#clean up a bit:
wine_ratings <- wine_ratings %>% 
  select(-X1) %>% #X1 is not informative
  distinct()      #de-dupe based on a tip posted on twitter

#Some countries only have a handful of ratings.
# Select only countries that have atleast 1000 ratings:
large_sample_countries <- wine_ratings %>% 
  group_by(country) %>% 
  summarize(med_cntry_pnts = median(points), cnt = n()) %>% 
  arrange(desc(med_cntry_pnts)) %>%  
  filter(cnt >= 1000) #%>% View()

data4plotting <- inner_join(wine_ratings, large_sample_countries)

#Note: I had to use the showtext package (extrafonts didn't offer very many fonts 
# and newly installed fonts didn't render... may be user error). 
# Required copying and pasting code into terminal window.
# Read more about showtext package here: 
# https://cran.rstudio.com/web/packages/showtext/vignettes/introduction.html
font_add_google(""Satisfy"", ""satisfy"")
showtext_auto()


# Country vs Taster. Do some tasters give higher ratings in general than others?  
p <- data4plotting %>% 
  filter(!is.na(taster_name)) %>%
  group_by(taster_name, country) %>%
  summarize(med_cntry_taster_pnts = median(points), cnt_cntry_taster = n())  %>%
  ungroup() %>%
  mutate(taster_name = fct_reorder(taster_name, med_cntry_taster_pnts)) %>%
  ggplot(aes(x = country, y = taster_name, size = cnt_cntry_taster, color = med_cntry_taster_pnts)) +
  geom_point() +
  scale_colour_gradient(low = ""white"", high = ""dark red"") +
  theme_light() +
  labs(y = ""Taster"", 
       x = ""Wine Country"", 
       title = ""Wine Taster Rating Profile (by Country)"",
       color = ""Median Score"",
       size = ""Number of Reviews"",
       caption = ""Countries limited to those with atleast 1000 rated wines"") +
  theme(axis.text.x = element_text(angle = 45, hjust=1, size = 20),
        axis.text.y = element_text(size = 20),
        title = element_text(family = ""satisfy"", size = 36),
        plot.caption = element_text(hjust = 0.5),
        legend.text = element_text(size = 18))

p

ggsave(""wine_tasting.png"", p, height = 4, width = 7)


### Bonus code:

#The following parallel plot looks cool, but I don't think it's as informative 
# as the bubble plot.
library(ggparallel)  

df <- data4plotting %>% 
    filter(!is.na(taster_name)) %>%
    group_by(taster_name, country) %>%
    summarize(med_cntry_taster_pnts = median(points)) 
  
ggparallel(list(""taster_name"", ""country""), as.data.frame(df))

","2019-22"
"125",1085,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week20/20190514.R","AmandaRP","tidytuesday","2019/week20/20190514.R","library(tidyverse)
library(tidytext)
library(wordcloud)

#Read data:
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

#Get list of words and their counts
words_df <- nobel_winners %>% 
  select(gender, motivation) %>%
  filter(!is.na(motivation) & !is.na(gender)) %>%
  unnest_tokens(word, motivation) %>%
  anti_join(stop_words) %>%
  group_by(gender, word) %>%
  summarize(cnt = n()) %>%
  arrange(desc(cnt)) %>% 
  ungroup()

#Create document term matrix:
dtm <- words_df %>% cast_dtm(gender, word, cnt) 

#Draw word clouds:
comparison.cloud(t(as.matrix(dtm)), max.words=75)
commonality.cloud(t(as.matrix(dtm)), max.words=40)
","2019-20"
"126",1086,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week26/ufo.R","AmandaRP","tidytuesday","2019/week26/ufo.R","library(tidyverse)
library(summarytools)
library(tidytext)
library(igraph)
library(ggraph)

#read data:
ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

#Look at the data:
View(ufo_sightings)
view(dfSummary(ufo_sightings))

#Clean and tokenize 
bigram_counts <- ufo_sightings %>%
  select(description) %>%
  mutate(description = str_replace_all(description, ""\\&\\#\\d+"", """")) %>%  # Remove &#digit
  filter(!is.na(description)) %>%
  unnest_tokens(bigram, description, token = ""ngrams"", n = 2) %>%
  separate(bigram, c(""word1"", ""word2""), sep = "" "") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>%
  count(word1, word2, sort = TRUE) %>%
  filter(word1 != ""nuforc"" & word2 != ""nuforc"")

#Create graph structure:
bigram_graph <- bigram_counts %>%
  filter(n > 225) %>%
  graph_from_data_frame()

a <- grid::arrow(type = ""closed"", length = unit(.15, ""inches""))

#plot:
ggraph(bigram_graph, layout = ""fr"") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = ""lightgreen"", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()  +
  theme(plot.margin=unit(c(.5, .5, .5, .5),""cm"")) +
  labs(title = ""Common Bigrams in UFO Sighting Descriptions"",
       subtitle = ""Data provided by NUFORC"")

","2019-26"
"127",1124,"https://github.com/Talitrus/tidytuesday/tree/master/2019/week25","Talitrus","tidytuesday","2019/week25/Jun192019_tidytuesday.R","####################
# Bryan Nguyen
####################
# Data is from https://www.birdscanada.org/
# Cleaned and tidied by @_sharleen_w on Twitter.
############################################
# This code performs an ordination on the Christmas Bird Count (CBC) data from Hamilton, Ontario, Canada.
# Specifically, it uses a Principle Coordinates Analysis on the Bray-Curtis distance matrix of yearly data.
# The resulting plot is colored by year to show a trend through time.
# Some years were missing CBC data and were removed.
#######################################

library(tidyverse)
library(LaCroixColoR)
library(vegan)
library(ggrepel)
library(extrafont)
bird_counts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")


table <- spread(data = bird_counts %>% select(year, species_latin, how_many_counted_by_hour), key = ""year"", value = ""how_many_counted_by_hour"", fill = 0) %>% 
  column_to_rownames(var = ""species_latin"")
vegan_table <- t(table)

vegan_table <- vegan_table[rowSums(vegan_table) > 0,] # remove birds with no sightings in Hamilton ever.

bc_matrix <- vegdist(as.matrix(vegan_table)) # Calculate (abundance-weighted) Bray-Curtis ecological community distances between years.

PCoA_ord <- cmdscale(bc_matrix, k = 2, eig = TRUE) # Principle Coordinates Analysis
PCoA_df <- tibble(year = as.numeric(rownames(PCoA_ord$points)), x = PCoA_ord$points[,1], y = PCoA_ord$points[,2])
years_to_label <- c(1921, 1939, 2017)
PCoA_df$label <- """" # Years with a blank label are not labelled.
PCoA_df$label[match(years_to_label, PCoA_df$year)] <- years_to_label # Label years to label with the corresponding year information.

PCoA_plot <- ggplot(data = PCoA_df) +
  geom_point(mapping = aes(x = x, y = y, color = year), size = I(5), alpha = 0.70) +
  #viridis::scale_color_viridis() + # sorry, but the LaCroix color palettes are too much fun.
  scale_color_gradientn(colors = lacroix_palette(""PeachPear"")) +
  geom_label_repel(mapping = aes(x = x, y = y, label = label, color = year), force = 5) +
  xlab(paste0(""PCoA axis 1: "", round(PCoA_ord$eig[1] / sum(PCoA_ord$eig) * 100, digits = 1), ""%"")) +
  ylab(paste0(""PCoA axis 2: "", round(PCoA_ord$eig[2] / sum(PCoA_ord$eig) * 100, digits = 1), ""%"")) +
  ggtitle(""Hamilton, Canada CBC bird communities change / time"") +
  theme_minimal() +
  theme(
    text = element_text(
      family = ""Lato"" # This is a freely available Google font that I imported into R with the 'extrafont' library.
        ),
    plot.title = element_text(
      face=""bold"")
  )
PCoA_plot

ggsave(filename = ""PCoA_plot.png"", plot = PCoA_plot, height = 4, width = 6)
","2019-25"
"128",1126,"https://github.com/toscano84/TidyTuesday/blob/master/week4_2019/week4_2019.R","toscano84","TidyTuesday","week4_2019/week4_2019.R","# week 4 2019 - TidyTuesday

library(tidyverse) # wrangle, visualization of data
library(data.table) # load file
library(albersusa) # map of all 50 states plus DC
library(broom) # in this case to tidy a shape file
library(ggalt) # create coordinate system in maps
library(viridis) # color palette
library(extrafont) # add fonts to R


options(scipen = 999)

# load file
incarceration <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/incarceration_trends.csv"")

# tidy the dataframe
murder_crime_tbl <- incarceration %>% 
  mutate(decade = year -year %% 10) %>% # create variable decade)
  group_by(decade, state) %>% # group by decade and state
  mutate(crime = rowSums(cbind(violent_crime, murder_crime),na.rm=TRUE) 
         / total_pop * 100) %>% # create variable crime that corresponds to the sum of violent crime and murder crime
  summarize(crime_rate = mean(crime, na.rm = TRUE)) %>%
  filter(!state %in% c(""AK"", ""AL"") | decade != 1970)

#--- create map of the us states

us <- usa_composite() %>%
  tidy(., region = ""iso_3166_2"") # use tidy function from the broom package to create a dataframe of the us map

#---- create quantiles
number_quantiles <- 5
labels <- c()

quantiles <- quantile(murder_crime_tbl$crime_rate, 
                      probs = seq(0, 1, length.out = no_classes + 1))

# create custom labels for the quantiles
for(i in 1:length(quantiles)){
  labels <- c(labels, paste0(round(quantiles[i], 2), 
                             "" - "", 
                             round(quantiles[i + 1], 2)))
}
# Remove last label
labels <- labels[1:length(labels)-1]

# create new variable based on quantiles
murder_crime_tbl$crime_rate_quantiles <- cut(murder_crime_tbl$crime_rate, 
                                          breaks = quantiles, 
                                          labels = labels, 
                                          include.lowest = T)


#----------build plot: fill varriable correspond to the quantiles-----#
p <-  ggplot() +
  geom_map(data = us, map = us,
           aes(x = long, y = lat,
               map_id = id),
           color = ""grey30"",
           fill = NA) +
  geom_map(data = murder_crime_tbl, map = us,
           aes(fill = crime_rate_quantiles, map_id = state),
           color = ""grey30"") +
  scale_fill_viridis_d(option = ""plasma"",
                     name = ""Violent\nand Murder Crime Rate"",
    direction = -1,
    guide = guide_legend(
      keyheight = unit(5, units = ""mm""),
      title.position = 'top',
      reverse = T
    )) +
  facet_wrap(vars(decade)) +
  coord_proj(us_laea_proj) +
  labs(title = ""Violent and Murder Crime in the USA"",
       subtitle = ""Mean Rate (%) by decade "",
       x = """",
       y ="""") +
  theme_minimal() +
  theme(plot.title = element_text(family = ""Cooper Black"",
                                  size = 30, hjust = 0.5),
        plot.subtitle = element_text(family = ""Cooper Black"",
                                  size = 20, hjust = 0.5),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Cooper Black"", size = 18, 
                                  face = ""bold""),
        legend.text = element_text(family = ""Cooper Black"", size = 14),
        legend.title = element_text(family = ""Cooper Black"", size = 18),
        plot.background = element_rect(fill = ""#e8e8ea""),
        panel.grid = element_line(color = ""grey70""),
        legend.direction = ""vertical"",
        legend.position = c(0.85, 0.25))

ggsave(""crime_usa.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")

","2019-4"
"129",1129,"https://github.com/toscano84/TidyTuesday/blob/master/week2_2019/week2_2019.R","toscano84","TidyTuesday","week2_2019/week2_2019.R","# week 2 2019 - TidyTuesday

# libraries needed
library(tidyverse)
library(data.table)
library(ggrepel)
library(lubridate)
library(ggdark)
library(ggrepel)
library(extrafont)

# import and load fonts
font_import()
loadfonts(device = ""win"")

# open the file
imdb_ratings <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"")

# glimpse the dataframe
glimpse(imdb_ratings)

# tidy the file
imdb_ratings_tidy <- imdb_ratings %>%
  mutate(year = year(date), # create variable year
         decade = year - year %% 10) # create variable decade


# create variable above_below_median grouped by year
imdb_ratings_tidy <- imdb_ratings_tidy %>%
  group_by(year) %>%
  mutate(above_below_median = ifelse(av_rating > median(av_rating), 
                               1, 0))

# create a dataframe with highest average tv_ratings per decade
imdb_top_perdecade <- imdb_ratings_tidy %>%
  group_by(decade) %>%
  top_n(1, wt = av_rating)

#----plot----#
plot <- imdb_ratings_tidy %>%
  group_by(year) %>%
  ggplot(aes(x = factor(year),
             y= av_rating, label = title)) +
  geom_jitter(aes(color = factor(above_below_median)), size = 3, alpha = 0.3) +
  geom_boxplot(alpha = 0, color = ""grey50"", outlier.colour = ""red"") +
  geom_label_repel(data = imdb_top_perdecade, # label with the top show per decade
                   fontface = ""bold"",
                   color = ""grey50"",
                   size = 6,
                   family = ""Agency FB"",
                   direction = ""x"") +
  stat_summary(fun.y = median, geom = ""line"", aes(group = 1), 
               linetype = 1, colour = ""grey50"", size = 1) # create a line based on the median +
  dark_theme_gray() +
  theme(plot.title = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 40, hjust = 0.5),
        plot.subtitle = element_text(family = ""Agency FB"", face = ""bold"",
                                     size = 20, hjust = 0.5),
        plot.background = element_rect(fill = ""grey10""),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = ""grey30"", size = 0.2),
        panel.grid.minor = element_line(color = ""grey30"", size = 0.2),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_text(family = ""Agency FB"", size = 15),
        axis.text = element_text(family = ""Agency FB"", size = 15),
        legend.key = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Agency FB"", size = 15),
        legend.text = element_text(family = ""Agency FB"", size = 15),
        legend.title = element_text(family = ""Agency FB"", size = 15)) +
  scale_color_manual(values = c(""#d35400"", ""#1abc9c""), labels = c(""Below the Median"", 
                                                                  ""Above the Median"")) + 
  labs(title = ""Average Rating of Tv Shows"",
       subtitle = ""Parenthood, Third Watch and Breaking Bad had\nthe highest average rating for each decade"", 
       x = ""Year"", 
       y = ""Average Rating"", 
       color = ""Shows"") +
  facet_wrap(vars(decade), ncol = 3, scales = ""free_x"")

plot

ggsave(""av_ratings_imdb.jpg"", plot, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")
","2019-2"
"130",1130,"https://github.com/toscano84/TidyTuesday/blob/master/week5_2019/week5_2019.R","toscano84","TidyTuesday","week5_2019/week5_2019.R","# week 5 2019 - TidyTuesday

library(tidyverse) # wrangle, visualization of data
library(data.table) # load file
library(extrafont) # add fonts to R
library(gghighlight) # highlight values in a plot

options(scipen = 999) # remove scientific notation


# load data frame
milk_facts <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milk_products_facts.csv"")

# create manual palette
cols <-  c(""#578300"", ""#991200"", ""#1280A1"", ""yellow"", ""Tomato"",
           ""MediumSeaGreen"", ""DodgerBlue"", ""blue"", ""#FA8072"", 
           ""#FFC300"", ""#FF5733"", ""#C70039"", ""#900C3E"", ""#571845"",
           ""#D35400"", ""#000080"") 

# create plot
p <- milk_facts %>%
  gather(key = types_milk, value = avg_consumption, 2:ncol(.)) %>%
  filter(types_milk != ""fluid_milk"") %>% #do not include fluid_milk
  mutate(types_milk2 = recode(types_milk,
                                  ""butter"" = ""Butter"", 
          ""cheese_american"" = ""Cheese American"", 
          ""cheese_cottage"" = ""Cheese Cottage"", 
          ""cheese_other"" = ""Cheese Other"",
          ""dry_buttermilk"" = ""Dry Buttermilk"", 
          ""dry_nonfat_milk"" = ""Dry non-fat Milk"", 
          ""dry_whey"" = ""Dry Whey"",
         ""dry_whole_milk"" = ""Dry Whole Milk"",
         ""evap_cnd_canned_whole_milk"" = ""Evap. and Canned whole Milk"",
         ""evap_cnd_bulk_whole_milk"" = ""Evap. and Canned Bulk whole Milk"",
         ""evap_cnd_bulk_and_can_skim_milk"" = ""Evap. and Canned Bulk & skim Milk"",
         ""fluid_yogurt"" = ""Fluid Yogurt"",
         ""frozen_ice_cream_regular"" = ""Frozen Ice cream Regular"",
         ""frozen_ice_cream_reduced_fat"" = ""Frozen Ice Cream reduced Fat"",
         ""frozen_other"" = ""Frozen Other"",
         ""frozen_sherbet"" = ""Frozen Sherbet"",
         ""fluid_milk"" = ""Fluid Milk"")) %>%
  group_by(year, types_milk2) %>%
  summarize(avg_milk_consumed = mean(avg_consumption, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = avg_milk_consumed)) +
  guides(color = FALSE) +
  geom_line(aes(colour = types_milk2), size = 3.5) +
  gghighlight(use_direct_label = FALSE, use_group_by = FALSE,
              unhighlighted_colour = alpha(""grey20"", 0.3)) +
  facet_wrap(vars(types_milk2)) + 
  labs(title = ""Average Consumption of Milk Products (lbs per person)"",
       subtitle = ""Not including fluid Milk"",
       x = NULL,
       y = NULL) +
  scale_x_continuous(breaks = c(seq(1975, 2015, by = 10)),
                     limits = c(1975, 2017)) +
  ggdark::dark_theme_bw() +
  scale_color_manual(values = cols) +
  theme(plot.title = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 30, hjust = 0.5),
        plot.subtitle = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 15, hjust = 0.5),
        plot.background = element_rect(fill = ""black""),
        panel.border = element_blank(),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(family = ""Agency FB"", size = 15),
        legend.key = element_blank(),
        axis.title = element_text(family = ""Agency FB"", size = 20, face = ""bold""),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Agency FB"", size = 20, face = ""bold""),
        legend.text = element_text(family = ""Agency FB"", size = 15),
        legend.title = element_text(family = ""Agency FB"", size = 15))


ggsave(""milk_consumption.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")


           


","2019-5"
"131",1132,"https://github.com/toscano84/TidyTuesday/blob/master/week6_2019/week6_2019.R","toscano84","TidyTuesday","week6_2019/week6_2019.R","# week 6 Tidy Tuesday

library(tidyverse) # wrangle, visualization data
library(data.table) # load file
library(geojsonio) # open json files
library(cartogram) # create cartograms
library(broom) # tidy data frames
library(rgeos) # manipulation of spatial objects
library(viridis) # palette
library(extrafont) # add new fonts to R

# open data frame
hpi_usa <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")


# tidy the data frame
hpi_usa_tbl <- hpi_usa %>% 
  mutate(state_full_name = as.factor(case_when(state == ""AL"" ~ ""Alabama"",
                                               state == ""AK"" ~ ""Alaska"",
                                state == ""AR"" ~ ""Arkansas"",
                                state == ""AZ"" ~ ""Arizona"",
                                state == ""CA"" ~ ""California"",
                                state == ""CO"" ~ ""Colorado"",
                                state == ""CT"" ~ ""Connecticut"",
                                state == ""DC"" ~ ""District of Columbia"",
                                state == ""DE"" ~ ""Delaware"",
                                state == ""FL"" ~ ""Florida"",
                                state == ""GA"" ~ ""Georgia"",
                                state == ""HI"" ~ ""Hawaii"",
                                state == ""IA"" ~ ""Iowa"",
                                state == ""ID"" ~ ""Idaho"",
                                state == ""IL"" ~ ""Illinois"",
                                state == ""IN"" ~ ""Indiana"",
                                state == ""KS"" ~ ""Kansas"",
                                state == ""KY"" ~ ""Kentucky"",
                                state == ""LA"" ~ ""Louisiana"",
                                state == ""MD"" ~ ""Maryland"",
                                state == ""ME"" ~ ""Maine"",
                                state == ""MA"" ~ ""Massachusetts"",
                                state == ""MI"" ~ ""Michigan"",
                                state == ""MN"" ~ ""Minnesota"",
                                state == ""MO"" ~ ""Missouri"",
                                state == ""MS"" ~ ""Mississippi"",
                                state == ""MT"" ~ ""Montana"",
                                state == ""NC"" ~ ""North Carolina"",
                                state == ""NH"" ~ ""New Hampshire"",
                                state == ""ND"" ~ ""North Dakota"",
                                state == ""NE"" ~ ""Nebraska"",
                                state == ""NJ"" ~ ""New Jersey"",
                                state == ""NM"" ~ ""New Mexico"",
                                state == ""NV"" ~ ""Nevada"",
                                state == ""NY"" ~ ""New York"",
                                state == ""OH"" ~ ""Ohio"",
                                state == ""OK"" ~ ""Oklahoma"",
                                state == ""OR"" ~ ""Oregon"",
                                state == ""PA"" ~ ""Pennsylvania"",
                                state == ""RI"" ~ ""Rhode Island"",
                                state == ""SC"" ~ ""South Carolina"",
                                state == ""SD"" ~ ""South Dakota"",
                                state == ""TN"" ~ ""Tennessee"",
                                state == ""TX"" ~ ""Texas"",
                                state == ""UT"" ~ ""Utah"",
                                state == ""VA"" ~ ""Virginia"",
                                state == ""VT"" ~ ""Vermont"",
                                state == ""WA"" ~ ""Washington"",
                                state == ""WI"" ~ ""Wisconsin"",
                                state == ""WV"" ~ ""West Virginia"",
                                state == ""WY"" ~ ""Wyoming""))) %>% # create new variable as factor with the state name in a long format
  group_by(year, state_full_name) %>%
  summarize(price_index_avg = mean(price_index, na.rm = TRUE)) %>% # create variable with mean price index per year and state
  mutate(id_row = 1:n()) %>% # this step is important for the spread function to work
  spread(year, price_index_avg) %>% # from long to wide format
  mutate(change_price_index = (`2018` - `2000`) / `2000` * 100) %>% # create variable based on the changes in the house price index from 2000 to 2018
  select(-id_row)
  
  
#-----manipulate hexbin file of the USA------

# open hexbin file
# Hexbin available in https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map.
us_hexagonal <- geojson_read(""us_states_hexgrid.geojson"",  what = ""sp"")

# create variable region
us_hexagonal@data <- us_hexagonal@data %>% 
  mutate(google_name = gsub("" \\(United States\\)"", """", google_name))

# merge both data frames
us_hexagonal@data <- us_hexagonal@data %>% 
  left_join(., hpi_usa_tbl, by=c(""google_name""=""state_full_name""))


# create the cartogram using the change_price_index variable
cartogram <- cartogram(us_hexagonal, 'change_price_index')


# use the broom package to make the spatial object a data frame and then merge it with the cartogram
us_fortified <- tidy(cartogram, region = ""google_name"")
us_fortified <-  us_fortified %>% 
  left_join(. , cartogram@data, by=c(""id""=""google_name"")) 

# Important step to center the state labels
centers <- cbind.data.frame(data.frame(gCentroid(cartogram, byid=TRUE), 
                                       id=cartogram@data$iso3166_2))

#----plot-----#
#---alter the key legend with specific breaks---
# create breaks
new_breaks <- c(50,100,150,200,250,300)
# find the min for the labels
minvalue <- min(us_fortified$change_price_index, na.rm = T)

# create labels
labels <- c()
breaks <- c(minvalue, new_breaks)
# round the labels 
for(i in 1:length(breaks)){
  labels <- c(labels,round(breaks[i + 1], 2))
}

labels <- labels[1:length(labels)-1]
# create a new variable based on breaks
us_fortified$breaks <- cut(us_fortified$change_price_index, 
                     breaks = breaks, 
                     include.lowest = TRUE, 
                     labels = labels)

breaks_scale <- levels(us_fortified$breaks)
labels_scale <- rev(breaks_scale)

p <- ggplot() +
  geom_polygon(data = us_fortified, 
               aes(fill = breaks, 
                   x = long, y = lat, group = group) , 
               size=0.05, color=""grey40"") +
      # create manual scale based on the breaks 
  scale_fill_manual(values = rev(cividis(8)), # reverse cividis scale from the viridis palette
    breaks = rev(breaks_scale),
    name = ""Change of Price Index (%)"",
    drop = FALSE,
    labels = labels_scale,
    guide = guide_legend(
      direction = ""horizontal"",
      keyheight = unit(3.4, units = ""mm""),
      keywidth = unit(18, units = ""mm""),
      title.position = 'top',
      title.hjust = 0.5,
      label.hjust = 1,
      nrow = 1,
      byrow = TRUE,
      reverse = TRUE,
      label.position = ""bottom""
    )
  ) +
  geom_text(data=centers, aes(x=x, y=y, label=id), 
            color=""grey25"", size=5, alpha=0.6, family = ""Cooper Black"") +
  labs(title =  ""House Price Index"",
       subtitle = ""From 2000 to 2018"") +
  theme_void() +
  theme(panel.grid = element_blank(),
    legend.position = c(0.5, 0.87),
    axis.line = element_blank(),
    axis.text = element_blank(),
    plot.background = element_rect(fill = ""#333333"", color = NA), 
    panel.background = element_rect(fill = ""#333333"", color = NA), 
    legend.background = element_rect(fill = ""#333333"", color = NA),
    legend.text = element_text(size= 12, color = ""grey50"", family = ""Cooper Black""),
    plot.title = element_text(size= 28, hjust=0.5, color = ""grey50"", family = ""Cooper Black""),
    plot.subtitle = element_text(size= 14, hjust=0.5, vjust = -5, color = ""grey50"", family = ""Cooper Black""),
    legend.title = element_text(size= 16, hjust=0.5, vjust = -5, color = ""grey50"", family = ""Cooper Black"")) +
  coord_map()

ggsave(""hpi_index_changes.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")

","2019-6"
"132",1134,"https://github.com/toscano84/TidyTuesday/blob/master/week7_2019/week7_2019.R","toscano84","TidyTuesday","week7_2019/week7_2019.R","# week 7 Tidy Tuesday

library(tidyverse) # wrangle, visualization data
library(data.table) # load file
library(viridis) # palette
library(extrafont) # add new fonts to R
library(waffle) # create waffle plot



options(scipen = 999) # remove scientific notation

# import and load fonts
font_import()
loadfonts(device = ""win"")

# importing fontawesome font
fa_font <- tempfile(fileext = "".ttf"")
download.file(""http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/fonts/fontawesome-webfont.ttf?v=4.3.0"",
              destfile = fa_font, method = ""curl"")

font_import(paths = dirname(fa_font), prompt = FALSE)

fonts()
if (.Platform$OS.type == ""windows"") loadfonts(""win"")


# open data frame
fed_spend <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"") 


glimpse(fed_spend)


# tidy the data frame
fed_spend_tbl <- fed_spend %>%
  group_by(year) %>%
  mutate(sum_rd = sum(rd_budget),
         perc_rd = round((rd_budget / sum_rd * 100),0)) %>%
  ungroup() %>%
  filter(year > 2014) %>% # only include the last 3 years
  select(year, department, perc_rd) %>%
  group_by(department) %>% # important step to remove NAs after changing the format from long to wide
  mutate(n = row_number()) %>% # this step is important for the spread function to work
  spread(department, perc_rd) %>%
  select(-n) %>%
  select_if(~mean(.) > 4) %>%
  select(year, DOD, HHS,NIH, everything())



# turn each year data into a vector
year_2015 <- unlist(fed_spend_tbl[1, 2:6])
year_2016 <- unlist(fed_spend_tbl[2, 2:6])
year_2017 <- unlist(fed_spend_tbl[3, 2:6])


# scale color manual
cols <- c(""#F8C932"", ""#E55B2F"", ""#A42C60"", ""#61156E"", ""#120A33"")

# set theme
theme_new <- ggdark::dark_theme_gray() +
  theme(plot.title = element_text(family = ""Cooper Black"", face = ""bold"",
                                  size = 18, hjust = 0.5),
        plot.subtitle = element_text(family = ""Cooper Black"", face = ""bold"",
                                     size = 14, hjust = 0.5),
        plot.background = element_rect(fill = ""grey10""),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_text(family = ""Cooper Black"", size = 12),
        axis.text = element_blank(),
        legend.key = element_blank(),
        legend.text = element_text(family = ""Cooper Black"", size = 10),
        legend.title = element_text(family = ""Cooper Black"", size = 10)) 

# Make waffle graph for each year
fed1 <- waffle(year_2015, rows = 5, size = 0.3, pad = 0.5, colors = cols, 
              use_glyph = ""dollar"", glyph_size = 8) +
  labs(title = ""Top 5 Departments per R&D Budget (%)"",
       subtitle = ""Year 2015"") +
  theme_new
  
fed2 <-  waffle(year_2016, rows = 5, size = 0.3, pad = 1, colors = cols, 
              use_glyph = ""dollar"", glyph_size = 8) +
  labs(subtitle = ""Year 2016"") +
  theme_new

fed3 <-  waffle(year_2017, rows = 5, size = 0.3, pad = 1, colors = cols, 
              use_glyph = ""dollar"", glyph_size = 8) +
  labs(subtitle = ""Year 2017"",
       x = ""Each dollar sign represents ~1% of the RD budget"") +
  theme_new


# iron function to arrange the three plots into one
iron(fed1, fed2, fed3)



","2019-7"
"133",1138,"https://github.com/toscano84/TidyTuesday/blob/master/week1_2019/week1_2019.R","toscano84","TidyTuesday","week1_2019/week1_2019.R","# week 1 2019 - TidyTuesday

# load needed libraries
library(tidyverse) # wrangle and visualize the data
library(lubridate) # deal with dates
library(viridis) # color palette
library(extrafont) # add fonts to R

# open file
tweets <- readRDS(""rstats_tweets.rds"")


# tidy the dataframe
tweets_tidy <- tweets %>%
  mutate(year = year(created_at), # create variable year 
         weekday = wday(created_at, label = TRUE),
         weekday = fct_relevel(weekday, ""Mon"",
                               ""Tue"",
                               ""Wed"",
                               ""Thu"",
                               ""Fri"",
                               ""Sat"",
                               ""Sun""), # create variable day of the week and relevel it
         month = month(created_at, label = TRUE), # create variable month
         week = week(created_at)) %>% # create variable week of the year
  filter(year > 2013) %>% # only include last 5 years
  count(year, weekday, week, month)

## plot ##
p <- tweets_tidy %>%
  ggplot(aes(week, weekday, fill = n)) +
  geom_tile(colour = ""grey30"") +
  facet_grid(year ~ month, scales = ""free"") + # divide by month and year
  scale_fill_viridis(name = ""Number of Tweets"",
                     option = ""plasma"", guide = guide_colorbar(
    direction = ""horizontal"",
    barheight = unit(3.5, units = ""mm""),
    barwidth = unit(50, units = ""mm""),
    title.position = 'top',
    title.hjust = 0.5,
    label.hjust = 0.5)) + # manipulate dimensions of the legend's scale 
  labs(title = ""#rstats Tweets in the last 5 years"",
       x = """", y = """") +
  theme(plot.title = element_text(family = ""Cooper Black"",
                                  size = 30, hjust = 0.5),
        plot.background = element_rect(fill = ""#d0d3d4""),
        panel.grid = element_blank(),
        panel.background = element_blank(),
        legend.background = element_blank(),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_text(colour = ""black"",
                                   family = ""Cooper Black"", size = 12),
        axis.text.x = element_blank(),
        legend.key = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Cooper Black"", size = 18, face = ""bold""),
        legend.text = element_text(family = ""Cooper Black"", size = 15),
        legend.title = element_text(family = ""Cooper Black"", size = 15),
        legend.position = ""bottom"") 

ggsave(""rstats.jpg"", p, units = ""cm"", height = 20, width = 40, dpi = ""retina"")

","2019-1"
"134",1139,"https://github.com/toscano84/TidyTuesday/blob/master/week3_2019/week3_2019.R","toscano84","TidyTuesday","week3_2019/week3_2019.R","# week 3 tidytuesday 2019

library(tidyverse) # wrangle and visualize data
library(data.table) # in this case to open the file with the function fread
library(lubridate) # manipulate dates and times
library(ggdark) # theme for plots
library(extrafont) # add new fonts to base R

# open file
space_launches <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")


# create new dataframe with new variables
space_launches_us <- space_launches %>%
  filter(state_code == ""US"") %>% #only include usa launches
  mutate(administration = case_when(between(launch_year, 1957, 1960) ~ ""Eisenhower"",
                                    between(launch_date, ""1961-01-20"", ""1963-11-22"") ~ ""Kennedy"",
                                    between(launch_date, ""1963-11-23"", ""1969-01-19"") ~ ""Johnson"",
                                    between(launch_date,""1969-01-20"", ""1974-08-09"") ~ ""Nixon"",
                                    between(launch_date,""1974-08-10"", ""1977-01-19"") ~ ""Ford"",
                                    between(launch_date,""1977-01-20"", ""1981-01-19"") ~ ""Carter"",
                                    between(launch_date,""1981-01-20"", ""1989-01-19"") ~ ""Reagan"",
                                    between(launch_date,""1989-01-20"", ""1993-01-19"") ~ ""Bush I"",
                                    between(launch_date,""1993-01-20"", ""2001-01-19"") ~ ""Clinton"",
                                    between(launch_date,""2001-01-20"", ""2009-01-19"") ~ ""Bush II"",
                                    between(launch_date,""2009-01-20"", ""2017-01-19"") ~ ""Obama"",
                                    between(launch_date,""2017-01-20"", ""2019-01-17"") ~ ""Trump""
                                    ), # create variable based on presidential administrations
         party = case_when(administration %in% c(""Kennedy"", ""Johnson"", ""Carter"", ""Clinton"", ""Obama"") ~ ""Democratic"",
                           administration %in% c(""Eisenhower"", ""Nixon"", ""Ford"", ""Reagan"", ""Bush I"", ""Bush II"",
                                                 ""Trump"") ~ ""Republican"")) %>% # party variable
  drop_na(administration) # delete missing values in the variable administration



##----plot------##
# function created to have separate breaks due to the use of facets in the plot
breaks_created <- function(x) { 
  if (max(x) < 1961) seq(1957, 1960, 1) 
  else if (max(x) < 1964) seq(1960, 1964, 1)
  else if (max(x) < 1969) seq(1963, 1969, 1)
  else if (max(x) < 1975) seq(1969, 1974, 1)
  else if (max(x) < 1977) seq(1974, 1977, 1)
  else if (max(x) < 1981) seq(1977, 1981, 1)
  else if (max(x) < 1989) seq(1981, 1989, 1)
  else if (max(x) < 1994) seq(1989, 1994, 1)
  else if (max(x) < 2001) seq(1993, 2001, 1)
  else if (max(x) < 2010) seq(2001, 2009, 1)
  else if (max(x) < 2018) seq(2009, 2017, 1)
  else (seq(2017, 2018, 1))}

# plot creation
p <- space_launches_us %>%
  group_by(launch_year, party, administration) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = launch_year, y = n, fill = party)) +
  geom_area() +
  dark_theme_grey() +
  labs(title = ""Space Launches during each Presidential Administration"", 
       subtitle =, x = """", y = """") +
  scale_fill_manual(name = ""Party"", values = c(""navyblue"", ""red""), 
                    labels = c(""Democratic"", ""Republican"")) +
  scale_x_continuous(breaks = breaks_created) +
  theme(plot.title = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 30, hjust = 0.5),
        plot.background = element_rect(fill = ""grey10""),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = ""grey20"", size = 0.2),
        panel.grid.minor = element_line(color = ""grey20"", size = 0.2),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(family = ""Agency FB"", size = 15),
        legend.key = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Agency FB"", size = 20, face = ""bold""),
        legend.text = element_text(family = ""Agency FB"", size = 15),
        legend.title = element_text(family = ""Agency FB"", size = 15)) +
  facet_wrap(vars(fct_reorder(administration, launch_year)), ncol = 3, scales = ""free_x"")

p

ggsave(""plot_us_space.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")




  
 
","2019-3"
"135",1140,"https://github.com/toscano84/TidyTuesday/blob/master/week8_2019/week8_2019.R","toscano84","TidyTuesday","week8_2019/week8_2019.R","# week 8 Tidy Tuesday

library(tidyverse) # wrangle, visualization data
library(data.table) # load file
library(highcharter) # interactive data visualizations

options(scipen = 999)

# open data
phd <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")




# top 20 fields
phd_per <- phd  %>%
  group_by(field) %>%
  summarize(phd_number = sum(n_phds, na.rm = TRUE)) %>%
  mutate(phd_perc = phd_number / sum(phd_number) * 100) %>%
  top_n(20, phd_perc) %>%
  arrange(desc(phd_perc))


# highcharter plot
hchart(phd_per, ""bar"",
       hcaes(x = fct_reorder(field, phd_perc),
             y = phd_perc)) %>%
  hc_add_theme(hc_theme_chalk()) %>%
  hc_title(text = ""Percentage of PhDs: Top 20 Fields"", margin = 10, 
           fontSize = ""50px"") %>%
  hc_xAxis(title = list(text = NULL)) %>% 
  hc_yAxis(title = list(text = ""Percentage"")) %>% 
  hc_subtitle(text = ""From 2008 to 2017"") %>%
  hc_credits(enabled = TRUE,
             text = ""Tidy Tuesday Week 8"",
             style = list(
               fontSize = ""14px""
             )
  )
  


","2019-8"
"136",1646,"https://github.com/lizwillow/TidyTuesday/blob/master/TT.2019.01.01/week20190101.Rmd","lizwillow","TidyTuesday","TT.2019.01.01/week20190101.Rmd","---
output: github_document
---

### #First #TidyTuesday of 2019

This is the code behind an analysis of the ""#rstats and #TidyTuesday Tweets from rtweet"" dataset from the [#tidytuesday project](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-01).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning=FALSE,error=FALSE)

library(tidyverse)
library(scales)
library(broom)
library(ggthemes)
library(plotly)
library(here)
library(rtweet)

theme_set(theme_light())
```

```{r, include=FALSE}

githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/tidytuesday_tweets.rds?raw=true"")
download.file(githubURL,""tidytuesday_tweets.rds"")
tidytuesday <- read_rds(""tidytuesday_tweets.rds"")


githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/rstats_tweets.rds?raw=true"")
download.file(githubURL,""rstats_tweets.rds"")
rstats <- read_rds(""rstats_tweets.rds"")

```

Whose #rstats tweets were retweeted the most in 2018?

```{r}

library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>% 
  summarise(total_retweets = sum(retweet_count),
            n=n()) %>%
  arrange(desc(total_retweets)) %>%
  head(5)

myColors <- as.list(ghibli_palette(""PonyoMedium"",n=5))
names(myColors) <- toppeople$screen_name

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,total_retweets)) %>%
  ggplot(aes(y = total_retweets, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Who had the most retweeted #rstats tweets in 2018?"",
       y = ""Number of retweets of #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm"")) +
  scale_fill_manual(name = ""screen_name"",values = myColors) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",5)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 2,
            col=""white"")

#ggsave(filename = ""rstatsretweets.png"", path = here(""Week20190101_files""),width = 7, height = 4)

```

Whose #rstats tweets were liked the most in 2018?

```{r}

library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_favs = sum(favorite_count),
            n=n()) %>%
  arrange(desc(total_favs)) %>%
  head(5)

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,total_favs)) %>%
  ggplot(aes(y = total_favs, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Who had the most liked #rstats tweets in 2018?"",
       y = ""Number of favorites of #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm"")) +
  scale_fill_manual(name = ""screen_name"",values = myColors) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",5)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 2,
            col=""white"")

#ggsave(filename = ""rstatslikes.png"", path = here(""Week20190101_files""),width = 7, height = 4)


```

Who had the most liked and retweeted #rstats tweets of 2018?

```{r}
topliked <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text,favorite_count) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_fav_ret = sum(retweet_count,favorite_count)) %>%
  arrange(desc(total_fav_ret)) %>%
  head(10)

topliked %>% 
  mutate(screen_name = fct_reorder(screen_name,total_fav_ret)) %>%
  ggplot(aes(y = total_fav_ret, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Users with the most retweeted and favorited #rstats tweets in 2018"",
       y = ""Total #rstats retweets and favorites in 2018"",
       x = """") +
  theme(legend.position = ""none"")

#ggsave(filename=""rstats.png"",path=here(""Week20190101_files""),width = 9, height = 6)
```

Who had the most liked and retweeted #tidytuesday tweets of 2018?

```{r}
topliked <- tidytuesday %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text,favorite_count) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_fav_ret = sum(retweet_count,favorite_count)) %>%
  arrange(desc(total_fav_ret)) %>%
  head(10)

topliked %>% 
  mutate(screen_name = fct_reorder(screen_name,total_fav_ret)) %>%
  ggplot(aes(y = total_fav_ret, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Users with the most retweeted and favorited #TidyTuesday tweets in 2018"",
       y = ""Total #TidyTuesday retweets and favorites in 2018"",
       x = """") +
  theme(legend.position = ""none"")

#ggsave(filename=""tidytuesday.png"",path=here(""Week20190101_files""),width = 9, height = 6)
```

What were the most retweeted and favorited #tidytuesday tweets of 2018?

```{r}
# install.packages(""devtools"")
#devtools::install_github(""hadley/emo"")
#devtools::install_github(""GuangchuangYu/emojifont"")

toptweet <- tidytuesday %>% 
  select(screen_name,created_at,is_retweet,favorite_count, retweet_count,text,status_id) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  mutate(fav_ret = retweet_count+favorite_count) %>%
  arrange(desc(fav_ret)) %>%
  head(10)

toptweet %>%
  mutate(tex = paste0(str_sub(text,1,60),"" ... ("",format(created_at,format = ""%b %d %Y""),"")""),
         screen_name = paste0(""@"",screen_name)) %>% 
  mutate(tex = fct_reorder(tex,fav_ret)) %>%
  ggplot(aes(y = fav_ret, x = tex, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_minimal() +
  labs(title = ""The most retweeted and favorited #TidyTuesday tweets of 2018"",
       y = ""Number of retweets and favorites combined"",
       x = """",
       fill="""",
       caption = ""Data from the rtweet package."") +
  theme(legend.position = ""bottom"",
        axis.text=element_text(size=7),
        legend.text=element_text(size=7),
        title=element_text(size=8),
        text=element_text(family = ""Tahoma"")) 

#ggsave(filename=""tidytuesdaytweets.png"",path=here(""Week20190101_files""),width = 8, height = 4)

```



How have the number of tweets changed over time?

```{r}

rstats %>% 
  ts_plot(by = ""weeks"")

tidytuesday %>%
  ts_plot(by = ""days"")

```

Whose #rstats tweets were retweeted the most in 2018 on average?

```{r}

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>% 
  summarise(mean_retweets = mean(retweet_count),
            n = n()) %>%
  filter(n>19) %>%
  arrange(desc(mean_retweets)) %>%
  head(7)

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,mean_retweets)) %>%
  ggplot(aes(y = mean_retweets, x = screen_name, fill=n)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Whose #rstats tweets were retweeted most on average in 2018?"",
       subtitle = ""(of those with at least 10 tweets)"",
       y = ""Mean number of retweets of #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm""),
        axis.text = element_text(size = 10)) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",7)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 3,
            col=""white"") +
  scale_fill_gradient(low = myColors[1], high = myColors[5])

#ggsave(filename = ""rstatsavgretweets.png"", path = here(""Week20190101_files""),width = 8.5, height = 4)

```

Whose #rstats tweets were liked the most in 2018?

```{r}

library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(mean_favs = mean(favorite_count),
            n=n()) %>%
  filter(n>19) %>%
  arrange(desc(mean_favs)) %>%
  head(7)

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,mean_favs)) %>%
  ggplot(aes(y = mean_favs, x = screen_name, fill=n)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Whose #rstats tweets were liked most on average in 2018?"",
       subtitle = ""(of those with at least 10 tweets)"",
       y = ""Mean number of favorites for #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm""),
        axis.text = element_text(size = 10)) +
  scale_fill_gradient(low = myColors[1], high = myColors[5]) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",7)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 3,
            col=""white"")

#ggsave(filename = ""rstatsavglikes.png"", path = here(""Week20190101_files""),width = 8.5, height = 4)


```

```{r,echo=FALSE}
knitr::knit_exit()
```

What were the most liked tweets of 2018?

```{r}

toptweet <- tidytuesday %>% 
  select(screen_name,created_at,is_retweet,favorite_count, retweet_count,text,status_id) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  arrange(desc(favorite_count)) %>%
  head(10)

toptweet %>%
  mutate(tex = paste0(str_sub(text,1,60),"" ... ("",format(created_at,format = ""%b %d %Y""),"")""),
         screen_name = paste0(""@"",screen_name)) %>% 
  mutate(tex = fct_reorder(tex,favorite_count)) %>%
  ggplot(aes(y = favorite_count, x = tex, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_minimal() +
  labs(title = ""The most liked #TidyTuesday tweets of 2018"",
       y = ""Number of likes"",
       x = """",
       fill="""",
       caption = ""Data from the rtweet package."") +
  theme(legend.position = ""bottom"",
        axis.text=element_text(size=7),
        legend.text=element_text(size=7),
        title=element_text(size=8),
        text=element_text(family = ""Tahoma"")) 

#ggsave(filename=""tidytuesdaytweets.png"",path=here(""Week20190101_files""),width = 8, height = 4)

```
","2019-1"
"137",1649,"https://github.com/rakash/TidyTuesday-Social-data-project/blob/master/week1_2019.R","rakash","TidyTuesday-Social-data-project","week1_2019.R","library(tidyverse)
library(scales)
library(broom)
library(ggthemes)
library(plotly)
library(here)
library(rtweet)

install.packages(""yaml"")
install.packages(""rtweet"")

install.packages(""htmlwidgets"")

trace(utils:::unpackPkgZip, edit=TRUE)

update.packages()

.libPaths()

#githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/tidytuesday_tweets.rds?raw=true"")
#download.file(githubURL,""tidytuesday_tweets.rds"")
tidytuesday <- read_rds(""C:/Users/AKASHR/Documents/tidytuesday_tweets.rds"")


#githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/rstats_tweets.rds?raw=true"")
#download.file(githubURL,""rstats_tweets.rds"")
rstats <- readRDS(""C:/Users/AKASHR/Documents/rstats_tweets.rds"")
rstats

## 1. Whose #rstats tweets were retweeted the most in 2018?

install.packages(""ghibli"")
library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>% 
  summarise(total_retweets = sum(retweet_count),
            n=n()) %>%
  arrange(desc(total_retweets)) %>%
  head(5)

myColors <- as.list(ghibli_palette(""PonyoMedium"",n=5))
names(myColors) <- toppeople$screen_name

View(rstats)
View(toppeople)

library(ggplot2)
theme_set(theme_classic())

# Plot

ggplot(toppeople, aes(x=screen_name, y=n, label=n))+ 
  geom_point(stat='identity', fill=""black"", size=12)  +
  geom_segment(aes(y = 0, 
                   x = `screen_name`, 
                   yend = n, 
                   xend = `screen_name`), 
               color = ""black"") +
  geom_text(color=""white"", size=4) +
  labs(title=""Lollipop Chart"", 
       subtitle=""Whose #rstats tweets were retweeted the most in 2018?"")
       + 
  coord_flip()


## 2. Whose #rstats tweets were liked the most in 2018?


toplikes <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_favs = sum(favorite_count),
            n=n()) %>%
  arrange(desc(total_favs)) %>%
  head(5)


View(toplikes)

theme_set(theme_classic())

# Plot
ggplot(toplikes, aes(x=screen_name, y=total_favs)) + 
  geom_point(col=""tomato2"", size=3) + # Draw points
  geom_segment(aes(x=screen_name, 
                   xend=screen_name, 
                   y=min(total_favs), 
                   yend=max(total_favs)), 
               linetype=""dashed"", 
               size=0.1) +   # Draw dashed lines
  labs(title=""Dot Plot"", 
       subtitle=""Whose #rstats tweets were liked the most in 2018"", 
       caption=""source: mpg"") +  
  coord_flip()


## 3. Who had the most liked and retweeted #tidytuesday tweets of 2018?

View(tidytuesday)


toplikedtt <- tidytuesday %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text,favorite_count) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_favr = sum(retweet_count,favorite_count)) %>%
  arrange(desc(total_favr)) %>%
  head(10)

View(toplikedtt)

tt5 <- toplikedtt %>% head(5)
View(tt5)

library(ggplot2)
library(gganimate)
library(gapminder)
theme_set(theme_dark())  # pre-set the bw theme.

g <- ggplot(tt5, aes(screen_name, total_favr)) + 
  labs(subtitle=""Who had the most liked and retweeted #tidytuesday tweets of 2018?"",
       title=""Bubble chart"")

g + geom_jitter(aes(col=screen_name, size=total_favr)) + 
  geom_smooth(aes(col=screen_name), method=""lm"", se=F)

## 4. Total #rstats and #tidytuesday tweets over time in 2018 ?


rstats1 <- rstats %>% mutate(tweet_month = as.POSIXct(rstats$created_at))

rstats1$tweet_month <- format(rstats1$tweet_month,""%B"")

View(rstats1)
View(rtotal)

rtotal <- rstats1 %>% 
  select(created_at, tweet_month) %>%
  filter(created_at >= as.Date(""2018-01-01"")) %>%
  group_by(tweet_month) %>%
  summarise(month_tweets=n()) %>%
  arrange(desc(month_tweets))# %>%

theme_set(theme_light())

ggplot(rtotal, aes(tweet_month, month_tweets)) +
  geom_linerange(
    aes(x = tweet_month, ymin = 0, ymax = month_tweets), 
    color = ""lightgray"", size = 1.5
  )+
  geom_point(aes(color = tweet_month), size = 2)
  #ggpubr::color_palette(""jco"")


## TIdy tuesday 

View(tidytuesday)

ttotal <- tidytuesday %>% mutate(tweet_month = as.POSIXct(tidytuesday$created_at))

ttotal$tweet_month <- format(ttotal$tweet_month,""%B"")

View(ttotal)

ttotal <- ttotal %>% 
  select(created_at, tweet_month) %>%
  filter(created_at >= as.Date(""2018-01-01"")) %>%
  group_by(tweet_month) %>%
  summarise(month_tweets=n()) %>%
  arrange(desc(month_tweets))# %>%

View(ttotal)

theme_set(theme_dark())

# plot 
ggplot(ttotal , aes(x = tweet_month, y = month_tweets)) +
  geom_bar(fill = ""#0073C2FF"", stat = ""identity"") +
  geom_text(aes(label = month_tweets), vjust = -0.3) + 
  labs(title=""which month had the most #tidytuesday tweets of 2018?"")
","2019-1"
"138",1747,"https://github.com/tbobin/tidytuesday/blob/master/src/20180514_tidytuseday_week7.R","tbobin","tidytuesday","src/20180514_tidytuseday_week7.R","

library(tidyverse)
library(purrrlyr)
library(viridis)



df_sw_raw <- read.csv(""./Data/week7_starwars.csv"")

# replace all """" with NA
df_sw_raw[df_sw_raw == """" ] <- NA


# Not Fans #

# if not seen any of the films not a Fan
# if not self considered as fan not a Fan

# Star Wars: Episode I The Phantom Menace
# Star Wars: Episode II Attack of the Clones
# Star Wars: Episode III Revenge of the Sith
# Star Wars: Episode IV A New Hope
# Star Wars: Episode V The Empire Strikes Back
# Star Wars: Episode VI Return of the Jedi


df_sw_not_Fans <- df_sw_raw %>% 
  mutate(Fan = ifelse(
    (Have.you.seen.any.of.the.6.films.in.the.Star.Wars.franchise. == ""No"") |
      (Do.you.consider.yourself.to.be.a.fan.of.the.Star.Wars.film.franchise. == ""No"") |
      is.na(Do.you.consider.yourself.to.be.a.fan.of.the.Star.Wars.film.franchise.), ""No"", ""Yes""
    )) %>% 
  filter(Fan == ""No"") %>% 
  mutate(have.you.seen.Episode.I = ifelse(!is.na(Which.of.the.following.Star.Wars.films.have.you.seen..Please.select.all.that.apply.),
                                          1, 0 ),
         have.you.seen.Episode.II = ifelse(!is.na(X), 1, 0),
         have.you.seen.Episode.III = ifelse(!is.na(X.1), 1, 0),
         have.you.seen.Episode.IV = ifelse(!is.na(X.2), 1, 0),
         have.you.seen.Episode.V = ifelse(!is.na(X.3), 1, 0),
         have.you.seen.Episode.VI = ifelse(!is.na(X.4), 1, 0)) %>% 
  select(RespondentID, Fan:have.you.seen.Episode.VI)



df_Fan_seen_old <- df_sw_not_Fans %>% 
  select(have.you.seen.Episode.I:have.you.seen.Episode.III) %>% 
  by_row(sum, .collate = ""cols"", .to = ""sum_seen_old"")

df_Fan_seen_new <- df_sw_not_Fans %>% 
  select(have.you.seen.Episode.IV:have.you.seen.Episode.VI) %>% 
  by_row(sum, .collate = ""cols"", .to = ""sum_seen_new"")


df_sw_not_Fans <- cbind(df_sw_not_Fans, 
                        new = df_Fan_seen_new$sum_seen_new, 
                        old = df_Fan_seen_old$sum_seen_old) %>% 
  mutate(`one of episodes I - III and one of IV - VI` = ifelse(new > 0 & old > 0 , 1, 0),
         `only one of episodes I - III` = ifelse(new > 0 & old == 0 , 1, 0),
         `only one of episodes IV - VI`= ifelse(new == 0 & old > 0 , 1, 0),
         `no one` = ifelse(new == 0 & old == 0 , 1, 0))

df_sw_not_Fans %>% 
  select(RespondentID, `one of episodes I - III and one of IV - VI`:`no one`) %>% 
  gather(`one of episodes I - III and one of IV - VI`:`no one`,
         key = ""seen"", value = ""count"") %>% 
  mutate(seen = factor(seen, levels = c(""one of episodes I - III and one of IV - VI"", 
                                        ""only one of episodes I - III"", 
                                        ""only one of episodes IV - VI"",
                                        ""no one""), ordered = T)) %>% 
  filter(count > 0) %>% 
  ggplot(aes(x = seen, fill = seen)) + 
  geom_bar(stat = ""count"") +
  geom_text(aes(label = ..count..), stat = ""count"", vjust = -1) +
  viridis::scale_fill_viridis(discrete = T ) +
  scale_y_continuous(limits = c(0, 360)) +
  theme_minimal() +
  theme(panel.grid = element_blank(), 
        legend.position = """", 
        axis.text.y = element_blank()) +
  labs(y = """", x = """",
       title = ""Which episodes have people seen, that are not a fan of the franchise?"",
       subtitle = ""A fan is someone who constider himself as a fan, all others are not seen as a fan.
Most of the people, who consider themself not as as Fan and have seen at least one movie, have seen at least one of 
the new and one of the old episodes. The fewest people of this group saw only the old episodes."",
       caption = ""@T_bobin\nsource: https://github.com/rudeboybert/fivethirtyeight"") 
  



","2018-7"
"139",1748,"https://github.com/tbobin/tidytuesday/blob/master/src/20180511_tidytuseday_week6.R","tbobin","tidytuesday","src/20180511_tidytuseday_week6.R","

library(tidyverse)
library(readxl)
library(scales)
library(geojsonio)
library(broom)
library(viridis)
library(rgeos)
library(skimr)


# read in data
df_cof_raw <- readxl::read_xlsx(paste0(here::here(),""/data/week6_coffee_chains.xlsx""))

# let's start with stores in the US by Brand

df_cof_all <- df_cof_raw %>% 
  filter(Country == ""US"") %>% 
  group_by(`State/Province`, Brand) %>% 
  count()

# let's take a look at the data
df_cof_all %>% 
  ggplot(aes(n)) +
  geom_histogram(binwidth = 100)

df_cof_all %>% ungroup %>% select(-(`State/Province`)) %>% skim(n)

## From r-graph-gallery: https://www.r-graph-gallery.com/328-hexbin-map-of-the-usa/
# Hexbin available in the geojson format here: https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map. Download it and then:
spdf <- geojson_read(paste0(here::here(),""/data/us_states_hexgrid.geojson""),  what = ""sp"")

# I need to 'fortify' the data to be able to show it with ggplot2 (we need a data frame format)
# spdf@data = spdf@data %>% mutate(google_name = gsub("" \\(United States\\)"", """", google_name))
spdf_fortified <- tidy(spdf, region = ""iso3166_2"")


# join data with spital data
spdf_fortified <- spdf_fortified %>% 
  left_join(df_cof_all, by=c(""id"" = ""State/Province""))

#
centers <- cbind.data.frame(data.frame(gCentroid(spdf, byid=TRUE), id=spdf@data$iso3166_2))

# Prepare binning
spdf_fortified$bin = cut( spdf_fortified$n , breaks=c(seq(0,500,100), Inf), 
                          labels=c(""0-100"", ""101-200"", ""201-300"", ""301-400"", ""401-500"", ""500+"" ), include.lowest = TRUE )



# lets plot the Starbucks map
spdf_fortified %>% 
  filter(Brand == ""Starbucks"") %>% 
  ggplot(aes()) +
  geom_polygon(aes(fill = bin, x = long, y = lat, group = group) , size=0, alpha=0.9) +
  geom_text(data=centers, aes(x=x, y=y, label=id), color=""white"", size=3, alpha=0.6) +
  scale_fill_viridis(option = ""viridis"", discrete=TRUE,
                     name = """") +
  theme_minimal() +
  labs(title = ""Starbucks Coffee stores per State"",
       caption = ""@T_Bobin \nsource: kaggle.com"")+
  theme(panel.border=element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        legend.position = ""bottom"") +
  coord_map() 

#ggsave(""/graphs/20180512_tidyTuseday_week_6.png"", width = 10, dpi = 600)

","2018-6"
"140",1,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week1/R/tw1_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(ggrepel)

tidy_data <- dir(here(""week1"", ""data""), full.names = TRUE, pattern = ""us_avg"") %>%
  read_excel() %>%
  gather(year, avg_tuition, -State) %>%
  rename(state = State)


nat_avg <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  group_by(year) %>%
  summarize(avg_tuition = mean(avg_tuition)) %>%
  mutate(state = ""National Average"")


plot_data <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  left_join(select(nat_avg, year, nat_avg = avg_tuition), by = ""year"") %>%
  bind_rows(nat_avg)

labels <- plot_data %>%
  group_by(state) %>%
  filter(all(avg_tuition > nat_avg)) %>%
  pull(state) %>%
  unique()

plot <- plot_data %>%
  ggplot(., aes(x = year, y = avg_tuition, group = state)) +
  geom_text_repel(data = filter(plot_data, state %in% labels, year == ""2015-16""), aes(label = state), direction = ""y"", nudge_x = 0.1, segment.size = 0.1, hjust = 0, family = ""Oxygen"", size = 3) +
  geom_path(color = ""grey50"", size = 0.5, alpha = 0.5) +
  geom_point(color = ""grey50"") +
  geom_path(data = nat_avg, color = ""red"", size = 1) +
  geom_point(data = nat_avg, color = ""red"") +
  scale_y_continuous(labels = scales::dollar) +
  labs(x = NULL, y = NULL, title = ""Comparison of the average US tuition growth between 2005 and 2015"", subtitle = ""Eastern and Northeastern students consistently face tutition above the national average, indicated by the red line."", caption = ""\nData: http://trends.collegeboard.org/ | Graphic: @jakekaupp"") +
  theme_minimal(base_family = ""Oswald Light"") +
  theme(panel.grid.minor = element_blank())

ggsave(plot, filename = glue('{here(""week1"")}/tidyweek-{Sys.Date()}.png'), height = 8, width = 6, dpi = 300)

","2018-1"
"141",2,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week11/R/tw11_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)

raw_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week11_fifa_audience.csv"") %>% 
  select(-X1)

font_add_google(""Oswald"",""Oswald-Light"", regular.wt = 300)
font_add_google(""Scope One"",""Scope One"")

showtext_auto()

vplayout <- function(x, y) viewport(width=11/3, height=8.5, layout.pos.row = x, layout.pos.col = y)

build_treemap <- function(x, y, size)  {
  
  title <- set_names(c(""Population Share"", ""TV Audience Share"", ""GDP Weighted Share""), c(""population_share"",""tv_audience_share"", ""gdp_weighted_share""))
  
  treemap(raw_data,
          index = c(""confederation"",""country""),
          vSize = size,
          vColor = ""confederation"",
          type = ""categorical"",
          title = title[size],
          title.legend = """",
          fontfamily.title = ""Oswald-Light"",
          fontsize.labels = c(20, 10),
          fontfamily.labels = ""Oswald-Light"",
          fontcolor.labels = ""#f0f0f0"",
          lowerbound.cex.labels = 1,
          bg.labels = 0,
          inflate.labels = FALSE,
          border.col = ""white"",
          border.lwds = 1,
          position.legend = ""none"",
          palette = nord(""baie_mouton""),
          align.labels = list(c(""left"",""top""), c(""right"",""bottom"")),
          drop.unused.levels = TRUE,
          vp = vplayout(x,y))
  
  
  
}

fifa_maps <- function() {
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(3, 3, heights = c(0.1, 0.8, 0.1))))
  par(mai=c(0,0,0,0))
  
  grid.text(""Comparing FIFA Share Differences by Confederation and Country"", x = 0.1, hjust = 0, vp = vplayout(1,1), gp = gpar(fontfamily = ""Oswald-Light"", fontsize = 30))
  build_treemap(2, 1, ""population_share"")
  build_treemap(2, 2, ""tv_audience_share"")
  build_treemap(2, 3, ""gdp_weighted_share"")
  grid.text(""Data: fivethirtyeight.com | Graphic: @jakekaupp"", x = 0.5, vp = vplayout(3,3), gp = gpar(fontfamily = ""Scope One"", fontsize = 10))
  
}

png(here(""week11"", ""Fifa Treemaps.png""), width = 11, height=8.5, units = ""in"", res = 100)
fifa_maps()
dev.off()

","2018-11"
"142",3,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week12/R/tw12_plot.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(ggridges)
library(nord)
library(here)
library(showtext)

font_add_google(""Oswald"", ""Oswald"", regular.wt = 400)
font_add_google(""Scope One"", ""Scope One"")

trend_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_google_trends.csv"", skip = 2, col_names = TRUE) %>% 
  set_names(str_extract(names(.), ""(?<=Hurricane )(\\w+)|(Day)"")) %>% 
  rename(Date = Day) %>% 
  mutate(source = ""Google Trends"") %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

mediacloud_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_mediacloud_hurricanes.csv"", col_names = TRUE) %>% 
  mutate(source = ""Online News"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_tv_hurricanes.csv"") %>% 
  mutate(source = ""TV"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

all_data <- bind_rows(trend_data, mediacloud_data, tv_data) %>%
  gather(hurricane, value, -Date, - source) %>% 
  set_names(tolower(names(.)))

showtext_auto()

plot <- ggplot(all_data, aes(x = date, y = source)) +
  geom_ridgeline(aes(height = value, fill = factor(hurricane)), size = 0.1, scale = 0.8, alpha = 0.8) +
  labs(title = ""On nearly every form of media, hurricanes that hit mainland US received more sustained coverage than Maria in Puerto Rico"",
       subtitle = ""Ridgeline plots of normalized media shares (TV, Online News and Google Trends)"",
       caption = ""Data: fivethirtyeight | Graphic: @jakekaupp"",
       y = NULL,
       x = NULL) +
  scale_x_date(expand = c(0,0)) +
  scale_fill_nord(name = ""Hurricane"", palette = ""lumina"") +
  theme_jk(plot_title_size = 28, subtitle_size = 24, base_size = 20, caption_size = 12,  grid = ""X"") +
  theme(axis.text.y = element_text(vjust = -2))

ggsave(plot, filename = here(""week12"", ""ROCK YOU LIKE A HURRICANE.png""), width = 6, height = 3)
","2018-12"
"143",4,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week18/R/tw18_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)
library(readxl)
library(ggalt)
library(jkmisc)


raw_data <- read_xlsx(here(""week18"", ""data"", ""week18_dallas_animals.xlsx""), sheet = 1)

data <- raw_data %>% 
  filter(animal_type %in% c(""CAT"",""DOG""), mo_year == ""2017"") %>% 
  count(animal_type, month, mo_year, outcome_type) %>% 
  group_by(animal_type, month, mo_year) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  select(-n) %>% 
  filter(outcome_type %in% c(""EUTHANIZED"",""ADOPTION"")) %>% 
  mutate_if(is.character, tolower) %>%
  spread(outcome_type, percent) %>% 
  mutate_if(is.character, tools::toTitleCase) %>% 
  mutate(month = ifelse(month == ""may"", ""May"", month)) %>% 
  arrange(month) %>% 
  complete(month = month.abb, mo_year, animal_type, fill = list(adoption = NA, euthanized = NA)) %>% 
  mutate(ratio = adoption/euthanized) %>% 
  mutate(month = factor(month, month.abb))



ggplot(data, aes(x = month, y = ratio, group = animal_type, color = animal_type)) +
  geom_hline(yintercept = 1.0, size = 0.1, color = ""firebrick"", linetype = ""dashed"") +
  geom_line(size = 0.5) +
  geom_text(data = filter(data, month == ""Sep""), aes(label = animal_type), nudge_x = 0.3, family = ""Oswald"") +
  theme_jk(grid = ""XY"") +
  scale_color_nord(""victory_bonds"") +
  labs(x = NULL, y = ""Ratio of Adopted/Euthanized"", title = ""2017 was a bad time to be a cat in a shelter"", subtitle = ""Cats in the shelters were euthanized more than adopted compared to dogs."") +
  theme(legend.position = ""none"")
  



","2018-18"
"144",5,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week2/R/tw2_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(janitor)
library(rvest)
library(nord)
library(jkmisc)
library(viridis)

# Function to scrape the top avg cap salary by player ----
pull_position_data <- function(year, position) {
  
  Sys.sleep(5)
  
  url <- glue(""http://www.spotrac.com/nfl/positional/{year}/{position}"")
  
  read_html(url) %>% 
    html_nodes(""#main > div.teams > table:nth-child(6)"") %>% 
    html_table() %>%
    flatten_df() %>% 
    set_names(c(""rank"",""player"",""cap_dollars"", ""cap_percent""))
}


# Formatter for 538 year labels 
labels_538 <- function(labels) {
  labels_out <- sprintf(""20%s"", str_sub(labels, 3, 4))
  labels_out <- c(labels_out[1], glue(""'{str_sub(labels_out[-1], 3, 4)}""))
  return(labels_out)
}

# Create the data scaffold 
years <- 2011:2018
positions <- c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"",""defensive-end"",""cornerback"",""defensive-tackle"", ""inside-linebacker"", ""outside-linebacker"", ""free-safety"", ""strong-safety"", ""kicker"",""punter"",""long-snapper"")

scaffold <- tibble(year = years,
                   position = list(positions)) %>% 
  unnest() 

# Populate the scaffold
if(!file.exists(here(""week2"", ""data"", ""position_cap_data_named.RDS""))) {
  
  scaffold <- scaffold %>% 
    mutate(data = map2(year, position, ~pull_position_data(.x, .y))) %>% 
    unnest() %>% 
    mutate_at(c(""cap_dollars"", ""cap_percent""), parse_number) %>% 
    mutate(side = case_when(position %in% c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"") ~ ""Offense"",
                            position %in% c(""kicker"",""punter"",""long-snapper"") ~ ""Special Teams"",
                            TRUE ~ ""Defense""))
  
  
  # Save it to avoid re-scraping 
  saveRDS(scaffold, file = here(""week2"", ""data"", ""position_cap_data_named.RDS""))
} else {
  
  scaffold <- readRDS(here(""week2"", ""data"", ""position_cap_data_named.RDS""))
  
}


# Make data for the plot
plot_data <- scaffold %>% 
  group_by(year, position, side) %>% 
  top_n(16, cap_dollars) %>% 
  summarize(avg_pay = mean(cap_dollars))
  
# Make a heatmap!
ggplot(plot_data, aes(x = year, y = position, fill = avg_pay)) +
  geom_tile(color = ""white"", size = 0.1) +
  coord_equal() +
  labs(x = NULL, y = NULL, title = ""The Fullback Gets No Respect"", subtitle = ""Average cap value of the 16 highest payed players in all positions"", caption = ""Data: http://www.spotrac.com/ | Graphic: @jakekaupp"") +
  scale_x_continuous(labels = labels_538, breaks = 2011:2018) +
  scale_y_discrete(labels = function(x) str_to_title(gsub(""[[:punct:]]"", "" "", x))) +
  scale_fill_viridis(discrete = FALSE, labels = scales::dollar, name = ""Average Salary"") +
  theme_jk(grid = FALSE, base_size = 14)

ggsave(here(""week2"", ""tw2_heatmap.png""), width = 8, height = 8)
","2018-2"
"145",6,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week3/R/tw3_plot.R","library(tidyverse)
library(here)
library(readxl)
library(jkmisc)

# Read in the data
mortality_data <- dir(here(""week3"",""data""), pattern = ""global"", full.names = TRUE) %>% 
  read_excel()


# Tidy up the data
tidy_mort <- mortality_data %>% 
  gather(cause_of_death, percentage, -country:-year) %>% 
  mutate(cause_of_death = trimws(str_remove(cause_of_death, ""\\(\\%\\)""))) %>% 
  mutate(percentage = ifelse(is.na(percentage), NA, percentage/100))

# Get just the data pertaining to suicides
suicide_data <- tidy_mort %>% 
  filter(cause_of_death == ""Suicide"", !is.na(country_code))

# Get the World percentage
global_rate <- suicide_data %>% 
  filter(country == ""World"") %>% 
  select(year, percentage)

# Get the top 40 problem countries, those with the suicide rate constantly over the world average (note the all statement in the filter)
problem_countries <- suicide_data %>% 
  filter(country != ""World"") %>% 
  left_join(global_rate, by = ""year"") %>% 
  group_by(country) %>% 
  filter(all(percentage.x > percentage.y)) %>% 
  summarize(percentage = mean(percentage.x, na.rm = TRUE)) %>% 
  top_n(40, percentage) %>% 
  arrange(desc(percentage)) %>% 
  pull(country)

# Create the data to make the plot, and arrange descending by the overall avg rate of suicide
plot_data <- suicide_data %>% 
  filter(country %in% problem_countries) %>% 
  mutate(country = factor(country, problem_countries))

# Create the sad plot
sad_plot <- ggplot(plot_data, aes(x = year, y = percentage)) +
  geom_segment(aes(x = min(year), xend = max(year), y = 0, yend = 0)) +
  geom_area(fill = ""steelblue4"") +
  geom_path(color = ""grey30"", size = 0.2) +
  geom_area(data = global_rate, fill = ""steelblue3"") +
  geom_path(data = global_rate, color = ""grey30"", size = 0.2) +
  facet_wrap(~country, nrow = 5) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = ""Countries Coping With the Tradgedy and Pain of Suicide"",
       subtitle = ""Dark blue indicates suicide rate by year, Light blue fill indicates the global average suicide rate by year."",
       x = NULL,
       y = NULL,
       caption = ""Data: ourworldindata.org | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"")

# Save the sad plot
ggsave(here(""week3"",""tw3_sad_plot.png""), sad_plot, width = 16, height = 10)
","2018-3"
"146",7,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week4/R/tw4_plot.R","library(tidyverse)
library(here)
library(jkmisc)
library(scales)
library(ggiraph)
library(glue)
library(waffle)

make_tooltip <- function(occupation, female, male, income_gap, ...) {
 
  glue('<div class=""tipchart"">
      <h3>{occupation}</h3>
      <h4>Mens taxable income {ifelse(income_gap <= 1, percent(1-round(income_gap, 2)), percent(round(income_gap, 2)))} {ifelse(income_gap <= 1, ""less"", ""more"")} than womens</h4>
      <table>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Male Taxable Income:</td>
      <td class=""tiptext"">{dollar(male)}</td>
      </tr>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Female Taxable Income:</td>
      <td class=""tiptext"">{dollar(female)}</td>
      </tr>
      </table>
      </div>')
  
}


# Read in the data
income_data <- dir(here(""week4"",""data""), pattern = ""salary"", full.names = TRUE) %>% 
  read_csv(locale = locale(""en""))
 
# Clean occupation up a bit.  Some rouge unicodes in there.
tidy_gap <- income_data %>% 
  mutate(occupation = iconv(occupation, ""UTF-8"", ""UTF-8"",sub='')) %>% 
  spread(gender, average_taxable_income) %>%
  set_names(tolower(names(.))) %>% 
  group_by(occupation) %>% 
  summarize_at(c(""female"", ""male""), sum, na.rm = TRUE) %>% 
  filter(female != 0, male != 0) %>% 
  mutate(income_gap = male/female)

plot_data <- tidy_gap %>% 
 mutate(fill = if_else(income_gap >= 1, ""grey80"", ""#ffd700""),
         alpha = if_else(income_gap >= 1, 0.2, 1)) %>% 
  mutate(tooltip = pmap(., make_tooltip)) %>% 
  mutate(tooltip = gsub(""\\\n"", """", tooltip)) %>% 
  mutate(tooltip = gsub(""'"", """", tooltip)) %>% 
  mutate(idx = row_number())

tooltip_css <- ""background-color:white;padding:10px;border-radius:20px 20px 20px 20px;border-color:black;border-style:solid;border-width:1px""

plot <- ggplot(plot_data, aes(x = female, y = male, fill = fill)) +
  geom_segment(x = 0, xend = 600000, y = 0, yend = 600000, size = 0.05, color = ""grey80"") +
  geom_point_interactive(aes(alpha = alpha, tooltip = tooltip, data_id = idx), shape = 21, color = ""grey30"", size = 3) +
  scale_y_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_x_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Gender Differences in Taxble Income in Australia"",
       subtitle = str_wrap(""Average male taxable income plotted against average female taxable income by occupation. Yellow dots indicate occupations where women have more taxable income than their male counterparts, 
       line indicates income equality. Hover over points for occupation, % difference and detailed income."", 100),
       caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme_jk()

ggiraph(ggobj = plot, width_svg = 9, width = 1, tooltip_extra_css = tooltip_css)

waffle_data <- tidy_gap %>% 
  ungroup() %>% 
  mutate(category = case_when(income_gap > 1 ~ ""Men have more income"",
                              income_gap < 1 ~ ""Women have more income""))%>% 
  count(category) %>% 
  pull(n) %>% 
  set_names(., c(""Men have more income"", ""Women have more income""))

waffle(waffle_data, 
       rows = 14,
       size = 1,
       colors = c(""dodgerblue3"", ""deeppink""), 
       legend_pos = ""bottom"", 
       title = ""Out of 1092 occupations on record, men have more taxable income than women in 1011 of them.  That's 92.5% of occupations for those counting at home."") + 
  theme_jk() +
  labs(caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme(axis.text = element_blank(),
        legend.position = ""bottom"")
","2018-4"
"147",8,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week5/R/tw_5plot.R","library(tidyverse)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)


census_data <- dir(here(""week5"", ""data""), full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

# Lets look at commuting!
commuting_data <- census_data %>% 
  select(census_id, state, county, total_pop, drive:mean_commute)

# Despacito is 3:47 in length
despacito_length <- 3 + 47/60

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") 

# Calculate the how many despacitos the average commute has
despacito_commute <- commuting_data %>% 
  mutate(despacitos = mean_commute/despacito_length,
         id = ifelse(str_length(as.character(census_id)) < 5, glue(""0{census_id}""), as.character(census_id))) %>% 
  right_join(us_map)


# Make the map!
map <- ggplot() +
 geom_map(data = us_map, map = us_map,
                    aes(x = long, y = lat, map_id = id),
                    color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = despacito_commute, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = despacitos),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis(name=""How many despactios?"", na.value = viridis(5, option = ""cividis"")[3], option = 'cividis', breaks = seq(1,12,2)) +
  labs(title = ""Just how much do you like your commute?"",
       subtitle = str_wrap(""What if your commute was defined by hearing a song on repeat?  
                           What if that song was the most streamed song on the planet, Despacito? 
                           Illustrated below is the average number of times you'd hear it on your way home across the US."", 80),
       caption = ""Data: census.gov | Graphic: @jakekaupp"") +
  coord_map() +
  theme_map(base_family=""Scope One"", 
            base_size = 16) +
  theme(legend.title = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        plot.caption = element_text(size = 10),
        legend.position = c(0.9,0.1))

ggsave(here(""week5"", ""tw5_choropleth map.png""), width = 10, height = 6)


","2018-5"
"148",9,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week6/R/tw_6plot.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(glue)
library(fuzzyjoin)
library(stringi)
library(ggalt)
library(jkmisc)
library(nord)



provinces <- set_names(c(""Alberta"", ""British Columbia"", ""Manitoba"", ""New Brunswick"", ""Newfoundland and Labrador"",
                         ""Nova Scotia"", ""Northwest Territories"", ""Nunavut"", ""Ontario"", ""Prince Edward Island"", ""Quebec"",
                         ""Saskatchewan"", ""Yukon""),
                       c(""AB"", ""BC"", ""MB"", ""NB"", ""NL"", ""NS"", ""NT"", ""NU"", ""ON"", ""PE"", ""QC"", ""SK"", ""YT""))

# Just get the Tims data just for Canada
tim_hortons <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""xlsx"") %>% 
  read_excel(sheet = ""timhorton"") %>% 
  filter(country == ""ca"") %>% 
  rename(province = state) 

# Counts at the City/Province level
tims_city_prov <- tim_hortons %>% 
  count(city, province)

# Counts at the National level
tims_national <- tim_hortons %>% 
  count(province) %>% 
  mutate(color = ifelse(province == ""ON"", nord(""victory_bonds"", 1), ""grey50""))

national <- ggplot(tims_national, aes(x = reorder(province,n), y = n)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0.01,0.05),  breaks = scales::pretty_breaks()) +
  scale_x_discrete(labels = function(x) provinces[x]) +
  coord_flip() +
  labs(x = NULL, y = NULL, title = ""Ontario, we have a problem...."", subtitle = ""The highest number of Tim Hortons per province goes to Ontario, a land where you can't even get an oat cake."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = national, here(""week6"", ""National Tims.png""), width = 10, height = 6)

census_2011 <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""2011 census"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  remove_empty(""rows"") %>% 
  select(city = geographic_name, population = population_2011) %>% 
  mutate(province = stri_extract_last_regex(city, ""\\(([A-Za-z\\.]+?)\\)""),
         city = stri_replace_all_regex(city, ""\\((.*?)\\)"", """"),
         province = gsub(""[[:punct:]]"", """", province)) %>% 
  mutate(province = case_when(province == ""Que"" ~ ""QC"",
                              province == ""Ont"" ~ ""ON"",
                              province == ""Man"" ~ ""MB"",
                              province == ""Sask"" ~ ""SK"",
                              province == ""Alta"" ~ ""AB"",
                              province == ""NWT"" ~ ""NT"",
                              province == ""Nvt"" ~ ""NU"",
                              province == ""PEI"" ~ ""PE"",
                              TRUE ~ province)) %>% 
  mutate_if(is.character, trimws)



tims_density <- regex_right_join(census_2011, tims_city_prov,  by = c(""city"", ""province""), ignore_case = TRUE) 


plot_data <- tims_density %>% 
  select(population, city = city.y, province = province.x, n) %>% 
  group_by(city, province) %>% 
  summarize_at(c(""n"", ""population""), sum, na.rm = TRUE) %>% 
  ungroup() %>% 
  filter(population != 0, n > 1, population > 10000) %>% 
  mutate(density = (n/(population/1000))) %>% 
  top_n(25, density) %>% 
  mutate(color = ifelse(density == max(density), nord(""victory_bonds"", 1), ""grey50""))


most_tims <- ggplot(plot_data, aes(x = reorder(city, density), y = density)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0,0.01),  breaks = scales::pretty_breaks(), limits = c(0,1.2)) +
  coord_flip() +
  labs(y = ""Number of Tim Hortons stores per 1,000 people"", x = NULL, title = ""However, the title of most Tim Hortons per capita belongs to Cold Lake, Alberta"", 
       subtitle = ""When looking at towns/cities with population > 10,000 and with more than two Tim Hortons. \nMy hometown of Truro, Nova Scotia comes in a puzzling fourth."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = most_tims, here(""week6"", ""Most Tims.png""), width = 10, height = 6)

","2018-6"
"149",10,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2018/week7/R/tw_7plot.R","library(tidyverse)
library(here)
library(janitor)
library(likert)
library(jkmisc)
library(nord)

star_wars <- dir(here(""week7"", ""data""), pattern = ""StarWars"", full.names = TRUE) %>% 
  read_csv() 

clean_names <- stringi::stri_trans_general(names(star_wars), ""latin-ascii"") %>% 
  gsub(""[^\\x{00}-\\x{7f}]"", """", ., perl = TRUE) %>% 
  clean_names()

star_wars <- set_names(star_wars, clean_names) 

headers <- slice(star_wars, 1) %>% 
  flatten_chr()

clean_names <- gsub(""X\\d+"", NA_character_, clean_names) %>% 
  enframe() %>% 
  fill(value) %>% 
  pull(value)


shiny_clean_names <- paste(clean_names, headers, sep = ""|"")

long_star_wars <- set_names(star_wars, c(""RespondentID"", shiny_clean_names[-1])) %>% 
  slice(-1) %>% 
  gather(item, value, -1) %>% 
  separate(item, c(""question"", ""category""), sep = ""\\|"") %>% 
  mutate(category = if_else(category == ""Response"", NA_character_, category)) %>% 
  mutate(index = group_indices(., question))


plot_data <- long_star_wars %>% 
  filter(index == 12) %>% 
  replace_na(list(value = ""Unfamiliar (N/A)"")) %>% 
  filter(value != ""Unfamiliar (N/A)"") %>% 
  spread(category, value) %>% 
  mutate_at(vars(-RespondentID, -question, -index), function(x)
    factor(x, 
            levels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""),
            labels = 1:5
    )) 
            
            
likert_data <- plot_data %>% 
  select(-RespondentID, -question, -index) %>%
  as.data.frame() %>% 
  likert()


ggplot2::update_geom_defaults(""text"", list(family = ""Scope One"", size = 4))
  
plot <- likert.bar.plot(likert_data) + 
  scale_fill_nord(""mountain_forms"", labels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""), name = ""Response"") +
  labs(title = ""The Favorability Rankings of Star Wars Characters"", subtitle = ""People look favourably upon the scruffy nerf herder, and would give a ride to the EVIL RAISIN THAT SHOOTS LIGHTNING FROM HIS HANDS before the goofy gungan."") +
  theme_jk(grid = ""XY"") +
  theme(plot.title = element_text(family = ""Oswald""))

ggsave(here(""week7"", ""tw7_likert.png""), width = 16, height = 10)
  
  
 
","2018-7"
"150",11,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week1/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)


# week-of-month function
wom <- function(date) { 
  first <- wday(as.Date(paste(year(date),month(date),1,sep=""-"")))
  return((mday(date)+(first-2)) %/% 7+1)
}

# Get the TidyTuesday Tweets Data
tt_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""tidytuesday_tweets.rds""))

# Get the R tweet data 
r_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""rstats_tweets.rds""))

# Most that tweet about R tweet about the r4ds tidy tuesday.
no_rstats <- anti_join(tt_tweet_data, r_tweet_data, by = ""screen_name"") %>% 
  mutate(rstats_tag = case_when(grepl(""rstats"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""r4ds"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""visualization"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""data"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""code"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""plot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""chart"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""graph"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""drob"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""ggplot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""rstudio"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""model"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""median"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""average"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""week \\d+"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""@thomas_mock"", text, ignore.case = TRUE) ~ TRUE,
                                TRUE ~ FALSE)) %>% 
  mutate(rstats_tag = case_when(screen_name %in% c(""NosyOwl"", ""sebastianhwells"", ""JenniferCai7"", ""matthwong"",
                                                   ""scrite_jones"", ""jrosenblum123"", ""zlipp"") ~ TRUE,
                                TRUE ~ rstats_tag)) %>% 
  filter(rstats_tag == FALSE)
  

plot_data <- anti_join(tt_tweet_data, no_rstats, by = ""screen_name"") %>% 
  mutate(created_at = as_date(created_at)) %>% 
  mutate(day = wday(created_at, label = TRUE, abbr = FALSE),
         week = wom(created_at),
         iweek = isoweek(created_at),
         month = month(created_at, label =  TRUE, abbr = FALSE),
         year = year(created_at))


count(plot_data, day, iweek) %>% 
  complete(day, iweek = 1:52, fill = list(n = NA)) %>% 
  ggplot(aes(x = iweek, y = day, fill = n)) +
  geom_tile(color = ""white"", size = 0.1) +
  scale_fill_viridis_c(""Tweet Frequency"", option = ""cividis"", na.value = ""grey95"", labels = seq(0,25,5), breaks = seq(0,25,5), limits = c(0,25)) +
  coord_equal() +
  labs(title = ""Tidy Tuesday or Tardy Tuesday?"",
       subtitle = ""A glance at when the community decides to submit their work."",
       y = NULL,
       x = ""Week of the Year"",
       caption = ""Data: rtweet | Analysis: @jakekaupp"") +
  scale_x_continuous(limits = c(1, 53), breaks = c(1,10,20,30,40,50), expand = c(0, 0)) +
  theme_jk(grid = FALSE, ticks = FALSE) +
  theme(legend.position = c(0.5,-0.7),
        legend.direction = ""horizontal"",
        legend.title = element_text(family = ""Scope One"", vjust = 0.8))

ggsave(here(""2019"", ""week1"",""tidy_or_tardy.png""), width = 8, height = 4)
","2019-1"
"151",12,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week10/R/analysis.R","library(tidyverse)
library(jkmisc)
library(ggrepel)
library(here)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")


plot_data <- jobs_gender %>% 
  select(-year) %>% 
  group_by(occupation, major_category, minor_category) %>% 
  summarize_all(mean, na.rm = TRUE) %>% 
  filter(str_detect(occupation, ""engineer""), str_detect(major_category, ""Engineering"")) %>% 
  mutate(diff = if_else((total_earnings_female - total_earnings_male) > 0, ""firebrick"", ""grey80"")) %>% 
  mutate(alpha = if_else(diff == ""firebrick"", 1, 0.2)) %>% 
  gather(variable, value, starts_with(""total_earnings_"")) %>% 
  mutate(variable = factor(variable, c(""total_earnings_male"", ""total_earnings_female""), c(""Men"", ""Women"")))
 
slope_data <- build_slopegraph(plot_data, ""variable"", ""value"", ""occupation"") %>% 
  left_join(distinct(plot_data, occupation, diff, alpha), by = c(""group"" = ""occupation"")) %>% 
  mutate(group = case_when(str_detect(group, ""Mining"") ~ ""Mining Engineers"",
                                str_detect(group, ""Computer"") ~ ""Computer Engineers"",
                                str_detect(group, ""Electrical"") ~ ""Electrical Engineers"",
                                str_detect(group, ""Marine"") ~ ""Marine Engineers"",
                                str_detect(group, ""Industrial"") ~ ""Industrial Engineers"",
                           TRUE ~ str_to_title(group))) %>% 
  mutate(group = str_replace(group, ""Engineers"", ""Engineering""))


labels <- pretty(slope_data$y, 9)
breaks <- pretty(slope_data$ypos, 5)


plot <- ggplot(slope_data, aes(x = x, y = ypos, group = group, color = diff)) +
  geom_point() +
  geom_line() +
  geom_label_repel(data = filter(slope_data, x == ""Women""), aes(label = group), direction = ""y"", hjust = 0, nudge_x = 1, segment.alpha = 0.3, family = ""Oswald"", label.size = 0, fill = ""white"") +
  theme_jk(grid = ""XY"") +
  expand_limits(x = c(0, 5)) +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_y_continuous(labels = scales::dollar(labels), breaks = breaks, limits = range(breaks)) +
  theme(panel.grid.major.x = element_line(linetype = ""dashed"", color = ""black"")) +
  labs(x = NULL,
       y = NULL,
       title = ""The Unnecessary and Unethical Pay Disparity in Engineering."",
       subtitle = str_wrap(""A slopegraph presenting the average total earnings from 2014-2016 for men and women across engineering disciplines.  Mining Engineering is the only discipline with women earning more than men on average."", 70),
       caption = ""Data: Census Bureau | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week10"", ""tw10_plot.png""), plot, width = 6.5, height = 9, type = ""cairo"")
","2019-10"
"152",13,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week10/R/helpers.R","# Functions from an old friend.
# https://github.com/jkeirstead/r-slopegraph/blob/master/slopegraph.r

build_slopegraph <- function(df, x, y, group, min.space=0.05) {
  
  ## First rename the columns for consistency
  ids <- match(c(x, y, group), names(df))
  
  df <- df[,ids]
  
  names(df) <- c(""x"", ""y"", ""group"")
  
  ## Expand grid to ensure every combination has a defined value
  tmp <- expand.grid(x=unique(df$x), group=unique(df$group))
  
  tmp <- merge(df, tmp, all.y=TRUE)
  
  df <- mutate(tmp, y=ifelse(is.na(y), 0, y))
  
  spaced_sort(df, min.space=min.space)
  
}



spaced_sort <- function(df, min.space=0.05) {
  ## Define a minimum spacing (5% of full data range)
  min.space <- min.space*diff(range(df$y))
  
  ## Transform the data
  
  df <- split(df, ""x"") %>% 
    map_df(~calc_spaced_offset(.x, min.space))
  
  return(df)
}

##' Calculates the vertical offset between successive data points
##' 
##' @param df a data frame representing a single year of data
##' @param min.space the minimum spacing between y values
##' @return a data frame
calc_spaced_offset <- function(df, min.space) {
  
  ## Sort by value
  ord <- order(df$y, decreasing=T)
  ## Calculate the difference between adjacent values
  delta <- -1*diff(df$y[ord])
  ## Adjust to ensure that minimum space requirement is met 
  offset <- (min.space - delta)
  offset <- replace(offset, offset<0, 0)
  ## Add a trailing zero for the lowest value
  offset <- c(offset, 0)
  ## Calculate the offset needed to be added to each point
  ## as a cumulative sum of previous values
  offset <- rev(cumsum(rev(offset)))
  ## Assemble and return the new data frame
  df.new <- data.frame(group=df$group[ord],
                       x=df$x[ord],
                       y=df$y[ord],
                       ypos=offset+df$y[ord])
  return(df.new)
}
","2019-10"
"153",14,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week11/R/analysis.R","library(tidyverse)
library(jkmisc)
library(here)

board_games <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")

prolific <- board_games %>% 
  separate_rows(designer, sep = "","") %>% 
  filter(!str_detect(designer, ""Uncredited""), !str_detect(designer, ""Jr|III""), year_published >= 1990) %>% 
  group_by(designer) %>% 
  filter(n() >= 10) %>% 
  group_by(designer, year_published) %>% 
  summarize(year_avg_rating = mean(average_rating, na.rm = TRUE),
            games_published = n()) 

top_rated <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, overall_rating) %>% 
  pull(designer)

top_publishing <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, total_games) %>% 
  pull(designer)

overall_avg <- prolific %>% 
  group_by(year_published) %>% 
  summarize(year_avg_rating = mean(year_avg_rating, na.rm = TRUE),
            designer = ""Overall"")


plot_data <- prolific %>%
  bind_rows(overall_avg) %>% 
  mutate(color = case_when(designer == top_rated ~ ""#eebd31"" ,
                           designer == ""Overall"" ~ ""firebrick"",
                           designer == top_publishing ~ ""dodgerblue"",
                           TRUE ~ ""black""),
         alpha = case_when(designer == top_rated ~ 1,
                           designer == ""Overall"" ~ 1,
                           designer == top_publishing ~ 1,
                           TRUE ~ 0.05),
         size = case_when(designer == top_rated ~ 0.5,
                           designer == ""Overall"" ~ 0.5,
                           designer == top_publishing ~ 0.5,
                           TRUE ~ 0.3),
         point_size = case_when(designer == top_rated ~ 2,
                          designer == ""Overall"" ~ 2,
                          designer == top_publishing ~ 2,
                          TRUE ~ 1),
         line = case_when(designer == top_rated ~ ""solid"",
                           designer == ""Overall"" ~ ""dashed"",
                           designer == top_publishing ~ ""solid"",
                           TRUE ~ ""solid""))

plot <- ggplot(plot_data, aes(x = year_published, y = year_avg_rating, group = designer)) +
  geom_path(aes(color = color, alpha = alpha, linetype = line, size = size)) +
  geom_point(aes(fill = color, alpha = alpha, size = point_size), color = ""white"", shape = 21) +
  annotate(""label"", x = 1989.8, y = 2, label = ""Most Prolific: Reiner Knizia with 229 published games."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""dodgerblue"", hjust = 0) +
  annotate(""segment"", x = 1990, xend = 1990, y = 2.3, yend = 5.5, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""dodgerblue"") +
  annotate(""label"", x = 2002, y = 9, label = ""Highest Average Rating: Mark H. Walker with a 7.70 rating."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""#eebd31"") +
  annotate(""segment"", x = 2002, xend = 2002.8, y = 8.8, yend = 7.7, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""#eebd31"") +
  scale_y_continuous(limits = c(0, 10), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_color_identity() +
  scale_linetype_identity() +
  scale_size_identity() +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL,
       title = ""It's Not A Habit, It's Cool, I'm a Prolific Game Designer"",
       subtitle = str_wrap(""A comparison from 1990 to 2016 of the the top rated and top published designer amongst those with 10 or more published games. Red dashed line represents the overall average designer rating."", 150),
       caption = ""Data: Board Game Geek | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"")

ggsave(here(""2019"",""week11"", ""tw11_plot.png""), width = 12, height = 6)
","2019-11"
"154",15,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week13/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(fs)
library(janitor)
library(jkmisc)

pet_licenses <- here(""2019"", ""week13"", ""data"") %>% 
  dir_ls(regexp = ""Seattle"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  mutate_at(""license_issue_date"", mdy)

burst_name <- function(df) { 
  
  df %>% 
    distinct(license_issue_date) %>% 
    pull(license_issue_date) %>% 
    kleinberg()
    
  }

out <- pet_licenses %>% 
  filter(!is.na(animals_name)) %>% 
  mutate(animals_name = str_to_lower(animals_name)) %>% 
  group_by(animals_name) %>% 
  filter(n() >= 100) %>% 
  nest() %>% 
  mutate(bursts = map(data, burst_name)) %>% 
  unnest(bursts) %>% 
  arrange(desc(animals_name), level) %>% 
  mutate(id = ntile(animals_name, 1)) %>%
  mutate(color = case_when(level == 1 ~ ""grey50"",
                           level == 2 ~ ""#6baed6"",
                           level == 3 ~ ""#3182bd"",
                           level == 4 ~ ""#08519c""),
         alpha = case_when(level == 1 ~ 0.5,
                           level == 2 ~ 1,
                           level == 3 ~ 1,
                           level == 4 ~ 1)) %>% 
  ungroup()

facet_labels <- out %>% 
  group_by(id) %>% 
  summarize(label = sprintf(""%s to %s"", last(str_sub(animals_name, 1, 1)), first(str_sub(animals_name, 1, 1)))) %>% 
  pull(label) %>% 
  set_names(., sort(unique(out$id)))

order <- out %>% 
  filter(level == 1) %>% 
  arrange(desc(start)) %>% 
  pull(animals_name)

plot <- ggplot(out) +
  geom_segment(aes(x = start, xend = end, y = factor(animals_name, order), yend = factor(animals_name, order), color = color, alpha = alpha), size = 4, lineend = ""square"") +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_x_date(limits = c(ymd(""2006/01/01""),ymd(""2019/01/01"")),  date_breaks = ""1 year"", date_labels = ""%Y"", expand = c(0.02, 0)) +
  scale_y_discrete(position = ""right"") +
  theme_jk(grid = ""XY"") +
  labs(x = NULL,
       y = NULL,
       title = ""What is it, Lassie? 'Bark! Bark-bark-bark! Bark-bark!' What, Timmy's fallen in the well?"",
       subtitle = str_wrap(""Illustrated below is the recorded use of and bursts in popularity of registered pet names (frequency of use > 100) in Seattle from 2006 to 2019.  The grey bar indicates the duration the name is in use, and the blue segments indicate bursts of increased use of the name.  Darker blue segments represent repeated bursts indicating an increased intensity of use."", 100),
       caption = ""Data: seattle.gov | Graphic: @jakekaupp"")

ggsave(here(""2019"",""week13"",""tw13_plot.png""), plot, width = 8, height = 10, type = ""cairo-png"")
","2019-13"
"155",16,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week14/R/analysis.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(here)
library(patchwork)

bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

clean_bikes <- bike_traffic %>% 
  mutate(date = mdy_hms(date),
         month = month(date),
         year = year(date)) %>% 
  filter(between(year, 2014, 2018))

by_year <- clean_bikes %>% 
  group_by(year, month, crossing) %>% 
  summarize(total_bikes = sum(bike_count, na.rm = TRUE)) 

glyph <- ggplot(by_year, aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 1, aes(color = crossing)) +
  facet_grid(year ~ month, labeller = labeller(.cols = set_names(month.abb, 1:12)), switch = ""y"") +
  scale_color_manual(values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
  labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180),
        legend.position = ""none"")

main <- by_year %>% 
  filter(year == 2015, month == 1) %>% 
  ggplot(aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 3, aes(color = crossing)) +
  scale_color_manual(""Crossing"", values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
   labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180))

plot <- wrap_plots(list(main, glyph), widths = c(0.25, 0.75)) +
  plot_annotation(title = ""Annual Patterns in Seatle Bicycle Traffic"", 
                  subtitle = str_wrap(""This chart is glyph plot using multiple parallel coordinates plots to illustrate the monthly bike traffic at Seattle crossings.  A  colored dot represents each crossing and vertical position represents the total number of riders counted each month.  You can observe the year over year trends, as well as see which crossings experience cyclical patterns and which remain stable."", 155),
                  theme = theme_jk())

ggsave(here(""2019"", ""week14"", ""tw14_plot.png""), plot, width = 12, height = 6)
","2019-14"
"156",17,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week15/R/analysis.R","library(tidyverse)
library(lubridate)
library(ggbeeswarm)
library(here)
library(jkmisc)
library(nord)

player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")


plot_data <- player_dob %>% 
  select(name, date_of_birth) %>% 
  left_join(grand_slams, by = ""name"") %>% 
  mutate(age = interval(date_of_birth, tournament_date)/years(1)) %>% 
  group_by(name) %>% 
  filter(n()>1)
  

order <- plot_data %>% 
  group_by(name) %>% 
  filter(rolling_win_count == max(rolling_win_count)) %>% 
  arrange(rolling_win_count) %>% 
  pull(name)
  

plot <- ggplot(plot_data, aes(x = age, y = factor(name, order), size = rolling_win_count, color = gender, alpha = rolling_win_count)) +
  geom_point(aes(group = name)) + 
  facet_wrap(~gender, scales = ""free_y"") +
  scale_color_manual(values = c(""#C01E65"",""#117AB3"")) +
  scale_size_area(""Rolling Win Count"") +
  guides(size = guide_legend(override.aes = list(shape = 21, color = ""black"")), color = FALSE, alpha = FALSE) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  labs(x = NULL,
       y = NULL,
       title = ""Bright Stardom or Fading Obscurity: Looking at Players Major Wins Across their Careers."",
       subtitle = str_wrap(""The chart plots cumulative major wins against player age. Size and transparency of each point are mapped to the cumulative number of majors won.  Looking at the data, we can see the hot streaks in individual players, as well as the dominance of certain champions."", 110),
       caption = ""Data: wikipedia | Graphic: @jakekaupp"")
  
ggsave(here(""2019"",""week15"",""tw15_plot.png""), type = ""cairo"", width = 10, height = 12)
","2019-15"
"157",18,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week16/R/analysis.R","library(tidyverse)
library(here) 
library(jkmisc)
library(ggalt)
library(grid)
library(Cairo)

dogs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

png(file = here(""2019"", ""week16"", ""tw16_plot.png""), width = 4, height = 4, units = ""in"", res = 300, type = ""cairo"")
                       
ggplot(dogs, aes(x = avg_weight, y = avg_neck)) +
  geom_xspline(size = 1) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 0.5, size = 2) +
  geom_text(data = filter(dogs, year == min(year)), aes(label = year), hjust = 0, nudge_x = 0.1, nudge_y = 0.01, family = ""Oswald"", size = 3) +
  geom_text(data = filter(dogs, year == max(year)), aes(label = year), hjust = 1, nudge_x = -0.1, family = ""Oswald"", size = 3) +
  annotate(""segment"", arrow = arrow(length = unit(0.2, ""cm""), type = ""closed""), x = 20.48, xend = 20.2, y = 44.3, yend = 44.03) +
  scale_y_continuous(limits = c(42, 45), breaks = 42:45) +
  expand_limits(x = c(17.5, 21)) +
  labs(title = ""Fit as a butcher's dog"",
       subtitle = ""Characteristics of dogs registered with the UK's\nKennel Club, average when fully grown"",
       x = bquote(""Weight*, kg""),
       y = NULL,
       caption = ""Sources: Kennel Club;\n The Economist "") +
  theme_jk(grid = ""XY"") +
  theme(plot.caption = element_text(hjust = -0.1))

grid.text(expression(paste(Neck~size, "", "", cm^""\u2020"")), x = 0.1, y = 0.78, gp = gpar(fontfamily = ""Oswald"", cex = 0.8))
grid.text(bquote(""* Where at leat 50 are registered per year""), x = 0.98, y = 0.075, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)
grid.text(expression(""\u2020""~Where~at~least~100~are~registered~per~year), x = 0.98, y = 0.040, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)

dev.off()
","2019-16"
"158",19,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week17/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

plot_data <- tidy_anime %>% 
  mutate(title = coalesce(title_english, name)) %>% 
  mutate(end_date = if_else(is.na(end_date), as.Date(""2019-04-01""), end_date)) %>% 
  mutate(interval = interval(start_date, end_date)) %>% 
  filter(type != ""Unknown"") %>% 
  distinct(animeID, .keep_all = TRUE) 


scaffold <- tibble(year = rep(1917:2019, each = 6),
       type = rep(c(""Movie"", ""Music"", ""ONA"", ""OVA"", ""Special"", ""TV""), length(1917:2019))) 

timeline <- scaffold %>% 
  mutate(count = map2_dbl(year, type, ~nrow(filter(plot_data, ymd(sprintf(""%s/01/01"", .x)) %within% interval , type == .y))))

order <- timeline %>% 
  filter(year == last(year)) %>% 
  arrange(desc(count)) %>% 
  pull(type)

# Area ----
area <- timeline %>% 
  mutate(type = factor(type, order, order)) %>% 
  ggplot(aes(x = year, y = count)) +
  geom_area(aes(fill = type)) +
  scale_fill_manual(""Anime Type"", values = tol6qualitative) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_y_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Fourty Years of Growth: The Rapid Rise of Anime"",
       subtitle = str_wrap(""The area chart below presents the number of anime titles released from 1919 to the present by release type.  Anime releases have increased over 400% since the 1980s, to meet the increasing demand driven by the invention of the VCR, the internet and the rise of streaming media services."", 95),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE))

# Popularity vs Score Hexbin ----
hex <- ggplot(plot_data, aes(x = popularity, y = score)) +
  geom_hex() +
  facet_wrap(~type, nrow = 1) +
  scale_fill_viridis_c(option = ""plasma"") +
  scale_x_continuous(trans = ""reverse"", breaks = scales::pretty_breaks(), labels = c("""","""",""Higher\nPopularity"", """", ""Lower\nPopularity"", """")) +
  scale_y_continuous(breaks = scales::pretty_breaks(), limits = c(0,10)) +
  guides(fill = guide_colorbar(title = ""Titles per Hex""), alpha =""none"") +
  labs(x = NULL, 
       y = NULL,
       title = ""The Relationship Between Ratings and Popularity on MyAnimeList"",
       subtitle = str_wrap(""The chart below plots the ratings score (out of 10) against popularity (rank) for all anime titles and anime types.  The data were hexangonally binned to illustrate areas of high occurance. It appears that a relationship may exist between ratings and popularity, warranting further analysis."", 100),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"",""week17"",""tw17_hex.png""), hex, width = 8, height = 6)

ggsave(here(""2019"",""week17"",""tw17_area.png""), area, width = 8, height = 6)

","2019-17"
"159",20,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week18/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


flower <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.2) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar()) +
  coord_polar() +
  labs(x = NULL,
       y = NULL,
       title = ""Overall"") +
  theme_jk(dark = FALSE, grid = ""X"", strip_text_size = 10, plot_title_size = 14) +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

petals <- flower +
  aes(group = year) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  labs(title = ""By Species"") +
  facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7) 

legend <- plot_data %>% 
  filter(binomial_name == ""Setophaga fusca"") %>% 
  ggplot(aes(x = month, y = percent, fill = binomial_name, group = year)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.1) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  annotate(""text"", x = 11, y = 0.8, label = ""One year of\ncollisions in October"", family = ""Scope One"", size = 3, hjust = 0) +
  annotate(""segment"", x = 10.8, y = 0.8, xend = 10, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  annotate(""text"", x = 3.5, y = 0.8, label = ""Multiple years of\ncollisions in May"", family = ""Scope One"", size = 3) +
  annotate(""segment"", x = 3.8, y = 0.8, xend = 5, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""How to Interpret This Chart"",
       subtitle = str_wrap(""A flower represents the recorded total collisions of each bird species with the individual petals representing the normalized events during each year (from 0-1).  The position of the petals indicates the month or months collisions occur, with overlaps indicating repeated year-over-year collisions."", 70)) +
  guides(fill = guide_colorbar()) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- wrap_plots(flower / legend, petals, ncol = 2, widths = c(1, 2)) +
  plot_annotation(title = ""Seasonality of Bird Collisions in Chicago"",
                  subtitle = str_wrap(""Presented below is a petal chart of of bird collisions, with instructions on how to interpret this chart in the lower left.  The upper left flower represents collisions recorded across all years and species, with individual species presented as small multiple flowers on the right."", 220),
                  caption = ""Data: Winger et al. (2019) Nocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. Proceedings of the Royal Society B 286(1900): 20190364. https://doi.org/10.1098/rspb.2019.0364 | Graphic: @jakekaupp"",
      theme = theme_jk())

ggsave(here(""2019"",""week18"", ""tw18_plot.png""), out, width = 16, height = 10, type = ""cairo"")



","2019-18"
"160",21,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week18/R/experiment.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)


bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))

petals <- plot_data %>% 
  filter(n != 0) %>% 
  split(list(.$year, .$month, .$binomial_name), drop = TRUE) %>% 
  map(~complete(.x, year, binomial_name, month = 1:12, fill = list(n = 0, percent = 0))) %>% 
  map(~geom_area(data = .x, aes(color = binomial_name), size = 0.2, alpha = 0.1))


base_plot <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- base_plot + petals + facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7)


ggsave(here(""2019"",""week18"", ""test.png""), plot = out)

","2019-18"
"161",22,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week19/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(fs)
library(jkmisc)
library(janitor)
library(countrycode)
library(patchwork)

ratio_data <- here(""2019"", ""week19"", ""data"") %>% 
  dir_ls(regexp = ""student_teacher_ratio"") %>% 
  read_excel(na = c("".."")) %>% 
  set_names(tolower(names(.))) %>% 
  gather(year, ratio, -1:-2,convert = TRUE)



plot_region <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, group = region, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~region, nrow = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") 
  
  }

plot_continent <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~continent, ncol = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    scale_shape_identity() +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") +
    theme(strip.text = element_blank())
  
}

plot_data <- ratio_data %>% 
  filter(type == ""Countries"") %>% 
  mutate(country_code = countrycode(country, ""country.name"", ""iso3c"")) %>% 
  mutate(region = countrycode(country_code, ""iso3c"", ""region"")) %>% 
  mutate(continent = countrycode(country_code, ""iso3c"", ""continent"")) %>% 
  filter(!is.na(region))

colors <- set_names(c(""#171635"", ""#00225D"", ""#763262"", ""#CA7508"", ""#E9A621""), c(unique(plot_data$continent)))

individual <- plot_data %>% 
  group_by(year, region, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_region) 

summary <- plot_data %>% 
  group_by(year, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_continent) 
  
plots <- map2(summary, individual, ~wrap_plots(.x, .y, nrow = 1, widths = c(1, 1)))
  
out <- wrap_plots(plots, ncol = 1) +
  plot_annotation(title = ""Working to Two Sigma: Student Teacher Ratios Improving Since the 1970s"",
                  subtitle = str_wrap(""Illustrated below is the average student to teacher ratio across each continent (left column) and region (right column).  Continent and region assigned from iso3c coding of country name and are consistent with the World Bank Dvelopment Indicators."", 210),
                  caption = ""Data: UNESCO Institute of Statistics | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"",""week19"",""tw19_plot.png""), out, width = 16, height = 10)
","2019-19"
"162",23,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week2/R/analysis.R","library(tidyverse)
library(ggraph)
library(tidygraph)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)
library(nord)

set.seed(42)

source(here(""2019"", ""week2"", ""R"", ""functions.R""))

# Read data from github repo
tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"") %>% 
  rename(title_id = titleId,
         season_number = seasonNumber) %>% 
  mutate(year = year(date))

# Make this into a nodes tibble
list <- tv_data %>% 
  split(.$year) %>% 
  map(share_packed_circle)

out <- wrap_plots(list, ncol = 10, nrow = 3) +
  plot_annotation(title = ""The Evolution and Differentiation of Dramas Across the Golden Age of Television"",
                  subtitle = str_wrap(""This chart presents a time series of circle-packed network representations of the television dramas.  
                                      The larger dark blue circle represents the year, light blue represents the genre (Action, Comedy, etc.) and the pale pink represents the individual program. 
                                      The area of each circle (node) is porportional to the sum of the audience share of the smaller circles within (child nodes)."", 180),
                  caption = ""data: IMDb | graphic: @jakekaupp"",
                  theme = theme_jk(plot_title_size  = 22, subtitle_size = 14) %+replace% theme(plot.background = element_rect(fill =""#2E3440""),
                                                      text = element_text(color = ""white"")))
 
ggsave(here(""2019"",""week2"", ""tt_week2.png""), out, width = 16, height = 8)
","2019-2"
"163",24,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week2/R/functions.R","share_packed_circle <- function(df) {
 
  nodes <- make_nodes(df)
  
  edges <- make_edges(df)
 
  mygraph <- tbl_graph(nodes = nodes, edges = edges)
  
  # Make the plot
  plot <- ggraph(mygraph, layout = 'circlepack', weight = ""size"") + 
    geom_node_circle(aes(fill = depth)) +
    theme_void() +
    labs(title = unique(df$year)) +
    coord_equal() +
    scale_fill_nord(""lumina"", discrete = FALSE, reverse = TRUE) +
    #scale_fill_viridis(option = ""plasma"") +
    theme(legend.position = ""none"", 
          plot.background = element_rect(fill = ""#4C566A""),
          plot.title = element_text(family = ""Oswald"", hjust = 0.5, color = ""white""),
          )
  
  return(plot)
}


make_nodes <- function(df) {
  
  size <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    distinct(genres, title, share) %>% 
    rename(name = title, size = share)
  
  genre_size <- size %>% 
    group_by(genres) %>% 
    summarize(size = sum(size)) %>% 
    rename(name = genres)
  
  title_size <- size %>% 
    ungroup() %>% 
    distinct(name, size) %>% 
    mutate(size = size)
  
  total_size <- df %>% 
    distinct(title, share) %>% 
    summarize(name = as.character(unique(df$year)),
              size = sum(share))
  
  sizes <- bind_rows(genre_size, title_size, total_size)
  
  nodes <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    gather(variable, name, title, genres, year) %>% 
    arrange(variable, name) %>% 
    distinct(name) %>% 
    left_join(sizes, by = ""name"") %>% 
    mutate(size = if_else(size == 0, 0.001, size)) %>% 
    arrange(size)
  
  return(nodes)
  
  
}

make_edges <- function(df) {
  
  base <- tibble(from = as.character(unique(df$year)), to = unique(df$genres))
  
  inner <- df %>% 
    select(from = genres, to = title) %>% 
    distinct() 
  
  edges <- bind_rows(base, inner) 
  
  return(edges)
  
}
","2019-2"
"164",25,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week20/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(rcrossref)
library(ggbeeswarm)
library(jkmisc)


# Not re-downloading things, the citation count pulls take 2hrs.
if (length(dir_ls(here(""2019"", ""week20"", ""data""))) <= 0) {
 
  nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
  nobel_winners_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")
  
  saveRDS(nobel_winners, here(""2019"", ""week20"", ""data"", ""nobel_winners.RDS""))
  
  saveRDS(nobel_winners_all_pubs, here(""2019"", ""week20"", ""data"", ""nobel_winners_all_pubs.RDS""))

  
} else {
  
  nobel_winners <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners.RDS"") %>% 
    readRDS()
  
  nobel_winners_all_pubs <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners_all_pubs.RDS"") %>% 
    readRDS()
 
}


if (length(dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""cite_count"")) <= 0) {

  dois <- nobel_winners_all_pubs$doi

  list  <- split(dois, rep(1:ceiling(length(dois)/50), each=50)[1:length(dois)])

wait_cr_citation_count <- function(doi, index, list_len) {
  
  print(sprintf(""%s complete"", scales::percent(index/list_len)))
  
  Sys.sleep(1)
  
  cr_citation_count(doi)
  
}

cite_count <- imap_dfr(list, ~wait_cr_citation_count(.x, .y, length = length(list)))

saveRDS(cite_count, here(""2019"", ""week20"", ""data"", ""cite_count.RDS"")) 

} else {
  
cite_count <- readRDS(here(""2019"", ""week20"", ""data"", ""cite_count.RDS""))
  
}

highlights <- c(""einstein, a"", ""hill, av"", ""heeger, a"")

plot_data <- nobel_winners_all_pubs %>%
  left_join(cite_count) %>%
  distinct(laureate_id, paper_id, .keep_all = TRUE) %>%
  select(pub_year, laureate_name, is_prize_winning_paper, count, category) %>% 
  replace_na(list(count = 0)) %>% 
  group_by(laureate_name, pub_year, category) %>%
  summarize(count = sum(count)) %>% 
  group_by(laureate_name) %>% 
  mutate(rolling_sum = cumsum(count)) %>% 
  mutate(color = if_else(laureate_name %in% highlights, ""#F24534"", ""#21344F""),
         alpha = if_else(laureate_name %in% highlights, 1, 0.2))


everyone <- filter(plot_data, laureate_name %notin% highlights)

focus <- filter(plot_data, laureate_name %in% highlights) %>% 
  ungroup() %>% 
  mutate(laureate_name = case_when(laureate_name == ""einstein, a"" ~ ""Einstein, A"",
                                   laureate_name == ""hill, av"" ~ ""Hill, AV"",
                                   laureate_name == ""heeger, a"" ~ ""Heeger, A"")) %>% 
  group_by(laureate_name)


plot <- ggplot(plot_data, aes(x = pub_year, y = rolling_sum, group = laureate_name)) +
  geom_step(aes(color = color, alpha = alpha)) +
  geom_step(data = focus, aes(color = color, alpha = alpha)) +
  geom_text(data = filter(focus, pub_year == last(pub_year)), aes(color = color, alpha = alpha, label = laureate_name), x = 2018, family = ""Oswald"", hjust = 0) +
  scale_x_continuous(limits = c(1900, 2100), breaks = c(1900, 1925, 1950, 1975, 2000, 2018)) +
  scale_y_continuous(breaks = scales::pretty_breaks(), labels = scales::number) +
  scale_color_identity() +
  scale_alpha_identity() +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  labs(x = NULL,
       y = NULL,
       title = ""Growth Patterns in How Often Nobel Prize Winning Researchers Are Cited"",
       subtitle = str_wrap(""Cummulative citation count by year (1900-2018).  Highlighted are A. Heeger (conductive polymers), A.V. Hill (heat and work in muscle) and A. Einstein (photoelecric effect). Each exhibit different citation patterns, likely attributed to the continued relevance and impact of their work."", 150),
       caption = ""Data: Li, Jichao; Yin, Yian; Fortunato, Santo; Wang Dashun, 2018, 'A dataset of publication records for Nobel laureates', https://doi.org/10.7910/DVN/6NJ5RN, Harvard Dataverse. | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"", ""week20"", ""tw20_plot.png""), plot, width = 12, height = 6)

","2019-20"
"165",26,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week21/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(fs)
library(janitor)
library(jkmisc)
library(patchwork)


# Plotting Function to make separate ordered stacked bars by group----
make_bars <- function(df, pals) {
  
  order <- df %>% 
    arrange(desc(other)) %>% 
    pull(country)
  
  labs <- c(""HIC"" = ""High Income Group"",
            ""UMI"" = ""Upper Middle Income Group"",
            ""LMI"" = ""Lower Middle Income Group"",
            ""LI"" = ""Low Income Group"")
  
  
  df %>% 
    gather(type, value, c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste"")) %>% 
    mutate(type = factor(type, c(""other"", ""inadequate_waste"", ""plastic_waste"", ""littered_waste""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
    mutate(country = factor(country, order)) %>% 
    mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
    ggplot() +
    geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
    coord_flip() +
    scale_fill_manual("""", values = pals) +
    scale_alpha_identity() +
    scale_y_continuous(expand = c(0,0.05), labels = scales::percent) +
    labs(x = NULL, y = NULL) +
    facet_wrap(~economic_status, scales = ""free_y"", labeller = as_labeller(labs)) +
    theme_jk(grid = FALSE) +
    theme(legend.direction = ""horizontal"")
  
}


# Function to extract ggplot legends ----
extract_legend <- function(ggp){
  
  tmp <- ggplot_gtable(ggplot_build(ggp))
  
  leg <- which(map_lgl(tmp$grobs, function(x) x$name == ""guide-box""))
  
  legend <- tmp$grobs[[leg]]
  
  return(legend)}


# Read in Coastal Waste Data----
# Plastic waste inputs from land into the ocean
# BY JENNA R. JAMBECK, ROLAND GEYER, CHRIS WILCOX, THEODORE R. SIEGLER, MIRIAM PERRYMAN, ANTHONY ANDRADY, RAMANI NARAYAN, KARA LAVENDER LAW
# 
# SCIENCE13 FEB 2015 : 768-771

coastal_waste <- here(""2019"", ""week21"", ""data"") %>% 
  dir_ls(regexp = ""xlsx"") %>% 
  read_excel() %>% 
  clean_names() %>% 
  set_names(str_remove(names(.), ""_*[0-9]$"")) %>% 
  mutate(country = str_remove(country, ""[0-9]"")) %>% 
  mutate(country = case_when(str_detect(country, ""Palestine"") ~ ""Palestine"",
                             str_detect(country, ""Korea, South"") ~ ""South Korea"",
                             str_detect(country, ""Korea, North"") ~ ""North Korea"",
                             str_detect(country, ""Congo"") ~ ""Congo"",
                             TRUE ~ country)) %>% 
  filter(!grepl(""Burma"", country)) %>% 
  filter(complete.cases(.)) %>% 
  mutate(other = 100 - (percent_plastic_in_waste_stream + percent_inadequately_managed_waste + percent_littered_waste)) %>% 
  rename(plastic_waste = percent_plastic_in_waste_stream, inadequate_waste  = percent_inadequately_managed_waste, littered_waste = percent_littered_waste) %>% 
  mutate_at(c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste""), function(x) x/100) %>% 
  mutate(other = if_else(other < 0, 0, other)) %>% 
  mutate(total_waste = waste_generation_kg_day * 365/1000,
         total_plastic_waste = total_waste * plastic_waste,
         total_inadequate_waste = total_waste * inadequate_waste,
         total_littered =  total_waste * littered_waste,
         other_waste = total_waste * other)


# Palette for plot----
pal <- c(""#F5F0F6"", ""#629460"", ""#385F71"", ""#2B4162"")

avg <- coastal_waste %>% 
  summarize(total_waste = mean(total_waste, na.rm = TRUE),
            other_waste  = mean(other_waste, na.rm = TRUE),
            total_plastic_waste  = mean(total_plastic_waste, na.rm = TRUE),
            total_inadequate_waste = mean(total_inadequate_waste, na.rm = TRUE),
            total_littered = mean(total_littered, na.rm = TRUE)) %>% 
  mutate(country = ""Global Average"")


order <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  pull(country) 



overall_mismanaged <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  gather(type, value, c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered"")) %>% 
  mutate(type = factor(type,  c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
  mutate(country = factor(country, rev(order))) %>% 
  mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
  mutate(strip = ""Top 50 Producers & Global Average of Total Indequately Managed Waste (kg)"") %>% 
  ggplot() +
  geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
  coord_flip() +
  scale_fill_manual("""", values = pal) +
  scale_alpha_identity() +
  scale_y_continuous(expand = c(0,0.05), labels = scales::comma) +
  labs(x = NULL, y = NULL) +
  facet_wrap(~strip) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""none"")


# Make plots----
list <- coastal_waste %>% 
  split(.$economic_status) %>% 
  map(make_bars, pal)

# Extract legend----
legend <- extract_legend(list[[1]])

# Remove legend from list of plots----
list <- map(list, ~.x + theme(legend.position = ""none""))
  
# Finish plot----
out <- (overall_mismanaged + wrap_plots(list[c(""HIC"", ""UMI"", ""LMI"", ""LI"")], nrow = 1) + plot_layout(widths = c(0.3, 0.7))) / legend + plot_layout(heights = c(0.95, 0.05)) +
  plot_annotation(title = ""The Relationship Between World Bank Income Classification and Mismanaged Waste"",
                  subtitle = str_wrap(""Illustrated below is the percentage of waste by category for each country by World Bank income classification.  The lower the classification, the higher the mismanaged waste.  Much of this mismanaged waste (especially plastics) ends up in waterways that ultimately lead to our oceans, suggesting that global income inequality plays a role in ocean pollution by hampering the implementation of effective waste management strategies."", 240),
                  caption = ""Data: Jambeck, Jenna R., et al. 'Plastic waste inputs from land into the ocean.' Science 347.6223 (2015): 768-771. | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"", ""week21"", ""tw21_plot.png""), out, width = 19, height = 12)



","2019-21"
"166",27,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week22/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(ggridges)
library(tidytext)
library(countrycode)
library(ggwordcloud)
library(patchwork)

source(here(""2019"", ""week22"", ""R"", ""packed_bars.R""))

wine_ratings <- here(""2019"", ""week22"", ""data"", ""winemag-data-130k-v2.csv"") %>% 
  read_csv()

wine_counts <- wine_ratings %>% 
  count(country) %>% 
  mutate(max_rel_val = n/sum(n)) %>% 
  filter(!is.na(country))
 
summary_ratings <- wine_ratings %>% 
  group_by(country) %>% 
  summarize_at(c(""points"",""price""), mean, na.rm = TRUE) %>% 
  filter(!is.na(country))

summary_data <- left_join(wine_counts, summary_ratings)

plot_data <- pack_bars(summary_data, number_rows = 4, max_rel_val)

packed_bar <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"") +
  geom_text(data = filter(plot_data, fill == ""#4B384C""), aes(x = xmin, y = (ymin + ymax)/2, label = country), family = ""Oswald"", color = ""white"", nudge_x = 0.01, hjust = 0) +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

word_counts <- wine_ratings %>%
  select(country, description) %>%
  group_by(country) %>% 
  filter(n() > 2) %>% 
  filter(!is.na(country)) %>% 
  unnest_tokens(word, description) %>% 
  anti_join(stop_words) %>% 
  count(country, word) %>% 
  mutate(word = trimws(word)) %>% 
  filter(!str_detect(word, ""[0-9]""), !str_detect(word, ""aroma|wine|note|nose|notes|aromas|drink|drinks|feel|feels|finish"")) %>% 
  group_by(country) %>% 
  top_n(300, n) 

clouds <- word_counts %>% 
  ungroup() %>% 
  mutate(iso2 = tolower(countrycode(country, ""country.name"", ""iso2c"")),
         iso2 = if_else(country == ""England"", ""gb"", iso2)) %>% 
  filter(country %in%  c(""US"", ""France"", ""Italy"", ""Spain"")) %>% 
  mutate(country = factor(country, levels = c(""US"", ""France"", ""Italy"", ""Spain"")),
         iso2 = factor(iso2, levels = c(""us"",""fr"", ""it"", ""es""))) %>% 
  group_by(iso2) %>% 
  nest() %>% 
  arrange(iso2) %>% 
  mutate(clouds =  map2(iso2, data, create_wc))

word_clouds <- wrap_plots(clouds$clouds, ncol = 1) 

out <- packed_bar + word_clouds +
  plot_annotation(title = ""Wine-ing: The Top 4 Countries and What Reviewers Say About Their Wines"",
                  subtitle = str_wrap(""On the left, a packed bar chart showing the % of reviewed wines by country.  On the right, wordclouds of the top 300 most frequent terms used in reviews."", 100),
                  caption = ""Data: Kaggle via WineEnthusiast | Graphic: @jakekaupp"",
                  theme = theme_jk()
                  )

ggsave(here('2019', ""week22"", ""tw22_plot.png""), out, width = 8, height = 12)

ggsave(here('2019', ""week22"", ""packed_bar.png""), packed_bar + labs(title = ""Top 4 Countries Reviewed as Packed Bar Chart"",
                                                                   subtitle = str_wrap(""The visualizion below is a packed bar chart, developed by Xan Gregg.  It combines the ordered nature of a bar chart with the total view and condensed nature of a treemap.  Colour denotes the focus, while the each gray sections represents each other reviwed country. This gives a sense of how many secondary categories there are, their magnitude and distribution. Additionally, since they are on the same scale of the focused bars we can even estimate some of the values from the length they span on the axis."", 100)), width = 8, height = 6)
","2019-22"
"167",28,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week22/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- summary_data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- summary_data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}


create_wc <- function(iso2, data) {
  
  cntry_mask <- png::readPNG(here(""2019"", ""week22"", ""data"", ""png maps"", iso2, ""1024.png""))
  
  ggplot(data, aes(label = word, size = n)) +
    geom_text_wordcloud(family = ""Oswald"", mask = cntry_mask, rm_outside = TRUE) +
    scale_radius(range = c(0, 40)) +
    theme_jk() 
  
  
}
","2019-22"
"168",29,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week23/R/analysis.R","library(tidyverse)
library(glue)
library(rvest)
library(xml2)
library(lubridate)
library(here)
library(jkmisc)



#Scraping functions----

get_urls <- function(sitemap_url) {
  
  read_xml(sitemap_url) %>%
    xml_children() %>% 
    xml_children() %>% 
    xml_text() %>% 
    keep(~str_detect(.x, ""https://www.theramenrater.com/[0-9]{4}/[0-9]{2}/[0-9]{1,}/\\w+""))
  
}

get_post_title <- function(url, idx, rows) {
  
  print(sprintf(""Progress: %s/%s"", idx, rows))
  
  read_html(url) %>% 
    html_node("".entry-title"") %>% 
    html_text()
  
  
}

slowly_get_post_title <- slowly(~ get_post_title(.x, .y, rows), rate = rate_delay(pause = 0.5), quiet = TRUE)

#Week of month
wom <- function(date) { # week-of-month
  first <- wday(as.Date(paste(year(date), month(date), 1, sep=""-"")))
  return((mday(date) + (first - 2)) %/% 7 + 1)
}

#Plotting functions----
month_outline <- function(df) {
  
  top1 <- with(df, tibble(x = min(wmonth) - 0.5,
                          xend = wday[day == min(day)] - 0.5,
                          y = wmonth[day == min(day)] + 0.5,
                          yend = wmonth[day == min(day)] + 0.5,
                          line = ""top1"")) 
  
  top2 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                          xend = max(wday) + 0.5,
                          y = min(wmonth) - 0.5,
                          yend = min(wmonth) - 0.5,
                          line = ""top2"")) 
  
  left1 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                           xend = wday[day == min(day)] - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = min(wmonth) - 0.5,
                           line = ""left1""))
  
  left2 <- with(df, tibble(x = min(wmonth) - 0.5,
                           xend = min(wmonth) - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = wmonth[day == max(day)] + 0.5,
                           line = ""left2""))
  

  right1 <- with(df, tibble(x = max(wday) + 0.5,
                            xend = max(wday) + 0.5,
                            y = min(wmonth) - 0.5,
                            yend = wmonth[day == max(day)] - 0.5,
                            line = ""right1""))
  
  right2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                            xend = wday[day == max(day)] + 0.5,
                            y = wmonth[day == max(day)] - 0.5,
                            yend = wmonth[day == max(day)] + 0.5,
                            line = ""right2""))

  
  bottom1 <- with(df, tibble(x = min(wmonth) - 0.5,
                             xend = wday[day == max(day)] + 0.5,
                             y = wmonth[day == max(day)] + 0.5,
                             yend = wmonth[day == max(day)] + 0.5,
                             line = ""bottom1""))
  
  bottom2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                             xend = max(wday) + 0.5,
                             y = wmonth[day == max(day)] - 0.5,
                             yend = wmonth[day == max(day)] -0.5,
                             line = ""bottom2""))
  
  top <- bind_rows(top1, top2)
  left <- bind_rows(left1, left2)
  bottom <- bind_rows(bottom1, bottom2) 
  right <- bind_rows(right1, right2) 
    
    bind_rows(top, left, right, bottom) %>% 
      mutate(year = unique(df$year),
             month = unique(df$month)) 
    
  
}


if(!file.exists(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))) {
  
  # Add Recent ratings #3181-319
  recent_ratings <- tibble(review_number = c(3181:3189, 1676, 2745, 2991),
                           stars = c(3.75, 3.25, 4.0, 3.25, 2.0, 3.75, 3.75, 3.5, 2.25, 4.25, 5, 3.25),
                           brand = c(""Nissin Yakisoba"", ""Maruchan"", ""Uni-President"", ""Maruchan"", ""Sakruai Foods"", ""Nissin Mago"", ""Big Bon"", ""Sapporo Ichiban"", ""Canton"", ""A1"", ""Nissin"", ""Big Bon""),
                           variety = c(""Instant Panict Savory Beef Flavour"", ""Maruchan Ramen Noodle Soup Roast Beef Flavour"", ""Imperial Big Meal Super Hot Pot Beef Flavour"",
                                       ""Ramen Noodle Soup Pork Beef Flavour"", ""Vegetarian Stir Fry Noodles"", ""Nissin Lamen Light Legumes "", ""Spice Mix Piquant"", ""Momosan Ramen Tokyo Chicken"", ""Instant Noodles Spicy Tomato"",
                                       ""Emperor Herbs Chicken Noodle"", ""U.F.O. Big Wasabi-Mayo Yakisoba"", ""Chicken & Salsa Sauce Instant Noodles""),
                           country = c(""Phillipines"", ""United States"", ""Taiwan"", ""United States"", ""Japan"", ""Brazil"", ""Russia"" , ""United States"", ""India"", ""Malaysia"", ""Japan"", ""Russia""),
                           style = c(""Cup"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack""))
  
  # Read tidytesday data----
  ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"") %>% 
    bind_rows(recent_ratings)
  
  out <- tibble(sitemap_url = glue(""https://www.theramenrater.com/post-sitemap{1:5}.xml""),
                contents = map(sitemap_url, get_urls)) %>% 
    unnest() 
  
  rows <- nrow(out)
  
  # Scrapin der web purges----
  out <-  out %>% 
    mutate(title = imap(contents, ~slowly_get_post_title(.x, .y, rows))) %>% 
    mutate(date = parse_date(str_extract(contents, ""[0-9]{4}/[0-9]{2}/[0-9]{1,}""), ""%Y/%m/%d""),
           review_number = as.numeric(str_extract(title, ""(?!#)[0-9]{1,4}(?=\\:)""))) %>% 
    filter(!is.na(review_number)) %>% 
    left_join(ramen_ratings) %>% 
    filter(review_number < 4000) %>% 
    select(-sitemap_url)
  
  # Saving the new dataset----
  saveRDS(out, here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
} else {
  
  ramen_data <- readRDS(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
}

#Make months
all_dates <- tibble(date = seq.Date(from = ymd(""2009/01/01""), to =ymd(""2019/12/31""), by =""day"")) %>% 
  mutate(day = day(date),
         month = month(date),
         year = year(date))

plot_data <- ramen_data %>%
  mutate(day = day(date),
         month = month(date),
         year = year(date)) %>% 
  group_by(year, month, day) %>% 
  summarize(brands = toString(sprintf(""%s: %s"", brand, variety)),
            count = n(),
            avg_stars = mean(stars)) %>% 
  right_join(all_dates) %>% 
  ungroup() %>% 
  mutate(wday = wday(date, label = TRUE, week_start = 7),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date))
  
outlines <- all_dates %>% 
  mutate(wday_label = wday(date, label = TRUE),
         wday = wday(date),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date)) %>% 
  split(list(.$year, .$month), drop = TRUE) %>% 
  map_df(month_outline)



plot <- ggplot(data = plot_data, aes(x = wday, y = wmonth, fill = avg_stars)) +
  geom_tile(color = ""grey80"", size = 0.1) +
  geom_segment(data = outlines, aes(x = x, xend = xend, y = y, yend = yend, group = line), color = ""grey30"", inherit.aes = FALSE) +
  scale_y_continuous(trans = ""reverse"", labels = NULL) +
  scale_x_discrete(labels = NULL) +
  scale_fill_gradientn(""Average Stars"", colors = rev(parula(100)), na.value = ""grey95"") +
  facet_grid(month ~ year, switch = ""y"") +
  labs(x = NULL,
       y = NULL,
       title = ""The Prolfic Nature of the Ramen Rater and a Birds-Eye View of Ramen Quality"",
       subtitle = str_wrap(""Below is a heatmap calendar of the all the Ramen Raters ramen ratings by the published date of the review.  In the early days, multiple reviews were posted in a single day, until reaching the usual pattern of a single review per day.  However, there are still some reviews that get posted en masse."", 100),
       caption = ""Data: The Ramen Rater | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE) +
  theme(strip.text.y = element_text(angle = 180),
        panel.spacing.y = unit(-0.2, ""lines""),
        legend.position = ""bottom"")

ggsave(here(""2019"", ""week23"", ""tw23_plot.png""), height = 11, width = 8.5, type = ""cairo"")





  
","2019-23"
"169",30,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week24/R/analysis.R","library(nord)
library(tidyverse)
library(ggmap)
library(here)
library(countrycode)
library(jkmisc)
library(patchwork)

source(here(""2019"", ""week24"", ""R"", ""packed_bars.R""))

if (!file.exists(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))) {
  
  slow_revgeocode <- slowly(~revgeocode(.x, output = ""address""), rate = rate_delay(0.03), quiet = TRUE)
  
  reverse_geocoded <- meteorites %>% 
    distinct(long, lat) %>% 
    mutate(location = map2_chr(long, lat, ~slow_revgeocode(c(.x, .y))))
  
  saveRDS(reverse_geocoded, here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
} else {
  
  meteorite_locations <- readRDS(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
}

meteorites <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

meteorites <- left_join(meteorites, meteorite_locations) %>% 
  mutate(country_code = countrycode(location, ""country.name"", ""iso3c"")) %>% 
  mutate(country_code = case_when(str_detect(location, ""UK"") ~ ""GBR"",
                                  str_detect(location, ""USA"") ~ ""USA"",
                                  str_detect(location, ""China"") ~ ""CHN"",
                                  str_detect(location, ""Philippines"") ~ ""PHL"",
                                  str_detect(location, ""Serbia"") ~ ""RUS"",
                                  str_detect(location, ""Australia"") ~ ""AUS"",
                                  str_detect(location, ""Chile"") ~ ""CHL"",
                                  str_detect(location, ""Shopian"") ~ ""IND"",
                                  str_detect(location, ""Argentina"") ~ ""ARG"",
                                  str_detect(location, ""Bass Strait"") ~ ""AUS"",
                                  TRUE ~ country_code)) %>% 
  mutate(country_code = case_when(str_detect(name, ""Indarch"") ~ ""AZE"",
                                  str_detect(name, ""Oum Dreyga"") ~ ""ESH"",
                                  str_detect(name, ""Zag"") ~ ""ESH"",
                                  str_detect(name, ""Al Haggounia"") ~ ""ESH"",
                                  str_detect(name, ""Bou Kra"") ~ ""ESH"",
                                  TRUE ~ country_code)) %>% 
  rename(iso3c = country_code) %>% 
  filter(!is.na(iso3c)) 


world_tile_grid <- read_csv(""https://gist.githubusercontent.com/maartenzam/787498bbc07ae06b637447dbd430ea0a/raw/9a9dafafb44d8990f85243a9c7ca349acd3a0d07/worldtilegrid.csv"")

meteorite_wtg <- meteorites %>% 
  group_by(iso3c) %>% 
  summarize(n = n(),
            mass = sum(mass, na.rm = TRUE)/1000) %>%
  mutate(per_meteorite = mass/n) %>% 
  right_join(world_tile_grid, by = c(""iso3c"" = ""alpha.3"")) %>% 
  mutate(text_color = if_else(per_meteorite < 1, ""white"", ""black"")) %>% 
  replace_na(list('alpha.2' = ""NA"",
                  ""text_color"" = ""black"")) 


meteorite_map <- ggplot(meteorite_wtg, aes(x, y, fill = odds, group = iso3c)) +
  geom_tile(color = ""grey30"", size = 0.1) +
  geom_text(aes(label = alpha.2, color = text_color), family = ""Oswald"") +
  labs(x = NULL,
       y = NULL) +
  scale_y_reverse() +
  scale_fill_viridis_c(name = ""Average Metorite Mass (kg, log scale)"",option = ""cividis"", na.value = ""white"", breaks = c(1, 10, 100, 1000, 10000, 100000), guide = guide_colourbar(title.position = ""top"", title.hjust = 0)) +
  scale_color_identity() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.direction = ""horizontal"",
        legend.key.width = unit(2, ""lines""),
        legend.position = c(0.2, 0.05))


plot_data <- meteorite_wtg %>%
  select(alpha.2, n) %>% 
  mutate(n = log10(n)) %>% 
  replace_na(list(n = 0)) %>% 
  pack_bars(10, value_column = n, fill_color = last(nord(""lumina"", 5)))


packed_bars <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"", size = 0.1) +
  geom_text(data = filter(plot_data, (xmax - xmin) > 0.1), aes(x = (xmin + xmax)/2, y = (ymin + ymax)/2, label = alpha.2), family = ""Oswald"", color = ""white"") +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())


out <- packed_bars + meteorite_map  + plot_annotation(title = ""You May Need More Than An Umbrella in Russia:  Where the Most, and Heaviest, Meteorites fall"",
                                                subtitle = str_wrap(""On the left is a packed bar chart showing the top 10 regions struck by the most meteorites, while the tile map on the right shows the average meteorite mass across all regions.  Both measures have been scaled logathrimically to aid in comparability."", 180),
                                                caption = ""Data: NASA | Graphic: @jakekaupp"",
                                              theme = theme_jk())

ggsave(here(""2019"", ""week24"", ""tw24_plot.png""), out, width = 14, height = 7)
","2019-24"
"170",31,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week24/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}

","2019-24"
"171",32,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week25/R/analysis.R","library(tidyverse)
library(waffle)
library(jkmisc)
library(here)

bird_counts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

top_10 <- bird_counts %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  group_by(genus) %>% 
  summarize(total = sum(how_many_counted_by_hour, na.rm = TRUE)) %>% 
  top_n(10, total) %>% 
  pull(genus)

by_genus <- filter(bird_counts, year >= 2000) %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  filter(genus %in% top_10) %>% 
  group_by(year, genus) %>% 
  summarize(counts_by_hour = sum(how_many_counted_by_hour, na.rm = TRUE))

colors <- set_names(gray.colors(10), top_10)

colors[""Anas""] <- ""#ffd45c""

ducks <- ggplot(by_genus, aes(values = counts_by_hour, fill = genus)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, nrow = 1, strip.position = ""bottom"") +
  coord_equal() +
  labs(title = str_to_title(""The Duck is one of the most noble, agile and intelligent creatures in the animal kingdom.""),
       subtitle = str_wrap(""Total counts per hour, of the top 10 genera from since 2000.  Duck counts (genus Anas) are highlighted in yellow, because if it looks like a duck, and quacks like a duck, we have at least to consider the possibility that we have a small aquatic bird of the family anatidae on our hands."", 120),
       caption = ""Data: www.birdscanada.org/ | Graphic: @jakekaupp"") +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  scale_fill_manual(values = colors) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(strip.text = element_text(size = rel(0.8)))

cobra_chicken <- bird_counts %>% 
  filter(year >=1950) %>% 
  group_split(species) %>% 
  map_dfr(~mutate(.x, color = if_else(species == ""Canada Goose"", ""#CB181D"", sample(gray.colors(255), 1)),
                  alpha = if_else(species == ""Canada Goose"", 1, 0.25))) %>%   
  ggplot(aes(x = year, y = how_many_counted_by_hour, group = fct_relevel(species, ""Canada Goose"", after = Inf), fill = color, alpha = alpha), color = ""grey30"") +
  geom_area() +
  scale_y_continuous(expand = c(0.01, 0.1), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = c(seq(1950, 2010, 10), 2017)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Rise Of The Cobra Chicken, the Scourge of the Hamilton Waterfront"",
       subtitle = str_wrap(""The Canada Goose, hilarious and aptly referred to as a 'Cobra Chicken' has been a threat to the delicate ecosystem of Hamilton's Harbor."", 120),
       caption = ""Data: www.birdscanada.org | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE, ticks = TRUE)
  

ggsave(here(""2019"", ""week25"", ""tw25_ducks.png""), ducks, width = 10, height = 4)
ggsave(here(""2019"", ""week25"", ""tw25_canada_goose.png""), cobra_chicken, width = 10, height = 4)
","2019-25"
"172",33,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week26/R/analysis.R","library(sf)
library(albersusa)
library(here)
library(jsonlite)
library(RCurl)
library(janitor)
library(jkmisc)
library(cowplot)
library(tidyverse)



# Get ufo  & pop. density data----
ufo_sightings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

pop_density <- read_csv(here(""2019"", ""week26"", ""data"", ""pop_density.csv""), skip = 1) %>% 
  clean_names() %>% 
  filter(target_geo_id2 > 1000) %>% 
  mutate(fips = str_pad(target_geo_id2, 5, side = ""left"", pad = ""0"")) %>% 
  select(fips, density = contains(""density""))

# Get alberusa us county sf object----
us_counties <- counties_sf()

# Conver the us ufo sightings to an sf object and join with the alberusa to the the county fips----
usa_sightings_fips <- ufo_sightings %>% 
  filter(country == 'us') %>% 
  st_as_sf(crs = 4326, coords = c(""longitude"", ""latitude"")) 

cont_usa_sightings <- st_join(us_counties, usa_sightings_fips) 



# Some are missing!----
missing <- st_join(usa_sightings_fips, us_counties)  %>% 
  filter(is.na(fips)) %>% 
  semi_join(ufo_sightings,.)

# Make a function to call to the fcc census block API----
geocode_fips <- function(latitude, longitude, index) {
  
  url <- sprintf(""https://geo.fcc.gov/api/census/block/find?latitude=%f&longitude=%f&format=json"",  latitude, longitude)
  
  response <- getURL(url)
  
  json <- fromJSON(response)
  
  print(index)
  
  as.character(json$County['FIPS'])
}

# Make this work insistently----
insistent_geocode <- insistently(~geocode_fips(..1, ..2, ..3), rate = rate_backoff())

# Make it return NA if it fails ----
poss_insistent_geocode <- possibly(~insistent_geocode(..1, ..2, ..3), otherwise = NA_character_)

# Get the missing fips ----

if(!file.exists(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))) {
  missing_fips <- missing %>% 
    distinct(latitude, longitude) %>% 
    mutate(index = row_number()) %>% 
    mutate(fips = pmap_chr(list(latitude, longitude, index), poss_insistent_geocode)) } else {
      
      missing_fips <- readRDS(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))
      
    }

# Join it back to missing to fill in fips ----
missing <- left_join(missing, missing_fips) %>% 
  dplyr::select(-index) 

# Bind rows back to cont_usa_sightings for full_usa data ----
full_usa <- cont_usa_sightings %>% 
  left_join(missing, by = c(names(ufo_sightings)[c(1:2,4:9)], ""state.x"" = ""state"")) %>% 
  mutate_at(vars(contains(""fips"")), as.character) %>% 
  mutate(fips = coalesce(`fips.x`, `fips.y`)) %>% 
  select(-fips.x, -fips.y, -state_fips, -county_fips, -latitude, -longitude)

# Summarize sightings, create a ratio and add in population densities----
plot_data <- full_usa %>% 
  group_by_at(.vars = vars(fips, name, lsad, census_area, state.y, iso_3166_2)) %>% 
  summarize(sightings = n()) %>% 
  ungroup() %>% 
  mutate(sightings_ratio = 100*sightings/sum(sightings)) %>% 
  left_join(pop_density)


# create 3 buckets for variables ---
quantiles_sightings <- plot_data %>%
  pull(sightings_ratio) %>%
  quantile(probs = seq(0, 1, length.out = 4))

quantiles_density <- plot_data %>%
  pull(density) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# create color scale that encodes two variables
# red for sightings and blue for population density
bivariate_color_scale <- tibble(
  ""3 - 3"" = ""#3F2949"", # high sightings, high density
  ""2 - 3"" = ""#435786"",
  ""1 - 3"" = ""#4885C1"", # low sightings, high density
  ""3 - 2"" = ""#77324C"",
  ""2 - 2"" = ""#806A8A"", # medium sightings, medium density
  ""1 - 2"" = ""#89A1C8"",
  ""3 - 1"" = ""#AE3A4E"", # high sightings, low density
  ""2 - 1"" = ""#BC7C8F"",
  ""1 - 1"" = ""#CABED0"" # low sightings, low density
) %>%
  gather(""group"", ""fill"")


# Assign each fips area to their correct group and assign the fill from the bivariate scale ----
plot_data <- plot_data %>%
  mutate(sightings_quantiles = cut(sightings_ratio,
                              breaks = quantiles_sightings,
                              include.lowest = TRUE),
    density_quantiles = cut(density,
                            breaks = quantiles_density,
                            include.lowest = TRUE),
    group = paste(as.numeric(sightings_quantiles), ""-"", as.numeric(density_quantiles))) %>%
  left_join(bivariate_color_scale, by = ""group"")


# Making ze plot ----
plot <- ggplot(plot_data) +
  geom_sf(aes(fill = fill), size = 0.05, color = ""#2b2b2b"") +
  scale_fill_identity() +
  labs(title = ""If A UFO Flew Over The Desert And No One Was Around To See It, Would Senators Be Briefed?"",
       subtitle = str_wrap(""Below is a bivariate choropleth map by county illustrating the relationship between the UFO sightings (% of recorded sightings since 1911) and population density (people per sq. mile circa 2010).  Densely populated coastal and lakeside areas along with the sparsely populated southwest have the highest sightings, whereas the less populous midwest and Alaska have lower percentages of sightings."", 110),
       caption = ""Data: NUFORC & 2010 US Census | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank()) +
  coord_sf(clip = ""off"")

# Making ze legend ---
bivariate_legend <- bivariate_color_scale %>% 
  separate(group, into = c(""sightings"", ""density""), sep = "" - "") %>%
  mutate_at(c(""sightings"", ""density""), as.integer)

legend <- ggplot(bivariate_legend) +
  geom_tile( aes(x = sightings, y = density, fill = fill)) +
  scale_fill_identity() +
  labs(x = expression(paste(""More Sightings "", symbol('\256'))),
       y = expression(paste(""More People "", symbol('\256')))) +
  theme_jk(grid = FALSE) +
  theme(axis.title = element_text(size = 6),
        axis.text = element_blank()) +
  coord_fixed(clip = ""off"")

finished_plot <- ggdraw() +
  draw_plot(plot, 0, 0, 1, 1) +
  draw_plot(legend, 0.75, 0.075, 0.2, 0.2)


ggsave(here(""2019"", ""week26"", ""tw26_plot.png""), plot = finished_plot, width = 10, height = 6)
","2019-26"
"173",34,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week28/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(glue)


squads <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")


data <- squads %>% 
  mutate(idx = goals/caps) %>% 
  filter(pos != ""GK"", caps > 0, goals > 0) %>% 
  mutate(pos = case_when(pos == ""DF"" ~ ""Defense"",
                         pos == ""FW"" ~ ""Forward"",
                         pos == ""MF"" ~ ""Mid-Field"")) %>% 
  mutate(desc = glue(""{club}\n{caps} Matches, {goals} Goals"")) %>% 
  mutate(pos = factor(pos, c(""Defense"", ""Mid-Field"", ""Forward"")))

means <- data %>% 
  group_by(pos) %>% 
  summarize(idx = mean(idx))

plot <- ggplot(data, aes(x = age, y = idx)) +
  geom_point(color = ""grey20"") +
  geom_mark_circle(aes(label = player, description = desc, filter = player == ""Khadija Shaw""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Lea Schller""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Ainon Phancha""), expand = unit(4, ""mm"")) +
  geom_hline(data = means, aes(yintercept = idx), color = ""firebrick"") +
  theme_jk() +
  facet_wrap(~pos, nrow = 1) +
  labs(y = NULL,
       x = ""Age"",
       title = ""Efficient Scorers Competing in the Womens World Cup by Position and Age"",
       subtitle = str_wrap(""Goals per games played in international play by player age.  Red line illustrates the average goals per game at each position.  The highly efficient players at each position are a mix of newcomers and seasoned veterans, illustrating consistency in some players through their career."", 120),
       caption = ""Data: data.world | Graphic : @jakekaupp"")

ggsave(here(""2019"", ""week28"", ""tw28_plot.png""), plot = plot, width = 10, height = 6)

","2019-28"
"174",35,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week29/R/analysis.R","library(tidyverse)
library(tricolore)
library(ggtern)
library(here)
library(jkmisc)
library(magick)

r4ds_members <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")


tern_plot <- Tricolore(r4ds_members, ""percent_of_messages_public_channels"",
          ""percent_of_messages_private_channels"",
          ""percent_of_messages_d_ms"", breaks = 5, show_data = FALSE)

legend <- tern_plot$key +
  labs(title = ""Color Legend"",
       x       = ""Public\nChannels"",
       y       = ""Private\nChannels"",
       z       = ""Direct\nMessages"") +
  theme_hidetitles() +
  theme_hidelabels() +
  theme_hideticks() +
  theme(plot.title = element_text(hjust = 0.5, family = ""Scope One"", size = 40),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One""))

png(here(""2019"", ""week29"", ""legend.png"")) 
legend
dev.off()

legend <- image_read(here(""2019"", ""week29"", ""legend.png""))

plot <- r4ds_members %>% 
  mutate(color = tern_plot$rgb,
         year = lubridate::year(date)) %>% 
  ggtern(aes(x = percent_of_messages_public_channels, y = percent_of_messages_private_channels, z = percent_of_messages_d_ms, color = color)) +
  geom_point(size = 3) +
  scale_color_identity() +
  labs(title = str_to_title(""The Dialogue in the R4DS Slack indicates an Open and Inclusive Learning Community""),
       subtitle = str_wrap(""Below is a ternary digram presenting the message composition in public channels, private channels and direct messages as a percentage.  Each day is represented by a point with the composition represented by position relative to each axes.  Composition is additionally encoded by color as illustrated on the inset legend."", 100),
       x       = ""Public\nChannels"",
       xarrow  = ""More Public Channel Messages"",
       y       = ""Private\nChannels"",
       yarrow  = ""More Private Channel Messages"",
       z       = ""Direct\nMessages"",
       zarrow  = ""More Direct Messages"",
       caption = ""Data: R4DS Community | Graphic: @jakekaupp"") +
  theme(panel.background = element_rect(fill = ""#2E3440""),
        panel.grid = element_line(color = ""#ffffff"", size = 0.1),
        panel.grid.minor = element_blank(),
        text = element_text(family = ""Oswald""),
        plot.subtitle = element_text(family = ""Scope One""),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One"")) +
  theme_showarrows() +
  theme_arrowlong() 


png(here(""2019"", ""week29"", ""tw29_plot.png""), width = 10, height = 8, units = ""in"", res = 200)
grid::grid.newpage()
plot
grid::grid.raster(legend, width = 0.18, height = 0.2, x = 0.75, y = 0.7)
dev.off()
","2019-29"
"175",36,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week3/R/analysis.R","library(tidyverse)
library(here)
library(nord)
library(jkmisc)
library(ggbeeswarm)
library(ggrepel)

agencies <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/agencies.csv"")

launches <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/launches.csv"")


us_launch_data <- launches %>% 
  filter(agency == ""US"" | state_code == ""US"") %>% 
  mutate(type = gsub(""Zenit-"", ""Zenit "", type),
         type = gsub(""/"", "" "", type),
         type = gsub(""Minotaur-"", ""Minotaur "", type)) %>% 
  separate(type, ""type"", sep = "" "", extra = ""drop"") %>% 
  mutate(type = if_else(type == ""Space"", ""Space Shuttle"", sprintf(""%s Program"",type))) %>% 
  mutate(label = if_else(type == ""Space Shuttle"" & category == ""F"", ""Challenger Disaster"", NA_character_)) %>% 
  group_by(type) %>% 
  filter(n() > 10)

plot <- ggplot(us_launch_data, aes(x = launch_year, y = type), size = 4) +
  geom_quasirandom(data = filter(us_launch_data, category == ""O""), alpha = 0.2, fill = nord(""polarnight"", 2)[2], shape = 21, groupOnX = FALSE) +
  geom_quasirandom(data = filter(us_launch_data, category == ""F""), fill = nord(""victory_bonds"", 5)[1], shape = 21, groupOnX = FALSE, color = ""grey30"", stroke = 0.2) +
  theme_jk(grid = ""XY"", dark = FALSE) +
  labs(x = NULL,
       y = NULL,
       title = ""From the Space Race to Space-X: 1548 Successes and 101 Failures of US Launch Vehicles from 1958-2018."",
       subtitle = str_wrap(""A beeswarm plot illustrating the success or failure of a launch vehicle program over time. Red dots indicate failed launches, grey dots indicate success.  Deeper grey colors indicate a higher frequency of success in a given year due to multiple launches. Only includes programs with more than 10 launches"", 120),
       caption = ""Data: JSR Launch Vehicle Database | Analysis: @jakekaupp"")

plot <- plot + annotate(""segment"", x = 1987, xend = 1986.2, y = 8.7, yend = 8.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1986, y = 9, label = ""Challenger Disaster"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1]) +
  annotate(""segment"", x = 1959, xend = 1958.2, y = 1.7, yend = 1.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1959, y = 2.5, label = ""First Communication\nSatellite Protoype"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0) +
  annotate(""segment"", x = 2015, xend = 2015, y = 5.5, yend = 3.1, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 2013, y = 6.5, label = ""SpaceX Falcon 9\nStrut Failure"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0)

ggsave(here(""2019"", ""week3"", ""tt_week3.png""), plot, width = 11, height = 5)

","2019-3"
"176",37,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week30/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  #mutate(airport_type = if_else(str_detect(airport, ""INTL""), ""INT"", ""DOM"")) %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  complete(incident_year = 1990:2018, state,  incident_month = 1:12, fill = list(n = 0)) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


state_flower_grid <- plot_data %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, 
       y = NULL) +
  coord_polar() +
  facet_geo(~ state, grid = ""us_state_grid2"") +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""))

flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Single colour petal represents a single collison event during this month"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1, breaks = c(seq(1990, 2020, by = 5))) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar(), color = ""none"") +
  labs(x = NULL, y = NULL) +
  coord_polar(clip = ""off"") +
  theme_jk(grid = ""XY"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())

finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.17, 0.4, 0.4)

out <- wrap_plots(finished_legend, state_flower_grid,  nrow = 1, widths = c(0.85, 1.2)) +
   plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                   subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft, with an inset legend showing assisting interpretation.  Wildlife collisions by state are presented as small multiples, geographically arranged.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                   caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                   theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot.png""), out, width = 16, height = 10, type = ""cairo"")


","2019-30"
"177",38,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week30/R/experiment.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent)) %>% 
  mutate(angle = 90 - (incident_month-1)*30,
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
         
         
big_flower <- ggplot(plot_data) +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.2, size = 0, color = ""white"") +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  theme_jk(grid = FALSE, plot_title_size = 12) +
  labs(x = NULL, y = NULL, title = ""National"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""),
        plot.title = element_text(hjust = 0.5)) +
  coord_equal() 

state_flower <- big_flower +
  facet_geo(~ state, grid = ""us_state_grid2"")


flower_axes_lines <- tibble(idx = 1:12,
                            angle = 90 - (idx-1)*30,
                            angle2 = ifelse(angle < 0, 360 + angle, angle),
                            radians = angle2*pi/180)

axes_lines <- function(radius) {
  
  tibble(segment = 1:6,
                     x = c(0, radius*cos(pi/3), radius*cos(pi/6), radius, radius*cos(pi/6), radius*cos(pi/3)),
                     xend = c(0, -radius*cos(pi/3), -radius*cos(pi/6), -radius, -radius*cos(pi/6), -radius*cos(pi/3)),
                     y = c(radius, radius*sin(pi/3), radius*sin(pi/6), 0, -radius*sin(pi/6), -radius*sin(pi/3)),
                     yend = c(-radius, -radius*sin(pi/3), -radius*sin(pi/6), 0, radius*sin(pi/6), radius*sin(pi/3))) 
  }

axes_labels <- function(radius) {
  tibble(month = 1:12,
                      label = month.abb[month],
                      x = c(axes_lines(radius)$x, axes_lines(radius)$xend),
                      y = c(axes_lines(radius)$y, axes_lines(radius)$yend))  }


flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_segment(data = axes_lines(2), aes(x = x, xend = xend, y = y , yend = yend), size = 0.1, color = ""#cccccc"", inherit.aes = FALSE) +
  geom_circle(aes(x0 = 0, y0 = 0, r = 2), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_circle(aes(x0 = 0, y0 = 0, r = 1), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.5, size = 0.1, color = ""white"") +
  geom_mark_circle(aes(x = 2*x0, y = 2*y0, label = glue(""{month.name[incident_month]}, {incident_year}""), description = ""Single colour long petal represents 100% of collison event during this month and year"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_mark_circle(aes(x = x0, y = y0, label = glue(""{month.name[incident_month]}, Multiple years""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_text(data = filter(axes_labels(2.15), label != ""Feb""), aes(x = x, y = y, label = label), inherit.aes = FALSE, family = ""Oswald"") +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  coord_fixed(clip = ""off"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())


finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.175, 0.4, 0.4)

state_flower_grid <- ggdraw() +
  draw_plot(state_flower, 0, 0, 1, 1) + 
  draw_plot(big_flower, 0.75, 0.15, 0.25, 0.25)

out <- wrap_plots(finished_legend, state_flower_grid, nrow = 1, widths = c(0.85, 1.2)) +
  plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                  subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft across the US from 1990-2018. Below this is an inset legend showing assisting interpretation of the plots.  On the right are wildlife-aircraft collisions by state presented as small multiples, geographically arranged, with an inset flower representing the National data. Petal length is the annual proportion of collisions in a given month.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                  caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                  theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot_remix.png""), out, width = 16, height = 10, type = ""cairo"")
","2019-30"
"178",39,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week31/R/analysis.R","library(tidyverse)
library(here)
library(ggbeeswarm)
library(jkmisc)

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")  
 
all_games <- video_games %>% 
  filter(!is.na(game), !is.na(metascore))  %>% 
  mutate(developer = tolower(developer),
         idx = row_number())

plot_data <- tibble(facet = c(""bioware"", ""valve"", ""ubisoft"", ""rockstar"", ""square enix""),
       data = list(all_games)) %>% 
  mutate(filtered = map2(data, facet, ~mutate(.x, option = case_when(str_detect(tolower(developer), .y) ~ ""selected"", 
                                                                     TRUE ~ ""other"")))) %>% 
  unnest(filtered) %>% 
  mutate(facet = case_when(facet == ""bioware"" ~ ""BioWare"",
                           facet == ""valve"" ~ ""Valve"",
                           facet == ""ubisoft"" ~ ""Ubisoft"",
                           facet == ""rockstar"" ~ ""Rockstar"",
                           facet == ""square enix"" ~ ""Square Enix"")) %>% 
  mutate(option = factor(option, c(""other"", ""selected""))) %>% 
  arrange(facet, option)



mean <- all_games %>% 
  summarize(metascore = mean(metascore, na.rm = TRUE)) %>% 
  pull(metascore)

min_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == min(metascore))

max_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == max(metascore)) %>% 
  mutate(game = if_else(str_detect(""FINAL FANTASY"", game), ""Final Fantasy IX"", game)) %>% 
  slice(1)

plot <- ggplot(plot_data) +
  geom_quasirandom(aes(y = metascore, x = 0, alpha = option, fill = option, size = option), shape = 21, method = ""tukey"", show.legend = FALSE) +
  geom_label(data = min_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = -2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_label(data = max_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = +2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_hline(yintercept = mean, color = ""firebrick"", size = 0.5, linetype = ""dashed"") +
  labs(x = NULL, 
       y = NULL,
       title = ""How Do The Big Developers Score Against The Competition on Steam?"",
       subtitle = str_wrap(""Presented below is a jittered strip plot of metascore by developer.  Titles worked on by that developer are highlighted in yellow, the average metascore (72) is shown as a dashed red line. Annotations show the top an bottom rated titles for each developer.  Sqaure and Ubisoft have the most titles with less than average reviews amongst the large developers."", 180),
       caption = ""Data: SteamSpy | Graphic: @jakekaupp"") +
  scale_size_manual(values = c(""other"" = 2, ""selected"" = 2)) +
  scale_y_continuous(limits = c(20, 100), breaks = seq(20, 100, 20)) +
  scale_fill_manual(values = c(""other"" = ""#E5E4E2"", ""selected"" = ""#ffd644"")) +
  scale_alpha_manual(values = c(""other"" = 0.05, ""selected"" = 1)) +
  theme_jk(grid = ""Y"", dark = TRUE) +
  facet_wrap(~facet, nrow = 1) +
  theme(strip.text = element_text(color = ""white""),
      axis.text.x = element_blank())

ggsave(here(""2019"", ""week31"", ""tw31_plot.png""), plot, width = 14, height = 8)
","2019-31"
"179",40,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week32/R/analysis.R","library(tidyverse)
library(ggforce)
library(here)
library(jkmisc)
library(patchwork)

bob_ross_paintings <- here(""2019"", ""week32"", ""data"", ""tidytuesday_201932_bob_ross_paintings.csv"")

data <- read_csv(bob_ross_paintings, col_names = c('episode', 'title', 'color', 'color_name')) %>% 
  mutate(season = parse_number(str_extract(episode, ""S\\d+"")),
         color = if_else(color == ""#FFFFFF"", ""grey80"", color))


plot_data <- data %>% 
  count(season, title, color_name, color) %>% 
  group_by(season, title) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  mutate(color_number = as.numeric(factor(color_name))) %>% 
  mutate(angle = (color_number-1)*(360/15),
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
  

plot_spiros <- function(data) {
  
season <- sprintf(""Season %s"",unique(data$season))
  
ggplot(data) +
  geom_spiro(aes(R = ifelse(percent == 1, 0.1, 1 - percent), r = percent, d = radians, color = color, group = color), size = 0.1) +
  scale_color_identity() +
  theme_jk(grid = FALSE, plot_title_size = 8, strip_text_size = 8) +
  facet_wrap(~ title, ncol = 1, labeller = label_wrap_gen(15)) +
  labs(x = NULL, y = NULL, title = season) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines"")) +
  coord_equal()  }


plots <- plot_data %>% 
  split(.$season) %>% 
  map(plot_spiros)


all_seasons <- wrap_plots(plots, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = ""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."",
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot.png""), plot = all_seasons, width = 30, height = 15, type = ""cairo"")

twitter <- map(plots, ~.x + theme(strip.text = element_blank()))


all_seasons_twitter <- wrap_plots(twitter, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = str_wrap(""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."", 265),
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot_for_twitter.png""), plot = all_seasons_twitter, width = 20, height = 7)


","2019-32"
"180",41,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week33/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)


emperors <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"") 

ad_births <- c(""Augustus"", ""Tiberius"", ""Claudius"", ""Galba"")

emp_numeric_years <- emperors %>% 
  mutate_if(is.Date, list(year = year)) %>% 
  mutate(birth_year = if_else(name %in% ad_births, -birth_year, birth_year),
         reign_start_year = if_else(name == ""Augustus"", -reign_start_year, reign_start_year))


missing_birth_estimates <- emp_numeric_years %>% 
  filter(is.na(birth_year)) %>% 
  mutate(birth_year = case_when(name == ""Florian"" ~ 202,
                                name == ""Numerian"" ~ 248,
                                name == ""Carinus"" ~ 245,
                                name == ""Severus II"" ~ 260,
                                name == ""Vetranio"" ~ 325))


plot_data <- emp_numeric_years %>% 
  filter(!is.na(birth_year)) %>% 
  bind_rows(missing_birth_estimates)


dynasties <- plot_data %>% 
  group_by(dynasty) %>% 
  summarize(reign_start_year = min(reign_start_year),
               reign_end_year = max(reign_end_year))

roman_palette <- set_names(colorRampPalette(c(""#191970"", ""#FF7F50""))(8), unique(plot_data$dynasty))


overall <- ggplot(plot_data, aes(y = 0)) +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = 0, color = dynasty), size = 4) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, y = NULL,
       caption = ""Data: Wikipedia via @geokaramanis | Graphic: @jakekaupp"") +
  theme_jk(grid = ""X"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

bars <- ggplot(plot_data, aes(y = reorder(name, reign_start_year))) +
  geom_segment(aes(x = birth_year, xend = death_year, yend = name), size = 2, color = ""grey90"") +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = name, color = dynasty), size = 2) +
  geom_segment(data = filter(plot_data, reign_start_year == reign_end_year), aes(x = reign_start_year - 0.5, xend = reign_start_year + 0.5, y = name, yend = name, color = dynasty), size = 2) +
  geom_text(aes(x = death_year, label = name), hjust = 0, family = ""Scope One"", size = 2, nudge_x = 3) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, 
       y = NULL,
       title = str_to_title(""When in Rome: The Game of Imperial Thrones. You Win or You Die.""),
       subtitle = str_wrap(""Illustrated below is a timeline of the life and reigns of Roman Emperors from 62 BC to 395 AD.  The light grey bar depicts the liftime of the emperor, the colored bar (by dynasty) indicates the duration of their reign. An overall timeline by dynasty is shown near the horizontal axis. Unsurprisingly, the majority of emperors reign ending also coincides with the end of their life."", 100)) +
  theme_jk(grid = ""X"") +
  theme(axis.text = element_blank(),
        legend.position = c(0.2, 0.7),
        legend.background = element_rect(fill = ""white"", size = 0))


out <- wrap_plots(bars, overall, ncol = 1, heights = c(0.9, 0.1))

ggsave(here(""2019"", ""week33"", ""tw33_plot.png""), out, width = 7.5, height = 8)
","2019-33"
"181",42,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week34/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggtext)
library(jkmisc)
library(waffle)
library(ggforce)
library(glue)
library(ragg)

nuclear_explosions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")




plot_data <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  group_by(country, date_long) %>% 
  summarize(n = n(),
            total_yield = sum(yield_upper, na.rm = TRUE)) %>% 
  group_by(country) %>% 
  mutate(c_sum = cumsum(n),
         c_yield = cumsum(total_yield)/1000) %>% 
  filter(country %in% c(""USSR"", ""USA""))

items <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  group_by(country) %>% 
  top_n(1, yield_upper) %>% 
  slice(1) %>%
  semi_join(plot_data, .) %>% 
  mutate(date_long = ymd(date_long) - 1) %>% 
  mutate(name = if_else(country == ""USA"", ""March 1954: Castle Bravo"", ""October 1961: Tsar Bomba""),
         description  = if_else(country == ""USA"", ""2nd most powerful nuclear test explosion, 3 times over the predicted 5 MT yield."", ""Most powerful nuclear test explosion, twice the predicted yield of 25 MT.""))

explosions <- ggplot(plot_data, aes(x = c_sum, y = c_yield, color = country)) +
  geom_step(linetype = ""solid"", size = 1, direction = ""hv"") +
  geom_point(data = filter(plot_data, date_long %in% range(date_long))) +
  geom_text(data = filter(plot_data, date_long == last(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", hjust = -0.5) +
  geom_text(data = filter(plot_data, date_long == first(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", nudge_y = c(10, -10)) +
  geom_mark_circle(data = items, aes(color = country, label = name, description = description), expand = unit(3, ""mm""), label.margin = margin(5, 5, 5, 5, ""mm""), con.colour = c(""#0052A5"", ""#FF2400""), label.family = c(""Oswald"",""Scope One""), label.fill = NA, label.minwidth = unit(50, ""mm""), label.fontsize = 10, con.type = ""straight"") +
  scale_color_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_fill_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_y_continuous(labels = function(x) scales::comma(x, suffix = "" MT"")) +
  labs(x = 'Cumulative Number of Explosions',
       y = ""Cumulative Yield (MT)"",
       title = ""Nuclear Weapons Research Race During And After The Cold War"",
       subtitle = ""Illustrated below is a step chart showing the number and yield of nuclear explosions for weapons research for <span style='color:#0052A5'>**USA**</span> and <span style='color:#FF2400'>**USSR**</span>.  During this race nearly<br>500 MT of nuclear explosions and accompanying fallout blanketed the world. The effects are still being dealt with to this date."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(plot.title = element_markdown(), 
        plot.subtitle = element_markdown(),
        legend.position = ""none"")
  
ggsave(here(""2019"", ""week34"", ""tw34_plot_2.png""), plot = explosions, width = 12, height = 6, device = agg_png())


# Waffle ----

waffle_data <- nuclear_explosions %>% 
  mutate(purpose = case_when(grepl(""WR"", purpose) ~ ""WR"",
                             grepl(""WE"", purpose) ~ ""WE"",
                             grepl(""PNE"", purpose) ~ ""PNE"",
                             TRUE ~ purpose)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  count(year, purpose) %>% 
  group_by(purpose) %>% 
  mutate(c_sum = cumsum(n))


pal <- set_names(sample(grey.colors(50),10), unique(waffle_data$purpose))

pal[""WR""] <- ""#8A0303""

waffle <- ggplot(waffle_data, aes(fill = purpose, values = c_sum)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, strip.position = ""bottom"", nrow = 1) +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  coord_equal() +
  scale_fill_manual(values = pal) +
  labs(y = ""Cumulative Number of Explosions"",
       title = ""Nuclear Weapons Research Testing During the Cold War Was the Primary Driver of Controlled  Nuclear Explosions"",
       subtitle = ""Illustrated below is a timeline of waffle charts showing the distribution of cumulative explosions from <span style='color:#8A0303'>**weapons research**</span> or <span style='color:#4D4D4D'>**other purposes**</span>. Widescale Nuclear testing ceased in the mid-'90's. The only active country<br>conducting nuclear testing in this era is North Korea, weathering the disapproval and ire of the global community."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(strip_text_size = 10,
           subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(panel.grid = element_blank(), 
        axis.ticks.y = element_line(),
        strip.text = element_text(hjust = 0.5),
        plot.title = element_markdown(), 
        plot.subtitle = element_markdown())
  
ggsave(here(""2019"", ""week34"", ""tw34_plot.png""), plot = waffle, width = 18, height = 6, device = agg_png())
","2019-34"
"182",43,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week35/R/analysis.R","library(tidyverse)
library(tidygraph)
library(ggraph)
library(colorspace)
library(glue)
library(jkmisc)
library(ggtext)
library(ragg)
library(here)


html_string <- glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'. {subtitle_names} are the most frequent guest stars in the series."")

str_break <- function (html_string, width = 80, indent = 0, exdent = 0) {

tags <- str_extract_all(html_string, ""<.*?>"") %>% 
  flatten_chr() 

index <- sprintf(""tag_%s"", seq_along(tags))

string <- str_replace_all(html_string, set_names(index, tags))

  if (width <= 0) 
    width <- 1
  
  out <- stringi::stri_wrap(string, width = width, indent = indent, 
                   exdent = exdent, simplify = FALSE)
  
  broken <- vapply(out, str_c, collapse = ""<br>"", character(1))
  
  str_replace_all(broken, set_names(tags, index))
  
}

text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


simpsons <- read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")

nodes <- count(simpsons, guest_star) 

top5 <- top_n(nodes, 5, n) %>% 
  arrange(desc(n)) %>% 
  rownames_to_column(var = ""color"") %>% 
  select(-n)

nodes <- nodes %>% 
  left_join(top5) %>% 
  replace_na(list(color = 7)) %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  mutate(alpha = if_else(color < 7, 1, 0.5)) 


edges <- simpsons %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  group_by(production_code) %>% 
  mutate(co_stars = map(guest_star, ~str_subset(guest_star, .x, negate = TRUE))) %>%
  ungroup() %>% 
  mutate(co_stars = map(co_stars, ~ifelse(length(.x) == 0, NA_character_,.x))) %>% 
  unnest(co_stars) %>% 
  count(guest_star, co_stars) %>% 
  filter(!is.na(n), !is.na(co_stars)) %>% 
  set_names(c(""from"", ""to"", ""n"")) %>% 
  left_join(top5, by = c(""from"" = ""guest_star"")) %>% 
  left_join(top5, by = c(""to"" = ""guest_star"")) %>% 
  mutate(color = coalesce(color.x, color.y)) %>% 
  replace_na(list(color = ""grey80"")) 

  
colors <- set_names(tol6qualitative, top5$guest_star)  

subtitle_names <- imap(colors[1:5], ~text_bc(.y, .x)) %>% 
  glue_collapse(sep = ', ') %>% 
  glue("" and {imap(colors[6], ~text_bc(.y, .x))}"")

co_star_graph <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)

co_star_plot <- co_star_graph %>% 
  activate(nodes) %>% 
  arrange(n) %>% 
  mutate(degree = centrality_degree()) %>% 
  filter(degree > 1) %>%  
  ggraph(layout = ""fr"") + 
  geom_edge_arc(edge_width = 0.5, curvature = 0.2, aes(alpha = stat(index), edge_colour = color)) +
  geom_node_point(aes(size = n, color = color, alpha = alpha, fill = color), shape = 21) +
  scale_color_manual(values = c(darken(tol6qualitative), ""grey80"")) + 
  scale_alpha_identity() +
  scale_edge_color_manual(values = c(tol6qualitative, ""grey85"")) +
  scale_fill_manual(values = c(tol6qualitative, ""grey80"")) + 
  scale_size(range = c(2,6)) +
  labs(x = NULL,
       y = NULL,
       title = ""The Guest Star Backbone Of A Simpsons Co-Star Network"",
       subtitle = glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'.<br> {subtitle_names} <br>are the most frequent guest stars in the series.""),
       caption = ""**Data**: Wikipedia via @datawookie | **Graphic**: @jakekaupp"") +
  theme_jk(grid = FALSE,
           subtitle_family = ""Lora"",
           caption_family = ""Lora"",
           markdown = TRUE) +
  theme(legend.position = ""none"",
        axis.text = element_blank())

ggsave(here(""2019"", ""week35"", ""tw35_plot.png""), plot = co_star_plot, device = agg_png(), width = 9, height = 8)

ggplot(mtcars, aes(x = mpg, y = disp)) +
  geom_point() +
  labs(title = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't""),
       subtitle = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't"")) +
  theme_jk() +
  theme(plot.title = ggtext::element_markdown(),
        plot.subtitle = ggtext::element_markdown())
","2019-35"
"183",44,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week36/R/analysis.R","library(tidyverse)
library(jkmisc)
library(nord)
library(glue)
library(here)
library(ragg)

cpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")

gpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")

ram <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")


plot_data <- list(cpu = cpu, gpu = gpu) %>% 
  imap_dfr(~select(.x, date_of_introduction, transistor_count, area, process) %>% 
             mutate(type = .y)) %>% 
  group_by(date_of_introduction, type) %>% 
  summarize_at(vars(transistor_count, area, process), mean, na.rm = TRUE) %>% 
  arrange(date_of_introduction, type)

strip_labels <- tibble(type = c(""cpu"", ""gpu""))

plot <- ggplot(plot_data, aes(x = area, y = transistor_count)) +
  geom_text(data = strip_labels, aes(label = toupper(type)), x = 400, y = 4, family = ""Oswald Bold"", size = 18, color = ""grey90"") +
  geom_smooth(method = ""auto"", formula = y ~ log10(x), se = FALSE, size = 0.5,  color = nth(nord_palettes$victory_bonds, 3)) +
  geom_hline(aes(yintercept = 10^10), linetype = ""dotted"", color = first(nord_palettes$victory_bonds)) +
  geom_point(aes(color = log10(process)), size = 3) +
  scale_color_nord(name = ""Process Size"",
                        discrete = FALSE,
                        palette = ""lumina"",
                        reverse = TRUE,
                        labels = function(x) glue(""{scales::comma(10^x)} nm""),
                        breaks = c(1, 2, 3, 4)) +
  scale_y_log10(breaks = c(1, 10^4, 10^6, 10^8, 10^10),
                labels = c(""1"", ""10K"", ""1M"", ""100M"", ""10B"")) +
  scale_x_continuous(labels = function(x) glue(""{x} {expression(mm^2)}"")) +
  facet_wrap(~type) +
  labs(x = NULL, 
       y = NULL,
       title = ""Moore's Law May Be Dead, Killed By The Tension Between Manufacturing and Transistor Density"",
       subtitle = ""*Moore's law*, the observation that the **number of transistors** on integrated circuits **doubles every two years**<br>
       hasn't held.  Transistor density is reaching a plateau, requiring manufacturing changes of an increase in available<br>
       chip size or a decrease in process size."",
       caption = ""**Data:** Wikipedia | **Graphic:** @jakekaupp"") +
  theme_jk(grid = ""XY"",
          markdown = TRUE) +
  theme(strip.text = element_blank())

ggsave(here(""2019"", ""week36"", ""tw36_plot.png""), plot = plot, device = agg_png(), width = 10, height = 6)
","2019-36"
"184",45,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week37/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(tidygraph)
library(ggraph)
library(ggforce)
library(janitor)
library(jkmisc)
library(glue)
library(ggtext)
library(colorspace)
library(ragg)

legacy_data <- here(""2019"", ""week37"", ""data"", ""Saferparks-dataset-legacy.csv"") %>% 
  read_csv() %>% 
  mutate(year = year(mdy(acc_date))) %>% 
  filter(between(year, 1999, 2007))

device_type <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .75),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .75),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .75))) %>% 
  select(name = device_type, size, color)

device_category <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .25),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .25),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .25))) %>% 
  select(name = device_category, size, color) 

sector <-  legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ ""#251351"",
                           industry_sector == ""recreation"" ~ ""#7d2e68"",
                           industry_sector == ""water park"" ~""#41658a"")) %>% 
  select(name = industry_sector, size, color)

nodes <- bind_rows(sector, device_category, device_type)

edge_one <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(industry_sector, device_category) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edge_two <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(device_category, device_type) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edges <- bind_rows(edge_one, edge_two)

graph <- tbl_graph(nodes = nodes, edges = edges) 

labels <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  group_by(industry_sector) %>% 
  top_n(1 , size) %>% 
  filter(size > 1) %>% 
  pull(device_type) 
 
text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


plot <- ggraph(graph, 'circlepack', weight = size) + 
  geom_node_circle(aes(fill = color)) + 
  geom_node_text(aes(label = glue(""{str_remove(name, ' - undefined')}:\n{size}""), filter = name %in% labels, family = ""Oswald"")) +
  scale_fill_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Attractions With The Most Reported Injuries from 1999-2007"",
       caption = ""Data: **SaferParks** | Graphic: **@jakekaupp**"",
       subtitle = glue(""Shown below is a packed circle representation of reported accidents in the SaferParks database from 1999-2007.<br>Circles are organized by {highlight_text('Amusement rides', '#251351', 'b')}, {highlight_text('Recreation', '#7d2e68', 'b')} and {highlight_text('Water Park', '#41658a', 'b')}. Device category and device type are the<br>middle and lightest hues, respectively."")) +
  theme_jk(grid = FALSE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.subtitle = element_markdown(),
        plot.caption = element_markdown()) 


ggsave(here(""2019"", ""week37"", ""tw_37plot.png""), plot, width = 9, height = 10, dev = agg_png())


","2019-37"
"185",46,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week38/R/analysis.R","library(tidyverse)
library(rvest)
library(janitor)
library(here)
library(fuzzyjoin)
library(jkmisc)
library(ragg)

# Get park fees
fees_page <- ""https://www.nps.gov/aboutus/entrance-fee-prices.htm""

parks <- read_html(fees_page) %>% 
  html_nodes(""h3"") %>% 
  html_text() %>% 
  .[-1:-2]

park_fees <- read_html(fees_page) %>% 
  html_nodes("".table-wrapper > table"") %>% 
  html_table() %>% 
  map(~set_names(.x, c(""date"", ""park_specific_annual_pass"", ""per_vehicle"", ""per_person"", 
                       ""per_motorcycle""))) %>% 
  map2(parks, ~mutate(.x, park = .y)) %>% 
  bind_rows() %>% 
  filter(date == ""Current"") %>% 
  rename(park_name = park) %>% 
  mutate(park_name = stringi::stri_trans_general(park_name, id = ""Latin-ASCII""),
         park_name = str_replace(park_name, ""Hawai'i"", ""Hawaii""))



#udpated data
summary_report <- here(""2019"", ""week38"", ""data"", ""annual_summary_report.csv"") %>% 
  read_csv() %>% 
  clean_names()

plot_data <- summary_report %>% 
  filter(year == 2018) %>% 
  mutate(visitors = recreation_visitors + non_recreation_visitors) %>% 
  select(year, park_name, visitors) %>% 
  mutate(park_name = str_remove(park_name, ""[A-Z]{2,}""),
         park_name = str_remove(park_name, ""& PRES""),
         park_name = trimws(park_name)) %>% 
  regex_left_join(park_fees, ., ignore_case = TRUE) %>% 
  distinct(year, park_name.x, .keep_all = TRUE) %>% 
  filter(str_detect(park_name.x, ""Park""), !str_detect(park_name.x, ""Great Falls"")) %>% 
  mutate(revenue = visitors * parse_number(per_person)) %>% 
  rename(park_name = park_name.x) %>% 
  select(-park_name.y)
  

plot <- ggplot(plot_data, aes(x = fct_reorder(park_name, revenue), y = revenue)) +
  geom_col(fill = ""#5e81ac"", size = 0.1) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar, expand = c(0.01,0)) +
  labs(title = ""Estimated National Park Revenue from Fees for 2018"",
       subtitle = str_wrap(""Illustrated below is a bar chart of fee revenue from US National Parks in 2018.  Estimated Revenue calculated using per person admittance rates and total park visitors."", 95),
       caption = ""Data: www.nps.gov | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = ""X"") +
  theme(plot.background = element_rect(fill = ""#2e3440""),
        text = element_text(color = ""#eceff4""),
        panel.grid = element_line(color = ""#e5e9f0""),
        axis.text.x = element_text(color = ""#eceff4""),
        axis.text.y = element_text(color = ""#eceff4""))

ggsave(here(""2019"", ""week38"", ""tw_38plot.png""), plot, width = 10, height = 8, device = agg_png())

","2019-38"
"186",47,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week39/R/analysis.R","library(tidyverse)
library(janitor)
library(tidycensus)
library(glue)
library(here)
library(sf)
library(tigris)
library(jkmisc)
library(ggtext)

school_diversity <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv"")

## Getting the ACS Survey data ----
acs_var <- load_variables(2017, ""acs1"", cache = TRUE)

race_vars <- filter(acs_var, concept == ""RACE"") %>% 
  select(name, label) %>% 
  separate(label, c(""estimate"", ""total"", ""type""), sep = ""!!"") %>% 
  mutate(type = coalesce(type, total)) %>% 
  select(name, label = type)

if (!file.exists(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))) {
  
  acs_race <- map_df(state.abb, ~get_acs(geography = ""school district (unified)"", 
                                         variables = race_vars$name,
                                         state = .x))
  
  saveRDS(acs_race, here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
  
} else {
  
  acs_race <- readRDS(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
}





# Recoding ACS and aggregating data, sadly not easy to determine Hispanic origin ----
# Following methodology from WaPo repo, recoding Native Hawaiian and Pacifici Islander into Asian.
diversity_data <- acs_race %>% 
  left_join(race_vars, by = c(""variable"" = ""name"")) %>% 
  mutate(label = case_when(label == ""White alone"" ~ ""White"",
                           label == ""Black or African American alone"" ~ ""Black"",
                           label == ""American Indian and Alaska Native alone"" ~ ""AIAN"",
                           label == ""Native Hawaiian and Other Pacific Islander alone"" ~ ""Asian"",
                           label == ""Asian alone"" ~ ""Asian"",
                           label == ""Two or more races"" ~ ""Multi"",
                           label == ""Some other race alone"" ~ ""Other"",
                           TRUE ~ label)) %>% 
  group_by(GEOID, NAME, label) %>% 
  summarize_at(vars(estimate), sum) 


# Using Simpson's Diversity Index instead of max race metrics for diversity----
totals <- diversity_data %>% 
  summarize(total = sum(estimate)*(sum(estimate)-1))

dvs_score <- diversity_data %>% 
  filter(label != ""Total"") %>% 
  mutate(es_minus = estimate-1) %>% 
  summarize(numerator = sum(estimate*es_minus)) %>% 
  left_join(totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID, NAME, diversity) 
  
acs_diversity <- diversity_data %>% 
  spread(label, estimate) %>% 
  select(-Total) %>% 
  left_join(dvs_score) %>% 
  rename(acs_diversity = diversity) %>% 
  ungroup() %>% 
  mutate(NAME = tolower(NAME),
         NAME = str_remove(NAME, ""\\(.+\\)""),
         NAME = str_replace_all(NAME, "";"", "","")) %>% 
  separate(NAME, c(""NAME"", ""state""), sep = "","") %>% 
  mutate(NAME = str_remove_all(NAME, ""school district*+"")) %>% 
  select(GEOID, acs_diversity)

# Use WaPo data and calculate Simpson's Diversity Index
upd_school <- school_diversity %>% 
  filter(SCHOOL_YEAR == ""2016-2017"") %>% 
  select(LEAID, LEA_NAME, ST, SCHOOL_YEAR, AIAN:Total) %>% 
  pivot_longer(AIAN:Multi, ""race"", ""value"") %>% 
  mutate(n = floor(Total * value))

school_totals <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  summarize(total = sum(n)*(sum(n)-1))
  
upd_school_dvs <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  mutate(n_minus = n-1) %>% 
  summarize(numerator = sum(n*n_minus)) %>% 
  left_join(school_totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID = LEAID, NAME = LEA_NAME, ST, school_diversity = diversity) 

# Environment Cleanup---
remove(list = ls()[str_which(ls(), ""upd_school_dvs|acs_diversity"", negate = TRUE)])

# Comparing the two diversity measures and creating the ratio ----
overall_diversity <- upd_school_dvs %>% 
  left_join(acs_diversity, by = ""GEOID"") %>% 
  mutate(ratio = school_diversity/acs_diversity) %>% 
  filter(!is.na(acs_diversity))

# Get School District maps ----

if (!file.exists(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))) {
  
  district_maps <- map(state.abb, ~school_districts(.x, class = ""sf""))
  
  saveRDS(district_maps, here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
  
} else {
  
  district_maps <- readRDS(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
}



# One do.call to keep them all, and in the shallows bind them----
maps <- do.call(sf:::rbind.sf, district_maps)

plot <- overall_diversity %>%
  right_join(maps, ., by = ""GEOID"") %>%
  filter(!ST %in% c(""HI"", ""AK"")) %>%
  ggplot() +
  geom_sf(aes(fill = ratio), color = 'white', size = 0.01) +
  scale_fill_viridis_c(""Alignment Ratio"", option = ""cividis"", limits = c(0, 1), labels = scales::percent, na.value = ""white"") +
  coord_sf(crs = 26915) +
  labs(title = ""Is Diversity In School Districts Reflected In The Diversity Of The General Population?"",
       subtitle = glue(""Shown below is a choropleth map illustrating the ratio between the Diversity Index of a School Population and the Diversity Index of the General Population in that School District in 2017.<br>
       The more {highlight_text('yellow', '#FFEA46', 'b')} an area, the greater alignment between diversity indices.  The more {highlight_text('blue', '#00204D', 'b')} an area, the greater the difference between the diversity of the school and the general populace.<br> 
       This analysis focused on unified school districts and available data on race from the ACS Survey.  Diversity was calculated using Simpson's Diversity Index.""),
       caption = ""Data: **Washington Post via @dataKateR & American Community Survey** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
          markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week39"", ""tw39_plot.png""), width = 16, height = 10, device = ragg::agg_png())
","2019-39"
"187",48,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week4/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)



incar_data <- here(""2019"",""week4"",""data"") %>% 
  dir(full.names = TRUE, pattern = ""incarceration"") %>% 
  read_excel()

fix_null <- function(x) if_else(is.nan(x), NA_real_, x)

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") %>% 
  mutate_at(""id"", as.numeric)

ratio_data <- incar_data %>% 
  group_by(year, fips, state, county_name) %>% 
  transmute(black_pop_ratio = black_pop_15to64/total_pop_15to64,
         black_prison_ratio = black_prison_pop/total_prison_pop,
         asian_pop_ratio = asian_pop_15to64/total_pop_15to64,
         asian_prison_ratio = asian_prison_pop/total_prison_pop,
         latino_pop_ratio = latino_pop_15to64/total_pop_15to64,
         latino_prison_ratio = latino_prison_pop/total_prison_pop,
         native_pop_ratio = native_pop_15to64/total_pop_15to64,
         native_prison_ratio = native_prison_pop/total_prison_pop,
         white_pop_ratio = white_pop_15to64/total_pop_15to64,
         white_prison_ratio = white_prison_pop/total_prison_pop) %>% 
  group_by(fips, state, county_name) %>% 
  summarize_at(vars(contains(""ratio"")), mean, na.rm = TRUE) %>% 
  mutate_at(vars(contains(""ratio"")), fix_null)


map_data <- left_join(us_map, ratio_data, by = c(""id"" = ""fips""))  %>% 
  ungroup() %>% 
  gather(""variable"",""percentage"", contains(""ratio"")) %>% 
  separate(variable, c(""ethnicity"", ""category""), sep = ""_"")

plot <- ggplot() +
  geom_map(data = us_map, map = us_map,
           aes(x = long, y = lat, map_id = id),
           color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = map_data, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = percentage),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis_c("""", na.value = ""white"", option = 'cividis', labels = scales::percent) +
  coord_map() +
  labs(title = ""Differences between the General and Prison Population by County and Ethnic Group from 1970 to 2016"",
       subtitle = str_wrap(""Non-white and non-Asian ethnic groups in the South-Eastern United States have a higher average representation in prison than in the overall population.  Missing data indicated by no fill color."",  90),
       caption = ""Data: Vera Institute of Justice | Graphic: @jakekaupp"") +
  facet_grid(category ~ ethnicity , labeller = labeller(category = c(""pop"" = ""Total\nPopulation"", ""prison"" = ""Prison\nPopulation""),
                                                       ethnicity = str_to_title)) +
  theme_map(base_family = ""Scope One"", 
            base_size = 16) +
  theme(plot.caption = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        legend.position = ""bottom"",
        legend.justification = ""center"",
        legend.direction = ""horizontal"",
        legend.key.height = unit(0.2, ""cm""),
        legend.key.width = unit(1, ""cm""),
        strip.background = element_blank(),
        strip.text.y = element_text(angle = 0))

ggsave(here(""2019"",""week4"",""tw4_choro.png""), width = 11, height = 5)

","2019-4"
"188",49,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week40/R/analysis.R","library(tidyverse)
library(sf)
library(tigris)
library(glue)
library(colorspace)
library(jkmisc)
library(ggforce)
library(ragg)
library(here)

# Get TidyTuesday data
pizza_datafiniti <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_datafiniti.csv"") %>% 
  filter(province == ""NY"") %>% 
  distinct(name, latitude, longitude)

pizza_barstool <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_barstool.csv"") %>% 
  distinct(name, latitude, longitude) %>% 
  filter(!is.na(latitude))

# Get all New York County road maps
counties <- c(""New York County"", ""Kings County"", ""Bronx County"", ""Richmond County"",  ""Queens County"")

roads_data <- map(counties, ~roads(""NY"", .x, class = ""sf"")) %>% 
  do.call(sf:::rbind.sf, .)

# Build plot colors as a named vector and as a tibble
plotcolors <- c('Other' = '#cccccc',
                'Ave' = '#59c8e5',
                'St' = '#fed032',
                'Tunl' = '#fed032',
                'Brg' = '#fed032',
                'N' = '#fed032',
                'S' = '#fed032',
                'E' = '#fed032',
                'W' = '#fed032',
                'Rd' = '#4cb580',
                'Dr' = '#0a7abf', 
                'Hwy' = '#ff9223', 
                'Plz' = '#ff9223',
                'Viaduct' = '#ff9223', 
                'Expy' = '#ff9223', 
                'Pkwy' = '#ff9223',
                'Thruway' = '#ff9223',
                'State Hwy' = '#ff9223',
                'State' = '#ff9223',
                'US Hwy' = '#ff9223',
                'Blvd'= '#2e968c')

pc_tibble <- tibble(street_type = names(plotcolors),
                    color = plotcolors)

# Assign street types to roads
roads <- roads_data %>% 
  filter(!is.na(RTTYP)) %>% 
  mutate(street_type = map_chr(FULLNAME, ~first(names(plotcolors)[str_which(.x, glue(""{names(plotcolors)}\\b""))]))) %>% 
  mutate(street_type = if_else(str_detect(FULLNAME, ""I-""), 'I-', street_type)) %>% 
  mutate(street_type = case_when(is.na(street_type) & MTFCC == ""S1100"" ~ 'Expy',
                                 is.na(street_type) & MTFCC == ""S1200"" ~ 'St',
                                 is.na(street_type) & !MTFCC %in% c(""S1100"", ""S1200"") ~ ""Other"",
                                 TRUE ~ street_type)) %>% 
  left_join(pc_tibble, by = ""street_type"")

# Get Counties shapefiles to determine which pizza places are in the areas I want
counties_sf <- counties(""NY"", class = ""sf"") %>% 
  filter(NAMELSAD %in% counties)

# Use st_intersects and filter to remove out of bounds pizza places
pizza_sf_df <- st_as_sf(pizza_datafiniti, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
pizza_sf_bs <- st_as_sf(pizza_barstool, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
  
  
# Filter to pizza places in the five boroughs
ny_pizza_df <-  filter(pizza_sf_df, map_lgl(st_intersects(pizza_sf_df, counties_sf), ~!is_empty(.x)))

ny_pizza_bs <-  filter(pizza_sf_bs, map_lgl(st_intersects(pizza_sf_bs, counties_sf), ~!is_empty(.x)))

ny_pizza <- sf:::rbind.sf(ny_pizza_bs, ny_pizza_df) %>% 
  distinct(geometry)

# Construct the color legend
legend <- pc_tibble %>% 
  filter(street_type %in% c(""Other"",""Ave"",""St"", ""Rd"", ""Dr"", ""Hwy"", ""Blvd"")) %>% 
  mutate(street_type = factor(street_type, levels = c(""Other"", ""Ave"", ""Dr"", ""Rd"", ""Blvd"", ""St"", ""Hwy""), labels = c(""Other"", ""Avenue"", ""Drive"", ""Road"", ""Boulevard "", ""Street"", ""Highway""))) %>%
  arrange(street_type) %>% 
  mutate(x0 = seq(3, by = 4.5, length.out = 7),
         r = 1.75,
         y0 = 0) %>% 
  ggplot(aes(x0 = x0, y0 = y0, r = r)) +
  geom_circle(aes(fill = color, color = darken(color))) +
  geom_text(aes(label = street_type, x = x0, y = 0), family = ""Lora"", size = 3) +
  annotate(""text"", family = ""Oswald"", x = -2, y = 0, label = ""Legend"", size = 6) +
  scale_fill_identity() +
  scale_color_identity() +
  expand_limits(y = c(-0.5, 4),
                x = c(-4, 24)) +
  labs(x = NULL,
       y = NULL) +
  coord_equal(clip = ""off"") +
  theme_jk(grid = FALSE, plot_title_size = 30) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 

legend_grob <- ggplotGrob(legend)

subtitle <- ""Shown on this map are the roads and the pizza places of the Five Boroughs of New York City.  
Pizza places are distinct locations almagamated from the DataFiniti and Barstool datasets, and a represented by purple dots.  Manhattan is the most represented borough in the dataset, unsurprising given the relative population, and it being the home of the Teenage Mutant Ninja Turtles.
The map style of plotting the colored roads were inspired by Erin Davis (erdavis1 on github), and her series of circular maps of World Cities.""

caption <- ""Data: DataFiniti, Barstool, US Census Shapefiles\nGraphic: @jakekaupp""


# Plot the Street maps and Pizza place data
pizza_map <- ggplot() +
  geom_sf(data = filter(roads, street_type != ""Other""), aes(color = color), size = 0.25) + 
  geom_sf(data = filter(roads, street_type == ""Other""), aes(color = color), size = 0.35) + 
  geom_sf(data = ny_pizza, color = darken(""#963484""), fill = ""#963484"", shape = 21, size = 2, alpha = 0.5) +
  annotate(""text"", label = ""Pizza Places of the Five Boroughs"", family = ""Oswald"", x = -74.3, y = 40.91, size = 6, hjust = 0) +
  annotate(""text"", family = ""Lato"", label = str_wrap(subtitle, 60), x = -74.3, y = 40.89, hjust = 0, vjust = 1) +
  annotate(""text"", family = ""Lato"", label = caption, x = -74.3, y = 40.78, hjust = 0, vjust = 1) +
  annotation_custom(legend_grob, xmin = -74.2, xmax = Inf, ymin = 40.49, ymax = 40.55) +
  scale_color_identity() +
  scale_size_identity() +
  coord_sf(clip = ""off"") +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 


ggsave(here('2019', 'week40', 'tw40_plot.png'), width = 12, height = 9, dev = agg_png())","2019-40"
"189",50,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week41/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(janitor)
library(jkmisc)
library(ggforce)
library(ggtext)
library(nord)
library(glue)
library(ragg)

# It's 250mb, can't put it into git, you're going to have to go get it
# from https://openpowerlifting.org/data and stick it in data.
pl_data <- here(""2019"", ""week41"", ""data"") %>% 
  dir(pattern = ""openpowerlifting"", full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

plot_data <- pl_data %>%
  filter_at(vars(starts_with(""best"")), all_vars(. > 0)) %>% 
  filter(str_detect(place, ""1"")) %>% 
  mutate(year = year(date)) %>%
  select(-date) %>%
  mutate_at(vars(starts_with(""best"")), ~./bodyweight_kg) %>% 
  pivot_longer(starts_with(""best""), names_to = ""lift"") %>% 
  group_by(year, sex, lift) %>%
  filter(value == max(value, na.rm = TRUE)) %>% 
  arrange(lift, sex, year)

labels <- tibble(label = c(""Bench Press"", ""Deadlift"", ""Squat""),
                 lift = c(""best3bench_kg"", ""best3deadlift_kg"", ""best3squat_kg""),
                 year = 2020,
                 value = 1)

annotations <- plot_data %>% 
  group_by(sex, lift) %>% 
  filter(value == max(value, na.rm = TRUE)) %>% 
  mutate(description = glue(""Weight: {bodyweight_kg} kg\nLifted: {bodyweight_kg*value} kg\n{federation}: {meet_name}""),
         name = str_remove(name, ""\\#[0-9]""))

plot <- ggplot(plot_data, aes(x = year, y = value)) +
  geom_path(aes(color = sex)) +
  geom_point(aes(fill = sex), shape = 21, color = ""#2E3440"") +
  geom_text(data = labels, aes(label = label), color = ""#E5E9F0"", family = ""Oswald"", fontface = ""bold"", size = 10, hjust = 1) +
  geom_mark_circle(data = filter(annotations, sex == ""M""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  geom_mark_circle(data = filter(annotations, sex == ""F""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  facet_wrap(~lift) +
  scale_color_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_fill_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_x_continuous(breaks = seq(1970, 2020, 10)) +
  theme_jk(dark = TRUE, 
           grid = ""XY"",
           markdown = TRUE) +
  labs(x = NULL,
       y = NULL,
       title = ""Evolution of Power: How the Ratio of Bodyweight to Lifted Weight Has Progressed"",
       subtitle = glue(""Illustrated below is the maximum of the ratio of bodyweight to lifted weight for winning lifts in each year and event for both {highlight_text('Men', '#314cb6', 'b')} and {highlight_text('Women', '#DD2A7B', 'b')} for all meets recorded by Open Powerlifting.""),
       caption = ""Data: **openpowerlifting.org** | Graphic: **@jakekaupp**"") +
  theme(legend.position = ""none"",
        panel.grid.major = element_line(size = 0.01),
        strip.text = element_blank())

ggsave(here('2019', 'week41', 'tw41_plot.png'), plot, width = 15, height = 8, device = agg_png())","2019-41"
"190",51,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week42/R/analysis.R","library(tidyverse)
library(here)
library(janitor)
library(jkmisc)
library(ggalt)
library(ggtext)
library(glue)
library(ragg)

big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")

top <- big_epa_cars %>% 
  clean_names() %>% 
  count(make, year) %>% 
  count(make) %>% 
  filter(n == 37)

plot_data <- big_epa_cars %>% 
  clean_names() %>% 
  select(make, v_class, year, you_save_spend) %>% 
  semi_join(top) %>% 
  group_by(year, make) %>% 
  summarize(total_save_spend = mean(you_save_spend)) %>%
  group_by(year) %>% 
  mutate(rank = min_rank(desc(total_save_spend))) %>% 
  ungroup() %>% 
  mutate(size = if_else(make == ""Ford"", 1, 0.5),
         make = factor(make, pull(top, make)),
         make = fct_relevel(make, ""Ford"", after = Inf),
         make = fct_recode(make, ""**Ford**"" = ""Ford""))


grid <- tibble(rank = 1:22)

colors <- set_names(grey.colors(22), pull(top, make) %>%
                      factor() %>%
                      fct_recode(""**Ford**"" = ""Ford""))

colors[[""**Ford**""]] <- ""#DD2A7B""


plot <- ggplot(plot_data, aes(x = year, y = rank)) +
  geom_segment(data = grid, aes(x = 1983, xend = 2021, y = rank, yend = rank), color = ""#cccccc"", alpha = 0.5, size = 0.1) +
  geom_xspline(aes(color = make, size = size), show.legend = FALSE) +
  geom_point(aes(fill = make), shape = 21, color = ""white"", show.legend = FALSE) +
  geom_richtext(data = filter(plot_data, year == 2020), aes(label = as.character(make), x = 2021, color = make), hjust = 0, family = ""Lora"", size = 4, show.legend = FALSE,  fill = NA, label.color = NA, 
                label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_text(data = filter(plot_data, year == 1984), aes(label = rank, x = 1983), hjust = 1, family = ""Oswald"", size = 4) +
  labs(x = NULL,
       y = NULL,
       title = ""From Chugging to Sipping: Fuel Cost Savings of Major Automakers since 1984"",
       subtitle = glue(""Shown below is a rankings chart of average fuel cost savings, measured over 5 years, from 1984 to 2020.  {highlight_text('Ford','#DD2A7B', 'b')} has had quite the journey, battling from the bottom<br>of the list to the second-best North American manufacturer."")) +
  scale_color_manual(values = colors) +
  scale_fill_manual(values = colors) +
  scale_size_identity() +
  scale_x_continuous(breaks = 1984:2020) +
  scale_y_continuous(trans = ""reverse"", breaks = NULL) +
  expand_limits(x = 2025) +
  theme_jk(grid = ""X"", 
           markdown = TRUE)

ggsave(here(""2019"", ""week42"", ""tw42_plot.png""), plot = plot, width = 13, height = 6)
","2019-42"
"191",52,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week43/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggraph)
library(tidygraph)
library(glue)
library(jkmisc)
library(colorspace)
library(ggforce)
library(ggtext)

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

movie_cast <- distinct(horror_movies, title, release_date, review_rating, .keep_all = TRUE) %>% 
  mutate(year = str_extract(title, ""\\((\\d{4})\\)""),
         year = parse_number(year),
         title = str_remove(title, ""(\\s\\(\\d{4}\\))""),
         date = dmy(release_date)) %>% 
  arrange(title) %>% 
  separate_rows(cast, sep = ""\\|"") %>% 
  mutate(cast = trimws(cast)) %>% 
  select(title, year, review_rating, cast)

cast_df <- left_join(movie_cast, movie_cast, by = c(""title"", ""year"", ""review_rating"")) %>% 
  rename(from = cast.x,
         to = cast.y) %>% 
  filter(from != to) 

nodes <- cast_df %>% 
  group_by(from) %>% 
  summarize(node_size = n_distinct(title)) %>% 
  distinct(from, .keep_all = TRUE) 

focus <- ""Eric Roberts""

edges <- cast_df %>% 
  count(from, to, sort = TRUE, name = ""edge_size"") %>% 
  distinct(from, to, .keep_all = TRUE) %>% 
  mutate(color = if_else(from == focus | to == focus, ""#bb0a1e"", ""#373e40""),
         alpha = if_else(from == focus | to == focus, 1, 0.2),
         size = if_else(from == focus | to == focus, 1, 0.1))

connected <- filter(edges, from == focus) %>% 
  distinct() %>% 
  pull(to) 

cast_network <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE) %>% 
  activate(nodes) %>% 
  mutate(degree = centrality_eigen(),
         alpha = if_else(from %in% c(focus, connected),  1, 0.2)) %>% 
  top_n(500, degree) %>% 
  mutate(fill = if_else(from %in% c(focus, connected), ""#bb0a1e"", ""#373e40""),
         color = if_else(from %in% c(focus, connected), darken(""#bb0a1e""), darken(""#373e40"")))

plot <- ggraph(cast_network, layout = ""graphopt"") + 
  geom_edge_link(aes(alpha = stat(index), edge_colour = color, edge_width = size), show.legend = FALSE) + 
  geom_node_point(aes(size = node_size, fill = fill, color = color), shape = 21, show.legend = FALSE) +
  #geom_mark_circle(aes(x, y, filter = from == focus, label = from, description = ""Legendary B-Movie Actor""), expand = unit(0, ""mm""), label.family = c(""Oswald"", ""Lora"")) +
  scale_edge_color_identity() +
  scale_alpha_identity() +
  scale_fill_identity() +
  scale_edge_width_identity() +
  scale_color_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Horror Movie Co-Star Networks of the Top 500 Prolific Performers"",
       subtitle = glue(""The reach of B-movie legend {highlight_text('Eric Roberts', '#bb0a1e', 'b')} is featured below across his 27 films. Prolific performers determined by the top 500<br>actors by eigenvalue centrality.""),
       caption = ""Data: **IMDB** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
           markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week43"", ""tw43_plot.png""), plot, width = 10, height = 6, device = ragg::agg_png())

  
","2019-43"
"192",53,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week44/R/analysis.R","library(tidyverse)
library(waffle)
library(lubridate)
library(jkmisc)
library(scales)
library(colorspace)
library(patchwork)
library(ggtext)
library(glue)
library(here)

#Get the data ----
nyc_squirrels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

# Process the data ----
activity_data <- nyc_squirrels %>% 
  mutate(date = mdy(date)) %>% 
  pivot_longer(names_to = ""activity"", running:foraging) %>%
  group_by(date, activity) %>% 
  summarize(value = sum(as.numeric(value))) %>% 
  mutate(activity = factor(activity, labels = unique(activity)),
         activity = fct_reorder(activity, value, .fun = sum)) %>% 
  arrange(date, desc(activity))

# Make my palette

slate_ramp <- colorRampPalette(c(""#3B454A"", lighten(""#3B454A"", 0.8)))(5) 

grey_ramp <- grey.colors(5, 0.5, 0.9)

pal <- set_names(slate_ramp, unique(activity_data$activity))

pal[""foraging""] <- ""#DD2A7B""

partition_waffle <- function(x, start, nrows, flip = FALSE) {
  
   offset <- start - x
  
   offset_rows <- offset %/% nrows
   
   offset_blocks <- offset %% nrows
   
  
   comp_blocks <- nrows - offset_blocks
   
   if (comp_blocks != nrows) {
     
     rows <- (x - comp_blocks) %/% nrows
     
     blocks <- (x - comp_blocks) %% nrows
     
     start_row <- offset_rows + rows + 1
     
     if (blocks == 0) {
       
       end_row <- start_row
       
     } else {
       
       end_row <- start_row + 1 
       
     }
     
   } else {
     
     rows <- x %/% nrows
     
     blocks <- x %% nrows
     
     start_row <- rows + offset_rows
     
     end_row <- rows + offset_rows + 1
     
   }
   
   
   if (flip) {
     
     tibble(y = c(start_row, start_row, end_row),
            yend = c(start_row, end_row, end_row),
            x = c(blocks, blocks, 0),
            xend = c(nrows, blocks, blocks))
     
     
   } else {
     
     tibble(x = c(start_row, start_row, end_row),
            xend = c(start_row, end_row, end_row),
            y = c(blocks, blocks, 0 -1),
            yend = c(nrows + 1, blocks, blocks))
   }
     
     

   
  
} 

# Waffles by activity ----

activity_outlines <- activity_data %>% 
  ungroup() %>% 
  arrange(desc(activity), date) %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, flip = FALSE, nrows = 20)) %>% 
  unnest(lines) %>% 
  filter(date == last(date))

activity_labels <- activity_data %>% 
  group_by(activity) %>% 
  summarize(total = sum(value)) %>%
  left_join(filter(activity_outlines, yend == 21), by = ""activity"")

waffle_by_activity <- activity_data %>% 
  arrange(desc(activity), date) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = activity_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""black"", size = 0.5) +
  geom_richtext(data = activity_labels, aes(label = glue(""<b>{str_to_title(activity)}</b>""), x = x, y = yend, color = activity), fill = ""white"", hjust = 1, vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = activity_labels, aes(label = glue(""{total}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_color_manual(values = pal) +
  coord_equal() +
  labs(x = NULL, 
       y = NULL) +
  theme_jk(grid = FALSE) +
  scale_x_continuous(expand = c(0,0)) +
  expand_limits(y = c(-5, 25), x = c(0, 200)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffles by day ----

by_day_outlines <- activity_data %>% 
  ungroup() %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE)) %>% 
  unnest(lines) %>% 
  filter(activity == ""chasing"")

by_day_labels <- activity_data %>% 
  group_by(date) %>% 
  summarize(total = sum(value)) %>% 
  left_join(filter(by_day_outlines, yend == 21))

waffle_by_day <- activity_data %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = by_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{month.abb[month(date)]} {day(date)}""), x = x, y = yend), fill = ""white"", color = ""black"", hjust = c(rep(1,10), 0), vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{total}""), x = x, y = -1), fill = ""white"", color = ""black"", hjust = c(rep(0,9),1,0), vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_x_continuous(expand = c(0,0)) +
  coord_equal(clip = ""off"") +
  labs(x = NULL, 
       y = NULL) +
  expand_limits(y = c(-5, 25), x = c(0, 205)) +
  theme_jk(grid = FALSE) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffle bars by day ----

waffle_day_outlines  <- activity_data %>% 
  arrange(desc(date)) %>% 
  filter(activity == ""foraging"") %>% 
  ungroup() %>%
  group_split(date) %>% 
  map(~mutate(.x, cum_sum = cumsum(value))) %>%
  map_dfr(~mutate(.x, lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE))) %>%
  unnest(lines) 

waffle_labels <- waffle_day_outlines %>% 
  filter(y == -1)

mday_label <- function(x) {
  
  glue(""{month.abb[month(x)]} {day(x)}"")
  
}

split_waffle_by_day <- activity_data %>% 
  arrange(desc(date)) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = waffle_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = waffle_labels, aes(label = glue(""{value}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  coord_equal() +
  scale_color_manual(values = pal) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  facet_wrap(~date, nrow = 1, as.table = FALSE, strip.position = ""top"", labeller = labeller(date = mday_label)) +
  expand_limits(y = c(-5, 20)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

out <- wrap_plots(waffle_by_activity, waffle_by_day, split_waffle_by_day, ncol = 1) +
  plot_annotation(title = ""Breakdown of Observed Squirrel Activity from the 2018 NYC Squirrel Census"",
                  subtitle = glue(""Below are  waffle charts of activity totals (I), daily totals (II) and exploded daily activity (III) views of observed squirrel activity.<br>{highlight_text('Foraging', '#DD2A7B', 'b')} is the most frequently observed activity recorded in the census, not surprising for squirrels in the fall.""),
                  caption = ""Data: **NYC Data Portal** | Graphic: **@jakekaupp**"",
                  tag_levels = ""I"",
                  theme = theme_jk(markdown = TRUE))

ggsave(here(""2019"", ""week44"", ""tw44_plot.png""), out, width = 11, height = 8, dev = ragg::agg_png(), dpi = ""print"")

","2019-44"
"193",54,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week45/R/analysis.R","library(tidyverse)
library(jkmisc)
library(glue)

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

total_avg <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  mutate(state = ""US"",
         state_abb = ""US"")

slope_data <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(state, state_abb, mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  ungroup() %>% 
  mutate(state_abb = ifelse(is.na(state_abb), ""DC"", state_abb))

direct_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(-3:-6)

direct_labels_bike <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  top_n(5, avg)

mid_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(3:6) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
    avg = mean(.$avg),
    y = min(.$avg),
    yend = max(.$avg))
  
lower_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  arrange(-avg) %>% 
  slice(9:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))

lower_bike_labels <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  arrange(-avg) %>% 
  slice(6:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))


ggplot(slope_data, aes(x = mode, y = avg)) +
  geom_line(aes(group = state), size = 0.2) +
  geom_line(data = total_avg, aes(group = state), color = ""#DD2A7B"", size = 1) +
  geom_point(shape = 21, color = ""white"", stroke = 0.2, fill = ""black"", size = 2) +
  geom_text(data = direct_labels, aes(label = state_abb),  nudge_x = 0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = direct_labels_bike, aes(label = state_abb),  nudge_x = -0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = mid_labels, aes(label = state_abb),  nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_bike_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = -0.5, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.95, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.91, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL,
       title = ""Bicycling and Walking to Work in the United States: 2008-2012"",
       subtitle = glue(""Illustrated below is a slopegraph contrasting the percentage of population that bikes to work and the percentage<br>that bikes to work as well as {highlight_text('the US average', '#DD2A7B', 'b')}"")) +
  scale_x_discrete(labels = c(""Bike to Work"", ""Walk to Work"")) +
  theme_jk(grid = ""XY"",
           markdown = TRUE) +
  theme(panel.grid.major = element_line(linetype = ""dashed""))
  
","2019-45"
"194",55,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week5/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(here)
library(scales)

milk_cow_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milkcow_facts.csv"")

milk_product_facts <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milk_products_facts.csv"")

us_pop <- read_csv(here(""2019"", ""week5"", ""data"",""us-population-1990-to-2016.csv""))

totals <- milk_product_facts %>% 
  mutate(total_consumption = rowSums(select(., -year))) %>% 
  select(year, total_consumption)

full_data <- left_join(milk_cow_data, totals) %>% 
  left_join(us_pop) %>% 
  mutate(total_consumption_lbs = total_consumption * population)


ggplot(full_data, aes(y = total_consumption_lbs, x = milk_production_lbs)) +
  geom_xspline2(aes(s_open = TRUE, s_shape = 0.5)) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 1) +
  scale_y_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  scale_x_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  labs(x = ""US Milk Production (lbs)"",
       y = ""US Average Dairy Consumption (lbs)"",
       title = ""100 Slices of American Cheese or, the Fable of Supply Management"",
       subtitle = str_wrap(""The connected scatterplot below illustrates the relationship between total average dairy consumption and total milk production over the past 25 years.
                           US supply far exceeds the demand, highlighting overproduction and a case for supply management."", 120)) +  
  theme_jk()
","2019-5"
"195",56,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week6/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(lubridate)
library(here)
library(scales)
library(janitor)
library(ggrepel)
library(patchwork)

state_hpi <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")

prime_rates <- read_csv(here(""2019"",""week6"",""data"",""MPRIME.csv"")) %>% 
  clean_names() %>% 
  mutate(year = year(date)) %>% 
  select(-date) %>% 
  group_by(year) %>% 
  summarize_all(mean) %>% 
  filter(year %in% min(state_hpi$year):max(state_hpi$year))

highs <- filter(prime_rates, mprime %in% range(mprime)) %>% 
  distinct(mprime, .keep_all = TRUE)

plot_data <- state_hpi %>% 
  group_by(year, state) %>% 
  summarize_all(mean, na.rm = TRUE) 

prime <- ggplot(prime_rates, aes(x = year, y = mprime)) +
  geom_line(color = viridis_pal()(1), size = 0.5) +
  geom_point(data = highs, color = viridis_pal()(1)) +
  geom_text_repel(data = highs, aes(label = paste0(mprime, ""%"")), color = viridis_pal()(1), nudge_x = 2, nudge_y = 2, family = ""Oswald"", segment.size = 0) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  theme_jk(grid = ""XY"") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Interest Rates Fall, Housing Prices on the Rise"",
       subtitle = str_wrap(""The top chart shows the average prime interest rate by year since 1975.  The bottom heatmap illustrates the yearly average housing price index by State since 1975."", 100))


heatmap <- ggplot(plot_data, aes(x = year, y = fct_reorder(state, price_index, .fun = mean), fill = price_index)) +
  geom_tile(color = ""white"", size = 0.05) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  scale_fill_viridis_c(""House Price Index"", option = ""viridis"", direction = 1, breaks = pretty_breaks(5)) +
  scale_color_identity() +
  labs(x = NULL, y = NULL, caption = ""Data: FRED | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"",
        legend.key.width = unit(1, ""cm""))


out <- patchwork::wrap_plots(prime, heatmap, heights = c(0.2,1), ncol = 1)

ggsave(here(""2019"", ""week6"", ""tw6_plot.png""), out, width = 8, height = 10)
","2019-6"
"196",57,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week7/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(janitor)
library(jkmisc)
library(nord)

oecd_data <- here(""2019"", ""week7"", ""data"", ""OECD--1.xlsx"") %>% 
  read_excel(skip = 1, na = c(""na"")) %>% 
  clean_names() %>% 
  filter(!is.na(x1995)) %>% 
  rename(country = x1) %>% 
  gather(year, intensity, -country) %>% 
  arrange(country, year) %>% 
  fill(intensity, .direction =  ""down"") %>% 
  mutate(year = parse_number(year)) %>% 
  group_by(year) %>% 
  arrange(year, intensity) %>% 
  mutate(rank = row_number(-intensity)) %>% 
  ungroup() %>% 
  mutate(color = if_else(country == ""Canada"", nord(""victory_bonds"")[2], nord(""snowstorm"", 1)),
         text_color = if_else(country == ""Canada"", nord(""snowstorm"", 1), ""black""))




plot <- ggplot(oecd_data, aes(x = year, y = -rank, group = country)) +
  geom_line(aes(color = color)) +
  geom_point(aes(color = color)) +
  geom_text(data = filter(oecd_data, year == min(year)), aes(label = rank, color = color), x = 1994, hjust = 0, family = ""Oswald"") +
  geom_text(data = filter(oecd_data, year == max(year)), aes(label = country, color = color), x = 2016.5, hjust = 0, family = ""Oswald"") +
  expand_limits(x = c(1994, 2019)) +
  scale_x_continuous(breaks = 1995:2016) +
  scale_color_identity() +
  theme_jk(dark = TRUE, grid = FALSE) +
  theme(axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Canada is Losing a Step In the Global Research Race."",
       subtitle = str_wrap(""Shown below is the ranking of research intensity (% of Gross Domestic Product devoted to Research) from 1995-2016. Canada has been on a decline since hitting a peak in 2001.  Most notably is 2009-2016, which coincides with the systematic defunding of Canadian research scientists by the Conservative Harper Government."", 120),
       caption = ""Data: OECD | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week7"", ""tw7_plot.png""), plot, width = 9, height = 4.5)
","2019-7"
"197",58,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week8/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(readxl)
library(janitor)
library(jkmisc)
library(scales)
library(egg)

parse_table31 <- function(file) {
  
  df <- file %>% 
    read_excel(na = ""na"") %>% 
    clean_names()
  
  start <- min(str_which(df$x3,""\\d{4}""))
  
  end <- pull(df, 1) %>% 
    str_which(""Since"") %>% 
    max()
  
  df <- slice(df, start:end)
  
  field_idx <- select(df, -1) %>% 
    map_df(is.na) %>% 
    pmap_lgl(all)
  
  labels <- select(df, 1) %>%
    filter(field_idx) %>% 
    na.omit() %>% 
    pull() %>% 
    str_remove(""[abcd]$"")
  
  years <- slice(df, 1) %>% 
    select(-1) %>% 
    flatten_chr() %>% 
    str_remove(""\\.0+$"")
  
 rep <- filter(df, !field_idx) %>% 
    slice(-1) %>% 
    select(1) %>% 
    n_distinct()
  
  filter(df, !field_idx) %>% 
    slice(-1) %>% 
    mutate(discipline = rep(labels, each = rep)) %>% 
    set_names(c(""category"", years, ""discipline"")) %>% 
    gather(year, value, matches(""[0-9]{4}"")) %>% 
    mutate_at(vars(-category, -discipline), as.numeric) %>% 
    mutate_at(""category"", function(x) str_remove(x, ""[abcd]$""))
  
  
}


files <- here(""2019"",""week8"",""data"") %>% 
  dir_ls() 

data <- map_df(files, parse_table31) %>% 
  ungroup() %>% 
  distinct()

plot_data <- data %>% 
  filter(discipline != ""Other"", !str_detect(category, ""doctoral"")) %>% 
  filter(!str_detect(discipline, ""and (?!computer)"")) %>% 
  filter(!str_detect(discipline, ""Physical"")) %>% 
  arrange(year) %>% 
  group_by(category, discipline, year) %>% 
  summarize(value = mean(value, na.rm = TRUE)) %>% 
  ungroup()

plot <- ggplot(plot_data, aes(x = year, y = value, color = discipline)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(breaks = pretty_breaks(), limits = c(0, 25)) +
  scale_color_manual(""Discipline"", values = tol7qualitative) +
  scale_x_continuous(limits = c(1985, 2017)) +
  expand_limits(x = c(1985, 2025)) +
  facet_wrap(~category, labeller = as_labeller(str_to_title), nrow = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""Median Completion Time for Doctoral Degrees Are Getting Shorter"",
       subtitle = str_wrap(""Median completion time in years from 1985 to 2017 contrasting selected disciplines for both University and Graduate School experience.  Education, Humanities and Social Sciences doctoral candidates have a higher than average time to completion in both categories compared to other disciplines. "", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

ggsave(here('2019','week8',""tw8_plot.png""), plot, width = 10, height = 7)


bonus_plot_data <- plot_data %>% 
  filter(discipline == ""All fields"") %>% 
  rename(overall = value) %>% 
  select(-discipline) %>% 
  left_join(filter(plot_data, discipline != ""All fields"")) %>% 
  mutate(diff = abs(value - overall)/2) %>%
  filter(between(year, 1990, 2011))


order <- c(""Education"", ""Mathematics and computer sciences"",  ""Engineering"", ""Humanities"",""Life sciences"", 
   ""Social sciences"")

bonus_plot <- ggplot(bonus_plot_data, aes(ymin = -diff, ymax = diff, x = year, fill = fct_relevel(discipline, order))) +
  geom_ribbon(color = ""white"", size = 0.2, alpha = 0.8) +
  geom_segment(data = filter(bonus_plot_data, year == 2000, category == ""Since bachelor's"", discipline == ""Education""), aes(y = -diff, yend = diff, x = year, xend = year), color = ""grey20"", arrow = arrow(length = unit(0.25, ""cm""), ends = ""both"", type = ""closed"")) +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  scale_fill_viridis_d(""Discipline"") +
  scale_y_continuous(breaks = c(-5, -2.5, -1, 0, 1, 2.5, 5), labels = c(""10 Years"", ""5 Years"", ""2 Years"", ""Group Median"", ""2 Years"", ""5 Years"", ""10 Years"")) +
  labs(x = NULL,
       y = NULL,
       title = ""Relative Differences in Median Doctoral Completion Time from the Group Median by Discipline and Interval"",
       subtitle = str_wrap(""The streamgraph below presents the difference between discipline median completion time and the group median completion time (All Fields) as the width of each colored band (discipline) from 1990 to 2011."", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

bonus_plot <- tag_facet(bonus_plot, x = 1996, y = 5.5, open = """", close = """", tag_pool = c(""Difference from Group Median = 9.1 years"", """"),  fontface = 1, family = ""Oswald"") 



ggsave(here('2019','week8',""tw8_bonus_plot.png""), bonus_plot, width = 12, height = 6)
","2019-8"
"198",59,"https://github.com/jkaupp/tidytuesdays","jkaupp","tidytuesdays","2019/week9/R/analysis.R","library(tidyverse)
library(here)
library(ggforce)
library(jkmisc)
library(sf)
library(osmdata)

full_trains <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

available_tags(""railway"")

railways <- st_read(here(""2019"", ""week9"", ""data"", ""railways.shp""))

q <- getbb(""fr"") %>%
  opq(timeout=25*1000)%>%
  add_osm_feature(""railway"")

stations <- osmdata_sf(q)

ggplot(stations$osm_lines) +
  geom_sf()

railways$geometry[[1]] %>% st_coordinates() %>% as_tibble -> line

ggplot(line, aes(x = X, y = Y)) +
  geom_link2() +
  coord_sf(datum=NA)

nat_trains <- full_trains %>% 
  filter(service == ""National"") %>% 
  group_by(year, departure_station, arrival_station) %>% 
  summarize_at(vars(journey_time_avg, total_num_trips, avg_delay_late_at_departure, avg_delay_late_on_arrival), mean, na.rm = TRUE)


# Orbit test

centre <- ""PARIS LYON""

test_data <- filter(nat_trains, departure_station == centre | arrival_station == centre) %>% 
  arrange(departure_station)



positions <- test_data %>% 
  filter(arrival_station == centre) %>% 
  group_by(arrival_station, departure_station) %>% 
  summarize(dist = mean(journey_time_avg)) 


circles <- test_data %>% 
  group_by(departure_station) %>% 
  summarize(centre_radius = mean(avg_delay_late_at_departure)) %>% 
  left_join(positions)

main <- circles %>% 
  filter(departure_station == centre)

circles <- circles %>% 
  filter(departure_station != centre) %>% 
  mutate(fraction = nrow(.) - (nrow(.) - seq_along(departure_station)),
         delta = 360/nrow(.)*fraction) %>% 
  bind_rows(main) %>% 
  mutate(x0 = if_else(departure_station == centre, 0, dist*cos((delta*pi/180))),
         y0 = if_else(departure_station == centre, 0, dist*sin((delta*pi/180)))) 


link_coords <- function(dept, arr, lnk) {
  
  circles %>% 
    filter(departure_station == dept | departure_station == arr) %>%
    summarise(x = ifelse(lnk == ""from"", x0[x0 != 0], 0),
           xend = ifelse(lnk == ""from"", 0, x0[x0 != 0]),
           y = ifelse(lnk == ""from"", y0[y0 != 0], 0),
           yend = ifelse(lnk == ""from"", 0, y0[y0 != 0]))
  
  
  
}

links <- test_data %>% 
  group_by(departure_station, arrival_station) %>% 
  mutate(total_delay = ((avg_delay_late_at_departure + avg_delay_late_on_arrival)/journey_time_avg),
         total_trips = sum(total_num_trips)) %>% 
  summarize(size = mean(total_delay),
            alpha = mean(total_num_trips)/max(total_num_trips)) %>% 
  mutate(link = if_else(departure_station == centre, ""to"", ""from"")) %>% 
  ungroup() %>% 
  mutate(links = pmap(list(departure_station, arrival_station, link), ~link_coords(..1, ..2, ..3))) %>% 
  unnest() %>% 
  arrange(link, departure_station)




ggplot() +
  geom_curve(data = links, aes(x = x, xend = xend, y = y, yend = yend, size = size, color = link, alpha = alpha), lineend = ""round"", angle = 270) +
  geom_circle(data = circles, aes(x0 = x0, y0 = y0, group = departure_station, r = 5), fill = ""white"", color = ""#2b41a7"") +
  scale_size(range = c(1,6)) +
  scale_color_manual(values = c(""#2b41a7"", ""#c7ad24"")) +
  scale_fill_distiller(palette = ""Greys"")+
  scale_alpha_identity() +
  labs(x = NULL, y = NULL) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank())

","2019-9"
"199",60,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week1/R/tw1_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(ggrepel)

tidy_data <- dir(here(""week1"", ""data""), full.names = TRUE, pattern = ""us_avg"") %>%
  read_excel() %>%
  gather(year, avg_tuition, -State) %>%
  rename(state = State)


nat_avg <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  group_by(year) %>%
  summarize(avg_tuition = mean(avg_tuition)) %>%
  mutate(state = ""National Average"")


plot_data <- tidy_data %>%
  filter(year %in% c(""2005-06"", ""2015-16"")) %>%
  left_join(select(nat_avg, year, nat_avg = avg_tuition), by = ""year"") %>%
  bind_rows(nat_avg)

labels <- plot_data %>%
  group_by(state) %>%
  filter(all(avg_tuition > nat_avg)) %>%
  pull(state) %>%
  unique()

plot <- plot_data %>%
  ggplot(., aes(x = year, y = avg_tuition, group = state)) +
  geom_text_repel(data = filter(plot_data, state %in% labels, year == ""2015-16""), aes(label = state), direction = ""y"", nudge_x = 0.1, segment.size = 0.1, hjust = 0, family = ""Oxygen"", size = 3) +
  geom_path(color = ""grey50"", size = 0.5, alpha = 0.5) +
  geom_point(color = ""grey50"") +
  geom_path(data = nat_avg, color = ""red"", size = 1) +
  geom_point(data = nat_avg, color = ""red"") +
  scale_y_continuous(labels = scales::dollar) +
  labs(x = NULL, y = NULL, title = ""Comparison of the average US tuition growth between 2005 and 2015"", subtitle = ""Eastern and Northeastern students consistently face tutition above the national average, indicated by the red line."", caption = ""\nData: http://trends.collegeboard.org/ | Graphic: @jakekaupp"") +
  theme_minimal(base_family = ""Oswald Light"") +
  theme(panel.grid.minor = element_blank())

ggsave(plot, filename = glue('{here(""week1"")}/tidyweek-{Sys.Date()}.png'), height = 8, width = 6, dpi = 300)

","2018-1"
"200",61,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week11/R/tw11_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)

raw_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week11_fifa_audience.csv"") %>% 
  select(-X1)

font_add_google(""Oswald"",""Oswald-Light"", regular.wt = 300)
font_add_google(""Scope One"",""Scope One"")

showtext_auto()

vplayout <- function(x, y) viewport(width=11/3, height=8.5, layout.pos.row = x, layout.pos.col = y)

build_treemap <- function(x, y, size)  {
  
  title <- set_names(c(""Population Share"", ""TV Audience Share"", ""GDP Weighted Share""), c(""population_share"",""tv_audience_share"", ""gdp_weighted_share""))
  
  treemap(raw_data,
          index = c(""confederation"",""country""),
          vSize = size,
          vColor = ""confederation"",
          type = ""categorical"",
          title = title[size],
          title.legend = """",
          fontfamily.title = ""Oswald-Light"",
          fontsize.labels = c(20, 10),
          fontfamily.labels = ""Oswald-Light"",
          fontcolor.labels = ""#f0f0f0"",
          lowerbound.cex.labels = 1,
          bg.labels = 0,
          inflate.labels = FALSE,
          border.col = ""white"",
          border.lwds = 1,
          position.legend = ""none"",
          palette = nord(""baie_mouton""),
          align.labels = list(c(""left"",""top""), c(""right"",""bottom"")),
          drop.unused.levels = TRUE,
          vp = vplayout(x,y))
  
  
  
}

fifa_maps <- function() {
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(3, 3, heights = c(0.1, 0.8, 0.1))))
  par(mai=c(0,0,0,0))
  
  grid.text(""Comparing FIFA Share Differences by Confederation and Country"", x = 0.1, hjust = 0, vp = vplayout(1,1), gp = gpar(fontfamily = ""Oswald-Light"", fontsize = 30))
  build_treemap(2, 1, ""population_share"")
  build_treemap(2, 2, ""tv_audience_share"")
  build_treemap(2, 3, ""gdp_weighted_share"")
  grid.text(""Data: fivethirtyeight.com | Graphic: @jakekaupp"", x = 0.5, vp = vplayout(3,3), gp = gpar(fontfamily = ""Scope One"", fontsize = 10))
  
}

png(here(""week11"", ""Fifa Treemaps.png""), width = 11, height=8.5, units = ""in"", res = 100)
fifa_maps()
dev.off()

","2018-11"
"201",62,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week12/R/tw12_plot.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(ggridges)
library(nord)
library(here)
library(showtext)

font_add_google(""Oswald"", ""Oswald"", regular.wt = 400)
font_add_google(""Scope One"", ""Scope One"")

trend_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_google_trends.csv"", skip = 2, col_names = TRUE) %>% 
  set_names(str_extract(names(.), ""(?<=Hurricane )(\\w+)|(Day)"")) %>% 
  rename(Date = Day) %>% 
  mutate(source = ""Google Trends"") %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

mediacloud_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_mediacloud_hurricanes.csv"", col_names = TRUE) %>% 
  mutate(source = ""Online News"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/week12_tv_hurricanes.csv"") %>% 
  mutate(source = ""TV"") %>% 
  mutate(Date = mdy(Date)) %>% 
  mutate_at(vars(-Date, -source), funs(./max(.)))

all_data <- bind_rows(trend_data, mediacloud_data, tv_data) %>%
  gather(hurricane, value, -Date, - source) %>% 
  set_names(tolower(names(.)))

showtext_auto()

plot <- ggplot(all_data, aes(x = date, y = source)) +
  geom_ridgeline(aes(height = value, fill = factor(hurricane)), size = 0.1, scale = 0.8, alpha = 0.8) +
  labs(title = ""On nearly every form of media, hurricanes that hit mainland US received more sustained coverage than Maria in Puerto Rico"",
       subtitle = ""Ridgeline plots of normalized media shares (TV, Online News and Google Trends)"",
       caption = ""Data: fivethirtyeight | Graphic: @jakekaupp"",
       y = NULL,
       x = NULL) +
  scale_x_date(expand = c(0,0)) +
  scale_fill_nord(name = ""Hurricane"", palette = ""lumina"") +
  theme_jk(plot_title_size = 28, subtitle_size = 24, base_size = 20, caption_size = 12,  grid = ""X"") +
  theme(axis.text.y = element_text(vjust = -2))

ggsave(plot, filename = here(""week12"", ""ROCK YOU LIKE A HURRICANE.png""), width = 6, height = 3)
","2018-12"
"202",63,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week18/R/tw18_plot.R","library(here)
library(tidyverse)
library(treemap)
library(sysfonts)
library(showtext)
library(grid)
library(nord)
library(readxl)
library(ggalt)
library(jkmisc)


raw_data <- read_xlsx(here(""week18"", ""data"", ""week18_dallas_animals.xlsx""), sheet = 1)

data <- raw_data %>% 
  filter(animal_type %in% c(""CAT"",""DOG""), mo_year == ""2017"") %>% 
  count(animal_type, month, mo_year, outcome_type) %>% 
  group_by(animal_type, month, mo_year) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  select(-n) %>% 
  filter(outcome_type %in% c(""EUTHANIZED"",""ADOPTION"")) %>% 
  mutate_if(is.character, tolower) %>%
  spread(outcome_type, percent) %>% 
  mutate_if(is.character, tools::toTitleCase) %>% 
  mutate(month = ifelse(month == ""may"", ""May"", month)) %>% 
  arrange(month) %>% 
  complete(month = month.abb, mo_year, animal_type, fill = list(adoption = NA, euthanized = NA)) %>% 
  mutate(ratio = adoption/euthanized) %>% 
  mutate(month = factor(month, month.abb))



ggplot(data, aes(x = month, y = ratio, group = animal_type, color = animal_type)) +
  geom_hline(yintercept = 1.0, size = 0.1, color = ""firebrick"", linetype = ""dashed"") +
  geom_line(size = 0.5) +
  geom_text(data = filter(data, month == ""Sep""), aes(label = animal_type), nudge_x = 0.3, family = ""Oswald"") +
  theme_jk(grid = ""XY"") +
  scale_color_nord(""victory_bonds"") +
  labs(x = NULL, y = ""Ratio of Adopted/Euthanized"", title = ""2017 was a bad time to be a cat in a shelter"", subtitle = ""Cats in the shelters were euthanized more than adopted compared to dogs."") +
  theme(legend.position = ""none"")
  



","2018-18"
"203",64,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week2/R/tw2_plot.R","library(here)
library(readxl)
library(tidyverse)
library(glue)
library(janitor)
library(rvest)
library(nord)
library(jkmisc)
library(viridis)

# Function to scrape the top avg cap salary by player ----
pull_position_data <- function(year, position) {
  
  Sys.sleep(5)
  
  url <- glue(""http://www.spotrac.com/nfl/positional/{year}/{position}"")
  
  read_html(url) %>% 
    html_nodes(""#main > div.teams > table:nth-child(6)"") %>% 
    html_table() %>%
    flatten_df() %>% 
    set_names(c(""rank"",""player"",""cap_dollars"", ""cap_percent""))
}


# Formatter for 538 year labels 
labels_538 <- function(labels) {
  labels_out <- sprintf(""20%s"", str_sub(labels, 3, 4))
  labels_out <- c(labels_out[1], glue(""'{str_sub(labels_out[-1], 3, 4)}""))
  return(labels_out)
}

# Create the data scaffold 
years <- 2011:2018
positions <- c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"",""defensive-end"",""cornerback"",""defensive-tackle"", ""inside-linebacker"", ""outside-linebacker"", ""free-safety"", ""strong-safety"", ""kicker"",""punter"",""long-snapper"")

scaffold <- tibble(year = years,
                   position = list(positions)) %>% 
  unnest() 

# Populate the scaffold
if(!file.exists(here(""week2"", ""data"", ""position_cap_data_named.RDS""))) {
  
  scaffold <- scaffold %>% 
    mutate(data = map2(year, position, ~pull_position_data(.x, .y))) %>% 
    unnest() %>% 
    mutate_at(c(""cap_dollars"", ""cap_percent""), parse_number) %>% 
    mutate(side = case_when(position %in% c(""quarterback"", ""running-back"", ""fullback"", ""guard"", ""center"", ""left-tackle"", ""right-tackle"", ""tight-end"",""wide-receiver"") ~ ""Offense"",
                            position %in% c(""kicker"",""punter"",""long-snapper"") ~ ""Special Teams"",
                            TRUE ~ ""Defense""))
  
  
  # Save it to avoid re-scraping 
  saveRDS(scaffold, file = here(""week2"", ""data"", ""position_cap_data_named.RDS""))
} else {
  
  scaffold <- readRDS(here(""week2"", ""data"", ""position_cap_data_named.RDS""))
  
}


# Make data for the plot
plot_data <- scaffold %>% 
  group_by(year, position, side) %>% 
  top_n(16, cap_dollars) %>% 
  summarize(avg_pay = mean(cap_dollars))
  
# Make a heatmap!
ggplot(plot_data, aes(x = year, y = position, fill = avg_pay)) +
  geom_tile(color = ""white"", size = 0.1) +
  coord_equal() +
  labs(x = NULL, y = NULL, title = ""The Fullback Gets No Respect"", subtitle = ""Average cap value of the 16 highest payed players in all positions"", caption = ""Data: http://www.spotrac.com/ | Graphic: @jakekaupp"") +
  scale_x_continuous(labels = labels_538, breaks = 2011:2018) +
  scale_y_discrete(labels = function(x) str_to_title(gsub(""[[:punct:]]"", "" "", x))) +
  scale_fill_viridis(discrete = FALSE, labels = scales::dollar, name = ""Average Salary"") +
  theme_jk(grid = FALSE, base_size = 14)

ggsave(here(""week2"", ""tw2_heatmap.png""), width = 8, height = 8)
","2018-2"
"204",65,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week3/R/tw3_plot.R","library(tidyverse)
library(here)
library(readxl)
library(jkmisc)

# Read in the data
mortality_data <- dir(here(""week3"",""data""), pattern = ""global"", full.names = TRUE) %>% 
  read_excel()


# Tidy up the data
tidy_mort <- mortality_data %>% 
  gather(cause_of_death, percentage, -country:-year) %>% 
  mutate(cause_of_death = trimws(str_remove(cause_of_death, ""\\(\\%\\)""))) %>% 
  mutate(percentage = ifelse(is.na(percentage), NA, percentage/100))

# Get just the data pertaining to suicides
suicide_data <- tidy_mort %>% 
  filter(cause_of_death == ""Suicide"", !is.na(country_code))

# Get the World percentage
global_rate <- suicide_data %>% 
  filter(country == ""World"") %>% 
  select(year, percentage)

# Get the top 40 problem countries, those with the suicide rate constantly over the world average (note the all statement in the filter)
problem_countries <- suicide_data %>% 
  filter(country != ""World"") %>% 
  left_join(global_rate, by = ""year"") %>% 
  group_by(country) %>% 
  filter(all(percentage.x > percentage.y)) %>% 
  summarize(percentage = mean(percentage.x, na.rm = TRUE)) %>% 
  top_n(40, percentage) %>% 
  arrange(desc(percentage)) %>% 
  pull(country)

# Create the data to make the plot, and arrange descending by the overall avg rate of suicide
plot_data <- suicide_data %>% 
  filter(country %in% problem_countries) %>% 
  mutate(country = factor(country, problem_countries))

# Create the sad plot
sad_plot <- ggplot(plot_data, aes(x = year, y = percentage)) +
  geom_segment(aes(x = min(year), xend = max(year), y = 0, yend = 0)) +
  geom_area(fill = ""steelblue4"") +
  geom_path(color = ""grey30"", size = 0.2) +
  geom_area(data = global_rate, fill = ""steelblue3"") +
  geom_path(data = global_rate, color = ""grey30"", size = 0.2) +
  facet_wrap(~country, nrow = 5) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = ""Countries Coping With the Tradgedy and Pain of Suicide"",
       subtitle = ""Dark blue indicates suicide rate by year, Light blue fill indicates the global average suicide rate by year."",
       x = NULL,
       y = NULL,
       caption = ""Data: ourworldindata.org | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"")

# Save the sad plot
ggsave(here(""week3"",""tw3_sad_plot.png""), sad_plot, width = 16, height = 10)
","2018-3"
"205",66,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week4/R/tw4_plot.R","library(tidyverse)
library(here)
library(jkmisc)
library(scales)
library(ggiraph)
library(glue)
library(waffle)

make_tooltip <- function(occupation, female, male, income_gap, ...) {
 
  glue('<div class=""tipchart"">
      <h3>{occupation}</h3>
      <h4>Mens taxable income {ifelse(income_gap <= 1, percent(1-round(income_gap, 2)), percent(round(income_gap, 2)))} {ifelse(income_gap <= 1, ""less"", ""more"")} than womens</h4>
      <table>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Male Taxable Income:</td>
      <td class=""tiptext"">{dollar(male)}</td>
      </tr>
      <tr class=""tiprow"">
      <td class=""tipheader"">Average Female Taxable Income:</td>
      <td class=""tiptext"">{dollar(female)}</td>
      </tr>
      </table>
      </div>')
  
}


# Read in the data
income_data <- dir(here(""week4"",""data""), pattern = ""salary"", full.names = TRUE) %>% 
  read_csv(locale = locale(""en""))
 
# Clean occupation up a bit.  Some rouge unicodes in there.
tidy_gap <- income_data %>% 
  mutate(occupation = iconv(occupation, ""UTF-8"", ""UTF-8"",sub='')) %>% 
  spread(gender, average_taxable_income) %>%
  set_names(tolower(names(.))) %>% 
  group_by(occupation) %>% 
  summarize_at(c(""female"", ""male""), sum, na.rm = TRUE) %>% 
  filter(female != 0, male != 0) %>% 
  mutate(income_gap = male/female)

plot_data <- tidy_gap %>% 
 mutate(fill = if_else(income_gap >= 1, ""grey80"", ""#ffd700""),
         alpha = if_else(income_gap >= 1, 0.2, 1)) %>% 
  mutate(tooltip = pmap(., make_tooltip)) %>% 
  mutate(tooltip = gsub(""\\\n"", """", tooltip)) %>% 
  mutate(tooltip = gsub(""'"", """", tooltip)) %>% 
  mutate(idx = row_number())

tooltip_css <- ""background-color:white;padding:10px;border-radius:20px 20px 20px 20px;border-color:black;border-style:solid;border-width:1px""

plot <- ggplot(plot_data, aes(x = female, y = male, fill = fill)) +
  geom_segment(x = 0, xend = 600000, y = 0, yend = 600000, size = 0.05, color = ""grey80"") +
  geom_point_interactive(aes(alpha = alpha, tooltip = tooltip, data_id = idx), shape = 21, color = ""grey30"", size = 3) +
  scale_y_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_x_continuous(labels = dollar, limits = c(0, 600000)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Gender Differences in Taxble Income in Australia"",
       subtitle = str_wrap(""Average male taxable income plotted against average female taxable income by occupation. Yellow dots indicate occupations where women have more taxable income than their male counterparts, 
       line indicates income equality. Hover over points for occupation, % difference and detailed income."", 100),
       caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme_jk()

ggiraph(ggobj = plot, width_svg = 9, width = 1, tooltip_extra_css = tooltip_css)

waffle_data <- tidy_gap %>% 
  ungroup() %>% 
  mutate(category = case_when(income_gap > 1 ~ ""Men have more income"",
                              income_gap < 1 ~ ""Women have more income""))%>% 
  count(category) %>% 
  pull(n) %>% 
  set_names(., c(""Men have more income"", ""Women have more income""))

waffle(waffle_data, 
       rows = 14,
       size = 1,
       colors = c(""dodgerblue3"", ""deeppink""), 
       legend_pos = ""bottom"", 
       title = ""Out of 1092 occupations on record, men have more taxable income than women in 1011 of them.  That's 92.5% of occupations for those counting at home."") + 
  theme_jk() +
  labs(caption = ""Data: data.gov.au | Graphic: @jakekaupp"") +
  theme(axis.text = element_blank(),
        legend.position = ""bottom"")
","2018-4"
"206",67,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week5/R/tw_5plot.R","library(tidyverse)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)


census_data <- dir(here(""week5"", ""data""), full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

# Lets look at commuting!
commuting_data <- census_data %>% 
  select(census_id, state, county, total_pop, drive:mean_commute)

# Despacito is 3:47 in length
despacito_length <- 3 + 47/60

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") 

# Calculate the how many despacitos the average commute has
despacito_commute <- commuting_data %>% 
  mutate(despacitos = mean_commute/despacito_length,
         id = ifelse(str_length(as.character(census_id)) < 5, glue(""0{census_id}""), as.character(census_id))) %>% 
  right_join(us_map)


# Make the map!
map <- ggplot() +
 geom_map(data = us_map, map = us_map,
                    aes(x = long, y = lat, map_id = id),
                    color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = despacito_commute, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = despacitos),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis(name=""How many despactios?"", na.value = viridis(5, option = ""cividis"")[3], option = 'cividis', breaks = seq(1,12,2)) +
  labs(title = ""Just how much do you like your commute?"",
       subtitle = str_wrap(""What if your commute was defined by hearing a song on repeat?  
                           What if that song was the most streamed song on the planet, Despacito? 
                           Illustrated below is the average number of times you'd hear it on your way home across the US."", 80),
       caption = ""Data: census.gov | Graphic: @jakekaupp"") +
  coord_map() +
  theme_map(base_family=""Scope One"", 
            base_size = 16) +
  theme(legend.title = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        plot.caption = element_text(size = 10),
        legend.position = c(0.9,0.1))

ggsave(here(""week5"", ""tw5_choropleth map.png""), width = 10, height = 6)


","2018-5"
"207",68,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week6/R/tw_6plot.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(glue)
library(fuzzyjoin)
library(stringi)
library(ggalt)
library(jkmisc)
library(nord)



provinces <- set_names(c(""Alberta"", ""British Columbia"", ""Manitoba"", ""New Brunswick"", ""Newfoundland and Labrador"",
                         ""Nova Scotia"", ""Northwest Territories"", ""Nunavut"", ""Ontario"", ""Prince Edward Island"", ""Quebec"",
                         ""Saskatchewan"", ""Yukon""),
                       c(""AB"", ""BC"", ""MB"", ""NB"", ""NL"", ""NS"", ""NT"", ""NU"", ""ON"", ""PE"", ""QC"", ""SK"", ""YT""))

# Just get the Tims data just for Canada
tim_hortons <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""xlsx"") %>% 
  read_excel(sheet = ""timhorton"") %>% 
  filter(country == ""ca"") %>% 
  rename(province = state) 

# Counts at the City/Province level
tims_city_prov <- tim_hortons %>% 
  count(city, province)

# Counts at the National level
tims_national <- tim_hortons %>% 
  count(province) %>% 
  mutate(color = ifelse(province == ""ON"", nord(""victory_bonds"", 1), ""grey50""))

national <- ggplot(tims_national, aes(x = reorder(province,n), y = n)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0.01,0.05),  breaks = scales::pretty_breaks()) +
  scale_x_discrete(labels = function(x) provinces[x]) +
  coord_flip() +
  labs(x = NULL, y = NULL, title = ""Ontario, we have a problem...."", subtitle = ""The highest number of Tim Hortons per province goes to Ontario, a land where you can't even get an oat cake."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = national, here(""week6"", ""National Tims.png""), width = 10, height = 6)

census_2011 <- dir(here(""week6"", ""data""), full.names = TRUE, pattern = ""2011 census"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  remove_empty(""rows"") %>% 
  select(city = geographic_name, population = population_2011) %>% 
  mutate(province = stri_extract_last_regex(city, ""\\(([A-Za-z\\.]+?)\\)""),
         city = stri_replace_all_regex(city, ""\\((.*?)\\)"", """"),
         province = gsub(""[[:punct:]]"", """", province)) %>% 
  mutate(province = case_when(province == ""Que"" ~ ""QC"",
                              province == ""Ont"" ~ ""ON"",
                              province == ""Man"" ~ ""MB"",
                              province == ""Sask"" ~ ""SK"",
                              province == ""Alta"" ~ ""AB"",
                              province == ""NWT"" ~ ""NT"",
                              province == ""Nvt"" ~ ""NU"",
                              province == ""PEI"" ~ ""PE"",
                              TRUE ~ province)) %>% 
  mutate_if(is.character, trimws)



tims_density <- regex_right_join(census_2011, tims_city_prov,  by = c(""city"", ""province""), ignore_case = TRUE) 


plot_data <- tims_density %>% 
  select(population, city = city.y, province = province.x, n) %>% 
  group_by(city, province) %>% 
  summarize_at(c(""n"", ""population""), sum, na.rm = TRUE) %>% 
  ungroup() %>% 
  filter(population != 0, n > 1, population > 10000) %>% 
  mutate(density = (n/(population/1000))) %>% 
  top_n(25, density) %>% 
  mutate(color = ifelse(density == max(density), nord(""victory_bonds"", 1), ""grey50""))


most_tims <- ggplot(plot_data, aes(x = reorder(city, density), y = density)) +
  geom_lollipop(aes(color = color)) +
  scale_color_identity() +
  scale_y_continuous(expand = c(0,0.01),  breaks = scales::pretty_breaks(), limits = c(0,1.2)) +
  coord_flip() +
  labs(y = ""Number of Tim Hortons stores per 1,000 people"", x = NULL, title = ""However, the title of most Tim Hortons per capita belongs to Cold Lake, Alberta"", 
       subtitle = ""When looking at towns/cities with population > 10,000 and with more than two Tim Hortons. \nMy hometown of Truro, Nova Scotia comes in a puzzling fourth."",
       caption = ""\nData: timhortons.com | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Xx"")

ggsave(plot = most_tims, here(""week6"", ""Most Tims.png""), width = 10, height = 6)

","2018-6"
"208",69,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2018/week7/R/tw_7plot.R","library(tidyverse)
library(here)
library(janitor)
library(likert)
library(jkmisc)
library(nord)

star_wars <- dir(here(""week7"", ""data""), pattern = ""StarWars"", full.names = TRUE) %>% 
  read_csv() 

clean_names <- stringi::stri_trans_general(names(star_wars), ""latin-ascii"") %>% 
  gsub(""[^\\x{00}-\\x{7f}]"", """", ., perl = TRUE) %>% 
  clean_names()

star_wars <- set_names(star_wars, clean_names) 

headers <- slice(star_wars, 1) %>% 
  flatten_chr()

clean_names <- gsub(""X\\d+"", NA_character_, clean_names) %>% 
  enframe() %>% 
  fill(value) %>% 
  pull(value)


shiny_clean_names <- paste(clean_names, headers, sep = ""|"")

long_star_wars <- set_names(star_wars, c(""RespondentID"", shiny_clean_names[-1])) %>% 
  slice(-1) %>% 
  gather(item, value, -1) %>% 
  separate(item, c(""question"", ""category""), sep = ""\\|"") %>% 
  mutate(category = if_else(category == ""Response"", NA_character_, category)) %>% 
  mutate(index = group_indices(., question))


plot_data <- long_star_wars %>% 
  filter(index == 12) %>% 
  replace_na(list(value = ""Unfamiliar (N/A)"")) %>% 
  filter(value != ""Unfamiliar (N/A)"") %>% 
  spread(category, value) %>% 
  mutate_at(vars(-RespondentID, -question, -index), function(x)
    factor(x, 
            levels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""),
            labels = 1:5
    )) 
            
            
likert_data <- plot_data %>% 
  select(-RespondentID, -question, -index) %>%
  as.data.frame() %>% 
  likert()


ggplot2::update_geom_defaults(""text"", list(family = ""Scope One"", size = 4))
  
plot <- likert.bar.plot(likert_data) + 
  scale_fill_nord(""mountain_forms"", labels = c(""Very unfavorably"", ""Somewhat unfavorably"",""Neither favorably nor unfavorably (neutral)"", ""Somewhat favorably"", ""Very favorably""), name = ""Response"") +
  labs(title = ""The Favorability Rankings of Star Wars Characters"", subtitle = ""People look favourably upon the scruffy nerf herder, and would give a ride to the EVIL RAISIN THAT SHOOTS LIGHTNING FROM HIS HANDS before the goofy gungan."") +
  theme_jk(grid = ""XY"") +
  theme(plot.title = element_text(family = ""Oswald""))

ggsave(here(""week7"", ""tw7_likert.png""), width = 16, height = 10)
  
  
 
","2018-7"
"209",70,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week1/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)


# week-of-month function
wom <- function(date) { 
  first <- wday(as.Date(paste(year(date),month(date),1,sep=""-"")))
  return((mday(date)+(first-2)) %/% 7+1)
}

# Get the TidyTuesday Tweets Data
tt_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""tidytuesday_tweets.rds""))

# Get the R tweet data 
r_tweet_data <- readRDS(here(""2019"", ""week1"", ""data"", ""rstats_tweets.rds""))

# Most that tweet about R tweet about the r4ds tidy tuesday.
no_rstats <- anti_join(tt_tweet_data, r_tweet_data, by = ""screen_name"") %>% 
  mutate(rstats_tag = case_when(grepl(""rstats"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""r4ds"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""visualization"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""data"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""code"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""plot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""chart"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""graph"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""drob"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""ggplot"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""rstudio"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""model"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""median"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""average"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""week \\d+"", text, ignore.case = TRUE) ~ TRUE,
                                grepl(""@thomas_mock"", text, ignore.case = TRUE) ~ TRUE,
                                TRUE ~ FALSE)) %>% 
  mutate(rstats_tag = case_when(screen_name %in% c(""NosyOwl"", ""sebastianhwells"", ""JenniferCai7"", ""matthwong"",
                                                   ""scrite_jones"", ""jrosenblum123"", ""zlipp"") ~ TRUE,
                                TRUE ~ rstats_tag)) %>% 
  filter(rstats_tag == FALSE)
  

plot_data <- anti_join(tt_tweet_data, no_rstats, by = ""screen_name"") %>% 
  mutate(created_at = as_date(created_at)) %>% 
  mutate(day = wday(created_at, label = TRUE, abbr = FALSE),
         week = wom(created_at),
         iweek = isoweek(created_at),
         month = month(created_at, label =  TRUE, abbr = FALSE),
         year = year(created_at))


count(plot_data, day, iweek) %>% 
  complete(day, iweek = 1:52, fill = list(n = NA)) %>% 
  ggplot(aes(x = iweek, y = day, fill = n)) +
  geom_tile(color = ""white"", size = 0.1) +
  scale_fill_viridis_c(""Tweet Frequency"", option = ""cividis"", na.value = ""grey95"", labels = seq(0,25,5), breaks = seq(0,25,5), limits = c(0,25)) +
  coord_equal() +
  labs(title = ""Tidy Tuesday or Tardy Tuesday?"",
       subtitle = ""A glance at when the community decides to submit their work."",
       y = NULL,
       x = ""Week of the Year"",
       caption = ""Data: rtweet | Analysis: @jakekaupp"") +
  scale_x_continuous(limits = c(1, 53), breaks = c(1,10,20,30,40,50), expand = c(0, 0)) +
  theme_jk(grid = FALSE, ticks = FALSE) +
  theme(legend.position = c(0.5,-0.7),
        legend.direction = ""horizontal"",
        legend.title = element_text(family = ""Scope One"", vjust = 0.8))

ggsave(here(""2019"", ""week1"",""tidy_or_tardy.png""), width = 8, height = 4)
","2019-1"
"210",71,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week10/R/analysis.R","library(tidyverse)
library(jkmisc)
library(ggrepel)
library(here)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")


plot_data <- jobs_gender %>% 
  select(-year) %>% 
  group_by(occupation, major_category, minor_category) %>% 
  summarize_all(mean, na.rm = TRUE) %>% 
  filter(str_detect(occupation, ""engineer""), str_detect(major_category, ""Engineering"")) %>% 
  mutate(diff = if_else((total_earnings_female - total_earnings_male) > 0, ""firebrick"", ""grey80"")) %>% 
  mutate(alpha = if_else(diff == ""firebrick"", 1, 0.2)) %>% 
  gather(variable, value, starts_with(""total_earnings_"")) %>% 
  mutate(variable = factor(variable, c(""total_earnings_male"", ""total_earnings_female""), c(""Men"", ""Women"")))
 
slope_data <- build_slopegraph(plot_data, ""variable"", ""value"", ""occupation"") %>% 
  left_join(distinct(plot_data, occupation, diff, alpha), by = c(""group"" = ""occupation"")) %>% 
  mutate(group = case_when(str_detect(group, ""Mining"") ~ ""Mining Engineers"",
                                str_detect(group, ""Computer"") ~ ""Computer Engineers"",
                                str_detect(group, ""Electrical"") ~ ""Electrical Engineers"",
                                str_detect(group, ""Marine"") ~ ""Marine Engineers"",
                                str_detect(group, ""Industrial"") ~ ""Industrial Engineers"",
                           TRUE ~ str_to_title(group))) %>% 
  mutate(group = str_replace(group, ""Engineers"", ""Engineering""))


labels <- pretty(slope_data$y, 9)
breaks <- pretty(slope_data$ypos, 5)


plot <- ggplot(slope_data, aes(x = x, y = ypos, group = group, color = diff)) +
  geom_point() +
  geom_line() +
  geom_label_repel(data = filter(slope_data, x == ""Women""), aes(label = group), direction = ""y"", hjust = 0, nudge_x = 1, segment.alpha = 0.3, family = ""Oswald"", label.size = 0, fill = ""white"") +
  theme_jk(grid = ""XY"") +
  expand_limits(x = c(0, 5)) +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_y_continuous(labels = scales::dollar(labels), breaks = breaks, limits = range(breaks)) +
  theme(panel.grid.major.x = element_line(linetype = ""dashed"", color = ""black"")) +
  labs(x = NULL,
       y = NULL,
       title = ""The Unnecessary and Unethical Pay Disparity in Engineering."",
       subtitle = str_wrap(""A slopegraph presenting the average total earnings from 2014-2016 for men and women across engineering disciplines.  Mining Engineering is the only discipline with women earning more than men on average."", 70),
       caption = ""Data: Census Bureau | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week10"", ""tw10_plot.png""), plot, width = 6.5, height = 9, type = ""cairo"")
","2019-10"
"211",72,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week10/R/helpers.R","# Functions from an old friend.
# https://github.com/jkeirstead/r-slopegraph/blob/master/slopegraph.r

build_slopegraph <- function(df, x, y, group, min.space=0.05) {
  
  ## First rename the columns for consistency
  ids <- match(c(x, y, group), names(df))
  
  df <- df[,ids]
  
  names(df) <- c(""x"", ""y"", ""group"")
  
  ## Expand grid to ensure every combination has a defined value
  tmp <- expand.grid(x=unique(df$x), group=unique(df$group))
  
  tmp <- merge(df, tmp, all.y=TRUE)
  
  df <- mutate(tmp, y=ifelse(is.na(y), 0, y))
  
  spaced_sort(df, min.space=min.space)
  
}



spaced_sort <- function(df, min.space=0.05) {
  ## Define a minimum spacing (5% of full data range)
  min.space <- min.space*diff(range(df$y))
  
  ## Transform the data
  
  df <- split(df, ""x"") %>% 
    map_df(~calc_spaced_offset(.x, min.space))
  
  return(df)
}

##' Calculates the vertical offset between successive data points
##' 
##' @param df a data frame representing a single year of data
##' @param min.space the minimum spacing between y values
##' @return a data frame
calc_spaced_offset <- function(df, min.space) {
  
  ## Sort by value
  ord <- order(df$y, decreasing=T)
  ## Calculate the difference between adjacent values
  delta <- -1*diff(df$y[ord])
  ## Adjust to ensure that minimum space requirement is met 
  offset <- (min.space - delta)
  offset <- replace(offset, offset<0, 0)
  ## Add a trailing zero for the lowest value
  offset <- c(offset, 0)
  ## Calculate the offset needed to be added to each point
  ## as a cumulative sum of previous values
  offset <- rev(cumsum(rev(offset)))
  ## Assemble and return the new data frame
  df.new <- data.frame(group=df$group[ord],
                       x=df$x[ord],
                       y=df$y[ord],
                       ypos=offset+df$y[ord])
  return(df.new)
}
","2019-10"
"212",73,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week11/R/analysis.R","library(tidyverse)
library(jkmisc)
library(here)

board_games <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")

prolific <- board_games %>% 
  separate_rows(designer, sep = "","") %>% 
  filter(!str_detect(designer, ""Uncredited""), !str_detect(designer, ""Jr|III""), year_published >= 1990) %>% 
  group_by(designer) %>% 
  filter(n() >= 10) %>% 
  group_by(designer, year_published) %>% 
  summarize(year_avg_rating = mean(average_rating, na.rm = TRUE),
            games_published = n()) 

top_rated <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, overall_rating) %>% 
  pull(designer)

top_publishing <- prolific %>% 
  group_by(designer) %>% 
  summarize(total_games = sum(games_published),
            overall_rating = mean(year_avg_rating, na.rm = TRUE)) %>% 
  top_n(1, total_games) %>% 
  pull(designer)

overall_avg <- prolific %>% 
  group_by(year_published) %>% 
  summarize(year_avg_rating = mean(year_avg_rating, na.rm = TRUE),
            designer = ""Overall"")


plot_data <- prolific %>%
  bind_rows(overall_avg) %>% 
  mutate(color = case_when(designer == top_rated ~ ""#eebd31"" ,
                           designer == ""Overall"" ~ ""firebrick"",
                           designer == top_publishing ~ ""dodgerblue"",
                           TRUE ~ ""black""),
         alpha = case_when(designer == top_rated ~ 1,
                           designer == ""Overall"" ~ 1,
                           designer == top_publishing ~ 1,
                           TRUE ~ 0.05),
         size = case_when(designer == top_rated ~ 0.5,
                           designer == ""Overall"" ~ 0.5,
                           designer == top_publishing ~ 0.5,
                           TRUE ~ 0.3),
         point_size = case_when(designer == top_rated ~ 2,
                          designer == ""Overall"" ~ 2,
                          designer == top_publishing ~ 2,
                          TRUE ~ 1),
         line = case_when(designer == top_rated ~ ""solid"",
                           designer == ""Overall"" ~ ""dashed"",
                           designer == top_publishing ~ ""solid"",
                           TRUE ~ ""solid""))

plot <- ggplot(plot_data, aes(x = year_published, y = year_avg_rating, group = designer)) +
  geom_path(aes(color = color, alpha = alpha, linetype = line, size = size)) +
  geom_point(aes(fill = color, alpha = alpha, size = point_size), color = ""white"", shape = 21) +
  annotate(""label"", x = 1989.8, y = 2, label = ""Most Prolific: Reiner Knizia with 229 published games."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""dodgerblue"", hjust = 0) +
  annotate(""segment"", x = 1990, xend = 1990, y = 2.3, yend = 5.5, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""dodgerblue"") +
  annotate(""label"", x = 2002, y = 9, label = ""Highest Average Rating: Mark H. Walker with a 7.70 rating."", family = ""Oswald"", label.size = 0, fill = ""white"", color = ""#eebd31"") +
  annotate(""segment"", x = 2002, xend = 2002.8, y = 8.8, yend = 7.7, arrow = arrow(type = ""closed"", length = unit(1, ""mm"")), color = ""#eebd31"") +
  scale_y_continuous(limits = c(0, 10), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_color_identity() +
  scale_linetype_identity() +
  scale_size_identity() +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL,
       title = ""It's Not A Habit, It's Cool, I'm a Prolific Game Designer"",
       subtitle = str_wrap(""A comparison from 1990 to 2016 of the the top rated and top published designer amongst those with 10 or more published games. Red dashed line represents the overall average designer rating."", 150),
       caption = ""Data: Board Game Geek | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"")

ggsave(here(""2019"",""week11"", ""tw11_plot.png""), width = 12, height = 6)
","2019-11"
"213",74,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week13/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(fs)
library(janitor)
library(jkmisc)

pet_licenses <- here(""2019"", ""week13"", ""data"") %>% 
  dir_ls(regexp = ""Seattle"") %>% 
  read_csv() %>% 
  clean_names() %>% 
  mutate_at(""license_issue_date"", mdy)

burst_name <- function(df) { 
  
  df %>% 
    distinct(license_issue_date) %>% 
    pull(license_issue_date) %>% 
    kleinberg()
    
  }

out <- pet_licenses %>% 
  filter(!is.na(animals_name)) %>% 
  mutate(animals_name = str_to_lower(animals_name)) %>% 
  group_by(animals_name) %>% 
  filter(n() >= 100) %>% 
  nest() %>% 
  mutate(bursts = map(data, burst_name)) %>% 
  unnest(bursts) %>% 
  arrange(desc(animals_name), level) %>% 
  mutate(id = ntile(animals_name, 1)) %>%
  mutate(color = case_when(level == 1 ~ ""grey50"",
                           level == 2 ~ ""#6baed6"",
                           level == 3 ~ ""#3182bd"",
                           level == 4 ~ ""#08519c""),
         alpha = case_when(level == 1 ~ 0.5,
                           level == 2 ~ 1,
                           level == 3 ~ 1,
                           level == 4 ~ 1)) %>% 
  ungroup()

facet_labels <- out %>% 
  group_by(id) %>% 
  summarize(label = sprintf(""%s to %s"", last(str_sub(animals_name, 1, 1)), first(str_sub(animals_name, 1, 1)))) %>% 
  pull(label) %>% 
  set_names(., sort(unique(out$id)))

order <- out %>% 
  filter(level == 1) %>% 
  arrange(desc(start)) %>% 
  pull(animals_name)

plot <- ggplot(out) +
  geom_segment(aes(x = start, xend = end, y = factor(animals_name, order), yend = factor(animals_name, order), color = color, alpha = alpha), size = 4, lineend = ""square"") +
  scale_color_identity() +
  scale_alpha_identity() +
  scale_x_date(limits = c(ymd(""2006/01/01""),ymd(""2019/01/01"")),  date_breaks = ""1 year"", date_labels = ""%Y"", expand = c(0.02, 0)) +
  scale_y_discrete(position = ""right"") +
  theme_jk(grid = ""XY"") +
  labs(x = NULL,
       y = NULL,
       title = ""What is it, Lassie? 'Bark! Bark-bark-bark! Bark-bark!' What, Timmy's fallen in the well?"",
       subtitle = str_wrap(""Illustrated below is the recorded use of and bursts in popularity of registered pet names (frequency of use > 100) in Seattle from 2006 to 2019.  The grey bar indicates the duration the name is in use, and the blue segments indicate bursts of increased use of the name.  Darker blue segments represent repeated bursts indicating an increased intensity of use."", 100),
       caption = ""Data: seattle.gov | Graphic: @jakekaupp"")

ggsave(here(""2019"",""week13"",""tw13_plot.png""), plot, width = 8, height = 10, type = ""cairo-png"")
","2019-13"
"214",75,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week14/R/analysis.R","library(tidyverse)
library(lubridate)
library(jkmisc)
library(here)
library(patchwork)

bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

clean_bikes <- bike_traffic %>% 
  mutate(date = mdy_hms(date),
         month = month(date),
         year = year(date)) %>% 
  filter(between(year, 2014, 2018))

by_year <- clean_bikes %>% 
  group_by(year, month, crossing) %>% 
  summarize(total_bikes = sum(bike_count, na.rm = TRUE)) 

glyph <- ggplot(by_year, aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 1, aes(color = crossing)) +
  facet_grid(year ~ month, labeller = labeller(.cols = set_names(month.abb, 1:12)), switch = ""y"") +
  scale_color_manual(values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
  labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180),
        legend.position = ""none"")

main <- by_year %>% 
  filter(year == 2015, month == 1) %>% 
  ggplot(aes(x = crossing, y = total_bikes, group = year)) +
  geom_path() +
  geom_point(size = 3, aes(color = crossing)) +
  scale_color_manual(""Crossing"", values = tol7qualitative) +
  theme_jk(grid = FALSE, plot_title_size = 14) +
   labs(x = NULL, 
       y = NULL) +
  theme(axis.text = element_blank(),
        strip.text.y = element_text(angle = 180))

plot <- wrap_plots(list(main, glyph), widths = c(0.25, 0.75)) +
  plot_annotation(title = ""Annual Patterns in Seatle Bicycle Traffic"", 
                  subtitle = str_wrap(""This chart is glyph plot using multiple parallel coordinates plots to illustrate the monthly bike traffic at Seattle crossings.  A  colored dot represents each crossing and vertical position represents the total number of riders counted each month.  You can observe the year over year trends, as well as see which crossings experience cyclical patterns and which remain stable."", 155),
                  theme = theme_jk())

ggsave(here(""2019"", ""week14"", ""tw14_plot.png""), plot, width = 12, height = 6)
","2019-14"
"215",76,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week15/R/analysis.R","library(tidyverse)
library(lubridate)
library(ggbeeswarm)
library(here)
library(jkmisc)
library(nord)

player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")


plot_data <- player_dob %>% 
  select(name, date_of_birth) %>% 
  left_join(grand_slams, by = ""name"") %>% 
  mutate(age = interval(date_of_birth, tournament_date)/years(1)) %>% 
  group_by(name) %>% 
  filter(n()>1)
  

order <- plot_data %>% 
  group_by(name) %>% 
  filter(rolling_win_count == max(rolling_win_count)) %>% 
  arrange(rolling_win_count) %>% 
  pull(name)
  

plot <- ggplot(plot_data, aes(x = age, y = factor(name, order), size = rolling_win_count, color = gender, alpha = rolling_win_count)) +
  geom_point(aes(group = name)) + 
  facet_wrap(~gender, scales = ""free_y"") +
  scale_color_manual(values = c(""#C01E65"",""#117AB3"")) +
  scale_size_area(""Rolling Win Count"") +
  guides(size = guide_legend(override.aes = list(shape = 21, color = ""black"")), color = FALSE, alpha = FALSE) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  labs(x = NULL,
       y = NULL,
       title = ""Bright Stardom or Fading Obscurity: Looking at Players Major Wins Across their Careers."",
       subtitle = str_wrap(""The chart plots cumulative major wins against player age. Size and transparency of each point are mapped to the cumulative number of majors won.  Looking at the data, we can see the hot streaks in individual players, as well as the dominance of certain champions."", 110),
       caption = ""Data: wikipedia | Graphic: @jakekaupp"")
  
ggsave(here(""2019"",""week15"",""tw15_plot.png""), type = ""cairo"", width = 10, height = 12)
","2019-15"
"216",77,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week16/R/analysis.R","library(tidyverse)
library(here) 
library(jkmisc)
library(ggalt)
library(grid)
library(Cairo)

dogs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

png(file = here(""2019"", ""week16"", ""tw16_plot.png""), width = 4, height = 4, units = ""in"", res = 300, type = ""cairo"")
                       
ggplot(dogs, aes(x = avg_weight, y = avg_neck)) +
  geom_xspline(size = 1) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 0.5, size = 2) +
  geom_text(data = filter(dogs, year == min(year)), aes(label = year), hjust = 0, nudge_x = 0.1, nudge_y = 0.01, family = ""Oswald"", size = 3) +
  geom_text(data = filter(dogs, year == max(year)), aes(label = year), hjust = 1, nudge_x = -0.1, family = ""Oswald"", size = 3) +
  annotate(""segment"", arrow = arrow(length = unit(0.2, ""cm""), type = ""closed""), x = 20.48, xend = 20.2, y = 44.3, yend = 44.03) +
  scale_y_continuous(limits = c(42, 45), breaks = 42:45) +
  expand_limits(x = c(17.5, 21)) +
  labs(title = ""Fit as a butcher's dog"",
       subtitle = ""Characteristics of dogs registered with the UK's\nKennel Club, average when fully grown"",
       x = bquote(""Weight*, kg""),
       y = NULL,
       caption = ""Sources: Kennel Club;\n The Economist "") +
  theme_jk(grid = ""XY"") +
  theme(plot.caption = element_text(hjust = -0.1))

grid.text(expression(paste(Neck~size, "", "", cm^""\u2020"")), x = 0.1, y = 0.78, gp = gpar(fontfamily = ""Oswald"", cex = 0.8))
grid.text(bquote(""* Where at leat 50 are registered per year""), x = 0.98, y = 0.075, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)
grid.text(expression(""\u2020""~Where~at~least~100~are~registered~per~year), x = 0.98, y = 0.040, gp = gpar(fontfamily = ""Scope One"", cex = 0.8), hjust = 1)

dev.off()
","2019-16"
"217",78,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week17/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

plot_data <- tidy_anime %>% 
  mutate(title = coalesce(title_english, name)) %>% 
  mutate(end_date = if_else(is.na(end_date), as.Date(""2019-04-01""), end_date)) %>% 
  mutate(interval = interval(start_date, end_date)) %>% 
  filter(type != ""Unknown"") %>% 
  distinct(animeID, .keep_all = TRUE) 


scaffold <- tibble(year = rep(1917:2019, each = 6),
       type = rep(c(""Movie"", ""Music"", ""ONA"", ""OVA"", ""Special"", ""TV""), length(1917:2019))) 

timeline <- scaffold %>% 
  mutate(count = map2_dbl(year, type, ~nrow(filter(plot_data, ymd(sprintf(""%s/01/01"", .x)) %within% interval , type == .y))))

order <- timeline %>% 
  filter(year == last(year)) %>% 
  arrange(desc(count)) %>% 
  pull(type)

# Area ----
area <- timeline %>% 
  mutate(type = factor(type, order, order)) %>% 
  ggplot(aes(x = year, y = count)) +
  geom_area(aes(fill = type)) +
  scale_fill_manual(""Anime Type"", values = tol6qualitative) +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  scale_y_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Fourty Years of Growth: The Rapid Rise of Anime"",
       subtitle = str_wrap(""The area chart below presents the number of anime titles released from 1919 to the present by release type.  Anime releases have increased over 400% since the 1980s, to meet the increasing demand driven by the invention of the VCR, the internet and the rise of streaming media services."", 95),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") +
  guides(fill = guide_legend(nrow = 1, byrow = TRUE))

# Popularity vs Score Hexbin ----
hex <- ggplot(plot_data, aes(x = popularity, y = score)) +
  geom_hex() +
  facet_wrap(~type, nrow = 1) +
  scale_fill_viridis_c(option = ""plasma"") +
  scale_x_continuous(trans = ""reverse"", breaks = scales::pretty_breaks(), labels = c("""","""",""Higher\nPopularity"", """", ""Lower\nPopularity"", """")) +
  scale_y_continuous(breaks = scales::pretty_breaks(), limits = c(0,10)) +
  guides(fill = guide_colorbar(title = ""Titles per Hex""), alpha =""none"") +
  labs(x = NULL, 
       y = NULL,
       title = ""The Relationship Between Ratings and Popularity on MyAnimeList"",
       subtitle = str_wrap(""The chart below plots the ratings score (out of 10) against popularity (rank) for all anime titles and anime types.  The data were hexangonally binned to illustrate areas of high occurance. It appears that a relationship may exist between ratings and popularity, warranting further analysis."", 100),
       caption = ""Data: MyAnimeList | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"",""week17"",""tw17_hex.png""), hex, width = 8, height = 6)

ggsave(here(""2019"",""week17"",""tw17_area.png""), area, width = 8, height = 6)

","2019-17"
"218",79,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week18/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)

bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


flower <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.2) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar()) +
  coord_polar() +
  labs(x = NULL,
       y = NULL,
       title = ""Overall"") +
  theme_jk(dark = FALSE, grid = ""X"", strip_text_size = 10, plot_title_size = 14) +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

petals <- flower +
  aes(group = year) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  labs(title = ""By Species"") +
  facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7) 

legend <- plot_data %>% 
  filter(binomial_name == ""Setophaga fusca"") %>% 
  ggplot(aes(x = month, y = percent, fill = binomial_name, group = year)) +
  geom_area(size = 0, position = position_dodge(), alpha = 0.1) +
  geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
  annotate(""text"", x = 11, y = 0.8, label = ""One year of\ncollisions in October"", family = ""Scope One"", size = 3, hjust = 0) +
  annotate(""segment"", x = 10.8, y = 0.8, xend = 10, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  annotate(""text"", x = 3.5, y = 0.8, label = ""Multiple years of\ncollisions in May"", family = ""Scope One"", size = 3) +
  annotate(""segment"", x = 3.8, y = 0.8, xend = 5, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""How to Interpret This Chart"",
       subtitle = str_wrap(""A flower represents the recorded total collisions of each bird species with the individual petals representing the normalized events during each year (from 0-1).  The position of the petals indicates the month or months collisions occur, with overlaps indicating repeated year-over-year collisions."", 70)) +
  guides(fill = guide_colorbar()) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- wrap_plots(flower / legend, petals, ncol = 2, widths = c(1, 2)) +
  plot_annotation(title = ""Seasonality of Bird Collisions in Chicago"",
                  subtitle = str_wrap(""Presented below is a petal chart of of bird collisions, with instructions on how to interpret this chart in the lower left.  The upper left flower represents collisions recorded across all years and species, with individual species presented as small multiple flowers on the right."", 220),
                  caption = ""Data: Winger et al. (2019) Nocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. Proceedings of the Royal Society B 286(1900): 20190364. https://doi.org/10.1098/rspb.2019.0364 | Graphic: @jakekaupp"",
      theme = theme_jk())

ggsave(here(""2019"",""week18"", ""tw18_plot.png""), out, width = 16, height = 10, type = ""cairo"")



","2019-18"
"219",80,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week18/R/experiment.R","library(tidyverse)
library(lubridate)
library(here)
library(jkmisc)
library(patchwork)


bird_collisions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")


plot_data <- bird_collisions %>%
  filter(locality == ""CHI"") %>% 
  mutate(month = month(date),
         year = year(date)) %>% 
  unite(""binomial_name"", genus, species, sep = "" "") %>% 
  count(year, month, binomial_name) %>% 
  complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
  group_by(year, binomial_name) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))

petals <- plot_data %>% 
  filter(n != 0) %>% 
  split(list(.$year, .$month, .$binomial_name), drop = TRUE) %>% 
  map(~complete(.x, year, binomial_name, month = 1:12, fill = list(n = 0, percent = 0))) %>% 
  map(~geom_area(data = .x, aes(color = binomial_name), size = 0.2, alpha = 0.1))


base_plot <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
  scale_x_continuous(labels = month.abb, breaks = 1:12) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_d(option = ""plasma"", direction = 1) +
  labs(x = NULL,
       y = NULL) +
  coord_polar(theta = ""x"", start = 0) +
  theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

out <- base_plot + petals + facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7)


ggsave(here(""2019"",""week18"", ""test.png""), plot = out)

","2019-18"
"220",81,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week19/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(fs)
library(jkmisc)
library(janitor)
library(countrycode)
library(patchwork)

ratio_data <- here(""2019"", ""week19"", ""data"") %>% 
  dir_ls(regexp = ""student_teacher_ratio"") %>% 
  read_excel(na = c("".."")) %>% 
  set_names(tolower(names(.))) %>% 
  gather(year, ratio, -1:-2,convert = TRUE)



plot_region <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, group = region, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~region, nrow = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") 
  
  }

plot_continent <- function(data) {
  
  ggplot(data, aes(x = year, y = ratio, color = continent)) +
    geom_line(size = 0.3, show.legend = FALSE) +
    geom_ribbon(aes(ymin = 0, ymax = ratio, fill = continent), alpha = 0.5, color = NA, show.legend = FALSE) +
    facet_wrap(~continent, ncol = 1) +
    scale_color_manual(values = colors) +
    scale_fill_manual(values = colors) +
    scale_x_continuous(breaks = seq(1970, 2010, 10)) +
    scale_y_continuous(limits = c(0, 40)) +
    scale_shape_identity() +
    labs(x = NULL,
         y = NULL,
         title = unique(data$continent)) +
    theme_jk(grid = ""XY"") +
    theme(strip.text = element_blank())
  
}

plot_data <- ratio_data %>% 
  filter(type == ""Countries"") %>% 
  mutate(country_code = countrycode(country, ""country.name"", ""iso3c"")) %>% 
  mutate(region = countrycode(country_code, ""iso3c"", ""region"")) %>% 
  mutate(continent = countrycode(country_code, ""iso3c"", ""continent"")) %>% 
  filter(!is.na(region))

colors <- set_names(c(""#171635"", ""#00225D"", ""#763262"", ""#CA7508"", ""#E9A621""), c(unique(plot_data$continent)))

individual <- plot_data %>% 
  group_by(year, region, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_region) 

summary <- plot_data %>% 
  group_by(year, continent) %>% 
  summarize(ratio = mean(ratio, na.rm = TRUE)) %>% 
  filter(!is.nan(ratio)) %>% 
  split(.$continent) %>% 
  map(plot_continent) 
  
plots <- map2(summary, individual, ~wrap_plots(.x, .y, nrow = 1, widths = c(1, 1)))
  
out <- wrap_plots(plots, ncol = 1) +
  plot_annotation(title = ""Working to Two Sigma: Student Teacher Ratios Improving Since the 1970s"",
                  subtitle = str_wrap(""Illustrated below is the average student to teacher ratio across each continent (left column) and region (right column).  Continent and region assigned from iso3c coding of country name and are consistent with the World Bank Dvelopment Indicators."", 210),
                  caption = ""Data: UNESCO Institute of Statistics | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"",""week19"",""tw19_plot.png""), out, width = 16, height = 10)
","2019-19"
"221",82,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week2/R/analysis.R","library(tidyverse)
library(ggraph)
library(tidygraph)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)
library(nord)

set.seed(42)

source(here(""2019"", ""week2"", ""R"", ""functions.R""))

# Read data from github repo
tv_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"") %>% 
  rename(title_id = titleId,
         season_number = seasonNumber) %>% 
  mutate(year = year(date))

# Make this into a nodes tibble
list <- tv_data %>% 
  split(.$year) %>% 
  map(share_packed_circle)

out <- wrap_plots(list, ncol = 10, nrow = 3) +
  plot_annotation(title = ""The Evolution and Differentiation of Dramas Across the Golden Age of Television"",
                  subtitle = str_wrap(""This chart presents a time series of circle-packed network representations of the television dramas.  
                                      The larger dark blue circle represents the year, light blue represents the genre (Action, Comedy, etc.) and the pale pink represents the individual program. 
                                      The area of each circle (node) is porportional to the sum of the audience share of the smaller circles within (child nodes)."", 180),
                  caption = ""data: IMDb | graphic: @jakekaupp"",
                  theme = theme_jk(plot_title_size  = 22, subtitle_size = 14) %+replace% theme(plot.background = element_rect(fill =""#2E3440""),
                                                      text = element_text(color = ""white"")))
 
ggsave(here(""2019"",""week2"", ""tt_week2.png""), out, width = 16, height = 8)
","2019-2"
"222",83,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week2/R/functions.R","share_packed_circle <- function(df) {
 
  nodes <- make_nodes(df)
  
  edges <- make_edges(df)
 
  mygraph <- tbl_graph(nodes = nodes, edges = edges)
  
  # Make the plot
  plot <- ggraph(mygraph, layout = 'circlepack', weight = ""size"") + 
    geom_node_circle(aes(fill = depth)) +
    theme_void() +
    labs(title = unique(df$year)) +
    coord_equal() +
    scale_fill_nord(""lumina"", discrete = FALSE, reverse = TRUE) +
    #scale_fill_viridis(option = ""plasma"") +
    theme(legend.position = ""none"", 
          plot.background = element_rect(fill = ""#4C566A""),
          plot.title = element_text(family = ""Oswald"", hjust = 0.5, color = ""white""),
          )
  
  return(plot)
}


make_nodes <- function(df) {
  
  size <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    distinct(genres, title, share) %>% 
    rename(name = title, size = share)
  
  genre_size <- size %>% 
    group_by(genres) %>% 
    summarize(size = sum(size)) %>% 
    rename(name = genres)
  
  title_size <- size %>% 
    ungroup() %>% 
    distinct(name, size) %>% 
    mutate(size = size)
  
  total_size <- df %>% 
    distinct(title, share) %>% 
    summarize(name = as.character(unique(df$year)),
              size = sum(share))
  
  sizes <- bind_rows(genre_size, title_size, total_size)
  
  nodes <- df %>% 
    group_by(title, genres, year) %>% 
    summarize(share = mean(share)) %>% 
    gather(variable, name, title, genres, year) %>% 
    arrange(variable, name) %>% 
    distinct(name) %>% 
    left_join(sizes, by = ""name"") %>% 
    mutate(size = if_else(size == 0, 0.001, size)) %>% 
    arrange(size)
  
  return(nodes)
  
  
}

make_edges <- function(df) {
  
  base <- tibble(from = as.character(unique(df$year)), to = unique(df$genres))
  
  inner <- df %>% 
    select(from = genres, to = title) %>% 
    distinct() 
  
  edges <- bind_rows(base, inner) 
  
  return(edges)
  
}
","2019-2"
"223",84,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week20/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(rcrossref)
library(ggbeeswarm)
library(jkmisc)


# Not re-downloading things, the citation count pulls take 2hrs.
if (length(dir_ls(here(""2019"", ""week20"", ""data""))) <= 0) {
 
  nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
  nobel_winners_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")
  
  saveRDS(nobel_winners, here(""2019"", ""week20"", ""data"", ""nobel_winners.RDS""))
  
  saveRDS(nobel_winners_all_pubs, here(""2019"", ""week20"", ""data"", ""nobel_winners_all_pubs.RDS""))

  
} else {
  
  nobel_winners <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners.RDS"") %>% 
    readRDS()
  
  nobel_winners_all_pubs <- dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""nobel_winners_all_pubs.RDS"") %>% 
    readRDS()
 
}


if (length(dir_ls(here(""2019"", ""week20"", ""data""), regexp = ""cite_count"")) <= 0) {

  dois <- nobel_winners_all_pubs$doi

  list  <- split(dois, rep(1:ceiling(length(dois)/50), each=50)[1:length(dois)])

wait_cr_citation_count <- function(doi, index, list_len) {
  
  print(sprintf(""%s complete"", scales::percent(index/list_len)))
  
  Sys.sleep(1)
  
  cr_citation_count(doi)
  
}

cite_count <- imap_dfr(list, ~wait_cr_citation_count(.x, .y, length = length(list)))

saveRDS(cite_count, here(""2019"", ""week20"", ""data"", ""cite_count.RDS"")) 

} else {
  
cite_count <- readRDS(here(""2019"", ""week20"", ""data"", ""cite_count.RDS""))
  
}

highlights <- c(""einstein, a"", ""hill, av"", ""heeger, a"")

plot_data <- nobel_winners_all_pubs %>%
  left_join(cite_count) %>%
  distinct(laureate_id, paper_id, .keep_all = TRUE) %>%
  select(pub_year, laureate_name, is_prize_winning_paper, count, category) %>% 
  replace_na(list(count = 0)) %>% 
  group_by(laureate_name, pub_year, category) %>%
  summarize(count = sum(count)) %>% 
  group_by(laureate_name) %>% 
  mutate(rolling_sum = cumsum(count)) %>% 
  mutate(color = if_else(laureate_name %in% highlights, ""#F24534"", ""#21344F""),
         alpha = if_else(laureate_name %in% highlights, 1, 0.2))


everyone <- filter(plot_data, laureate_name %notin% highlights)

focus <- filter(plot_data, laureate_name %in% highlights) %>% 
  ungroup() %>% 
  mutate(laureate_name = case_when(laureate_name == ""einstein, a"" ~ ""Einstein, A"",
                                   laureate_name == ""hill, av"" ~ ""Hill, AV"",
                                   laureate_name == ""heeger, a"" ~ ""Heeger, A"")) %>% 
  group_by(laureate_name)


plot <- ggplot(plot_data, aes(x = pub_year, y = rolling_sum, group = laureate_name)) +
  geom_step(aes(color = color, alpha = alpha)) +
  geom_step(data = focus, aes(color = color, alpha = alpha)) +
  geom_text(data = filter(focus, pub_year == last(pub_year)), aes(color = color, alpha = alpha, label = laureate_name), x = 2018, family = ""Oswald"", hjust = 0) +
  scale_x_continuous(limits = c(1900, 2100), breaks = c(1900, 1925, 1950, 1975, 2000, 2018)) +
  scale_y_continuous(breaks = scales::pretty_breaks(), labels = scales::number) +
  scale_color_identity() +
  scale_alpha_identity() +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  labs(x = NULL,
       y = NULL,
       title = ""Growth Patterns in How Often Nobel Prize Winning Researchers Are Cited"",
       subtitle = str_wrap(""Cummulative citation count by year (1900-2018).  Highlighted are A. Heeger (conductive polymers), A.V. Hill (heat and work in muscle) and A. Einstein (photoelecric effect). Each exhibit different citation patterns, likely attributed to the continued relevance and impact of their work."", 150),
       caption = ""Data: Li, Jichao; Yin, Yian; Fortunato, Santo; Wang Dashun, 2018, 'A dataset of publication records for Nobel laureates', https://doi.org/10.7910/DVN/6NJ5RN, Harvard Dataverse. | Graphic: @jakekaupp"") +
  theme_jk(grid = ""Y"") +
  theme(legend.position = ""bottom"") 

ggsave(here(""2019"", ""week20"", ""tw20_plot.png""), plot, width = 12, height = 6)

","2019-20"
"224",85,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week21/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(fs)
library(janitor)
library(jkmisc)
library(patchwork)


# Plotting Function to make separate ordered stacked bars by group----
make_bars <- function(df, pals) {
  
  order <- df %>% 
    arrange(desc(other)) %>% 
    pull(country)
  
  labs <- c(""HIC"" = ""High Income Group"",
            ""UMI"" = ""Upper Middle Income Group"",
            ""LMI"" = ""Lower Middle Income Group"",
            ""LI"" = ""Low Income Group"")
  
  
  df %>% 
    gather(type, value, c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste"")) %>% 
    mutate(type = factor(type, c(""other"", ""inadequate_waste"", ""plastic_waste"", ""littered_waste""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
    mutate(country = factor(country, order)) %>% 
    mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
    ggplot() +
    geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
    coord_flip() +
    scale_fill_manual("""", values = pals) +
    scale_alpha_identity() +
    scale_y_continuous(expand = c(0,0.05), labels = scales::percent) +
    labs(x = NULL, y = NULL) +
    facet_wrap(~economic_status, scales = ""free_y"", labeller = as_labeller(labs)) +
    theme_jk(grid = FALSE) +
    theme(legend.direction = ""horizontal"")
  
}


# Function to extract ggplot legends ----
extract_legend <- function(ggp){
  
  tmp <- ggplot_gtable(ggplot_build(ggp))
  
  leg <- which(map_lgl(tmp$grobs, function(x) x$name == ""guide-box""))
  
  legend <- tmp$grobs[[leg]]
  
  return(legend)}


# Read in Coastal Waste Data----
# Plastic waste inputs from land into the ocean
# BY JENNA R. JAMBECK, ROLAND GEYER, CHRIS WILCOX, THEODORE R. SIEGLER, MIRIAM PERRYMAN, ANTHONY ANDRADY, RAMANI NARAYAN, KARA LAVENDER LAW
# 
# SCIENCE13 FEB 2015 : 768-771

coastal_waste <- here(""2019"", ""week21"", ""data"") %>% 
  dir_ls(regexp = ""xlsx"") %>% 
  read_excel() %>% 
  clean_names() %>% 
  set_names(str_remove(names(.), ""_*[0-9]$"")) %>% 
  mutate(country = str_remove(country, ""[0-9]"")) %>% 
  mutate(country = case_when(str_detect(country, ""Palestine"") ~ ""Palestine"",
                             str_detect(country, ""Korea, South"") ~ ""South Korea"",
                             str_detect(country, ""Korea, North"") ~ ""North Korea"",
                             str_detect(country, ""Congo"") ~ ""Congo"",
                             TRUE ~ country)) %>% 
  filter(!grepl(""Burma"", country)) %>% 
  filter(complete.cases(.)) %>% 
  mutate(other = 100 - (percent_plastic_in_waste_stream + percent_inadequately_managed_waste + percent_littered_waste)) %>% 
  rename(plastic_waste = percent_plastic_in_waste_stream, inadequate_waste  = percent_inadequately_managed_waste, littered_waste = percent_littered_waste) %>% 
  mutate_at(c(""other"", ""plastic_waste"", ""inadequate_waste"", ""littered_waste""), function(x) x/100) %>% 
  mutate(other = if_else(other < 0, 0, other)) %>% 
  mutate(total_waste = waste_generation_kg_day * 365/1000,
         total_plastic_waste = total_waste * plastic_waste,
         total_inadequate_waste = total_waste * inadequate_waste,
         total_littered =  total_waste * littered_waste,
         other_waste = total_waste * other)


# Palette for plot----
pal <- c(""#F5F0F6"", ""#629460"", ""#385F71"", ""#2B4162"")

avg <- coastal_waste %>% 
  summarize(total_waste = mean(total_waste, na.rm = TRUE),
            other_waste  = mean(other_waste, na.rm = TRUE),
            total_plastic_waste  = mean(total_plastic_waste, na.rm = TRUE),
            total_inadequate_waste = mean(total_inadequate_waste, na.rm = TRUE),
            total_littered = mean(total_littered, na.rm = TRUE)) %>% 
  mutate(country = ""Global Average"")


order <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  pull(country) 



overall_mismanaged <- coastal_waste %>% 
  top_n(50, total_inadequate_waste) %>% 
  bind_rows(avg) %>% 
  top_n(50, total_inadequate_waste) %>% 
  arrange(desc(total_inadequate_waste)) %>% 
  gather(type, value, c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered"")) %>% 
  mutate(type = factor(type,  c(""other_waste"", ""total_plastic_waste"", ""total_inadequate_waste"", ""total_littered""), c(""Other"", ""Inadequately Managed Waste"", ""Plastic Waste"", ""Littered Waste""))) %>% 
  mutate(country = factor(country, rev(order))) %>% 
  mutate(alpha = if_else(type == 'Other', 0.5, 0.8)) %>% 
  mutate(strip = ""Top 50 Producers & Global Average of Total Indequately Managed Waste (kg)"") %>% 
  ggplot() +
  geom_col(aes(x = country, y = value, fill = type, alpha = alpha), width = 0.90, size = 0.1) +
  coord_flip() +
  scale_fill_manual("""", values = pal) +
  scale_alpha_identity() +
  scale_y_continuous(expand = c(0,0.05), labels = scales::comma) +
  labs(x = NULL, y = NULL) +
  facet_wrap(~strip) +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""none"")


# Make plots----
list <- coastal_waste %>% 
  split(.$economic_status) %>% 
  map(make_bars, pal)

# Extract legend----
legend <- extract_legend(list[[1]])

# Remove legend from list of plots----
list <- map(list, ~.x + theme(legend.position = ""none""))
  
# Finish plot----
out <- (overall_mismanaged + wrap_plots(list[c(""HIC"", ""UMI"", ""LMI"", ""LI"")], nrow = 1) + plot_layout(widths = c(0.3, 0.7))) / legend + plot_layout(heights = c(0.95, 0.05)) +
  plot_annotation(title = ""The Relationship Between World Bank Income Classification and Mismanaged Waste"",
                  subtitle = str_wrap(""Illustrated below is the percentage of waste by category for each country by World Bank income classification.  The lower the classification, the higher the mismanaged waste.  Much of this mismanaged waste (especially plastics) ends up in waterways that ultimately lead to our oceans, suggesting that global income inequality plays a role in ocean pollution by hampering the implementation of effective waste management strategies."", 240),
                  caption = ""Data: Jambeck, Jenna R., et al. 'Plastic waste inputs from land into the ocean.' Science 347.6223 (2015): 768-771. | Graphic: @jakekaupp"",
                  theme = theme_jk())

ggsave(here(""2019"", ""week21"", ""tw21_plot.png""), out, width = 19, height = 12)



","2019-21"
"225",86,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week22/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(ggridges)
library(tidytext)
library(countrycode)
library(ggwordcloud)
library(patchwork)

source(here(""2019"", ""week22"", ""R"", ""packed_bars.R""))

wine_ratings <- here(""2019"", ""week22"", ""data"", ""winemag-data-130k-v2.csv"") %>% 
  read_csv()

wine_counts <- wine_ratings %>% 
  count(country) %>% 
  mutate(max_rel_val = n/sum(n)) %>% 
  filter(!is.na(country))
 
summary_ratings <- wine_ratings %>% 
  group_by(country) %>% 
  summarize_at(c(""points"",""price""), mean, na.rm = TRUE) %>% 
  filter(!is.na(country))

summary_data <- left_join(wine_counts, summary_ratings)

plot_data <- pack_bars(summary_data, number_rows = 4, max_rel_val)

packed_bar <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"") +
  geom_text(data = filter(plot_data, fill == ""#4B384C""), aes(x = xmin, y = (ymin + ymax)/2, label = country), family = ""Oswald"", color = ""white"", nudge_x = 0.01, hjust = 0) +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

word_counts <- wine_ratings %>%
  select(country, description) %>%
  group_by(country) %>% 
  filter(n() > 2) %>% 
  filter(!is.na(country)) %>% 
  unnest_tokens(word, description) %>% 
  anti_join(stop_words) %>% 
  count(country, word) %>% 
  mutate(word = trimws(word)) %>% 
  filter(!str_detect(word, ""[0-9]""), !str_detect(word, ""aroma|wine|note|nose|notes|aromas|drink|drinks|feel|feels|finish"")) %>% 
  group_by(country) %>% 
  top_n(300, n) 

clouds <- word_counts %>% 
  ungroup() %>% 
  mutate(iso2 = tolower(countrycode(country, ""country.name"", ""iso2c"")),
         iso2 = if_else(country == ""England"", ""gb"", iso2)) %>% 
  filter(country %in%  c(""US"", ""France"", ""Italy"", ""Spain"")) %>% 
  mutate(country = factor(country, levels = c(""US"", ""France"", ""Italy"", ""Spain"")),
         iso2 = factor(iso2, levels = c(""us"",""fr"", ""it"", ""es""))) %>% 
  group_by(iso2) %>% 
  nest() %>% 
  arrange(iso2) %>% 
  mutate(clouds =  map2(iso2, data, create_wc))

word_clouds <- wrap_plots(clouds$clouds, ncol = 1) 

out <- packed_bar + word_clouds +
  plot_annotation(title = ""Wine-ing: The Top 4 Countries and What Reviewers Say About Their Wines"",
                  subtitle = str_wrap(""On the left, a packed bar chart showing the % of reviewed wines by country.  On the right, wordclouds of the top 300 most frequent terms used in reviews."", 100),
                  caption = ""Data: Kaggle via WineEnthusiast | Graphic: @jakekaupp"",
                  theme = theme_jk()
                  )

ggsave(here('2019', ""week22"", ""tw22_plot.png""), out, width = 8, height = 12)

ggsave(here('2019', ""week22"", ""packed_bar.png""), packed_bar + labs(title = ""Top 4 Countries Reviewed as Packed Bar Chart"",
                                                                   subtitle = str_wrap(""The visualizion below is a packed bar chart, developed by Xan Gregg.  It combines the ordered nature of a bar chart with the total view and condensed nature of a treemap.  Colour denotes the focus, while the each gray sections represents each other reviwed country. This gives a sense of how many secondary categories there are, their magnitude and distribution. Additionally, since they are on the same scale of the focused bars we can even estimate some of the values from the length they span on the axis."", 100)), width = 8, height = 6)
","2019-22"
"226",87,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week22/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- summary_data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- summary_data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}


create_wc <- function(iso2, data) {
  
  cntry_mask <- png::readPNG(here(""2019"", ""week22"", ""data"", ""png maps"", iso2, ""1024.png""))
  
  ggplot(data, aes(label = word, size = n)) +
    geom_text_wordcloud(family = ""Oswald"", mask = cntry_mask, rm_outside = TRUE) +
    scale_radius(range = c(0, 40)) +
    theme_jk() 
  
  
}
","2019-22"
"227",88,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week23/R/analysis.R","library(tidyverse)
library(glue)
library(rvest)
library(xml2)
library(lubridate)
library(here)
library(jkmisc)



#Scraping functions----

get_urls <- function(sitemap_url) {
  
  read_xml(sitemap_url) %>%
    xml_children() %>% 
    xml_children() %>% 
    xml_text() %>% 
    keep(~str_detect(.x, ""https://www.theramenrater.com/[0-9]{4}/[0-9]{2}/[0-9]{1,}/\\w+""))
  
}

get_post_title <- function(url, idx, rows) {
  
  print(sprintf(""Progress: %s/%s"", idx, rows))
  
  read_html(url) %>% 
    html_node("".entry-title"") %>% 
    html_text()
  
  
}

slowly_get_post_title <- slowly(~ get_post_title(.x, .y, rows), rate = rate_delay(pause = 0.5), quiet = TRUE)

#Week of month
wom <- function(date) { # week-of-month
  first <- wday(as.Date(paste(year(date), month(date), 1, sep=""-"")))
  return((mday(date) + (first - 2)) %/% 7 + 1)
}

#Plotting functions----
month_outline <- function(df) {
  
  top1 <- with(df, tibble(x = min(wmonth) - 0.5,
                          xend = wday[day == min(day)] - 0.5,
                          y = wmonth[day == min(day)] + 0.5,
                          yend = wmonth[day == min(day)] + 0.5,
                          line = ""top1"")) 
  
  top2 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                          xend = max(wday) + 0.5,
                          y = min(wmonth) - 0.5,
                          yend = min(wmonth) - 0.5,
                          line = ""top2"")) 
  
  left1 <- with(df, tibble(x = wday[day == min(day)] - 0.5,
                           xend = wday[day == min(day)] - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = min(wmonth) - 0.5,
                           line = ""left1""))
  
  left2 <- with(df, tibble(x = min(wmonth) - 0.5,
                           xend = min(wmonth) - 0.5,
                           y = wmonth[day == min(day)] + 0.5,
                           yend = wmonth[day == max(day)] + 0.5,
                           line = ""left2""))
  

  right1 <- with(df, tibble(x = max(wday) + 0.5,
                            xend = max(wday) + 0.5,
                            y = min(wmonth) - 0.5,
                            yend = wmonth[day == max(day)] - 0.5,
                            line = ""right1""))
  
  right2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                            xend = wday[day == max(day)] + 0.5,
                            y = wmonth[day == max(day)] - 0.5,
                            yend = wmonth[day == max(day)] + 0.5,
                            line = ""right2""))

  
  bottom1 <- with(df, tibble(x = min(wmonth) - 0.5,
                             xend = wday[day == max(day)] + 0.5,
                             y = wmonth[day == max(day)] + 0.5,
                             yend = wmonth[day == max(day)] + 0.5,
                             line = ""bottom1""))
  
  bottom2 <- with(df, tibble(x = wday[day == max(day)] + 0.5,
                             xend = max(wday) + 0.5,
                             y = wmonth[day == max(day)] - 0.5,
                             yend = wmonth[day == max(day)] -0.5,
                             line = ""bottom2""))
  
  top <- bind_rows(top1, top2)
  left <- bind_rows(left1, left2)
  bottom <- bind_rows(bottom1, bottom2) 
  right <- bind_rows(right1, right2) 
    
    bind_rows(top, left, right, bottom) %>% 
      mutate(year = unique(df$year),
             month = unique(df$month)) 
    
  
}


if(!file.exists(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))) {
  
  # Add Recent ratings #3181-319
  recent_ratings <- tibble(review_number = c(3181:3189, 1676, 2745, 2991),
                           stars = c(3.75, 3.25, 4.0, 3.25, 2.0, 3.75, 3.75, 3.5, 2.25, 4.25, 5, 3.25),
                           brand = c(""Nissin Yakisoba"", ""Maruchan"", ""Uni-President"", ""Maruchan"", ""Sakruai Foods"", ""Nissin Mago"", ""Big Bon"", ""Sapporo Ichiban"", ""Canton"", ""A1"", ""Nissin"", ""Big Bon""),
                           variety = c(""Instant Panict Savory Beef Flavour"", ""Maruchan Ramen Noodle Soup Roast Beef Flavour"", ""Imperial Big Meal Super Hot Pot Beef Flavour"",
                                       ""Ramen Noodle Soup Pork Beef Flavour"", ""Vegetarian Stir Fry Noodles"", ""Nissin Lamen Light Legumes "", ""Spice Mix Piquant"", ""Momosan Ramen Tokyo Chicken"", ""Instant Noodles Spicy Tomato"",
                                       ""Emperor Herbs Chicken Noodle"", ""U.F.O. Big Wasabi-Mayo Yakisoba"", ""Chicken & Salsa Sauce Instant Noodles""),
                           country = c(""Phillipines"", ""United States"", ""Taiwan"", ""United States"", ""Japan"", ""Brazil"", ""Russia"" , ""United States"", ""India"", ""Malaysia"", ""Japan"", ""Russia""),
                           style = c(""Cup"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack"", ""Pack""))
  
  # Read tidytesday data----
  ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"") %>% 
    bind_rows(recent_ratings)
  
  out <- tibble(sitemap_url = glue(""https://www.theramenrater.com/post-sitemap{1:5}.xml""),
                contents = map(sitemap_url, get_urls)) %>% 
    unnest() 
  
  rows <- nrow(out)
  
  # Scrapin der web purges----
  out <-  out %>% 
    mutate(title = imap(contents, ~slowly_get_post_title(.x, .y, rows))) %>% 
    mutate(date = parse_date(str_extract(contents, ""[0-9]{4}/[0-9]{2}/[0-9]{1,}""), ""%Y/%m/%d""),
           review_number = as.numeric(str_extract(title, ""(?!#)[0-9]{1,4}(?=\\:)""))) %>% 
    filter(!is.na(review_number)) %>% 
    left_join(ramen_ratings) %>% 
    filter(review_number < 4000) %>% 
    select(-sitemap_url)
  
  # Saving the new dataset----
  saveRDS(out, here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
} else {
  
  ramen_data <- readRDS(here(""2019"",""week23"", ""data"", ""full_ramen_data.RDS""))
  
}

#Make months
all_dates <- tibble(date = seq.Date(from = ymd(""2009/01/01""), to =ymd(""2019/12/31""), by =""day"")) %>% 
  mutate(day = day(date),
         month = month(date),
         year = year(date))

plot_data <- ramen_data %>%
  mutate(day = day(date),
         month = month(date),
         year = year(date)) %>% 
  group_by(year, month, day) %>% 
  summarize(brands = toString(sprintf(""%s: %s"", brand, variety)),
            count = n(),
            avg_stars = mean(stars)) %>% 
  right_join(all_dates) %>% 
  ungroup() %>% 
  mutate(wday = wday(date, label = TRUE, week_start = 7),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date))
  
outlines <- all_dates %>% 
  mutate(wday_label = wday(date, label = TRUE),
         wday = wday(date),
         month = month(date,label = TRUE),
         wmonth = wom(date),
         week = week(date)) %>% 
  split(list(.$year, .$month), drop = TRUE) %>% 
  map_df(month_outline)



plot <- ggplot(data = plot_data, aes(x = wday, y = wmonth, fill = avg_stars)) +
  geom_tile(color = ""grey80"", size = 0.1) +
  geom_segment(data = outlines, aes(x = x, xend = xend, y = y, yend = yend, group = line), color = ""grey30"", inherit.aes = FALSE) +
  scale_y_continuous(trans = ""reverse"", labels = NULL) +
  scale_x_discrete(labels = NULL) +
  scale_fill_gradientn(""Average Stars"", colors = rev(parula(100)), na.value = ""grey95"") +
  facet_grid(month ~ year, switch = ""y"") +
  labs(x = NULL,
       y = NULL,
       title = ""The Prolfic Nature of the Ramen Rater and a Birds-Eye View of Ramen Quality"",
       subtitle = str_wrap(""Below is a heatmap calendar of the all the Ramen Raters ramen ratings by the published date of the review.  In the early days, multiple reviews were posted in a single day, until reaching the usual pattern of a single review per day.  However, there are still some reviews that get posted en masse."", 100),
       caption = ""Data: The Ramen Rater | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE) +
  theme(strip.text.y = element_text(angle = 180),
        panel.spacing.y = unit(-0.2, ""lines""),
        legend.position = ""bottom"")

ggsave(here(""2019"", ""week23"", ""tw23_plot.png""), height = 11, width = 8.5, type = ""cairo"")





  
","2019-23"
"228",89,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week24/R/analysis.R","library(nord)
library(tidyverse)
library(ggmap)
library(here)
library(countrycode)
library(jkmisc)
library(patchwork)

source(here(""2019"", ""week24"", ""R"", ""packed_bars.R""))

if (!file.exists(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))) {
  
  slow_revgeocode <- slowly(~revgeocode(.x, output = ""address""), rate = rate_delay(0.03), quiet = TRUE)
  
  reverse_geocoded <- meteorites %>% 
    distinct(long, lat) %>% 
    mutate(location = map2_chr(long, lat, ~slow_revgeocode(c(.x, .y))))
  
  saveRDS(reverse_geocoded, here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
} else {
  
  meteorite_locations <- readRDS(here(""2019"", ""week24"", ""data"", ""rev_geocoded_meteorites.RDS""))
  
  
}

meteorites <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

meteorites <- left_join(meteorites, meteorite_locations) %>% 
  mutate(country_code = countrycode(location, ""country.name"", ""iso3c"")) %>% 
  mutate(country_code = case_when(str_detect(location, ""UK"") ~ ""GBR"",
                                  str_detect(location, ""USA"") ~ ""USA"",
                                  str_detect(location, ""China"") ~ ""CHN"",
                                  str_detect(location, ""Philippines"") ~ ""PHL"",
                                  str_detect(location, ""Serbia"") ~ ""RUS"",
                                  str_detect(location, ""Australia"") ~ ""AUS"",
                                  str_detect(location, ""Chile"") ~ ""CHL"",
                                  str_detect(location, ""Shopian"") ~ ""IND"",
                                  str_detect(location, ""Argentina"") ~ ""ARG"",
                                  str_detect(location, ""Bass Strait"") ~ ""AUS"",
                                  TRUE ~ country_code)) %>% 
  mutate(country_code = case_when(str_detect(name, ""Indarch"") ~ ""AZE"",
                                  str_detect(name, ""Oum Dreyga"") ~ ""ESH"",
                                  str_detect(name, ""Zag"") ~ ""ESH"",
                                  str_detect(name, ""Al Haggounia"") ~ ""ESH"",
                                  str_detect(name, ""Bou Kra"") ~ ""ESH"",
                                  TRUE ~ country_code)) %>% 
  rename(iso3c = country_code) %>% 
  filter(!is.na(iso3c)) 


world_tile_grid <- read_csv(""https://gist.githubusercontent.com/maartenzam/787498bbc07ae06b637447dbd430ea0a/raw/9a9dafafb44d8990f85243a9c7ca349acd3a0d07/worldtilegrid.csv"")

meteorite_wtg <- meteorites %>% 
  group_by(iso3c) %>% 
  summarize(n = n(),
            mass = sum(mass, na.rm = TRUE)/1000) %>%
  mutate(per_meteorite = mass/n) %>% 
  right_join(world_tile_grid, by = c(""iso3c"" = ""alpha.3"")) %>% 
  mutate(text_color = if_else(per_meteorite < 1, ""white"", ""black"")) %>% 
  replace_na(list('alpha.2' = ""NA"",
                  ""text_color"" = ""black"")) 


meteorite_map <- ggplot(meteorite_wtg, aes(x, y, fill = odds, group = iso3c)) +
  geom_tile(color = ""grey30"", size = 0.1) +
  geom_text(aes(label = alpha.2, color = text_color), family = ""Oswald"") +
  labs(x = NULL,
       y = NULL) +
  scale_y_reverse() +
  scale_fill_viridis_c(name = ""Average Metorite Mass (kg, log scale)"",option = ""cividis"", na.value = ""white"", breaks = c(1, 10, 100, 1000, 10000, 100000), guide = guide_colourbar(title.position = ""top"", title.hjust = 0)) +
  scale_color_identity() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.direction = ""horizontal"",
        legend.key.width = unit(2, ""lines""),
        legend.position = c(0.2, 0.05))


plot_data <- meteorite_wtg %>%
  select(alpha.2, n) %>% 
  mutate(n = log10(n)) %>% 
  replace_na(list(n = 0)) %>% 
  pack_bars(10, value_column = n, fill_color = last(nord(""lumina"", 5)))


packed_bars <- ggplot(plot_data) +
  geom_rect(aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), color = ""white"", size = 0.1) +
  geom_text(data = filter(plot_data, (xmax - xmin) > 0.1), aes(x = (xmin + xmax)/2, y = (ymin + ymax)/2, label = alpha.2), family = ""Oswald"", color = ""white"") +
  scale_fill_identity() +
  scale_color_identity() +
  scale_x_continuous(breaks = scales::pretty_breaks()) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())


out <- packed_bars + meteorite_map  + plot_annotation(title = ""You May Need More Than An Umbrella in Russia:  Where the Most, and Heaviest, Meteorites fall"",
                                                subtitle = str_wrap(""On the left is a packed bar chart showing the top 10 regions struck by the most meteorites, while the tile map on the right shows the average meteorite mass across all regions.  Both measures have been scaled logathrimically to aid in comparability."", 180),
                                                caption = ""Data: NASA | Graphic: @jakekaupp"",
                                              theme = theme_jk())

ggsave(here(""2019"", ""week24"", ""tw24_plot.png""), out, width = 14, height = 7)
","2019-24"
"229",90,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week24/R/packed_bars.R","
pack_bars <- function(data, number_rows, value_column, fill_color = ""#4B384C"", border_color = ""white"") {

value_column <- ensym(value_column)  
  
color_bar_data <- data %>% 
  top_n(number_rows, !!value_column) %>% 
  arrange(desc(!!value_column))

# calc row height based on num rows
bar_h = 1/number_rows

color_bars <- color_bar_data %>% 
  mutate(fill = fill_color,
         color = border_color,
         xmin = 0,
         xmax = !!value_column,
         ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1)),
         ymax = map_dbl(1:number_rows, ~1 - bar_h*.x))

gray_bar_data <- data %>% 
  anti_join(color_bar_data) %>% 
  arrange(desc(!!value_column))

#get max x level for each bar level
row_sums <- pull(color_bar_data, !!value_column)

#gen gray ramp function
gray_gen <- colorRampPalette(c(""#E8E8E8"", ""#cccccc""))

#gen gray ramp
grays <- gray_gen(105)
low_grays <- grays[1:50]
hi_grays  <- grays[56:105]

last_gray <- sample(c(low_grays, hi_grays), number_rows, replace = TRUE)

gray_bar_list <- vector('list', nrow(gray_bar_data))


for (i in 1:nrow(gray_bar_data)) {
  
  row <- gray_bar_data[i,]
  
  # Determine placing of each block by looking at the minium starting values of colored bars
  # adding on the new block and setting value to represent the new block length
  vert_pos <- which.min(row_sums + pull(row, !!value_column))
  
  # Assign alternating random grays to fill
  if (i == 1) {
    
    gray_fill <- sample(low_grays, 1)
    
  } else {
    
    last_gray <- last_gray[vert_pos]
    
    gray_fill <- ifelse(last_gray %in% low_grays, sample(hi_grays, 1), sample(low_grays, 1))
  }
  
  last_gray[vert_pos] <- gray_fill
  
  # Generate aes for geom_rect
  gray_bar_list[[i]]  <- mutate(row, 
                                fill = gray_fill,
                                color = border_color,
                                xmin = row_sums[[vert_pos]],
                                xmax = row_sums[[vert_pos]] + !!value_column,
                                ymin = map_dbl(1:number_rows, ~1 - bar_h*(.x-1))[[vert_pos]],
                                ymax = map_dbl(1:number_rows, ~1 - bar_h*.x)[[vert_pos]]
  )
  
  # Assign the new color_bar + rectangle as the max value for that row 
  row_sums[[vert_pos]] <- gray_bar_list[[i]]$xmax
  
}

gray_bars <- bind_rows(gray_bar_list)

bind_rows(color_bars, gray_bars)

}

","2019-24"
"230",91,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week25/R/analysis.R","library(tidyverse)
library(waffle)
library(jkmisc)
library(here)

bird_counts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

top_10 <- bird_counts %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  group_by(genus) %>% 
  summarize(total = sum(how_many_counted_by_hour, na.rm = TRUE)) %>% 
  top_n(10, total) %>% 
  pull(genus)

by_genus <- filter(bird_counts, year >= 2000) %>% 
  separate(species_latin, c(""genus"", ""family""), sep = "" "") %>% 
  filter(genus %in% top_10) %>% 
  group_by(year, genus) %>% 
  summarize(counts_by_hour = sum(how_many_counted_by_hour, na.rm = TRUE))

colors <- set_names(gray.colors(10), top_10)

colors[""Anas""] <- ""#ffd45c""

ducks <- ggplot(by_genus, aes(values = counts_by_hour, fill = genus)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, nrow = 1, strip.position = ""bottom"") +
  coord_equal() +
  labs(title = str_to_title(""The Duck is one of the most noble, agile and intelligent creatures in the animal kingdom.""),
       subtitle = str_wrap(""Total counts per hour, of the top 10 genera from since 2000.  Duck counts (genus Anas) are highlighted in yellow, because if it looks like a duck, and quacks like a duck, we have at least to consider the possibility that we have a small aquatic bird of the family anatidae on our hands."", 120),
       caption = ""Data: www.birdscanada.org/ | Graphic: @jakekaupp"") +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  scale_fill_manual(values = colors) +
  theme_jk(grid = FALSE, ticks = TRUE) +
  theme(strip.text = element_text(size = rel(0.8)))

cobra_chicken <- bird_counts %>% 
  filter(year >=1950) %>% 
  group_split(species) %>% 
  map_dfr(~mutate(.x, color = if_else(species == ""Canada Goose"", ""#CB181D"", sample(gray.colors(255), 1)),
                  alpha = if_else(species == ""Canada Goose"", 1, 0.25))) %>%   
  ggplot(aes(x = year, y = how_many_counted_by_hour, group = fct_relevel(species, ""Canada Goose"", after = Inf), fill = color, alpha = alpha), color = ""grey30"") +
  geom_area() +
  scale_y_continuous(expand = c(0.01, 0.1), breaks = scales::pretty_breaks()) +
  scale_x_continuous(breaks = c(seq(1950, 2010, 10), 2017)) +
  scale_fill_identity() +
  scale_alpha_identity() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Rise Of The Cobra Chicken, the Scourge of the Hamilton Waterfront"",
       subtitle = str_wrap(""The Canada Goose, hilarious and aptly referred to as a 'Cobra Chicken' has been a threat to the delicate ecosystem of Hamilton's Harbor."", 120),
       caption = ""Data: www.birdscanada.org | Graphic: @jakekaupp"") +
  theme_jk(grid = FALSE, ticks = TRUE)
  

ggsave(here(""2019"", ""week25"", ""tw25_ducks.png""), ducks, width = 10, height = 4)
ggsave(here(""2019"", ""week25"", ""tw25_canada_goose.png""), cobra_chicken, width = 10, height = 4)
","2019-25"
"231",92,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week26/R/analysis.R","library(sf)
library(albersusa)
library(here)
library(jsonlite)
library(RCurl)
library(janitor)
library(jkmisc)
library(cowplot)
library(tidyverse)



# Get ufo  & pop. density data----
ufo_sightings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

pop_density <- read_csv(here(""2019"", ""week26"", ""data"", ""pop_density.csv""), skip = 1) %>% 
  clean_names() %>% 
  filter(target_geo_id2 > 1000) %>% 
  mutate(fips = str_pad(target_geo_id2, 5, side = ""left"", pad = ""0"")) %>% 
  select(fips, density = contains(""density""))

# Get alberusa us county sf object----
us_counties <- counties_sf()

# Conver the us ufo sightings to an sf object and join with the alberusa to the the county fips----
usa_sightings_fips <- ufo_sightings %>% 
  filter(country == 'us') %>% 
  st_as_sf(crs = 4326, coords = c(""longitude"", ""latitude"")) 

cont_usa_sightings <- st_join(us_counties, usa_sightings_fips) 



# Some are missing!----
missing <- st_join(usa_sightings_fips, us_counties)  %>% 
  filter(is.na(fips)) %>% 
  semi_join(ufo_sightings,.)

# Make a function to call to the fcc census block API----
geocode_fips <- function(latitude, longitude, index) {
  
  url <- sprintf(""https://geo.fcc.gov/api/census/block/find?latitude=%f&longitude=%f&format=json"",  latitude, longitude)
  
  response <- getURL(url)
  
  json <- fromJSON(response)
  
  print(index)
  
  as.character(json$County['FIPS'])
}

# Make this work insistently----
insistent_geocode <- insistently(~geocode_fips(..1, ..2, ..3), rate = rate_backoff())

# Make it return NA if it fails ----
poss_insistent_geocode <- possibly(~insistent_geocode(..1, ..2, ..3), otherwise = NA_character_)

# Get the missing fips ----

if(!file.exists(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))) {
  missing_fips <- missing %>% 
    distinct(latitude, longitude) %>% 
    mutate(index = row_number()) %>% 
    mutate(fips = pmap_chr(list(latitude, longitude, index), poss_insistent_geocode)) } else {
      
      missing_fips <- readRDS(here(""2019"", ""week26"", ""data"", ""missing_fips.RDS""))
      
    }

# Join it back to missing to fill in fips ----
missing <- left_join(missing, missing_fips) %>% 
  dplyr::select(-index) 

# Bind rows back to cont_usa_sightings for full_usa data ----
full_usa <- cont_usa_sightings %>% 
  left_join(missing, by = c(names(ufo_sightings)[c(1:2,4:9)], ""state.x"" = ""state"")) %>% 
  mutate_at(vars(contains(""fips"")), as.character) %>% 
  mutate(fips = coalesce(`fips.x`, `fips.y`)) %>% 
  select(-fips.x, -fips.y, -state_fips, -county_fips, -latitude, -longitude)

# Summarize sightings, create a ratio and add in population densities----
plot_data <- full_usa %>% 
  group_by_at(.vars = vars(fips, name, lsad, census_area, state.y, iso_3166_2)) %>% 
  summarize(sightings = n()) %>% 
  ungroup() %>% 
  mutate(sightings_ratio = 100*sightings/sum(sightings)) %>% 
  left_join(pop_density)


# create 3 buckets for variables ---
quantiles_sightings <- plot_data %>%
  pull(sightings_ratio) %>%
  quantile(probs = seq(0, 1, length.out = 4))

quantiles_density <- plot_data %>%
  pull(density) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# create color scale that encodes two variables
# red for sightings and blue for population density
bivariate_color_scale <- tibble(
  ""3 - 3"" = ""#3F2949"", # high sightings, high density
  ""2 - 3"" = ""#435786"",
  ""1 - 3"" = ""#4885C1"", # low sightings, high density
  ""3 - 2"" = ""#77324C"",
  ""2 - 2"" = ""#806A8A"", # medium sightings, medium density
  ""1 - 2"" = ""#89A1C8"",
  ""3 - 1"" = ""#AE3A4E"", # high sightings, low density
  ""2 - 1"" = ""#BC7C8F"",
  ""1 - 1"" = ""#CABED0"" # low sightings, low density
) %>%
  gather(""group"", ""fill"")


# Assign each fips area to their correct group and assign the fill from the bivariate scale ----
plot_data <- plot_data %>%
  mutate(sightings_quantiles = cut(sightings_ratio,
                              breaks = quantiles_sightings,
                              include.lowest = TRUE),
    density_quantiles = cut(density,
                            breaks = quantiles_density,
                            include.lowest = TRUE),
    group = paste(as.numeric(sightings_quantiles), ""-"", as.numeric(density_quantiles))) %>%
  left_join(bivariate_color_scale, by = ""group"")


# Making ze plot ----
plot <- ggplot(plot_data) +
  geom_sf(aes(fill = fill), size = 0.05, color = ""#2b2b2b"") +
  scale_fill_identity() +
  labs(title = ""If A UFO Flew Over The Desert And No One Was Around To See It, Would Senators Be Briefed?"",
       subtitle = str_wrap(""Below is a bivariate choropleth map by county illustrating the relationship between the UFO sightings (% of recorded sightings since 1911) and population density (people per sq. mile circa 2010).  Densely populated coastal and lakeside areas along with the sparsely populated southwest have the highest sightings, whereas the less populous midwest and Alaska have lower percentages of sightings."", 110),
       caption = ""Data: NUFORC & 2010 US Census | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank()) +
  coord_sf(clip = ""off"")

# Making ze legend ---
bivariate_legend <- bivariate_color_scale %>% 
  separate(group, into = c(""sightings"", ""density""), sep = "" - "") %>%
  mutate_at(c(""sightings"", ""density""), as.integer)

legend <- ggplot(bivariate_legend) +
  geom_tile( aes(x = sightings, y = density, fill = fill)) +
  scale_fill_identity() +
  labs(x = expression(paste(""More Sightings "", symbol('\256'))),
       y = expression(paste(""More People "", symbol('\256')))) +
  theme_jk(grid = FALSE) +
  theme(axis.title = element_text(size = 6),
        axis.text = element_blank()) +
  coord_fixed(clip = ""off"")

finished_plot <- ggdraw() +
  draw_plot(plot, 0, 0, 1, 1) +
  draw_plot(legend, 0.75, 0.075, 0.2, 0.2)


ggsave(here(""2019"", ""week26"", ""tw26_plot.png""), plot = finished_plot, width = 10, height = 6)
","2019-26"
"232",93,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week28/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(glue)


squads <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")


data <- squads %>% 
  mutate(idx = goals/caps) %>% 
  filter(pos != ""GK"", caps > 0, goals > 0) %>% 
  mutate(pos = case_when(pos == ""DF"" ~ ""Defense"",
                         pos == ""FW"" ~ ""Forward"",
                         pos == ""MF"" ~ ""Mid-Field"")) %>% 
  mutate(desc = glue(""{club}\n{caps} Matches, {goals} Goals"")) %>% 
  mutate(pos = factor(pos, c(""Defense"", ""Mid-Field"", ""Forward"")))

means <- data %>% 
  group_by(pos) %>% 
  summarize(idx = mean(idx))

plot <- ggplot(data, aes(x = age, y = idx)) +
  geom_point(color = ""grey20"") +
  geom_mark_circle(aes(label = player, description = desc, filter = player == ""Khadija Shaw""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Lea Schller""), expand = unit(4, ""mm"")) +
  geom_mark_circle(aes(label = player, description = desc, filter = player  == ""Ainon Phancha""), expand = unit(4, ""mm"")) +
  geom_hline(data = means, aes(yintercept = idx), color = ""firebrick"") +
  theme_jk() +
  facet_wrap(~pos, nrow = 1) +
  labs(y = NULL,
       x = ""Age"",
       title = ""Efficient Scorers Competing in the Womens World Cup by Position and Age"",
       subtitle = str_wrap(""Goals per games played in international play by player age.  Red line illustrates the average goals per game at each position.  The highly efficient players at each position are a mix of newcomers and seasoned veterans, illustrating consistency in some players through their career."", 120),
       caption = ""Data: data.world | Graphic : @jakekaupp"")

ggsave(here(""2019"", ""week28"", ""tw28_plot.png""), plot = plot, width = 10, height = 6)

","2019-28"
"233",94,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week29/R/analysis.R","library(tidyverse)
library(tricolore)
library(ggtern)
library(here)
library(jkmisc)
library(magick)

r4ds_members <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")


tern_plot <- Tricolore(r4ds_members, ""percent_of_messages_public_channels"",
          ""percent_of_messages_private_channels"",
          ""percent_of_messages_d_ms"", breaks = 5, show_data = FALSE)

legend <- tern_plot$key +
  labs(title = ""Color Legend"",
       x       = ""Public\nChannels"",
       y       = ""Private\nChannels"",
       z       = ""Direct\nMessages"") +
  theme_hidetitles() +
  theme_hidelabels() +
  theme_hideticks() +
  theme(plot.title = element_text(hjust = 0.5, family = ""Scope One"", size = 40),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One""))

png(here(""2019"", ""week29"", ""legend.png"")) 
legend
dev.off()

legend <- image_read(here(""2019"", ""week29"", ""legend.png""))

plot <- r4ds_members %>% 
  mutate(color = tern_plot$rgb,
         year = lubridate::year(date)) %>% 
  ggtern(aes(x = percent_of_messages_public_channels, y = percent_of_messages_private_channels, z = percent_of_messages_d_ms, color = color)) +
  geom_point(size = 3) +
  scale_color_identity() +
  labs(title = str_to_title(""The Dialogue in the R4DS Slack indicates an Open and Inclusive Learning Community""),
       subtitle = str_wrap(""Below is a ternary digram presenting the message composition in public channels, private channels and direct messages as a percentage.  Each day is represented by a point with the composition represented by position relative to each axes.  Composition is additionally encoded by color as illustrated on the inset legend."", 100),
       x       = ""Public\nChannels"",
       xarrow  = ""More Public Channel Messages"",
       y       = ""Private\nChannels"",
       yarrow  = ""More Private Channel Messages"",
       z       = ""Direct\nMessages"",
       zarrow  = ""More Direct Messages"",
       caption = ""Data: R4DS Community | Graphic: @jakekaupp"") +
  theme(panel.background = element_rect(fill = ""#2E3440""),
        panel.grid = element_line(color = ""#ffffff"", size = 0.1),
        panel.grid.minor = element_blank(),
        text = element_text(family = ""Oswald""),
        plot.subtitle = element_text(family = ""Scope One""),
        axis.text = element_text(family = ""Scope One""),
        axis.title = element_text(family = ""Scope One"")) +
  theme_showarrows() +
  theme_arrowlong() 


png(here(""2019"", ""week29"", ""tw29_plot.png""), width = 10, height = 8, units = ""in"", res = 200)
grid::grid.newpage()
plot
grid::grid.raster(legend, width = 0.18, height = 0.2, x = 0.75, y = 0.7)
dev.off()
","2019-29"
"234",95,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week3/R/analysis.R","library(tidyverse)
library(here)
library(nord)
library(jkmisc)
library(ggbeeswarm)
library(ggrepel)

agencies <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/agencies.csv"")

launches <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-15/launches.csv"")


us_launch_data <- launches %>% 
  filter(agency == ""US"" | state_code == ""US"") %>% 
  mutate(type = gsub(""Zenit-"", ""Zenit "", type),
         type = gsub(""/"", "" "", type),
         type = gsub(""Minotaur-"", ""Minotaur "", type)) %>% 
  separate(type, ""type"", sep = "" "", extra = ""drop"") %>% 
  mutate(type = if_else(type == ""Space"", ""Space Shuttle"", sprintf(""%s Program"",type))) %>% 
  mutate(label = if_else(type == ""Space Shuttle"" & category == ""F"", ""Challenger Disaster"", NA_character_)) %>% 
  group_by(type) %>% 
  filter(n() > 10)

plot <- ggplot(us_launch_data, aes(x = launch_year, y = type), size = 4) +
  geom_quasirandom(data = filter(us_launch_data, category == ""O""), alpha = 0.2, fill = nord(""polarnight"", 2)[2], shape = 21, groupOnX = FALSE) +
  geom_quasirandom(data = filter(us_launch_data, category == ""F""), fill = nord(""victory_bonds"", 5)[1], shape = 21, groupOnX = FALSE, color = ""grey30"", stroke = 0.2) +
  theme_jk(grid = ""XY"", dark = FALSE) +
  labs(x = NULL,
       y = NULL,
       title = ""From the Space Race to Space-X: 1548 Successes and 101 Failures of US Launch Vehicles from 1958-2018."",
       subtitle = str_wrap(""A beeswarm plot illustrating the success or failure of a launch vehicle program over time. Red dots indicate failed launches, grey dots indicate success.  Deeper grey colors indicate a higher frequency of success in a given year due to multiple launches. Only includes programs with more than 10 launches"", 120),
       caption = ""Data: JSR Launch Vehicle Database | Analysis: @jakekaupp"")

plot <- plot + annotate(""segment"", x = 1987, xend = 1986.2, y = 8.7, yend = 8.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1986, y = 9, label = ""Challenger Disaster"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1]) +
  annotate(""segment"", x = 1959, xend = 1958.2, y = 1.7, yend = 1.2, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 1959, y = 2.5, label = ""First Communication\nSatellite Protoype"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0) +
  annotate(""segment"", x = 2015, xend = 2015, y = 5.5, yend = 3.1, arrow = arrow(length = unit(1, ""mm"")), color = nord(""victory_bonds"", 5)[1]) +
  annotate(""text"", x = 2013, y = 6.5, label = ""SpaceX Falcon 9\nStrut Failure"", family = ""Scope One"", color = nord(""victory_bonds"", 5)[1], hjust = 0)

ggsave(here(""2019"", ""week3"", ""tt_week3.png""), plot, width = 11, height = 5)

","2019-3"
"235",96,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week30/R/analysis.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  #mutate(airport_type = if_else(str_detect(airport, ""INTL""), ""INT"", ""DOM"")) %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  complete(incident_year = 1990:2018, state,  incident_month = 1:12, fill = list(n = 0)) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent))


state_flower_grid <- plot_data %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, 
       y = NULL) +
  coord_polar() +
  facet_geo(~ state, grid = ""us_state_grid2"") +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""))

flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_area(position = position_identity(), alpha = 0.5, size = 0.1) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Single colour petal represents a single collison event during this month"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  geom_mark_circle(aes(label = glue(""{month.name[incident_month]}""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm"")) +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_y_continuous(limits = c(0,1), breaks = c(0, 0.25, 0.5, 0.75, 1)) +
  scale_fill_viridis_c(""Year"", option = ""plasma"", direction = 1, breaks = c(seq(1990, 2020, by = 5))) +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  guides(fill = guide_colorbar(), color = ""none"") +
  labs(x = NULL, y = NULL) +
  coord_polar(clip = ""off"") +
  theme_jk(grid = ""XY"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())

finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.17, 0.4, 0.4)

out <- wrap_plots(finished_legend, state_flower_grid,  nrow = 1, widths = c(0.85, 1.2)) +
   plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                   subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft, with an inset legend showing assisting interpretation.  Wildlife collisions by state are presented as small multiples, geographically arranged.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                   caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                   theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot.png""), out, width = 16, height = 10, type = ""cairo"")


","2019-30"
"236",97,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week30/R/experiment.R","library(tidyverse)
library(here)
library(jkmisc)
library(ggforce)
library(geofacet)
library(patchwork)
library(glue)
library(cowplot)

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Petal charts ----
plot_data <- wildlife_impacts %>% 
  filter(state %in% state.abb) %>% 
  count(state,  incident_month, incident_year) %>% 
  group_by(incident_year, state) %>% 
  mutate(percent = n/sum(n)) %>% 
  mutate(percent = ifelse(is.nan(percent), 0, percent)) %>% 
  mutate(angle = 90 - (incident_month-1)*30,
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
         
         
big_flower <- ggplot(plot_data) +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.2, size = 0, color = ""white"") +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  theme_jk(grid = FALSE, plot_title_size = 12) +
  labs(x = NULL, y = NULL, title = ""National"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines""),
        plot.title = element_text(hjust = 0.5)) +
  coord_equal() 

state_flower <- big_flower +
  facet_geo(~ state, grid = ""us_state_grid2"")


flower_axes_lines <- tibble(idx = 1:12,
                            angle = 90 - (idx-1)*30,
                            angle2 = ifelse(angle < 0, 360 + angle, angle),
                            radians = angle2*pi/180)

axes_lines <- function(radius) {
  
  tibble(segment = 1:6,
                     x = c(0, radius*cos(pi/3), radius*cos(pi/6), radius, radius*cos(pi/6), radius*cos(pi/3)),
                     xend = c(0, -radius*cos(pi/3), -radius*cos(pi/6), -radius, -radius*cos(pi/6), -radius*cos(pi/3)),
                     y = c(radius, radius*sin(pi/3), radius*sin(pi/6), 0, -radius*sin(pi/6), -radius*sin(pi/3)),
                     yend = c(-radius, -radius*sin(pi/3), -radius*sin(pi/6), 0, radius*sin(pi/6), radius*sin(pi/3))) 
  }

axes_labels <- function(radius) {
  tibble(month = 1:12,
                      label = month.abb[month],
                      x = c(axes_lines(radius)$x, axes_lines(radius)$xend),
                      y = c(axes_lines(radius)$y, axes_lines(radius)$yend))  }


flower_legend <- plot_data %>% 
  filter(state == ""ME"") %>% 
  ggplot(aes(x = incident_month, y = percent, group = incident_year, color = incident_year, fill = incident_year)) +
  geom_segment(data = axes_lines(2), aes(x = x, xend = xend, y = y , yend = yend), size = 0.1, color = ""#cccccc"", inherit.aes = FALSE) +
  geom_circle(aes(x0 = 0, y0 = 0, r = 2), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_circle(aes(x0 = 0, y0 = 0, r = 1), inherit.aes = FALSE, size = 0.1, color = ""#cccccc"") +
  geom_ellipse(aes(x0 = x0, y0 = y0, a = percent, b = percent/3, angle = radians, fill = incident_year), alpha = 0.5, size = 0.1, color = ""white"") +
  geom_mark_circle(aes(x = 2*x0, y = 2*y0, label = glue(""{month.name[incident_month]}, {incident_year}""), description = ""Single colour long petal represents 100% of collison event during this month and year"", filter = incident_year == 1991 & incident_month == 3), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_mark_circle(aes(x = x0, y = y0, label = glue(""{month.name[incident_month]}, Multiple years""), description = ""Multiple coloured petals represent repeated annual incidents during this month"", filter = incident_year == 1996 & incident_month == 11), expand = unit(1, ""mm""), label.family = c(""Oswald"", ""Scope One""), label.fontsize = 10, label.buffer = unit(5, ""mm""), inherit.aes = FALSE) +
  geom_text(data = filter(axes_labels(2.15), label != ""Feb""), aes(x = x, y = y, label = label), inherit.aes = FALSE, family = ""Oswald"") +
  scale_color_viridis_c(option = ""plasma"", direction = 1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  coord_fixed(clip = ""off"") +
  theme(axis.text = element_blank(),
        legend.position = ""none"")

color_legend <- tibble(year = 1990:2018,
                       y = 1) %>% 
  ggplot() +
  geom_tile(aes(x = year, y = y, fill = year), show.legend = FALSE, color = ""white"", size = 0.1) +
  scale_fill_viridis_c(option = ""plasma"", direction = 1) +
  scale_x_continuous(breaks = c(1990, 2000, 2010, 2018)) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  labs(x = NULL, y = NULL) +
  theme(axis.text.y = element_blank())


finished_legend <- ggdraw() +
  draw_plot(flower_legend, 0, 0, 1, 1) +
  draw_plot(color_legend, 0.3, -0.175, 0.4, 0.4)

state_flower_grid <- ggdraw() +
  draw_plot(state_flower, 0, 0, 1, 1) + 
  draw_plot(big_flower, 0.75, 0.15, 0.25, 0.25)

out <- wrap_plots(finished_legend, state_flower_grid, nrow = 1, widths = c(0.85, 1.2)) +
  plot_annotation(title = ""Seasonality of Wildlife-Aircraft Collisions by State"",
                  subtitle = str_wrap(""Presented below is a petal chart of of wildlife collisions with aircraft across the US from 1990-2018. Below this is an inset legend showing assisting interpretation of the plots.  On the right are wildlife-aircraft collisions by state presented as small multiples, geographically arranged, with an inset flower representing the National data. Petal length is the annual proportion of collisions in a given month.  Smaller compact flowers illustrate states with collisions occuring year round, while the bigger flowers tend to see single or concentrated spikes of collision activity.  Flowers with diverse colours indicate repeated annual collisons while the single-hued flowers illustrate more sparse or isolated annual events."", 210),
                  caption = ""Data: FAA Wildlife Strike Database | Graphic: @jakekaupp"",
                  theme = theme_jk())


ggsave(here(""2019"",""week30"", ""tw30_plot_remix.png""), out, width = 16, height = 10, type = ""cairo"")
","2019-30"
"237",98,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week31/R/analysis.R","library(tidyverse)
library(here)
library(ggbeeswarm)
library(jkmisc)

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")  
 
all_games <- video_games %>% 
  filter(!is.na(game), !is.na(metascore))  %>% 
  mutate(developer = tolower(developer),
         idx = row_number())

plot_data <- tibble(facet = c(""bioware"", ""valve"", ""ubisoft"", ""rockstar"", ""square enix""),
       data = list(all_games)) %>% 
  mutate(filtered = map2(data, facet, ~mutate(.x, option = case_when(str_detect(tolower(developer), .y) ~ ""selected"", 
                                                                     TRUE ~ ""other"")))) %>% 
  unnest(filtered) %>% 
  mutate(facet = case_when(facet == ""bioware"" ~ ""BioWare"",
                           facet == ""valve"" ~ ""Valve"",
                           facet == ""ubisoft"" ~ ""Ubisoft"",
                           facet == ""rockstar"" ~ ""Rockstar"",
                           facet == ""square enix"" ~ ""Square Enix"")) %>% 
  mutate(option = factor(option, c(""other"", ""selected""))) %>% 
  arrange(facet, option)



mean <- all_games %>% 
  summarize(metascore = mean(metascore, na.rm = TRUE)) %>% 
  pull(metascore)

min_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == min(metascore))

max_labels <- plot_data %>% 
  filter(option == ""selected"", !is.na(metascore)) %>% 
  group_by(facet) %>% 
  filter(metascore == max(metascore)) %>% 
  mutate(game = if_else(str_detect(""FINAL FANTASY"", game), ""Final Fantasy IX"", game)) %>% 
  slice(1)

plot <- ggplot(plot_data) +
  geom_quasirandom(aes(y = metascore, x = 0, alpha = option, fill = option, size = option), shape = 21, method = ""tukey"", show.legend = FALSE) +
  geom_label(data = min_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = -2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_label(data = max_labels, aes(x = 0, y = metascore, label = game), family = ""Oswald"", nudge_y = +2, fill = ""#E5E4E2"", label.r = unit(0, ""lines""), alpha = 0.5) +
  geom_hline(yintercept = mean, color = ""firebrick"", size = 0.5, linetype = ""dashed"") +
  labs(x = NULL, 
       y = NULL,
       title = ""How Do The Big Developers Score Against The Competition on Steam?"",
       subtitle = str_wrap(""Presented below is a jittered strip plot of metascore by developer.  Titles worked on by that developer are highlighted in yellow, the average metascore (72) is shown as a dashed red line. Annotations show the top an bottom rated titles for each developer.  Sqaure and Ubisoft have the most titles with less than average reviews amongst the large developers."", 180),
       caption = ""Data: SteamSpy | Graphic: @jakekaupp"") +
  scale_size_manual(values = c(""other"" = 2, ""selected"" = 2)) +
  scale_y_continuous(limits = c(20, 100), breaks = seq(20, 100, 20)) +
  scale_fill_manual(values = c(""other"" = ""#E5E4E2"", ""selected"" = ""#ffd644"")) +
  scale_alpha_manual(values = c(""other"" = 0.05, ""selected"" = 1)) +
  theme_jk(grid = ""Y"", dark = TRUE) +
  facet_wrap(~facet, nrow = 1) +
  theme(strip.text = element_text(color = ""white""),
      axis.text.x = element_blank())

ggsave(here(""2019"", ""week31"", ""tw31_plot.png""), plot, width = 14, height = 8)
","2019-31"
"238",99,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week32/R/analysis.R","library(tidyverse)
library(ggforce)
library(here)
library(jkmisc)
library(patchwork)

bob_ross_paintings <- here(""2019"", ""week32"", ""data"", ""tidytuesday_201932_bob_ross_paintings.csv"")

data <- read_csv(bob_ross_paintings, col_names = c('episode', 'title', 'color', 'color_name')) %>% 
  mutate(season = parse_number(str_extract(episode, ""S\\d+"")),
         color = if_else(color == ""#FFFFFF"", ""grey80"", color))


plot_data <- data %>% 
  count(season, title, color_name, color) %>% 
  group_by(season, title) %>% 
  mutate(percent = n/sum(n)) %>% 
  ungroup() %>% 
  mutate(color_number = as.numeric(factor(color_name))) %>% 
  mutate(angle = (color_number-1)*(360/15),
         angle = ifelse(angle < 0, 360 + angle, angle),
         radians = angle*pi/180,
         x0 = percent * cos(radians),
         y0 = percent * sin(radians))
  

plot_spiros <- function(data) {
  
season <- sprintf(""Season %s"",unique(data$season))
  
ggplot(data) +
  geom_spiro(aes(R = ifelse(percent == 1, 0.1, 1 - percent), r = percent, d = radians, color = color, group = color), size = 0.1) +
  scale_color_identity() +
  theme_jk(grid = FALSE, plot_title_size = 8, strip_text_size = 8) +
  facet_wrap(~ title, ncol = 1, labeller = label_wrap_gen(15)) +
  labs(x = NULL, y = NULL, title = season) +
  theme(axis.text = element_blank(),
        legend.position = ""none"",
        panel.spacing = unit(0.1, ""lines"")) +
  coord_equal()  }


plots <- plot_data %>% 
  split(.$season) %>% 
  map(plot_spiros)


all_seasons <- wrap_plots(plots, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = ""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."",
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot.png""), plot = all_seasons, width = 30, height = 15, type = ""cairo"")

twitter <- map(plots, ~.x + theme(strip.text = element_blank()))


all_seasons_twitter <- wrap_plots(twitter, nrow = 1) + plot_annotation(title = ""Happy Accidents with 1960s Toys: Sprirographs of Palette Colors of Bob Ross Paintings for 31 Seaons"",
                                                             subtitle = str_wrap(""Illustrated below is a spirograph tracing of the 15 distinct un-mixed palette colours used in each of Bob Ross' paintings.  The more colours used in a painting, the larger the spirograph and it appears similar to china pattern while those paintings with a more minimalist palette show up as smaller sparse rings."", 265),
                                                             caption = ""Data: c/o @geokaramanis | Graphic: @jakekaupp"",
                                                             theme = theme_jk())


ggsave(filename = here(""2019"", ""week32"", ""tw32_plot_for_twitter.png""), plot = all_seasons_twitter, width = 20, height = 7)


","2019-32"
"239",100,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week33/R/analysis.R","library(tidyverse)
library(jkmisc)
library(lubridate)
library(here)
library(patchwork)


emperors <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"") 

ad_births <- c(""Augustus"", ""Tiberius"", ""Claudius"", ""Galba"")

emp_numeric_years <- emperors %>% 
  mutate_if(is.Date, list(year = year)) %>% 
  mutate(birth_year = if_else(name %in% ad_births, -birth_year, birth_year),
         reign_start_year = if_else(name == ""Augustus"", -reign_start_year, reign_start_year))


missing_birth_estimates <- emp_numeric_years %>% 
  filter(is.na(birth_year)) %>% 
  mutate(birth_year = case_when(name == ""Florian"" ~ 202,
                                name == ""Numerian"" ~ 248,
                                name == ""Carinus"" ~ 245,
                                name == ""Severus II"" ~ 260,
                                name == ""Vetranio"" ~ 325))


plot_data <- emp_numeric_years %>% 
  filter(!is.na(birth_year)) %>% 
  bind_rows(missing_birth_estimates)


dynasties <- plot_data %>% 
  group_by(dynasty) %>% 
  summarize(reign_start_year = min(reign_start_year),
               reign_end_year = max(reign_end_year))

roman_palette <- set_names(colorRampPalette(c(""#191970"", ""#FF7F50""))(8), unique(plot_data$dynasty))


overall <- ggplot(plot_data, aes(y = 0)) +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = 0, color = dynasty), size = 4) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, y = NULL,
       caption = ""Data: Wikipedia via @geokaramanis | Graphic: @jakekaupp"") +
  theme_jk(grid = ""X"") +
  theme(axis.text.y = element_blank(),
        legend.position = ""none"")

bars <- ggplot(plot_data, aes(y = reorder(name, reign_start_year))) +
  geom_segment(aes(x = birth_year, xend = death_year, yend = name), size = 2, color = ""grey90"") +
  geom_segment(aes(x = reign_start_year, xend = reign_end_year, yend = name, color = dynasty), size = 2) +
  geom_segment(data = filter(plot_data, reign_start_year == reign_end_year), aes(x = reign_start_year - 0.5, xend = reign_start_year + 0.5, y = name, yend = name, color = dynasty), size = 2) +
  geom_text(aes(x = death_year, label = name), hjust = 0, family = ""Scope One"", size = 2, nudge_x = 3) +
  scale_color_manual(""Dynasty"", values = roman_palette, breaks = names(roman_palette)) +
  scale_x_continuous(breaks = c(-62, 0, 100, 200, 300, 400), labels = c(""62 BC"", ""1 AD"", ""100 AD"", ""200 AD"", ""300 AD"", ""400 AD"")) +
  expand_limits(x = c(-62, 450)) +
  labs(x = NULL, 
       y = NULL,
       title = str_to_title(""When in Rome: The Game of Imperial Thrones. You Win or You Die.""),
       subtitle = str_wrap(""Illustrated below is a timeline of the life and reigns of Roman Emperors from 62 BC to 395 AD.  The light grey bar depicts the liftime of the emperor, the colored bar (by dynasty) indicates the duration of their reign. An overall timeline by dynasty is shown near the horizontal axis. Unsurprisingly, the majority of emperors reign ending also coincides with the end of their life."", 100)) +
  theme_jk(grid = ""X"") +
  theme(axis.text = element_blank(),
        legend.position = c(0.2, 0.7),
        legend.background = element_rect(fill = ""white"", size = 0))


out <- wrap_plots(bars, overall, ncol = 1, heights = c(0.9, 0.1))

ggsave(here(""2019"", ""week33"", ""tw33_plot.png""), out, width = 7.5, height = 8)
","2019-33"
"240",101,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week34/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggtext)
library(jkmisc)
library(waffle)
library(ggforce)
library(glue)
library(ragg)

nuclear_explosions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")




plot_data <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  group_by(country, date_long) %>% 
  summarize(n = n(),
            total_yield = sum(yield_upper, na.rm = TRUE)) %>% 
  group_by(country) %>% 
  mutate(c_sum = cumsum(n),
         c_yield = cumsum(total_yield)/1000) %>% 
  filter(country %in% c(""USSR"", ""USA""))

items <- nuclear_explosions %>% 
  mutate(date_long = ymd(date_long)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  group_by(country) %>% 
  top_n(1, yield_upper) %>% 
  slice(1) %>%
  semi_join(plot_data, .) %>% 
  mutate(date_long = ymd(date_long) - 1) %>% 
  mutate(name = if_else(country == ""USA"", ""March 1954: Castle Bravo"", ""October 1961: Tsar Bomba""),
         description  = if_else(country == ""USA"", ""2nd most powerful nuclear test explosion, 3 times over the predicted 5 MT yield."", ""Most powerful nuclear test explosion, twice the predicted yield of 25 MT.""))

explosions <- ggplot(plot_data, aes(x = c_sum, y = c_yield, color = country)) +
  geom_step(linetype = ""solid"", size = 1, direction = ""hv"") +
  geom_point(data = filter(plot_data, date_long %in% range(date_long))) +
  geom_text(data = filter(plot_data, date_long == last(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", hjust = -0.5) +
  geom_text(data = filter(plot_data, date_long == first(date_long)), aes(label = year(ymd(date_long))), family = ""Oswald"", nudge_y = c(10, -10)) +
  geom_mark_circle(data = items, aes(color = country, label = name, description = description), expand = unit(3, ""mm""), label.margin = margin(5, 5, 5, 5, ""mm""), con.colour = c(""#0052A5"", ""#FF2400""), label.family = c(""Oswald"",""Scope One""), label.fill = NA, label.minwidth = unit(50, ""mm""), label.fontsize = 10, con.type = ""straight"") +
  scale_color_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_fill_manual(values = c('USSR' = ""#FF2400"", ""USA"" = ""#0052A5"")) +
  scale_y_continuous(labels = function(x) scales::comma(x, suffix = "" MT"")) +
  labs(x = 'Cumulative Number of Explosions',
       y = ""Cumulative Yield (MT)"",
       title = ""Nuclear Weapons Research Race During And After The Cold War"",
       subtitle = ""Illustrated below is a step chart showing the number and yield of nuclear explosions for weapons research for <span style='color:#0052A5'>**USA**</span> and <span style='color:#FF2400'>**USSR**</span>.  During this race nearly<br>500 MT of nuclear explosions and accompanying fallout blanketed the world. The effects are still being dealt with to this date."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(plot.title = element_markdown(), 
        plot.subtitle = element_markdown(),
        legend.position = ""none"")
  
ggsave(here(""2019"", ""week34"", ""tw34_plot_2.png""), plot = explosions, width = 12, height = 6, device = agg_png())


# Waffle ----

waffle_data <- nuclear_explosions %>% 
  mutate(purpose = case_when(grepl(""WR"", purpose) ~ ""WR"",
                             grepl(""WE"", purpose) ~ ""WE"",
                             grepl(""PNE"", purpose) ~ ""PNE"",
                             TRUE ~ purpose)) %>% 
  filter(country %in% c(""USSR"", ""USA"")) %>% 
  count(year, purpose) %>% 
  group_by(purpose) %>% 
  mutate(c_sum = cumsum(n))


pal <- set_names(sample(grey.colors(50),10), unique(waffle_data$purpose))

pal[""WR""] <- ""#8A0303""

waffle <- ggplot(waffle_data, aes(fill = purpose, values = c_sum)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = TRUE, show.legend = FALSE) +
  facet_wrap(~year, strip.position = ""bottom"", nrow = 1) +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10,
                     expand = c(0,0)) +
  coord_equal() +
  scale_fill_manual(values = pal) +
  labs(y = ""Cumulative Number of Explosions"",
       title = ""Nuclear Weapons Research Testing During the Cold War Was the Primary Driver of Controlled  Nuclear Explosions"",
       subtitle = ""Illustrated below is a timeline of waffle charts showing the distribution of cumulative explosions from <span style='color:#8A0303'>**weapons research**</span> or <span style='color:#4D4D4D'>**other purposes**</span>. Widescale Nuclear testing ceased in the mid-'90's. The only active country<br>conducting nuclear testing in this era is North Korea, weathering the disapproval and ire of the global community."",
       caption = ""Data: Our World in Data | Graphic: @jakekaupp"") +
  theme_jk(strip_text_size = 10,
           subtitle_family = ""PT Serif"",
           caption_family = ""PT Serif"") +
  theme(panel.grid = element_blank(), 
        axis.ticks.y = element_line(),
        strip.text = element_text(hjust = 0.5),
        plot.title = element_markdown(), 
        plot.subtitle = element_markdown())
  
ggsave(here(""2019"", ""week34"", ""tw34_plot.png""), plot = waffle, width = 18, height = 6, device = agg_png())
","2019-34"
"241",102,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week35/R/analysis.R","library(tidyverse)
library(tidygraph)
library(ggraph)
library(colorspace)
library(glue)
library(jkmisc)
library(ggtext)
library(ragg)
library(here)


html_string <- glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'. {subtitle_names} are the most frequent guest stars in the series."")

str_break <- function (html_string, width = 80, indent = 0, exdent = 0) {

tags <- str_extract_all(html_string, ""<.*?>"") %>% 
  flatten_chr() 

index <- sprintf(""tag_%s"", seq_along(tags))

string <- str_replace_all(html_string, set_names(index, tags))

  if (width <= 0) 
    width <- 1
  
  out <- stringi::stri_wrap(string, width = width, indent = indent, 
                   exdent = exdent, simplify = FALSE)
  
  broken <- vapply(out, str_c, collapse = ""<br>"", character(1))
  
  str_replace_all(broken, set_names(tags, index))
  
}

text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


simpsons <- read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")

nodes <- count(simpsons, guest_star) 

top5 <- top_n(nodes, 5, n) %>% 
  arrange(desc(n)) %>% 
  rownames_to_column(var = ""color"") %>% 
  select(-n)

nodes <- nodes %>% 
  left_join(top5) %>% 
  replace_na(list(color = 7)) %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  mutate(alpha = if_else(color < 7, 1, 0.5)) 


edges <- simpsons %>% 
  mutate(guest_star = str_remove(guest_star, ""'"")) %>% 
  group_by(production_code) %>% 
  mutate(co_stars = map(guest_star, ~str_subset(guest_star, .x, negate = TRUE))) %>%
  ungroup() %>% 
  mutate(co_stars = map(co_stars, ~ifelse(length(.x) == 0, NA_character_,.x))) %>% 
  unnest(co_stars) %>% 
  count(guest_star, co_stars) %>% 
  filter(!is.na(n), !is.na(co_stars)) %>% 
  set_names(c(""from"", ""to"", ""n"")) %>% 
  left_join(top5, by = c(""from"" = ""guest_star"")) %>% 
  left_join(top5, by = c(""to"" = ""guest_star"")) %>% 
  mutate(color = coalesce(color.x, color.y)) %>% 
  replace_na(list(color = ""grey80"")) 

  
colors <- set_names(tol6qualitative, top5$guest_star)  

subtitle_names <- imap(colors[1:5], ~text_bc(.y, .x)) %>% 
  glue_collapse(sep = ', ') %>% 
  glue("" and {imap(colors[6], ~text_bc(.y, .x))}"")

co_star_graph <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE)

co_star_plot <- co_star_graph %>% 
  activate(nodes) %>% 
  arrange(n) %>% 
  mutate(degree = centrality_degree()) %>% 
  filter(degree > 1) %>%  
  ggraph(layout = ""fr"") + 
  geom_edge_arc(edge_width = 0.5, curvature = 0.2, aes(alpha = stat(index), edge_colour = color)) +
  geom_node_point(aes(size = n, color = color, alpha = alpha, fill = color), shape = 21) +
  scale_color_manual(values = c(darken(tol6qualitative), ""grey80"")) + 
  scale_alpha_identity() +
  scale_edge_color_manual(values = c(tol6qualitative, ""grey85"")) +
  scale_fill_manual(values = c(tol6qualitative, ""grey80"")) + 
  scale_size(range = c(2,6)) +
  labs(x = NULL,
       y = NULL,
       title = ""The Guest Star Backbone Of A Simpsons Co-Star Network"",
       subtitle = glue(""Shown below is a co-occurance network of guest stars in The Simpsons, best explained as a 'Who co-stars together?'.<br> {subtitle_names} <br>are the most frequent guest stars in the series.""),
       caption = ""**Data**: Wikipedia via @datawookie | **Graphic**: @jakekaupp"") +
  theme_jk(grid = FALSE,
           subtitle_family = ""Lora"",
           caption_family = ""Lora"",
           markdown = TRUE) +
  theme(legend.position = ""none"",
        axis.text = element_blank())

ggsave(here(""2019"", ""week35"", ""tw35_plot.png""), plot = co_star_plot, device = agg_png(), width = 9, height = 8)

ggplot(mtcars, aes(x = mpg, y = disp)) +
  geom_point() +
  labs(title = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't""),
       subtitle = paste0(highlight_text(""This is bold"", style = ""bi""), ""This isn't"")) +
  theme_jk() +
  theme(plot.title = ggtext::element_markdown(),
        plot.subtitle = ggtext::element_markdown())
","2019-35"
"242",103,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week36/R/analysis.R","library(tidyverse)
library(jkmisc)
library(nord)
library(glue)
library(here)
library(ragg)

cpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")

gpu <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")

ram <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")


plot_data <- list(cpu = cpu, gpu = gpu) %>% 
  imap_dfr(~select(.x, date_of_introduction, transistor_count, area, process) %>% 
             mutate(type = .y)) %>% 
  group_by(date_of_introduction, type) %>% 
  summarize_at(vars(transistor_count, area, process), mean, na.rm = TRUE) %>% 
  arrange(date_of_introduction, type)

strip_labels <- tibble(type = c(""cpu"", ""gpu""))

plot <- ggplot(plot_data, aes(x = area, y = transistor_count)) +
  geom_text(data = strip_labels, aes(label = toupper(type)), x = 400, y = 4, family = ""Oswald Bold"", size = 18, color = ""grey90"") +
  geom_smooth(method = ""auto"", formula = y ~ log10(x), se = FALSE, size = 0.5,  color = nth(nord_palettes$victory_bonds, 3)) +
  geom_hline(aes(yintercept = 10^10), linetype = ""dotted"", color = first(nord_palettes$victory_bonds)) +
  geom_point(aes(color = log10(process)), size = 3) +
  scale_color_nord(name = ""Process Size"",
                        discrete = FALSE,
                        palette = ""lumina"",
                        reverse = TRUE,
                        labels = function(x) glue(""{scales::comma(10^x)} nm""),
                        breaks = c(1, 2, 3, 4)) +
  scale_y_log10(breaks = c(1, 10^4, 10^6, 10^8, 10^10),
                labels = c(""1"", ""10K"", ""1M"", ""100M"", ""10B"")) +
  scale_x_continuous(labels = function(x) glue(""{x} {expression(mm^2)}"")) +
  facet_wrap(~type) +
  labs(x = NULL, 
       y = NULL,
       title = ""Moore's Law May Be Dead, Killed By The Tension Between Manufacturing and Transistor Density"",
       subtitle = ""*Moore's law*, the observation that the **number of transistors** on integrated circuits **doubles every two years**<br>
       hasn't held.  Transistor density is reaching a plateau, requiring manufacturing changes of an increase in available<br>
       chip size or a decrease in process size."",
       caption = ""**Data:** Wikipedia | **Graphic:** @jakekaupp"") +
  theme_jk(grid = ""XY"",
          markdown = TRUE) +
  theme(strip.text = element_blank())

ggsave(here(""2019"", ""week36"", ""tw36_plot.png""), plot = plot, device = agg_png(), width = 10, height = 6)
","2019-36"
"243",104,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week37/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(tidygraph)
library(ggraph)
library(ggforce)
library(janitor)
library(jkmisc)
library(glue)
library(ggtext)
library(colorspace)
library(ragg)

legacy_data <- here(""2019"", ""week37"", ""data"", ""Saferparks-dataset-legacy.csv"") %>% 
  read_csv() %>% 
  mutate(year = year(mdy(acc_date))) %>% 
  filter(between(year, 1999, 2007))

device_type <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .75),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .75),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .75))) %>% 
  select(name = device_type, size, color)

device_category <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ lighten(""#251351"", .25),
                           industry_sector == ""recreation"" ~ lighten(""#7d2e68"", .25),
                           industry_sector == ""water park"" ~ lighten(""#41658a"", .25))) %>% 
  select(name = device_category, size, color) 

sector <-  legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, name = ""size"") %>% 
  mutate(color = case_when(industry_sector == ""amusement ride"" ~ ""#251351"",
                           industry_sector == ""recreation"" ~ ""#7d2e68"",
                           industry_sector == ""water park"" ~""#41658a"")) %>% 
  select(name = industry_sector, size, color)

nodes <- bind_rows(sector, device_category, device_type)

edge_one <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(industry_sector, device_category) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edge_two <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>%
  select(device_category, device_type) %>% 
  mutate_all(~as.numeric(factor(., nodes$name))) %>% 
  set_names(c(""from"", ""to""))

edges <- bind_rows(edge_one, edge_two)

graph <- tbl_graph(nodes = nodes, edges = edges) 

labels <- legacy_data %>% 
  filter(industry_sector != ""unknown"") %>% 
  count(industry_sector, device_category, device_type, name = ""size"") %>% 
  group_by(industry_sector) %>% 
  top_n(1 , size) %>% 
  filter(size > 1) %>% 
  pull(device_type) 
 
text_bc <- function(text, color) {
  
  glue(""<span style = color:{color}>**{text}**</span>"")
  
}


plot <- ggraph(graph, 'circlepack', weight = size) + 
  geom_node_circle(aes(fill = color)) + 
  geom_node_text(aes(label = glue(""{str_remove(name, ' - undefined')}:\n{size}""), filter = name %in% labels, family = ""Oswald"")) +
  scale_fill_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Attractions With The Most Reported Injuries from 1999-2007"",
       caption = ""Data: **SaferParks** | Graphic: **@jakekaupp**"",
       subtitle = glue(""Shown below is a packed circle representation of reported accidents in the SaferParks database from 1999-2007.<br>Circles are organized by {highlight_text('Amusement rides', '#251351', 'b')}, {highlight_text('Recreation', '#7d2e68', 'b')} and {highlight_text('Water Park', '#41658a', 'b')}. Device category and device type are the<br>middle and lightest hues, respectively."")) +
  theme_jk(grid = FALSE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.subtitle = element_markdown(),
        plot.caption = element_markdown()) 


ggsave(here(""2019"", ""week37"", ""tw_37plot.png""), plot, width = 9, height = 10, dev = agg_png())


","2019-37"
"244",105,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week38/R/analysis.R","library(tidyverse)
library(rvest)
library(janitor)
library(here)
library(fuzzyjoin)
library(jkmisc)
library(ragg)

# Get park fees
fees_page <- ""https://www.nps.gov/aboutus/entrance-fee-prices.htm""

parks <- read_html(fees_page) %>% 
  html_nodes(""h3"") %>% 
  html_text() %>% 
  .[-1:-2]

park_fees <- read_html(fees_page) %>% 
  html_nodes("".table-wrapper > table"") %>% 
  html_table() %>% 
  map(~set_names(.x, c(""date"", ""park_specific_annual_pass"", ""per_vehicle"", ""per_person"", 
                       ""per_motorcycle""))) %>% 
  map2(parks, ~mutate(.x, park = .y)) %>% 
  bind_rows() %>% 
  filter(date == ""Current"") %>% 
  rename(park_name = park) %>% 
  mutate(park_name = stringi::stri_trans_general(park_name, id = ""Latin-ASCII""),
         park_name = str_replace(park_name, ""Hawai'i"", ""Hawaii""))



#udpated data
summary_report <- here(""2019"", ""week38"", ""data"", ""annual_summary_report.csv"") %>% 
  read_csv() %>% 
  clean_names()

plot_data <- summary_report %>% 
  filter(year == 2018) %>% 
  mutate(visitors = recreation_visitors + non_recreation_visitors) %>% 
  select(year, park_name, visitors) %>% 
  mutate(park_name = str_remove(park_name, ""[A-Z]{2,}""),
         park_name = str_remove(park_name, ""& PRES""),
         park_name = trimws(park_name)) %>% 
  regex_left_join(park_fees, ., ignore_case = TRUE) %>% 
  distinct(year, park_name.x, .keep_all = TRUE) %>% 
  filter(str_detect(park_name.x, ""Park""), !str_detect(park_name.x, ""Great Falls"")) %>% 
  mutate(revenue = visitors * parse_number(per_person)) %>% 
  rename(park_name = park_name.x) %>% 
  select(-park_name.y)
  

plot <- ggplot(plot_data, aes(x = fct_reorder(park_name, revenue), y = revenue)) +
  geom_col(fill = ""#5e81ac"", size = 0.1) +
  coord_flip() +
  scale_y_continuous(labels = scales::dollar, expand = c(0.01,0)) +
  labs(title = ""Estimated National Park Revenue from Fees for 2018"",
       subtitle = str_wrap(""Illustrated below is a bar chart of fee revenue from US National Parks in 2018.  Estimated Revenue calculated using per person admittance rates and total park visitors."", 95),
       caption = ""Data: www.nps.gov | Graphic: @jakekaupp"",
       x = NULL,
       y = NULL) +
  theme_jk(grid = ""X"") +
  theme(plot.background = element_rect(fill = ""#2e3440""),
        text = element_text(color = ""#eceff4""),
        panel.grid = element_line(color = ""#e5e9f0""),
        axis.text.x = element_text(color = ""#eceff4""),
        axis.text.y = element_text(color = ""#eceff4""))

ggsave(here(""2019"", ""week38"", ""tw_38plot.png""), plot, width = 10, height = 8, device = agg_png())

","2019-38"
"245",106,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week39/R/analysis.R","library(tidyverse)
library(janitor)
library(tidycensus)
library(glue)
library(here)
library(sf)
library(tigris)
library(jkmisc)
library(ggtext)

school_diversity <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv"")

## Getting the ACS Survey data ----
acs_var <- load_variables(2017, ""acs1"", cache = TRUE)

race_vars <- filter(acs_var, concept == ""RACE"") %>% 
  select(name, label) %>% 
  separate(label, c(""estimate"", ""total"", ""type""), sep = ""!!"") %>% 
  mutate(type = coalesce(type, total)) %>% 
  select(name, label = type)

if (!file.exists(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))) {
  
  acs_race <- map_df(state.abb, ~get_acs(geography = ""school district (unified)"", 
                                         variables = race_vars$name,
                                         state = .x))
  
  saveRDS(acs_race, here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
  
} else {
  
  acs_race <- readRDS(here(""2019"", ""week39"", ""data"", ""acs_race.RDS""))
}





# Recoding ACS and aggregating data, sadly not easy to determine Hispanic origin ----
# Following methodology from WaPo repo, recoding Native Hawaiian and Pacifici Islander into Asian.
diversity_data <- acs_race %>% 
  left_join(race_vars, by = c(""variable"" = ""name"")) %>% 
  mutate(label = case_when(label == ""White alone"" ~ ""White"",
                           label == ""Black or African American alone"" ~ ""Black"",
                           label == ""American Indian and Alaska Native alone"" ~ ""AIAN"",
                           label == ""Native Hawaiian and Other Pacific Islander alone"" ~ ""Asian"",
                           label == ""Asian alone"" ~ ""Asian"",
                           label == ""Two or more races"" ~ ""Multi"",
                           label == ""Some other race alone"" ~ ""Other"",
                           TRUE ~ label)) %>% 
  group_by(GEOID, NAME, label) %>% 
  summarize_at(vars(estimate), sum) 


# Using Simpson's Diversity Index instead of max race metrics for diversity----
totals <- diversity_data %>% 
  summarize(total = sum(estimate)*(sum(estimate)-1))

dvs_score <- diversity_data %>% 
  filter(label != ""Total"") %>% 
  mutate(es_minus = estimate-1) %>% 
  summarize(numerator = sum(estimate*es_minus)) %>% 
  left_join(totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID, NAME, diversity) 
  
acs_diversity <- diversity_data %>% 
  spread(label, estimate) %>% 
  select(-Total) %>% 
  left_join(dvs_score) %>% 
  rename(acs_diversity = diversity) %>% 
  ungroup() %>% 
  mutate(NAME = tolower(NAME),
         NAME = str_remove(NAME, ""\\(.+\\)""),
         NAME = str_replace_all(NAME, "";"", "","")) %>% 
  separate(NAME, c(""NAME"", ""state""), sep = "","") %>% 
  mutate(NAME = str_remove_all(NAME, ""school district*+"")) %>% 
  select(GEOID, acs_diversity)

# Use WaPo data and calculate Simpson's Diversity Index
upd_school <- school_diversity %>% 
  filter(SCHOOL_YEAR == ""2016-2017"") %>% 
  select(LEAID, LEA_NAME, ST, SCHOOL_YEAR, AIAN:Total) %>% 
  pivot_longer(AIAN:Multi, ""race"", ""value"") %>% 
  mutate(n = floor(Total * value))

school_totals <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  summarize(total = sum(n)*(sum(n)-1))
  
upd_school_dvs <- upd_school %>% 
  group_by(LEAID, LEA_NAME, ST, SCHOOL_YEAR) %>% 
  mutate(n_minus = n-1) %>% 
  summarize(numerator = sum(n*n_minus)) %>% 
  left_join(school_totals) %>% 
  mutate(diversity = 1 - numerator/total) %>% 
  select(GEOID = LEAID, NAME = LEA_NAME, ST, school_diversity = diversity) 

# Environment Cleanup---
remove(list = ls()[str_which(ls(), ""upd_school_dvs|acs_diversity"", negate = TRUE)])

# Comparing the two diversity measures and creating the ratio ----
overall_diversity <- upd_school_dvs %>% 
  left_join(acs_diversity, by = ""GEOID"") %>% 
  mutate(ratio = school_diversity/acs_diversity) %>% 
  filter(!is.na(acs_diversity))

# Get School District maps ----

if (!file.exists(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))) {
  
  district_maps <- map(state.abb, ~school_districts(.x, class = ""sf""))
  
  saveRDS(district_maps, here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
  
} else {
  
  district_maps <- readRDS(here(""2019"", ""week39"", ""data"", ""district_maps.RDS""))
}



# One do.call to keep them all, and in the shallows bind them----
maps <- do.call(sf:::rbind.sf, district_maps)

plot <- overall_diversity %>%
  right_join(maps, ., by = ""GEOID"") %>%
  filter(!ST %in% c(""HI"", ""AK"")) %>%
  ggplot() +
  geom_sf(aes(fill = ratio), color = 'white', size = 0.01) +
  scale_fill_viridis_c(""Alignment Ratio"", option = ""cividis"", limits = c(0, 1), labels = scales::percent, na.value = ""white"") +
  coord_sf(crs = 26915) +
  labs(title = ""Is Diversity In School Districts Reflected In The Diversity Of The General Population?"",
       subtitle = glue(""Shown below is a choropleth map illustrating the ratio between the Diversity Index of a School Population and the Diversity Index of the General Population in that School District in 2017.<br>
       The more {highlight_text('yellow', '#FFEA46', 'b')} an area, the greater alignment between diversity indices.  The more {highlight_text('blue', '#00204D', 'b')} an area, the greater the difference between the diversity of the school and the general populace.<br> 
       This analysis focused on unified school districts and available data on race from the ACS Survey.  Diversity was calculated using Simpson's Diversity Index.""),
       caption = ""Data: **Washington Post via @dataKateR & American Community Survey** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
          markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week39"", ""tw39_plot.png""), width = 16, height = 10, device = ragg::agg_png())
","2019-39"
"246",107,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week4/R/analysis.R","library(tidyverse)
library(readxl)
library(here)
library(janitor)
library(albersusa)
library(sf)
library(sp)
library(rgeos)
library(maptools)
library(ggthemes)
library(viridis)
library(scales)
library(glue)
library(jkmisc)



incar_data <- here(""2019"",""week4"",""data"") %>% 
  dir(full.names = TRUE, pattern = ""incarceration"") %>% 
  read_excel()

fix_null <- function(x) if_else(is.nan(x), NA_real_, x)

# Mapping things
us <- counties_composite()
us_map <- fortify(us, region=""fips"") %>% 
  mutate_at(""id"", as.numeric)

ratio_data <- incar_data %>% 
  group_by(year, fips, state, county_name) %>% 
  transmute(black_pop_ratio = black_pop_15to64/total_pop_15to64,
         black_prison_ratio = black_prison_pop/total_prison_pop,
         asian_pop_ratio = asian_pop_15to64/total_pop_15to64,
         asian_prison_ratio = asian_prison_pop/total_prison_pop,
         latino_pop_ratio = latino_pop_15to64/total_pop_15to64,
         latino_prison_ratio = latino_prison_pop/total_prison_pop,
         native_pop_ratio = native_pop_15to64/total_pop_15to64,
         native_prison_ratio = native_prison_pop/total_prison_pop,
         white_pop_ratio = white_pop_15to64/total_pop_15to64,
         white_prison_ratio = white_prison_pop/total_prison_pop) %>% 
  group_by(fips, state, county_name) %>% 
  summarize_at(vars(contains(""ratio"")), mean, na.rm = TRUE) %>% 
  mutate_at(vars(contains(""ratio"")), fix_null)


map_data <- left_join(us_map, ratio_data, by = c(""id"" = ""fips""))  %>% 
  ungroup() %>% 
  gather(""variable"",""percentage"", contains(""ratio"")) %>% 
  separate(variable, c(""ethnicity"", ""category""), sep = ""_"")

plot <- ggplot() +
  geom_map(data = us_map, map = us_map,
           aes(x = long, y = lat, map_id = id),
           color =""#2b2b2b"", size = 0.05, fill = NA) +
  geom_map(data = map_data, map = us_map,
           aes(x = long, y = lat, map_id = id, fill = percentage),
           color =""#2b2b2b"", size = 0.05) + 
  scale_fill_viridis_c("""", na.value = ""white"", option = 'cividis', labels = scales::percent) +
  coord_map() +
  labs(title = ""Differences between the General and Prison Population by County and Ethnic Group from 1970 to 2016"",
       subtitle = str_wrap(""Non-white and non-Asian ethnic groups in the South-Eastern United States have a higher average representation in prison than in the overall population.  Missing data indicated by no fill color."",  90),
       caption = ""Data: Vera Institute of Justice | Graphic: @jakekaupp"") +
  facet_grid(category ~ ethnicity , labeller = labeller(category = c(""pop"" = ""Total\nPopulation"", ""prison"" = ""Prison\nPopulation""),
                                                       ethnicity = str_to_title)) +
  theme_map(base_family = ""Scope One"", 
            base_size = 16) +
  theme(plot.caption = element_text(size = 10),
        plot.title = element_text(family = ""Oswald""),
        legend.background = element_rect(fill = NA),
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        legend.position = ""bottom"",
        legend.justification = ""center"",
        legend.direction = ""horizontal"",
        legend.key.height = unit(0.2, ""cm""),
        legend.key.width = unit(1, ""cm""),
        strip.background = element_blank(),
        strip.text.y = element_text(angle = 0))

ggsave(here(""2019"",""week4"",""tw4_choro.png""), width = 11, height = 5)

","2019-4"
"247",108,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week40/R/analysis.R","library(tidyverse)
library(sf)
library(tigris)
library(glue)
library(colorspace)
library(jkmisc)
library(ggforce)
library(ragg)
library(here)

# Get TidyTuesday data
pizza_datafiniti <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_datafiniti.csv"") %>% 
  filter(province == ""NY"") %>% 
  distinct(name, latitude, longitude)

pizza_barstool <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_barstool.csv"") %>% 
  distinct(name, latitude, longitude) %>% 
  filter(!is.na(latitude))

# Get all New York County road maps
counties <- c(""New York County"", ""Kings County"", ""Bronx County"", ""Richmond County"",  ""Queens County"")

roads_data <- map(counties, ~roads(""NY"", .x, class = ""sf"")) %>% 
  do.call(sf:::rbind.sf, .)

# Build plot colors as a named vector and as a tibble
plotcolors <- c('Other' = '#cccccc',
                'Ave' = '#59c8e5',
                'St' = '#fed032',
                'Tunl' = '#fed032',
                'Brg' = '#fed032',
                'N' = '#fed032',
                'S' = '#fed032',
                'E' = '#fed032',
                'W' = '#fed032',
                'Rd' = '#4cb580',
                'Dr' = '#0a7abf', 
                'Hwy' = '#ff9223', 
                'Plz' = '#ff9223',
                'Viaduct' = '#ff9223', 
                'Expy' = '#ff9223', 
                'Pkwy' = '#ff9223',
                'Thruway' = '#ff9223',
                'State Hwy' = '#ff9223',
                'State' = '#ff9223',
                'US Hwy' = '#ff9223',
                'Blvd'= '#2e968c')

pc_tibble <- tibble(street_type = names(plotcolors),
                    color = plotcolors)

# Assign street types to roads
roads <- roads_data %>% 
  filter(!is.na(RTTYP)) %>% 
  mutate(street_type = map_chr(FULLNAME, ~first(names(plotcolors)[str_which(.x, glue(""{names(plotcolors)}\\b""))]))) %>% 
  mutate(street_type = if_else(str_detect(FULLNAME, ""I-""), 'I-', street_type)) %>% 
  mutate(street_type = case_when(is.na(street_type) & MTFCC == ""S1100"" ~ 'Expy',
                                 is.na(street_type) & MTFCC == ""S1200"" ~ 'St',
                                 is.na(street_type) & !MTFCC %in% c(""S1100"", ""S1200"") ~ ""Other"",
                                 TRUE ~ street_type)) %>% 
  left_join(pc_tibble, by = ""street_type"")

# Get Counties shapefiles to determine which pizza places are in the areas I want
counties_sf <- counties(""NY"", class = ""sf"") %>% 
  filter(NAMELSAD %in% counties)

# Use st_intersects and filter to remove out of bounds pizza places
pizza_sf_df <- st_as_sf(pizza_datafiniti, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
pizza_sf_bs <- st_as_sf(pizza_barstool, coords = c(""longitude"", ""latitude""), crs = st_crs(roads)) 
  
  
# Filter to pizza places in the five boroughs
ny_pizza_df <-  filter(pizza_sf_df, map_lgl(st_intersects(pizza_sf_df, counties_sf), ~!is_empty(.x)))

ny_pizza_bs <-  filter(pizza_sf_bs, map_lgl(st_intersects(pizza_sf_bs, counties_sf), ~!is_empty(.x)))

ny_pizza <- sf:::rbind.sf(ny_pizza_bs, ny_pizza_df) %>% 
  distinct(geometry)

# Construct the color legend
legend <- pc_tibble %>% 
  filter(street_type %in% c(""Other"",""Ave"",""St"", ""Rd"", ""Dr"", ""Hwy"", ""Blvd"")) %>% 
  mutate(street_type = factor(street_type, levels = c(""Other"", ""Ave"", ""Dr"", ""Rd"", ""Blvd"", ""St"", ""Hwy""), labels = c(""Other"", ""Avenue"", ""Drive"", ""Road"", ""Boulevard "", ""Street"", ""Highway""))) %>%
  arrange(street_type) %>% 
  mutate(x0 = seq(3, by = 4.5, length.out = 7),
         r = 1.75,
         y0 = 0) %>% 
  ggplot(aes(x0 = x0, y0 = y0, r = r)) +
  geom_circle(aes(fill = color, color = darken(color))) +
  geom_text(aes(label = street_type, x = x0, y = 0), family = ""Lora"", size = 3) +
  annotate(""text"", family = ""Oswald"", x = -2, y = 0, label = ""Legend"", size = 6) +
  scale_fill_identity() +
  scale_color_identity() +
  expand_limits(y = c(-0.5, 4),
                x = c(-4, 24)) +
  labs(x = NULL,
       y = NULL) +
  coord_equal(clip = ""off"") +
  theme_jk(grid = FALSE, plot_title_size = 30) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 

legend_grob <- ggplotGrob(legend)

subtitle <- ""Shown on this map are the roads and the pizza places of the Five Boroughs of New York City.  
Pizza places are distinct locations almagamated from the DataFiniti and Barstool datasets, and a represented by purple dots.  Manhattan is the most represented borough in the dataset, unsurprising given the relative population, and it being the home of the Teenage Mutant Ninja Turtles.
The map style of plotting the colored roads were inspired by Erin Davis (erdavis1 on github), and her series of circular maps of World Cities.""

caption <- ""Data: DataFiniti, Barstool, US Census Shapefiles\nGraphic: @jakekaupp""


# Plot the Street maps and Pizza place data
pizza_map <- ggplot() +
  geom_sf(data = filter(roads, street_type != ""Other""), aes(color = color), size = 0.25) + 
  geom_sf(data = filter(roads, street_type == ""Other""), aes(color = color), size = 0.35) + 
  geom_sf(data = ny_pizza, color = darken(""#963484""), fill = ""#963484"", shape = 21, size = 2, alpha = 0.5) +
  annotate(""text"", label = ""Pizza Places of the Five Boroughs"", family = ""Oswald"", x = -74.3, y = 40.91, size = 6, hjust = 0) +
  annotate(""text"", family = ""Lato"", label = str_wrap(subtitle, 60), x = -74.3, y = 40.89, hjust = 0, vjust = 1) +
  annotate(""text"", family = ""Lato"", label = caption, x = -74.3, y = 40.78, hjust = 0, vjust = 1) +
  annotation_custom(legend_grob, xmin = -74.2, xmax = Inf, ymin = 40.49, ymax = 40.55) +
  scale_color_identity() +
  scale_size_identity() +
  coord_sf(clip = ""off"") +
  labs(x = NULL, y = NULL) +
  theme_jk(grid = FALSE) +
  theme(panel.grid.major = element_line(colour = ""transparent""),
        axis.text.x = element_blank(),
        axis.text.y = element_blank()) 


ggsave(here('2019', 'week40', 'tw40_plot.png'), width = 12, height = 9, dev = agg_png())","2019-40"
"248",109,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week41/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(janitor)
library(jkmisc)
library(ggforce)
library(ggtext)
library(nord)
library(glue)
library(ragg)

# It's 250mb, can't put it into git, you're going to have to go get it
# from https://openpowerlifting.org/data and stick it in data.
pl_data <- here(""2019"", ""week41"", ""data"") %>% 
  dir(pattern = ""openpowerlifting"", full.names = TRUE) %>% 
  read_csv() %>% 
  clean_names()

plot_data <- pl_data %>%
  filter_at(vars(starts_with(""best"")), all_vars(. > 0)) %>% 
  filter(str_detect(place, ""1"")) %>% 
  mutate(year = year(date)) %>%
  select(-date) %>%
  mutate_at(vars(starts_with(""best"")), ~./bodyweight_kg) %>% 
  pivot_longer(starts_with(""best""), names_to = ""lift"") %>% 
  group_by(year, sex, lift) %>%
  filter(value == max(value, na.rm = TRUE)) %>% 
  arrange(lift, sex, year)

labels <- tibble(label = c(""Bench Press"", ""Deadlift"", ""Squat""),
                 lift = c(""best3bench_kg"", ""best3deadlift_kg"", ""best3squat_kg""),
                 year = 2020,
                 value = 1)

annotations <- plot_data %>% 
  group_by(sex, lift) %>% 
  filter(value == max(value, na.rm = TRUE)) %>% 
  mutate(description = glue(""Weight: {bodyweight_kg} kg\nLifted: {bodyweight_kg*value} kg\n{federation}: {meet_name}""),
         name = str_remove(name, ""\\#[0-9]""))

plot <- ggplot(plot_data, aes(x = year, y = value)) +
  geom_path(aes(color = sex)) +
  geom_point(aes(fill = sex), shape = 21, color = ""#2E3440"") +
  geom_text(data = labels, aes(label = label), color = ""#E5E9F0"", family = ""Oswald"", fontface = ""bold"", size = 10, hjust = 1) +
  geom_mark_circle(data = filter(annotations, sex == ""M""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  geom_mark_circle(data = filter(annotations, sex == ""F""), aes(color = sex, label = name, description = description), expand = unit(2, ""mm""), label.family = c(""Oswald"", ""Lato""), label.fill = ""#4C566A"", label.colour = ""#E5E9F0"", con.colour = ""#D8DEE9"", label.margin = margin(2, 3, 2, 3, ""mm"")) +
  facet_wrap(~lift) +
  scale_color_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_fill_manual(values = set_names(c(""#314cb6"",""#DD2A7B""), c(""M"",""F""))) +
  scale_x_continuous(breaks = seq(1970, 2020, 10)) +
  theme_jk(dark = TRUE, 
           grid = ""XY"",
           markdown = TRUE) +
  labs(x = NULL,
       y = NULL,
       title = ""Evolution of Power: How the Ratio of Bodyweight to Lifted Weight Has Progressed"",
       subtitle = glue(""Illustrated below is the maximum of the ratio of bodyweight to lifted weight for winning lifts in each year and event for both {highlight_text('Men', '#314cb6', 'b')} and {highlight_text('Women', '#DD2A7B', 'b')} for all meets recorded by Open Powerlifting.""),
       caption = ""Data: **openpowerlifting.org** | Graphic: **@jakekaupp**"") +
  theme(legend.position = ""none"",
        panel.grid.major = element_line(size = 0.01),
        strip.text = element_blank())

ggsave(here('2019', 'week41', 'tw41_plot.png'), plot, width = 15, height = 8, device = agg_png())","2019-41"
"249",110,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week42/R/analysis.R","library(tidyverse)
library(here)
library(janitor)
library(jkmisc)
library(ggalt)
library(ggtext)
library(glue)
library(ragg)

big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")

top <- big_epa_cars %>% 
  clean_names() %>% 
  count(make, year) %>% 
  count(make) %>% 
  filter(n == 37)

plot_data <- big_epa_cars %>% 
  clean_names() %>% 
  select(make, v_class, year, you_save_spend) %>% 
  semi_join(top) %>% 
  group_by(year, make) %>% 
  summarize(total_save_spend = mean(you_save_spend)) %>%
  group_by(year) %>% 
  mutate(rank = min_rank(desc(total_save_spend))) %>% 
  ungroup() %>% 
  mutate(size = if_else(make == ""Ford"", 1, 0.5),
         make = factor(make, pull(top, make)),
         make = fct_relevel(make, ""Ford"", after = Inf),
         make = fct_recode(make, ""**Ford**"" = ""Ford""))


grid <- tibble(rank = 1:22)

colors <- set_names(grey.colors(22), pull(top, make) %>%
                      factor() %>%
                      fct_recode(""**Ford**"" = ""Ford""))

colors[[""**Ford**""]] <- ""#DD2A7B""


plot <- ggplot(plot_data, aes(x = year, y = rank)) +
  geom_segment(data = grid, aes(x = 1983, xend = 2021, y = rank, yend = rank), color = ""#cccccc"", alpha = 0.5, size = 0.1) +
  geom_xspline(aes(color = make, size = size), show.legend = FALSE) +
  geom_point(aes(fill = make), shape = 21, color = ""white"", show.legend = FALSE) +
  geom_richtext(data = filter(plot_data, year == 2020), aes(label = as.character(make), x = 2021, color = make), hjust = 0, family = ""Lora"", size = 4, show.legend = FALSE,  fill = NA, label.color = NA, 
                label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_text(data = filter(plot_data, year == 1984), aes(label = rank, x = 1983), hjust = 1, family = ""Oswald"", size = 4) +
  labs(x = NULL,
       y = NULL,
       title = ""From Chugging to Sipping: Fuel Cost Savings of Major Automakers since 1984"",
       subtitle = glue(""Shown below is a rankings chart of average fuel cost savings, measured over 5 years, from 1984 to 2020.  {highlight_text('Ford','#DD2A7B', 'b')} has had quite the journey, battling from the bottom<br>of the list to the second-best North American manufacturer."")) +
  scale_color_manual(values = colors) +
  scale_fill_manual(values = colors) +
  scale_size_identity() +
  scale_x_continuous(breaks = 1984:2020) +
  scale_y_continuous(trans = ""reverse"", breaks = NULL) +
  expand_limits(x = 2025) +
  theme_jk(grid = ""X"", 
           markdown = TRUE)

ggsave(here(""2019"", ""week42"", ""tw42_plot.png""), plot = plot, width = 13, height = 6)
","2019-42"
"250",111,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week43/R/analysis.R","library(tidyverse)
library(lubridate)
library(here)
library(ggraph)
library(tidygraph)
library(glue)
library(jkmisc)
library(colorspace)
library(ggforce)
library(ggtext)

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

movie_cast <- distinct(horror_movies, title, release_date, review_rating, .keep_all = TRUE) %>% 
  mutate(year = str_extract(title, ""\\((\\d{4})\\)""),
         year = parse_number(year),
         title = str_remove(title, ""(\\s\\(\\d{4}\\))""),
         date = dmy(release_date)) %>% 
  arrange(title) %>% 
  separate_rows(cast, sep = ""\\|"") %>% 
  mutate(cast = trimws(cast)) %>% 
  select(title, year, review_rating, cast)

cast_df <- left_join(movie_cast, movie_cast, by = c(""title"", ""year"", ""review_rating"")) %>% 
  rename(from = cast.x,
         to = cast.y) %>% 
  filter(from != to) 

nodes <- cast_df %>% 
  group_by(from) %>% 
  summarize(node_size = n_distinct(title)) %>% 
  distinct(from, .keep_all = TRUE) 

focus <- ""Eric Roberts""

edges <- cast_df %>% 
  count(from, to, sort = TRUE, name = ""edge_size"") %>% 
  distinct(from, to, .keep_all = TRUE) %>% 
  mutate(color = if_else(from == focus | to == focus, ""#bb0a1e"", ""#373e40""),
         alpha = if_else(from == focus | to == focus, 1, 0.2),
         size = if_else(from == focus | to == focus, 1, 0.1))

connected <- filter(edges, from == focus) %>% 
  distinct() %>% 
  pull(to) 

cast_network <- tbl_graph(nodes = nodes, edges = edges, directed = FALSE) %>% 
  activate(nodes) %>% 
  mutate(degree = centrality_eigen(),
         alpha = if_else(from %in% c(focus, connected),  1, 0.2)) %>% 
  top_n(500, degree) %>% 
  mutate(fill = if_else(from %in% c(focus, connected), ""#bb0a1e"", ""#373e40""),
         color = if_else(from %in% c(focus, connected), darken(""#bb0a1e""), darken(""#373e40"")))

plot <- ggraph(cast_network, layout = ""graphopt"") + 
  geom_edge_link(aes(alpha = stat(index), edge_colour = color, edge_width = size), show.legend = FALSE) + 
  geom_node_point(aes(size = node_size, fill = fill, color = color), shape = 21, show.legend = FALSE) +
  #geom_mark_circle(aes(x, y, filter = from == focus, label = from, description = ""Legendary B-Movie Actor""), expand = unit(0, ""mm""), label.family = c(""Oswald"", ""Lora"")) +
  scale_edge_color_identity() +
  scale_alpha_identity() +
  scale_fill_identity() +
  scale_edge_width_identity() +
  scale_color_identity() +
  labs(x = NULL,
       y = NULL,
       title = ""Horror Movie Co-Star Networks of the Top 500 Prolific Performers"",
       subtitle = glue(""The reach of B-movie legend {highlight_text('Eric Roberts', '#bb0a1e', 'b')} is featured below across his 27 films. Prolific performers determined by the top 500<br>actors by eigenvalue centrality.""),
       caption = ""Data: **IMDB** | Graphic: **@jakekaupp**"") +
  theme_jk(grid = FALSE,
           markdown = TRUE) +
  theme(axis.text = element_blank())

ggsave(here(""2019"", ""week43"", ""tw43_plot.png""), plot, width = 10, height = 6, device = ragg::agg_png())

  
","2019-43"
"251",112,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week44/R/analysis.R","library(tidyverse)
library(waffle)
library(lubridate)
library(jkmisc)
library(scales)
library(colorspace)
library(patchwork)
library(ggtext)
library(glue)
library(here)

#Get the data ----
nyc_squirrels <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

# Process the data ----
activity_data <- nyc_squirrels %>% 
  mutate(date = mdy(date)) %>% 
  pivot_longer(names_to = ""activity"", running:foraging) %>%
  group_by(date, activity) %>% 
  summarize(value = sum(as.numeric(value))) %>% 
  mutate(activity = factor(activity, labels = unique(activity)),
         activity = fct_reorder(activity, value, .fun = sum)) %>% 
  arrange(date, desc(activity))

# Make my palette

slate_ramp <- colorRampPalette(c(""#3B454A"", lighten(""#3B454A"", 0.8)))(5) 

grey_ramp <- grey.colors(5, 0.5, 0.9)

pal <- set_names(slate_ramp, unique(activity_data$activity))

pal[""foraging""] <- ""#DD2A7B""

partition_waffle <- function(x, start, nrows, flip = FALSE) {
  
   offset <- start - x
  
   offset_rows <- offset %/% nrows
   
   offset_blocks <- offset %% nrows
   
  
   comp_blocks <- nrows - offset_blocks
   
   if (comp_blocks != nrows) {
     
     rows <- (x - comp_blocks) %/% nrows
     
     blocks <- (x - comp_blocks) %% nrows
     
     start_row <- offset_rows + rows + 1
     
     if (blocks == 0) {
       
       end_row <- start_row
       
     } else {
       
       end_row <- start_row + 1 
       
     }
     
   } else {
     
     rows <- x %/% nrows
     
     blocks <- x %% nrows
     
     start_row <- rows + offset_rows
     
     end_row <- rows + offset_rows + 1
     
   }
   
   
   if (flip) {
     
     tibble(y = c(start_row, start_row, end_row),
            yend = c(start_row, end_row, end_row),
            x = c(blocks, blocks, 0),
            xend = c(nrows, blocks, blocks))
     
     
   } else {
     
     tibble(x = c(start_row, start_row, end_row),
            xend = c(start_row, end_row, end_row),
            y = c(blocks, blocks, 0 -1),
            yend = c(nrows + 1, blocks, blocks))
   }
     
     

   
  
} 

# Waffles by activity ----

activity_outlines <- activity_data %>% 
  ungroup() %>% 
  arrange(desc(activity), date) %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, flip = FALSE, nrows = 20)) %>% 
  unnest(lines) %>% 
  filter(date == last(date))

activity_labels <- activity_data %>% 
  group_by(activity) %>% 
  summarize(total = sum(value)) %>%
  left_join(filter(activity_outlines, yend == 21), by = ""activity"")

waffle_by_activity <- activity_data %>% 
  arrange(desc(activity), date) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = activity_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""black"", size = 0.5) +
  geom_richtext(data = activity_labels, aes(label = glue(""<b>{str_to_title(activity)}</b>""), x = x, y = yend, color = activity), fill = ""white"", hjust = 1, vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = activity_labels, aes(label = glue(""{total}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_color_manual(values = pal) +
  coord_equal() +
  labs(x = NULL, 
       y = NULL) +
  theme_jk(grid = FALSE) +
  scale_x_continuous(expand = c(0,0)) +
  expand_limits(y = c(-5, 25), x = c(0, 200)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffles by day ----

by_day_outlines <- activity_data %>% 
  ungroup() %>% 
  mutate(cum_sum = cumsum(value)) %>% 
  mutate(lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE)) %>% 
  unnest(lines) %>% 
  filter(activity == ""chasing"")

by_day_labels <- activity_data %>% 
  group_by(date) %>% 
  summarize(total = sum(value)) %>% 
  left_join(filter(by_day_outlines, yend == 21))

waffle_by_day <- activity_data %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = by_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{month.abb[month(date)]} {day(date)}""), x = x, y = yend), fill = ""white"", color = ""black"", hjust = c(rep(1,10), 0), vjust = 0, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  geom_richtext(data = by_day_labels, aes(label = glue(""{total}""), x = x, y = -1), fill = ""white"", color = ""black"", hjust = c(rep(0,9),1,0), vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  scale_x_continuous(expand = c(0,0)) +
  coord_equal(clip = ""off"") +
  labs(x = NULL, 
       y = NULL) +
  expand_limits(y = c(-5, 25), x = c(0, 205)) +
  theme_jk(grid = FALSE) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        strip.text = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

# Waffle bars by day ----

waffle_day_outlines  <- activity_data %>% 
  arrange(desc(date)) %>% 
  filter(activity == ""foraging"") %>% 
  ungroup() %>%
  group_split(date) %>% 
  map(~mutate(.x, cum_sum = cumsum(value))) %>%
  map_dfr(~mutate(.x, lines = map2(value, cum_sum, partition_waffle, nrows = 20, flip = FALSE))) %>%
  unnest(lines) 

waffle_labels <- waffle_day_outlines %>% 
  filter(y == -1)

mday_label <- function(x) {
  
  glue(""{month.abb[month(x)]} {day(x)}"")
  
}

split_waffle_by_day <- activity_data %>% 
  arrange(desc(date)) %>% 
  ggplot(aes(fill = activity, values = value)) +
  geom_waffle(color = ""white"", size = 0.25, n_rows = 20, flip = FALSE, show.legend = FALSE) +
  geom_segment(data = waffle_day_outlines, aes(x = x, xend = xend, y = y, yend = yend), color = ""grey20"", size = 0.5) +
  geom_richtext(data = waffle_labels, aes(label = glue(""{value}""), x = x + 1, y = -1), fill = ""white"", color = ""black"", hjust = 0, vjust = 1, family = ""Oswald"", show.legend = FALSE, label.color = NA, label.padding = grid::unit(rep(0, 4), ""pt"")) +
  scale_fill_manual(values = pal) +
  coord_equal() +
  scale_color_manual(values = pal) +
  labs(x = NULL,
       y = NULL) +
  theme_jk(grid = FALSE) +
  facet_wrap(~date, nrow = 1, as.table = FALSE, strip.position = ""top"", labeller = labeller(date = mday_label)) +
  expand_limits(y = c(-5, 20)) +
  theme(axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.spacing.y = unit(0.1, ""lines""),
        panel.spacing.x = unit(0.1, ""lines"")) 

out <- wrap_plots(waffle_by_activity, waffle_by_day, split_waffle_by_day, ncol = 1) +
  plot_annotation(title = ""Breakdown of Observed Squirrel Activity from the 2018 NYC Squirrel Census"",
                  subtitle = glue(""Below are  waffle charts of activity totals (I), daily totals (II) and exploded daily activity (III) views of observed squirrel activity.<br>{highlight_text('Foraging', '#DD2A7B', 'b')} is the most frequently observed activity recorded in the census, not surprising for squirrels in the fall.""),
                  caption = ""Data: **NYC Data Portal** | Graphic: **@jakekaupp**"",
                  tag_levels = ""I"",
                  theme = theme_jk(markdown = TRUE))

ggsave(here(""2019"", ""week44"", ""tw44_plot.png""), out, width = 11, height = 8, dev = ragg::agg_png(), dpi = ""print"")

","2019-44"
"252",113,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week45/R/analysis.R","library(tidyverse)
library(jkmisc)
library(glue)

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

total_avg <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  mutate(state = ""US"",
         state_abb = ""US"")

slope_data <- commute_mode %>% 
  group_by(city, mode) %>% 
  filter(n() > 1) %>% 
  group_by(state, state_abb, mode) %>% 
  summarize(avg = mean(percent/100)) %>% 
  ungroup() %>% 
  mutate(state_abb = ifelse(is.na(state_abb), ""DC"", state_abb))

direct_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(-3:-6)

direct_labels_bike <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  top_n(5, avg)

mid_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  top_n(8, avg) %>% 
  arrange(-avg) %>% 
  slice(3:6) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
    avg = mean(.$avg),
    y = min(.$avg),
    yend = max(.$avg))
  
lower_labels <- slope_data %>% 
  filter(mode == ""Walk"") %>% 
  arrange(-avg) %>% 
  slice(9:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))

lower_bike_labels <- slope_data %>% 
  filter(mode == ""Bike"") %>% 
  arrange(-avg) %>% 
  slice(6:nrow(.)) %>% 
  group_by(mode) %>% 
  summarize(state_abb = toString(state_abb),
            avg = mean(avg),
            y = min(.$avg),
            yend = max(.$avg))


ggplot(slope_data, aes(x = mode, y = avg)) +
  geom_line(aes(group = state), size = 0.2) +
  geom_line(data = total_avg, aes(group = state), color = ""#DD2A7B"", size = 1) +
  geom_point(shape = 21, color = ""white"", stroke = 0.2, fill = ""black"", size = 2) +
  geom_text(data = direct_labels, aes(label = state_abb),  nudge_x = 0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = direct_labels_bike, aes(label = state_abb),  nudge_x = -0.05, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = mid_labels, aes(label = state_abb),  nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = 0.1, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_text(data = lower_bike_labels, aes(label = str_wrap(state_abb, 30)), nudge_x = -0.5, family = ""Lora"", size = 3, hjust = 0, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.06, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.01, xend = 2.06, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = mid_labels, aes(x = 2.06, xend = 2.09, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.95, y = y, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = y, yend = y), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.98, xend = 0.95, y = yend, yend = yend), size = 0.2, color = ""grey50"") +
  geom_segment(data = lower_bike_labels, aes(x = 0.95, xend = 0.91, y = avg, yend = avg), size = 0.2, color = ""grey50"") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL,
       y = NULL,
       title = ""Bicycling and Walking to Work in the United States: 2008-2012"",
       subtitle = glue(""Illustrated below is a slopegraph contrasting the percentage of population that bikes to work and the percentage<br>that bikes to work as well as {highlight_text('the US average', '#DD2A7B', 'b')}"")) +
  scale_x_discrete(labels = c(""Bike to Work"", ""Walk to Work"")) +
  theme_jk(grid = ""XY"",
           markdown = TRUE) +
  theme(panel.grid.major = element_line(linetype = ""dashed""))
  
","2019-45"
"253",114,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week5/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(here)
library(scales)

milk_cow_data <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milkcow_facts.csv"")

milk_product_facts <- read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-01-29/milk_products_facts.csv"")

us_pop <- read_csv(here(""2019"", ""week5"", ""data"",""us-population-1990-to-2016.csv""))

totals <- milk_product_facts %>% 
  mutate(total_consumption = rowSums(select(., -year))) %>% 
  select(year, total_consumption)

full_data <- left_join(milk_cow_data, totals) %>% 
  left_join(us_pop) %>% 
  mutate(total_consumption_lbs = total_consumption * population)


ggplot(full_data, aes(y = total_consumption_lbs, x = milk_production_lbs)) +
  geom_xspline2(aes(s_open = TRUE, s_shape = 0.5)) +
  geom_point(shape = 21, fill = ""black"", color = ""white"", stroke = 1) +
  scale_y_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  scale_x_continuous(labels = scales::unit_format(unit = ""B"", scale = 10e-10, sep = """"), breaks = pretty_breaks(6)) +
  labs(x = ""US Milk Production (lbs)"",
       y = ""US Average Dairy Consumption (lbs)"",
       title = ""100 Slices of American Cheese or, the Fable of Supply Management"",
       subtitle = str_wrap(""The connected scatterplot below illustrates the relationship between total average dairy consumption and total milk production over the past 25 years.
                           US supply far exceeds the demand, highlighting overproduction and a case for supply management."", 120)) +  
  theme_jk()
","2019-5"
"254",115,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week6/R/analysis.R","library(tidyverse)
library(ggalt)
library(jkmisc)
library(lubridate)
library(here)
library(scales)
library(janitor)
library(ggrepel)
library(patchwork)

state_hpi <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")

prime_rates <- read_csv(here(""2019"",""week6"",""data"",""MPRIME.csv"")) %>% 
  clean_names() %>% 
  mutate(year = year(date)) %>% 
  select(-date) %>% 
  group_by(year) %>% 
  summarize_all(mean) %>% 
  filter(year %in% min(state_hpi$year):max(state_hpi$year))

highs <- filter(prime_rates, mprime %in% range(mprime)) %>% 
  distinct(mprime, .keep_all = TRUE)

plot_data <- state_hpi %>% 
  group_by(year, state) %>% 
  summarize_all(mean, na.rm = TRUE) 

prime <- ggplot(prime_rates, aes(x = year, y = mprime)) +
  geom_line(color = viridis_pal()(1), size = 0.5) +
  geom_point(data = highs, color = viridis_pal()(1)) +
  geom_text_repel(data = highs, aes(label = paste0(mprime, ""%"")), color = viridis_pal()(1), nudge_x = 2, nudge_y = 2, family = ""Oswald"", segment.size = 0) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  theme_jk(grid = ""XY"") +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Interest Rates Fall, Housing Prices on the Rise"",
       subtitle = str_wrap(""The top chart shows the average prime interest rate by year since 1975.  The bottom heatmap illustrates the yearly average housing price index by State since 1975."", 100))


heatmap <- ggplot(plot_data, aes(x = year, y = fct_reorder(state, price_index, .fun = mean), fill = price_index)) +
  geom_tile(color = ""white"", size = 0.05) +
  scale_x_continuous(breaks = c(1975, seq(1980, 2010, 10), 2018)) +
  scale_fill_viridis_c(""House Price Index"", option = ""viridis"", direction = 1, breaks = pretty_breaks(5)) +
  scale_color_identity() +
  labs(x = NULL, y = NULL, caption = ""Data: FRED | Graphic: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"",
        legend.key.width = unit(1, ""cm""))


out <- patchwork::wrap_plots(prime, heatmap, heights = c(0.2,1), ncol = 1)

ggsave(here(""2019"", ""week6"", ""tw6_plot.png""), out, width = 8, height = 10)
","2019-6"
"255",116,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week7/R/analysis.R","library(tidyverse)
library(here)
library(readxl)
library(janitor)
library(jkmisc)
library(nord)

oecd_data <- here(""2019"", ""week7"", ""data"", ""OECD--1.xlsx"") %>% 
  read_excel(skip = 1, na = c(""na"")) %>% 
  clean_names() %>% 
  filter(!is.na(x1995)) %>% 
  rename(country = x1) %>% 
  gather(year, intensity, -country) %>% 
  arrange(country, year) %>% 
  fill(intensity, .direction =  ""down"") %>% 
  mutate(year = parse_number(year)) %>% 
  group_by(year) %>% 
  arrange(year, intensity) %>% 
  mutate(rank = row_number(-intensity)) %>% 
  ungroup() %>% 
  mutate(color = if_else(country == ""Canada"", nord(""victory_bonds"")[2], nord(""snowstorm"", 1)),
         text_color = if_else(country == ""Canada"", nord(""snowstorm"", 1), ""black""))




plot <- ggplot(oecd_data, aes(x = year, y = -rank, group = country)) +
  geom_line(aes(color = color)) +
  geom_point(aes(color = color)) +
  geom_text(data = filter(oecd_data, year == min(year)), aes(label = rank, color = color), x = 1994, hjust = 0, family = ""Oswald"") +
  geom_text(data = filter(oecd_data, year == max(year)), aes(label = country, color = color), x = 2016.5, hjust = 0, family = ""Oswald"") +
  expand_limits(x = c(1994, 2019)) +
  scale_x_continuous(breaks = 1995:2016) +
  scale_color_identity() +
  theme_jk(dark = TRUE, grid = FALSE) +
  theme(axis.text.y = element_blank()) +
  labs(x = NULL, 
       y = NULL,
       title = ""Canada is Losing a Step In the Global Research Race."",
       subtitle = str_wrap(""Shown below is the ranking of research intensity (% of Gross Domestic Product devoted to Research) from 1995-2016. Canada has been on a decline since hitting a peak in 2001.  Most notably is 2009-2016, which coincides with the systematic defunding of Canadian research scientists by the Conservative Harper Government."", 120),
       caption = ""Data: OECD | Graphic: @jakekaupp"")

ggsave(here(""2019"", ""week7"", ""tw7_plot.png""), plot, width = 9, height = 4.5)
","2019-7"
"256",117,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week8/R/analysis.R","library(tidyverse)
library(here)
library(fs)
library(readxl)
library(janitor)
library(jkmisc)
library(scales)
library(egg)

parse_table31 <- function(file) {
  
  df <- file %>% 
    read_excel(na = ""na"") %>% 
    clean_names()
  
  start <- min(str_which(df$x3,""\\d{4}""))
  
  end <- pull(df, 1) %>% 
    str_which(""Since"") %>% 
    max()
  
  df <- slice(df, start:end)
  
  field_idx <- select(df, -1) %>% 
    map_df(is.na) %>% 
    pmap_lgl(all)
  
  labels <- select(df, 1) %>%
    filter(field_idx) %>% 
    na.omit() %>% 
    pull() %>% 
    str_remove(""[abcd]$"")
  
  years <- slice(df, 1) %>% 
    select(-1) %>% 
    flatten_chr() %>% 
    str_remove(""\\.0+$"")
  
 rep <- filter(df, !field_idx) %>% 
    slice(-1) %>% 
    select(1) %>% 
    n_distinct()
  
  filter(df, !field_idx) %>% 
    slice(-1) %>% 
    mutate(discipline = rep(labels, each = rep)) %>% 
    set_names(c(""category"", years, ""discipline"")) %>% 
    gather(year, value, matches(""[0-9]{4}"")) %>% 
    mutate_at(vars(-category, -discipline), as.numeric) %>% 
    mutate_at(""category"", function(x) str_remove(x, ""[abcd]$""))
  
  
}


files <- here(""2019"",""week8"",""data"") %>% 
  dir_ls() 

data <- map_df(files, parse_table31) %>% 
  ungroup() %>% 
  distinct()

plot_data <- data %>% 
  filter(discipline != ""Other"", !str_detect(category, ""doctoral"")) %>% 
  filter(!str_detect(discipline, ""and (?!computer)"")) %>% 
  filter(!str_detect(discipline, ""Physical"")) %>% 
  arrange(year) %>% 
  group_by(category, discipline, year) %>% 
  summarize(value = mean(value, na.rm = TRUE)) %>% 
  ungroup()

plot <- ggplot(plot_data, aes(x = year, y = value, color = discipline)) +
  geom_point() +
  geom_line() +
  scale_y_continuous(breaks = pretty_breaks(), limits = c(0, 25)) +
  scale_color_manual(""Discipline"", values = tol7qualitative) +
  scale_x_continuous(limits = c(1985, 2017)) +
  expand_limits(x = c(1985, 2025)) +
  facet_wrap(~category, labeller = as_labeller(str_to_title), nrow = 1) +
  labs(x = NULL,
       y = NULL,
       title = ""Median Completion Time for Doctoral Degrees Are Getting Shorter"",
       subtitle = str_wrap(""Median completion time in years from 1985 to 2017 contrasting selected disciplines for both University and Graduate School experience.  Education, Humanities and Social Sciences doctoral candidates have a higher than average time to completion in both categories compared to other disciplines. "", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

ggsave(here('2019','week8',""tw8_plot.png""), plot, width = 10, height = 7)


bonus_plot_data <- plot_data %>% 
  filter(discipline == ""All fields"") %>% 
  rename(overall = value) %>% 
  select(-discipline) %>% 
  left_join(filter(plot_data, discipline != ""All fields"")) %>% 
  mutate(diff = abs(value - overall)/2) %>%
  filter(between(year, 1990, 2011))


order <- c(""Education"", ""Mathematics and computer sciences"",  ""Engineering"", ""Humanities"",""Life sciences"", 
   ""Social sciences"")

bonus_plot <- ggplot(bonus_plot_data, aes(ymin = -diff, ymax = diff, x = year, fill = fct_relevel(discipline, order))) +
  geom_ribbon(color = ""white"", size = 0.2, alpha = 0.8) +
  geom_segment(data = filter(bonus_plot_data, year == 2000, category == ""Since bachelor's"", discipline == ""Education""), aes(y = -diff, yend = diff, x = year, xend = year), color = ""grey20"", arrow = arrow(length = unit(0.25, ""cm""), ends = ""both"", type = ""closed"")) +
  facet_wrap(~category, labeller = as_labeller(str_to_title)) +
  scale_fill_viridis_d(""Discipline"") +
  scale_y_continuous(breaks = c(-5, -2.5, -1, 0, 1, 2.5, 5), labels = c(""10 Years"", ""5 Years"", ""2 Years"", ""Group Median"", ""2 Years"", ""5 Years"", ""10 Years"")) +
  labs(x = NULL,
       y = NULL,
       title = ""Relative Differences in Median Doctoral Completion Time from the Group Median by Discipline and Interval"",
       subtitle = str_wrap(""The streamgraph below presents the difference between discipline median completion time and the group median completion time (All Fields) as the width of each colored band (discipline) from 1990 to 2011."", 120),
       caption = ""Data: NSF | Analysis: @jakekaupp"") +
  theme_jk(grid = ""XY"") +
  theme(legend.position = ""bottom"")

bonus_plot <- tag_facet(bonus_plot, x = 1996, y = 5.5, open = """", close = """", tag_pool = c(""Difference from Group Median = 9.1 years"", """"),  fontface = 1, family = ""Oswald"") 



ggsave(here('2019','week8',""tw8_bonus_plot.png""), bonus_plot, width = 12, height = 6)
","2019-8"
"257",118,"https://github.com/jkaupp/tidyweek","jkaupp","tidyweek","2019/week9/R/analysis.R","library(tidyverse)
library(here)
library(ggforce)
library(jkmisc)
library(sf)
library(osmdata)

full_trains <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

available_tags(""railway"")

railways <- st_read(here(""2019"", ""week9"", ""data"", ""railways.shp""))

q <- getbb(""fr"") %>%
  opq(timeout=25*1000)%>%
  add_osm_feature(""railway"")

stations <- osmdata_sf(q)

ggplot(stations$osm_lines) +
  geom_sf()

railways$geometry[[1]] %>% st_coordinates() %>% as_tibble -> line

ggplot(line, aes(x = X, y = Y)) +
  geom_link2() +
  coord_sf(datum=NA)

nat_trains <- full_trains %>% 
  filter(service == ""National"") %>% 
  group_by(year, departure_station, arrival_station) %>% 
  summarize_at(vars(journey_time_avg, total_num_trips, avg_delay_late_at_departure, avg_delay_late_on_arrival), mean, na.rm = TRUE)


# Orbit test

centre <- ""PARIS LYON""

test_data <- filter(nat_trains, departure_station == centre | arrival_station == centre) %>% 
  arrange(departure_station)



positions <- test_data %>% 
  filter(arrival_station == centre) %>% 
  group_by(arrival_station, departure_station) %>% 
  summarize(dist = mean(journey_time_avg)) 


circles <- test_data %>% 
  group_by(departure_station) %>% 
  summarize(centre_radius = mean(avg_delay_late_at_departure)) %>% 
  left_join(positions)

main <- circles %>% 
  filter(departure_station == centre)

circles <- circles %>% 
  filter(departure_station != centre) %>% 
  mutate(fraction = nrow(.) - (nrow(.) - seq_along(departure_station)),
         delta = 360/nrow(.)*fraction) %>% 
  bind_rows(main) %>% 
  mutate(x0 = if_else(departure_station == centre, 0, dist*cos((delta*pi/180))),
         y0 = if_else(departure_station == centre, 0, dist*sin((delta*pi/180)))) 


link_coords <- function(dept, arr, lnk) {
  
  circles %>% 
    filter(departure_station == dept | departure_station == arr) %>%
    summarise(x = ifelse(lnk == ""from"", x0[x0 != 0], 0),
           xend = ifelse(lnk == ""from"", 0, x0[x0 != 0]),
           y = ifelse(lnk == ""from"", y0[y0 != 0], 0),
           yend = ifelse(lnk == ""from"", 0, y0[y0 != 0]))
  
  
  
}

links <- test_data %>% 
  group_by(departure_station, arrival_station) %>% 
  mutate(total_delay = ((avg_delay_late_at_departure + avg_delay_late_on_arrival)/journey_time_avg),
         total_trips = sum(total_num_trips)) %>% 
  summarize(size = mean(total_delay),
            alpha = mean(total_num_trips)/max(total_num_trips)) %>% 
  mutate(link = if_else(departure_station == centre, ""to"", ""from"")) %>% 
  ungroup() %>% 
  mutate(links = pmap(list(departure_station, arrival_station, link), ~link_coords(..1, ..2, ..3))) %>% 
  unnest() %>% 
  arrange(link, departure_station)




ggplot() +
  geom_curve(data = links, aes(x = x, xend = xend, y = y, yend = yend, size = size, color = link, alpha = alpha), lineend = ""round"", angle = 270) +
  geom_circle(data = circles, aes(x0 = x0, y0 = y0, group = departure_station, r = 5), fill = ""white"", color = ""#2b41a7"") +
  scale_size(range = c(1,6)) +
  scale_color_manual(values = c(""#2b41a7"", ""#c7ad24"")) +
  scale_fill_distiller(palette = ""Greys"")+
  scale_alpha_identity() +
  labs(x = NULL, y = NULL) +
  coord_equal() +
  theme_jk(grid = FALSE) +
  theme(axis.text = element_blank())

","2019-9"
"258",969,"https://github.com/deepshamenghani/tidytuesday/tree/master/tt_07_29_2019_week31_videogames","deepshamenghani","tidytuesday","tt_07_29_2019_week31_videogames/video_games.R","library(tidyverse)
library(lubridate)
library(plotly)
library(ggrepel)
library(cowplot)
library(ggforce)

vg_df <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

# Clean dates
vg_edited <- vg_df %>% 
    mutate(release_date = as.Date(release_date, format = '%b %d, %Y')) %>%
    mutate(release_year  = as_factor(year(release_date))) %>% 
    drop_na(release_year) %>% 
    mutate(label_text = str_glue(""Game: {game}
                                 Year: {release_year}
                                 Price: {price}""))

# Create text for annotations by playtime
annotations_playtime <- vg_edited %>% 
    arrange(desc(median_playtime)) %>% 
    filter(row_number() < 5) %>% 
    mutate(log_price = log(price)) %>% 
    mutate(game_label = str_glue(""{game}\n{release_year}\n{scales::dollar(price)}"")) %>% # Create label text for plot
    select(game_label, median_playtime, log_price) %>% 
    mutate(y = c(median_playtime[1] + 400, median_playtime[2] - 200, median_playtime[3] + 150, median_playtime[4] - 400),  # Define annotations location
           x = c(log_price[1], log_price[2] + 0.85, log_price[3] - 0.85, log_price[4])) %>% 
    mutate(y_arrow = c(median_playtime[1] + 200, median_playtime[2] + 50, median_playtime[3] - 50, median_playtime[4] - 200)) # Define arrow location

# Create text for annotations by price
annotations_price <- vg_edited %>% 
    arrange(desc((price))) %>% 
    filter(row_number() < 3) %>% 
    mutate(log_price = log(price)) %>% 
    mutate(game_label = str_glue(""{game}\n{release_year}\n{scales::dollar(price)}"")) %>%
    select(game_label, median_playtime, log_price) %>% 
    mutate(y = c(median_playtime[1] + 550, median_playtime[2] + 450), # Define annotations location
           x = c(log_price[1] - 0.2, log_price[2] - 0.75)) %>% 
    mutate(y_arrow = c(median_playtime[1] + 300, median_playtime[2] + 200))  # Define arrow location
    

# Plot with annotations and arrows
pc_games_plot <- ggplot(data = vg_edited, 
                        aes(x = log(price), 
                            y = median_playtime)) +
    geom_point(aes(color = median_playtime, 
                   size  = median_playtime), 
                   alpha = 0.8) +
    scale_color_gradient(low  = ""blue2"", 
                         high = ""darkgreen"") +
    annotate(""text"", 
             x        = annotations_playtime$x, 
             y        = annotations_playtime$y, 
             fontface = ""bold"", 
             label    = annotations_playtime$game_label, 
             size     = 5, 
             color    = ""darkgreen"") + 
    geom_curve(data      = annotations_playtime, 
               aes(x     = log_price, 
                   y     = median_playtime, 
                   xend  = x, 
                   yend  = y_arrow),
               arrow     = arrow(length = unit(0.07, ""inch"")), 
               size      = 1,
               color     = ""gray20"", 
               curvature = -0.25)+
    annotate(""text"", 
             x        = annotations_price$x, 
             y        = annotations_price$y, 
             fontface = ""bold"", 
             label    = annotations_price$game_label, 
             size     = 5, color = ""blue2"") + 
    geom_curve(data      = annotations_price, 
               aes(x     = log_price, 
                   y     = median_playtime, 
                   xend  = x, 
                   yend  = y_arrow),
               arrow     = arrow(length = unit(0.07, ""inch"")), 
               size      = 1,
               color     = ""gray20"", 
               curvature = -0.25) + 
    geom_mark_circle(data       = annotations_price, 
                     aes(x      =log_price[1] ,
                         y      =median_playtime[1]), 
                     color      ='blue2', 
                     label.fill = NA, 
                     expand     = unit(3, ""mm"")) + 
    geom_mark_circle(data       = annotations_price, 
                     aes(x      =log_price[2] ,
                         y      =median_playtime[2]), 
                     color      ='blue2', 
                     label.fill = NA, 
                     expand     = unit(3, ""mm"")) +
    labs(
        x     = ""price (logarithmic scale)"",
        y     = ""Median playtime"",
        title = ""Playtime vs Price""
    ) +
    theme_minimal() +
    scale_y_continuous(breaks = seq(from = 0, to = 4000, by = 500))  +
    scale_x_continuous(breaks = seq(from = -1, to = 7, by = 1)) +
    theme(
        axis.title.x     = element_text(size = 20),
        axis.title.y     = element_text(size = 20, vjust = 1.5),
        axis.text.x      = element_text(size = 15),
        axis.text.y      = element_text(size = 15),
        plot.title       = element_text(size = 25),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()
    ) 

ggsave(""PC_Games.png"", plot = pc_games_plot, width = 60, height =25, units = ""cm"")
","2019-31"
"259",1080,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week21/plastic_waste.R","AmandaRP","tidytuesday","2019/week21/plastic_waste.R","library(tidyverse)
library(janitor)
library(inspectdf)
library(cowplot)
library(ggrepel)


#Read data and clean with janitor:
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>% clean_names()
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")  %>% clean_names()
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")  %>% clean_names()

#Put data together in one df:
waste <- left_join(waste_vs_gdp, coast_vs_waste, by = c(""entity"", ""code"", ""year""))
(waste <- left_join(waste, mismanaged_vs_gdp, by = c(""entity"", ""code"", ""year"")))

View(waste)

#Clean names a bit more
(waste <- waste %>%
  select(-total_population_gapminder.y, -total_population_gapminder.x, -gdp_per_capita_ppp_constant_2011_international_rate) %>%
  rename(mismng_pl_waste_tons = mismanaged_plastic_waste_tonnes,
        mismng_pl_waste_per_cap = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day,
        plastic_waste_per_cap = per_capita_plastic_waste_kilograms_per_person_per_day,
        coast_pop = coastal_population,
        gdp_per_cap = gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
        population = total_population_gapminder))
View(waste)


#Look for correlations using the inspectdf package:
inspect_cor(waste, show_plot = TRUE) 
inspect_na(waste, show_plot = TRUE) #Looks like we only have 2010 waste data

#Plots:
data4plot <- waste %>% filter(year == 2010) %>% filter(entity != ""World"")
plt1 <- ggplot(data4plot, aes(x = log(gdp_per_cap), 
             y = log(plastic_waste_per_cap), 
             size = mismng_pl_waste_tons)) +
  geom_smooth(method = ""lm"") +
  geom_point(color = ""#333333"", alpha = 0.7) +
  geom_text_repel(aes(label = entity),
    color         = ""red"",
    size          = 4,
    data          = subset(data4plot, log(plastic_waste_per_cap) > 0 | log(plastic_waste_per_cap) < -4.5 | (log(gdp_per_cap) < 7 & log(plastic_waste_per_cap) < -4) | code %in% c(""USA"",""CHN"")),
    nudge_y       = .8,
    segment.size  = 0.2,
    segment.color = ""grey50"",
    direction     = ""x""
  ) +
  labs(title = ""Richer nations tend to produce more plastic waste"",
       x = ""GDP Per Capita (log scale)"",
       y = ""Per Capita Plastic Waste in kg/day (log scale)"",
       size = ""Mismanagement of \nPlastic Waste (tons)"")  +
  theme(legend.position = ""none"") 


#Richer nations manage their plastic waste better
plt2 <- ggplot(data4plot, aes(x = log(gdp_per_cap), 
             y = mismng_pl_waste_per_cap, 
             size = mismng_pl_waste_tons)) +
  geom_smooth(show.legend = FALSE) + 
  geom_point(color = ""#333333"", alpha = 0.7) + 
  geom_text_repel(aes(label = entity), 
    color         = ""red"",
    size          = 4,
    data          = subset(data4plot, mismng_pl_waste_per_cap > .14 | code %in% c(""USA"",""CHN"")),
    nudge_y       = .025,
    nudge_x       = .1,
    segment.size  = 0.2,
    segment.color = ""grey50"",
    direction     = ""x""
  ) + 
  ylim(0, NA) +
  labs(title = ""Many countries having mid-range GDP are\nbad at management of their plastic waste "",
       x = ""GDP Per Capita (log scale)"",
       y = ""Per Capita Mismanaged Plastic Waste in kg/day"",
       size = ""Mismanaged\nPlastic Waste (tons)"") 

#Get the legend from plot 2 so that I can put it in its own plot grid panel:
l <- get_legend(plt2) 

#Final plot
plot_grid(plt1, 
          plt2 + theme(legend.position = ""none""), 
          l,
          nrow = 1)

","2019-21"
"260",1081,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week24/meteorites.R","AmandaRP","tidytuesday","2019/week24/meteorites.R","library(tidyverse)
library(ggdark)
library(gganimate)

#read data:
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

#Get rid of outliers:
meteorites %<>% filter(long<180 & year <= 2013)

#map:
mapWorld <- borders(""world"", colour=""gray50"", fill=""gray50"") # create a layer of borders

ggplot(meteorites) +   
  mapWorld + 
  geom_point(aes(x=long, y=lat) ,color=""green"", size=1, alpha = .1) +
  dark_mode() +
  theme(panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_blank()) + 
  labs(caption = ""Data from the Meteoritical Society (and shared by NASA)"") +
  labs(title = ""Meteorite Crashes on Earth"") 
    
      
# Experimentation with animation:  
#transition_states(year,
#                    transition_length = 2,
#                    state_length = 1) +
#    ggtitle(""Meteorites"", subtitle = ""Year:  {frame_time}"") 
  

#Time series plot:
meteorites %>% 
  filter(year > 1950 & year < 2013) %>%
  group_by(year) %>% 
  count() %>% 
  arrange(desc(n)) %>%
  ggplot(aes(year, n)) +
  geom_line(color = ""green"") + 
  dark_mode() + 
  labs(title = ""Meteorites by Year (1950 - 2012)"",
       x = ""Year"",
       y = ""Count"") +
  geom_curve(aes(x = 1979 + 5, y = 3000, xend = 1979.5, yend = 3046), curvature = 0.3, arrow = arrow(length=unit(2,""mm"")), color = ""white"") +
  annotate(""text"", x = 1979 + 7, y = 2950, label = ""1979"")
  


","2019-24"
"261",1082,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week19/R/20190507.Rmd","AmandaRP","tidytuesday","2019/week19/R/20190507.Rmd","---
title: ""Week 19""
output: html_notebook
---

```{r}
library(tidyverse)
library(here)
library(rworldmap)
library(ggthemes)
```

Read data:

```{r}
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

```

Clean data and calculate median:

```{r}

med_ratios <- student_ratio %>% 
  filter(!is.na(student_ratio)) %>%      # remove NAs
  group_by(country_code, indicator) %>%
  filter(year == max(year)) %>%          # grab the most recent data for each country and education level
  ungroup() %>%
  group_by(country_code, country) %>%
  summarise(median_ratio = median(student_ratio)) 

```

Check names in med_ratios compared to map_data(""world"")

```{r}
anti_join(med_ratios, map_data(""world""), by = c(""country"" = ""region"")) %>% View()
```


Need to recode some country names to match map_data:

```{r}
med_ratios_fixed <- med_ratios %>%
  mutate(country = recode(country,
                                ""United States of America"" = ""USA"",
                                ""Viet Nam"" = ""Vietnam"",
                                ""British Virgin Islands"" = ""Virgin Islands"",
                                ""United Republic of Tanzania"" = ""Tanzania"",
                                ""Syrian Arab Republic"" = ""Syria"",
                                ""Russian Federation"" = ""Russia"",
                                ""Democratic People's Republic of Korea"" = ""North Korea"",
                                ""The former Yugoslav Republic of Macedonia"" = ""Macedonia"",
                                ""Republic of Moldova"" = ""Moldova"",
                                ""Republic of Korea"" = ""South Korea"",
                                ""Cte d'Ivoire"" = ""Ivory Coast"",
                                ""Iran (Islamic Republic of)"" = ""Iran"",
                                ""United Kingdom of Great Britain and Northern Ireland"" = ""UK"",
                                ""Micronesia (Federated States of)"" = ""Micronesia"",
                                ""Czechia"" = ""Czech Republic"",
                                ""Cabo Verde"" = ""Cape Verde"",
                                ""Congo"" = ""Democratic Republic of the Congo"",
                                ""Brunei Darussalam"" = ""Brunei"",
                                ""Bolivia (Plurinational State of)"" = ""Bolivia""))
                                
```

Join median student teacher ratio data with map data:

```{r}
my_map_data <- med_ratios_fixed %>%
  full_join(map_data(""world""), by = c(""country"" = ""region"")) %>% 
  filter(!grepl(""Antarctica"",country)) #don't need Antarctica
```


Plot:

```{r}
ggplot(my_map_data, aes(x = long, y = lat)) +
     geom_polygon(aes(fill = median_ratio, group = group), color = ""black"", size = 0.2) +
     scale_fill_gradient2(low = ""blue"", high = ""red"", midpoint = 17.428480) +
     theme_fivethirtyeight() + 
     theme(axis.line=element_blank(),
           axis.text.x=element_blank(),
           axis.text.y=element_blank(),
          panel.grid.major=element_blank(),
          panel.grid.minor=element_blank()) +
     labs(fill = ""ratio"",
          title = ""Median Student to Teacher Ratios"",
          caption = str_c(str_wrap(""Median student-to-teacher ratio calculated across all education levels using the most recent data for each level. White indicates a median ratio close to the world median. Countries shown in blue have a smaller ratio, while countries shown in red have a larger (less favorable) ratio. Grey indicates missing data."", width = 120),""\nData Source: UNESCO\nVisualization: @AmandaRPlunkett"")) 
  
```



```{r}
ggsave(""studentTeacherRatios.png"", width = 7.4, height = 4.5, dpi = ""retina"")
```

","2019-19"
"262",1083,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week28/fifa.R","AmandaRP","tidytuesday","2019/week28/fifa.R","library(tidyverse)
library(ggimage)

#Get the data
wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

#get alternative country codes
more_codes <- countrycode::codelist_panel %>% 
  group_by(country.name.en) %>% 
  top_n(1, year) %>%
  select(country.name.en, ioc, iso2c, iso3c, genc3c, fips)

#join data with codes
wwc_outcomes_wcodes <- dplyr::left_join(wwc_outcomes, codes, by = ""team"") %>%
  select(year, team, score, country) %>%
  left_join(more_codes, by = c(""team"" = ""ioc"")) %>%
  mutate(year = as.character(year))
#Fix England:
wwc_outcomes_wcodes[wwc_outcomes_wcodes$country == ""England"", ""iso2c""] <- ""GB""

#Limit plot to top scoring countries 
top_countries <- wwc_outcomes %>%
  group_by(team) %>%
  summarize(total_score = sum(score)) %>%
  top_n(11, total_score) 

#plot
ggplot(inner_join(wwc_outcomes_wcodes, top_countries), 
       aes(reorder(country, total_score), score, fill = year)) + 
  geom_col(position = position_stack(reverse = TRUE)) + #adjusted position_stack to have years increase from left to right
  ggthemes::scale_fill_tableau(name=""Year"") +           #nice colors
  coord_flip() +
  labs(
    title = ""Womens World Cup Soccer: Total Goals (1991 - 2019)"",
    caption = ""Data from https://data.world/sportsvizsunday/womens-world-cup-data""
  ) +
  geom_flag(y = -5, aes(image = iso2c)) +
  expand_limits(y = -5) +
  geom_image(aes(x = ""France"", y = 120, 
                 image = ""~/tidytuesday/2019/week28/soccer2.png""),
             size = 0.15) +
  theme_minimal() +
  theme(title = element_text(size=14),
        panel.grid = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.title = element_blank(),
        strip.text.y = element_text(angle = 180)) + 
  guides(fill = guide_legend(reverse = TRUE))  #put 2019 at top of legend

","2019-28"
"263",1084,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week22/wine.R","AmandaRP","tidytuesday","2019/week22/wine.R","library(tidyverse)
library(showtext)

#read data:
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

#clean up a bit:
wine_ratings <- wine_ratings %>% 
  select(-X1) %>% #X1 is not informative
  distinct()      #de-dupe based on a tip posted on twitter

#Some countries only have a handful of ratings.
# Select only countries that have atleast 1000 ratings:
large_sample_countries <- wine_ratings %>% 
  group_by(country) %>% 
  summarize(med_cntry_pnts = median(points), cnt = n()) %>% 
  arrange(desc(med_cntry_pnts)) %>%  
  filter(cnt >= 1000) #%>% View()

data4plotting <- inner_join(wine_ratings, large_sample_countries)

#Note: I had to use the showtext package (extrafonts didn't offer very many fonts 
# and newly installed fonts didn't render... may be user error). 
# Required copying and pasting code into terminal window.
# Read more about showtext package here: 
# https://cran.rstudio.com/web/packages/showtext/vignettes/introduction.html
font_add_google(""Satisfy"", ""satisfy"")
showtext_auto()


# Country vs Taster. Do some tasters give higher ratings in general than others?  
p <- data4plotting %>% 
  filter(!is.na(taster_name)) %>%
  group_by(taster_name, country) %>%
  summarize(med_cntry_taster_pnts = median(points), cnt_cntry_taster = n())  %>%
  ungroup() %>%
  mutate(taster_name = fct_reorder(taster_name, med_cntry_taster_pnts)) %>%
  ggplot(aes(x = country, y = taster_name, size = cnt_cntry_taster, color = med_cntry_taster_pnts)) +
  geom_point() +
  scale_colour_gradient(low = ""white"", high = ""dark red"") +
  theme_light() +
  labs(y = ""Taster"", 
       x = ""Wine Country"", 
       title = ""Wine Taster Rating Profile (by Country)"",
       color = ""Median Score"",
       size = ""Number of Reviews"",
       caption = ""Countries limited to those with atleast 1000 rated wines"") +
  theme(axis.text.x = element_text(angle = 45, hjust=1, size = 20),
        axis.text.y = element_text(size = 20),
        title = element_text(family = ""satisfy"", size = 36),
        plot.caption = element_text(hjust = 0.5),
        legend.text = element_text(size = 18))

p

ggsave(""wine_tasting.png"", p, height = 4, width = 7)


### Bonus code:

#The following parallel plot looks cool, but I don't think it's as informative 
# as the bubble plot.
library(ggparallel)  

df <- data4plotting %>% 
    filter(!is.na(taster_name)) %>%
    group_by(taster_name, country) %>%
    summarize(med_cntry_taster_pnts = median(points)) 
  
ggparallel(list(""taster_name"", ""country""), as.data.frame(df))

","2019-22"
"264",1085,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week20/20190514.R","AmandaRP","tidytuesday","2019/week20/20190514.R","library(tidyverse)
library(tidytext)
library(wordcloud)

#Read data:
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

#Get list of words and their counts
words_df <- nobel_winners %>% 
  select(gender, motivation) %>%
  filter(!is.na(motivation) & !is.na(gender)) %>%
  unnest_tokens(word, motivation) %>%
  anti_join(stop_words) %>%
  group_by(gender, word) %>%
  summarize(cnt = n()) %>%
  arrange(desc(cnt)) %>% 
  ungroup()

#Create document term matrix:
dtm <- words_df %>% cast_dtm(gender, word, cnt) 

#Draw word clouds:
comparison.cloud(t(as.matrix(dtm)), max.words=75)
commonality.cloud(t(as.matrix(dtm)), max.words=40)
","2019-20"
"265",1086,"https://github.com/AmandaRP/tidytuesday/blob/master/2019/week26/ufo.R","AmandaRP","tidytuesday","2019/week26/ufo.R","library(tidyverse)
library(summarytools)
library(tidytext)
library(igraph)
library(ggraph)

#read data:
ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

#Look at the data:
View(ufo_sightings)
view(dfSummary(ufo_sightings))

#Clean and tokenize 
bigram_counts <- ufo_sightings %>%
  select(description) %>%
  mutate(description = str_replace_all(description, ""\\&\\#\\d+"", """")) %>%  # Remove &#digit
  filter(!is.na(description)) %>%
  unnest_tokens(bigram, description, token = ""ngrams"", n = 2) %>%
  separate(bigram, c(""word1"", ""word2""), sep = "" "") %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>%
  count(word1, word2, sort = TRUE) %>%
  filter(word1 != ""nuforc"" & word2 != ""nuforc"")

#Create graph structure:
bigram_graph <- bigram_counts %>%
  filter(n > 225) %>%
  graph_from_data_frame()

a <- grid::arrow(type = ""closed"", length = unit(.15, ""inches""))

#plot:
ggraph(bigram_graph, layout = ""fr"") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = ""lightgreen"", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()  +
  theme(plot.margin=unit(c(.5, .5, .5, .5),""cm"")) +
  labs(title = ""Common Bigrams in UFO Sighting Descriptions"",
       subtitle = ""Data provided by NUFORC"")

","2019-26"
"266",1124,"https://github.com/Talitrus/tidytuesday/tree/master/2019/week25","Talitrus","tidytuesday","2019/week25/Jun192019_tidytuesday.R","####################
# Bryan Nguyen
####################
# Data is from https://www.birdscanada.org/
# Cleaned and tidied by @_sharleen_w on Twitter.
############################################
# This code performs an ordination on the Christmas Bird Count (CBC) data from Hamilton, Ontario, Canada.
# Specifically, it uses a Principle Coordinates Analysis on the Bray-Curtis distance matrix of yearly data.
# The resulting plot is colored by year to show a trend through time.
# Some years were missing CBC data and were removed.
#######################################

library(tidyverse)
library(LaCroixColoR)
library(vegan)
library(ggrepel)
library(extrafont)
bird_counts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")


table <- spread(data = bird_counts %>% select(year, species_latin, how_many_counted_by_hour), key = ""year"", value = ""how_many_counted_by_hour"", fill = 0) %>% 
  column_to_rownames(var = ""species_latin"")
vegan_table <- t(table)

vegan_table <- vegan_table[rowSums(vegan_table) > 0,] # remove birds with no sightings in Hamilton ever.

bc_matrix <- vegdist(as.matrix(vegan_table)) # Calculate (abundance-weighted) Bray-Curtis ecological community distances between years.

PCoA_ord <- cmdscale(bc_matrix, k = 2, eig = TRUE) # Principle Coordinates Analysis
PCoA_df <- tibble(year = as.numeric(rownames(PCoA_ord$points)), x = PCoA_ord$points[,1], y = PCoA_ord$points[,2])
years_to_label <- c(1921, 1939, 2017)
PCoA_df$label <- """" # Years with a blank label are not labelled.
PCoA_df$label[match(years_to_label, PCoA_df$year)] <- years_to_label # Label years to label with the corresponding year information.

PCoA_plot <- ggplot(data = PCoA_df) +
  geom_point(mapping = aes(x = x, y = y, color = year), size = I(5), alpha = 0.70) +
  #viridis::scale_color_viridis() + # sorry, but the LaCroix color palettes are too much fun.
  scale_color_gradientn(colors = lacroix_palette(""PeachPear"")) +
  geom_label_repel(mapping = aes(x = x, y = y, label = label, color = year), force = 5) +
  xlab(paste0(""PCoA axis 1: "", round(PCoA_ord$eig[1] / sum(PCoA_ord$eig) * 100, digits = 1), ""%"")) +
  ylab(paste0(""PCoA axis 2: "", round(PCoA_ord$eig[2] / sum(PCoA_ord$eig) * 100, digits = 1), ""%"")) +
  ggtitle(""Hamilton, Canada CBC bird communities change / time"") +
  theme_minimal() +
  theme(
    text = element_text(
      family = ""Lato"" # This is a freely available Google font that I imported into R with the 'extrafont' library.
        ),
    plot.title = element_text(
      face=""bold"")
  )
PCoA_plot

ggsave(filename = ""PCoA_plot.png"", plot = PCoA_plot, height = 4, width = 6)
","2019-25"
"267",1126,"https://github.com/toscano84/TidyTuesday/blob/master/week4_2019/week4_2019.R","toscano84","TidyTuesday","week4_2019/week4_2019.R","# week 4 2019 - TidyTuesday

library(tidyverse) # wrangle, visualization of data
library(data.table) # load file
library(albersusa) # map of all 50 states plus DC
library(broom) # in this case to tidy a shape file
library(ggalt) # create coordinate system in maps
library(viridis) # color palette
library(extrafont) # add fonts to R


options(scipen = 999)

# load file
incarceration <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/incarceration_trends.csv"")

# tidy the dataframe
murder_crime_tbl <- incarceration %>% 
  mutate(decade = year -year %% 10) %>% # create variable decade)
  group_by(decade, state) %>% # group by decade and state
  mutate(crime = rowSums(cbind(violent_crime, murder_crime),na.rm=TRUE) 
         / total_pop * 100) %>% # create variable crime that corresponds to the sum of violent crime and murder crime
  summarize(crime_rate = mean(crime, na.rm = TRUE)) %>%
  filter(!state %in% c(""AK"", ""AL"") | decade != 1970)

#--- create map of the us states

us <- usa_composite() %>%
  tidy(., region = ""iso_3166_2"") # use tidy function from the broom package to create a dataframe of the us map

#---- create quantiles
number_quantiles <- 5
labels <- c()

quantiles <- quantile(murder_crime_tbl$crime_rate, 
                      probs = seq(0, 1, length.out = no_classes + 1))

# create custom labels for the quantiles
for(i in 1:length(quantiles)){
  labels <- c(labels, paste0(round(quantiles[i], 2), 
                             "" - "", 
                             round(quantiles[i + 1], 2)))
}
# Remove last label
labels <- labels[1:length(labels)-1]

# create new variable based on quantiles
murder_crime_tbl$crime_rate_quantiles <- cut(murder_crime_tbl$crime_rate, 
                                          breaks = quantiles, 
                                          labels = labels, 
                                          include.lowest = T)


#----------build plot: fill varriable correspond to the quantiles-----#
p <-  ggplot() +
  geom_map(data = us, map = us,
           aes(x = long, y = lat,
               map_id = id),
           color = ""grey30"",
           fill = NA) +
  geom_map(data = murder_crime_tbl, map = us,
           aes(fill = crime_rate_quantiles, map_id = state),
           color = ""grey30"") +
  scale_fill_viridis_d(option = ""plasma"",
                     name = ""Violent\nand Murder Crime Rate"",
    direction = -1,
    guide = guide_legend(
      keyheight = unit(5, units = ""mm""),
      title.position = 'top',
      reverse = T
    )) +
  facet_wrap(vars(decade)) +
  coord_proj(us_laea_proj) +
  labs(title = ""Violent and Murder Crime in the USA"",
       subtitle = ""Mean Rate (%) by decade "",
       x = """",
       y ="""") +
  theme_minimal() +
  theme(plot.title = element_text(family = ""Cooper Black"",
                                  size = 30, hjust = 0.5),
        plot.subtitle = element_text(family = ""Cooper Black"",
                                  size = 20, hjust = 0.5),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Cooper Black"", size = 18, 
                                  face = ""bold""),
        legend.text = element_text(family = ""Cooper Black"", size = 14),
        legend.title = element_text(family = ""Cooper Black"", size = 18),
        plot.background = element_rect(fill = ""#e8e8ea""),
        panel.grid = element_line(color = ""grey70""),
        legend.direction = ""vertical"",
        legend.position = c(0.85, 0.25))

ggsave(""crime_usa.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")

","2019-4"
"268",1129,"https://github.com/toscano84/TidyTuesday/blob/master/week2_2019/week2_2019.R","toscano84","TidyTuesday","week2_2019/week2_2019.R","# week 2 2019 - TidyTuesday

# libraries needed
library(tidyverse)
library(data.table)
library(ggrepel)
library(lubridate)
library(ggdark)
library(ggrepel)
library(extrafont)

# import and load fonts
font_import()
loadfonts(device = ""win"")

# open the file
imdb_ratings <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"")

# glimpse the dataframe
glimpse(imdb_ratings)

# tidy the file
imdb_ratings_tidy <- imdb_ratings %>%
  mutate(year = year(date), # create variable year
         decade = year - year %% 10) # create variable decade


# create variable above_below_median grouped by year
imdb_ratings_tidy <- imdb_ratings_tidy %>%
  group_by(year) %>%
  mutate(above_below_median = ifelse(av_rating > median(av_rating), 
                               1, 0))

# create a dataframe with highest average tv_ratings per decade
imdb_top_perdecade <- imdb_ratings_tidy %>%
  group_by(decade) %>%
  top_n(1, wt = av_rating)

#----plot----#
plot <- imdb_ratings_tidy %>%
  group_by(year) %>%
  ggplot(aes(x = factor(year),
             y= av_rating, label = title)) +
  geom_jitter(aes(color = factor(above_below_median)), size = 3, alpha = 0.3) +
  geom_boxplot(alpha = 0, color = ""grey50"", outlier.colour = ""red"") +
  geom_label_repel(data = imdb_top_perdecade, # label with the top show per decade
                   fontface = ""bold"",
                   color = ""grey50"",
                   size = 6,
                   family = ""Agency FB"",
                   direction = ""x"") +
  stat_summary(fun.y = median, geom = ""line"", aes(group = 1), 
               linetype = 1, colour = ""grey50"", size = 1) # create a line based on the median +
  dark_theme_gray() +
  theme(plot.title = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 40, hjust = 0.5),
        plot.subtitle = element_text(family = ""Agency FB"", face = ""bold"",
                                     size = 20, hjust = 0.5),
        plot.background = element_rect(fill = ""grey10""),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = ""grey30"", size = 0.2),
        panel.grid.minor = element_line(color = ""grey30"", size = 0.2),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_text(family = ""Agency FB"", size = 15),
        axis.text = element_text(family = ""Agency FB"", size = 15),
        legend.key = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Agency FB"", size = 15),
        legend.text = element_text(family = ""Agency FB"", size = 15),
        legend.title = element_text(family = ""Agency FB"", size = 15)) +
  scale_color_manual(values = c(""#d35400"", ""#1abc9c""), labels = c(""Below the Median"", 
                                                                  ""Above the Median"")) + 
  labs(title = ""Average Rating of Tv Shows"",
       subtitle = ""Parenthood, Third Watch and Breaking Bad had\nthe highest average rating for each decade"", 
       x = ""Year"", 
       y = ""Average Rating"", 
       color = ""Shows"") +
  facet_wrap(vars(decade), ncol = 3, scales = ""free_x"")

plot

ggsave(""av_ratings_imdb.jpg"", plot, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")
","2019-2"
"269",1130,"https://github.com/toscano84/TidyTuesday/blob/master/week5_2019/week5_2019.R","toscano84","TidyTuesday","week5_2019/week5_2019.R","# week 5 2019 - TidyTuesday

library(tidyverse) # wrangle, visualization of data
library(data.table) # load file
library(extrafont) # add fonts to R
library(gghighlight) # highlight values in a plot

options(scipen = 999) # remove scientific notation


# load data frame
milk_facts <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milk_products_facts.csv"")

# create manual palette
cols <-  c(""#578300"", ""#991200"", ""#1280A1"", ""yellow"", ""Tomato"",
           ""MediumSeaGreen"", ""DodgerBlue"", ""blue"", ""#FA8072"", 
           ""#FFC300"", ""#FF5733"", ""#C70039"", ""#900C3E"", ""#571845"",
           ""#D35400"", ""#000080"") 

# create plot
p <- milk_facts %>%
  gather(key = types_milk, value = avg_consumption, 2:ncol(.)) %>%
  filter(types_milk != ""fluid_milk"") %>% #do not include fluid_milk
  mutate(types_milk2 = recode(types_milk,
                                  ""butter"" = ""Butter"", 
          ""cheese_american"" = ""Cheese American"", 
          ""cheese_cottage"" = ""Cheese Cottage"", 
          ""cheese_other"" = ""Cheese Other"",
          ""dry_buttermilk"" = ""Dry Buttermilk"", 
          ""dry_nonfat_milk"" = ""Dry non-fat Milk"", 
          ""dry_whey"" = ""Dry Whey"",
         ""dry_whole_milk"" = ""Dry Whole Milk"",
         ""evap_cnd_canned_whole_milk"" = ""Evap. and Canned whole Milk"",
         ""evap_cnd_bulk_whole_milk"" = ""Evap. and Canned Bulk whole Milk"",
         ""evap_cnd_bulk_and_can_skim_milk"" = ""Evap. and Canned Bulk & skim Milk"",
         ""fluid_yogurt"" = ""Fluid Yogurt"",
         ""frozen_ice_cream_regular"" = ""Frozen Ice cream Regular"",
         ""frozen_ice_cream_reduced_fat"" = ""Frozen Ice Cream reduced Fat"",
         ""frozen_other"" = ""Frozen Other"",
         ""frozen_sherbet"" = ""Frozen Sherbet"",
         ""fluid_milk"" = ""Fluid Milk"")) %>%
  group_by(year, types_milk2) %>%
  summarize(avg_milk_consumed = mean(avg_consumption, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = avg_milk_consumed)) +
  guides(color = FALSE) +
  geom_line(aes(colour = types_milk2), size = 3.5) +
  gghighlight(use_direct_label = FALSE, use_group_by = FALSE,
              unhighlighted_colour = alpha(""grey20"", 0.3)) +
  facet_wrap(vars(types_milk2)) + 
  labs(title = ""Average Consumption of Milk Products (lbs per person)"",
       subtitle = ""Not including fluid Milk"",
       x = NULL,
       y = NULL) +
  scale_x_continuous(breaks = c(seq(1975, 2015, by = 10)),
                     limits = c(1975, 2017)) +
  ggdark::dark_theme_bw() +
  scale_color_manual(values = cols) +
  theme(plot.title = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 30, hjust = 0.5),
        plot.subtitle = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 15, hjust = 0.5),
        plot.background = element_rect(fill = ""black""),
        panel.border = element_blank(),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(family = ""Agency FB"", size = 15),
        legend.key = element_blank(),
        axis.title = element_text(family = ""Agency FB"", size = 20, face = ""bold""),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Agency FB"", size = 20, face = ""bold""),
        legend.text = element_text(family = ""Agency FB"", size = 15),
        legend.title = element_text(family = ""Agency FB"", size = 15))


ggsave(""milk_consumption.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")


           


","2019-5"
"270",1132,"https://github.com/toscano84/TidyTuesday/blob/master/week6_2019/week6_2019.R","toscano84","TidyTuesday","week6_2019/week6_2019.R","# week 6 Tidy Tuesday

library(tidyverse) # wrangle, visualization data
library(data.table) # load file
library(geojsonio) # open json files
library(cartogram) # create cartograms
library(broom) # tidy data frames
library(rgeos) # manipulation of spatial objects
library(viridis) # palette
library(extrafont) # add new fonts to R

# open data frame
hpi_usa <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")


# tidy the data frame
hpi_usa_tbl <- hpi_usa %>% 
  mutate(state_full_name = as.factor(case_when(state == ""AL"" ~ ""Alabama"",
                                               state == ""AK"" ~ ""Alaska"",
                                state == ""AR"" ~ ""Arkansas"",
                                state == ""AZ"" ~ ""Arizona"",
                                state == ""CA"" ~ ""California"",
                                state == ""CO"" ~ ""Colorado"",
                                state == ""CT"" ~ ""Connecticut"",
                                state == ""DC"" ~ ""District of Columbia"",
                                state == ""DE"" ~ ""Delaware"",
                                state == ""FL"" ~ ""Florida"",
                                state == ""GA"" ~ ""Georgia"",
                                state == ""HI"" ~ ""Hawaii"",
                                state == ""IA"" ~ ""Iowa"",
                                state == ""ID"" ~ ""Idaho"",
                                state == ""IL"" ~ ""Illinois"",
                                state == ""IN"" ~ ""Indiana"",
                                state == ""KS"" ~ ""Kansas"",
                                state == ""KY"" ~ ""Kentucky"",
                                state == ""LA"" ~ ""Louisiana"",
                                state == ""MD"" ~ ""Maryland"",
                                state == ""ME"" ~ ""Maine"",
                                state == ""MA"" ~ ""Massachusetts"",
                                state == ""MI"" ~ ""Michigan"",
                                state == ""MN"" ~ ""Minnesota"",
                                state == ""MO"" ~ ""Missouri"",
                                state == ""MS"" ~ ""Mississippi"",
                                state == ""MT"" ~ ""Montana"",
                                state == ""NC"" ~ ""North Carolina"",
                                state == ""NH"" ~ ""New Hampshire"",
                                state == ""ND"" ~ ""North Dakota"",
                                state == ""NE"" ~ ""Nebraska"",
                                state == ""NJ"" ~ ""New Jersey"",
                                state == ""NM"" ~ ""New Mexico"",
                                state == ""NV"" ~ ""Nevada"",
                                state == ""NY"" ~ ""New York"",
                                state == ""OH"" ~ ""Ohio"",
                                state == ""OK"" ~ ""Oklahoma"",
                                state == ""OR"" ~ ""Oregon"",
                                state == ""PA"" ~ ""Pennsylvania"",
                                state == ""RI"" ~ ""Rhode Island"",
                                state == ""SC"" ~ ""South Carolina"",
                                state == ""SD"" ~ ""South Dakota"",
                                state == ""TN"" ~ ""Tennessee"",
                                state == ""TX"" ~ ""Texas"",
                                state == ""UT"" ~ ""Utah"",
                                state == ""VA"" ~ ""Virginia"",
                                state == ""VT"" ~ ""Vermont"",
                                state == ""WA"" ~ ""Washington"",
                                state == ""WI"" ~ ""Wisconsin"",
                                state == ""WV"" ~ ""West Virginia"",
                                state == ""WY"" ~ ""Wyoming""))) %>% # create new variable as factor with the state name in a long format
  group_by(year, state_full_name) %>%
  summarize(price_index_avg = mean(price_index, na.rm = TRUE)) %>% # create variable with mean price index per year and state
  mutate(id_row = 1:n()) %>% # this step is important for the spread function to work
  spread(year, price_index_avg) %>% # from long to wide format
  mutate(change_price_index = (`2018` - `2000`) / `2000` * 100) %>% # create variable based on the changes in the house price index from 2000 to 2018
  select(-id_row)
  
  
#-----manipulate hexbin file of the USA------

# open hexbin file
# Hexbin available in https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map.
us_hexagonal <- geojson_read(""us_states_hexgrid.geojson"",  what = ""sp"")

# create variable region
us_hexagonal@data <- us_hexagonal@data %>% 
  mutate(google_name = gsub("" \\(United States\\)"", """", google_name))

# merge both data frames
us_hexagonal@data <- us_hexagonal@data %>% 
  left_join(., hpi_usa_tbl, by=c(""google_name""=""state_full_name""))


# create the cartogram using the change_price_index variable
cartogram <- cartogram(us_hexagonal, 'change_price_index')


# use the broom package to make the spatial object a data frame and then merge it with the cartogram
us_fortified <- tidy(cartogram, region = ""google_name"")
us_fortified <-  us_fortified %>% 
  left_join(. , cartogram@data, by=c(""id""=""google_name"")) 

# Important step to center the state labels
centers <- cbind.data.frame(data.frame(gCentroid(cartogram, byid=TRUE), 
                                       id=cartogram@data$iso3166_2))

#----plot-----#
#---alter the key legend with specific breaks---
# create breaks
new_breaks <- c(50,100,150,200,250,300)
# find the min for the labels
minvalue <- min(us_fortified$change_price_index, na.rm = T)

# create labels
labels <- c()
breaks <- c(minvalue, new_breaks)
# round the labels 
for(i in 1:length(breaks)){
  labels <- c(labels,round(breaks[i + 1], 2))
}

labels <- labels[1:length(labels)-1]
# create a new variable based on breaks
us_fortified$breaks <- cut(us_fortified$change_price_index, 
                     breaks = breaks, 
                     include.lowest = TRUE, 
                     labels = labels)

breaks_scale <- levels(us_fortified$breaks)
labels_scale <- rev(breaks_scale)

p <- ggplot() +
  geom_polygon(data = us_fortified, 
               aes(fill = breaks, 
                   x = long, y = lat, group = group) , 
               size=0.05, color=""grey40"") +
      # create manual scale based on the breaks 
  scale_fill_manual(values = rev(cividis(8)), # reverse cividis scale from the viridis palette
    breaks = rev(breaks_scale),
    name = ""Change of Price Index (%)"",
    drop = FALSE,
    labels = labels_scale,
    guide = guide_legend(
      direction = ""horizontal"",
      keyheight = unit(3.4, units = ""mm""),
      keywidth = unit(18, units = ""mm""),
      title.position = 'top',
      title.hjust = 0.5,
      label.hjust = 1,
      nrow = 1,
      byrow = TRUE,
      reverse = TRUE,
      label.position = ""bottom""
    )
  ) +
  geom_text(data=centers, aes(x=x, y=y, label=id), 
            color=""grey25"", size=5, alpha=0.6, family = ""Cooper Black"") +
  labs(title =  ""House Price Index"",
       subtitle = ""From 2000 to 2018"") +
  theme_void() +
  theme(panel.grid = element_blank(),
    legend.position = c(0.5, 0.87),
    axis.line = element_blank(),
    axis.text = element_blank(),
    plot.background = element_rect(fill = ""#333333"", color = NA), 
    panel.background = element_rect(fill = ""#333333"", color = NA), 
    legend.background = element_rect(fill = ""#333333"", color = NA),
    legend.text = element_text(size= 12, color = ""grey50"", family = ""Cooper Black""),
    plot.title = element_text(size= 28, hjust=0.5, color = ""grey50"", family = ""Cooper Black""),
    plot.subtitle = element_text(size= 14, hjust=0.5, vjust = -5, color = ""grey50"", family = ""Cooper Black""),
    legend.title = element_text(size= 16, hjust=0.5, vjust = -5, color = ""grey50"", family = ""Cooper Black"")) +
  coord_map()

ggsave(""hpi_index_changes.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")

","2019-6"
"271",1134,"https://github.com/toscano84/TidyTuesday/blob/master/week7_2019/week7_2019.R","toscano84","TidyTuesday","week7_2019/week7_2019.R","# week 7 Tidy Tuesday

library(tidyverse) # wrangle, visualization data
library(data.table) # load file
library(viridis) # palette
library(extrafont) # add new fonts to R
library(waffle) # create waffle plot



options(scipen = 999) # remove scientific notation

# import and load fonts
font_import()
loadfonts(device = ""win"")

# importing fontawesome font
fa_font <- tempfile(fileext = "".ttf"")
download.file(""http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/fonts/fontawesome-webfont.ttf?v=4.3.0"",
              destfile = fa_font, method = ""curl"")

font_import(paths = dirname(fa_font), prompt = FALSE)

fonts()
if (.Platform$OS.type == ""windows"") loadfonts(""win"")


# open data frame
fed_spend <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"") 


glimpse(fed_spend)


# tidy the data frame
fed_spend_tbl <- fed_spend %>%
  group_by(year) %>%
  mutate(sum_rd = sum(rd_budget),
         perc_rd = round((rd_budget / sum_rd * 100),0)) %>%
  ungroup() %>%
  filter(year > 2014) %>% # only include the last 3 years
  select(year, department, perc_rd) %>%
  group_by(department) %>% # important step to remove NAs after changing the format from long to wide
  mutate(n = row_number()) %>% # this step is important for the spread function to work
  spread(department, perc_rd) %>%
  select(-n) %>%
  select_if(~mean(.) > 4) %>%
  select(year, DOD, HHS,NIH, everything())



# turn each year data into a vector
year_2015 <- unlist(fed_spend_tbl[1, 2:6])
year_2016 <- unlist(fed_spend_tbl[2, 2:6])
year_2017 <- unlist(fed_spend_tbl[3, 2:6])


# scale color manual
cols <- c(""#F8C932"", ""#E55B2F"", ""#A42C60"", ""#61156E"", ""#120A33"")

# set theme
theme_new <- ggdark::dark_theme_gray() +
  theme(plot.title = element_text(family = ""Cooper Black"", face = ""bold"",
                                  size = 18, hjust = 0.5),
        plot.subtitle = element_text(family = ""Cooper Black"", face = ""bold"",
                                     size = 14, hjust = 0.5),
        plot.background = element_rect(fill = ""grey10""),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_text(family = ""Cooper Black"", size = 12),
        axis.text = element_blank(),
        legend.key = element_blank(),
        legend.text = element_text(family = ""Cooper Black"", size = 10),
        legend.title = element_text(family = ""Cooper Black"", size = 10)) 

# Make waffle graph for each year
fed1 <- waffle(year_2015, rows = 5, size = 0.3, pad = 0.5, colors = cols, 
              use_glyph = ""dollar"", glyph_size = 8) +
  labs(title = ""Top 5 Departments per R&D Budget (%)"",
       subtitle = ""Year 2015"") +
  theme_new
  
fed2 <-  waffle(year_2016, rows = 5, size = 0.3, pad = 1, colors = cols, 
              use_glyph = ""dollar"", glyph_size = 8) +
  labs(subtitle = ""Year 2016"") +
  theme_new

fed3 <-  waffle(year_2017, rows = 5, size = 0.3, pad = 1, colors = cols, 
              use_glyph = ""dollar"", glyph_size = 8) +
  labs(subtitle = ""Year 2017"",
       x = ""Each dollar sign represents ~1% of the RD budget"") +
  theme_new


# iron function to arrange the three plots into one
iron(fed1, fed2, fed3)



","2019-7"
"272",1138,"https://github.com/toscano84/TidyTuesday/blob/master/week1_2019/week1_2019.R","toscano84","TidyTuesday","week1_2019/week1_2019.R","# week 1 2019 - TidyTuesday

# load needed libraries
library(tidyverse) # wrangle and visualize the data
library(lubridate) # deal with dates
library(viridis) # color palette
library(extrafont) # add fonts to R

# open file
tweets <- readRDS(""rstats_tweets.rds"")


# tidy the dataframe
tweets_tidy <- tweets %>%
  mutate(year = year(created_at), # create variable year 
         weekday = wday(created_at, label = TRUE),
         weekday = fct_relevel(weekday, ""Mon"",
                               ""Tue"",
                               ""Wed"",
                               ""Thu"",
                               ""Fri"",
                               ""Sat"",
                               ""Sun""), # create variable day of the week and relevel it
         month = month(created_at, label = TRUE), # create variable month
         week = week(created_at)) %>% # create variable week of the year
  filter(year > 2013) %>% # only include last 5 years
  count(year, weekday, week, month)

## plot ##
p <- tweets_tidy %>%
  ggplot(aes(week, weekday, fill = n)) +
  geom_tile(colour = ""grey30"") +
  facet_grid(year ~ month, scales = ""free"") + # divide by month and year
  scale_fill_viridis(name = ""Number of Tweets"",
                     option = ""plasma"", guide = guide_colorbar(
    direction = ""horizontal"",
    barheight = unit(3.5, units = ""mm""),
    barwidth = unit(50, units = ""mm""),
    title.position = 'top',
    title.hjust = 0.5,
    label.hjust = 0.5)) + # manipulate dimensions of the legend's scale 
  labs(title = ""#rstats Tweets in the last 5 years"",
       x = """", y = """") +
  theme(plot.title = element_text(family = ""Cooper Black"",
                                  size = 30, hjust = 0.5),
        plot.background = element_rect(fill = ""#d0d3d4""),
        panel.grid = element_blank(),
        panel.background = element_blank(),
        legend.background = element_blank(),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text.y = element_text(colour = ""black"",
                                   family = ""Cooper Black"", size = 12),
        axis.text.x = element_blank(),
        legend.key = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Cooper Black"", size = 18, face = ""bold""),
        legend.text = element_text(family = ""Cooper Black"", size = 15),
        legend.title = element_text(family = ""Cooper Black"", size = 15),
        legend.position = ""bottom"") 

ggsave(""rstats.jpg"", p, units = ""cm"", height = 20, width = 40, dpi = ""retina"")

","2019-1"
"273",1139,"https://github.com/toscano84/TidyTuesday/blob/master/week3_2019/week3_2019.R","toscano84","TidyTuesday","week3_2019/week3_2019.R","# week 3 tidytuesday 2019

library(tidyverse) # wrangle and visualize data
library(data.table) # in this case to open the file with the function fread
library(lubridate) # manipulate dates and times
library(ggdark) # theme for plots
library(extrafont) # add new fonts to base R

# open file
space_launches <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")


# create new dataframe with new variables
space_launches_us <- space_launches %>%
  filter(state_code == ""US"") %>% #only include usa launches
  mutate(administration = case_when(between(launch_year, 1957, 1960) ~ ""Eisenhower"",
                                    between(launch_date, ""1961-01-20"", ""1963-11-22"") ~ ""Kennedy"",
                                    between(launch_date, ""1963-11-23"", ""1969-01-19"") ~ ""Johnson"",
                                    between(launch_date,""1969-01-20"", ""1974-08-09"") ~ ""Nixon"",
                                    between(launch_date,""1974-08-10"", ""1977-01-19"") ~ ""Ford"",
                                    between(launch_date,""1977-01-20"", ""1981-01-19"") ~ ""Carter"",
                                    between(launch_date,""1981-01-20"", ""1989-01-19"") ~ ""Reagan"",
                                    between(launch_date,""1989-01-20"", ""1993-01-19"") ~ ""Bush I"",
                                    between(launch_date,""1993-01-20"", ""2001-01-19"") ~ ""Clinton"",
                                    between(launch_date,""2001-01-20"", ""2009-01-19"") ~ ""Bush II"",
                                    between(launch_date,""2009-01-20"", ""2017-01-19"") ~ ""Obama"",
                                    between(launch_date,""2017-01-20"", ""2019-01-17"") ~ ""Trump""
                                    ), # create variable based on presidential administrations
         party = case_when(administration %in% c(""Kennedy"", ""Johnson"", ""Carter"", ""Clinton"", ""Obama"") ~ ""Democratic"",
                           administration %in% c(""Eisenhower"", ""Nixon"", ""Ford"", ""Reagan"", ""Bush I"", ""Bush II"",
                                                 ""Trump"") ~ ""Republican"")) %>% # party variable
  drop_na(administration) # delete missing values in the variable administration



##----plot------##
# function created to have separate breaks due to the use of facets in the plot
breaks_created <- function(x) { 
  if (max(x) < 1961) seq(1957, 1960, 1) 
  else if (max(x) < 1964) seq(1960, 1964, 1)
  else if (max(x) < 1969) seq(1963, 1969, 1)
  else if (max(x) < 1975) seq(1969, 1974, 1)
  else if (max(x) < 1977) seq(1974, 1977, 1)
  else if (max(x) < 1981) seq(1977, 1981, 1)
  else if (max(x) < 1989) seq(1981, 1989, 1)
  else if (max(x) < 1994) seq(1989, 1994, 1)
  else if (max(x) < 2001) seq(1993, 2001, 1)
  else if (max(x) < 2010) seq(2001, 2009, 1)
  else if (max(x) < 2018) seq(2009, 2017, 1)
  else (seq(2017, 2018, 1))}

# plot creation
p <- space_launches_us %>%
  group_by(launch_year, party, administration) %>%
  summarize(n = n()) %>%
  ggplot(aes(x = launch_year, y = n, fill = party)) +
  geom_area() +
  dark_theme_grey() +
  labs(title = ""Space Launches during each Presidential Administration"", 
       subtitle =, x = """", y = """") +
  scale_fill_manual(name = ""Party"", values = c(""navyblue"", ""red""), 
                    labels = c(""Democratic"", ""Republican"")) +
  scale_x_continuous(breaks = breaks_created) +
  theme(plot.title = element_text(family = ""Agency FB"", face = ""bold"",
                                  size = 30, hjust = 0.5),
        plot.background = element_rect(fill = ""grey10""),
        panel.background = element_blank(),
        panel.grid.major = element_line(color = ""grey20"", size = 0.2),
        panel.grid.minor = element_line(color = ""grey20"", size = 0.2),
        legend.background = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(family = ""Agency FB"", size = 15),
        legend.key = element_blank(),
        strip.background = element_blank(),
        strip.text = element_text(family = ""Agency FB"", size = 20, face = ""bold""),
        legend.text = element_text(family = ""Agency FB"", size = 15),
        legend.title = element_text(family = ""Agency FB"", size = 15)) +
  facet_wrap(vars(fct_reorder(administration, launch_year)), ncol = 3, scales = ""free_x"")

p

ggsave(""plot_us_space.jpg"", p, units = ""cm"", 
       height = 25, width = 40, dpi = ""retina"")




  
 
","2019-3"
"274",1140,"https://github.com/toscano84/TidyTuesday/blob/master/week8_2019/week8_2019.R","toscano84","TidyTuesday","week8_2019/week8_2019.R","# week 8 Tidy Tuesday

library(tidyverse) # wrangle, visualization data
library(data.table) # load file
library(highcharter) # interactive data visualizations

options(scipen = 999)

# open data
phd <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")




# top 20 fields
phd_per <- phd  %>%
  group_by(field) %>%
  summarize(phd_number = sum(n_phds, na.rm = TRUE)) %>%
  mutate(phd_perc = phd_number / sum(phd_number) * 100) %>%
  top_n(20, phd_perc) %>%
  arrange(desc(phd_perc))


# highcharter plot
hchart(phd_per, ""bar"",
       hcaes(x = fct_reorder(field, phd_perc),
             y = phd_perc)) %>%
  hc_add_theme(hc_theme_chalk()) %>%
  hc_title(text = ""Percentage of PhDs: Top 20 Fields"", margin = 10, 
           fontSize = ""50px"") %>%
  hc_xAxis(title = list(text = NULL)) %>% 
  hc_yAxis(title = list(text = ""Percentage"")) %>% 
  hc_subtitle(text = ""From 2008 to 2017"") %>%
  hc_credits(enabled = TRUE,
             text = ""Tidy Tuesday Week 8"",
             style = list(
               fontSize = ""14px""
             )
  )
  


","2019-8"
"275",1646,"https://github.com/lizwillow/TidyTuesday/blob/master/TT.2019.01.01/week20190101.Rmd","lizwillow","TidyTuesday","TT.2019.01.01/week20190101.Rmd","---
output: github_document
---

### #First #TidyTuesday of 2019

This is the code behind an analysis of the ""#rstats and #TidyTuesday Tweets from rtweet"" dataset from the [#tidytuesday project](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-01).

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,warning=FALSE,error=FALSE)

library(tidyverse)
library(scales)
library(broom)
library(ggthemes)
library(plotly)
library(here)
library(rtweet)

theme_set(theme_light())
```

```{r, include=FALSE}

githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/tidytuesday_tweets.rds?raw=true"")
download.file(githubURL,""tidytuesday_tweets.rds"")
tidytuesday <- read_rds(""tidytuesday_tweets.rds"")


githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/rstats_tweets.rds?raw=true"")
download.file(githubURL,""rstats_tweets.rds"")
rstats <- read_rds(""rstats_tweets.rds"")

```

Whose #rstats tweets were retweeted the most in 2018?

```{r}

library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>% 
  summarise(total_retweets = sum(retweet_count),
            n=n()) %>%
  arrange(desc(total_retweets)) %>%
  head(5)

myColors <- as.list(ghibli_palette(""PonyoMedium"",n=5))
names(myColors) <- toppeople$screen_name

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,total_retweets)) %>%
  ggplot(aes(y = total_retweets, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Who had the most retweeted #rstats tweets in 2018?"",
       y = ""Number of retweets of #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm"")) +
  scale_fill_manual(name = ""screen_name"",values = myColors) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",5)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 2,
            col=""white"")

#ggsave(filename = ""rstatsretweets.png"", path = here(""Week20190101_files""),width = 7, height = 4)

```

Whose #rstats tweets were liked the most in 2018?

```{r}

library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_favs = sum(favorite_count),
            n=n()) %>%
  arrange(desc(total_favs)) %>%
  head(5)

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,total_favs)) %>%
  ggplot(aes(y = total_favs, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Who had the most liked #rstats tweets in 2018?"",
       y = ""Number of favorites of #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm"")) +
  scale_fill_manual(name = ""screen_name"",values = myColors) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",5)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 2,
            col=""white"")

#ggsave(filename = ""rstatslikes.png"", path = here(""Week20190101_files""),width = 7, height = 4)


```

Who had the most liked and retweeted #rstats tweets of 2018?

```{r}
topliked <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text,favorite_count) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_fav_ret = sum(retweet_count,favorite_count)) %>%
  arrange(desc(total_fav_ret)) %>%
  head(10)

topliked %>% 
  mutate(screen_name = fct_reorder(screen_name,total_fav_ret)) %>%
  ggplot(aes(y = total_fav_ret, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Users with the most retweeted and favorited #rstats tweets in 2018"",
       y = ""Total #rstats retweets and favorites in 2018"",
       x = """") +
  theme(legend.position = ""none"")

#ggsave(filename=""rstats.png"",path=here(""Week20190101_files""),width = 9, height = 6)
```

Who had the most liked and retweeted #tidytuesday tweets of 2018?

```{r}
topliked <- tidytuesday %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text,favorite_count) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_fav_ret = sum(retweet_count,favorite_count)) %>%
  arrange(desc(total_fav_ret)) %>%
  head(10)

topliked %>% 
  mutate(screen_name = fct_reorder(screen_name,total_fav_ret)) %>%
  ggplot(aes(y = total_fav_ret, x = screen_name, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Users with the most retweeted and favorited #TidyTuesday tweets in 2018"",
       y = ""Total #TidyTuesday retweets and favorites in 2018"",
       x = """") +
  theme(legend.position = ""none"")

#ggsave(filename=""tidytuesday.png"",path=here(""Week20190101_files""),width = 9, height = 6)
```

What were the most retweeted and favorited #tidytuesday tweets of 2018?

```{r}
# install.packages(""devtools"")
#devtools::install_github(""hadley/emo"")
#devtools::install_github(""GuangchuangYu/emojifont"")

toptweet <- tidytuesday %>% 
  select(screen_name,created_at,is_retweet,favorite_count, retweet_count,text,status_id) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  mutate(fav_ret = retweet_count+favorite_count) %>%
  arrange(desc(fav_ret)) %>%
  head(10)

toptweet %>%
  mutate(tex = paste0(str_sub(text,1,60),"" ... ("",format(created_at,format = ""%b %d %Y""),"")""),
         screen_name = paste0(""@"",screen_name)) %>% 
  mutate(tex = fct_reorder(tex,fav_ret)) %>%
  ggplot(aes(y = fav_ret, x = tex, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_minimal() +
  labs(title = ""The most retweeted and favorited #TidyTuesday tweets of 2018"",
       y = ""Number of retweets and favorites combined"",
       x = """",
       fill="""",
       caption = ""Data from the rtweet package."") +
  theme(legend.position = ""bottom"",
        axis.text=element_text(size=7),
        legend.text=element_text(size=7),
        title=element_text(size=8),
        text=element_text(family = ""Tahoma"")) 

#ggsave(filename=""tidytuesdaytweets.png"",path=here(""Week20190101_files""),width = 8, height = 4)

```



How have the number of tweets changed over time?

```{r}

rstats %>% 
  ts_plot(by = ""weeks"")

tidytuesday %>%
  ts_plot(by = ""days"")

```

Whose #rstats tweets were retweeted the most in 2018 on average?

```{r}

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>% 
  summarise(mean_retweets = mean(retweet_count),
            n = n()) %>%
  filter(n>19) %>%
  arrange(desc(mean_retweets)) %>%
  head(7)

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,mean_retweets)) %>%
  ggplot(aes(y = mean_retweets, x = screen_name, fill=n)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Whose #rstats tweets were retweeted most on average in 2018?"",
       subtitle = ""(of those with at least 10 tweets)"",
       y = ""Mean number of retweets of #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm""),
        axis.text = element_text(size = 10)) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",7)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 3,
            col=""white"") +
  scale_fill_gradient(low = myColors[1], high = myColors[5])

#ggsave(filename = ""rstatsavgretweets.png"", path = here(""Week20190101_files""),width = 8.5, height = 4)

```

Whose #rstats tweets were liked the most in 2018?

```{r}

library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(mean_favs = mean(favorite_count),
            n=n()) %>%
  filter(n>19) %>%
  arrange(desc(mean_favs)) %>%
  head(7)

toppeople %>% 
  mutate(screen_name = fct_reorder(screen_name,mean_favs)) %>%
  ggplot(aes(y = mean_favs, x = screen_name, fill=n)) +
  geom_col() +
  coord_flip() +
  theme_light() +
  labs(title = ""Whose #rstats tweets were liked most on average in 2018?"",
       subtitle = ""(of those with at least 10 tweets)"",
       y = ""Mean number of favorites for #rstats tweets in 2018"",
       x = """",
       caption = ""(Data from the rtweet package)"") +
  theme(legend.position = ""none"",
        text = element_text(family = ""Andale Mono""),
        plot.margin = unit(c(.5,1,.5,0),""cm""),
        axis.text = element_text(size = 10)) +
  scale_fill_gradient(low = myColors[1], high = myColors[5]) +
  geom_text(aes(label = paste(n,c(rep(""tweets"",7)))), 
            position = position_stack(vjust = 0.5),
            family = ""Andale Mono"",
            size = 3,
            col=""white"")

#ggsave(filename = ""rstatsavglikes.png"", path = here(""Week20190101_files""),width = 8.5, height = 4)


```

```{r,echo=FALSE}
knitr::knit_exit()
```

What were the most liked tweets of 2018?

```{r}

toptweet <- tidytuesday %>% 
  select(screen_name,created_at,is_retweet,favorite_count, retweet_count,text,status_id) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  arrange(desc(favorite_count)) %>%
  head(10)

toptweet %>%
  mutate(tex = paste0(str_sub(text,1,60),"" ... ("",format(created_at,format = ""%b %d %Y""),"")""),
         screen_name = paste0(""@"",screen_name)) %>% 
  mutate(tex = fct_reorder(tex,favorite_count)) %>%
  ggplot(aes(y = favorite_count, x = tex, fill=screen_name)) +
  geom_col() +
  coord_flip() +
  theme_minimal() +
  labs(title = ""The most liked #TidyTuesday tweets of 2018"",
       y = ""Number of likes"",
       x = """",
       fill="""",
       caption = ""Data from the rtweet package."") +
  theme(legend.position = ""bottom"",
        axis.text=element_text(size=7),
        legend.text=element_text(size=7),
        title=element_text(size=8),
        text=element_text(family = ""Tahoma"")) 

#ggsave(filename=""tidytuesdaytweets.png"",path=here(""Week20190101_files""),width = 8, height = 4)

```
","2019-1"
"276",1649,"https://github.com/rakash/TidyTuesday-Social-data-project/blob/master/week1_2019.R","rakash","TidyTuesday-Social-data-project","week1_2019.R","library(tidyverse)
library(scales)
library(broom)
library(ggthemes)
library(plotly)
library(here)
library(rtweet)

install.packages(""yaml"")
install.packages(""rtweet"")

install.packages(""htmlwidgets"")

trace(utils:::unpackPkgZip, edit=TRUE)

update.packages()

.libPaths()

#githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/tidytuesday_tweets.rds?raw=true"")
#download.file(githubURL,""tidytuesday_tweets.rds"")
tidytuesday <- read_rds(""C:/Users/AKASHR/Documents/tidytuesday_tweets.rds"")


#githubURL <- (""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-01-01/rstats_tweets.rds?raw=true"")
#download.file(githubURL,""rstats_tweets.rds"")
rstats <- readRDS(""C:/Users/AKASHR/Documents/rstats_tweets.rds"")
rstats

## 1. Whose #rstats tweets were retweeted the most in 2018?

install.packages(""ghibli"")
library(ghibli)

toppeople <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>% 
  summarise(total_retweets = sum(retweet_count),
            n=n()) %>%
  arrange(desc(total_retweets)) %>%
  head(5)

myColors <- as.list(ghibli_palette(""PonyoMedium"",n=5))
names(myColors) <- toppeople$screen_name

View(rstats)
View(toppeople)

library(ggplot2)
theme_set(theme_classic())

# Plot

ggplot(toppeople, aes(x=screen_name, y=n, label=n))+ 
  geom_point(stat='identity', fill=""black"", size=12)  +
  geom_segment(aes(y = 0, 
                   x = `screen_name`, 
                   yend = n, 
                   xend = `screen_name`), 
               color = ""black"") +
  geom_text(color=""white"", size=4) +
  labs(title=""Lollipop Chart"", 
       subtitle=""Whose #rstats tweets were retweeted the most in 2018?"")
       + 
  coord_flip()


## 2. Whose #rstats tweets were liked the most in 2018?


toplikes <- rstats %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_favs = sum(favorite_count),
            n=n()) %>%
  arrange(desc(total_favs)) %>%
  head(5)


View(toplikes)

theme_set(theme_classic())

# Plot
ggplot(toplikes, aes(x=screen_name, y=total_favs)) + 
  geom_point(col=""tomato2"", size=3) + # Draw points
  geom_segment(aes(x=screen_name, 
                   xend=screen_name, 
                   y=min(total_favs), 
                   yend=max(total_favs)), 
               linetype=""dashed"", 
               size=0.1) +   # Draw dashed lines
  labs(title=""Dot Plot"", 
       subtitle=""Whose #rstats tweets were liked the most in 2018"", 
       caption=""source: mpg"") +  
  coord_flip()


## 3. Who had the most liked and retweeted #tidytuesday tweets of 2018?

View(tidytuesday)


toplikedtt <- tidytuesday %>% 
  select(screen_name,created_at,followers_count,is_retweet,favorite_count, retweet_count,text,favorite_count) %>%
  filter(created_at >= as.Date(""2018-01-01""),
         is_retweet == FALSE)  %>%
  group_by(screen_name) %>%
  summarise(total_favr = sum(retweet_count,favorite_count)) %>%
  arrange(desc(total_favr)) %>%
  head(10)

View(toplikedtt)

tt5 <- toplikedtt %>% head(5)
View(tt5)

library(ggplot2)
library(gganimate)
library(gapminder)
theme_set(theme_dark())  # pre-set the bw theme.

g <- ggplot(tt5, aes(screen_name, total_favr)) + 
  labs(subtitle=""Who had the most liked and retweeted #tidytuesday tweets of 2018?"",
       title=""Bubble chart"")

g + geom_jitter(aes(col=screen_name, size=total_favr)) + 
  geom_smooth(aes(col=screen_name), method=""lm"", se=F)

## 4. Total #rstats and #tidytuesday tweets over time in 2018 ?


rstats1 <- rstats %>% mutate(tweet_month = as.POSIXct(rstats$created_at))

rstats1$tweet_month <- format(rstats1$tweet_month,""%B"")

View(rstats1)
View(rtotal)

rtotal <- rstats1 %>% 
  select(created_at, tweet_month) %>%
  filter(created_at >= as.Date(""2018-01-01"")) %>%
  group_by(tweet_month) %>%
  summarise(month_tweets=n()) %>%
  arrange(desc(month_tweets))# %>%

theme_set(theme_light())

ggplot(rtotal, aes(tweet_month, month_tweets)) +
  geom_linerange(
    aes(x = tweet_month, ymin = 0, ymax = month_tweets), 
    color = ""lightgray"", size = 1.5
  )+
  geom_point(aes(color = tweet_month), size = 2)
  #ggpubr::color_palette(""jco"")


## TIdy tuesday 

View(tidytuesday)

ttotal <- tidytuesday %>% mutate(tweet_month = as.POSIXct(tidytuesday$created_at))

ttotal$tweet_month <- format(ttotal$tweet_month,""%B"")

View(ttotal)

ttotal <- ttotal %>% 
  select(created_at, tweet_month) %>%
  filter(created_at >= as.Date(""2018-01-01"")) %>%
  group_by(tweet_month) %>%
  summarise(month_tweets=n()) %>%
  arrange(desc(month_tweets))# %>%

View(ttotal)

theme_set(theme_dark())

# plot 
ggplot(ttotal , aes(x = tweet_month, y = month_tweets)) +
  geom_bar(fill = ""#0073C2FF"", stat = ""identity"") +
  geom_text(aes(label = month_tweets), vjust = -0.3) + 
  labs(title=""which month had the most #tidytuesday tweets of 2018?"")
","2019-1"
"277",1747,"https://github.com/tbobin/tidytuesday/blob/master/src/20180514_tidytuseday_week7.R","tbobin","tidytuesday","src/20180514_tidytuseday_week7.R","

library(tidyverse)
library(purrrlyr)
library(viridis)



df_sw_raw <- read.csv(""./Data/week7_starwars.csv"")

# replace all """" with NA
df_sw_raw[df_sw_raw == """" ] <- NA


# Not Fans #

# if not seen any of the films not a Fan
# if not self considered as fan not a Fan

# Star Wars: Episode I The Phantom Menace
# Star Wars: Episode II Attack of the Clones
# Star Wars: Episode III Revenge of the Sith
# Star Wars: Episode IV A New Hope
# Star Wars: Episode V The Empire Strikes Back
# Star Wars: Episode VI Return of the Jedi


df_sw_not_Fans <- df_sw_raw %>% 
  mutate(Fan = ifelse(
    (Have.you.seen.any.of.the.6.films.in.the.Star.Wars.franchise. == ""No"") |
      (Do.you.consider.yourself.to.be.a.fan.of.the.Star.Wars.film.franchise. == ""No"") |
      is.na(Do.you.consider.yourself.to.be.a.fan.of.the.Star.Wars.film.franchise.), ""No"", ""Yes""
    )) %>% 
  filter(Fan == ""No"") %>% 
  mutate(have.you.seen.Episode.I = ifelse(!is.na(Which.of.the.following.Star.Wars.films.have.you.seen..Please.select.all.that.apply.),
                                          1, 0 ),
         have.you.seen.Episode.II = ifelse(!is.na(X), 1, 0),
         have.you.seen.Episode.III = ifelse(!is.na(X.1), 1, 0),
         have.you.seen.Episode.IV = ifelse(!is.na(X.2), 1, 0),
         have.you.seen.Episode.V = ifelse(!is.na(X.3), 1, 0),
         have.you.seen.Episode.VI = ifelse(!is.na(X.4), 1, 0)) %>% 
  select(RespondentID, Fan:have.you.seen.Episode.VI)



df_Fan_seen_old <- df_sw_not_Fans %>% 
  select(have.you.seen.Episode.I:have.you.seen.Episode.III) %>% 
  by_row(sum, .collate = ""cols"", .to = ""sum_seen_old"")

df_Fan_seen_new <- df_sw_not_Fans %>% 
  select(have.you.seen.Episode.IV:have.you.seen.Episode.VI) %>% 
  by_row(sum, .collate = ""cols"", .to = ""sum_seen_new"")


df_sw_not_Fans <- cbind(df_sw_not_Fans, 
                        new = df_Fan_seen_new$sum_seen_new, 
                        old = df_Fan_seen_old$sum_seen_old) %>% 
  mutate(`one of episodes I - III and one of IV - VI` = ifelse(new > 0 & old > 0 , 1, 0),
         `only one of episodes I - III` = ifelse(new > 0 & old == 0 , 1, 0),
         `only one of episodes IV - VI`= ifelse(new == 0 & old > 0 , 1, 0),
         `no one` = ifelse(new == 0 & old == 0 , 1, 0))

df_sw_not_Fans %>% 
  select(RespondentID, `one of episodes I - III and one of IV - VI`:`no one`) %>% 
  gather(`one of episodes I - III and one of IV - VI`:`no one`,
         key = ""seen"", value = ""count"") %>% 
  mutate(seen = factor(seen, levels = c(""one of episodes I - III and one of IV - VI"", 
                                        ""only one of episodes I - III"", 
                                        ""only one of episodes IV - VI"",
                                        ""no one""), ordered = T)) %>% 
  filter(count > 0) %>% 
  ggplot(aes(x = seen, fill = seen)) + 
  geom_bar(stat = ""count"") +
  geom_text(aes(label = ..count..), stat = ""count"", vjust = -1) +
  viridis::scale_fill_viridis(discrete = T ) +
  scale_y_continuous(limits = c(0, 360)) +
  theme_minimal() +
  theme(panel.grid = element_blank(), 
        legend.position = """", 
        axis.text.y = element_blank()) +
  labs(y = """", x = """",
       title = ""Which episodes have people seen, that are not a fan of the franchise?"",
       subtitle = ""A fan is someone who constider himself as a fan, all others are not seen as a fan.
Most of the people, who consider themself not as as Fan and have seen at least one movie, have seen at least one of 
the new and one of the old episodes. The fewest people of this group saw only the old episodes."",
       caption = ""@T_bobin\nsource: https://github.com/rudeboybert/fivethirtyeight"") 
  



","2018-7"
"278",1748,"https://github.com/tbobin/tidytuesday/blob/master/src/20180511_tidytuseday_week6.R","tbobin","tidytuesday","src/20180511_tidytuseday_week6.R","

library(tidyverse)
library(readxl)
library(scales)
library(geojsonio)
library(broom)
library(viridis)
library(rgeos)
library(skimr)


# read in data
df_cof_raw <- readxl::read_xlsx(paste0(here::here(),""/data/week6_coffee_chains.xlsx""))

# let's start with stores in the US by Brand

df_cof_all <- df_cof_raw %>% 
  filter(Country == ""US"") %>% 
  group_by(`State/Province`, Brand) %>% 
  count()

# let's take a look at the data
df_cof_all %>% 
  ggplot(aes(n)) +
  geom_histogram(binwidth = 100)

df_cof_all %>% ungroup %>% select(-(`State/Province`)) %>% skim(n)

## From r-graph-gallery: https://www.r-graph-gallery.com/328-hexbin-map-of-the-usa/
# Hexbin available in the geojson format here: https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map. Download it and then:
spdf <- geojson_read(paste0(here::here(),""/data/us_states_hexgrid.geojson""),  what = ""sp"")

# I need to 'fortify' the data to be able to show it with ggplot2 (we need a data frame format)
# spdf@data = spdf@data %>% mutate(google_name = gsub("" \\(United States\\)"", """", google_name))
spdf_fortified <- tidy(spdf, region = ""iso3166_2"")


# join data with spital data
spdf_fortified <- spdf_fortified %>% 
  left_join(df_cof_all, by=c(""id"" = ""State/Province""))

#
centers <- cbind.data.frame(data.frame(gCentroid(spdf, byid=TRUE), id=spdf@data$iso3166_2))

# Prepare binning
spdf_fortified$bin = cut( spdf_fortified$n , breaks=c(seq(0,500,100), Inf), 
                          labels=c(""0-100"", ""101-200"", ""201-300"", ""301-400"", ""401-500"", ""500+"" ), include.lowest = TRUE )



# lets plot the Starbucks map
spdf_fortified %>% 
  filter(Brand == ""Starbucks"") %>% 
  ggplot(aes()) +
  geom_polygon(aes(fill = bin, x = long, y = lat, group = group) , size=0, alpha=0.9) +
  geom_text(data=centers, aes(x=x, y=y, label=id), color=""white"", size=3, alpha=0.6) +
  scale_fill_viridis(option = ""viridis"", discrete=TRUE,
                     name = """") +
  theme_minimal() +
  labs(title = ""Starbucks Coffee stores per State"",
       caption = ""@T_Bobin \nsource: kaggle.com"")+
  theme(panel.border=element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        legend.position = ""bottom"") +
  coord_map() 

#ggsave(""/graphs/20180512_tidyTuseday_week_6.png"", width = 10, dpi = 600)

","2018-6"
"279",119,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_21/tidytuesday_2019_05_21.R","jmmnyc","tidytuesday","2019_05_21/tidytuesday_2019_05_21.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(janitor)
library(gridExtra)

coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")

# Set custom ggplot theme
my_font <- ""Segoe UI Black""

base_color <- ""#f5f3dc""

font_color <- ""#42ac96"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 7, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 10))

theme_set(theme_light() + my_theme)



# Clean names
coast_vs_waste <- clean_names(coast_vs_waste)

# Let's find out the years included
# Seems we have over 200 countries from around mid 1950's until 2013

coast_vs_waste %>% 
  group_by(year) %>% 
  tally() %>% 
  ggplot(aes(x = year, y = n)) +
  geom_col()

coast_vs_waste %>% 
  group_by(year) %>% 
  tally() %>% 
  tail()

# Let's take a look at the data on mismanged waste
# Looks like we only have data for 2010

coast_vs_waste %>% 
  filter(!is.na(mismanaged_plastic_waste_tonnes)) %>% 
  group_by(entity, year) %>% 
  summarise(mismanaged_plastic_waste_tonnes) %>% 
  View()

# Let's filter to focus 2010 and create a measure for % of population that is coastal

plot_data <- coast_vs_waste %>% 
  filter(year == 2010) %>% 
  mutate(coastal_pop_pct = coastal_population/total_population_gapminder) 


# I would expect to see population size and waste are positively correlated

waste_pop <- plot_data %>% 
  #filter(entity == ""Dominican Republic"") %>% 
  ggplot(aes(x = log(total_population_gapminder), y = log(mismanaged_plastic_waste_tonnes))) +
  geom_point(aes(col = entity), size = 2, alpha = .7) +
  geom_smooth(method = ""lm"") +
  theme(legend.position = ""none"") +
  labs(title = ""Countries with larger populations produce more plastic waste (2010)"",
       x = ""Total population (log scale)"",
       y = ""Mismanaged plastic waste in tonnes (log scale)"",
       caption = """") 


# Maybe countires with larger coastal populations behave differently

waste_coast_pop <- plot_data %>% 
  #filter(entity == ""Dominican Republic"") %>% 
  ggplot(aes(x = coastal_pop_pct, y = log(mismanaged_plastic_waste_tonnes))) +
  geom_point(aes(col = entity), size = 2, alpha = .7) +
  geom_vline(xintercept = 1) +
  geom_text(aes(x = 1, y = 15, 
                label = ""Some data points might have errors \n    with coastal pop greater total"",
                hjust = -0.1),
                size = 3) +
  geom_smooth(method = ""lm"") +
  theme(legend.position = ""none"") +
  labs(title = ""Lower waste produced in countries with higher % of coastal population"",
       x = ""Coastal population as % of total"",
       y = """",
       caption = ""Source: Our World in Data \nVisualization by Jose M @Joseph_Mike"") 


combined_plots <- arrangeGrob(waste_pop, waste_coast_pop, ncol = 2)


ggsave(""TidyTuesday_2019_05_21.png"", combined_plots, width = 12, height = 4, device = ""png"", type = ""cairo"")
","2019-21"
"280",120,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_07/tidytuesday_2019_05_07.R","jmmnyc","tidytuesday","2019_05_07/tidytuesday_2019_05_07.R","
library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

# Set custom theme
my_font <- ""Lucida Sans""

base_color <- ""#f5f3dc""

font_color <- ""#42ac96"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 14))

theme_set(theme_light() + my_theme)

# Subset data
plot_data <- student_ratio %>% 
  filter(str_detect(country, "".countries""),
         indicator %in% c(""Primary Education"", ""Secondary Education"", ""Tertiary Education""),
         year == ""2017"") %>% 
  select(country, year, indicator, student_ratio)

# Viz
plot_data %>% 
  ggplot(aes(student_ratio, reorder(country, -student_ratio), fill = indicator)) +
  geom_point(shape = 21, size = 4, alpha = .6) +
  labs(title = ""Less teachers per students in lower income countries in 2017"",
       subtitle = ""the difference is greater in primary schools (elementary)"",
       x = ""Student:Teacher ratio (# of students per teacher)"",
       y = """",
       caption = ""Source: UNESCO Institute of Statistics \nVisualization by Jose M @Joseph_Mike"",
       fill = """") +
  theme(legend.position = ""top"") +
  scale_fill_manual(values = c(""#984EA3"", ""#FF7F00"")) #, ""#4DAF4A""))""#984EA3""


ggsave(""TidyTuesday_2019_05_07.png"", device = ""png"", type = ""cairo"")","2019-19"
"281",121,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_05/tidytuesday_2019_03_05.R","jmmnyc","tidytuesday","2019_03_05/tidytuesday_2019_03_05.R","#load packages
library(tidyverse)
library(ggthemes)
library(scales)

jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")

jobs_gender$minor_category <- as.factor(jobs_gender$minor_category)

plot_data <- jobs_gender %>% 
  filter(year == 2016) %>%
  group_by(minor_category) %>% 
  summarise(pct_female_workers = sum(workers_female, na.rm = TRUE)/sum(total_workers, na.rm = TRUE),
            pct_female_wages = sum(total_earnings_female, na.rm = TRUE)/sum(total_earnings_male, na.rm = TRUE)) %>% 
  ungroup() 
  
plot_data %>%   
  ggplot(aes(x = reorder(minor_category, pct_female_wages), y = pct_female_wages)) +
  geom_col() +
  geom_hline(yintercept = 1, linetype = ""dashed"", col = ""red"") +
  theme_economist_white() +
  labs(title = ""Female wages as a % of Male wages by Industry"",
       subtitle = ""100% = pay parity"",
       x = """",
       y = ""Percent"") +
  coord_flip() +
  theme(axis.text.y = element_blank()) +
  geom_text(aes(x = reorder(minor_category, pct_female_wages), y = .35, label = minor_category), size = 4, col = ""white"") +
  scale_y_continuous(labels = percent_format(accuracy = 1))
","2019-10"
"282",122,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_09/tidytuesday_2019_04_09.R","jmmnyc","tidytuesday","2019_04_09/tidytuesday_2019_04_09.R","library(tidyverse)
library(ggthemes)
library(RColorBrewer)

player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

#set custom theme
my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8),
                  axis.title.x = element_text(margin = margin(15,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,15,0,0)),
                  axis.title = element_text(margin = margin (0,0,15,0))
)

theme_set(theme_light() + my_theme)



age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>% # needs to be datetime
  group_by(name, age, gender) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins)) %>% 
  ungroup() %>% 
  mutate(age = as.numeric(age/365)) 

over_10_wins <- age_slams_comb %>% 
  group_by(name, gender) %>% 
  select(name, total_wins) %>% 
  summarise(max_total_wins = max(total_wins)) %>%
  filter(max_total_wins >= 10) %>% 
  ungroup() %>% 
  group_by(gender) %>% 
  mutate(rank = dense_rank(max_total_wins)) %>% 
  ungroup()

brewer.pal(n=5, name = ""Set1"")

color_map <- data.frame(rank = c(1:5), 
                        color = c(""#E41A1c"", ""#377EB8"", ""#4DAF4A"", ""#984EA3"", ""#FF7F00""))


age_slams_rank <- left_join(age_slams_comb, over_10_wins, by = c(""name"")) 

plot_data <- age_slams_rank %>% 
  mutate(
    line_col = case_when(
      rank == ""1"" ~ ""1"", 
      rank == ""2"" ~ ""2"", 
      rank == ""3"" ~ ""3"", 
      rank == ""4"" ~ ""4"", 
      rank == ""5"" ~ ""5"",
      T ~ ""other"")
  ) 



ggplot(data = plot_data, aes(age, total_wins, group = name, col = line_col)) +
  geom_step(alpha = 0.6) +
  geom_point(data = plot_data %>% 
               group_by(name) %>% 
               filter(total_wins == max(total_wins)), 
             aes(col = line_col), size = 1.5, alpha = 0.6) +
  facet_wrap(~gender.x, nrow = 2) +
  geom_text(data = plot_data %>% 
              group_by(name) %>% 
              filter(age == max(age)) %>% 
              ungroup(),
            aes(x = age, y = total_wins,label=ifelse(total_wins > 10,name,'')),hjust= -0.1,vjust= -0.3, size = 3) +
  labs(title = ""Grand Slam victories by age"",
       x = ""Age"",
       y = ""Grand Slams won"",
       caption = ""\nData sourced from Wikipedia \nPlot by: Jose M. @Joseph_Mike"") +
  scale_x_continuous(limits = c(15,40)) +
  scale_color_manual(values = c(""#FF7F00"", ""#984EA3"", ""#4DAF4A"", ""#377EB8"", ""#E41A1c"", ""#7f7f7f"")) +
  theme(strip.text.x = element_text(size = 14, color = ""black"")) +
  theme(legend.position = ""none"") 
","2019-15"
"283",123,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_30/tidytuesday_2019_04_30.R","jmmnyc","tidytuesday","2019_04_30/tidytuesday_2019_04_30.R","library(tidyverse)
library(lubridate)
library(ggthemes)
library(extrafont)

bird_col <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

loadfonts(device = ""win"")

my_font <- ""Century Gothic""
base_color <- ""#f5f3dc""
font_color <- ""#42ac96"" # or #213549
my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0)))

theme_set(theme_light() + my_theme)

plot_data <- bird_col %>% 
  mutate(year = year(date)) %>% 
  group_by(year, habitat) %>% 
  summarise(collisions = n()) %>% 
  ungroup()

View(plot_data)

plot <- plot_data %>% 
  ggplot(aes(year, collisions, group = habitat, col = habitat)) +
  geom_line(size = 1) +
  theme(legend.position = ""top"") +
  labs(title = ""Annual trends of reported bird window collisions in Chicago (1978-2016)"",
       x = ""Year"",
       y = ""Reported collisions"",
       colour = ""Habitat"",
       caption = ""Source:  Winger et al https://doi.org/10.1098/rspb.2019.0364 \nVisiualization by Jose M @Joseph_Mike"") +
  scale_color_manual(values = c(""#FF7F00"", ""#984EA3"", ""#4DAF4A""))

ggsave(""TidyTuesday_2019_04_30.png"", dpi = ""retina"", height = 5, width = 8, units = ""in"")
","2019-18"
"284",124,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_07_30/tidytuesday_2019_07_30.R","jmmnyc","tidytuesday","2019_07_30/tidytuesday_2019_07_30.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(ggsci)
library(lubridate)

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

# Set custom ggplot theme
my_font <- ""Baskerville Old Face""

base_color <- ""#1E1F22""

font_color <- ""#CfC5AA"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 10, color = ""#6173A5""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.x = element_text(size = 12, color = '#99886F'),
                  axis.text.y = element_text(size = 12, color = '#99886F'),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_light() + my_theme)


# Top 10 Video Game publishers by number of titles
top_publishers <- video_games %>% 
  filter(!is.na(publisher),!is.na(price), !is.na(metascore),!is.na(average_playtime)) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE) %>% 
  filter(n >= 30)

# Filter for top 10 publishers
plot_data <- inner_join(video_games, top_publishers, by = ""publisher"") 


plot_data %>% 
  ggplot(aes(metascore, price)) +
  geom_point(aes(color = publisher, alpha = .8), size = 2) +
  scale_x_continuous(breaks = seq(50,100,10), limits = c(45,105)) +
  scale_color_simpsons() +
  theme(legend.position = ""none"") +
  facet_wrap(~publisher, nrow = 2) +
  theme(panel.grid.minor.x = element_blank(),
        strip.text.x = element_text(size = 8, color = ""#f7f5f5""),
        strip.background.x = element_rect(fill = ""#000000"")) +
  labs (title = ""Metascores and Average Playtimes across top Video Game Publishers"",
      subtitle = ""Top game publishers by number of titles"",
      x = ""Metascore"",
      y = ""Price"",
      caption = ""Data from Liza Wood via Steam Spy\nVisualization by Jose M @Joseph_Mike"")

data_by_year <- video_games %>% 
  filter(!is.na(publisher),!is.na(price), !is.na(metascore),!is.na(average_playtime))

metascore_avg <- data_by_year %>% 
  summarise(avg = mean(metascore, na.rm = TRUE)) %>% 
  pull(avg)

arrows <- tibble(
  x_start = c(2004,2007),
  x_end = c(2004.8,2008.5),
  y_start = c(43.5,36.5),
  y_end = c(78,72)
)


data_by_year %>% 
  mutate(year = year(mdy(release_date))) %>%
  group_by(year) %>% 
  mutate(yearly_avg = mean(metascore)) %>% 
  ungroup() %>% 
  ggplot(aes(year, metascore)) +
  geom_hline(yintercept = metascore_avg, color = ""#f3f3f3"", size = 2) +
  geom_jitter(color = '#84A6E1', alpha = .5, size = 1) +
  geom_point(aes(year, yearly_avg), shape = 21, fill = '#84A6E1', size = 6) +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank()) +
  scale_x_continuous(breaks = seq(2004,2018,1), limits = c(2003,2019)) +
  theme(legend.position = ""none"") +
  annotate(""text"", x = 2004, y = 42.5, size = 4, color = ""#f3f3f3"",
           label = paste0(""Yearly average"")) + 
  annotate(""text"", x = 2008, y = 35, size = 4, color = ""#f3f3f3"",
           label = paste0(""Overall metascore average"")) + 
  geom_curve(data = arrows, aes(x = x_start, y = y_start, xend= x_end, yend = y_end),
             arrow = arrow(length = unit(0.08, ""inch"")), size = 0.8,
             color = ""#CFC5AA"", curvature = -0.3) +
  labs (title = ""Video Game Metascore trends from 2004-2018"",
        subtitle = ""Excludes free to play games"",
        x = ""Year"",
        y = ""Metascore"",
        caption = ""Data from Liza Wood via Steam Spy\nVisualization by Jose M @Joseph_Mike"")


ggsave(""TidyTuesday_2019_07_30.png"", width = 8, height = 5,device = ""png"", type = ""cairo"")
  
  
","2019-31"
"285",125,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_19/tidytuesday_2019_03_19.R","jmmnyc","tidytuesday","2019_03_19/tidytuesday_2019_03_19.R","library(tidyverse)
library(ggthemes)
library(scales)

combined_data <- readr::read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")

View(combined_data)

my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8))

theme_set(theme_light() + my_theme)

rates_by_states <- combined_data %>% 
  filter(!is.na(location) & state != ""RI"") %>%
  select(location, state, driver_race, stop_rate, stops_per_year) %>% 
  group_by(state) %>% 
  mutate(total_state_stops = sum(stops_per_year)) %>% 
  ungroup() %>% 
  mutate(weight = stops_per_year/total_state_stops,
         weighted_stop_rate = weight * stop_rate) %>% 
  select(location, state, driver_race, weighted_stop_rate) %>% 
  spread(driver_race, weighted_stop_rate) %>% 
  group_by(state) %>% 
  summarise(Minority_stop_rate = sum(Black, na.rm = TRUE) + sum(Hispanic, na.rm = TRUE),
            White_stop_rate = sum(White, na.rm = TRUE))
  


plot <- rates_by_states %>% 
  ggplot(aes(x = Minority_stop_rate, y = White_stop_rate, label = state)) + 
  geom_point(color = ""#bc5652"",alpha = .3, size = 8) +
  geom_text(aes(label = state)) +
  geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +
  labs(title = ""Search rate of traffic stops by State"",
       subtitle = ""Points on the line represent parity across driver race"",
       caption = ""Plot: @Joseph_Mike \nData: Stanford Open Policing Project"") +
  scale_x_continuous('White search rate', limits=c(0, .35), labels = percent_format(accuracy = 1), expand=c(0,0)) + 
  scale_y_continuous('Minority search rate', limits=c(0, .35), labels = percent_format(accuracy = 1), expand=c(0,0)) +
  theme(legend.position = ""none"") +
  theme(axis.title.x = element_text(margin = margin(15,0,0,0)),
        axis.title.y = element_text(margin = margin(0,15,0,0)),
        axis.title = element_text(margin = margin (0,0,15,0)))

plot
","2019-12"
"286",126,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_04/tidytuesday_2019_06_04.R","jmmnyc","tidytuesday","2019_06_04/tidytuesday_2019_06_04.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(ggridges)
library(Cairo)
library(ggsci)

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

# Set custom ggplot theme
my_font <- ""Tempus Sans ITC""

base_color <- ""#ffffff""

font_color <- ""#b85f29"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#293042""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.y = element_text(size = 12),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_light() + my_theme)

# find countries with over 100 ramen dishes rated
top_countries <- ramen_ratings %>% 
  group_by(country) %>% 
  tally(sort = TRUE) %>% 
  filter(n >= 100, 
         !is.na(country)) %>% 
  ungroup()

# filter data for the top 11 countires
plot_data <- inner_join(ramen_ratings, top_countries, by = ""country"") %>% select(-n)

# import image of Naruto eating ramen
img <- png::readPNG(""ramen.png"")

rast <- grid::rasterGrob(img, interpolate = T)

#create plot
plot_data %>% 
  ggplot(aes(stars, reorder(country, stars, median))) +
  annotation_custom(rast, ymin = 1, ymax = 6, xmin = 5.5) +
  geom_density_ridges(scale = 2,
                      aes(fill = country),
                      color = ""#e58f1e"",
                      size = 1,
                      alpha = 0.7) + 
  theme(legend.position = ""none"") +
  scale_fill_igv() +
  scale_x_continuous(breaks = seq(0,6,1), limits = c(1,6)) +
  coord_cartesian(clip = ""off"") +
  theme(panel.grid.minor.x = element_blank()) +
  labs(title = ""Ramen rating distribution by country"",
       subtitle = ""Countries with over 100 ramen dishes reviewed"",
       x = ""Rating"",
       y = ""Country"",
       caption = ""Data from The Ramen Rater \nVisualization by Jose M @Joseph_Mike"") 

ggsave(""TidyTuesday_2019_06_04.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")
","2019-23"
"287",127,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_25/tidytuesday_2019_06_25.R","jmmnyc","tidytuesday","2019_06_25/tidytuesday_2019_06_25.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(lubridate)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

# Set custom ggplot theme
my_font <- ""Agency FB"" 

base_color <- ""#1E132C""

font_color <- ""#70cd3e"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
                  panel.border = element_blank(),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 10, color = ""#da7792""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.y = element_text(color = ""#f7f5f5"", size = 10),
                  axis.text.x = element_text(color = ""#f7f5f5"", size = 10),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_dark() + my_theme)




plot_data <- ufo_sightings %>% 
  mutate(date_time = parse_date_time(date_time, 'mdy_HM'),
         month = as.factor(month(date_time, label = TRUE)),
         year = year(date_time)) %>% 
  filter(year > 1980,
         year < 2009) %>% 
  mutate(decade = year - year%%10) %>% 
  group_by(decade, month) %>% 
  summarise(count = n()) %>% 
  ungroup() 

plot_data %>% 
  ggplot(aes(month, count)) +
  geom_col(fill = ""#eaa27c"")  +
  facet_wrap(~decade) +
  theme(panel.grid.major.x = element_blank(),
        strip.text.x = element_text(size = 14, color = ""#f7f5f5""),
        strip.background.x = element_rect(fill = ""#eaa27c"")) +
  labs(title = ""Monthly distribution of UFO sightings in last 3 decades"",
        x = ""Month"",
        y = ""UFOs sighted"",
        caption = ""Data from NUFORC\nVisualization by Jose M @Joseph_Mike"")

ggsave(""TidyTuesday_2019_06_25.png"", width = 10, height = 6,device = ""png"", type = ""cairo"")



","2019-26"
"288",128,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_28/tidytuesday_2019_05_28.R","jmmnyc","tidytuesday","2019_05_28/tidytuesday_2019_05_28.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(ggsci)


set.seed(123)

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

# Set custom ggplot theme
my_font <- ""Segoe UI Black""

base_color <- ""#f5f3dc""

font_color <- ""#331C20"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#331C20""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 10))

theme_set(theme_light() + my_theme)


# Remove duplicates
wr2 <- wine_ratings %>% 
  select(-X1) %>% 
  distinct()

# filter out NAs for country, price, and points
# select only necessary columns and view top countries
wr2 %>% 
  filter(!is.na(country),
         !is.na(price),
         !is.na(points)) %>% 
  select(country, price, points) %>% 
  group_by(country) %>% 
  tally(sort = TRUE)


# apply filters from above with additional filter on top 5 countries
# create a column for mean price for each country
# reorder countries
plot_data <- wr2 %>% 
  filter(!is.na(country),
         !is.na(price),
         !is.na(points),
         country %in% c(""US"",""France"",""Italy"",""Spain"",""Portugal"")) %>% 
  mutate(country = ifelse(country == ""US"", ""United States"", country)) %>%
  group_by(country) %>% 
  mutate(cntr_mean_price = mean(price),
         cntr_mean_points = mean(points)) %>% 
  ungroup() %>% 
  mutate(country = fct_reorder(country, cntr_mean_points))

world_avg <- wr2 %>% 
  summarise(avg = mean(points, na.rm = TRUE)) %>% 
  pull(avg)

arrows <- tibble(
  x_start = c(5.0,2.4,1.5,1.5),
  x_end = c(4.8,2,0.9,1.1),
  y_start = c(93,84,83,83),
  y_end = c(88.44,88,85,86)
)

  
plot_data %>%   
  ggplot(aes(country, points, color = country)) +
  geom_segment(aes(x = country, xend = country,
                   y = world_avg, yend = cntr_mean_points),
               size = 0.5) +
  geom_point(aes(country, cntr_mean_points), size = 4) +
  geom_jitter(size = 0.5, alpha = 0.05) +
  geom_hline(yintercept = world_avg, color = ""#2D2D2D"", size = 0.5) +
  coord_flip() +
  scale_y_continuous(limits = c(80,100), expand = c(0.005,0.005)) +
  theme(panel.grid.major.y = element_blank()) +
  scale_color_futurama() +
  theme(legend.position = ""none"") +
  annotate(""text"", x = 5.3, y = 93, size = 4, color = ""#2D2D2D"",
           label = glue::glue(""Average points rating of\n{round(world_avg,1)} across all countries"")) +
  annotate(""text"", x = 2.3, y = 84, size = 4, color = ""#2D2D2D"",
           label = paste0(""Country average"")) + 
  annotate(""text"", x = 1.6, y = 82, size = 4, color = ""#2D2D2D"",
           label = paste0(""Wines\nper country"")) + 
  geom_curve(data = arrows, aes(x = x_start, y = y_start, xend= x_end, yend = y_end),
             arrow = arrow(length = unit(0.08, ""inch"")), size = 0.5,
             color = ""#2D2D2D"", curvature = -0.3) +
  labs(title = ""Distribution of ratings for top 5 sampled countries"",
       x = """",
       y = ""Points rating (only 80 and above were scored)"",
       caption = ""Source: Kaggle \nVisualization by Jose M @Joseph_Mike"")
  
ggsave(""TidyTuesday_2019_05_28.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")

","2019-22"
"289",129,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_18/tidytuesday_2019_06_18.R","jmmnyc","tidytuesday","2019_06_18/tidytuesday_2019_06_18.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(ggsci)

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

# Set custom ggplot theme
my_font <- ""Segoe UI Black""

base_color <- ""#ffffff""

font_color <- ""#b85f29"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#293042""),
                  plot.subtitle = element_text(size = 10),
                  axis.title.x = element_text(margin = margin(20,0,0,0), size = 14),
                  axis.title.y = element_text(margin = margin(0,20,0,0), size = 14),
                  axis.text.y = element_text(size = 12),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 18))

theme_set(theme_light() + my_theme)

# Collect top 10 birds by total count
top_birds <- bird_counts %>%
  filter(year >= 2007) %>% 
  select(year, species, how_many_counted) %>% 
  group_by(species) %>% 
  summarize(count = sum(how_many_counted, na.rm = TRUE)) %>% 
  arrange(-count) %>% 
  ungroup() %>% 
  filter(count > quantile(count, .95))
  
# filter for top 10 birds
plot_data <- inner_join(filter(bird_counts, year >= 2007), top_birds, by = ""species"") %>% 
  select(-count) %>% 
  group_by(year) %>% 
  arrange(year, desc(how_many_counted)) %>% 
  mutate(rank = row_number())


plot_data %>% 
  ggplot(aes(year, rank, group = species)) +
  geom_line(aes(color = species, alpha = .9), size = 2) +
  geom_point(aes(color = species, alpha = .9), fill = ""white"", shape = 21, size = 3, stroke = 2) +
  scale_y_reverse(breaks = 1:10) +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_blank()) +
  scale_x_continuous(breaks = seq(2007,2017,1), limits = c(2007,2020)) +
  scale_color_simpsons() +
  theme(legend.position = ""none"") +
  geom_text(data = filter(plot_data, year == 2017), 
            aes(x = 2017.2, label = species, color = species), 
            size = 4, hjust = ""left"", fontface = ""bold"") +
  labs (title = ""Top 10 in the last 10"",
        subtitle = ""Species of birds counted during Christmas in Canada in the last decade"",
        x = ""Year"",
        y = ""Rank"",
        caption = ""Data from Bird Studies Canada @BirdsCanada\nVisualization by Jose M @Joseph_Mike"")

ggsave(""TidyTuesday_2019_06_18.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")
","2019-25"
"290",130,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_05_14/tidytuesday_2019_05_14.R","jmmnyc","tidytuesday","2019_05_14/tidytuesday_2019_05_14.R","
library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(lubridate)
library(ggbeeswarm)

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

my_font <- ""Lucida Sans""

base_color <- ""#f5f3dc""

font_color <- ""#42ac96"" # or #213549

my_theme <- theme(text = element_text(family = my_font, color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8, color = ""#223a4f""),
                  axis.title.x = element_text(margin = margin(20,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,20,0,0)),
                  plot.title = element_text(margin = margin(0,0,20,0), size = 14))

theme_set(theme_light() + my_theme)

plot_data <- nobel_winners %>% 
  mutate(age = prize_year - year(birth_date)) 

plot_data %>% 
  ggplot(aes(x = category, y = age, col = gender)) +
  geom_beeswarm(alpha = 0.7, size = .8) +
  coord_flip() +
  labs(title = ""Nobel prizes by Age and Gender"",
       x = ""Category"",
       y = ""Age"",
       caption = ""Source: Kaggle \nVisualization by Jose M @Joseph_Mike"",
       colour = """") +
  theme(legend.position = ""top"") +
  scale_color_manual(values = c(""#70283D"", ""#E2525B"")) 

ggsave(""TidyTuesday_2019_05_14.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")



","2019-20"
"291",131,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_16/tidytuesday_2019_04_16.R","jmmnyc","tidytuesday","2019_04_16/tidytuesday_2019_04_16.R","library(tidyverse)
library(scales)
library(ggthemes)

women_research <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")





women_research %>% 
  ggplot(aes(x = reorder(country, -percent_women), y = percent_women, group = field, fill = field)) +
  geom_point(size = 3, shape = 21, alpha = .6) +
  theme_economist() +
  geom_hline(yintercept = .5, linetype = ""dashed"", col = ""red"") +
  scale_y_continuous(labels = percent_format(accuracy = 1), limits = c(0,0.65)) +
  labs(title = ""Still a man's world..."",
       subtitle = ""Women among researchers with papers published 2011-2015"",
       y = ""% of Research papers published by Women"",
       x = ""Country"",
       caption = ""\nSource:  'Gender in the Global Research Landscape' by Elsevier; The Economist \nPlot by Jose M. @Joseph_Mike"") +
  theme(legend.position = ""top"",
        legend.title = element_blank(),
        legend.text = element_text(size = 8)) +
  scale_fill_discrete(labels = c(""computer science, math"", ""engineering"", ""health sciences"", ""physical sciences"", ""inventors"")) +
  coord_flip()
  

","2019-16"
"292",132,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_04_02/Tidytuesday_2019_04_02.R","jmmnyc","tidytuesday","2019_04_02/Tidytuesday_2019_04_02.R","library(tidyverse)
library(ggthemes)
library(lubridate)

bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

#custom theme
my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8),
                  axis.title.x = element_text(margin = margin(15,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,15,0,0)),
                  axis.title = element_text(margin = margin (0,0,15,0))
)

theme_set(theme_light() + my_theme)



View(bike_traffic)


plot_data <- bike_traffic %>% 
  mutate(date_time = mdy_hms(date),
         date_only = date(date_time),
         year = year(date_time),
         weekday = wday(date_time, label = TRUE),
         weekday_ind = ifelse(weekday %in% c(""Sat"", ""Sun""), ""Weekend"", ""Weekdays""),
         hour = hour(date_time),
         bikes = sum(bike_count, na.rm = TRUE)) %>% 
  filter(year == '2018') %>% 
  group_by(crossing, weekday_ind, hour) %>% 
  summarise(total_bikes = sum(bike_count, na.rm = TRUE))

plot <- plot_data %>% 
  ggplot(aes(x = hour, y = total_bikes/1000)) +
  geom_line(color = ""#bc5652"", size = 1) +
  facet_grid(rows = vars(crossing),
             cols = vars(weekday_ind),
             scales = ""free_y"",
             labeller = labeller(crossing = label_wrap_gen(24))) +
  theme(strip.text.x = element_text(angle = 0, hjust = 0, size = 10)) +
  theme(strip.text.y = element_text(angle = 0, hjust = 0, size = 10)) +
  scale_y_continuous(labels = scales::number_format(accuracy = 1)) +
  labs(title = ""Hourly trends of Seatle bike usage"",
       subtitle = ""2018"",
       y = ""Bike usage (in thousands)"",
       x = ""Time of day"",
       caption = ""Plot: @Joseph_Mike \nData: Seattle Department of Transportation"")
  

plot


","2019-14"
"293",133,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_02_26/tidytuesday_2019_02_26.R","jmmnyc","tidytuesday","2019_02_26/tidytuesday_2019_02_26.R","#load packages
library(tidyverse)
library(ggthemes)
library(scales)

#get data
full_trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

#create combined date field in order to chart monthly trends across years
full_trains$date <- as.Date(with(full_trains, paste(year, month, ""1"", sep = ""-"")), format = ""%Y-%m-%d"")

#transform the data to get % of trips that are late and count distinct stations
monthly_trips <- full_trains %>%
  group_by(date) %>% 
  summarise(monthly_pct_late = sum(num_late_at_departure) / sum(total_num_trips),
            stations = n_distinct(departure_station)) %>% 
  ungroup()

#plot
plot <- ggplot(monthly_trips, aes(x = date, y = monthly_pct_late)) +
  geom_line(col = ""white"", size = 1) +
  theme_dark() +
  labs(title = ""How has the % of delayed departures changed in 2018?"",
       x = """",
       y = ""% of trains delayed on departure"") +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  scale_x_date(limits = as.Date(c('2015-01-01', '2019-02-01')))

plot
","2019-9"
"294",134,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_12/tidytuesday_2019_03_12.R","jmmnyc","tidytuesday","2019_03_12/tidytuesday_2019_03_12.R","library(tidyverse)
library(ggthemes)

board_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")


#set parameters
number_of_players <- 4
average_play_time <- 15
top_n_games <- 15

#filter the data
test_group <- board_games %>% 
  filter(min_players >= number_of_players & number_of_players <= max_players) %>% 
  filter(playing_time <= average_play_time) %>% 
  arrange(-average_rating) %>% 
  filter(users_rated >= 100) %>% #filter to games with over 100 user ratings
  head(n = top_n_games)

#create a custom theme
my_font <- ""Avenir""
base_color <- ""#faf7ec""
font_color <- ""#399694""  # or ""#213549"" ""#42ac96"" 
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8))

theme_set(theme_light() + my_theme)

#plot
ggplot(test_group, aes(x = reorder(name, average_rating), y = average_rating)) +
  geom_col(fill = ""#c79966"") +
  coord_flip() +
  theme(legend.position = ""none"") +
  labs(title = ""Highest rated games \nfor 4-players and avg. play time <= 15 minutes"",
       x = """",
       y = ""Avg. Rating"",
       caption = ""Plot by: @Joseph_Mike\n Data:  Board Game Geek"") +
  scale_y_continuous(breaks = c(0,2,4,6,8,10), limits = c(0,10))","2019-11"
"295",135,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_03_26/tidytuesday_2019_03_26.R","jmmnyc","tidytuesday","2019_03_26/tidytuesday_2019_03_26.R","library(tidyverse)
library(lubridate)
library(ggthemes)

#read data
seattle_pets <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")

#custom theme
my_font <- ""Verdana""
base_color <- ""#faf7ec""
font_color <- ""#399694""
my_theme <- theme(text = element_text(family = my_font, face = ""bold"" ,color = font_color),
                  rect = element_rect(fill = base_color, color = NA), 
                  plot.background = element_rect(fill = base_color, color = NA), 
                  panel.background = element_rect(fill = base_color, color = NA), 
                  panel.border = element_blank(),
                  legend.background = element_rect(fill = base_color, color = NA),
                  legend.key = element_rect(fill = base_color),
                  plot.caption = element_text(size = 8),
                  axis.title.x = element_text(margin = margin(15,0,0,0)),
                  axis.title.y = element_text(margin = margin(0,15,0,0)),
                  axis.title = element_text(margin = margin (0,0,15,0))
                  )

theme_set(theme_light() + my_theme)

#structure of data
str(seattle_pets)

#have a look at the data
head(seattle_pets)

#transform data that will be used for the plot
seattle_pets$date <- floor_date(mdy(seattle_pets$license_issue_date), ""month"")

plot_data <- seattle_pets %>% 
  filter(species %in% c(""Cat"", ""Dog""), !is.na(animals_name), !is.na(zip_code), date >= '2015-01-01') %>% 
  group_by(species, date) %>% 
  summarise(pet_count = n()) 

ggplot(plot_data, aes(x = date, y = pet_count, col = species)) +
  geom_line() +
  labs(title = ""Monthly pet registration trends in Seattle"",
       x = """",
       y = ""Number of pets registered"",
       caption = ""Plot: @Joseph_Mike \nData: Seattle's Open Data Portal"") +
  theme(legend.position = ""top"", legend.title = element_blank())
  
","2019-13"
"296",136,"https://github.com/jmmnyc/tidytuesday/blob/master/2019_06_11/tidytuesday_2019_06_11.R","jmmnyc","tidytuesday","2019_06_11/tidytuesday_2019_06_11.R","library(extrafont)

loadfonts(device = ""win"")

library(tidyverse)
library(ggthemes)
library(Cairo)
library(cowplot)


meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

# find the year with the most meotorites
meteorites %>% 
  group_by(year) %>%
  tally(sort = T)

# filter for 2003
plot_data <- meteorites %>% filter(year == 2003)

# plot colors
plot_base <- ""#272238""

land_mass <- ""#8dc6d1""

land_border <- ""#388089""

meteor_points <- ""#ef601f""

# font and font color
my_font <- ""Agency FB"" 

font_color <- ""#f1e1b0"" 

# Initial plot
world_view <- plot_data %>% 
  ggplot() +
  borders(""world"", col = land_border, fill = land_mass, size = .1) +
  theme_map() +
  theme(text = element_text(family = my_font, color = font_color, face = ""bold""),
        plot.caption = element_text(size = 12),
        plot.subtitle = element_text(size = 16),
        plot.title = element_text(margin = margin(0,0,20,0), size = 22)) +
  coord_map(projection = ""mollweide"", orientation = c(90, 0, 0)) +
  geom_point(aes(x = long, y = lat, size = log(mass)), 
             size = 2, 
             alpha = .15,  
             fill = meteor_points,
             shape = 21) +
  labs(title = ""Where did most meteorites fall in 2003?"",
       subtitle = ""The year with the highest meteorite count"",
       caption = ""Data from NASA \nVisualization by Jose M @Joseph_Mike"")

ggdraw(world_view) +
  theme(
    plot.background = element_rect(fill = plot_base),
    panel.background = element_rect(fill = plot_base, color = plot_base),
    plot.margin = unit(c(.2, .2, .2, .2), ""cm"")
  ) 

ggsave(""TidyTuesday_2019_06_11.png"", width = 10, height = 6.5,device = ""png"", type = ""cairo"")","2019-24"
"297",137,"https://github.com/bvreede/tidytuesdays/blob/master/20190813_emperors/emperors.R","bvreede","tidytuesdays","20190813_emperors/emperors.R","library(readr)
library(dplyr)
library(magrittr)
library(stringr)
library(lubridate)
library(ggplot2)
library(RColorBrewer)

emperors <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

BCEtransform <- function(date,BCE){
  # transform a positive BCE date to a negative
  # only when BCE is TRUE
  # NB: the year 0000 does not exist; this was the year 1 BCE
  # but the data has taken this into account already
  # and emperors born in BCE have an adjusted year (eg born in 63BCE is 62 in the data)
  if(BCE){
  yr = as.numeric(format(date, ""%Y""))
  date = date - years(2*yr)
  }
  return(date)
}

emperors %<>% mutate(bce_birth = ifelse(!is.na(notes),
                                        # if BCE is mentioned, birth years are BCE
                                        ifelse(str_detect(notes,""BCE""),T,F),
                                        F),
                     birth_corrected = as_date( # weirdly, the date object is not returned as a date
                       mapply(BCEtransform,birth,bce_birth)),
                     # same for reign
                     bce_reign = ifelse(!is.na(notes),
                                        # if ""reign.start are BCE"" is mentioned, reign start is BCE (one guy but still)
                                        ifelse(str_detect(notes,""reign.start are BCE""),T,F),
                                        F),
                     reign_start_corrected = as_date(
                       mapply(BCEtransform,reign_start,bce_reign))
                     )

# express years in age/duration
emperors %<>% mutate(
  ## age at start reign
  age_reign_start = as.numeric(reign_start_corrected-birth_corrected)/365.25,
  ## age at end reign
  age_reign_end = as.numeric(reign_end-birth_corrected)/365.25,
  ## age at death
  age_death = as.numeric(death-birth_corrected)/365.25,
  # reign duration
  reign_duration = as.numeric(reign_end-reign_start_corrected)/365.25
)

# change levels to highest death count first
cause_level <- count(emperors,cause,sort=T)
emperors$cause <- factor(emperors$cause, levels = rev(cause_level$cause))

# adjust esthetics of plot
theme_set(theme_light(base_size = 12, base_family = ""Courier""))
cscale_killer <- c(brewer.pal(8,""Spectral""),brewer.pal(5,""BuPu"")[2:5],brewer.pal(4,""PiYG""))
cscale_rise <- cscale_killer[c(1,3,4,7,8,10,12,13)]


# make plots
emperors %>%
  ggplot(aes(x = cause, y = age_death)) +
  geom_jitter(aes(size = reign_duration, color=killer), width=0.2) +
  scale_colour_manual(values=cscale_killer) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Death to Roman Emperors"",
       y = ""Age at death (years)"",
       x = ""Cause of death"",
       size = ""Duration of reign"",
       color = ""Killed by"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 


emperors %>%
  ggplot(aes(x = cause, y = age_death)) +
  geom_jitter(aes(size = reign_duration, color=rise), width=0.2) +
  scale_colour_manual(values=cscale_rise) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Rise and fall of Roman Emperors"",
       y = ""Age at death (years)"",
       x = ""Cause of death"",
       size = ""Duration of reign"",
       color = ""Rise to power"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 


emperors %>%
  ggplot(aes(x = cause, y = reign_duration)) +
  geom_jitter(aes(size = age_death, color=rise), width=0.2, alpha=0.7) +
  scale_colour_manual(values=cscale_rise) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Rise and fall of Roman Emperors"",
       size = ""Age at death (years)"",
       x = ""Cause of death"",
       y = ""Duration of reign"",
       color = ""Rise to power"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 

# change levels to highest rise to power-count first
rise_level <- count(emperors,rise,sort=T)
emperors$rise <- factor(emperors$rise, levels = rev(rise_level$rise))

emperors %>%
  ggplot(aes(x = rise, y = reign_duration)) +
  geom_jitter(aes(size = age_death, color=cause), width=0.2, alpha=0.7) +
  scale_colour_manual(values=cscale_rise) +
  coord_flip() +
  theme(panel.grid.major.x = element_line(linetype=""dotted"",color=""darkgrey""),
        panel.grid.minor.x = element_line(linetype=""dotted"",color=""lightgrey""),
        axis.ticks.y = element_blank(),
        axis.ticks.x = element_blank(),
        plot.caption = element_text(size = 8, color = ""darkgrey"")
  ) +
  labs(title = ""Rise and fall of Roman Emperors"",
       size = ""Age at death (years)"",
       color = ""Cause of death"",
       y = ""Duration of reign"",
       x = ""Rise to power"",
       caption = ""data: Wikipedia / credit: Georgios Karamanis"") 
","2019-33"
"298",178,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-02_media-franchises","jmcastagnetto","tidytuesday-kludges","2019-07-02_media-franchises/01-get-data-process-and-plot.R","library(tidyverse)

# get the data
media_franchises <- read_csv(
  ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"",
  col_types = ""ccdiccc""
)

# store it locally
save(
  media_franchises,
  file = here::here(""2019-07-02_media-franchises/data/media_franchises.Rdata"")
)

# prepare it for plotting
df <- media_franchises %>%
  mutate(
    decade = as.factor((year_created %/% 10) * 10)
  ) %>%
  group_by(decade, revenue_category) %>%
  summarise(
    total_revenue = sum(revenue)
  ) %>%
  ungroup() %>%
  group_by(decade) %>%
  mutate(
    pct_revenue = total_revenue / sum(total_revenue)
  ) %>%
  ungroup() %>%
  select(-total_revenue)

# simple comparison plot
ggplot(df, aes(x = decade, y = pct_revenue, fill = revenue_category)) +
  geom_col() +
  scale_fill_viridis_d(name = ""Revenue\nCategory"", option = ""inferno"") +
  scale_y_continuous(labels = scales::percent) +
  scale_x_discrete(limits = rev(levels(df$decade))) +
  labs(
    x = """",
    y = """",
    title = ""Share of revenue per category over the decades"",
    subtitle = ""#tidytuesday: 'Media Franchises' (2019-07-02)"",
    caption = ""Jesus Castagnetto (@jmcastagnetto), 2019""
  ) +
  #theme_minimal() +
  ggthemes::theme_clean() +
  theme(
    legend.position = ""bottom"",
    legend.text = element_text(size = 7),
    legend.title = element_text(size = 7),
    legend.background = element_blank(),
    plot.background = element_blank(),
    plot.caption = element_text(face = ""italic"",
                                size = 8,
                                color = ""grey30""
                          )
  ) +
  guides (
     fill = guide_legend(nrow = 3, byrow = TRUE)
  ) +
  coord_flip()

# save the plot
ggsave(
  here::here(
    ""2019-07-02_media-franchises"",
    ""20190702-tidytuesday-media-franchises-category-decades.png""
  )
)


","2019-27"
"299",179,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-02_media-franchises","jmcastagnetto","tidytuesday-kludges","2019-07-02_media-franchises/02-radar.R","library(tidyverse)
library(gganimate)
library(ggiraph)
library(ggiraphExtra)

load(here::here(""2019-07-02_media-franchises/data/media_franchises.Rdata""))

df <- media_franchises %>%
  mutate(
    Decade = as.factor((year_created %/% 10) * 10)
  ) %>%
  group_by(Decade, revenue_category) %>%
  summarise(
    total_revenue = sum(revenue)
  ) %>%
  ungroup() %>%
  group_by(Decade) %>%
  mutate(
    pct_revenue = total_revenue / sum(total_revenue)
  ) %>%
  select(-total_revenue) %>%
  pivot_wider(
    id_cols = Decade,
    names_from = revenue_category,
    values_from = pct_revenue,
    values_fill = list(pct_revenue = 0)
  )

radar_chart <- ggRadar(data = df,
       mapping = aes(
         color = Decade),
       interactive = FALSE, horizontal = TRUE,
       size = 1) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent) +
  theme(
    axis.text.x = element_text(size = 10),
    legend.position = ""none""
  ) +
  labs(
    title = ""Change in revenue distribution for media franchises"",
    subtitle = ""Decade: {closest_state}"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  transition_states(Decade) +
  ease_aes(""linear"")

radar_chart

anim_save(
  filename  = here::here(""2019-07-02_media-franchises/radar-chart.gif""),
  animation = radar_chart
)
","2019-27"
"300",180,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/01-get-data.R","# library(tidyverse)

# bird_impacts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/bird_impacts.csv"") %>%
#   mutate(
#     phase_of_flt = str_to_lower(phase_of_flt),
#     damage = replace_na(damage, ""U"") # unknown
#   )
#
# save(
#   bird_impacts,
#   file = here::here(""2019-07-23_bird-impacts/data/bird_impacts.Rdata"")
# )

# data dictionary
download.file(
  ""https://wildlife.faa.gov/downloads/fieldlist.xls"",
  destfile = here::here(""2019-07-23_bird-impacts/data/fieldlist.xls"")
)

# original data in MS Access Format
download.file(
  ""https://wildlife.faa.gov/downloads/wildlife.zip"",
  destfile = here::here(""2019-07-23_bird-impacts/data/wildlife.zip"")
)

# see README.md for command line processing of the database","2019-30"
"301",181,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/02-process-data.R","library(readr)
library(janitor)
library(dplyr)

bird_strikes <- read_csv(
  here::here(""2019-07-23_bird-impacts/data/strike_reports-1990_current.csv.gz"")
) %>%
  clean_names() %>%
  select(incident_date:faaregion,
         opid, operator, atype, ac_class, ac_mass,
         num_engs, type_eng,
         height, speed, phase_of_flt,
         damage, effect,
         species, birds_seen, birds_struck, size,
         sky, precip,
         cost_repairs_infl_adj,
         nr_injuries, nr_fatalities) %>%
  mutate(
    state = replace_na(state, ""UNK""),
    damage = replace_na(damage, ""U""),
    phase_of_flt = str_to_sentence(phase_of_flt),
    size = na_if(size, ""#N/A"") %>%
      replace_na(., ""Unknown"") %>%
      str_to_title(.),
    time_of_day = replace_na(time_of_day, ""Unknown"") %>%
      str_to_title(.),
    species = replace_na(species, ""Unknown"") %>% str_to_title(.),
    birds_struck = replace_na(birds_struck, ""Unknown""),
    operator_type = case_when(
      opid == ""MIL"" ~ ""Military"",
      opid == ""GOV"" ~ ""Government"",
      opid == ""BUS"" ~ ""Business"",
      opid == ""PVT"" ~ ""Private"",
      TRUE ~ ""Commercial""
    )
  )

save(
  bird_strikes,
  file = here::here(""2019-07-23_bird-impacts/data/bird_strikes.Rdata"")
)
","2019-30"
"302",182,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/03-plot-heatmap-and-movie.R","library(tidyverse)
library(rayshader)

load(
  here::here(""2019-07-23_bird-impacts/data/bird_strikes.Rdata"")
)

tmp_df <- bird_strikes %>%
  mutate(
    op_type_binary = ifelse(operator_type == ""Commercial"",
                            operator_type,
                            ""Non commercial""),
    size = forcats::fct_infreq(size, ordered = TRUE),
    operator_type = forcats::fct_infreq(operator_type,
                                        ordered = TRUE),
  )

p1 <- ggplot(tmp_df , aes(x = incident_date, y = operator_type)) +
  geom_bin2d() +
  theme_minimal() +
  labs(
    title = ""Distribution of wildlife strikes 1990-2019"",
    subtitle = ""Source: FAA Wildlife Strike database, #Tidytuesday, 2019-07-23"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)"",
    x = ""Incident date"",
    y = ""Aircraft operator type"",
    fill = ""Impacts""
  ) +
  scale_fill_viridis_c(option = ""plasma"", direction = -1) +
  facet_grid(time_of_day~size)

ggsave(
  plot = p1,
  filename  = here::here(""2019-07-23_bird-impacts/wildlife-strikes-heatmap.png""),
  width = 12, height = 8, units = ""in""
)

options(
  cores = 3
)

plot_gg(p1,
        multicore=TRUE,
        width=5,
        height=5,
        scale=250)

render_movie(
  filename = here::here(""2019-07-23_bird-impacts/wildlife-strikes-heatmap.mp4"")
)
","2019-30"
"303",183,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-07-23_bird-impacts","jmcastagnetto","tidytuesday-kludges","2019-07-23_bird-impacts/04-plot-usmap-yearly-heatmap.R","library(maps)
library(tidyverse)
library(rayshader)

us_states <- map_data(""state"")

load(
  here::here(""2019-07-23_bird-impacts/data/bird_strikes.Rdata"")
)

states_df <- data.frame(
  abb = state.abb,
  name = state.name
)

bystate_yr_df <- bird_strikes %>%
  group_by(incident_year, state) %>%
  summarise(
    impacts = n()
  ) %>%
  left_join(
    states_df,
    by = c(""state"" = ""abb"")
  ) %>%
  left_join(
    us_states %>%
      mutate(region = str_to_title(region)) %>%
      select(-subregion),
    by = c(""name"" = ""region"")
  ) %>%
  filter(
    !is.na(group)
  ) # removes Canada, Puerto Rico, Virgin Islands, and non-contiguous


p2 <- ggplot(data = bystate_yr_df) +
  geom_polygon(aes(x = long, y = lat,
                   fill = impacts, group = group),
               color = ""white"") +
  coord_fixed(1.3) +
  scale_fill_viridis_c(option = ""plasma"", direction = -1) +
  labs(
    title = ""Yearly wildlife strikes frequency in the contiguous USA"",
    subtitle = ""Source: FAA Wildlife Strike database, #Tidytuesday, 2019-07-23"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  theme_void() +
  theme(
    legend.position = ""bottom"",
    plot.margin = unit(c(1,1,1,1), ""cm"")
  ) +
  facet_wrap(~incident_year, ncol = 6)

ggsave(
  plot = p2,
  filename  = here::here(""2019-07-23_bird-impacts/wildlife-strikes-usamap.png""),
  width = 12, height = 8, units = ""in""
)

options(
  cores = 3
)

plot_gg(p2,
        multicore=TRUE,
        width=5,
        height=5,
        scale=250)

render_movie(
  filename = here::here(""2019-07-23_bird-impacts/wildlife-strikes-usamap.mp4""),
  phi = 70
)
","2019-30"
"304",184,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/01-get-data.R","library(tidyverse)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

predecessor <- function(idx, df) {
  emp_df <- df  %>% filter(index == idx)
  pred_df <- df %>%
    filter(index < idx) %>%
    arrange(desc(index)) %>%
    mutate(
      diff_days = int_length(
        interval(reign_end, emp_df$reign_start)
      ) / (3600 * 24)
    ) %>%
    filter(diff_days >= -1) %>%
    filter(diff_days == min(diff_days)) %>%
    select(-diff_days)
  pred_df$index
}

df <- emperors %>%
  mutate(
    prev_reign_end = lag(reign_end),
    interv_days = int_length(
                    interval(prev_reign_end, reign_start)
                  ) / (3600 * 24),
    prev_emperor = sapply(index, predecessor, .) %>%
      str_replace(""c\\("", """") %>%
      str_replace(""\\)"", """"),
    prev_emperor = ifelse(index == 1, NA, prev_emperor)
  ) %>%
  separate_rows(
    prev_emperor
  ) %>%
  select(
    index,
    name,
    rise,
    reign_start,
    reign_end,
    cause,
    killer,
    dynasty,
    era,
    interv_days,
    prev_emperor
  )

save(
  df,
  emperors,
  file = here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
)


# how many have interr_days >= -1
sum(df$interv_days >= -1, na.rm = TRUE)

# what % is that?
sum(df$interv_days >= -1, na.rm = TRUE) / nrow(df)
","2019-33"
"305",185,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/02-igraph-viz.R","library(tidyverse)
library(igraph)

load(
  here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
)

# Using igraph

links_df <- df %>%
  filter(index > 1) %>%
  mutate(
    link_label = paste0(""("", cause, "", "", rise, "")"")
  ) %>%
  rename(
    from = prev_emperor,
    to = index
  ) %>%
  select(
    from,
    to,
    link_label
  )

nodes_df <- emperors %>%
  mutate(
    node_label = paste0(""Name: "", name,
                        ""\nDynasty: "", dynasty,
                        ""\nEra: "", era),
    shape = ifelse(
      era == ""Principate"",
      ""square"",
      ""circle""
    )
  ) %>%
  select(
    index,
    name,
    node_label,
    shape,
    cause,
    era,
    dynasty
  )

g <- graph_from_data_frame(links_df,
                           vertices = nodes_df,
                           directed = TRUE)


set.seed(1453)
graph_attr(g, ""layout"") <- layout_with_graphopt
plot(
  g,
  vertex.label = V(g)$name,
  vertex.label.cex = 1,
  vertex.label.dist = 1,
  vertex.size = 5,
  vertex.label.color = ""black"",
  vertex.shape = V(g)$shape,
  vertex.color = NA,
  vertex.frame.color = as.factor(V(g)$cause),
  edge.arrow.size = 0.05,
  edge.curved = 0.3,
  main = ""A network of Roman emperors (#TidyTuesday, 2019-08-13)"",
  sub = ""@jmcastagnetto / Jesus M. Castagnetto""
)

set.seed(1453)
clp <- cluster_infomap(g)
graph_attr(g, ""layout"") <- layout_with_graphopt
plot(
  clp,
  g,
  vertex.label = V(g)$name,
  vertex.label.cex = 1,
  vertex.label.dist = 1,
  vertex.size = 5,
  vertex.label.color = ""black"",
  vertex.shape = V(g)$shape,
  vertex.color = NA,
  vertex.frame.color = as.factor(V(g)$cause),
  edge.arrow.size = 0.05,
  edge.curved = 0.3,
  main = ""A network of Roman emperors (#TidyTuesday, 2019-08-13)"",
  sub = ""@jmcastagnetto / Jesus M. Castagnetto""
)
","2019-33"
"306",186,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/03-ggraph-viz.R","library(tidyverse)
library(igraph)
library(ggraph)

load(
  here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
)

links_df <- df %>%
  filter(index > 1) %>%
  mutate(
    link_label = paste0(""("", cause, "", "", rise, "")"")
  ) %>%
  rename(
    from = prev_emperor,
    to = index
  ) %>%
  select(
    from,
    to,
    link_label
  )

nodes_df <- emperors %>%
  mutate(
    node_label = paste0(""Name: "", name,
                        ""\nDynasty: "", dynasty,
                        ""\nEra: "", era),
    shape = ifelse(
      era == ""Principate"",
      ""square"",
      ""circle""
    )
  ) %>%
  select(
    index,
    name,
    node_label,
    shape,
    cause,
    era,
    dynasty
  )

g <- graph_from_data_frame(links_df,
                           vertices = nodes_df,
                           directed = TRUE)


# Using ggraph
set.seed(1453)
ggraph(g, layout = ""graphopt"") +
  geom_edge_link2(
    arrow = grid::arrow(ends = ""last"",
                        type = ""open"",
                        length = unit(.8, ""cm""))) +
  geom_node_label(aes(label = name,
                      color = as.factor(dynasty))) +
  labs(
    title = ""A network of roman emperors"",
    subtitle = ""#TidyTuesday, dataset from 2019-08-13"",
    caption = ""@jmcastagnetto / Jesus M. Castagnetto"",
    color = ""Dynasty""
  ) +
  theme_void() +
  theme(

    plot.margin = unit(rep(.5, 4), ""cm""),
  )

","2019-33"
"307",187,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-13_roman-emperors","jmcastagnetto","tidytuesday-kludges","2019-08-13_roman-emperors/04-visnetwork-viz.R","library(tidyverse)
  library(visNetwork)

  load(
    here::here(""2019-08-13_roman-emperors/emperors.Rdata"")
  )

  # Using visNetwork
  links_df <- df %>%
    mutate(
      cause_prev_emperor = lag(cause, 1),
      label = paste(""by"", cause_prev_emperor)
    ) %>%
    filter(index > 1) %>%
    rename(
      from = prev_emperor,
      to = index
    ) %>%
    select(
      from,
      to,
      label
    ) %>%
    mutate(
      font.color = ""red"",
      font.size = 10,
      arrows = ""to""
    )

  nodes_df <- emperors %>%
    mutate(
      label = name,
      group = dynasty,
      title = paste0(""Name: "", name,
                     ""<br/>Dynasty: "", dynasty,
                     ""<br/>Era: "", era,
                     ""<br/>Rise by: "", rise,
                     ""<br/>End by: "",cause),
      shape = ifelse(
        era == ""Principate"",
        ""square"",
        ""triangle""
      )
    ) %>%
    rename(
      id = index
    ) %>%
    select(
      id,
      label,
      title,
      shape,
      group,
      dynasty
    ) %>%
    mutate(
      value = 2
    )

vn <- visNetwork(nodes_df, links_df,
                   main = ""A Network of Roman Emperors"",
                   submain = ""#TidyTuesday, using the 2019-08-13 dataset"",
                   footer = ""@jmcastagnetto (Jesus M. Castagnetto)"",
                   width = 800,
                   height = 600) %>%
    visGroups() %>%
    visOptions(
      highlightNearest = list(
        enabled = TRUE,
        degree = 1,
        hover = TRUE),
      selectedBy = ""dynasty""
    ) %>%
    visInteraction(
      navigationButtons = TRUE
    ) %>%
    visLayout(
      randomSeed = 1453
    )


htmlwidgets::saveWidget(
    vn,
    file = here::here(""2019-08-13_roman-emperors/visnetwork-interactive.html""))

","2019-33"
"308",188,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-06-25_ufo-sightings","jmcastagnetto","tidytuesday-kludges","2019-06-25_ufo-sightings/01-getdata.R","library(tidyverse)
library(lubridate)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

ufo_sightings <- ufo_sightings %>%
  mutate(
    date_time = mdy_hm(date_time)
  )

save(ufo_sightings, file = here::here(""2019-06-25_ufo-sightings/data/ufo_sightings.Rdata""))
","2019-26"
"309",189,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-06-25_ufo-sightings","jmcastagnetto","tidytuesday-kludges","2019-06-25_ufo-sightings/02-tmap-animation.R","library(tidyverse)
library(lubridate)
library(tmap)
library(tmaptools)
library(countrycode)

load(here::here(""2019-06-25_ufo-sightings/data/ufo_sightings.Rdata""))

data(""World"")

ufo <- World %>%
  inner_join(
    ufo_sightings %>%
      mutate(
        iso3 = countrycode(country, ""iso2c"", ""iso3c"")
      ) %>%
      group_by(year(date_time), iso3) %>%
      summarise(
        n = n()
      ) %>%
      rename(
        yr = 1
      ),
    by = c(""iso_a3"" = ""iso3"")
  ) %>%
  arrange(
    yr, iso_a3
  )

yrs <- unique(ufo$yr)
countries <- World %>%
  filter(iso_a3 %in% ufo$iso_a3)

breaks <- seq(0, 7000, by = 1000)

mk_tmap_anim <- function(basemap, df, breaks, years) {
  df <- subset(df, yr %in% years)
  fname <- paste0(""animation_"", min(years), ""-"", max(years), "".gif"")
  map1 <- tm_shape(basemap) +
    tm_polygons(NA) +
    tm_shape(df) +
    tm_polygons(""n"", breaks = breaks, title = ""Number of sightings"") +
    tm_facets(along = ""yr"", free.coords = FALSE, free.scales = FALSE)
  tmap_animation(map1,
                 filename = here::here(""2019-06-25_ufo-sightings/"", fname))
}

mk_tmap_anim(countries, ufo, breaks, yrs[1:20])
mk_tmap_anim(countries, ufo, breaks, yrs[21:40])
mk_tmap_anim(countries, ufo, breaks, yrs[41:60])
mk_tmap_anim(countries, ufo, breaks, yrs[61:83])

# small multiples (static) from 2011-2014 (for twitter)
multmap <- tm_shape(countries) +
  tm_polygons(NA) +
  tm_shape(ufo %>% filter(yr %in% yrs[80:83])) +  # 2011-2014
  tm_polygons(""n"", breaks = breaks, title = ""Number of sightings"") +
  tm_facets(by = ""yr"", free.coords = FALSE, free.scales = FALSE, ncol = 2) +
  tm_layout(legend.position = c(""right"", ""bottom""))

tmap_save(multmap,
          filename = here::here(""2019-06-25_ufo-sightings/tmap-facets-ufo-sightings.png""),
          width = 1200, height = 600)

","2019-26"
"310",190,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-06_bob-ross-paintings","jmcastagnetto","tidytuesday-kludges","2019-08-06_bob-ross-paintings/01-word-cloud.R","library(fivethirtyeight)
library(tidyverse)
library(ggwordcloud)

data(""bob_ross"")

bob_ross <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer) %>%
  select(-episode_num)

# modified from http://www.sthda.com/english/wiki/word-cloud-generator-in-r-one-killer-function-to-do-everything-you-need
mk_text_df <- function(txt, lang = ""en"") {
  library(tm)
  library(SnowballC)

  # Load the text as a corpus
  docs <- Corpus(VectorSource(txt))
  # Convert the text to lower case
  docs <- tm_map(docs, content_transformer(tolower))
  # Remove numbers
  docs <- tm_map(docs, removeNumbers)
  # Remove stopwords for the language
  docs <- tm_map(docs, removeWords, stopwords(lang))
  # Remove punctuations
  docs <- tm_map(docs, removePunctuation)
  # Eliminate extra white spaces
  docs <- tm_map(docs, stripWhitespace)
  # stemming
  docs <- tm_map(docs, stemDocument)
  tdm <- TermDocumentMatrix(docs)
  m <- as.matrix(tdm)
  v <- sort(rowSums(m),decreasing=TRUE)
  df <- tibble(word = names(v),freq=v)
  return(df)
}

set.seed(19421129) # Bob Ross's birth date

br_titles_df <- mk_text_df(paste(bob_ross$title, collapse = "" "")) %>%
  mutate(
    angle = 90 * sample(c(0, 1), n(), replace = TRUE, prob = c(60, 40))
  )

wp <- ggplot(br_titles_df, aes(label = word, size = freq,
                         color = freq, angle = angle)) +
  geom_text_wordcloud_area(rm_outside = TRUE, shape = ""square"") +
  scale_size_area(max_size = 24) +
  scale_color_viridis_c(option = ""cividis"", direction = -1) +
  labs(
    title = ""Bob Ross loved mountainscapes and winter"",
    subtitle = ""#tidytuesday, 2019-08-06"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  theme_minimal()

ggsave(
  filename = here::here(""2019-08-06_bob-ross-paintings/wordcloud.png""),
  plot = wp,
  width = 12,
  height = 12,
  units = ""cm""
)
","2019-32"
"311",191,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-06_bob-ross-paintings","jmcastagnetto","tidytuesday-kludges","2019-08-06_bob-ross-paintings/02-elements-by-season.R","library(fivethirtyeight)
library(tidyverse)

data(""bob_ross"")

bob_ross <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer) %>%
  select(-episode_num)

br_elements <- bob_ross %>%
  select(-episode, -title, -season) %>%
  pivot_longer(
    cols = apple_frame:wood_framed,
    names_to = ""element"",
    values_to = ""freq""
  ) %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  ungroup(element) %>%
  mutate(
    element = ifelse(freq < 5, ""** Other"", element)
  ) %>%
  filter(element != ""** Other"") %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  arrange(
    element
  )

valid_elements <- br_elements$element

br_elements_season <- bob_ross %>%
  select(-episode, -title) %>%
  group_by(season) %>%
  mutate_at(
    vars(-group_cols()),
    sum
  ) %>%
  distinct() %>%
  pivot_longer(
    cols = c(-1),
    names_to = ""element"",
    values_to = ""freq""
  ) %>%
  mutate(
    element = ifelse(element %in% valid_elements,
                     element, ""** Other"") %>%
      str_replace_all(""_"", "" "") %>%
      str_to_title() %>%
      forcats::fct_rev()
  )

hm <- ggplot(br_elements_season,
             aes(x = as.factor(season), y = element)) +
  geom_tile(aes(fill = freq)) +
  scale_fill_viridis_c(""Frequency"", option = ""magma"", direction = -1) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_x_discrete(expand = c(0, 0)) +
  labs(
    x = ""Season"",
    y = """",
    title = ""Bob Ross was very consistent in the elements he used"",
    subtitle = ""#tidytuesday, 2019-08-06\nelements with a total frequency < 5 are categorized as '** Other'"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    legend.position = c(0.2, -0.05),
    legend.direction = ""horizontal"",
    legend.key.width = unit(1.5, ""cm""),
    legend.text = element_text(size = 8),
    plot.margin = unit(rep(1, 4), ""cm"")
  )
hm
ggsave(
  filename = here::here(""2019-08-06_bob-ross-paintings/heatmap-elements.png""),
  plot = hm,
  width = 12,
  height = 12
)
","2019-32"
"312",192,"https://github.com/jmcastagnetto/tidytuesday-kludges/tree/master/2019-08-06_bob-ross-paintings","jmcastagnetto","tidytuesday-kludges","2019-08-06_bob-ross-paintings/03-circular-barchart.R","# adapted from https://www.r-graph-gallery.com/circular-barplot.html

library(fivethirtyeight)
library(tidyverse)
library(cowplot)

data(""bob_ross"")

br_elements <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer) %>%
  select(-episode_num) %>%
  select(-episode, -title, -season) %>%
  pivot_longer(
    cols = apple_frame:wood_framed,
    names_to = ""element"",
    values_to = ""freq""
  ) %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  ungroup(element) %>%
  mutate(
    element = ifelse(freq < 5, ""** Other"", element) %>%
      str_replace_all(""_"", "" "") %>%
      str_to_title()
  ) %>%
  group_by(element) %>%
  summarise(
    freq = sum(freq)
  ) %>%
  ungroup() %>%
  mutate(
    element = paste0(element,""\n(N = "", freq, "")"") %>%
              forcats::fct_reorder(freq)
  )

br_elements$id <- seq(1, nrow(br_elements))
angle <-  90 - (360 * (br_elements$id - 0.5) / nrow(br_elements))
br_elements$hjust <- as.numeric(angle < -90)
br_elements$angle <- angle

cb <- ggplot(br_elements,
       aes(x = element, y = freq)) +
  geom_segment(aes(x = element, xend = element,
                   y = 0, yend = 375),
               color = ""lightgrey"", size = .25,
               linetype = ""dashed"") +
  geom_col(aes(fill = element), width = 1) +
  labs(
    x = """",
    y = """",
    title = ""Frequency of elements in Bob Ross's paintings"",
    subtitle = ""#tidytuesday, 2019-08-06\nelements with a total frequency < 5 are categorized as '** Other'\nbar height in log10 scale"",
    caption = ""@jmcastagnetto (Jesus M. Castagnetto)""
  ) +
  scale_fill_viridis_d(option = ""vidiris"") +
  scale_y_log10() + # no reason, except that it looks nicer and colorful
  theme_minimal() +
  theme(
    legend.position = ""none"",
    axis.text.y = element_blank(),
    axis.text.x = element_text(angle = br_elements$angle, size = 9),
    axis.title = element_blank(),
    panel.grid = element_blank(),
  ) +
  coord_polar(start = 0)

ggsave(
  filename = here::here(""2019-08-06_bob-ross-paintings/circular-barchart-elements.png""),
  plot = cb,
  width = 12,
  height = 12
)
","2019-32"
"313",317,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2018/2018-09-04/readme.rmd","# Fast food entree data

* Data from [fastfoodnutrition.com](https://fastfoodnutrition.org/mcdonalds/chart) 
* Please notice that I really only took entrees - feel free to select ALL food, sides, drinks, desserts, etc.

At the request of the website owner - I have removed web-scraping guide.
","2018-36"
"314",318,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2018/2018-09-25/raw/invasive_species.R","library(tidyverse)

df <- read_csv(""afr_species.csv"") %>% 
        janitor::clean_names() %>% 
        select(species:origin)

df %>% write_csv(""africa_species.csv"")

df1 <- read_csv(""table1.csv"") %>% janitor::clean_names()
tab_1 <- df1 %>% 
        select(rank:o_tt) %>% 
        bind_rows(df1 %>% 
                          select(rank_1:o_tt_1) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        bind_rows(df1 %>% 
                          select(rank_2:o_tt_2) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        filter(!is.na(rank)) %>% 
        rename(""invasion_threat"" = o_tt)

df2 <- read_csv(""table2.csv"") %>% janitor::clean_names()
tab_2 <- df2 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df2 %>% 
                select(""country"" = x4, ""ti_ct"" = ti_ct_millions_1) %>% 
                        mutate(rank = parse_number(country),
                               country = str_extract(country, ""[:alpha:].*$""),
                               ti_ct = parse_number(ti_ct) * 1000000) %>% 
                        filter(!is.na(rank))
        ) %>% 
        bind_rows(df2 %>% 
                          select(""country"" = x7, ""ti_ct"" = ti_ct_millions_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000) %>% 
                          filter(!is.na(rank))
                
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df3 <- read_csv(""table3.csv"") %>% janitor::clean_names()
tab_3 <- df3 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions, 
               ""gdp_mean"" = x4, ""gdp_proportion"" = proportion_of) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000,
               gdp_mean = parse_number(gdp_mean) * 1000000,
               gdp_proportion = as.numeric(gdp_proportion)
        ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x6, ""ti_ct"" = ti_ct_millions_1, 
                                 ""gdp_mean"" = x9, ""gdp_proportion"" = proportion_of_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x11, ""ti_ct"" = ti_ct_millions_2, 
                                 ""gdp_mean"" = x14, ""gdp_proportion"" = proportion_of_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df4 <- read_csv(""table4.csv"") %>% janitor::clean_names()
tab_4 <- df4 %>% 
        select(""country"" = rank_country, ""ti_cs"" = ti_cs_millions_us) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_cs = parse_number(ti_cs) * 1000000
               ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_1, ""ti_cs"" = ti_cs_millions_us_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
                  ) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_2, ""ti_cs"" = ti_cs_millions_us_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_cs)

df6 <- read_csv(""table6.csv"") %>% janitor::clean_names()
tab_6 <- df6 %>% 
        select(species, ""max_impact_percent"" = maximum_reported_species) %>%
        filter(!is.na(species)) %>% 
        mutate(rank = 1:n(),
               species = species,
               max_impact_percent = parse_number(max_impact_percent)
        ) %>% 
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species, 
                                 ""max_impact_percent"" = maximum_reported_species_1) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>%
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species_1, 
                                 ""max_impact_percent"" = maximum_reported) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>% 
        filter(!is.na(species))

tab_list <- list(table_1 = tab_1, table_2 = tab_2, table_3 = tab_3, table_4 = tab_4, table_6 = tab_6)

tab_list %>% 
        names() %>% 
        walk(~ write_csv(tab_list[[.]], glue::glue(""{.}.csv"")))
","2018-39"
"315",319,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2018/2018-09-25/raw/readme.rmd","# Raw tabular data

Table data extracted from supplementary PDF via [Tabula](https://tabula.technology/) open-source software. 

This ended up being super messy - cleaning script found below.

[Cleaning Script](https://github.com/rfordatascience/tidytuesday/blob/master/data/2018-09-25/raw/invasive_species.R)
","2018-39"
"316",320,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-01-22/example_code.R","# Load Library
library(tidyverse)

# Read in raw data from Vera
df_raw <- read_csv(""https://raw.githubusercontent.com/vera-institute/incarceration_trends/master/incarceration_trends.csv"")

# Check out the data structure
df_raw %>% str()

# add a row id (for later joining)
df <- df_raw %>% 
  mutate(row_id = row_number())

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong

df_population <- df %>% 
  select(yfips:land_area, -total_pop, row_id) %>% 
  gather(pop_category, population, total_pop_15to64:white_pop_15to64) %>% 
  mutate(pop_category = case_when(str_detect(pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(pop_category, ""white"") ~ ""White"",
                                  str_detect(pop_category, ""black"") ~ ""Black"",
                                  str_detect(pop_category, ""female"") ~ ""Female"",
                                  str_detect(pop_category, ""male_pop"") ~ ""Male"",
                                  str_detect(pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(pop_category, ""total"") ~ ""Total"",
                                  str_detect(pop_category, ""native"") ~ ""Native American"",
                                  str_detect(pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong
df_prison_pop <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_prison_pop:white_prison_pop, row_id) %>% 
  gather(prison_pop_category, prison_population, total_prison_pop:white_prison_pop) %>% 
  mutate(prison_pop_category = case_when(str_detect(prison_pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(prison_pop_category, ""white"") ~ ""White"",
                                  str_detect(prison_pop_category, ""black"") ~ ""Black"",
                                  str_detect(prison_pop_category, ""female"") ~ ""Female"",
                                  str_detect(prison_pop_category, ""male_prison"") ~ ""Male"",
                                  str_detect(prison_pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(prison_pop_category, ""total"") ~ ""Total"",
                                  str_detect(prison_pop_category, ""native"") ~ ""Native American"",
                                  str_detect(prison_pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Left join the two dataframes together
# I used all the common columns including row_id

full_prison_pop_df <- left_join(df_population, df_prison_pop, 
          by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                 ""pop_category"" = ""prison_pop_category"", ""urbanicity"", ""region"",
                 ""division"", ""commuting_zone"", ""metro_area"", ""land_area"", ""row_id"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone)) 

# Summary data to get rate per 100000 by group

summ_prison <- full_prison_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(prison_population)/sum(population) * 100000) %>% 
  ungroup()

# Test plot looks good
ggplot(summ_prison, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category)

# More gathers to get pre-trial data
df_pretrial <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_jail_pretrial:male_jail_pretrial) %>% 
  gather(pretrial_category, pretrial_population, total_jail_pretrial:male_jail_pretrial) %>% 
  mutate(pretrial_category = case_when(str_detect(pretrial_category, ""asian"") ~ ""Asian"",
                                  str_detect(pretrial_category, ""white"") ~ ""White"",
                                  str_detect(pretrial_category, ""black"") ~ ""Black"",
                                  str_detect(pretrial_category, ""female"") ~ ""Female"",
                                  str_detect(pretrial_category, ""male_jail"") ~ ""Male"",
                                  str_detect(pretrial_category, ""latino"") ~ ""Latino"",
                                  str_detect(pretrial_category, ""total"") ~ ""Total"",
                                  str_detect(pretrial_category, ""native"") ~ ""Native American"",
                                  str_detect(pretrial_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Pretrial dataset joined with population numbers
pretrial_pop_df <- left_join(df_population, df_pretrial, 
                         by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                                ""pop_category"" = ""pretrial_category"", ""urbanicity"", ""region"",
                                ""division"", ""commuting_zone"", ""metro_area"", ""land_area"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone))

# Summary data to get rate per 100000 by group
summ_pretrial <- pretrial_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(pretrial_population)/sum(population) * 100000) %>% 
  ungroup()

# plot matches Vera plot
ggplot(summ_pretrial, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category) +
  labs(title = ""Rate per 100,000 by county type and population group"")

# Write files to .csv
write_csv(summ_prison, ""prison_summary.csv"")
write_csv(summ_pretrial, ""pretrial_summary.csv"")
write_csv(full_prison_pop_df, ""prison_population.csv"")
write_csv(pretrial_pop_df, ""pretrial_population.csv"")
","2019-4"
"317",321,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-04-09/tennis_pros.rmd","---
title: ""Men's and Women's Tennis""
author: ""Thomas Mock""
date: ""4/6/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
library(lubridate)
library(janitor)
```

### Get Women's Slams Records

I couldn't find a great source of historical dates for the grand slam winner's dates but they are consistently within a few days of each other based off my cursory examination. I fully ackowledge that the dates used for the tournament date are only estimations.

```{r}
raw_slams <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_women%27s_singles_champions"") %>% 
  html_table(fill = TRUE) %>% 
  .[[3]] %>% 
  janitor::clean_names()

clean_slams <- raw_slams %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove(name, """")),
         name = str_trim(str_remove(name, ""Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          TRUE ~ name)) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Female"") %>% 
  group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()
```


 
### Get Mens Slams Records

```{r}

raw_slams_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_men%27s_singles_champions"") %>% 
  html_nodes(xpath = '//*[@id=""mw-content-text""]/div/table[1]') %>% 
  html_table(fill = TRUE) %>% .[[1]] %>% janitor::clean_names()

clean_slams_men <- raw_slams_men %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  separate(col = winner, into = c(""country"", ""winner""), sep = "":"", fill = ""left"") %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove_all(name, ""|"")),
         name = str_trim(str_remove(name, ""Amateur era tennis ends|Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Male"") %>% 
  select(-country) %>% 
   group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()

```

### Get the Dates of Birth for women

This got the majority of women but I had to manually add birthdates for Ann and Chris.

```{r}
clean_dob <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[2]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          str_detect(name, ""Reid"") ~ ""Kerry Melville Reid"",
                          str_detect(name, ""Vicario"") ~ ""Arantxa Snchez Vicario"",
                          TRUE ~ name)) %>% 
  bind_rows(tibble(name = c(""Ann Haydon-Jones"",""Chris O'Neil""),
                   date_of_birth = c(lubridate::dmy(""7 October 1938""), lubridate::dmy(""19 March 1956""))))

dob_df <- clean_dob %>% 
  select(date_of_birth, name)
```

### Combine to get approx age at each tourney

```{r}
age_slams <- left_join(clean_slams, dob_df, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))
```

### MEN

```{r}
clean_dob_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  bind_rows(tibble(name = ""William Bowrey"",
                   date_of_birth = lubridate::dmy(""25 December 1943"")))

dob_df_men <- clean_dob_men %>% 
  select(date_of_birth, name)
```

### Combine

```{r}
age_slams_men <- left_join(clean_slams_men, dob_df_men, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

age_slams_men %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step()
```

### Total Combine

```{r}
grand_slams <- bind_rows(clean_slams, clean_slams_men) %>% 
  select(-total_win_count)
```

```{r}
player_dob <- bind_rows(clean_dob, clean_dob_men)
```

```{r}
age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age, gender) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

# test plot
age_slams_comb %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step() +
  facet_wrap(~gender)
```


```{r}
write_csv(grand_slams, ""grand_slams.csv"")
write_csv(player_dob, ""player_dob.csv"")
```


### Tennis Timeline Performance

I thought this was interesting data that could lead to some unique plots.

```{r}
yr_1968_1970 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[12]]
clean_1968_1970 <- yr_1968_1970 %>% 
  set_names(nm = paste0(names(yr_1968_1970), ""_"", yr_1968_1970[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1964_AUS`:`1970_USA`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year)) %>% 
  filter(year >= 1968)

yr_1971_1977 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[13]]

clean_1971_1977 <- yr_1971_1977 %>% 
  set_names(nm = paste0(names(yr_1971_1977), ""_"", yr_1971_1977[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1971_AUS`:`1977_AUSD`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year))

names(yr_1968_1970) %>% unique() %>% .[. != ""Player""] %>% as.integer()
```

I re-factored into a function but there were some gotchas in the data that limited where I could apply the function. Given I will never use it again I will somewhat break DRY principles for my own sake.

```{r}

get_timeline <- function(table_num){
  
  Sys.sleep(5)
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    filter(Player_Player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    rename(player = Player_Player) %>%
    mutate(year = as.integer(year))
}
```

# Collect women's timeline

```{r}

clean_1978_2012 <- 5:9 %>%
  map(get_timeline) %>%
  bind_rows()

```

```{r}
df_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[10]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}
final_timeline <- bind_rows(list(clean_1968_1970, clean_1971_1977, clean_1978_2012, clean_2013_2019)) %>% 
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Female"")

```

```{r}
final_timeline %>% group_by(tournament) %>% count(sort = TRUE)
```

### MENS Timeline

The function works a bit nicer here and I have further re-factored it.

```{r}
get_timeline_men <- function(table_num){
  Sys.sleep(5)
  
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>%
    na.omit() %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    janitor::clean_names(""all_caps"") %>% 
    select(-matches(""NA"")) %>% 
    select(player = PLAYER_PLAYER, matches(""AUS|FRA|WIM|USA"")) %>% 
    select(-matches(""NA|`NA`"")) %>% 
    filter(player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    mutate(year = as.integer(year))
}
```


```{r}
men_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[8]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}

clean_men_1967_2019 <- 3:10 %>% 
  map(get_timeline_men) %>% 
  bind_rows() %>% 
  filter(year > 1967)

final_timeline_men <- clean_men_1967_2019 %>%  
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Male"")

```


```{r}
both_timeline <- bind_rows(final_timeline, final_timeline_men) %>% 
  filter(str_length(player) > 4) %>% 
  filter(year <= 2019)

anti_timeline <- both_timeline %>% 
  filter(year == 2019 & tournament != ""Australian Open"")

combined_timeline <- anti_join(both_timeline, anti_timeline)
```

```{r}
write_csv(combined_timeline, ""grand_slam_timeline.csv"")
```

","2019-15"
"318",322,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-04-16/economist-mistakes.R","library(tidyverse)
library(here)
library(janitor)

### Brexit Raw

brexit_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_brexit.csv""))

brexit_clean <- brexit_raw %>% 
  set_names(nm = .[3,]) %>% 
  clean_names() %>% 
  slice(4:nrow(.))

brexit_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""brexit.csv""))

### corbyn

corbyn_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_corbyn.csv""))

corbyn_clean <- corbyn_raw %>% 
  set_names(nm = ""political_group"", ""avg_facebook_likes"") %>% 
  na.omit()

corbyn_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""corbyn.csv""))

### dogs

dogs_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_dogs.csv""))

dogs_clean <- dogs_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""year"", ""avg_weight"", ""avg_neck""))

dogs_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""dogs.csv""))

### EU Balance

eu_balance_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_eu-balance.csv""))


names_eu <- eu_balance_raw %>% 
  .[1,] %>% 
  as.character()

datapasta::vector_paste_vertical(names_eu)  

clean_names_eu <- c(""country"",
              ""current_2009"",
              ""current_2010"",
              ""current_2011"",
              ""current_2012"",
              ""current_2013"",
              ""current_2014"",
              ""current_2015"",
              ""budget_2009"",
              ""budget_2010"",
              ""budget_2011"",
              ""budget_2012"",
              ""budget_2013"",
              ""budget_2014"",
              ""budget_2015"")

eu_current <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""current"")) %>% 
  select(-starts_with(""budget"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_budget <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""budget"")) %>% 
  select(-starts_with(""current"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_balance_clean <- bind_rows(eu_current, eu_budget)

eu_balance_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""eu_balance.csv""))

### Pensions

pensions_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_pensions.csv""))

pensions_clean <- pensions_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""country"", ""pop_65_percent"", ""gov_spend_percent_gdp""))

pensions_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""pensions.csv""))

### Trade

trade_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_us-trade-manufacturing.csv""))

trade_clean <- trade_raw %>% 
  set_names(nm = c(""year"", ""trade_deficit"", ""manufacture_employment"")) %>% 
  mutate(trade_deficit = trade_deficit * 1e9,
         manufacture_employment = manufacture_employment * 1e6) %>% 
  na.omit()

trade_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""trade.csv""))

### Women
women_research_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_women-research.csv""))

women_research_raw[1,] %>% 
  as.character() %>% 
  datapasta::vector_paste_vertical()

research_names <- c(""country"",
  ""Health sciences"",
  ""Physical sciences"",
  ""Engineering"",
  ""Computer science, maths"",
  ""Women inventores"")

women_research_clean <- women_research_raw %>% 
  na.omit() %>% 
  set_names(nm = research_names) %>% 
  filter(country != ""Country"") %>% 
  gather(field, percent_women, `Health sciences`:`Women inventores`)

women_research_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""women_research.csv""))

","2019-16"
"319",323,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-05-14/nobel_winners.R","library(tidyverse)
library(here)
library(janitor)

# read in the specific category/field datasets and the overall winners

nobel_winners <- read_csv(here(""2019"", ""2019-05-14"", ""archive.csv"")) %>% 
  janitor::clean_names() %>% 
  rename(""prize_year"" = year,
         ""gender"" = sex)

chem_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Chemistry publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""chemistry"")

med_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Medicine publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""medicine"")

physics_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Physics publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""physics"")

all_pubs <- bind_rows(chem_pubs, med_pubs, physics_pubs)

all_pubs %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winner_all_pubs.csv""))

nobel_winners %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winners.csv""))




nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

nobel_winner_all_pubs %>% 
  distinct(category)","2019-20"
"320",324,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-07-02/revenue.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/List_of_highest-grossing_media_franchises""

df <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE) %>% 
  .[[2]]

clean_money <- df %>% 
  set_names(nm = c(""franchise"", ""year_created"", ""total_revenue"", ""revenue_items"",
                   ""original_media"", ""creators"", ""owners"")) %>% 
  mutate(total_revenue = str_remove(total_revenue, ""est.""),
         total_revenue = str_trim(total_revenue),
         total_revenue = str_remove(total_revenue, ""[$]""),
         total_revenue = word(total_revenue, 1, 1),
         total_revenue = as.double(total_revenue))

clean_category <- clean_money %>% 
  separate_rows(revenue_items, sep = ""\\["") %>% 
  filter(str_detect(revenue_items, ""illion"")) %>% 
  separate(revenue_items, into = c(""revenue_category"", ""revenue""), sep = ""[$]"") %>% 
  mutate(revenue_category = str_remove(revenue_category, ""  ""),
         revenue_category = str_remove(revenue_category, regex("".*\\]"")),
         revenue_category = str_remove(revenue_category, ""\n"")) 

clean_df <- clean_category %>% 
  mutate(revenue_category = case_when(
    str_detect(str_to_lower(revenue_category), ""box office"") ~ ""Box Office"",
    str_detect(str_to_lower(revenue_category), ""dvd|blu|vhs|home video|video rentals|video sales|streaming|home entertainment"") ~ ""Home Video/Entertainment"",
    str_detect(str_to_lower(revenue_category), ""video game|computer game|mobile game|console|game|pachinko|pet|card"") ~ ""Video Games/Games"",
    str_detect(str_to_lower(revenue_category), ""comic|manga"") ~ ""Comic or Manga"",
    str_detect(str_to_lower(revenue_category), ""music|soundtrack"") ~ ""Music"",
    str_detect(str_to_lower(revenue_category), ""tv"") ~ ""TV"",
    str_detect(str_to_lower(revenue_category), ""merchandise|licens|mall|stage|retail"") ~ ""Merchandise, Licensing & Retail"",
    
    TRUE ~ revenue_category)) %>% 
  mutate(revenue = str_remove(revenue, ""illion""),
         revenue = str_trim(revenue),
         revenue = str_remove(revenue, "" ""),
         revenue = case_when(str_detect(revenue, ""m"") ~ paste0(str_extract(revenue, ""[:digit:]+""), ""e-3""),
                             str_detect(revenue, ""b"") ~ str_extract(revenue, ""[:digit:]+""),
                             TRUE ~ NA_character_),
         revenue = format(revenue, scientific = FALSE),
         revenue = parse_number(revenue)) %>%
  mutate(original_media = str_remove(original_media, ""\\[.+"")) 

sum_df <- clean_df %>%
  group_by(franchise, revenue_category) %>% 
  summarize(revenue = sum(revenue))

total_sum_df <- clean_df %>% 
  group_by(franchise) %>% 
  summarize(revenue = sum(revenue)) %>% 
  arrange(desc(revenue))

metadata_df <- clean_df %>% 
  select(franchise:revenue_category, original_media:owners, -total_revenue)

final_df <- left_join(sum_df, metadata_df, 
                      by = c(""franchise"", ""revenue_category"")) %>% 
  distinct(.keep_all = TRUE)

final_df
write_csv(final_df, ""media_franchises.csv"")
","2019-27"
"321",325,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-07-09/wwc_cleaning.R","library(tidyverse)
library(here)

# read in the datasets
df <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""wwc_results.xlsx"")) %>% 
  mutate(Year = as.integer(Year))

df_2019 <- read_csv(here(""2019"", ""2019-07-09"", ""wwc_2019.csv""))

squads <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""Womens Squads.xlsx"")) %>% 
  janitor::clean_names()

# bind datasets to include 2019
df_all <- bind_rows(df, df_2019) %>% 
  janitor::clean_names()

# add win, tie status
df_both <- df_all %>% 
  group_by(year) %>% 
  mutate(yearly_game_id = row_number(),
         winner = case_when(score_1 > score_2 ~ ""Team 1 Win"",
                   score_2 > score_1 ~ ""Team 2 Win"",
                   score_1 == score_2 ~ ""Tie"",
                   TRUE ~ NA_character_)) 

# grab team 1/score 1
df_team_1 <- df_both %>% 
  select(year:score_1, round, yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 1)

# grab team2/score 2
df_team_2 <- df_both %>% 
  select(year, team_2:yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 2)

# attach team1/team2 datasets together
# Assign winner, loser, tie,
# Correct for shootout wins in knockout stages

df_tidy <- bind_rows(df_team_1, df_team_2) %>% 
  arrange(year, yearly_game_id) %>% 
  mutate(win_status = case_when(team_num == as.integer(str_extract(winner, ""[:digit:]"")) ~ ""Won"",
                            team == ""USA"" & round == ""Final"" & year == 1999 ~ ""Won"",
                            team == ""NOR"" & round == ""Round of 16"" & year == 2019 ~ ""Won"",
                            team == ""JPN"" & round == ""Final"" & year == 2011 ~ ""Won"",
                            team == ""CHN"" & round == ""Quarter Final"" & year == 1995 ~ ""Won"",
                            team == ""FRA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""USA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""GER"" & round == ""Quarter Final"" & year == 2015 ~ ""Won"",
                            team == ""BRA"" & round == ""Third Place Playoff"" & year == 1999 ~ ""Won"",
                            round == ""Group"" & winner == ""Tie"" ~ ""Tie"",
                            TRUE ~ ""Lost"")) %>% 
  select(-winner)

# confirm no double winners/losers
df_tidy %>% 
  filter(round != ""Group"") %>% 
  group_by(year, round, yearly_game_id) %>% 
  count(win_status, sort = TRUE) %>% 
  filter(n >1)

# output to csv
df_tidy %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""wwc_outcomes.csv""))

squads %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""squads.csv""))


# data dictionaries for TidyTuesday
tomtom::create_dictionary(df_tidy)
tomtom::create_dictionary(squads)
","2019-28"
"322",326,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-09-03/moores_law.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/Transistor_count""

tables <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE)

df1 <- tables %>% chuck(1) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df1_clean <- df1 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = str_sub(date_of_introduction, 1, 4),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
    ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)


df1_clean %>%
  mutate() 
df2 <- tables %>% chuck(2) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df2_clean <- df2 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)

df3 <- tables %>% chuck(4) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df3

df3_clean <- df3 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = if_else(
      str_length(date_of_introduction) >= 5,
      str_sub(date_of_introduction, -4),
      str_sub(date_of_introduction, 1, 4)),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+""),
    bit_units = case_when(
      str_detect(capacity_bits, ""bit"") ~ ""Bits"",
      str_detect(capacity_bits, ""kb"") ~ ""kb"",
      str_detect(capacity_bits, ""Mb"") ~ ""Mb"",
      str_detect(capacity_bits, ""Gb"") ~ ""Gb"",
      TRUE ~ """"
                 )
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double) %>% 
  select(chip_name, capacity_bits, bit_units, everything()) %>% 
  mutate(capacity_bits = str_extract(capacity_bits, ""[:digit:]+""))

df3_clean

write_csv(df1_clean, here::here(""2019"", ""2019-09-03"", ""cpu.csv""))
write_csv(df2_clean, here::here(""2019"", ""2019-09-03"", ""gpu.csv""))
write_csv(df3_clean, here::here(""2019"", ""2019-09-03"", ""ram.csv""))

tomtom::create_dictionary(df1_clean)

cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")
gpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")
ram <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")

","2019-36"
"323",327,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-09-17/parks.R","library(tidyverse)
library(rvest)

df_raw <- read_csv(here::here(""2019/2019-09-17/All National Parks Visitation 1904-2016.csv"")) 

df <- df_raw %>% 
  janitor::clean_names() %>%
  mutate(date = lubridate::mdy_hms(year)) %>% 
  select(date, gnis_id, geometry:year_raw)

df %>% 
  write_csv(here::here(""2019/2019-09-17/national_parks.csv""))


# Get pop data

url <- ""https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_historical_population""

raw_html <- url %>% 
  read_html() %>% 
  html_table()

pop_df <- raw_html %>% 
  chuck(5) %>% 
  gather(key = ""state"", value = ""pop"", AL:DC) %>% 
  rename(""year"" = 1) %>% 
  mutate(pop = str_remove_all(pop, "",""),
         pop = as.double(pop))

pop_df %>% 
  write_csv(here::here(""2019/2019-09-17"", ""state_pop.csv""))

# Get gas prices

url2 <- ""https://www.energy.gov/eere/vehicles/fact-915-march-7-2016-average-historical-annual-gasoline-pump-price-1929-2015""

raw_gas <- url2 %>% 
  read_html() %>% 
  html_table()

gas <- raw_gas %>% 
  chuck(1) %>% 
  set_names(nm = c(""year"", ""gas_current"", ""gas_constant"")) %>%   
  as_tibble() %>% 
  filter(!str_detect(year, ""Source"")) %>% 
  mutate(year = as.double(year),
         gas_current = as.double(gas_current),
         gas_constant = as.double(gas_constant))

gas %>% 
  write_csv(here::here(""2019/2019-09-17"", ""gas_price.csv""))
","2019-38"
"324",328,"https://github.com/rfordatascience/tidytuesday","rfordatascience","tidytuesday","data/2019/2019-11-05/bike_walk.R","# Load Packages -----------------------------------------------------------

library(tidyverse)
library(readxl)
library(here)
library(glue)
library(janitor)

# Read in Data ------------------------------------------------------------

table_num <- 1:6

# Generic read function for this dataset

supp_read <- function(number, ...){
  read_excel(here(""2019"", ""2019-11-05"", glue::glue(""supplemental-table{number}.xlsx"")), ...)
}

# 3 datasets for bikes, each of which has a corresponding City Size

small_bike <- supp_read(1, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"", 
         percentage_of_workers = as.numeric(percentage_of_workers),
         margin_of_error_2 = as.numeric(margin_of_error_2))

medium_bike <- supp_read(2, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_bike <- supp_read(3, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_bike <- bind_rows(small_bike, medium_bike, large_bike) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Bike"")


# 3 datasets for walking, each of which has a corresponding City Size

small_walk <- supp_read(4, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"")

medium_walk <- supp_read(5, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_walk <- supp_read(6, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_walk <- bind_rows(small_walk, medium_walk, large_walk) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Walk"")

# Built in state-level datasets
state_df <- tibble(
  state = state.name,
  state_abb = state.abb,
  state_region = as.character(state.region)
)

# Combine bike and walk data in tidy setup

full_commute <- 
  bind_rows(full_bike, full_walk) %>% 
  filter(!is.na(n),
         # There are some government-related areas that don't align with cities
         !str_detect(tolower(city), ""government|goverment"")) %>% 
  separate(city, into = c(""city"", ""state""), sep = "", "") %>% 
  select(city, state, city_size, mode, everything()) %>% 
  left_join(state_df, by = c(""state""))

full_commute %>% 
  write_csv(here(""2019"", ""2019-11-05"", ""commute.csv""))

# ACS Data ----------------------------------------------------------------

acs_data <- read_csv(here(""2019"", ""2019-11-05"", ""table_3.csv""))

age_data <- acs_data %>% 
  slice(1:6)

gender_data <- acs_data %>% 
  slice(9:10) %>% 
  rename(""gender"" = age)

race_data <- acs_data %>% 
  slice(13:18) %>% 
  rename(""race"" = age)

children_data <- acs_data %>% 
  slice(20:24) %>% 
  rename(""children"" = age)

income_data <- acs_data %>% 
  slice(27:36) %>% 
  rename(""income"" = age)

education_data <- acs_data %>% 
  slice(39:43) %>% 
  rename(""education"" = age)

","2019-45"
"325",368,"https://github.com/r0mymendez/R/tree/master/TidyTuesday/20190506","r0mymendez","R","TidyTuesday/20190506/script.R","library(extrafont)
library(tidyverse)

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")
unique(student_ratio$indicator)
df1=read.table('elements.txt',
               header = T,sep=',',stringsAsFactors = F)

df1$GroupName[113:118]='Others'


dff1=dff%>%filter(indicator=='Primary Education')%>%arrange(mean)
dff1=dff1[1:118,]

dft=data.frame(
  Column=df1$Column,
  Row=df1$Row,
  GroupName=df1$GroupName,
  continent=dff1$continent,
  codigo=dff1$country_code,
  country=dff1$country,
  value=round(dff1$mean,2),
  stringsAsFactors = F
)


loadfonts()

tile_width = 1
tile_height = 1



ggplot(dft, aes(Column, -Row)) + 
  geom_tile(data=dft, aes(fill=GroupName,width=tile_width, height=tile_height), 
            color=""black"",show.legend = F) + 
  geom_text( aes(label=codigo),parse=TRUE, nudge_y=.1, size=4)+
  geom_text( aes(label=value), nudge_x=-0.25, nudge_y=0.30,
            ha='left', va='top', fontweight='normal', size=3)+
  geom_text( aes(label=substr(country,1,10)), nudge_y=-0.125,size=3)+
  labs(x='',y='',caption = '@r0mymendez',
       title = 'The periodic table of education',
       subtitle = '\n Global Student to Teacher Ratios: Primary Education \n #TidyTuesday')+
  theme(plot.background = element_rect(fill='#2a2a2a')
        ,panel.background = element_rect(fill='#2a2a2a')
        ,axis.text.x = element_blank()
        ,axis.ticks = element_blank() 
        ,axis.text.y = element_blank()
        ,panel.grid.major= element_blank()
        ,axis.line = element_blank()
        ,plot.title = element_text(color = 'white',hjust = 0.5,size = 50,family = ""Pacifico"")
        ,plot.caption = element_text(color = 'white',size=18,family = ""Pacifico"")
        ,plot.subtitle = element_text(color = 'white',hjust = 0.5)
        ,panel.grid = element_line(colour = '#2a2a2a')
  )


ggsave(""plot.jpg"")

","2019-18"
"326",370,"https://github.com/r0mymendez/R/tree/master/TidyTuesday/20190514-NOBEL","r0mymendez","R","TidyTuesday/20190514-NOBEL/script.R","
rm(list=ls())
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")



library(patchwork)
library(grid)
library(gridExtra)
library(ggpubr)
library(tidyverse)
library(emojifont)
library(ggrepel)

emo=c(emoji('dollar'),
emoji('books'),
emoji('heart'),
emoji('microscope'),
emoji('globe_with_meridians'),
emoji('pill'))


df.category=nobel_winners%>%count(category)%>%top_n(10,n)%>%arrange((n))
df.category$x=1
df.category$y=seq(0,2.5,by=0.5) 
df.category$desc=paste0(df.category$category,' ',emo)
 

p0=
  df.category%>%mutate(category=reorder(category,n))%>%
  ggplot(aes(x=category,y=n))+
  geom_col(show.legend = F,fill='#2a2a2a')+
  geom_label_repel(aes(label = paste0(n,' in ',desc),color=category),
                   data = df.category,  size = 6,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0,
                   segment.size = 0,y = -500
  ) +
  coord_flip() +
  labs(x='',y='',title = ' ')+
  theme(
    axis.ticks = element_blank(),
    axis.text = element_blank(),
    axis.line = element_blank() ,
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.spacing = element_blank(),
    panel.grid.minor = element_blank(),
    plot.title = element_text(family = ""Atma Light"",
                              hjust = 0.5,size=20,colour = 'white',
                              face = 'bold')
  )


df.country=nobel_winners%>%count(birth_country)%>%top_n(10,n)%>%arrange((n))
usa=nobel_winners%>%filter(birth_country=='United States of America')%>%
  count(category)

p1=
  ggplot(usa,aes(category,n,fill=category))+
  geom_col(color='black',show.legend = F)+
  coord_flip()+
  labs(y = paste0('Usa: ',sum(usa$n),' prizes'),x='')+
  coord_polar()+
  geom_label_repel(aes(label = paste0(n,' in ',category)),
                   data = usa,  size = 4,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(1, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   segment.color='white',
                   show.legend = F)+
  theme(axis.title = element_text(family = ""Atma Light"",
                                    hjust = 0.5,size=20,colour = 'white'),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.line = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' )
        )

uk=nobel_winners%>%filter(birth_country=='United Kingdom')%>%
  count(category)

p2=ggplot(uk,aes(category,n,fill=category))+
  geom_col(color='black',show.legend = F)+
  labs(y = paste0('Uk: ',sum(uk$n),' prizes'),x='')+
  coord_flip()+
  coord_polar()+
  geom_label_repel(aes(label = paste0(n,' in ',category)),
                   data = uk,  size = 4,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(1, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   segment.color='white',
                   show.legend = F)+
  theme(axis.title = element_text(family = ""Atma Light"",
                                  hjust = 0.5,size=20,colour = 'white'),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.line = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' )
        
  )


Germany=nobel_winners%>%filter(birth_country=='Germany')%>%
  count(category)

p3=ggplot(Germany,aes(category,n,fill=category))+
  geom_col(color='black',show.legend = F)+
  labs(y = paste0('Germany: ',sum(Germany$n),' prizes'),x='')+
  coord_flip()+
  coord_polar()+
  geom_label_repel(aes(label = paste0(n,' in ',category)),
                   data = Germany,  size = 4,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   box.padding = unit(1, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   segment.color='white',
                   show.legend = F)+
  theme(axis.title = element_text(family = ""Atma Light"",
                                  hjust = 0.5,size=20,colour = 'white'),
        axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.line = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' )
        
  )


df.genero=nobel_winners%>%filter(is.na(gender)==F)%>%count(gender,category)

p4=ggplot(df.genero,
       aes(x=category,y=n,fill=gender))+
  geom_col(position = ""dodge"",color='#2a2a2a',show.legend = F)+
  geom_label_repel(aes(label =paste0(n,' ',gender)),
                   data = df.genero,  size = 5,  fill ='#fffeea',
                   family=""Atma Light"" ,
                   label.padding = 0.3,fontface = 'bold',
                   show.legend = F,
                   box.padding = unit(0.5, ""lines""),
                   segment.color='white',
                   point.padding = unit(0.5, ""lines""))+
  labs(x='',y='',title='The novel prize gender')+
  theme_bw()+   
  theme(legend.position = 'top', 
        legend.spacing.x = unit(0.41, 'cm'),
        legend.text = element_text(margin = margin(t = 10))) +
  guides(fill=guide_legend(title=""""))+
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        panel.background =element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        legend.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        axis.text =  element_text(colour='white'),
        legend.title =  element_text(colour='white'),
        plot.title =  element_text(colour = 'white',
                           family=""Atma Light"",face = 'bold'))




ggarrange(
ggarrange(p0,p1,p2,p3,ncol=4,nrow = 1, heights = c(0.05,0.1,0.1,0.1),
          widths =  c(0.15,0.2,0.2,0.2)),
p4,
          ncol = 1, nrow = 2)+
  labs(caption='@r0mymendez    \n   ',title='THE NOBEL PRIZE')+
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
        plot.caption = element_text(colour = 'white',size = 10,hjust = 1),
        plot.title  = element_text(colour = 'white',size = 40,hjust = 0.5,
                                   family =""Atma SemiBold"" ))








","2019-20"
"327",384,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190521-PlasticWaste/script.R","rm(list=ls())

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

library(tidyverse)
library(countrycode)
library(emojifont)
library(ggrepel)
library(ggridges)
library(ggpubr)


mismanaged_vs_gdp1 <- mismanaged_vs_gdp %>%
  rename('PerCapMismanaged'=`Per capita mismanaged plastic waste (kilograms per person per day)`,
         'GDPperCapita'=`GDP per capita, PPP (constant 2011 international $) (Rate)`,
         'TotalPop'=`Total population (Gapminder)`)%>%
  filter(!is.na(PerCapMismanaged),
         Year==2010,Entity!='World')%>%
  mutate(TotalPopM=TotalPop/1000000,
         PerCapMismanaged=PerCapMismanaged,
         continent = countrycode(sourcevar = Entity, 
                                 origin = ""country.name.en"", 
                                 destination = ""continent""))



gg <- 
  ggplot(mismanaged_vs_gdp1%>%top_n(15,PerCapMismanaged)%>%
           mutate(Entity=reorder(Entity,PerCapMismanaged)), 
         aes(x=Entity, y=PerCapMismanaged,fill=Entity)) + 
  geom_col(show.legend = F, color= '#2a2a2a',alpha = 0.75)+
  coord_flip()+
  geom_label_repel(
   aes(label=Entity),
   size=4, data=mismanaged_vs_gdp1%>%top_n(15,PerCapMismanaged),
   y=-10,
   fill ='#fffeea',
   family=""Atma Light"" ,
   box.padding = unit(0.35, ""lines""),
   point.padding = unit(0.3, ""lines""),
   show.legend = F,fontface = 'bold',
   hjust=0,vjust=0,
   segment.size = 0,
  ) +
  labs(title=""The 15 countries with more per capita mismanaged \nplastic waste "",
       subtitle="""", 
       x="""",
       y=""kg per person per day"" 
      ) +
  theme(      panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
              axis.text.y = element_blank(),
              axis.ticks = element_blank(),
              axis.title = element_text(family = ""Atma Light"",size=15),
              plot.caption = element_text(family = ""Atma Light"",size=15),
              plot.title =  element_text(family = ""Atma Light"",size=13),
              panel.background = element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              plot.background =  element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              panel.grid.major.x = element_line(color = '#2a2a2a')
              
  )


gg
  
img_a <- png::readPNG(""1.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 

gg1=
  mismanaged_vs_gdp1 %>% 
  mutate(continent = factor(continent)) %>%
  filter(is.na(continent)==F)%>%
  ggplot(aes(y=continent,x=PerCapMismanaged,
             fill = continent, color = continent)) +
    geom_density_ridges(alpha = 0.25,
                      show.legend = F,
                      aes(point_color = continent), 
                      jittered_points = TRUE)   +
  annotation_custom(a, xmin =0.26, xmax = 0.35,
                    ymin=0 ,ymax=2) +
  labs(y='Continent',x='Per capita mismanaged plastic waste',
       title='Analysis of continents with mismanaged plastic waste')+
  theme(      panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_blank(),
             # axis.text.y = element_blank(),
              axis.ticks = element_blank(),
              plot.title =  element_text(family = ""Atma Light"",size=15),
              axis.title = element_text(family = ""Atma Light"",size=13),
              plot.caption = element_text(family = ""Atma Light"",size=13),
              panel.background = element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              plot.background =  element_rect(fill = ""#fffeea"",
                                              colour = ""#fffeea""),
              panel.grid.major.x = element_blank(),
              panel.grid.major.y = element_line(color = '#2a2a2a',linetype = 3)
              
  )
gg1



ggarrange(
  gg,gg1,
  ncol = 2, nrow = 1,widths = c(0.9,1.4))+
  labs(caption=paste0(""Source: Our World In Data | by @r0mymendez"",emoji(""heart"")),
       subtitle = ' ',
       title=paste0('Global Plastic Waste - year: 2010',emoji('earth_americas'))) +
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
        plot.caption = element_text(colour = 'white',size = 13,hjust = 1,
                                    family= ""Finger Paint""  ),
        plot.title  = element_text(colour = 'white',size = 30,hjust = 0.5,
                                   family = ""Finger Paint""      ),
        plot.subtitle = element_text(colour = 'white',size = 10,hjust = 0.5,
                                   family =""Atma SemiBold"" ),
        plot.margin = unit(c(1,0,0.1,0), ""cm""))
","2019-21"
"328",385,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190528-wine/script-wine.R","library(tidyverse)
library(ggpubr)
library(ggrepel)
library(tidytext)
library(packcircles)

df_wines <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

df_wines_top_countries <- df_wines %>% 
  group_by(country) %>% 
  summarize(
    rating = mean(points, na.rm = T),
    n = n()
  ) %>% 
  mutate(rating = (rating - 80) / 20) %>% 
  filter(
    !is.na(country),
    n > 99
  ) %>%
  top_n(6, rating)

library(emojifont)
df_top_variety <- 
  df_wines %>% 
  filter(
    !is.na(country))%>% 
  group_by(country ) %>% 
  summarize(points = mean(points, na.rm = T), n = n()) %>% 
  filter(n>100)%>% 
  top_n(10,points)%>%
  mutate(icon=emoji('wine_glass'))

setwd('/home/romimendez/Romi/Proyectos/miercolesdata/tidy/20190527-wine')

df_wines_1=df_wines%>%count(points,variety)%>%
  filter(n>50)%>%top_n(10,points)


imgage <- jpeg::readJPEG(""9.jpg"")

g1=df_top_variety%>%mutate(country=reorder(country,-n))%>%
ggplot(aes(x=country,y=n,label=icon))+
  annotation_custom(rasterGrob(imgage, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  scale_fill_brewer(type='seq', palette='Reds')+
  geom_col(aes(fill=country),show.legend = F,alpha=0.2,color='#2a2a2a')+
    annotate(""text"", label = paste0('The top ten country Wine' ,emoji('wine_glass')),
           x = 5, y = 40000, size = 20,  fill ='#fffeea',  family=""Jadyn Maria Free"",
           colour =""black"") +
  annotate(""text"", label = paste0('_________' ),
           x = 5, y = 40100, size = 20,  fill ='#fffeea',  family=""Jadyn Maria Free"",
           colour =""black"") +
  annotate(""text"", label = paste0('These Countries have the Best \nAverage Classification of wines'),
           x = 6, y = 25000, size = 12,  fill ='#fffeea',  family=""Jadyn Maria Free"",
           colour =""black"") +
  labs(y='Quantity',x='',caption = 'by @r0mymendez')+
  geom_label_repel(aes(label = paste0(round(points,0),' points avg')),color='black',
                   data = df_top_variety,  size = 4,  fill ='#E7D4B3',
                   alpha=0.8,
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0.8,
                   segment.size = 0,
  ) +
  theme(axis.title.y =element_text(color='black',
                                   family = ""Fabiana"",
                                   size=15),
        plot.background = element_rect(fill='#CAA867'),
        axis.text.x = element_text(color='black',
                                 family = ""Fabiana"",
                                 size=15),
        axis.text.y =element_text(color='black',
                                  family = ""Atma"" ,
                                  size=10) )


data(""stop_words"")

dftext=df_wines%>%select(X1,description)
df_token=dftext%>%unnest_tokens(word,description)
df_token=df_token%>%anti_join(stop_words)
df_token=df_token%>%count(word)%>%top_n(50)


imgage1 <- jpeg::readJPEG(""a1.jpeg"")
packing <- circleProgressiveLayout(df_token$n, sizetype='area')
packing$radius=1.2*packing$radius
data = cbind(df_token, packing)
dat.gg <- circleLayoutVertices(packing, npoints=50)

g2=
  ggplot() + 
  annotation_custom(rasterGrob(imgage1, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_polygon(data = dat.gg, aes(x, y, group = id, fill=id), 
               colour = ""black"", alpha = 0.6) +
  scale_fill_gradient(low='#FFF5F0', high='#FFE6E6')+
  geom_text(data = data, aes(x, y, label =word),size=6,family=""Atma Light"", color=""black"") +
  theme_void() + 
  theme(legend.position=""none"") + 
  #theme(axis.title = 'Palabras relacionadas con tecnologia y conocimientos mas frecuentes')
  coord_equal() +
  scale_size(range = c(10,1), guide = F) +
  labs(title='The most frequent words in the text description ', 
       caption='by @r0mymendez')+
  theme(plot.background = element_rect(fill='#CAA867'),
        plot.title = element_text(color='black',
                                  family = ""Fabiana"",
                                  size=25))



","2019-22"
"329",386,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190621-BirdCounts/script_eu.R","rm(list=ls())
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")
setwd('.../tidy/20190621-bird')

library(grid)
library(emojifont)
library(tidyverse)
library(ggpubr)
library(ggrepel)

df=bird_counts%>%
  filter(how_many_counted>0)%>%
  group_by(species)%>%
  summarise(total=sum(how_many_counted))%>%
  top_n(1,total)

df.bird=bird_counts%>%
  filter(how_many_counted>0,species %in% df$species)%>%
  group_by(year)%>%
  summarise(total=sum(how_many_counted))

A1 <- png::readPNG(""1.png"")
A1 <- grid::rasterGrob(A1, interpolate = T) 
A2 <- png::readPNG(""2.png"")
A2 <- grid::rasterGrob(A2, interpolate = T) 

img_a <- png::readPNG(""5c.png"") 
a <- grid::rasterGrob(img_a, interpolate = T)

b <- jpeg::readJPEG(""3.jpg"") 


ggplot(df.bird,aes(x=year, y=total)) +
  geom_point(show.legend = F,color='#001C3E',alpha=0.7) +
  geom_line(show.legend = F,color='#32686B')+
  annotation_custom(a, ymin =30000, ymax =60000,
                    xmin=1890,xmax=2000)+
  annotation_custom(A1, ymin =52000, ymax =72000,
                    xmin=1920,xmax=2000)+
  annotation_custom(A2, ymin =40000, ymax =52000,
                    xmin=1910,xmax=1960)+
 annotate(""text"", label ='European Starling',
         x = 1938, y = 65000, size = 15,  fill ='#fffeea',  family=""Jadyn Maria Free"",
         colour =""black"") +
  annotate(""text"", label ='(1925 - 2017)',
           x = 1940, y = 57000, size = 8,  fill ='#fffeea',  family=""Atma Light"",
           colour =""black"") +
  scale_x_continuous(breaks = seq(1925,2017,4))+
  geom_label_repel(aes(label = total),color='white',
                   data = df.bird%>%top_n(5,total),  size = 4,  fill ='#9DACC0',
                   alpha=0.8,
                   family=""Atma Light"" ,
                   box.padding = unit(0.35, ""lines""),
                   point.padding = unit(0.3, ""lines""),
                   show.legend = F,fontface = 'bold',
                   hjust=0,vjust=0.8,
                   segment.size =0.8)+
  theme_minimal()+
  labs(caption = 'by @r0mymendez')+
  theme(plot.caption = element_text(size=14, family=""Atma Light""),
        axis.title = element_text(size=30, family=""Jadyn Maria Free""),
        plot.background = element_rect(fill = '#77939F'),
        panel.background = element_rect(fill = '#77939F'),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.x = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.grid.major.y = element_line(linetype = 2),
        axis.text = element_text(color = 'white')
        )

  

","2019-25"
"330",387,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190625-??/script.R","rm(list=ls())
ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

library(tidyverse)
library(grid)
library(gridExtra)
library(ggpubr)
library(ggrepel)
library(extrafont)


df=ufo_sightings%>%count(ufo_shape)%>%filter(is.na(ufo_shape)==F)
df=ufo_sightings%>%
  mutate(year=str_sub(date_time, -10, -7))%>%count(year)%>%
  mutate(year=as.numeric(year))%>%
  filter(as.numeric(year) %in% 1990:2014)


df_ufo=ufo_sightings%>%
  mutate(year=str_sub(date_time, -10, -7))%>%
  mutate(year=as.numeric(year),
         shape=ufo_shape)%>%
  filter(as.numeric(year) %in% 1990:2014)

df_ufo$id=seq_len(nrow(df_ufo))
dfsample=df_ufo%>%filter(df_ufo$id %in% sample(df_ufo$id,10))


img_a <- png::readPNG(""1.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 

img_b <- png::readPNG(""2.png"") 
b <- grid::rasterGrob(img_b, interpolate = T) 

world_map <- map_data(""world"")
g2=
  ggplot() +
  geom_polygon(data=world_map, aes(x = long, y = lat, group = group),
               fill=""#2a2a2a"", colour = ""#185060"")+
  geom_point(data=df_ufo,aes(x=longitude,y=latitude,color=shape))+
  annotation_custom(a, xmin =100, xmax =200,
                    ymin=50 ,ymax=90
                   ) +
  annotation_custom(b, xmin =50, xmax =100,
                    ymin=-50 ,ymax=-90
  ) +
  geom_label_repel(aes(label=described_encounter_length,x=longitude,y=latitude),
                   size=4, show.legend = F,
                   data=dfsample,fill ='#fffeea')+
  labs(x='',y='',title = paste0('UFO Sightings around the world ',emojifont::emoji('alien')),
       subtitle = 'FROM 1990-2014')+
  theme_void()+
  theme(
    legend.background = element_rect(fill='#2a2a2a'),
    legend.text = element_text(color='white'),
    plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
    panel.background =element_rect(fill='#2a2a2a'),
    legend.position=c(0.11, 0.32),
    legend.key = element_rect(fill = ""#2a2a2a"", color = NA),
    legend.title = element_text(color = ""white"", size = 10, hjust = 0.5),
    plot.title = element_text(family =     ""Atma""    ,
                              hjust = 0.5,
                              size=30,colour = '#00BFC4',
                              face = 'bold'),
    plot.subtitle =  element_text(family =     ""Atma Light""    ,
                                  hjust = 0.5,
                                  size=15,colour = '#00BFC4',
                                  face = 'bold'), 
  )

g2","2019-26"
"331",388,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190701/script.R","rm(list=ls())

library(tidyverse)
library(emojifont)
library(gridExtra)
library(grid)
library(ggrepel)
library(ggridges)

media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

df=media_franchises%>%
    mutate(category=
              case_when(
                revenue_category== ""Book sales""    ~ 'Book',
                revenue_category== ""TV""    ~ ""TV"",
                revenue_category== ""Video Games/Games""     ~ ""Video Games"",
                revenue_category== ""Comic or Manga""     ~ ""Comic"",
                revenue_category== ""Music""      ~ ""Music"" ,
                revenue_category== ""Box Office""      ~ ""Box Office"",
                revenue_category== ""Home Video/Entertainment""      ~ ""Entertainment"",
                revenue_category== ""Merchandise, Licensing & Retail""      ~ ""Merchandise""
              ),
            media=case_when(
                original_media==""Novel""             ~ ""Novel"",
                original_media==""Animated film""     ~ ""film"",
                original_media==""Video game""        ~ ""Video game"",
                original_media==""Manga""             ~ ""Manga"",
                original_media==""Comic book""        ~ ""Comic"",
                original_media== ""Animated series""  ~ ""series"",
                original_media==""Greeting card""     ~ ""card"",
                original_media== ""Film""             ~ ""Film"",
                original_media==""Visual novel""      ~ ""novel"",
                original_media==""Television series"" ~ ""series"",
                original_media==""Anime""             ~ ""Anime"",
                original_media==""Cartoon character"" ~ ""Cartoon"",
                original_media==""Cartoon""           ~ ""Cartoon"",
                original_media==""Animated cartoon""  ~ ""Cartoon"",
                original_media==""Comic strip""       ~ ""Comic"",
                original_media==""Musical theatre""   ~ ""Musical"",
                original_media==""Book""              ~ ""Book""
            )
    
    )
               


df.media=df%>%group_by(media)%>%summarise(revenue=sum(revenue))
df.category=df%>%group_by(category)%>%summarise(revenue=sum(revenue))
df.creators=df%>%group_by(creators)%>%summarise(revenue=sum(revenue))

df.franchise=df%>%group_by(franchise)%>%summarise(revenue=sum(revenue))%>%
  top_n(10,revenue)

img_a <- png::readPNG(""1.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""2.png"") 
b <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""3.png"") 
c <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""4.png"") 
d <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""5.png"") 
e <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""6.png"") 
f <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""7.png"") 
g <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""8.png"") 
h <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""9.png"") 
i <- grid::rasterGrob(img_a, interpolate = T) 

img_a <- png::readPNG(""10.png"") 
j <- grid::rasterGrob(img_a, interpolate = T) 

df.franchise%>%mutate(franchise=reorder(franchise,revenue))%>%
  ggplot()+
  geom_col(aes(x=franchise,y=revenue,fill=franchise),
           position = ""dodge"",color='#2a2a2a',show.legend = F)+
  annotation_custom(a, xmin = 9.5, xmax =10.5,
                    ymin = -30, ymax =50) +
  annotation_custom(b, xmin = 8.5, xmax =9.5,
                    ymin = -40, ymax =50) +
  annotation_custom(c, xmin = 7.5, xmax =8.6,
                    ymin = -25, ymax =50)+
  annotation_custom(d, xmin = 6.5, xmax =7.5,
                    ymin = -30, ymax =50)+
  annotation_custom(e, xmin = 5.0, xmax =6.5,
                    ymin = -30, ymax =50)+
  annotation_custom(f, xmin = 4.5, xmax =5.5,
                    ymin = -30, ymax =50)+
  annotation_custom(g, xmin = 3.5, xmax =4.5,
                    ymin = -20, ymax =50)+
  annotation_custom(h, xmin = 2.5, xmax =3.5,
                    ymin = -25, ymax =50)+
  annotation_custom(i, xmin = 1.0, xmax =3,
                    ymin = -30, ymax =50)+
  annotation_custom(j, xmin = 0.5, xmax =1.5,
                    ymin = -30, ymax =50)+
  labs(title = 'Media Franchise Powerhouses',x='')+
  theme_bw() +   
  theme(legend.position = 'top', 
        legend.spacing.x = unit(0.41, 'cm'),
        legend.text = element_text(margin = margin(t = 10),size=30))+
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        legend.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ),
        axis.text =  element_text(colour='white',family=""Atma Light"",size=12),
        axis.text.x = element_text(hjust = 1, angle=45),
        axis.title = element_text(colour='white', family=""Atma Light"",size=20),
        legend.title =  element_text(colour='white',size=20, family=""Atma Light""),
        plot.title =  element_text(colour = 'white',size=50,hjust = 0.5,
                                   family=""Atma Light"",face = 'bold'),
        plot.subtitle =  element_text(colour = 'white',size=12,hjust = 0.5,
                                      family=""Atma Light"",face = 'bold'),
        panel.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ))




","2019-26"
"332",389,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190813-Roman Emperors/script.R","rm(list=ls())
emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# Libraries
library(tidyverse)
library(grid)
library(ggpubr)

imgage1 <- jpeg::readJPEG(""8.jpg"")



df.as=
  emperors%>%
  count(cause)%>%
  ggplot(aes(x=cause,y=n))+
  annotation_custom(rasterGrob(imgage1, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_segment( aes(x=cause, xend=cause, y=0, yend=n),show.legend = F) +
  geom_point(aes(size=n),show.legend = F,alpha=0.5,stroke=2,color='#2a2a2a')+
  scale_size(range = c(4, 15))+
  labs(x='',y='')+
  annotate(""text"", label = 'Cause of death',
           x = 6.5, y = 21, size = 15,   family=""Jadyn Maria Free"",
           colour =""black"") +
  annotate(""text"", label = '_____________',
           x = 6.5, y = 20.8, size = 10,   family=""Jadyn Maria Free"",
           colour =""black"") +
  theme_bw()+
  theme(plot.background = element_rect(color='#CAA867',fill='#CAA867'),
        panel.background =  element_rect(color='#CAA867',fill='#CAA867'),
        axis.text.y = element_text(size=10,family=""Atma Light"",face = 'bold',
                                   color = 'black'),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        axis.text.x = element_text(size=20,family= ""Fabiana"",face = 'bold',
                                   color = 'black'))



df.as1=
  emperors%>%
  count(killer)%>%
  ggplot(aes(x=killer,y=n))+
  geom_segment( aes(x=killer, xend=killer, y=0, yend=n),show.legend = F) +
  geom_point(aes(size=n),show.legend = F,alpha=0.5,stroke=2,color='#2a2a2a')+
  scale_size(range = c(4, 10))+
  coord_flip()+
  annotate(""text"", label = 'Killers',
           x = 12, y = 16, size = 15,   family=""Jadyn Maria Free"",
           colour =""black"") +
  theme_bw()+
  labs(x='',y='')+
  theme(plot.background = element_rect(color='#CAA867',fill='#CAA867'),
        panel.background =  element_rect(color='#CAA867',fill='#CAA867'),
        axis.text.x =  element_text(size=10,family=""Atma Light"",face = 'bold',
                                     color = 'black'),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        axis.text.y = element_text(size=12,family= ""Fabiana"",
                                   color = 'black'))



ggarrange(df.as,df.as1,  nrow = 2,ncol=1,
 heights =  c(1,0.8))+
  labs(title='Roman Emperors',
       caption = 'by @r0mymendez')  +
  theme(plot.title = element_text(size=45,family = ""Fabiana""      ,
                                  hjust = 0.5,colour = 'white'),
        plot.caption = element_text(size=15,family = ""Atma""      ,
                                  hjust = 1,colour = 'white'),
        plot.background = element_rect(colour = 'black',fill='black'),
        panel.background = element_rect(colour = 'black',fill='black'))







","2019-33"
"333",390,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20190822-Nuclear Explosions/script.R","rm(list=ls())
nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")

library(rworldmap)
library(tidyverse)
library(ggplot2)
library(geosphere)
library(gpclib)
library('mapproj')
library(ggrepel)
library(gganimate)
library(ggpubr)
library(animation)


# World map
worldMap <- getMap()
world.points <- fortify(worldMap)
world.points$region <- world.points$id
world.df <- world.points[,c(""long"",""lat"",""group"", ""region"")]

max.year=max(nuclear_explosions$year)
min.year=min(nuclear_explosions$year)

invisible(
  saveGIF({
    
    
for (i in min.year:max.year){

worldmap <-
  ggplot() + 
  geom_polygon(data=worldMap, aes(x = long, y = lat, group = group),
               color=""#FFD300"", fill = ""#2a2a2a"") +
  theme_void()  +
  labs(title = 'Nuclear Explosions')+
  labs(caption = 'by @r0mymendez \n')+
  theme(
    legend.background = element_rect(fill='#2a2a2a'),
    legend.text = element_text(color='white'),
    plot.background = element_rect(fill='#FFD300',color ='#FFD300' ),
    panel.background =element_rect(fill='#FFD300')  ,
    legend.position=c(0.11, 0.32),
    legend.key = element_rect(fill = ""#2a2a2a"", color = NA),
    legend.title = element_text(color = ""white"", size = 20, hjust = 0),
    plot.title = element_text(family =    ""Bangers""    ,
                              hjust = 0.5,
                              size=50,colour = '#2A2A2A',
                              face = 'bold'),
    plot.subtitle =  element_text(family =     ""Atma Light""     ,
                                  hjust = 0.5,
                                  size=15, face = 'bold',
                                  colour = '#73d055ff' ),
    plot.caption = element_text(family =""Atma Light"",
                                hjust =0.9,
                                size=20, face = 'bold',
                                colour = 'black' )
  )+
  geom_point(data =  nuclear_explosions%>%filter(year == i),
             aes(x = longitude,
                 y = latitude,
                 size=magnitude_surface+0.5,
                 color=magnitude_body),
             alpha=0.3,show.legend = F)+
  scale_color_gradient(low=""#BF6068"", high=""#8C041D"")+
  scale_size_continuous(range = c(1,20))  
  
  p3 <- ggplot(data = NULL, aes(x = min.year:max.year , y = 1)) +
  geom_line() +
  geom_point(aes(fill = (x = min.year:max.year > i)), shape = 21, size = 5) +
  theme_void() +
  theme(legend.position = ""none"") +
  scale_fill_manual(values = c(""#b2d1e0"",""gold"")) +
  geom_text(aes(x = i, y = 1, label = i), vjust = -1, size = 9,
            family=""Bangers"" ,color='white') +
  theme(panel.background = element_rect(fill = ""	#fcfcfc"", colour = ""	#cccccc""))+
  theme(plot.background = element_rect(fill='#2a2a2a',color = 'black'))  

 print(ggarrange(worldmap,p3,nrow = 2,ncol = 1,heights =  c(1.4,0.3)))

}
  
    
      },
  movie.name = ""nuclearExplosions.gif"",  
  interval = 1,
  ani.width = 1200, 
  ani.height = 900))




?saveGIF


","2019-34"
"334",524,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-07-09/network_squads.R","csmontt","tidy-tuesdays","2019-07-09/network_squads.R","########################################################################
## Project: Women's World Cup 2019 Network Visualization
## Script purpose: To explore how countries and teams are connected
## Date: 15-07-2019
## Author: csmontt
########################################################################

options(stringsAsFactors = FALSE)

library(tidyverse)
library(here)
library(rvest)
library(R.utils)
library(tidygraph) # tidy graph analysis
library(ggraph)    # for plotting


# Scrape data ------------------------------------------------------------------------

url <- ""https://es.wikipedia.org/wiki/Anexo:Equipos_participantes_en_la_Copa_Mundial_Femenina_de_F%C3%BAtbol_de_2019""

html_content <- url %>% 
  read_html()

# get clubs ----
clubs <- html_content %>%
                html_nodes(""td:nth-child(6) , .jquery-tablesorter .flagicon+ a"") %>%
                html_text() %>% gsub(""^\\s+|\\s+$"", """", .)



# Get country of clubs ----
flags <- html_content %>%
                html_nodes(""a img"") %>% html_attr(""alt"")

flags <- flags[c(-(length(flags)-1), -length(flags))]

flags <- flags[-grep(""Capitn"", flags)]

inds <- grep(""equipo"", clubs)[1:3] #just the first three don't have flags

country_club <- insert(flags, inds, values=""?"")



# get countries ----
nationality <- html_content %>%
                html_nodes(""h2+ h3 , .plainrowheaders+ h3"") %>%
                html_text() %>% gsub(""^\\s+|\\s+$"", """", .) %>% gsub(""\\[editar\\]"", """", .)


nationality <- rep(nationality, each=23)



# combine all ----

df <- as.data.frame(cbind(nationality, clubs, country_club))

df <- df %>% group_by(nationality, clubs) %>% mutate(n_players = n()) # *5 so in visnetwork
                                                                    # the width is noticeable
                                                                    # in ggraph changes the legend
                                                                    # for visnetwork have
                                                                    # to call it width


# Vis --------------------------------------------------------------------------------
cuartos <- c(""Noruega"", ""Inglaterra"", ""Francia"", ""Estados Unidos"", ""Italia"", 
             ""Pases Bajos"", ""Suecia"", ""Alemania"")

df2 <- df[df$nationality %in% cuartos, ]


# there is some annoying character in netherlands name.
df2$nationality <- gsub(""P...es..ajos"", ""Pases Bajos"", df2$nationality)
df2$country_club <- gsub(""P...es..ajos"", ""Pases Bajos"", df2$country_club)


# Create graph -----
df_graph <- as_tbl_graph(df2, directed = FALSE) %>%
  mutate(n_rank_trv = node_rank_traveller(),
         neighbors = centrality_degree(),
         group = group_infomap(),
         center = node_is_center(),
         dist_to_center = node_distance_to(node_is_center()),
         keyplayer = node_is_keyplayer(k = 10)) %>%
  activate(edges) %>% 
  filter(!edge_is_multiple()) %>%
  mutate(centrality_e = centrality_edge_betweenness())



# create layout ----
layout <- create_layout(df_graph, 
                        layout = ""fr"")


# Add country of origin to layout, to colour the nodes by country
club_layout <- as.data.frame(layout$name)
names(club_layout) <- ""name""
df3 <- df2[, c(""clubs"", ""country_club"")]
df3 <- df3[!duplicated(df3), ]
club_layout2 <- left_join(club_layout, df3, by = c(""name"" = ""clubs""))
club_layout2$country_club <- ifelse(is.na(club_layout2$country_club), club_layout2$name, 
                               club_layout2$country_club)
layout$group <- club_layout2$country_club

# Create vis ----
ggraph(layout) + 
    geom_edge_density(aes(fill = n_players)) +
    geom_edge_link(aes(width = n_players), alpha = 0.2) + 
    geom_node_point(aes(color = factor(group)), size = 3) +
    geom_node_text(aes(label = name), size = 2, repel = TRUE) +
    theme_graph() +
    labs(title = ""Women's World Cup 2019: Where do players of each country play?"",
         subtitle = ""The connectiveness of quarter round finalists"",
         caption = ""Source: Wikipedia | Vis: @csmontt"") +
    scale_colour_discrete(name  =""Country"") #,
                          #labels = c(""Germany"", ""Spain"", ""United States"", 
                          #           ""France"", ""England"", ""Italy"", ""Norway"",
                          #           ""Netherlands"", ""Sweden""))
                                   

ggsave(here(""figures"", ""network_football_women.png""), width = 11, height = 6)


# option, use visNetwork
library(visNetwork)
df_graph %>% as.igraph() %>%
  visIgraph(idToLabel = TRUE) %>% # remove long url labels from underneath nodes
  visOptions(highlightNearest = TRUE) #%>%
  #visLegend()","2019-28"
"335",525,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/custom_theme.R","custom_theme <- function () 
{
    font <- ""Consolas""
    ggplot2::theme(plot.title = ggplot2::element_text(family = font, 
                         size = 10, face = ""bold"", color = ""#222222"", hjust = 0.5), 
                         plot.subtitle = ggplot2::element_text(family = font, 
                         size = 8, 
                         margin = ggplot2::margin(1, 0, -30, 0)), 
                   legend.position = c(0.50, 0.15), 
                   #legend.position = ""none"",
                   legend.text.align = 0, 
                   legend.title = ggplot2::element_blank(), 
                   legend.key = ggplot2::element_blank(), 
                   legend.key.size = unit(0.65,""line""),
                   legend.text = ggplot2::element_text(family = font, size = 6, 
                   color = ""black""), 
                   legend.direction = ""horizontal"",
                   axis.title = ggplot2::element_blank(), 
                   axis.text = ggplot2::element_text(family = font, size = 8, 
                   color = ""#222222""), 
                   axis.text.x = ggplot2::element_blank(), # , angle = 20
                   axis.text.y = ggplot2::element_blank(),
                   axis.ticks = ggplot2::element_blank(), 
                   axis.line = ggplot2::element_blank(), 
                   panel.grid.minor = ggplot2::element_blank(), 
                   # facet labels
                   #strip.background = element_rect(color=""transparent"", 
                   #                                fill=""transparent""),
                   #strip.text.x = element_text(size = 12, color = ""black"",
                   #                            family = font,
                   #                            face = ""bold""), #, face = ""bold.italic""
                   #horizontal line color
                   plot.caption=element_text(hjust=1,size=5, family = font),
        panel.grid.major.y = ggplot2::element_blank(), 
        panel.grid.major.x = ggplot2::element_blank(), 
        plot.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        panel.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        legend.background = element_rect(fill = ""#f5f5f2"", color = NA),
        strip.text = ggplot2::element_text(size = 10, hjust = 0)) 
}","2019-33"
"336",526,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/custom_theme2.R","custom_theme2 <- function () 
{
    font <- ""Consolas""
    ggplot2::theme(plot.title = ggplot2::element_text(family = font, 
                         size = 10, face = ""bold"", color = ""#222222"", hjust = 0.5), 
                         plot.subtitle = ggplot2::element_text(family = font, hjust = 0.5,
                         size = 8, 
                         margin = ggplot2::margin(1, 0, -30, 0)), 
                   legend.position = c(0.50, 0.17), 
                   #legend.position = ""none"",
                   legend.text.align = 0, 
                   legend.title = ggplot2::element_blank(), 
                   legend.key = ggplot2::element_blank(), 
                   legend.key.size = unit(0.65,""line""),
                   legend.text = ggplot2::element_text(family = font, size = 6, 
                   color = ""black""), 
                   legend.direction = ""horizontal"",
                   axis.title = ggplot2::element_blank(), 
                   axis.text = ggplot2::element_text(family = font, size = 8, 
                   color = ""#222222""), 
                   axis.text.x = ggplot2::element_text(vjust = 125, size = 5), # , angle = 20
                   axis.text.y = ggplot2::element_blank(),
                   axis.ticks = ggplot2::element_blank(), 
                   #axis.ticks.x = ggplot2::element_line(vjust = 135), 
                   axis.line = ggplot2::element_blank(), 
                   panel.grid.minor = ggplot2::element_blank(), 
                   # facet labels
                   #strip.background = element_rect(color=""transparent"", 
                   #                                fill=""transparent""),
                   #strip.text.x = element_text(size = 12, color = ""black"",
                   #                            family = font,
                   #                            face = ""bold""), #, face = ""bold.italic""
                   #horizontal line color
                   plot.caption=element_text(hjust=0.5,size=5, family = font),
        panel.grid.major.y = ggplot2::element_blank(), 
        panel.grid.major.x = ggplot2::element_blank(), 
        plot.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        panel.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        legend.background = element_rect(fill = ""#f5f5f2"", color = NA),
        strip.text = ggplot2::element_text(size = 10, hjust = 0)) 
}","2019-33"
"337",527,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/emperor_death_scarf.R","
library(tidyverse)
library(lubridate)
library(here)
library(extrafont)

loadfonts(device=""win"")
font <- ""Consolas""


source(here(""2019-08-13"", ""custom_theme.R""))

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

emperors$reign_start[1] <- lubridate::ymd(""0026/01/16"") - lubridate::years(52)
emperors$years_rule <- emperors$reign_end - emperors$reign_start
emperors$nothing <- ""nothing""
emperors2 <- emperors %>% filter(cause != ""Unknown"")


p <- ggplot(emperors2, aes(x = 1:nrow(emperors2), y=nothing,
                           fill=cause)) +
  geom_tile(color=""#f5f5f2"", height=0.35) +
        custom_theme() + guides(fill = guide_legend(nrow = 1)) +
        scale_fill_brewer(palette=""Set3"") +
        scale_x_continuous(expand = c(0,0)) +
        labs(title = ""\n\n\n\n\n\n\n\n\n\n\nHow Roman Emperors Died"",
        subtitle = ""                                                                       one tile one emperor"",
        caption = ""Data: Wikipedia via @geokaramanis | Vis: @Cristobal_Montt"") 
p  

p2 <- p + geom_segment(aes(x = 0.5, y = 0.81, xend = 0.5, yend = 1.2),linetype = ""dotted"") + 
#annotate(""rect"", linetype = ""dotted"", xmin = 0.47, xmax = 0.48, ymin = 0.81, ymax = 1.2, color = ""black"") +
    #annotate(""rect"", linetype = ""dotted"", xmin = 5.5, xmax = 5.51, ymin = 0.81, ymax = 1.2, color = ""black"") +
    geom_segment(aes(x = 5.52, y = 0.81, xend = 5.52, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 11.51, y = 0.81, xend = 11.51, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 18.50, y = 0.81, xend = 18.50, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 26.51, y = 0.81, xend = 26.51, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 46.5, y = 0.81, xend = 46.5, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 60.5, y = 0.81, xend = 60.5, yend = 1.2),linetype = ""dotted"") +
        geom_segment(aes(x = 64.52, y = 0.81, xend = 64.52, yend = 1.2),linetype = ""dotted"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 11.5, xmax = 11.51, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 18.48, xmax = 18.49, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 26.49, xmax = 26.5, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 46.5, xmax = 46.51, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 60.48, xmax = 60.49, ymin = 0.81, ymax = 1.2, color = ""black"") +
    # annotate(""rect"", linetype = ""dotted"", xmin = 64.49, xmax = 64.5, ymin = 0.81, ymax = 1.2, color = ""black"") + 
    annotate(""text"", x = 2.98, y = 1.23, label = ""Julio-Claudian"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 8.4, y = 1.23, label = ""Flavian"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 15, y = 1.23, label = ""Nerva-Antonine"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 22.3, y = 1.23, label = ""Severan"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 36, y = 1.23, label = ""Gordian"", 
             color = ""black"", size = 2.23, family = font) + 
    annotate(""text"", x = 53.5, y = 1.23, label = ""Constantinian"", 
             color = ""black"", size = 2.23, family = font) +
    annotate(""text"", x = 62.5, y = 1.23, label = ""Valentinian"", 
             color = ""black"", size = 2.23, family = font)
   
ggsave(here(""figures"", ""2019-08-13.png""), plot = p, width = 10, height = 6)  
ggsave(here(""figures"", ""2019-08-13b.png""), plot = p2, width = 10, height = 6)  

# other plots ----------------------------------------------------------------------------
# need to change the theme so the axis are visible
new_dest <- paste0(emperors$name, "" ("", emperors$reign_start, "")"")
emperors$names_ordered <- reorder(emperors$name, emperors$reign_start)

ggplot(emperors, aes(x = reign_start, y=names_ordered,  fill=cause)) +
  geom_tile(color=""#f5f5f2"", width=emperors$years_rule, height=1) +
        custom_theme()

ggplot(emperors, aes(x = reign_start, y=nothing,  fill=cause)) +
  geom_tile(color=""#f5f5f2"", width=emperors$years_rule*1.3, height=1) +
        custom_theme()
","2019-33"
"338",528,"https://github.com/csmontt/tidy-tuesdays/tree/master/2019-08-13","csmontt","tidy-tuesdays","2019-08-13/emperor_death_scarf_days.R","library(tidyverse)
library(lubridate)
library(here)
library(extrafont)

loadfonts(device=""win"")
font <- ""Consolas""


source(here(""2019-08-13"", ""custom_theme2.R""))

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

emperors$reign_start[1] <- lubridate::ymd(""0026/01/16"") - lubridate::years(52)
emperors$years_rule <- as.numeric(emperors$reign_end - emperors$reign_start)


emperors$gp <- seq(from = nrow(emperors), to = 1)
p3 <- ggplot(emperors, aes(x=""thing"", y=years_rule, fill=cause, group=factor(gp))) + 
       geom_bar(stat=""identity"", colour=""#f5f5f2"", width = 0.3, size = 0.001)  +
       scale_fill_brewer(palette=""Set3"") +
       guides(fill = guide_legend(nrow = 1)) +
       labs(title = ""\n\n\n\n\n\n\n\n\nHow Roman Emperors Died"",
       subtitle = ""one tile one emperor"",
       caption = ""Data: Wikipedia via @geokaramanis | Vis: @Cristobal_Montt"") +
       scale_y_continuous(breaks = c(0, 50000, 150000, 200000)) +
       coord_flip() +
       custom_theme2() +
       annotate(""text"", x = 0.831, y = 100000, label = ""Days since the beginning of the Roman Empire"", 
             color = ""black"", size = 1.8, family = font)
p3

ggsave(here(""figures"", ""2019-08-13c.png""), plot = p3, width = 10, height = 6)  
","2019-33"
"339",529,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-06-18/birds-time-series.R","csmontt","tidy-tuesdays","2019-06-18/birds-time-series.R","########################################################################
## Project: Tidytuesday 2019-06-18
## Script purpose: Create an animated time series of bird counts per hour
## over the last 60 years
##
## Date: 2019-06-18
## Author: csmontt
########################################################################
options(scipen = 999)

library(tidyverse)
library(plotly)
library(animation)
library(RColorBrewer)
library(here)

source(here(""2019-06-18"", ""theme_custom.R""))

# idea from 
# https://towardsdatascience.com/animating-your-data-visualizations-like-a-boss-using-r-f94ae20843e3
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")


# consider years where there is no missing data
nas_year <-  bird_counts %>% group_by(year) %>% 
        summarize(total_nas = sum(is.na(how_many_counted_by_hour)))

# get the latest interval of years without missing values 
# It gives back the row index of the last year with missing data
nas_year$missing <- nas_year$total_nas > 0
last_ind_missing = NA
for(i in 1:nrow(nas_year)){
        if (nas_year$missing[i] == TRUE){
                last_ind_missing <- i
        } 
}

nas_year <- nas_year[last_ind_missing + 1:nrow(nas_year), ]

# Im keeping only the interval of years without missing data (every year since
# 1950)
bird_counts <- bird_counts %>% filter(bird_counts$year %in% nas_year$year)

# keep the three most observed species over time, otherwise plot gets too 
# clutter
most_observed <- bird_counts %>% group_by(species) %>% 
        summarize(total_obs  = sum(how_many_counted)) %>%
        arrange(desc(total_obs)) %>% head(3)

most_obs_species <- most_observed$species


bird_filtered <- bird_counts %>% 
        filter(species %in% most_obs_species) %>%
        select(year, species, how_many_counted_by_hour)

# convert species to factor
bird_filtered$species<-as.factor(bird_filtered$species)


# animation --------------------------------------------------------------------
# set some of the options 
ani.options(interval = 0.2, 
            nmax = 100, ani.width = 800)

## The good animation as a simple GIF
saveGIF({
  end_year = 2017 #last year of the plot
  num_years = length(unique(bird_filtered$year)) #number of years in the animation
  #create a loop that does the subsetting
  for(i in 1:num_years){
    bird_subset <- bird_filtered %>% filter(year <= end_year-(num_years-i))
    #write the plot with a subset
    p<-ggplot(bird_subset,aes(x=year,y=how_many_counted_by_hour,
                                group=species,colour=species)) +
      geom_line(size = 1.5) +
      scale_x_continuous(breaks=c(1950, 1960, 1970, 1980, 1990, 2000, 2017)) +
      ylim(0,440)+
      xlab('') +
      ylab('') +
      scale_colour_brewer(palette=""Dark2"") +
      theme_custom() +
      labs(title=""Birds count per hour"", caption=""Data: www.birdscanada.org | Vis: @cristobal_montt"") +
      guides(fill=guide_legend(title=""Species""))
      print(p)
  }#close the for loop
  
}, movie.name = here(""figures"", ""2019-06-18.gif"")) #close the animation builder





","2019-25"
"340",530,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-07-02/box_plot_media_franchise.R","csmontt","tidy-tuesdays","2019-07-02/box_plot_media_franchise.R","########################################################################
## Project: tidytuesdays
## Script purpose: a simple annotated boxplot
##
##
## Date: 02-07-2019
## Author: csmontt
########################################################################
library(devtools)
library(extrafont)
library(here)
loadfonts(device = ""win"")
library(tidyverse)

source(here(""2019-07-02"", ""custom_theme.R""))

# load data --------------------------------------------------------------------------                     
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

# delete duplicates
media_franchises <- media_franchises[!duplicated(media_franchises), ]

# get most succesful media franchise by cateory
max_revenue <-  media_franchises %>% group_by(revenue_category) %>% 
        slice(which.max(revenue)) %>% tidyr::unnest()

# create plot
ggplot(media_franchises, 
              aes(x = factor(revenue_category), y = revenue, fill = revenue_category)) + 
        geom_boxplot() + custom_theme() +
        geom_text(data = max_revenue, 
              aes(x = factor(revenue_category), y = revenue, label = franchise, 
                  family = ""Century Gothic""), 
              nudge_x = 0, nudge_y = 2, size = 2) +
        labs(title=""Most succesful media franchises"",
             subtitle = ""Revenue in billions by media category"",
             caption = ""Source: Wikipedia | Vis: @csmontt"") +
        guides(fill=guide_legend(nrow=1))

# save plot
ggsave(here(""figures"", ""media_franchise_boxplot.png""), width = 11, height = 6)





","2019-27"
"341",531,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-07-16/streamgrapgh_R_slack.R","csmontt","tidy-tuesdays","2019-07-16/streamgrapgh_R_slack.R","library(tidyverse)
library(streamgraph)

# read the data ----

r4ds_members <-
        readr::read_csv(
                ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv""
        )

inds <- grep(""messages_in"", names(r4ds_members))
r4ds_members <- r4ds_members[, c(inds, 1)]

names(r4ds_members) <-
        c(
                'Messages in public channels',
                'Messages in private channels',
                'Messages in shared channels',
                'messages in Direct Messages',
                'date'
        )

# wide to long ----

r4ds_long <- gather(
        r4ds_members,
        message_type,
        total,
        'Messages in public channels':'messages in Direct Messages',
        factor_key = TRUE
)


# Create streamgraph ----
r4ds_long %>%
        group_by(date, message_type) %>%
        tally(wt = total) %>%
        streamgraph(""message_type"", ""n"", ""date"") %>%
        sg_axis_x(1, ""month"", ""%b/%Y"")







        
        
","2019-29"
"342",532,"https://github.com/csmontt/tidy-tuesdays/blob/master/2019-06-10/gganimate_meteorites.R","csmontt","tidy-tuesdays","2019-06-10/gganimate_meteorites.R","########################################################################
## Project: Tidy Tuesday 2019-10-04
## Script purpose: Use gganimate package to create an animate vis
## of meteorite collisions over time
##
## Date: 2019-06-10
## Author: csmontt
########################################################################

library(ggplot2)
library(ggthemes)
library(gganimate)


# Get base map
world <- ggplot() +
  borders(""world"", colour = ""#353535"", fill = ""#353535"") +
  theme_map()

# Read data
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

meteorites <- meteorites[!is.na(meteorites$lat) & !is.na(meteorites$year), ]

# Took the log of mass and divided it by 5, so when using this new 
# variable to size the geom_points in ggplot they didn't get too big.
meteorites <- meteorites %>% mutate(log_mass = log(mass)/5) %>%
        filter(year >= 1800 & year <= 20013)


# Specifiy vis
met_map <- world + geom_point(data = meteorites, 
               x = meteorites$long,
               y = meteorites$lat,
               color = ""#ffa500"",
               alpha = 0.7,
               size = meteorites$log_mass) + 
           transition_states(meteorites$year, 
                          transition_length = 1, 
                          state_length = 1) +
           shadow_mark(past=TRUE) +
           theme(plot.title = element_text(color = ""white"", 
                                           size = 20, 
                                           face = ""bold"",
                                           vjust = -10),
                 panel.background = element_rect(fill = ""#35535F"")) +
           labs(title = ""{closest_state}"")

options(gganimate.dev_args = list(width = 1000, height = 600))
ani_met <- animate(met_map, nframes = 300, fps=10, detail = 1)

# Save GIF
anim_save(""./figures/2019-06-10.gif"")

# To do:
# Should have specified more frames as 300 were not enough to show all 
# years with data.
# Add a lbel for the mass of the meteorites, maybe create categories instead
# of using a continous variable.
# add mapping by color to denote type of meteorite.

","2019-23"
"343",690,"https://github.com/jthomasmock/tidytuesday_projects/blob/master/2019/2019-02-09/tennis_grandslams.R","jthomasmock","tidytuesday_projects","2019/2019-02-09/tennis_grandslams.R","library(tidyverse)

# read in data
player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")
grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")
grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

# get age
age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>%
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age, gender) %>%
  summarize(counts = n()) %>%
  group_by(name) %>%
  mutate(total_wins = cumsum(counts)) %>%
  arrange(desc(total_wins)) %>%
  ungroup() %>%
  mutate(age = age / 365)

# find top 5 players
top_players <- age_slams_comb %>%
  group_by(name) %>%
  top_n(1, total_wins) %>%
  ungroup() %>%
  top_n(5, total_wins) %>%
  pull(name)

# create plot dataframe
plot_data <- age_slams_comb %>%
  ungroup() %>%
  mutate(
    colour = case_when(
      name == ""Serena Williams"" ~ ""#003399"",
      name == ""Steffi Graf"" ~ ""#FF2B4F"",
      name == ""Roger Federer"" ~ ""#fcab27"",
      name == ""Chris Evert"" ~ ""#3686d3"",
      name == ""Martina Navratilova"" ~ ""#88398a"",
      T ~ ""gray80""),
    name = fct_reorder(name, total_wins)
    ) %>%
  mutate(hj = if_else(name == ""Chris Evert"", 1, 0))

# plot - a lot of borrowing from John Burn-Murdoch
# https://gist.github.com/johnburnmurdoch/bd20db77b2582031604ccd1bdc4be582

(plot_slams <- ggplot(
  plot_data,
  aes(age, total_wins,
    group = name, col = colour, fill = colour,
    alpha = name %in% top_players)) +
  theme_minimal() +
  geom_step(aes(size = name %in% top_players)) +
  geom_point(data = . %>%
    group_by(name) %>%
    top_n(1, total_wins), shape = 21, aes(col = colour), size = 2.5, stroke = 1) +
  geom_text(
    data = . %>%
      group_by(name) %>%
      top_n(1, total_wins) %>%
      filter(name %in% top_players) %>%
      mutate(
        first_initial = str_sub(name, 1, 1),
        last_name = gsub("".+\\s"", """", name),
        short_name_wins = paste0(""  "", first_initial, "". "", last_name, "":"", total_wins, ""  "")),
    aes(label = short_name_wins, hjust = hj), family = ""Roboto Mono Medium"") +
  scale_color_identity() +
  scale_fill_identity() +
  scale_alpha_manual(values = c(0.7, 1), guide = F) +
  scale_size_manual(values = c(0.5, 0.8), guide = F) +
  scale_x_continuous(limits = c(15, 40), breaks = seq(15, 35, 5), expand = c(0, 0)) +
  scale_y_continuous(position = ""right"", expand = expand_scale(add = c(0, 5))) +
  tomtom::theme_tom() +
  theme(
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = ""gray85"", size = 0.3),
    axis.ticks.y = element_blank(),
    axis.ticks.x = element_line(color = ""#212121"", size = 0.3),
    axis.ticks.length = unit(0.2, ""cm""),
    axis.line.x = element_line(size = 0.3, color = ""#212121""),
    axis.text.y.right = element_text(hjust = 1),
    axis.title.y = element_blank(),
    plot.caption = element_text(hjust = 0, face = ""bold""),
    text = element_text(family = ""Roboto Mono"")) +
  labs(
    x = ""\nAge"",
    y = """",
    title = ""Serena owns the most Grand Slam wins, but was less efficient than Graf"",
    subtitle = ""Cumulative Open Era Grand Slams won, by age"",
    caption = ""\nSource: Wikipedia | Graphic: Thomas Mock / @thomas_mock"")
  )

ggsave(""top_slams.png"", width = 14, height = 8, units = ""in"")

colorblindr::cvd_grid(plot_slams)
","2019-6"
"344",740,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/roman_emperors.R","JonathonMifsud","tidytuesday","2019/code/roman_emperors.R","# Roman Emperors TidyTuesday
# 13/08/19


library(tidyverse)
library(lubridate)
library(scales)
library(ggraph)
library(igraph)
library(viridis)
library(treemap)
library(data.tree)  

# Data
emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# Cleaning
circle_data <- emperors %>% 
  select(name, cause, reign_start, reign_end, dynasty) %>%
  mutate(span = interval(ymd(reign_start), ymd(reign_end))) %>% 
  mutate(spandays = abs(span %/% days(1))) %>%
  mutate(spanmonths = round(spandays / 30)) %>% # length of reign in days
  mutate(spanyears = round(spanmonths / 12) + 1) %>% # length of reign in months
  select(-reign_start, -reign_end)

# Here I transform the dataframe into a hierarchical structure which is used for circle stacking plots. I was planning to have 3 levels of depth:
# 1. Cause of death 2. Dynasty and 3. Emperor Name and use the length of reign to size the circle but I ran out of time to do so. 

circle_data$pathString <- paste(""start"", 
                            circle_data$cause, 
                            circle_data$name,
                            sep = ""/"")
hier_emperors <- as.Node(circle_data, mode = ""table"")
hier_clone <- Clone(hier_emperors)
hier_network <- ToDataFrameNetwork(hier_clone, ""spandays"", ""spanmonths"", ""spanyears"") #spandays etc is added to the network
mygraph <- graph_from_data_frame(hier_network)

set.seed(123)
gg <- ggraph(mygraph, layout = 'circlepack') + 
  geom_node_circle(aes(fill = as.factor(depth), color = as.factor(depth))) +
  scale_fill_manual(values=c(""0"" = ""white"", ""1"" = viridis(4)[3], ""2"" = viridis(4)[4])) +
  scale_color_manual( values=c(""0"" = ""white"", ""1"" = ""black"", ""2"" = ""black"", ""3"" = ""black"", ""4""=""black"") ) +
  annotate(""text"", x = -6,9, y = 5.4, fontface = ""bold"", size = 5.5, label = ""Assassination"") + #text annotations
  annotate(""text"", x = 5.2, y = 6.1, fontface = ""bold"", size = 5.5, label = ""Execution"") +
  annotate(""text"", x = 7.2, y = 1.8, fontface = ""bold"", size = 5.5, label = ""Unknown"") +
  annotate(""text"", x = 5.3, y = -3.2, fontface = ""bold"", size = 5.5, label = ""Captivity"") +
  annotate(""text"", x = 5.4, y = -5.3, fontface = ""bold"", size = 5.5, label = ""Natural Causes"") +
  annotate(""text"", x = -6.4, y = -5.0, fontface = ""bold"", size = 5.5, label = ""Died in Battle"") +
  annotate(""text"", x = 1, y = -0.2, fontface = ""bold"", size = 5.5, label = ""Suicide"") +
  theme_void()+
  theme(legend.position=""FALSE"",
    plot.title = element_text(hjust = 0.5, size = 26),
    plot.subtitle = element_text(hjust = 0.5, size = 22),
    plot.caption = element_text(size = 8,
                                color = ""#939184"")
  )
 

arrows <- tibble(    
  x2 = c(-4.6,4.3,5.6,4.3,4.3,-5.2),    
  x1 = c(-6,5,6.5,5,5,-6.2),    
  y2 = c(4,4.6,0.4,-2.3,-4.3,-4.3),    
  y1 = c(5,5.7,1.5,-3,-5,-4.8)  
)  

gg1 <-gg +    geom_curve(data = arrows, aes(x = x1, y = y1, xend = x2, yend = y2),
                       arrow = arrow(length = unit(0.1, ""inch"")),
                       size = 1, color = ""black"", curvature = 0.15)  

ggfull <- gg1 + labs(title = ""Roman Emperors:"", subtitle = ""How they meet their end"", caption = ""Author: @jonathon_mifsud, Source: Wikipedia / Zonination"") 
ggsave(
  ""emperors.png"",
  plot = ggfull,
  width = 40,
  height = 30,
  units = ""cm""
)



















## Drafts ##
data <- emperors %>% 
  select(name, cause, reign_start, reign_end, dynasty) %>%
  mutate(span = interval(ymd(reign_start), ymd(reign_end))) %>% 
  mutate(spandays = abs(span %/% days(1))) %>% 
  mutate(spanmonths = round(spandays / 30)) %>% 
  mutate(spanyears = round(spanmonths / 12) + 1)

# Set a number of 'empty bar' to add at the end of each group
empty_bar <- 3
to_add <- data.frame( matrix(NA, empty_bar*nlevels(data$cause), ncol(data)) )
colnames(to_add) <- colnames(data)
to_add$cause <- rep(levels(data$cause), each=empty_bar)
data <- rbind(data, to_add)
data <- data %>% arrange(cause)
data$id <- seq(1, nrow(data))

# Get the name and the y position of each label
label_data <- data
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
label_data$hjust <- ifelse( angle < -90, 1, 0)
label_data$angle <- ifelse(angle < -90, angle+180, angle)

# prepare a data frame for base lines
base_data <- data %>% 
  group_by(cause) %>% 
  summarize(start=min(id), end=max(id) - empty_bar) %>% 
  rowwise() %>% 
  mutate(title=mean(c(start, end)))

# prepare a data frame for grid (scales)
grid_data <- base_data
grid_data$end <- grid_data$end[ c( nrow(grid_data), 1:nrow(grid_data)-1)] + 1
grid_data$start <- grid_data$start - 1
grid_data <- grid_data[-1,]

# Make the plot
p <- ggplot(data, aes(x=as.factor(id), y=spanyears, fill=cause)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  
  geom_bar(aes(x=as.factor(id), y=spanyears, fill=cause), stat=""identity"", alpha=0.5) +
  
  # Add a val=100/75/50/25 lines. I do it at the beginning to make sur barplots are OVER it.
  geom_segment(data=grid_data, aes(x = end, y = 33, xend = start, yend = 33), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  geom_segment(data=grid_data, aes(x = end, y = 23, xend = start, yend = 23), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  geom_segment(data=grid_data, aes(x = end, y = 13, xend = start, yend = 13), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  geom_segment(data=grid_data, aes(x = end, y = 3, xend = start, yend = 3), colour = ""grey"", alpha=1, size=0.3 , inherit.aes = FALSE ) +
  
  # Add text showing the value of each 100/75/50/25 lines
  annotate(""text"", x = rep(max(data$id),4), y = c(3, 13, 23, 33), label = c(""100"", ""200"", ""300"", ""400"") , color=""grey"", size=3 , angle=0, fontface=""bold"", hjust=1) +
  
  geom_bar(aes(x=as.factor(id), y=spanyears, fill=cause), stat=""identity"", alpha=0.5) +
  ylim(-100,40) +
  theme_minimal() +
  theme(
    legend.position = ""none"",
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), ""cm"") 
  ) +
  coord_polar() + 
  geom_text(data=label_data, aes(x=id, y=spanyears+10, label=name), color=""black"", fontface=""bold"",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE )+
  
  
  # Add base line information
  geom_segment(data=base_data, aes(x = start, y = -5, xend = end, yend = -5), colour = ""black"", alpha=0.8, size=0.6 , inherit.aes = FALSE )  +
  geom_text(data=base_data, aes(x = title, y = -18, label=cause), colour = ""black"", alpha=0.8, size=4, fontface=""bold"", inherit.aes = FALSE)

p

hjust <- c(0,0,1,1)



","2019-33"
"345",741,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/bobross.R","JonathonMifsud","tidytuesday","2019/code/bobross.R","## TidyTuesday 05/08/19
## Bob Ross Paintings

library(tidyverse)
library(ggridges)
library(viridis)# for scale_fill_viridis in one of the extra plots
library(hrbrthemes) # for theme_ipsum in main plot

bob_ross <-
  readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv""
  )

## In total we have 31 seasons each with a number of episodes.
## I am thinking of combining all elements into a total count.
## With this I will look at whether the total count of elements
## changes across seasons.


# to clean up the episode information
bob_ross <- bob_ross %>%
  janitor::clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer)

bobepiseason <- bob_ross %>%
  select(-title) %>%
  mutate(rowsum = rowSums(.[3:69])) %>% #sum all elements across each row
  select(season, episode, rowsum) %>%
  mutate(episode = as.factor(episode))



# Final plot
plot <- bobepiseason %>%
  mutate(episode = fct_rev(episode)) %>%
  ggplot(aes(y = episode, x = rowsum, fill = episode)) +
  geom_density_ridges(
    alpha = 0.6,
    stat = ""binline"",
    bins = 18,
    binwidth = 1,
    scale = 0.95
  ) +
  geom_text( # adding the numbers for each bin
    stat = ""bin"",
    aes(
      y = group + 0.95 * (..count.. / max(..count..)),
      label = ifelse(..count.. > 0, ..count.., """")
    ),
    vjust = 1,
    size = 3,
    color = ""black"",
    binwidth = 1
  ) +
  annotate( #annotation next to arrow
    ""text"",
    x = 13.7,
    y = 7.55,
    fontface = ""bold"",
    size = 3.5,
    label = ""Across all seasons Episode 7 \n had 11 elements on 4 occasions""
  ) +
  theme_ridges(grid = FALSE) +
  theme(
    legend.position = ""none"",
    strip.text.x = element_text(size = 8),
    axis.title.x = element_text(hjust = 0.5, face = ""bold""),
    axis.title.y = element_text(hjust = 0.5, face = ""bold""),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5),
    plot.caption = element_text(size = 8,
                                color = ""#939184"")
  )


# adding Labels
plot <- plot + labs(
  x = ""Number of Elements in a Painting"",
  y = ""Episode Number"",
  title = ""Are the number of elements to each Bob Ross painting consistent across each episode?"",
  subtitle = ""Occurence across all 33 seasons"",
  caption = ""Author: @jonathon_mifsud, Source: FiveThirtyEight""
)

# arrows
arrows <-
  tibble(x1 = 12.3, #arrow coords
         x2 = 11.6,
         y1 = 7.7,
         y2 = 7.3) 

# adding arrows
p <- plot + geom_curve(
    data = arrows,
    inherit.aes = FALSE,
    aes(
      x = x1,
      y = y1,
      xend = x2,
      yend = y2),
    arrow = arrow(length = unit(0.10, ""inch"")),
    size = 0.8,
    color = ""gray20"",
    curvature = 0.20
  )

# saving plot
ggsave(
  ""bobross.png"",
  plot = p,
  width = 40,
  height = 18,
  units = ""cm""
)





## Extras
bobseason <- bob_ross %>%
  select(-title,-episode) %>%
  group_by(season) %>%
  summarise_all(list(totalsum = sum)) %>%
  mutate(rowsum = rowSums(.[2:68])) %>%
  select(season, rowsum)

bobepisode <- bob_ross %>%
  select(-title) %>%
  group_by(episode) %>%
  summarise_all(list(totalsum = sum)) %>%
  mutate(rowsum = rowSums(.[3:68])) %>%
  mutate(episode = as.factor(episode)) %>%
  select(episode, rowsum) %>%
  na.omit

# First draft of final plot
ggplot(bobepiseason, aes(x = rowsum, y = episode, fill = episode)) +
  geom_density_ridges(scale = 1,
                      jittered_points = TRUE,
                      alpha = 0.8) +
  theme_ridges() +
  theme(legend.position = ""none"")

# Second draft of final plot
ggplot(bobepiseason, aes(x = `rowsum`, y = `episode`, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(name = ""rowsum"", option = ""F"") +
  labs(title = 'Title') +
  theme_ipsum() +
  theme(
    legend.position = ""none"",
    panel.spacing = unit(0.1, ""lines""),
    strip.text.x = element_text(size = 8)
  )
","2019-32"
"346",742,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/birdstrikes.R","JonathonMifsud","tidytuesday","2019/code/birdstrikes.R","###########################################
##      TidyTuesday Bird Strikes         ##
##            Jonathon Mifsud            ##
###########################################

library(rstudioapi)
library(tidyverse)
library(magrittr)
library(lintr)
library(sf)
library(raster)
library(viridis)
library(cowplot)
library(rvest)
library(albersusa)
### Cleaning

# I wanted to try a spatial plot this week. The dataset provided would need some rearranging for this to work.
# The first thing I did was look for infomation on how busy each airport in the US is.
# From this I can gather a really rough estimate of the amount of flights and aggregate this acrosss each state.
# I then can compare this to the number of bird strike incidents.
# Airport data taken from tables found in https://en.wikipedia.org/wiki/List_of_the_busiest_airports_in_the_United_States

airport_data <-
  read_html(
    ""https://en.wikipedia.org/wiki/List_of_the_busiest_airports_in_the_United_States""
  )

# The tables came in two parts with slightly different headings so I extracted them, cleaned and join them together
# Used rvest to import the table and the chrome extension SelectorGadget to obtain the xpath's

ad1 <- airport_data %>%
  html_node(xpath = '//*[@id=""mw-content-text""]/div/table[1]') %>%
  html_table()

ad1_clean <- ad1 %>%
  dplyr::select(""State"", ""2017[3]"", ""2016[4]"", ""2015[5]"", ""2014[6]"") %>%
  rename(
    ""state"" = ""State"",
    ""2017"" = ""2017[3]"",
    ""2016"" = ""2016[4]"",
    ""2015"" = ""2015[5]"",
    ""2014"" = ""2014[6]""
  )

ad2 <- airport_data %>%
  html_node(xpath = '//*[@id=""mw-content-text""]/div/table[2]') %>%
  html_table()

ad2_clean <- ad2 %>%
  dplyr::select(-""IATACode"",-""2018"",-""Airports (Medium Hubs)"",-""City Served"",-""Rank(2017)"") %>%
  rename(""state"" = ""State"",
         ""2015"" = ""2015[4]"",
         ""2014"" = ""2014[1]"")

## A horriblly unclean way to convert these to numeric and remove commas but it was the only one I found to work of the top of my head
ad1_clean$`2017` <- as.numeric(gsub("","", """", ad1_clean$`2017`))
ad1_clean$`2016` <- as.numeric(gsub("","", """", ad1_clean$`2016`))
ad1_clean$`2015` <- as.numeric(gsub("","", """", ad1_clean$`2015`))
ad1_clean$`2014` <- as.numeric(gsub("","", """", ad1_clean$`2014`))

ad2_clean$`2017` <- as.numeric(gsub("","", """", ad2_clean$`2017`))
ad2_clean$`2016` <- as.numeric(gsub("","", """", ad2_clean$`2016`))
ad2_clean$`2015` <- as.numeric(gsub("","", """", ad2_clean$`2015`))
ad2_clean$`2014` <- as.numeric(gsub("","", """", ad2_clean$`2014`))

passangers <- rbind(ad1_clean, ad2_clean)

passangers <- passangers %>%
  mutate(mean_pass = rowMeans(dplyr::select(passangers, -state))) %>%
  dplyr::select(state, mean_pass) %>%
  group_by(state) %>%
  summarise(mean_pass = sum(mean_pass)) %>% #calculating an average passanger count across 2017:2014
  mutate(state = recode(state, ""OH/KY"" = ""KY"")) #for the purposes of the analysis it is easier to break these up


# Bird data
bird_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")

bird_trim <- bird_impacts %>%
  dplyr::select(""state"", ""incident_year"") %>%
  filter(
    incident_year == 2017 |
      incident_year == 2016 |
      incident_year == 2015 |
      incident_year == 2014
  ) %>% #used the same years as the passanger dataset
  group_by(state) %>%
  summarise(incidents = sum(n()))


# Joining the two datasets
us_counties <-
  usa_sf(proj = c(""longlat"", ""laea"", ""lcc"", ""eqdc"", ""aeqd""))
pas_bird <- merge(passangers, bird_trim, by = ""state"")

# as each state doesnt have spatial components I used https://geocode.localfocus.nl/ to obtain these as a csv. file ""states""
states <-
  read.csv(""state.csv"", header = TRUE, stringsAsFactors = FALSE)
usa_strikes <- merge(pas_bird, states, by = ""state"")

#converting non sf to sf
usa_strikes_fips <- usa_strikes %>%
  st_as_sf(crs = 4326, coords = c(""long"", ""lat""))

cont_usa_sightings <- st_join(us_counties, usa_strikes_fips)



### Plotting
# This section is heavily based upon Timo Grossenbacher great bivariate map tutorial: https://timogrossenbacher.ch/2019/04/bivariate-maps-with-ggplot2-and-sf/

theme_map <- function(...) {
  theme_minimal() +
    theme(
      text = element_text(color = ""black""),
      # remove all axes
      axis.line = element_blank(),
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
      # add a subtle grid
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      # background colors
      plot.background = element_rect(fill = ""white"", colour = NA),
      panel.background = element_rect(fill = ""white"", colour = NA),
      legend.background = element_rect(fill = ""white"", colour = NA),
      # borders and margins
      plot.margin = unit(c(.5, .5, .2, .5), ""cm""),
      panel.border = element_blank(),
      panel.spacing = unit(c(-.1, 0.2, .2, 0.2), ""cm""),
      # titles
      legend.title = element_text(size = 11),
      legend.text = element_text(
        size = 9,
        hjust = 0,
        color = ""black""
      ),
      plot.title = element_text(
        size = 20,
        hjust = 0.5,
        color = ""black""
      ),
      plot.subtitle = element_text(
        size = 15,
        hjust = 0.5,
        color = ""black"",
        margin = margin(
          b = -0.1,
          t = -0.1,
          l = 2,
          unit = ""cm""
        ),
        debug = F
      ),
      # captions
      plot.caption = element_text(
        size = 7,
        hjust = .5,
        margin = margin(t = 0.2,
                        b = 0,
                        unit = ""cm""),
        color = ""#939184""
      ),
      ...
    )
}

# create 3 buckets for incidents
quantiles_incidents <- cont_usa_sightings %>%
  na.omit() %>%
  pull(incidents) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# create 3 buckets for mean passangers
quantiles_mean_pass <- cont_usa_sightings %>%
  na.omit() %>%
  pull(mean_pass) %>%
  quantile(probs = seq(0, 1, length.out = 4))

# As found on Timo Grossenbacher tutorial
# create color scale that encodes two variables
# red for incidents and blue for mean passangers
bivariate_color_scale <- tibble(
  ""3 - 3"" = ""#3F2949"",
  # high incidents, high passangers
  ""2 - 3"" = ""#435786"",
  ""1 - 3"" = ""#4885C1"",
  # low incidents, high passangers
  ""3 - 2"" = ""#77324C"",
  ""2 - 2"" = ""#806A8A"",
  # medium incidents, medium passangers
  ""1 - 2"" = ""#89A1C8"",
  ""3 - 1"" = ""#AE3A4E"",
  # high incidents, low passangers
  ""2 - 1"" = ""#BC7C8F"",
  ""1 - 1"" = ""#CABED0"" # low incidents, low passangers
) %>%
  gather(""group"", ""fill"")


# cut into groups defined above and join fill
cont_usa_sightings %<>%
  mutate(
    incidents_quantiles = cut(incidents,
                              breaks = quantiles_incidents,
                              include.lowest = TRUE),
    mean_pass_quantiles = cut(mean_pass,
                              breaks = quantiles_mean_pass,
                              include.lowest = TRUE),
    group = paste(
      as.numeric(incidents_quantiles),
      ""-"",
      as.numeric(mean_pass_quantiles)
    )
  ) %>%
  left_join(bivariate_color_scale, by = ""group"")

### Blank map used for states that do not have data

us_all_counties <-
  usa_sf(proj = c(""longlat"", ""laea"", ""lcc"", ""eqdc"", ""aeqd""))
states_all <-
  read.csv(""all_states.csv"",
           header = TRUE,
           stringsAsFactors = FALSE)

states_all_fips <- states_all %>%
  st_as_sf(crs = 4326, coords = c(""long"", ""lat""))

all_usa <- st_join(us_all_counties, states_all_fips)

# Final plot starts here
map <- ggplot(
  data = cont_usa_sightings) +
  geom_sf(aes(fill = ""gray88""), # states that have no data
          color = NA,
          size = 0.2,
          data = all_usa) +
  geom_sf(aes(fill = fill),
          # line for state borders
          color = ""white"",
          size = 0.4) +
  scale_alpha(name = """",
              range = c(0.6, 0),
              guide = F) +
  scale_fill_identity() +
  labs(
    x = NULL,
    y = NULL,
    title = ""More flights, more wildlife strikes?"",
    subtitle = paste0(""Average reported wildlife strikes by airplanes across 29 US states from 2014-2017""),
    caption = ""Author: @jonathon_mifsud, Code: , Source: FAAs Wildlife Strike Reporting Database""
  ) +
  theme_map()

bivariate_color_scale %<>%
  separate(group,
           into = c(""incidents"", ""mean_pass""),
           sep = "" - "") %>%
  mutate(gini = as.integer(incidents),
         mean = as.integer(mean_pass))

legend <- ggplot() +
  geom_tile(data = bivariate_color_scale,
            mapping = aes(x = incidents,
                          y = mean_pass,
                          fill = fill)) +
  scale_fill_identity() +
  labs(x = ""More incidents"",
       y = ""More flights"")+ # Arrows were added using illustrator after trying endlessly to do it in R
  theme_map() +
  theme(axis.title = element_text(size = 14)) +
  coord_fixed()

# Joining the plot and legend 

plot <- ggdraw() +
  draw_plot(map, 0, 0, 1, 1) +
  draw_plot(legend, 0.05, 0.075, 0.2, 0.2)

ggsave(
  ""2019/plots/plot_2019-07-24.png"",
  width = 29,
  height = 21,
  units = ""cm"",
  dpi = ""retina""
)
","2019-18"
"347",743,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/r4ds_stats.R","JonathonMifsud","tidytuesday","2019/code/r4ds_stats.R","#############################################################
##    R for Data Science Online Learning Community Stats   ##
##                       Jonathon Mifsud                   ##
#############################################################

library(tidyverse)
library(reshape2)
library(emojifont)
library(ggthemes)


r4ds_members <-
  readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv""
  )

theme <- theme_minimal()

## After looking at the data I am planning to examine which day slack is the busiest

r4ds_members <-  r4ds_members %>%
  filter(total_membership >= 428) %>% #removing slack early membership
  mutate(day = wday(date, label = TRUE, abbr = FALSE)) %>%
  mutate(daily_quiet_members = daily_active_members - daily_members_posting_messages)

r4ds_day <- r4ds_members %>%
  select(day,
         daily_members_posting_messages,
         daily_quiet_members) %>%
  group_by(day) %>%
  summarise(
    posting_members = round(sum(daily_members_posting_messages)),
    shy_members = round(sum(daily_quiet_members)),
    day_count = n()
  )

r4ds_melt <- r4ds_day %>%
  select(-day_count) %>%
  melt()

p <- r4ds_melt %>%
  ggplot(aes(day, value, fill = variable)) +
  geom_chicklet(width = .6, radius = grid::unit(5, ""pt"")) +
  theme_minimal() +
  ggthemes::scale_fill_tableau('Color Blind',
                               name = ""Type of R4DS Member:"",
                               labels = c(""Poster"", ""Shy"")) +
  theme(
    plot.background = element_rect(fill = ""grey97"", color = ""white""),
    legend.position = ""bottom"",
    legend.title = element_text(color = ""grey30"", size = 14, face = ""bold""),
    legend.text = element_text(
      color = ""grey30"",
      size = 12,
      face = ""bold"",
      margin = margin(t = 10)
    ),
    legend.spacing.x = unit(0.8, ""cm""),
    legend.spacing.y = NULL,
    axis.text.y = element_text(color = ""grey30"", size = 12),
    axis.text.x = element_text(color = ""grey30"", size = 12),
    axis.title.y = element_text(
      color = ""grey30"",
      size = 16,
      face = ""bold"",
      margin = margin(
        t = 0,
        r = 20,
        b = 0,
        l = 0
      )
    ),
    axis.title.x = element_text(color = ""grey30"", size = 12, face = ""bold""),
    plot.title = element_text(color = ""grey30"", size = 22, face = ""bold""),
    plot.subtitle = element_text(size = 14)
  ) +
  labs(
    x = NULL ,
    y = ""Total Number of Active Members Overtime"",
    title = ""User activity on R4DS Slack"",
    subtitle = ""By day of the week, segmented by whether the user contributes a message/post or just reads (shy)"",
    caption = ""Source R4DS Slack, Plot by @jonathon_mifsud""
  ) +
  guides(
    fill = guide_legend(
      title = ""Type of R4DS Member:"",
      label.position = ""right"",
      label.hjust = 0.5,
      title.position = ""top"",
      title.vjust = 0.3
    )
  )
p




## For exporting (problems with font size)
p2 <- r4ds_melt %>%
  ggplot(aes(day, value, fill = variable)) +
  geom_chicklet(width = .6, radius = grid::unit(5, ""pt"")) +
  theme_minimal() +
  ggthemes::scale_fill_tableau('Color Blind',
                               name = ""Type of R4DS Member:"",
                               labels = c(""Poster"", ""Shy"")) +
  theme(
    plot.background = element_rect(fill = ""grey97"", color = ""white""),
    legend.position = ""bottom"",
    legend.title = element_text(color = ""grey30"", size = 32, face = ""bold""),
    legend.text = element_text(
      color = ""grey30"",
      size = 32,
      face = ""bold"",
      margin = margin(t = 10)
    ),
    legend.spacing.x = unit(0.8, ""cm""),
    legend.spacing.y = NULL,
    axis.text.y = element_text(color = ""grey30"", size = 30),
    axis.text.x = element_text(color = ""grey30"", size = 40),
    axis.title.y = element_text(
      color = ""grey30"",
      size = 40,
      face = ""bold"",
      margin = margin(
        t = 0,
        r = 20,
        b = 0,
        l = 0
      )
    ),
    axis.title.x = element_text(color = ""grey30"", size = 40, face = ""bold""),
    plot.title = element_text(color = ""grey30"", size = 60, face = ""bold""),
    plot.subtitle = element_text(size = 40),
    plot.caption = element_text(size = 18)
  ) +
  labs(
    x = NULL ,
    y = ""Total Number of Active Members Overtime"",
    title = ""User activity on R4DS Slack"",
    subtitle = ""By day of the week, segmented by whether the user contributes a message/post or just reads (shy)"",
    caption = ""Source R4DS Slack, Plot by @jonathon_mifsud""
  ) +
  guides(
    fill = guide_legend(
      title = ""Type of R4DS Member:"",
      label.position = ""right"",
      label.hjust = 0.5,
      title.position = ""top"",
      title.vjust = 0.3
    )
  )
p2



ggsave(""2019/plots/plot_2019-07-16.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019-29"
"348",744,"https://github.com/JonathonMifsud/tidytuesday/blob/master/2019/code/media_franchises.R","JonathonMifsud","tidytuesday","2019/code/media_franchises.R","## TidyTuesday WK1 media_franchises ##
## jonathon_mifsud ##
## 03/07/19 ##

library(tidyverse)
library(hrbrthemes)
library(ggthemes)
library(ggchicklet)

## Reading in the file ##
media_franchises <- readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

# Looking at the data I think this week I would like to make a bar-plot. Franchise has a length of 103 unique titles,
# which may be too lengthy to analyse in this form. Instead, I aim to make a  of the total revenue separated by year.
# I will segment each year to show the contributions of each each type of original media.

## CLEANING ##

# delete duplicates
media_franchises <-
  media_franchises[!duplicated(media_franchises),]

# We have alot of years to work with. Instead of looking at a subset of this I will try creating multiple bins.
#We have 52 individual years so we could break this evenly into 13 bins. I am sure there is a better way to generate the labels!

media_franchises$year_created <-
  cut(
    media_franchises$year_created,
    breaks = 13,
    labels = c(
      ""1924-1931"",
      ""1931-1938"",
      ""1938-1945"",
      ""1945-1951"",
      ""1951-1958"",
      ""1958-1965"",
      ""1965-1972"",
      ""1972-1979"",
      ""1979-1986"",
      ""1986-1992"",
      ""1992-1999"",
      ""1999-2006"",
      ""2006-2013"")

year_counts <- media_franchises %>%
  group_by(revenue_category, year_created) %>%
  summarise(total_yearly_revenue_by_category = round(sum(revenue)),
            media_count = n())

## PLOT ##

#This barplot was inspired by a post and wonderful barplot tutorial by @hrbrmstr https://rud.is/b/2019/06/30/make-refreshing-segmented-column-charts-with-ggchicklet/ using the package ggchicklet

p <- year_counts %>%
  ggplot(aes(year_created, total_yearly_revenue_by_category, fill = revenue_category)) +
  geom_chicklet(width = 0.75) +
  scale_y_comma(position = ""right"") +
  coord_flip() +
  ggthemes::scale_fill_tableau('Superfishel Stone', name = NULL) +
  labs(
    x = NULL ,
    y = ""Total revenue generated overtime (in billions)"",
    fill = NULL,
    title = ""Revenue Generated by Media Franchise Powerhouses"",
    subtitle = ""By Year of Franchise Inception"",
    caption = ""Source Wikipedia, Plot by @jonathon_mifsud""
  ) +
  theme_ipsum_rc(grid = ""X"") +
  theme(legend.position = ""bottom"")

ggsave(
  ""plots/plot_2019-07-03.png"",
  width = 29,
  height = 21,
  units = ""cm"",
  dpi = ""retina""
)

## I have also made a version with the bar-plot ordered ##
year_counts_ordered <- media_franchises %>%
  group_by(revenue_category, year_created) %>%
  summarise(total_yearly_revenue_by_category = round(sum(revenue)),
            media_count = n()) %>%
  mutate(
    year_created = fct_relevel(
      year_created,
      ""1992-1999"",
      ""1972-1979"",
      ""1999-2006"",
      ""1979-1986"",
      ""1924-1931"",
      ""1986-1992"",
      ""2006-2013"",
      ""1965-1972"",
      ""1958-1965"",
      ""1938-1945"",
      ""1945-1951"",
      ""1951-1958"",
      ""1931-1938""))
#I am sure there is a better way to do this

year_counts_ordered <- year_counts_ordered %>%
  mutate(year_created = fct_rev(year_created))# after manually inputting the order I realised that it was lowest value first so I am reversing it so we get the higher revenes first.

p2 <- year_counts_ordered %>%
  ggplot(aes(year_created, total_yearly_revenue_by_category, fill = revenue_category)) +
  geom_chicklet(width = 0.75) +
  scale_y_comma(position = ""right"") +
  coord_flip() +
  ggthemes::scale_fill_tableau('Superfishel Stone', name = NULL) +
  labs(
    x = NULL ,
    y = ""Total revenue generated overtime (in billions)"",
    fill = NULL,
    title = ""Revenue Generated by Media Franchise Powerhouses"",
    subtitle = ""By Year of Franchise Inception"",
    caption = ""Source Wikipedia, Plot by @jonathon_mifsud""
  ) +
  theme_ipsum_rc(grid = ""X"") +
  theme(legend.position = ""bottom"")
","2019-27"
"349",745,"https://github.com/soroosj/TidyTuesday/blob/master/2019-08-06/bob_ross.Rmd","soroosj","TidyTuesday","2019-08-06/bob_ross.Rmd","----
   title: ""Bob Ross Paintings""
   author: ""Joel Soroos""
   date: ""August 10, 2019""
   output: pdf_document
---

### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   bob_ross_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"") %>%
      clean_names () 
```
   
   
### 2.  Convert show titles to one row per word
```{r transform, message = F}

   library (tidytext)

   bob_ross <- bob_ross_raw %>%
      select (episode, title) %>%
      unnest_tokens(word, title) %>%
      count(word, sort = TRUE) %>%
      rename (freq = n) %>%
      anti_join(stop_words) %>%
      inner_join (get_sentiments(""bing""))
```


### 3.  Create word tree
```{r}

   library (wordcloud2)
   png('filename.png')
   #https://www.datacamp.com/community/tutorials/R-nlp-machine-learning
   letterCloud(bob_ross, word = ""BOB ROSS"", size = 1.3)
   dev.off ()
```","2019-32"
"350",746,"https://github.com/soroosj/TidyTuesday/blob/master/2019-04-23/Anime.Rmd","soroosj","TidyTuesday","2019-04-23/Anime.Rmd","---
title: ""Anime""
output:
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}
   library (tidyverse)
   library (janitor)
   library (stringr)
   library (kableExtra)
```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }
   anime_raw <- 
      read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/raw_anime.csv"") %>%
      clean_names ()
```

### 3. Tidy data
```{r analyze}
   anime <- anime_raw %>%
      drop_na () %>%
      mutate (
         studio = str_remove_all (studio, ""\\[|\\]|'"")
         )
```

## 4. Create table
```{r analyze}
   anime %>%
      select (source,score) %>%
      group_by (source) %>%
      summarise_all (list(~median, ~mean, ~mad, ~sd, ~IQR,~n())) %>%
      arrange (desc(median)) %>%
      mutate_if (is.numeric,~round(., 2)) %>%
      mutate (
         median = ifelse(median> 7.3,
                     cell_spec(median, ""html"", background = ""green"", color = ""white"", align = ""left""),
                     cell_spec(median, ""html"", background = ""red"", color = ""white"", align = ""left""))
         ) %>%
      kable (escape =F) %>%
      kable_styling (bootstrap_options = ""striped"", full_width = F) %>%
      add_header_above (c("" "" = 1, "" "" = 6)) %>%
      add_header_above (
         c(""Anime Rating Summary Statistics by Source"" = 7),
         align = ""c"",
         font_size = 16
         ) %>%
      save_kable (""anime.png"")
```    

","2019-17"
"351",747,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-02-12/govt_spend.Rmd","---
title: ""US R&D Spending""
output: html_document
---


## Load libraries
```{r setup, echo = TRUE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(tidyverse)
library(ggthemes)
library(scales)
```


## Source and wrangle data
```{r source_files, echo = TRUE}
govt_raw <- read_csv (""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")
govt_clean <- govt_raw %>%
   drop_na() %>%
   mutate_at (3:6, funs(round(./1000000000,1)))
head(govt_clean,10)
```


## R&D 2017 by department

```{r govt_2017, echo=TRUE}
govt_clean %>%
   filter (year == ""2017"") %>%
   ggplot(aes(x=reorder(department, rd_budget), y=rd_budget)) +
      geom_bar(stat='identity') +
      coord_flip() +
      theme_economist () +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(title = ""R&D budget by department"",
           subtitle = ""2017, billions of USD"",
           caption = ""Source: American Association for the Advancement of Science"")
```


## Department of Defense R&D over Time

```{r dod, echo = TRUE}
govt_clean %>%
   filter (department == ""DOD"") %>%
   ggplot () +
      geom_rect(aes(xmin=1974, xmax=1977, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1977, xmax=1981, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=1981, xmax=1993, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1993, xmax=2001, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=2001, xmax=2009, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=2009, xmax=2017, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      scale_fill_manual (values = c('blue','red')) +
   
      geom_line(aes (year, rd_budget)) +
   
      scale_x_continuous(breaks = seq(1976, 2017,4)) +
      theme_economist() +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(title = ""Dept of Defense R&D budget increases with Republican presidents"",
           subtitle = ""1976-2017, billions of USD"",
           caption = ""Source: American Association for the Advancement of Science"")
```

## R&D by department over time

```{r govt_all, echo=TRUE}
govt_all <-
   govt_clean %>%
   ggplot() +
      geom_rect(aes(xmin=1974, xmax=1977, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1977, xmax=1981, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=1981, xmax=1993, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1993, xmax=2001, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=2001, xmax=2009, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=2009, xmax=2017, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      scale_fill_manual (values = c('blue','red')) +
   
      geom_line(aes (year, rd_budget)) +
   
      theme_economist() +
      theme(axis.title.x = element_blank(),
         axis.title.y = element_blank(),
         axis.text.x = element_text(size = 8),
         axis.text.y = element_text(size = 7),
         legend.text=element_text(size = 8),
         legend.title = element_blank(),
         panel.spacing = unit(2, ""lines""),
         strip.text = element_text(size = 7)) +
      facet_grid(department ~., scales = ""free_y"") +
      scale_x_continuous(breaks = seq(1976, 2017,4)) +
      scale_y_continuous(breaks = scales::pretty_breaks(2)) +
      labs(title = ""R&D budget by department"",
        subtitle = ""1976-2017, billions of USD"",
        caption = ""Source: American Association for the Advancement of Science"")
   
ggsave(""govt_all.png"",govt_all)","2019-7"
"352",748,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-02-12/govt_spend_flex.Rmd","---
title: ""U.S. Government R&D Budget""
output:
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    source_code: embed
  html_document:
    df_print: paged
  word_document: default
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(ggthemes)
library(scales)
library(cluster)
library(dendextend)
library(ggdendro)

govt_raw <- read_csv (""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")

govt_clean <- govt_raw %>%
   drop_na() %>%
   mutate_at (3:6, funs(round(./1000000000,1))) 
   

head(govt_clean,10)
```



Column {data-width=500}
-----------------------------------------------------------------------

### 1. R&D budget by department in 2017 ($b)

```{r}
govt_clean %>%
   filter (year == ""2017"") %>%
   ggplot(aes(x=reorder(department, rd_budget), y=rd_budget)) +
      geom_bar(stat='identity') +
      coord_flip() +
      theme_economist () +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(caption = ""Source: American Association for the Advancement of Science"")
```



### 3. R&D budget over time by department ($b)

```{r}
govt_clean %>%
   ggplot(aes(x=year, y=rd_budget, color=department)) +
      geom_point() +
      theme_economist () +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank(),
            legend.position = ""right"",
            legend.text=element_text(size=8)) +
      labs(caption = ""Source: American Association for the Advancement of Science"")
```

Column {data-width=500}
-----------------------------------------------------------------------
### 2. Dept of Defense R&D budget by presidential party 1976-2017 ($b)

```{r}
govt_clean %>%
   filter (department == ""DOD"") %>%
   ggplot () +
      geom_rect(aes(xmin=1974, xmax=1977, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1977, xmax=1981, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=1981, xmax=1993, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=1993, xmax=2001, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      geom_rect(aes(xmin=2001, xmax=2009, ymin=0,ymax=Inf, fill=""Republican""), alpha=0.2) +
      geom_rect(aes(xmin=2009, xmax=2017, ymin=0,ymax=Inf, fill=""Democrat""), alpha=0.2) +
      scale_fill_manual (values = c('blue','red')) +
   
      geom_line(aes (year, rd_budget)) +
   
      scale_x_continuous(breaks = seq(1976, 2017,4)) +
      theme_economist() +
      theme(axis.title.x = element_blank(),
            axis.title.y = element_blank(),
            legend.title = element_blank()) +
      labs(caption = ""Source: American Association for the Advancement of Science"")
```

### 4. R&D budget by department over time cluster analysis

```{r}
govt_spread <- govt_clean %>%
   select (department, year, rd_budget) %>%
   spread (year, rd_budget) %>%
   column_to_rownames(""department"")

govt_dist <- govt_spread %>%
   dist(method = 'euclidean') 

govt_clust <- govt_dist %>%
   hclust (method = 'complete') %>%
   as.dendrogram() %>%
   dendro_data(type=""rectangle"")

#ggplot(segment(govt_clust),labels=rownames(govt_clust)) + 
  #geom_segment(aes(x=x, y=y, xend=xend, yend=yend)) + 
  #theme_dendro() +
  #coord_flip() +
  #scale_x_reverse()

ggdendrogram(govt_clust)
```

","2019-7"
"353",749,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-02-26/Trains.Rmd","---
title: ""French Trains""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidygraph)
library(ggraph)

trains_raw <- read_csv (""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

trains <- trains_raw %>%
   select (year, month, departure_station, arrival_station, journey_time_avg, total_num_trips) %>%
   arrange (-total_num_trips)

trains_2017 <- trains %>%
   filter (year == 2017)

```

## R Markdown


```{r network}
departures <- trains_2017 %>%
   distinct(departure_station) %>%
   rename(station = departure_station)

arrivals <- trains_2017 %>%
   distinct(arrival_station) %>%
   rename(station = arrival_station)

nodes <- full_join(departures, arrivals, by = ""station"") %>%
    rowid_to_column(""id"")

per_route <- trains_2017 %>%  
  group_by(departure_station, arrival_station) %>%
  summarise(trips = n()) %>% 
  ungroup()

edges <- per_route %>% 
  left_join(nodes, by = c(""departure_station"" = ""station"")) %>% 
  rename(from = id) %>% 
  left_join(nodes, by = c(""arrival_station"" = ""station"")) %>% 
  rename(to = id) %>%
  select(from, to, trips)

routes_tidy <- tbl_graph(nodes = nodes, edges = edges, directed = TRUE)

ggraph(routes_tidy) +
   geom_edge_link() +
   geom_node_point() +
   theme_graph() +
   scale_edge_width(range = c(0.2, 2)) +
   geom_node_text(aes(label = station), size = 2, repel = TRUE) 
```

","2019-9"
"354",750,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-03-26/Pet breeds.Rmd","---
title: ""Seattle Pets""
output: html_document
---

### 1. Load packages
```{r setup}
knitr::opts_chunk$set(echo = TRUE)

library (tidyverse)
library (ggthemes)
library (ggtextures)
library (magick)

```

### 2. Source data 
```{r import, echo = TRUE} 
pets <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")

```

### 3. Identify most popular dog breeds
```{r popular}

pets_summ <- pets %>%
   drop_na () %>%
   filter (species == ""Dog"") %>%
   group_by (primary_breed) %>%
   summarize (count = n ()) %>%
   arrange (-count) %>%
   head (10)

pets_summ

```

### 4. Load dog images
```{r images}

pets_summ$image <- list (
   image_read (""https://www.petinsurancereview.com/sites/default/files/inline-images/Labrador%20Retriever%202.jpg""),
   image_read (""http://www.allsmalldogbreeds.com/breeds/chihuahua-short-coat.jpg""),
   image_read (""https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12133017/Golden-Care.jpg""),
   image_read (""https://bowwowinsurance.com.au/wp-content/uploads/2018/10/australian-aussie-terrier-700x700.jpg""),
   image_read (""https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRjJqstuFnEQYpXeNbb3Sqv6l5EHxE1TWrEkFwnsW8zMwiIEiwn""),
   image_read (""https://previews.123rf.com/images/fotojagodka/fotojagodka1311/fotojagodka131100256/23734288-miniature-poodle-puppy-sits-on-a-white-background.jpg""),
   image_read (""https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Female_German_Shepherd.jpg/330px-Female_German_Shepherd.jpg""),
   image_read (""https://cf-s3.petcoach.co/uploads/breed/48/1520278916-Aussie2.jpg""),
   image_read (""https://dailystormer.name/wp-content/uploads/2017/12/840dfdd1804b7291c59af3ae134660d8-bully-pitbull-pitbull-terrier.jpg""),
   image_read (""https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12212849/Australian-Cattle-Dog-History-06.jpg"")
      )

``` 

### 5. Create chart 
```{r chart}

pets_bar <- ggplot(pets_summ, aes(x=reorder(primary_breed,count), y=count, image = image)) +
      geom_textured_col (img_height = grid::unit(1,""null""), img_width = grid::unit(0.6,""cm""), ncol = 1, nrow = 1, hjust = 0, vjust = 0.5, fill = ""light blue"") + 
      theme_economist () +
      theme(
         axis.title.x=element_blank(),
         axis.title.y=element_blank(),
         axis.text.y=element_blank()) +
      labs(
         title = ""Most popular dog breeds"",
         subtitle = ""Seattle: April 2017 - September 2018"",
         caption = ""Source: City of Seattle"") +
      coord_flip ()

ggsave(""breeds.png"", pets_bar)
pets_bar  

```","2019-13"
"355",751,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-04-09/Tennis.Rmd","---
title: ""Grand Slam""
output:
  pdf_document: default
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

library (tidyverse)
library (janitor)
library (ggthemes)
library (ggrepel)
library (stringr)

```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }

tennis_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")
   
```
### 3. Convert outcomes to numeric
```{r}

tennis <- tennis_raw %>%
   clean_names() %>%
   mutate(
     outcome_num = case_when(
        outcome == ""Won"" ~ 8,
        outcome == ""Finalist"" ~ 7,
        outcome == ""Semi-finalist"" ~ 6,
        outcome == ""Quarterfinalist"" ~ 5,
        outcome == ""4th Round"" ~ 4,
        outcome == ""3rd Round"" ~ 3,
        outcome == ""2nd Round"" ~ 2,
        outcome == ""1st Round"" ~ 1
         ),
     player = str_remove (player, ""// ""),
     player = str_replace (player, ""Sele"", ""Seles"")
     )  %>%
   drop_na ()

tennis %>%
   head (10)

```

### 4. Calculate average outcomes
```{r aggregate}
  
tennis_avg <- tennis %>%
   group_by (player) %>%
   summarize (
      avg = round(mean (outcome_num),2),
      st_dev = round(sd (outcome_num),2),
      n = n ()
      ) %>%
   arrange (-avg) %>%
   filter (n>9) %>%
   drop_na ()

tennis_avg %>%
   head (10)
```

### 4. Create visualization
```{r chart}

tennis_plot <- ggplot (tennis_avg, aes (avg, st_dev, label = player)) +
   geom_point () +
   theme_economist() +
   scale_y_continuous(trans = ""reverse"") +
   geom_label_repel(
      aes(label=ifelse(avg>5.8,as.character(player),'')),
      box.padding   = 0.35, 
      point.padding = 0.5,
      size = 3,
      segment.color = 'grey50') +
   labs(
      title = ""Average and Dispersion of Grand Slam Outcomes (1968-2018)"",
      subtitle = ""Win = 8, 1st Round = 1"",
      caption = ""Source:Wikipedia"",
      x = ""Average"",
      y = ""Standard Deviation""
      ) +
   theme(
      axis.title.x=element_text(size=9),
      axis.title.y=element_text(size=9)
   )

tennis_plot
ggsave (""tennis.png"", tennis_plot)

```
","2019-15"
"356",752,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-04-30/birds.Rmd","---
title: ""Birds""
output:
  pdf_document: default
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

library (tidyverse)
library (janitor)
library (ggthemes)
library (ggridges)
library (stringr)

```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }

birds_raw <- read_delim(
   ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_call.csv"",
   delim = "" ""
   )%>%
   clean_names() 
   
```
### 3. Explore data
```{r}

birds <- birds_raw %>%
   drop_na () %>%
   group_by (species) %>%
   filter (flight > 50)

tabyl (birds, collisions)

   
```


### 4. Create visualization
```{r chart}

ggplot (data = birds, aes(x = flight, y = collisions)) +
  geom_density_ridges ()

```
","2019-18"
"357",753,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-05-07/student.Rmd","---
title: ""Student Ratio""
output:
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

library (tidyverse)
library (janitor)
library (inspectdf)
library (ggridges)
library (ggthemes)
library (countrycode)

```

### 2. Source data
```{r source, warning = FALSE, results = FALSE, message = FALSE }

student_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")%>%
   clean_names()

inspect_cat (student_raw, show_plot = T)
inspect_num (student_raw, show_plot = T)
inspect_na (student_raw, show_plot = T)

   
```

### 3. Transform data
```{r transform}

student <- student_raw %>%
   mutate (
      continent = countrycode(country, origin = ""country.name"", destination = ""continent""),
      indicator = str_replace (indicator, "" Education"", """"),
      indicator = as.factor(indicator),
      indicator = fct_relevel(indicator, c(""Pre-Primary"", ""Primary"", ""Lower Secondary"", ""Secondary"", ""Upper Secondary"", ""Post-Secondary Non-Tertiary"", ""Tertiary""))
      )%>%
   select (continent, country_code, country, indicator, year, student_ratio) %>%
   drop_na ()

```


### 4a. Create ridgeline chart by continent
```{r plot1}

continent_plot <- student %>%
   filter (
      year == 2016,
      indicator == ""Upper Secondary""
      ) %>%
   ggplot (aes(x = student_ratio, y = reorder(continent,desc(continent)), group = continent)) +
   geom_density_ridges (fill = ""skyblue"") +
   theme_economist() +
   labs(
      title = ""Upper Secondary Student/Teacher Ratio by Continent (2016)"",
      subtitle = ""Oceania has the most dispersion, Europe the least."",
      caption = ""\n Source:UNESCO Institute of Statistics  |  R4DS Tidy Tuesday
      Visualization: Joel Soroos (Twitter @soroosj)"",
      x = ""Student Teacher Ratio"",
      y = """") 

ggsave (""plots/continent.png"", continent_plot)

continent_plot

```

### 4b. Create ridgeline chart by indicator
```{r plot2}

indicator_plot <- student %>%
   filter (
      year == 2016,
      continent == ""Asia""
      ) %>%
   ggplot (aes(x = student_ratio, y = reorder(indicator,desc(indicator)), group = indicator)) +
   geom_density_ridges (fill = ""skyblue"") +
   theme_economist() %>%
   labs(
      title = ""Student/Teacher Ratio by Education Level in Asia (2016)"",
      caption = ""Source:UNESCO Institute of Statistics  |  R4DS Tidy Tuesday
      Visualization: Joel Soroos @soroosj"",
      x = """",
      y = """")

ggsave (""plots/indicator.png"", indicator_plot)

indicator_plot

```","2019-19"
"358",754,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-05-21/Plastic Waste.Rmd","---
title: ""Plastic Waste""
author: ""Joel Soroos""
date: ""May 26, 2019""
output:
  pdf_document: default
  html_document: default
---

### 1. Load packages
```{r setup, warning = FALSE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor)
   library (ggrepel)
   library (scales)
   library (kableExtra)
   
```


### 2. Get data
```{r source, warning = TRUE, results = FALSE, message = FALSE}
   
   mismanaged_vs_gdp<- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>%
      clean_names()
   
   coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>%
      clean_names()

```


### 3. Transform data
```{r transform}

   waste_raw <- left_join (mismanaged_vs_gdp, coast_vs_waste, by = c(""code"", ""year"")) %>%
      filter (year == 2010)
   
   waste <- waste_raw %>%
      filter (year == 2010) %>%
      drop_na () %>%
      rename (
         country_name = entity.x,
         waste = mismanaged_plastic_waste_tonnes,
         gdp_per_capita = gdp_per_capita_ppp_constant_2011_international_rate,
         population = total_population_gapminder.x
         )%>%
      mutate (
          waste_per_coastal_capita = waste / coastal_population * 100,
          population = population / 1000000
         ) %>%
      select (country_name, waste, coastal_population, waste_per_coastal_capita,  gdp_per_capita, population) %>%
      arrange (-waste_per_coastal_capita)
   
   kable (head(waste,10))

```

### 4. Visualize
```{r plot}

   ggplot (waste,
      aes(x = gdp_per_capita, y = waste_per_coastal_capita, size = population)) +
      geom_point () +
      geom_smooth () +
      #scales
         scale_x_continuous(
            label = unit_format(prefix = ""$"", unit = ""K"", scale = 1e-3, sep = """"),
            trans = log10_trans()
            ) +
         scale_y_continuous(trans = log10_trans()) +
         scale_size_continuous(breaks = c(10, 100, 1000)) +
      theme(
         plot.title = element_text(hjust=0, size = 14),
         plot.caption = element_text(color=""black"", size=8),
         legend.title = element_text(colour=""black"", size=9),
         legend.text = element_text(colour=""black"", size=9),
         legend.position = ""top"",
         axis.title=element_text(size=9),
         panel.grid.major = element_line(size = 0.05, linetype = 'solid', color = 'grey50'),
         panel.grid.minor = element_blank (),
         panel.background = element_rect(fill = ""white"")
         ) +
      guides(size = guide_legend(override.aes = list(linetype = 0))) +
      geom_label_repel(
         aes (label = ""India's waste lower than predicted \nfor its per capita GDP""),
         data = subset (waste, country_name == ""India""),
         box.padding = 0.8, 
         point.padding = 0.7,
         size = 3,
         alpha = .8,
         segment.color = 'grey50'
         ) +
       labs(
         title = ""Mismanaged waste decreases as nations reach middle income"",
         caption = ""\n Sources: National Geographic, Gapminder, R4DS Tidy Tuesday
         Visualization: Joel Soroos (Twitter: @soroosj)"",
         x = ""GDP per capita"",
         y = ""Mismanaged waste per coastal capita (100 kg/year)"",
         size = ""Population (millions): ""
         ) +
   ggsave(""plot1.png"")

```
","2019-21"
"359",755,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-05-28/Wine Reviews.Rmd","---
title: ""Wine Reviews""
author: ""Joel Soroos""
date: ""May 31, 2019""
output: pdf_document
---

### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor)  

   wine_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
      clean_names ()
```

### 2. Transform data
```{r transform, message = F}

   wine_raw %>%
      group_by (variety) %>%
      summarize (n = n()) %>%
      arrange (-n) %>%
      top_n (10) %>%
      select (-n) -> wine_group

   wine_raw %>%
      drop_na (variety, price) %>%
      mutate (
         variety = as.factor(variety),
         popularity = ifelse (variety %in% wine_group$variety, ""High"", ""Low""),
         color = case_when(
            variety %in% c(""Pinot Noir"", ""Cabernet Sauvignon"", ""Red Blend"", ""Bordeaux-style Red Blend"", ""Syrah"", ""Merlot"") ~ ""red4"",
            variety %in% c(""Pinot Noir"", ""Chardonnay"", ""Riesling"", ""Sauvignon Blanc"") ~ ""Oldlace"",
            variety %in% c(""Ros"") ~ ""Deeppink""
            )
         ) %>%
      filter (
         popularity == ""High"",
         price < 300
         ) %>%
      select (variety, color, price) -> wine
```

### 3. Visualize data
```{r plot}

   library (ggdark)
   library (scales)

   ggplot (
         data = wine,
         aes (x = reorder(variety, price, median), y = price, fill = I(color))
           ) +
      geom_violin(draw_quantiles = c(.50)) +
      scale_x_discrete(position = ""top"") +
      scale_y_continuous (
         trans = log10_trans(),
         label = unit_format(prefix = ""$"", unit = """")
            ) +
      coord_flip () +
      dark_mode(theme_minimal()) +
      theme (
          plot.title = element_text(hjust = 0, size = 15),
          plot.caption = element_text(hjust = 0, size = 9),
          axis.title=element_text(size=9),
          axis.text=element_text(size=9, face = ""bold""),
          axis.ticks = element_blank()
         ) +
      labs(
         title = ""Open your wallet wide if you prefer red wine!"",
         caption = ""\nVertical line within violin represents median wine bottle price for that grape variety. \nVarietals with 10 most reviews displayed.  Excludes wines priced > $300 per bottle. \nSource: Wine Enthusiast via Kaggle via R4DS Tidy Tuesday       |       Visualization: Joel Soroos @soroosj"",
         x = """",
         y = ""Price per 750ml bottle""
         ) +
   ggsave(""wine.png"")
```
","2019-22"
"360",756,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-06-24/UFO.Rmd","---
   title: ""UFO Sightings""
   author: ""Joel Soroos""
   date: ""June 30, 2019""
   output: pdf_document
---

### 1a. Source UFO encounter data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   ufo_raw<- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"") %>%
      clean_names ()
```
   
### 1b. Source North Carolina map borders 
```{r source, warning = TRUE, results = FALSE, message = FALSE}
   
   map_borders <- map_data(""state"", region = ""north carolina"") 
```

### 2.  Transform UFO data
```{r transform, message = F}

  library (lubridate)

   ufo <- ufo_raw %>%
      select (date_time, city_area, state, latitude, longitude, encounter_length) %>%
      filter (
         state == ""nc"",
         latitude > 30,      # remove borders erroneously listed as NC outside of state borders
         latitude < 37,      # remove borders erroneously listed as NC outside of state borders
         longitude < -75     # remove borders erroneously listed as NC outside of state borders
         )  %>%
      mutate (
         encounter_length = encounter_length/3600,              #convert seconds to hours
         date_time = as.Date(date_time, format = ""%m/%d/%Y"")
         )
```

### 3. Visualize data
```{r plot}

   library (ggdark)

   ggplot () +
      #plot North Carolina borders
      geom_polygon (data = map_borders, aes(x = long, y = lat, group = group), color = ""black"", fill = ""#303030"", size = 1.15) +
      #plot UFO encounters
      geom_point (data = ufo, aes (x = longitude, y = latitude, size = encounter_length), color = ""green"") +
      #Deep Gap encounter annotation
         annotate(""text"",
            label = ""30 hour encounter\nin Deep Gap (2009)"",
            size = 3, hjust = 0, color = ""green"", family = ""Rockwell"",
            x = -84.9, y = 36.1
            ) +
         geom_curve(
            aes(x = -83.2, y = 36.2, xend = -81.7, yend = 36.27),
            arrow = arrow(length = unit(0.2, ""cm"")), 
            size = 0.4, color = ""green"", curvature = -0.4
            ) +
      #Gastonia encounter annotation
         annotate(""text"",
            label = ""120 hour encounter\nin Gastonia (1993)."",
            size = 3, hjust = 0, color = ""green"", family = ""Rockwell"",
            x = -83.1, y = 34.5, xmax = -83.5
            ) +
         geom_curve(
            aes(x = -82.27, y = 34.65, xend = -81.37, yend = 35.2),
            arrow = arrow(length = unit(0.2, ""cm"")), 
            size = 0.4, color = ""green"", curvature = -0.3
            ) +
       labs(
         title = ""UFOs over North Carolina\n"",
         size = ""Encounter (hrs)"",
         caption = ""\nEach dot represents a reported UFO sighting between 1995 and 2014.  \nSource: National UFO Reporting Center  | Visualization: Joel Soroos @soroosj""
         ) +
      coord_fixed(1.3) +
      scale_size_continuous(breaks = c(1, 10, 100)) +
      dark_mode(theme_minimal()) +
      theme(
         text = element_text(family = ""Rockwell"", color = ""green""),
         plot.title = element_text(hjust = 0.5, size = 18),
         plot.caption = element_text(hjust = 0, size = 8),
         axis.title = element_blank(),
         axis.text = element_blank(),
         axis.ticks = element_blank(),
         legend.title = element_text(size = 10, hjust = 0.5, vjust = 0.5),
         legend.text = element_text(size = 9, hjust = 0.5, vjust = 0.5),
         legend.position = c(0.82,0.18),
         legend.justification=c(0, 1), 
         legend.key.size = unit(0.1, 'lines')
         ) +
      ggsave(""ufo.png"", height =3.85)
```
","2019-25"
"361",757,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-07-02/Media Franchises.Rmd","---
   title: ""Animated File Media Franchise Revenues""
   author: ""Joel Soroos""
   date: ""July 7, 2019""
   output: pdf_document
---

### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   franchise_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"") %>%
      clean_names ()
```
   
### 2. Transform data
```{r transform, message = F}

  franchise <- franchise_raw %>%
      filter (original_media == ""Animated film"") %>%
      select (franchise, year_created, revenue_category, revenue) %>%
      mutate (
         franchise = case_when (
            franchise == ""Despicable Me / Minions"" ~ ""Minions"",
            franchise == ""The Lion King"" ~ ""Lion King"",
            TRUE ~ franchise
            ),
         #concatenate franchise and start date to enable two rows on x axis
         franchise_start = paste (franchise, ""\n("", year_created, "")"", sep = """"), 
         franchise_start = fct_relevel(franchise_start,              #Control franchise order in chart
            ""Barbie\n(1987)"", ""Cars\n(2006)"", ""Toy Story\n(1995)"", ""Lion King\n(1994)"", ""Frozen\n(2013)"", ""Minions\n(2010)"", ""Aladdin\n(1992)"", ""Ice Age\n(2002)"" 
            ),
         revenue = revenue * 10,          #Multiply by 10 to generate more boxes in waffle chart for additional granularity.
         revenue_category = case_when (
            revenue_category == ""Home Video/Entertainment"" ~ ""Home Video"",
            revenue_category == ""Video Games/Games"" ~ ""Video Games"",
            revenue_category == ""Merchandise, Licensing & Retail"" ~ ""Merchandise"",
            TRUE ~ revenue_category
            ),
         #control revenue group order in chart
         revenue_category = fct_relevel(revenue_category, ""Box Office"", ""Home Video"", ""Music"", ""Video Games"", ""Merchandise"")
         ) 
```

#3.  Create chart
```{r chart, warning = TRUE, results = FALSE, message = FALSE}

   library (waffle)
   library (ggdark)

   ggplot(franchise, aes(fill=revenue_category, values=revenue)) + 
     geom_waffle(color = ""white"", size=.3, n_rows = 8, flip = T) +
     facet_wrap(~franchise_start, nrow=1, strip.position = ""bottom"") +     #creates multiple waffle columns
     #scales
         scale_x_discrete(expand=c(0,0)) +
         scale_y_continuous(
            breaks = seq(5, 50, by = 5), 
            labels = function(x) x * .8, # make this multiplier the same as n_rows
            expand = c(0,0)
            ) +
         scale_fill_brewer(palette = ""Set1"") +
     #themes
        dark_mode(theme_minimal()) +
        theme(
           #download custom Waltograph font and then upload to R via extrafont package:https://www.dafont.com/waltograph.font
           text = element_text(family = ""Waltograph"", color = ""white""),   
           plot.title = element_text(hjust = .5, size = 22, face = ""bold""),
           plot.caption = element_text(hjust = 1, size = 12, vjust = .5),
           axis.title.y = element_text(hjust=1, size = 12, face = ""bold""),
           axis.text.y=element_text(size=12, face = ""bold""),
           strip.text = element_text(size = 13),
           legend.position = c(0.92,0.67),
           legend.text = element_text(size=12),
           legend.key.size = unit(0.5, ""cm"")
           ) +
     labs(
        title = ""Animated Film Franchise Revenues"",
        y = ""Revenues ($, billions)"",
        fill = """",
        caption = ""\nEach square represents $100 million in revenues. Year below franchise signifies year of creation. \nSource: Wikipedia  |  Visualization: Joel Soroos @soroosj""
        ) +
      ggsave(""franchise.png"", width = 15, height = 9.5, units = ""cm"")
```
","2019-27"
"362",758,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-08-13/Emperor.Rmd","---
   title: ""Roman Emperors""
   author: ""Joel Soroos""
   date: ""August 18, 2019""
   output: pdf_document
---


### 1. Source 
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   emperors_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"") %>%
      clean_names () %>%
      drop_na (birth)
```


### 2a.  Transform data - count by death cause
```{r, warning = TRUE, results = FALSE, message = FALSE}

   library (glue)

   emperor_cause <- emperors_raw %>%
      filter (era == ""Principate"") %>%
      mutate (cause = fct_lump (cause,4)) %>%
      count (cause, sort = TRUE) %>%
      mutate (cause_long = glue (""{cause} ({n})"")) %>%
      select (cause, cause_long)
```

   
### 2b.  Transform data - calculate reign ages
```{r source, warning = TRUE, results = FALSE, message = FALSE}
   
   library (lubridate)

   emperors <- emperors_raw %>%
      filter (era == ""Principate"") %>%
      mutate (
         birth = case_when (
            index %in% c(1,2,4,6) ~ update (birth, year = - year (birth)),
            TRUE~ birth
            ),
        reign_start = case_when (
            index %in% c(1) ~ update (reign_start, year = - year (reign_start)),
            TRUE~ reign_start
            ),
         reign_start_age = (reign_start- birth)/365.25,
         reign_end_age = (reign_end - birth)/365.25,
         reign_length = (reign_end - reign_start)/365.25,
         cause = fct_lump (cause, 4)
      ) %>%
      #add count of emperor death cause to death cause
      right_join (emperor_cause) %>%
      select (index, name, birth, death, reign_start_age, reign_end_age, reign_length, cause_long, cause) 
```


### 3. Visualize data
```{r plot}

   ggplot( data = emperors) +
      #reign segments and death age points
         geom_segment(
            aes(
               x = reign_start_age, 
               xend = reign_end_age, 
               y = reorder(name, -reign_end_age), 
               yend = name
               ),
            alpha = 0.15, color = ""black"" 
            ) +
         geom_point(
            aes(y=name, x=reign_end_age, color = cause_long),
            size = 1
            ) +
      #youngest reign annotation
         annotate(""text"",
            label = ""Youngest\nreign"",
            size = 3, hjust = 0.5, family = ""Trajanus Roman"", color = ""black"",
            x = 12, y = 36 
            ) +
         geom_curve(
            aes(x = 12, xend = 12, y = 37,  yend = 38.6),
            arrow = arrow(length = unit(0.1, ""cm"")), 
            size = 0.1, color = ""black"", curvature = 0, alpha = 0.07
            ) +
      #last reign annotation
         annotate(""text"",
            label = ""Final reign"",
            size = 3, hjust = 0.5, family = ""Trajanus Roman"", color = ""black"",
            x = 49, y = 23
            ) +
         geom_curve(
            aes(x = 50.5, xend = 52.4, y = 23.2, yend = 24),
            arrow = arrow(length = unit(0.1, ""cm"")), 
            size = 0.1, color = ""black"", curvature = -0.3, alpha = 0.07
            ) +
      #longest reign annotation
         annotate(""text"",
            label = ""Longest reign"",
            size = 3, hjust = 0.5, family = ""Trajanus Roman"", color = ""black"",
            x = 31.5, y = 5, xmax = 36  
            ) +
         geom_curve(
            aes(x = 36.2, xend = 38, y = 4.8, yend = 4.2),
            arrow = arrow(length = unit(0.1, ""cm"")), 
            size = 0.1, color = ""black"", curvature = -0.3, alpha = 0.07
            ) +
      #scales
         scale_x_continuous(
            breaks = c(20, 40, 60, 80),
            labels = c(""XX"", ""LIX"", ""LX"", ""LXXX"")
            ) +
         scale_color_brewer(palette = ""Set1"") +
      theme (
         plot.title = element_text(hjust = 0.5, vjust = 0, size = 16, face = ""bold""),
         plot.subtitle = element_text(hjust = 0.5, vjust = 1, size = 12, face = ""bold""),
         plot.caption = element_text (hjust = 0, size = 10),
         plot.background = element_rect(fill = ""#fdf6e3""),
         panel.background = element_rect(fill = ""#fdf6e3""),     
         panel.grid = element_blank (),
         text = element_text(family = ""Trajanus Roman"", color = ""black"", face = ""bold""),   #download font from https://www.fontspace.com/roger-white/trajanus-roman
         axis.title.x = element_text (hjust = 0.5),
         axis.text.x = element_text (size = 8),
         axis.title.y = element_blank (),
         axis.ticks = element_blank (),
         legend.background = element_rect(fill = ""#fdf6e3""),
         legend.title = element_blank(),
         legend.position = c(0.85,0.88),
         legend.key.size = unit(0.1, 'lines')
         ) +
      labs(
         title = ""Roman Emperor Principate Era (62 BCE to AD 283)"",
         subtitle = ""They ruled history's largest empire but often died brutally.\n\n"",
         caption = ""\nLines represent the beginning through ending age of each emperor's reign.\nData: Wikipedia   Visualization: Joel Soroos @soroosj"",
         x = ""\nAge (Years)""
         ) +
     ggsave(""emperors.png"", width = 20, units = ""cm"")
```

","2019-33"
"363",759,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-08-20/Explosions.Rmd","---
   title: ""Nuclear Explosions""
   author: ""Joel Soroos""
   date: ""September 1, 2019""
   output: pdf_document
---


### 1. Source nuclear explosion data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   explosions_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"") %>%
      clean_names () %>%
      drop_na (country)
```
   

### 2.  Transform nuclear explosion data
```{r transform, message = F, results = F}

   explosions <- explosions_raw %>%
      mutate (
         country = ifelse(country == ""PAKIST"", ""Pakistan"", country),
         country = ifelse(country %in% c(""FRANCE"", ""INDIA"", ""CHINA""), str_to_title (country), country)
         ) %>%
      group_by (year) %>%
         count (country) %>%
         arrange (year, n) %>%
         mutate(rank = row_number(-n) * 1) %>%
         ungroup () 
```


### 3. Visualize nuclear explosion data
```{r plot}

   library (scales)
   library (ggdark)
   library (gganimate)
   library (gifski)

   g <-ggplot (explosions, aes (rank)) +
      #bars
         geom_tile (
            aes(y = n/2, height = n, fill = country),
            width = 0.5
            ) +
      #bar labels
         geom_text(
            aes(y = 0, label = paste (country, ""  "")), 
            hjust = 1, color = ""white"", size = 4.5, family = ""sans""
            ) +
         geom_text(
            aes(y = n, label = paste ("" "",n)), 
            hjust = ""left"", color = ""white"", size = 4, family = ""sans""
            ) +
      #scales
         coord_flip (clip = ""off"", expand = FALSE) +
         scale_x_reverse() +
         scale_y_continuous(trans = log10_trans()) +
         ylim (-18, 105) +
         scale_fill_brewer(type = ""qual"", palette = 2) +
      #themes
         dark_theme_classic () +
         theme(
            plot.title = element_text(hjust = 0.5, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,25,0)),
            plot.caption = element_text (hjust = 0, size = 11, margin = margin (20,0,0,0)),
            axis.title = element_blank(),
            axis.text = element_blank(),
            axis.ticks = element_blank(),
            axis.line = element_blank(),
            legend.position = ""none""
            ) +
      labs(
         title = ""Nuclear Weapon Explosions\n{closest_state}"",
         caption = ""Data: Stockholm International Peace Research Institute via R4DS Tidy Tuesday\nVisualization: Joel Soroos @soroosj""
         ) +
      #separate charts by year
         transition_states(year, transition_length = 4, state_length = 1)

      #animate charts
         animate(g, nframes = 200, fps = 5, width = 420, height = 230, 
           renderer = gifski_renderer(""explosions.gif""))
```
","2019-34"
"364",760,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-09-03/Moore.Rmd","---
   title: ""Moore's Law""
   author: ""Joel Soroos""
   date: ""September 15, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   cpu_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"") %>%
      clean_names ()

   #remove scientific notation 
   options(scipen=999)
```
   

### 2a.  Build Moore's Law prediction
```{r transform, message = F, results = F}

   moore <- tibble (
      year = as.numeric (seq (1971, 2020)),
      cpu_moore = round(2250 * sqrt(2) ^ (year - 1971),0)
   )
```


### 2b.  Transform actual transistor counts
```{r transform, message = F, results = F}

   cpu_all <- cpu_raw %>%
      select(date_of_introduction, transistor_count) %>%
      rename (
         year = date_of_introduction,
         cpu_actual = transistor_count
         )

   cpu_max <- cpu_all %>%
      group_by (year) %>%
      summarize (cpu_actual = max(cpu_actual))
```


### 2c.  Combine data
```{r transform, message = F, results = F}     
   
   combine <- moore %>%
      left_join (cpu_max) %>%
      select (year, cpu_moore, cpu_actual) %>%
      na.omit()
```

### 3.  Calculate model
```{r}

   library (broom)

   combine <- loess(		    
          log10(cpu_actual) ~ year,		   
          data = cpu_max,		       
          na.action = na.omit
          ) %>%		
       augment (combine) %>%
       mutate (cpu_model = 10^.fitted)
```


### 4. Visualize data
```{r plot}

   library (scales)
   library (ggdark)

   ggplot () +
      #Lines
         #Moore's law prediction
             geom_line(
                data = combine,
                aes (x=year, y = cpu_moore),
                size = 0.4, linetype = 3
                ) +
         #Actual CPU model
            geom_line(
                data = combine,
                aes (x=year, y = cpu_model),
                size = 0.7, linetype = 2
                ) + 
      #Ribbons
         #Underpredict
            geom_ribbon (
               data = filter (combine, cpu_moore < cpu_model),
               aes (x=year, ymin = cpu_moore, ymax = cpu_model, fill = ""Model fit > Moore's Law""),
               show.legend = T
               ) +
         #Overpredict
            geom_ribbon (
               data = filter (combine, cpu_moore > cpu_model),
               aes (x=year, ymin = cpu_moore, ymax = cpu_model, fill = ""Model fit < Moore's Law""),
               show.legend = T
               ) +
      #Points
         geom_point(
            data = cpu_max,
            aes (x= year, y = cpu_actual, fill = ""CPU actual""),
            size = 2, alpha = 0.6, show.legend = T
             ) +
      #Annotation
         #Moore's Law
             annotate(
                  geom=""text"", x=1991.5,y=30000000,
                  label=""Moore's\nLaw"", 
                  color=""white"", size=3, hjust=0.5,vjust=0.5, fontface=""bold""
                  ) +
               geom_curve(
                  aes(x = 1991.5, xend = 1991.5, y = 13000000, yend = 3000000),
                  arrow = arrow(length = unit(0.1, ""inch"")),
                  size = 0.25, color = ""white"", curvature = 0  
                  ) +   
         #Model
                annotate(
                  geom=""text"", x=1990,y=80000,
                  label=""Model"", 
                  color=""white"", size=3, hjust=0.5,vjust=0.5, fontface=""bold""
                  ) +
               geom_curve(
                  aes(x = 1990, xend = 1990, y = 99000, yend = 800000),
                  arrow = arrow(length = unit(0.1, ""inch"")),
                  size = 0.25, color = ""white"", curvature = 0  
                  ) +   
      #scales
         scale_y_continuous(
            trans = log10_trans(),
            breaks = c(2250, 10000, 100000, 1000000, 10000000, 100000000, 1000000000, 10000000000, 100000000000),
            labels = comma
            ) +
         scale_x_continuous(breaks = seq (1970, 2020, 10)) +
         scale_fill_manual(values = c(""white"",""red"", ""green"")) +
      #themes
         dark_theme_classic () +
         theme(
            plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,7,0)),
            plot.title.position = ""plot"",
            plot.subtitle = element_text(hjust = 0, vjust = 0, size = 8, face = ""bold"", margin = margin (0,0,30,0)),
            plot.caption = element_text (hjust = 0, size = 8, face = ""plain"", margin = margin (15,0,0,0), color=""#6D7C83""),
            plot.caption.position = ""plot"",
            panel.grid.major = element_line(colour=""white"", size=0.03),
            axis.title.y = element_text (size = 9, hjust = 0),
            axis.title.x = element_blank(),
            legend.position = c(0.87,0.33),
            legend.title = element_blank (),
            legend.text = element_text(size=8),
            legend.key.size = unit(0.2, ""cm"")
            ) +
         guides(fill = guide_legend(override.aes = list(shape = NA))) +
      labs(
         title = ""Exponential growth in computing power"",
         subtitle = ""Gordon Moore predicted in 1971 that computing power would double approximately every 2 years (Moore's Law).\nOver the next 38 years he has largely been correct - slightly below through 2000, slightly above from 2001-2012 and slightly trailing more recently."",
         y = ""# of transistors on a CPU microchip"",
         caption = ""Visualization: Joel Soroos @soroosj  |  Data: Wikipedia via R4DS Tidy Tuesday""
         ) +
      ggsave(""moore.png"", width = 22, height = 13, units = ""cm"")
```","2019-36"
"365",761,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-09-17/Parks.Rmd","---
   title: ""National Parks""
   author: ""Joel Soroos""
   date: ""September 29, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 

   visits_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-17/national_parks.csv"") %>%
      clean_names ()
```


### 2.  Transform visits
```{r transform, message = F, results = F}

   visits <- visits_raw %>%
      filter (
         unit_type == ""National Park"",
         unit_name != ""Total"",
         year %in% c(1995, 2005, 2015)
         ) %>%
      select(year, unit_code, unit_code, unit_name, state, visitors) %>%
      mutate (year = as.numeric (year)) %>%
      arrange (-year, -visitors) %>%
      group_by (year) %>%
      mutate (rank_visitors = rank(desc(visitors), ties.method = ""first"")) %>%
      do(head(., n = 10)) %>%
      ungroup (year)

   visits_max <- visits %>%
      filter(year == max(year)) %>%
      mutate(year = as.numeric(year) + 0.25)

  visits_min <- visits %>%
      filter(year == min(year)) %>%
      mutate(year = as.numeric(year) - 0.25)

```


### 3a. Visualize data
```{r}

   library (ggrepel)

   ggplot(data = visits, mapping = aes(year, y = rank_visitors, group = unit_code, color = unit_code)) +
     geom_line(size = 1.7, alpha = 0.25, data = visits) +
     geom_line(size = 2.5, data = visits) +
     geom_point(size = 4, alpha = 0.25, data = visits) +
     geom_point(size = 4, data = visits) +
     geom_point(size = 1.75, color = ""white"", data = visits) +
     geom_text_repel(
        data = visits_max, 
        aes(label = unit_code), 
        hjust = ""inward"", size = 3
        ) +
     geom_text_repel(
        data = visits_min,
        aes(label = unit_code),
        hjust = ""inward"", size = 3
        ) +
     #scales
         scale_x_continuous(
            breaks = seq (1995, 2015, 10),
            expand = c(.1, .1)
            ) +
         scale_y_reverse (breaks = c(1,5,10)) +
         scale_color_manual(values = c(""#a6cee3"", ""#1f78b4"", ""#b2df8a"", ""#33a02c"", ""#fb9a99"", ""#e31a1c"", ""#fdbf6f"", ""#ff7f00"", ""#cab2d6"", ""#6a3d9a"", ""#ffff99"")) +
     labs (
       title = ""United States National Park Visitors (1995 - 2015)"",
       subtitle = ""     - Great Smoky Mountain and Grand Canyon National Parks continue as #1 and #2 most visited.\n     - Rocky Mountain National Park has grown from #7 to #3 while Olympic National Park has slipped from #4 to #7."",
       caption = ""Visualization: Joel Soroos @soroosj  |  Data: Wikipedia via R4DS Tidy Tuesday"",
       y = ""# of visitors rank""
         ) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,3,0)),
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 9, face = ""bold"", margin = margin (0,0,20,0)),
         plot.caption = element_text (hjust = 0, size = 8, face = ""plain"", margin = margin (20,0,0,0), color=""#6D7C83""),
         legend.position = ""none"",
         axis.title.y = element_text (size = 10, hjust = 1),
         axis.title.x = element_blank ()
         ) +
      ggsave(""parks.png"", width = 22, height = 13, units = ""cm"")
```












","2019-38"
"366",762,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-09-17/Slope Chart.R","### 3b. Visualize data
```{r plot}

library (ggrepel)

ggplot(data = visits, aes(x = year, y = z_visitors, group = unit_code)) +
   geom_line(
      aes(color = unit_code),
      alpha = 1, size = 1
   )+
   geom_text_repel(
      data = visits %>% 
         filter(year == 1966), 
      aes(label = unit_code) ,
      hjust = ""left"", fontface = ""bold"", size = 3, nudge_x = -.45, direction = ""y""
   ) +
   geom_text_repel(
      data = visits %>% 
         filter(year == 2016), 
      aes(label = unit_code) , 
      hjust = ""right"", fontface = ""bold"", size = 3, nudge_x = .5, direction = ""y""
   ) +
   geom_label(
      aes(label = z_visitors), 
      size = 2.5, 
      label.padding = unit(0.05, ""lines""), 
      label.size = 0.0
   ) +
   scale_x_discrete(position = ""top"") +
   theme_bw() +
   theme(
      legend.position = ""none"",
      panel.border     = element_blank(),
      axis.title.y     = element_blank(),
      axis.text.y      = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      axis.title.x     = element_blank(),
      panel.grid.major.x = element_blank(),
      axis.text.x.top      = element_text(size=12),
      axis.ticks       = element_blank(),
      plot.title       = element_text(size=14, face = ""bold"", hjust = 0.5),
      plot.subtitle    = element_text(hjust = 0.5)
   ) +
   labs(
      title = ""Estimates of Percent Survival Rates"",
      subtitle = ""Based on: Edward Tufte, Beautiful Evidence, 174, 176."",
      caption = ""Visualization: Joel Soroos @soroosj  |  Data: Wikipedia via R4DS Tidy Tuesday""
   ) 
```","2019-38"
"367",763,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-10-15/Cars.Rmd","---
   title: ""Vehicle MPG""
   author: ""Joel Soroos""
   date: ""October 20, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library (tidyverse)
   library (janitor) 
   library (magick)
   library (grid)

   cars_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")%>%
      clean_names () 
   	
   pump_img <- image_read(""petrol-pump.jpg"") %>%
      rasterGrob(width = unit(2,""in""))
```


### 2.  Transform data
```{r transform, message = F, results = F}

   cars <- cars_raw %>%
      filter (year == 2019) %>%
      select(id, make, model, eng_dscr, v_class, fuel_type1, comb08) %>%
      rename (
         fuel_type = fuel_type1,
         vehicle_class = v_class,
         mph_comb = comb08
         ) %>%
      mutate (vehicle_class = str_remove(vehicle_class, "" 2WD| 4WD"")) 
```


###3.  Model data
```{r}

   library (broom)

   cars_tidy <- lm (mph_comb ~ vehicle_class + fuel_type, cars) %>%
      tidy() %>%                 #coefficient estimates
      mutate (
         term = str_remove_all(term, ""fuel_type|vehicle_class| -""),                  #remove field names
         term = fct_reorder(term, estimate),
         estimate_direction = ifelse(estimate >=0, ""positive"", ""negative"")
         ) 
```


### 4. Visualize data
```{r}

   ggplot(data = cars_tidy, aes(y = estimate, x = term, fill = estimate_direction)) +
      geom_col() +
      annotation_custom (pump_img, ymin = -10, xmin = -2) +
      #scales
         scale_y_continuous(limits = c (-20, 80)) +
         scale_fill_manual(values = c(""red"", ""darkgreen"")) +
         coord_flip () +
      labs(
         title = ""How does your vehicle choice impact fuel efficiency?"",
         subtitle = ""Electric cars contribute most marginal miles per hour on average, vans and pickup trucks detract most."",
         x = ""Regression term"",
         y = ""Estimated marginal contribution (detraction) to mph"",
         caption = ""Each row represents linear regression estimate of vehicle class & gasoline type indepedent variables vs. miles per gallon dependent variable.\nVisualization: Joel Soroos @soroosj  |  Data: U.S. EPA via R4DS Tidy Tuesday""
         ) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,3,0)),
         plot.title.position = ""plot"",
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 10, face = ""bold"", margin = margin (0,0,25,0)),
         plot.caption = element_text (hjust = 0, size = 8, face = ""plain"", margin = margin (20,0,0,0)),
         plot.caption.position = ""plot"",
         panel.background = element_rect (fill = ""white""),
         axis.title = element_text (size = 9, hjust = 0.75, color = ""gray20""),
         axis.line = element_line(color = ""gray70""),
         axis.ticks = element_line(color = ""gray70""),
         legend.position = ""none""
            ) +
      ggsave(""cars.png"", width = 18, height = 13, units = ""cm"")
```","2019-42"
"368",764,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-10-29/Squirrels.Rmd","---
   title: ""Squirrels""
   author: ""Joel Soroos""
   date: ""November 3, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library(""tidyverse"")
   library(""ggmap"")

   squirrels_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")
   
   register_google(key = Sys.getenv(""GOOGLE_MAPS_API""))
```


### 2.  Transform data
```{r transform, message = F, results = F}

   squirrels <- squirrels_raw %>%
      pivot_longer (
         cols = c(running:foraging, kuks:runs_from), 
         names_to = ""activity"", 
         values_to = ""value""
         ) %>%
      filter (value == T) %>%
      select (long, lat, activity) %>%
      mutate (
         activity = str_to_title (activity),
         activity = case_when (
            activity == ""Tail_flags"" ~ ""Tail Flags"",
            activity == ""Tail_twitches"" ~ ""Tail Twitches"",
            activity == ""Runs_from"" ~ ""Runs From"",
            TRUE ~ activity)
         )
```


### 3. Visualize data
```{r visualize}

   library (ggdark)

   ggmap(
      get_googlemap(
         center = c(""Central Park""),
         zoom = 13, scale = 2, color = 'color',
         maptype ='roadmap',
         style = 'style=feature:all|element:labels|visibility:off'
         )
      ) +
      geom_point(
         data = squirrels, 
         aes(x = long, y = lat),
         size = 0.05, alpha = 0.7, color = ""blue""
         ) +
      scale_x_continuous(limits = c(-73.982, -73.95)) +
      scale_y_continuous(limits = c(40.765, 40.80)) +
      dark_mode(theme_minimal()) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,4,0)),
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 8, margin = margin (0,0,25,0)),
         plot.caption = element_text (hjust = 1, size = 7, face = ""plain"", margin = margin (10,0,0,0), color=""#6D7C83""),
         axis.title=element_blank(),
         axis.text=element_blank(),
         axis.ticks=element_blank(),
         strip.text = element_text (size = 8),
         legend.title=element_blank()
         ) +
      facet_wrap (
         facets = vars(activity),
         nrow = 3
         ) +
      labs(
         title = ""Squirrel Behaviors in New York's Central Park"",
         subtitle = ""      - Movements such as climbing/foraging far more common than sounds such as kuks/moans.\n      - Results from a study conducted by Jamie Allen and a team of 300 volunteers from October 6-20, 2018."",
         caption = ""Visualization: Joel Soroos @soroosj  |  Data: The Squirrel Census via R4DS Tidy Tuesday""
         ) +
      ggsave(""squirrels.png"", width = 15, height = 17, units = ""cm"")
```","2019-44"
"369",765,"https://github.com/soroosj/TidyTuesday","soroosj","TidyTuesday","2019-11-4/Commute.Rmd","---
   title: ""Commute""
   author: ""Joel Soroos""
   date: ""November 10, 2019""
   output: pdf_document
---


### 1. Source data
```{r source, warning = TRUE, results = FALSE, message = FALSE}

   library(""tidyverse"")
   library(""ggmap"")

   commute_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")
   
   register_google(key = Sys.getenv(""GOOGLE_MAPS_API""))
```


### 2.  Transform data
```{r transform, message = F, results = F}

   library (glue)   

   commute <- commute_raw %>%
      head (100) %>%
      select (city, state, n, percent) %>%
      mutate (city_state = glue (""{city}, {state}"")) %>%
      mutate_geocode (city_state)
```


### 3. Visualize data
```{r visualize}

   library (ggdark)

   ggmap(
      get_googlemap(
         center = c(""United States""),
         zoom = 4, scale = 2, color = 'color',
         maptype ='roadmap',
         style = 'style=feature:all|element:labels|visibility:off'
         )
      ) +
      geom_point(
         data = commute, 
         aes(x = lon, y = lat, fill = percent),
         alpha = 0.7
         ) +
      scale_fill_brewer(palette = ""BuPu"") +
      dark_mode(theme_minimal()) +
      theme(
         plot.title = element_text(hjust = 0, vjust = 0, size = 17, face = ""bold"", margin = margin (0,0,4,0)),
         plot.subtitle = element_text(hjust = 0, vjust = 0, size = 8, margin = margin (0,0,25,0)),
         plot.caption = element_text (hjust = 1, size = 7, face = ""plain"", margin = margin (10,0,0,0), color=""#6D7C83""),
         axis.title=element_blank(),
         axis.text=element_blank(),
         axis.ticks=element_blank(),
         legend.title=element_blank()
         ) +
      labs(
         title = ""Squirrel Behaviors in New York's Central Park"",
         subtitle = ""      - Movements such as climbing/foraging far more common than sounds such as kuks/moans.\n      - Results from a study conducted by Jamie Allen and a team of 300 volunteers from October 6-20, 2018."",
         caption = ""Visualization: Joel Soroos @soroosj  |  Data: The Squirrel Census via R4DS Tidy Tuesday""
         ) +
      ggsave(""commute.png"", width = 25, height = 14, units = ""cm"")
```","2019-44"
"370",766,"https://github.com/MiguelHeCa/tidytuesday/blob/master/2019-06-11/Meteorites.R","MiguelHeCa","tidytuesday","2019-06-11/Meteorites.R","# Tidy Tuesday | Week 24
# Meteorites!
# Source: ""https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-06-11""

library(tidyverse)
library(gganimate)

# Read data ---------------------------------------------------------------

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

world <- map_data(""world"")

# Prepare data ------------------------------------------------------------

meteo <- meteorites %>%
  drop_na() %>% 
  filter(mass > 0, year > 1300) %>% 
  mutate(year = if_else(name == ""Northwest Africa 7701"", 2010, year),
         year = as.integer(year),
         calc_mass = if_else(mass > 10000, 10000, mass))

fallen <- meteo %>% filter(fall == ""Fell"")
found <- meteo %>% filter(fall == ""Found"")

# Create static plot ------------------------------------------------------

map <- ggplot() +
  geom_polygon(
    data = world,
    aes(x = long, y = lat, group = group),
    fill = ""#e6e6e9"",
    size = 0.1
  ) +
  geom_point(
    data = fallen,
    aes(
      x = long,
      y = lat,
      size = calc_mass,
      color = calc_mass
    ),
    alpha = 0.5
  ) +
  scale_color_distiller(
    palette = ""Reds"",
    direction = 1,
    labels = c(""0"", ""2.5"", ""5.0"", ""7.5"", ""10.0+""),
    guide = guide_colorbar(
      direction = ""horizontal"",
      barheight = unit(3, units = ""mm""),
      barwidth = unit(60, units = ""mm""),
      title.position = ""top"",
      title.hjust = 0.5,
      label.hjust = 0.5
    )
  ) +
  geom_point(
    data = found,
    aes(
      x = long,
      y = lat,
      size = calc_mass,
      fill = calc_mass
    ),
    shape = 21,
    alpha = 0.5
  ) +
  scale_fill_distiller(
    palette = ""Blues"",
    direction = 1,
    labels = c(""0"", ""2.5"", ""5.0"", ""7.5"", ""10.0+""),
    guide = guide_colorbar(
      direction = ""horizontal"",
      barheight = unit(3, units = ""mm""),
      barwidth = unit(60, units = ""mm""),
      title.position = ""top"",
      title.hjust = 0.5,
      label.hjust = 0.5
    )
  ) +
  scale_size(guide = ""none"") +
  theme_void() +
  theme(
    legend.position = c(0.15, 0.1),
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, color = ""gray50"", size = 14), 
    plot.caption = element_text(hjust = 0.5),
    text = element_text(family = ""B612 Mono"")
  ) +
  labs(
    color = ""Fallen mass in kilograms"",
    fill = ""Found mass in kilograms"",
    title = ""Meteorites on Earth"",
    subtitle = ""Year: {frame_time}"",
    caption = ""Source: NASA""
  ) +
  coord_map(""mollweide"", orientation = c(90, 0, 0))

# Create GIF --------------------------------------------------------------

map_gif <- map +
  transition_events(start = year,
                    end = year + 5L,
                    enter_length = 6L,
                    exit_length = 4L) +
  enter_grow() +
  exit_fade()

animate(map_gif, nframes = 160, duration = 40, height = 768, width = 1024)

anim_save(""2019-06-11/Meteorites.gif"")
","2019-24"
"371",767,"https://github.com/MiguelHeCa/tidytuesday/blob/master/2019-05-28/wine.R","MiguelHeCa","tidytuesday","2019-05-28/wine.R","# TidyTuesday Week 22


# Load packages -----------------------------------------------------------

library(tidyverse)
library(tidytext)
library(wordcloud2)

# Prepare data ------------------------------------------------------------

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

wr <- wine_ratings %>% drop_na(points, price)

# Select only latinamerican countries
latinamerica <- c(""Argentina"", ""Brazil"",  ""Chile"", ""Mexico"", ""Peru"", ""Uruguay"")

wr_lat <- wr %>% 
  filter(country %in% latinamerica) %>% 
  select(country, description, points, price)

# It was easier to include this words in the stop_words data frame than
# using regex. I excluded this words because I thought they might not give 
# give any useful insight about wine description.
additional_stop_words <- tibble(
  word = c(
    ""flavor"",
    ""flavors"",
    ""aroma"",
    ""aromas"",
    ""drink"",
    ""drinks""
  ),
  lexicon = ""Wine""
)

all_stop_words <- stop_words %>% 
  bind_rows(additional_stop_words)

# Select only the observations whose points are ranked in the top ten.
# Then I prepare data for the word clouds
wine_lat <- wr_lat %>%
  group_by(country) %>% 
  mutate(ranking = dense_rank(points)) %>% 
  arrange(ranking) %>% 
  ungroup() %>% 
  filter(ranking >= 10) %>% 
  mutate(description = str_replace_all(description, ""\\d"", """")) %>% 
  group_by(country) %>% 
  unnest_tokens(word, description) %>% 
  anti_join(all_stop_words, by = c(""word"" = ""word"")) %>% 
  count(word, sort = T, name = ""freq"") %>% 
  ungroup()

# Get a vector of the countries that are left from the criteria. Sorry Peru!
rated_countries <- wine_lat %>% 
  distinct(country) %>% 
  arrange(country) %>% 
  unlist() %>% 
  unname()

# Word cloud --------------------------------------------------------------

wine_colors <-  c(""#5b0b0b"", ""#790000"", ""#8f8023"", ""#9e934d"", ""#bcb37b"")

create_wordcloud <- function(COUNTRY){
  wine_lat %>% 
    filter(country == COUNTRY) %>% 
    select(word, freq) %>% 
    wordcloud2(size = 1,
               color = rep_len(wine_colors, nrow(.)),
               fontFamily = ""Open Sans"")
}  

wc_a <- create_wordcloud(rated_countries[1])
wc_b <- create_wordcloud(rated_countries[2])
wc_c <- create_wordcloud(rated_countries[3])
wc_m <- create_wordcloud(rated_countries[4])
wc_u <- create_wordcloud(rated_countries[5])

# Saved word clouds manually through RStudio given that saving it by code
# is too convoluted.
# I tried ggwordcloud and wordcloud also, but rendering took too long and the 
# cloud is not as aesthetically pleasing as in wordcloud2.
# Caveat is that making grids with wordcloud2 are a real pain, though,
# so I cheated a little bit with the final plot (edited it elsewhere).
# If you know any realiable method to make grids with wordcloud or wordcloud2
# please let me know.


","2019-22"
"372",784,"https://github.com/oscarbaruffa/tidytuesday-2019-01-01-rtweet","oscarbaruffa","tidytuesday-2019-01-01-rtweet","2019-01-01_rstats_tweets_script.R","
library(tidyverse)
library(tidytext)
library(extrafont)

font_import()
loadfonts(device = ""win"")

#reduce size of dataset

# tweets_raw <- read_rds(""data/rstats_tweets.rds"")
# 
# tweets_raw %>%
#   filter(lang == ""en"") %>%
#   select(""status_id"", ""created_at"", ""text"", ""source"") %>%
#   write_rds(""data/tweets_raw2.rds"", ""gz"")


tweets_raw2 <- read_rds(""data/tweets_raw2.rds"")

#View some summary stats
# summary(tweets_raw2)
# skimr::skim(tweets_raw2)
# glimpse(tweets_raw2)

#Let's see the top words. Code from https://github.com/jasonbaik94/rstats-2019-goals/find/master

# Get rid of all non-ASCII characters
# Get rid of 2019, #rstats, goals
# Get rid of \n
# Get rid of periods, numbers, https (urls), amp, tco

tweets <- tweets_raw2 %>% 
  mutate(text = str_replace_all(text, ""[^\x01-\x7F]"", """"),
         text = str_replace_all(text, ""2019|goals|#rstats|#Rstats|#RStats"", """"),
         text = str_replace_all(text, ""\n"", """"),
         text = str_replace_all(text, ""\\.|[[:digit:]]+"", """"),
         text = str_replace_all(text, ""http|rt|Http|Rt|https|amp|tco"", """"))

#just checking top 20 words
tweets %>%  
  unnest_tokens(word, text) %>% 
  anti_join(stop_words, by = ""word"") %>% 
  count(word, sort = TRUE) %>%
  head(20)
 
#filter for passion words
tweets %>%  
  unnest_tokens(word, text) %>% 
  filter(word %in% c(""love"", ""Love"", ""hate"", ""Hate"")) %>% 
  count(word, sort = TRUE)

#created Date-formatted dates
tweets$created_at <-  as.Date(tweets$created_at, 'GMT') 

#cumulative sum of passion words
passion_tweets <- tweets %>%  
  unnest_tokens(word, text) %>% 
  filter(word %in% c(""love"", ""Love"", ""hate"", ""Hate"")) %>% 
  arrange(created_at) %>% 
  mutate(hate_count = ifelse(word == ""hate"", 1, 0)) %>% 
  mutate(love_count = ifelse(word == ""love"", 1, 0)) %>% 
  mutate(hate = cumsum(hate_count)) %>% 
  mutate(love = cumsum(love_count)) %>% 
  gather(hate:love, key = passion_word, value = total_tweets)


ggplot(passion_tweets) + 
  geom_line(aes(created_at, total_tweets, color = passion_word), size = 2) +
  labs(title = ""Come for the #Rstats, stay for the Love"",
       subtitle = ""Cumulative sum of words 'love' and 'hate' in #rstats tweets"",
       x = """",
       y = """",
       caption = ""TidyTuesday 2019-01-01\n Plot: @oscar_b123 \n Data: rwteet"") +
  ylim(0, 5000) +
  geom_text(data = subset(passion_tweets, created_at == max(created_at)), 
            aes(x = max(created_at), y = total_tweets, label = passion_word,
                colour = passion_word), size = 6, hjust = 1, vjust = -0.2) +
  scale_colour_manual(values = c(""#000000"", ""#e00fc8""))+
  theme_minimal() +
  theme(legend.position = ""none"",
        text = element_text(family = ""Bahnschrift""),
        plot.background = element_rect(fill='#f5d59a', colour = ""#f5d59a""),
        panel.background = element_rect(fill='#f5d59a', colour = ""#f5d59a""),
        panel.grid.major = element_line(colour = ""#f4ece1""),
        panel.grid.minor = element_line(colour = ""#f4ece1""))
  

 


  
","2019-1"
"373",785,"https://github.com/PMassicotte/r-blog/blob/master/content/post/2019-07-30-tidytuesday-video-games.en.Rmd","PMassicotte","r-blog","content/post/2019-07-30-tidytuesday-video-games.en.Rmd","---
title: 'Tidytuesday: video games'
author: Philippe Massicotte
date: '2019-07-30'
slug: tidytuesday-video-games
categories:
  - R
  - Tidytuesday
tags: []
type: ''
subtitle: ''
image: ''
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = ""#>"",
  collapse = TRUE,
  cache = TRUE,
  dpi = 300,
  out.width = ""100%"",
  fig.align = ""center"",
  fig.width = 8,
  fig.asp = 0.618, # 1 / phi
  fig.show = ""hold"",
  dev = ""svg"",
  message = FALSE
)

library(tidyverse)
library(ggpmthemes)
library(glue)
theme_set(theme_poppins())
```

I must admit, I played a lot of PC video games when I was younger, *Battlefield*, *Half-life*, *Dark Age of Camelot*, *World of Warcraft*, *Diablo* just to name a few. This is why this week [tidytuesday](https://github.com/rfordatascience/tidytuesday) was a good occasion to participate in this weekly R visualization challenge. 

## Video Games Dataset

> This week's data comes courtesy of Liza Wood via Steam Spy. She recently published a blog post on her data analysis of this video game data. She was kind enough to provide a fairly clean dataset, and I have done some small additional clean up seen below. There is time played, ownership, release date, publishing information, and for some a metascore! Lots of ways to slice and dice this data!

Let us get started! First, read the data and remove duplicated entries.

```{r}
video_games <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"") %>%
  mutate(release_date = as.Date(release_date, ""%b %d, %Y"")) %>%
  distinct(game, developer, publisher, .keep_all = TRUE)
```

## Top played games

Which games have the highest average playing time in the past two weeks? In the following graph, it can be seen that *Clicker Heroes* (released in 2015) has an average playtime of about 80 hours. That is 40 hours per week, a full-time job.

```{r}
video_games %>%
  top_n(16, average_playtime) %>%
  mutate(game = glue(""{game} ({lubridate::year(release_date)})"")) %>%
  mutate(game = fct_reorder(game, average_playtime)) %>%
  ggplot(aes(x = game, y = average_playtime / 60)) +
  geom_col() +
  coord_flip() +
  xlab(NULL) +
  ylab(""Average played time (hours)"") +
  labs(title = str_wrap(""Average played time for the last two weeks"", 25)) +
  labs(subtitle = ""Only the top 16 averaged played game are shown"")
```

## Temporal evolution of metascore

What is the evolution of the metascore by the publishers? It seems that *high ranked* publishers have pretty constant metascore for their games. However, there is an interesting decreasing trend with *SEGA* that started in 2006.

```{r}
equal_breaks <- function(n = 3, s = 0.05, ...) {
  function(x) {
    # rescaling
    d <- s * diff(range(x)) / (1 + 2 * s)
    seq(min(x) + d, max(x) - d, length = n)
  }
}

video_games %>%
  drop_na(metascore) %>%
  add_count(publisher) %>%
  filter(dense_rank(desc(n)) <= 6) %>%
  group_by(year = lubridate::year(release_date), publisher) %>%
  summarise(mean_metascore = mean(metascore), sd_metascore = sd(metascore)) %>%
  ggplot(aes(x = year, y = mean_metascore)) +
  geom_line(size = 2) +
  facet_wrap(~publisher, scale = ""free_x"") +
  scale_x_continuous(
    labels = function(x) floor(x),
    breaks = equal_breaks(n = 4, s = 0.05)
  ) +
  xlab(NULL) +
  ylab(""Median metascore"") +
  theme(legend.position = ""none"") +
  theme(panel.spacing = unit(2, ""lines"")) +
  labs(title = ""Time series of metascore by publisher"") +
  labs(subtitle = ""Only the six publishers with the highest number of release are shown"")
```

## Price evolution of games

The median prices of the released game appear to decrease between 2015 and 2018. Also, we can see the lowest prices are happening in January, right after Christmas.

```{r}
video_games %>%
  drop_na(release_date) %>%
  group_by(year = lubridate::year(release_date), month = lubridate::month(release_date, label = TRUE)) %>%
  summarise(medan_price = median(price, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = month, fill = medan_price)) +
  geom_tile() +
  scale_fill_viridis_c(option = ""A"", labels = scales::dollar) +
  coord_equal() +
  scale_x_continuous(expand = c(0, 0), breaks = seq(2000, 2020, by = 2)) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(fill = ""Median\nprice (USD)"") +
  xlab(NULL) +
  ylab(NULL) +
  labs(title = ""Price evolution of games"") +
  labs(subtitle = ""Median price calculated monthly and yearly"")
```

There is a clear peak in November 2006 which can be explained by few game prices above 10$.

```{r}
video_games %>%
  filter(
    lubridate::year(release_date) == 2006 &
      lubridate::month(release_date) == 11
  ) %>%
  select(game, release_date, price) %>%
  arrange(desc(price)) %>%
  knitr::kable()
```

## Most expensive games

I was also surprised to see that the most expensive game was almost 600$ USD!

```{r}
video_games %>%
  top_n(5, price) %>%
  mutate(game = glue(""{game} ({lubridate::year(release_date)})"")) %>%
  mutate(game = str_wrap(game, 30)) %>%
  mutate(game = fct_reorder(game, price)) %>%
  ggplot(aes(x = game, y = price)) +
  geom_col() +
  coord_flip() +
  xlab(NULL) +
  ylab(""Price (USD)"") +
  labs(title = ""Top priced games"") +
  labs(subtitle = ""Only shows the top 5 most expensive games"") +
  scale_y_continuous(labels = scales::dollar)
```
","2019-31"
"374",786,"https://github.com/pabrodez/tidytuesday","pabrodez","tidytuesday","2019-07-16/script.R","library(tidyverse)
library(lubridate)
library(ggthemes)
library(grid)

r4ds_members <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")

df <-
  r4ds_members %>%  ## inspiration from https://github.com/andriy-gazin/geowaffle/blob/master/geowaffle.R
  select(date,
         messages_in_public_channels,
         messages_in_private_channels,
         messages_in_d_ms) %>%
  mutate(date = floor_date(date, ""month"")) %>%
  gather(""type_msg"", ""n_msg"", -date) %>%
  group_by(date, type_msg) %>%
  summarise(n_msg = sum(n_msg)) %>%
  mutate(total_msg = sum(n_msg)) %>%
  group_by(type_msg, add = TRUE) %>%
  summarise(prop_msg = floor(n_msg / total_msg * 100)) %>%
  group_by(type_msg, add = TRUE) %>%
  group_modify(.f = ~ slice(.x, rep(1, .x$prop_msg))) %>%
  select(-prop_msg) %>%
  arrange(date, type_msg) %>%
  ungroup() %>%
  group_by(date) %>%
  group_modify(.f = ~ {
    bind_cols(type_msg = .x$type_msg, head(expand.grid(x = 1:10, y = 1:10), nrow(.x)))
  }) %>%
  ungroup() %>%
  mutate(date = factor(strftime(date, ""%b %y""),
                       levels = strftime(seq.Date(
                         min(.$date), max(.$date), ""months""
                       ), ""%b %y"")))


plot_r4ds <- ggplot(df, aes(x = x, y = y, fill = type_msg)) +
  geom_tile(alpha = .5) +
  facet_wrap( ~ date) +
  coord_fixed(ratio = 1.5 / 1) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 12)) +
  scale_fill_solarized(
    label = c(""Direct\nmessages"", ""Private\nchannels"", ""Public\nchannels""),
    guide = guide_legend(
      title = NULL,
      label.position = ""bottom"",
      label.hjust = 0
    )
  ) +
  labs(title = ""How does the R4DS community message?"",
       caption = ""Data: R4DS tidytuesday | Graphic: @pabrodez"") +
  theme_void() +
  theme(
    text = element_text(color = ""#6b634e"", family = ""Ubuntu Mono""),
    panel.background = element_rect(fill = ""#ffefbf""),
    plot.background = element_rect(fill = ""#ffefbf""), 
    legend.direction = ""horizontal"",
    legend.spacing.x = unit(.1, ""cm""),
    legend.key.height = unit(.1, ""cm""),
    legend.position = c(.5, 1.1),
    strip.text = element_text(hjust = 0.1, vjust = 1, size = 10),
    plot.margin = margin(.5, 1, .5, 1, unit = ""cm""),
    plot.title = element_text(margin = margin(t = 1, b = 4, unit = ""cm""), hjust = .5, size = 16, face = ""bold""),
    plot.caption = element_text(margin = margin(t = 2, unit = ""cm""), size = 10)
  )

plot_r4ds <- ggplotGrob(plot_r4ds)  ## code from https://stackoverflow.com/questions/48199791/rounded-corners-in-ggplot2
bg <- plot_r4ds$grobs[[1]]
round_bg <- roundrectGrob(x=bg$x, y=bg$y, width=bg$width, height=bg$height,
                          r=unit(0.1, ""snpc""),
                          just=bg$just, name=bg$name, gp=bg$gp, vp=bg$vp)
plot_r4ds$grobs[[1]] <- round_bg

ggsave(""./tidytuesday/2019_07_16.png"", plot_r4ds, height = 29, width = 21, units = ""cm"", dpi = ""retina"")
","2019-29"
"375",787,"https://github.com/pabrodez/tidytuesday","pabrodez","tidytuesday","2019-07-30/2019_07_30.R","library(tidyverse)
library(janitor)
library(lubridate)
library(cowplot)

# clean dataset from lizawood's github
url <- ""https://raw.githubusercontent.com/lizawood/apps-and-games/master/PC_Games/PCgames_2004_2018_raw.csv""

# read in raw data
raw_df <- url %>% 
  read_csv() %>% 
  janitor::clean_names() 

# clean up some of the factors and playtime data
clean_df <- raw_df %>% 
  mutate(price = as.numeric(price),
         score_rank = word(score_rank_userscore_metascore, 1),
         average_playtime = word(playtime_median, 1),
         median_playtime = word(playtime_median, 2),
         median_playtime = str_remove(median_playtime, ""\\(""),
         median_playtime = str_remove(median_playtime, ""\\)""),
         average_playtime = 60 * as.numeric(str_sub(average_playtime, 1, 2)) +
           as.numeric(str_sub(average_playtime, 4, 5)),
         median_playtime = 60 * as.numeric(str_sub(median_playtime, 1, 2)) +
           as.numeric(str_sub(median_playtime, 4, 5)),
         metascore = as.double(str_sub(score_rank_userscore_metascore, start = -4, end = -3))) %>% 
  select(-score_rank_userscore_metascore, -score_rank, -playtime_median) %>% 
  rename(publisher = publisher_s, developer = developer_s) %>% 
  mutate(release_date = as.Date(release_date, ""%b %e, %Y""))

# top 5 publishers
top_publishers <- select(clean_df, publisher) %>% 
  na.omit() %>% 
  count(publisher) %>% 
  top_n(5) %>% 
  inner_join(., clean_df, by = ""publisher"") 

# plot
mean_price_plot <- 
  top_publishers %>% 
  group_by(publisher, release_year = year(release_date)) %>% 
  summarise(mean_year_price = mean(price, na.rm = TRUE)) %>% 
  ggplot(aes(y = publisher, x = release_year, fill = mean_year_price)) +
  geom_tile(height = .15) +
  scale_fill_continuous(low = ""#543f43"", high = ""#9e767d"", 
                        name = ""Mean price"", 
                        guide = guide_legend(label.position = ""bottom"", title.position = ""top"", title.hjust = .5)) +
  scale_x_continuous(breaks = 2004:2018, labels = function(x) substr(x, 3, 4), limits = c(2003, 2019)) +
  coord_polar() +
  ylim(letters[1], unique(top_publishers$publisher)) +  ## create dummy levels of discrete scale to create space between center and first level
  annotate(""segment"", x = seq(2003.5, 2017.5, 1), y = 2, xend = seq(2003.5, 2017.5, 1), yend = 6, alpha = .1) +
  theme_void() +
  theme(text = element_text(color = ""#CCCCCC"", family = ""Avant Garde""),
        plot.background = element_rect(fill = ""transparent""), 
        panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        legend.position = ""bottom"", 
        legend.key.height = unit(1, ""mm""),
        legend.spacing.x = unit(4, ""mm""))

legend_price <- get_legend(mean_price_plot)
mean_price_plot <- mean_price_plot + theme(legend.position = ""none"")

main_circle_plot <- 
  top_publishers %>% 
  group_by(publisher, release_year = year(release_date)) %>% 
  summarise(n = n()) %>% 
  ungroup() %>% 
  ggplot(aes(x = release_year, y = publisher, fill = n)) +
  geom_tile(height = .25) +
  scale_fill_continuous(low = ""#3f3f54"", high = ""#8d8eb7"",
                        breaks = c(10, 30, 60, 90), 
                        name = ""Games released"",
                        guide = guide_legend(label.position = ""bottom"", title.position = ""top"", title.hjust = .5)) +
  scale_x_continuous(breaks = 2004:2018, labels = function(x) substr(x, 3, 4), limits = c(2003, 2019)) +
  geom_text(aes(label = publisher, x = 2018.55), vjust = 0.5, hjust = 0, color = ""#CCCCCC"", family = ""Avant Garde"", size = 4) +
  coord_polar() +
  ylim(letters[1:10], unique(top_publishers$publisher)) +  ## create dummy levels of discrete scale to create space between center and first level
  annotate(""segment"", x = seq(2003.5, 2017.5, 1), y = 11, xend = seq(2003.5, 2017.5, 1), yend = 15, alpha = .1) +
  labs(title = ""Games released and mean price by year by top 5 publishers"",
       caption = ""Source: Steam Spy | Graphic: @pabrodez"") +
  theme_minimal() +
  theme(text = element_text(color = ""#CCCCCC"", family = ""Avant Garde""),
        plot.background = element_rect(fill = ""#405450""), 
        panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.text.y = element_blank(),
        axis.text.x = element_text(margin = margin(t = -5, unit = ""mm""), color = ""#CCCCCC""),
        legend.position = ""bottom"", 
        legend.key.height = unit(1, ""mm""),
        legend.spacing.x = unit(4, ""mm""),
        plot.margin = margin(.5, 1, .5, 1, unit = ""cm""),
        plot.caption = element_text(margin = margin(t = 100)),
        plot.title = element_text(hjust = .5, margin = margin(t = 25, b = 30)))

legend_games <- get_legend(main_circle_plot)
main_circle_plot <- main_circle_plot + theme(legend.position = ""none"")

arranged_plot <- 
  ggdraw() +
  draw_plot(main_circle_plot, 0, 0, 1, 1) +
  draw_plot(mean_price_plot, .225, .245, .55, .55) + ## adjusting position has been a source of affliction 
  draw_plot(legend_price, .2, .1, .1, .1) +
  draw_plot(legend_games, .7, .1, .1, .1)

ggsave(""./tidytuesday/2019_07_30.png"", plot = arranged_plot, height = 11, width = 9, dpi = ""retina"")
","2019-31"
"376",788,"https://github.com/pabrodez/tidytuesday","pabrodez","tidytuesday","2019-09-24/2019_09_24.R","library(tidyverse)
library(ggforce)
library(scales)

school_diversity <-
  readr::read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv""
  ) %>%
  set_names(tolower)

## cut prop of white into 0-25, 25-50, etc. groups in first and second school years
df <-
  school_diversity %>%
  select(leaid, school_year, white) %>% 
  group_by(leaid) %>%
  mutate(n = n()) %>%
  ungroup() %>%
  filter(n == 2) %>% 
  select(-n) %>% 
  pivot_wider(names_from = ""school_year"", values_from = ""white"") %>%
  mutate(perc_diff = `2016-2017` - `1994-1995`) %>% 
  mutate(perc_group_94 = cut_width(`1994-1995`, 25, boundary = 0, closed = ""left""),
         perc_group_17 = cut_width(`2016-2017`, 25, boundary = 0, closed = ""left"")) 

plot_schools <- 
  df %>% 
  ggplot() +
  geom_curve(aes(
    x = -10,
    y = `1994-1995`,
    xend = `2016-2017`,
    yend = -30,
    color = perc_diff
  ),
  curvature = -0.4,
  size = .1,
  ncp = 10) +
  scale_x_continuous(expand = expand_scale(mult = c(0, .01)),
                     labels = function(x) paste0(x, ""%"")) +
  scale_y_continuous(breaks = seq(0, 100, 25),
                     labels = function(x) paste0(x, ""%""),
                     expand = expand_scale(mult = c(0, .2))) +
  scale_color_gradient2(low = ""#004B40"", mid = ""#F6F6F6"", high = ""#533600"",
                        breaks = seq(-100, 100, 50),
                        limits = c(-100, 100),
                        labels = paste0(seq(-100, 100, 50), ""%""),
                        guide = guide_colorbar(title = ""Change in % units"",
                                               title.position = ""top"",
                                               title.hjust = .5,
                                               barheight = unit(2, ""mm""),
                                               barwidth = unit(50, ""mm""))) +
  facet_col(~ perc_group_94) +
  labs(x = ""2016-2017"", y = ""1994-1995"", 
       title = ""Change in proportion of white students\nin schools from 1994-95 to 2016-17"",
       caption = ""Graphic: @pabrodez | Source: The Washington Post"") +
  theme_minimal(base_family = ""Cabin"") +
  theme(strip.text = element_blank(),
        panel.grid.major.x = element_line(size = rel(.5), color = ""grey70""),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.spacing.y = unit(.5, ""cm""),
        plot.background = element_rect(fill = ""grey85""),
        panel.border = element_rect(color = ""transparent"", fill = ""transparent""),
        legend.position = ""top"",
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 10),
        legend.direction = ""horizontal"", legend.spacing.x = unit(0, units = ""cm""),
        plot.margin = margin(0, 1, 0, 0.5, unit = ""cm""),
        plot.caption = element_text(margin = margin(t = 1, b = .5, unit = ""cm"")),
        plot.title = element_text(margin = margin(t = 1, b = 1, unit = ""cm""), 
                                  hjust = .5, lineheight = 1.5, face = ""bold"", color = ""grey40"", size = 16)) 

ggsave(plot = plot_schools, filename = ""2019_09_24.png"", height = 10, width = 5, dpi = ""retina"")
","2019-39"
"377",789,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-04-23-anime.R","library(tidyverse)
library(ggthemes)

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

score_summary <- tidy_anime %>%
     filter(!is.na(studio)) %>% 
     group_by(studio) %>%
     summarise(
          n = n(),
          score_mean = mean(score, na.rm = TRUE),
          scored_by_mean = mean(scored_by, na.rm = TRUE),
          ) %>% 
     ungroup()

plot <- ggplot(score_summary, aes(n, score_mean)) +
     geom_point(aes(size = scored_by_mean), alpha = 0.7,
                show.legend = FALSE) +
     geom_smooth(se = FALSE, color = ""dimgray"") +
     scale_x_log10() +
     scale_color_viridis(option = ""A"") +
     labs(title = ""Do Bigger Studios Make Higher Rated Anime?"",
          subtitle = ""Point size correlates with number of user ratings"",
          x = ""Number of Titles from Studio"",
          y = ""Average Rating"",
          caption = ""Data: MyAnimeList \nVisualization: @frau_dr_barber"") +
     theme_solarized() +
     theme(plot.title = element_text(color = ""black""),
          plot.subtitle = element_text(size = 9),
          plot.caption = element_text(size = 7))

ggsave(""studio_rating.png"", height = 4, width = 5, units = ""in"")
","2019-17"
"378",790,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-04-30_bird-collisions.R","library(tidyverse)
library(lubridate)

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

plot <- bird_collisions %>%
     mutate(year = lubridate::year(date)) %>%
     ggplot(aes(year)) +
     geom_bar(aes(fill = fct_infreq(habitat) %>% fct_rev()), 
              position = ""stack"") +
     geom_hline(yintercept = 0, color = ""white"") +
     scale_fill_manual(values = c(""#FFF5EE"", ""#B5D7A6"", ""#197230"")) +
     labs(x = ""Year"", y = ""Number of Collisions"",
          title = ""Bird-Window Collisions in Chicago: 1978-present"",
          subtitle = ""Overall increase in the number of collisions, with forest-living birds showing a disproportionate increase"",
          fill = ""Natural Habitat:   "",
          caption = ""Visualization: @frau_dr_barber
          Source: https://doi.org/10.1098/rspb.2019.0364"") +
     theme(plot.background = element_rect(fill = ""#B3DDF2""),
           panel.background = element_rect(fill = ""#B3DDF2""),
           legend.background = element_rect(fill = ""#B3DDF2""),
           axis.text = element_text(size = 12),
           axis.title = element_text(size = 14),
           plot.title = element_text(size = 14, face = ""bold""),
           legend.position = c(0.12, 0.79),
           axis.ticks = element_blank(),
           panel.grid.major.x = element_blank(),
           panel.grid.minor.x = element_blank(),
           panel.grid.minor.y = element_blank()
           ) 

ggsave(""bird_collisions.png"", dpi = ""retina"", height = 5, width = 8, units = ""in"")
","2019-18"
"379",791,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-05-07_teacher-ratios.R","library(tidyverse)
library(paletteer)
library(ggthemes)
library(patchwork)

# Datasets ----
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

Europe_countries <- c(""Albania"", ""Andorra"", ""Austria"",  ""Belarus"",
                      ""Belgium"", ""Bosnia and Herzegovina"", ""Bulgaria"", 
                      ""Croatia"", ""Cyprus"", ""Czech Republic"", ""Denmark"", 
                      ""Estonia"",""Finland"", ""France"", ""Germany"", ""Greece"", 
                      ""Hungary"", ""Ireland"", ""Italy"", ""Iceland"", ""Kosovo"", 
                      ""Latvia"", ""Liechtenstein"",""Lithuania"", ""Luxembourg"", 
                      ""Malta"", ""Moldova"", ""Montenegro"", ""Monaco"", ""Macedonia"", 
                      ""Netherlands"", ""Norway"", ""Poland"", ""Portugal"", 
                      ""Romania"", ""San Marino"", ""Serbia"",""Slovakia"", ""Slovenia"",
                      ""Spain"", ""Sweden"", ""Switzerland"", ""Ukraine"", ""UK"")

map_data <- map_data(""world"") 
     
#fix country names to match names in Map database
student_ratio <- student_ratio %>% 
     mutate(
          country = str_replace_all(country, c(""Czechia"" = ""Czech Republic"",
                                               ""United Kingdom of Great Britain and Northern Ireland"" = ""UK"",
                                               ""Russian Federation"" = ""Russia"",
                                               ""Republic of Moldova"" = ""Moldova"",
                                               ""The former Yugoslav Republic of Macedonia"" = ""Macedonia"")),
          indicator = factor(indicator, levels = c(""Pre-Primary Education"",
                                                   ""Primary Education"",
                                                   ""Lower Secondary Education"",
                                                   ""Upper Secondary Education"",
                                                   ""Secondary Education"",
                                                   ""Post-Secondary Non-Tertiary Education"",
                                                   ""Tertiary Education""
          ))
     )
# collapse educaiton levels to combine lower and upper secondary
student_ratio_collapse <- student_ratio %>% 
     mutate(indicator = fct_collapse(indicator, 
                                     ""Secondary Education"" = c(""Lower Secondary Education"", ""Upper Secondary Education"",
                                                               ""Secondary Education""),
                                     ""Post-secondary Education"" = c(""Post-Secondary Non-Tertiary Education"",
                                                                    ""Tertiary Education""))
     )

# Map of Primary Education Class Sizes ----
primary <- student_ratio_collapse %>% 
     filter(country %in% Europe_countries, indicator == ""Primary Education"",
            country != ""Iceland"") %>% #sorry Iceland
     group_by(country) %>% 
     summarise(
          n = n(),
          average = mean(student_ratio, na.rm = TRUE)
     ) 

plot_primary <- primary %>% 
     left_join(map_data, by = c(""country"" = ""region"")) %>% 
     ggplot(aes(x = long, y = lat)) +
     geom_polygon(aes(fill = average, group = group), color = ""black"", size = 0.2) +
     coord_map(""mollweide"", ylim = c(30, 72)) +
     theme_economist() +
     labs(x = """",
          y = """",
          fill = ""Student-to-teacher ratio"",
          title = ""Primary Education\n(ISCED 1)"") +
     scale_fill_paletteer_c(""ggthemes"", ""Red-Green-White Diverging"", -1,
                            breaks = c(6, 9, 12, 15, 18)) +
     theme(axis.line.x = element_blank(),
           axis.text = element_blank(),
           axis.ticks = element_blank(),
           panel.grid = element_blank(),
           legend.position = ""bottom"",
           legend.direction = ""horizontal"",
           plot.title = element_text(hjust = 0.5, size = rel(1.4)),
           plot.margin = unit(c(0.2,0.2,0.2,0.2),""cm"")
     )

# Map of Secondary Education Class Sizes ---- 
secondary <- student_ratio_collapse %>% 
     filter(country %in% Europe_countries, indicator == ""Secondary Education"",
            country != ""Iceland"") %>% #sorry again Iceland
     group_by(country) %>% 
     summarise(
          n = n(),
          average = mean(student_ratio, na.rm = TRUE)
     ) 

plot_secondary <- secondary %>% 
     left_join(map_data, by = c(""country"" = ""region"")) %>% 
     ggplot(aes(x = long, y = lat)) +
     geom_polygon(aes(fill = average, group = group), color = ""black"", size = 0.2) +
     theme_economist() +
     coord_map(""mollweide"", ylim = c(30, 72)) +
     scale_fill_paletteer_c(""ggthemes"", ""Red-Green-White Diverging"", -1,
                            breaks = c(6, 9, 12, 15, 18)) +
     labs(x = """",
          y = """",
          fill = ""Student-to-teacher ratio"",
          title = ""Secondary Education\n(ISCED 2 & 3)"") +
     theme(axis.line.x = element_blank(),
           axis.text = element_blank(),
           axis.ticks = element_blank(),
           panel.grid = element_blank(),
           legend.position = ""bottom"",
           legend.direction = ""horizontal"",
           plot.title = element_text(hjust = 0.5, size = rel(1.4)),
           plot.margin = unit(c(0.2,0.2,0.2,0.2),""cm"")
     )

# Primary vs. secondary comparison ----
primary_secondary_comparison <- primary %>% 
     inner_join(secondary, by = ""country"") %>% 
     rename(primary = average.x, secondary = average.y) %>% 
     select(country, primary, secondary) %>% 
     mutate(diff = secondary - primary,
            perc_diff = (secondary / primary) - 1
            )

top_5 <- primary_secondary_comparison %>% top_n(5, perc_diff)
bottom_5 <- primary_secondary_comparison %>% top_n(-5, perc_diff)

plot_comparison <- bind_rows(top_5, bottom_5) %>% 
     ggplot(aes(fct_reorder(country, perc_diff), perc_diff)) +
     geom_col() +
     scale_y_continuous(labels = scales::percent_format(accuracy = 1), 
                        position = ""right"") +
     coord_flip() +
     labs(x = """", 
          y = ""Positive values = secondary school\nclasses larger than primary classes\n"",
          title = ""\nCountries with the greatest differences in\nprimary and secondary school class sizes\n\n""
     ) +
     theme_economist() +
     theme(panel.grid.major = element_line(size = 0.45),
           axis.text = element_text(size = rel(1.3)),
           axis.title = element_text(size = rel(1.3)),
           aspect.ratio = 1.4,
           plot.title = element_text(hjust = 0.7, size = rel(1.4))
     )

# Combine plots
grid <- plot_primary + plot_comparison + plot_secondary +
     plot_layout(ncol = 3, width = c(1, 0.6, 1)) +
     plot_annotation(theme = theme_economist(),
                     title = ""Student-to-Teacher Ratios in European Primary and Secondary Schools (2012-2017)"",
                     caption = ""Source: UNESCO
                     Visualization: @Frau_Dr_Barber"")

ggsave(""teacher_ratios.png"", dpi = ""retina"", height = 8, width = 15, units = ""in"")
","2019-19"
"380",792,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-05-14_nobel-winners.R","library(tidyverse)
library(ggalluvial)
library(paletteer)
library(cowplot)

# get dataset
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

# change historic countries to their modern day equivalents
nobel_winners_fixed <- nobel_winners %>% 
     filter(!is.na(birth_country), !is.na(death_country)) %>% 
     #364 winners are still alive and excluded from this visualization
     mutate(birth_country_modern = str_extract(birth_country, ""\\(([^()]*)\\)""),
            birth_country_modern = substr(birth_country_modern, 2, nchar(birth_country_modern)-1),
            death_country_modern = str_extract(death_country, ""\\(([^()]*)\\)""),
            death_country_modern = substr(death_country_modern, 2, nchar(death_country_modern)-1),
            birth_country = if_else(str_detect(birth_country, ""\\(""), birth_country_modern, birth_country),
            death_country = if_else(str_detect(death_country, ""\\(""), death_country_modern, death_country)
            ) %>%
     select(-birth_country_modern, -death_country_modern) %>%
     # assign Northern Ireland and Scotland to UK and abbrevaite UK and USA
     mutate(birth_country = str_replace_all(birth_country,
                                            c(""Northern Ireland"" = ""UK"",
                                            ""Scotland"" = ""UK"",
                                            ""United Kingdom"" = ""UK"",
                                            ""United States of America"" = ""USA"")),
            death_country = str_replace_all(death_country,
                                            c(""Northern Ireland"" = ""UK"",
                                              ""Scotland"" = ""UK"",
                                              ""United Kingdom"" = ""UK"",
                                              ""United States of America"" = ""USA""))
            ) %>%
     # condense countries to top 6 for less cluttered visualization
     mutate(birth_country = fct_lump(birth_country, 5),
            death_country = fct_lump(death_country, 5))

# time to plot
plot <- nobel_winners_fixed %>%
     filter(category %in% c(""Medicine"", ""Chemistry"", ""Physics"")) %>% 
     select(full_name, birth_country, death_country) %>%
     gather(birth_country, death_country, key = ""Event"", value = ""Country"") %>% 
     mutate(Event = str_replace_all(Event, c(""birth_country"" = ""Place of Birth"",
                                             ""death_country"" = ""Place of Death"")),
            Country = fct_infreq(Country)) %>%
     distinct() %>% 
     ggplot(aes(x = Event, stratum = Country, alluvium = full_name,
                fill = Country, label = Country, y = 1)) +
     geom_flow(alpha = 0.7) +
     geom_stratum(alpha = 0.8, size = 0) +
     geom_text(stat = ""stratum"", size = 4) +
     annotate(""text"", x = 1.75, y = -25, 
              label = ""(Laureates still alive excluded from analysis)"") +
     scale_x_discrete(expand = c(0.1, 0.1), position = ""top"") +
     scale_fill_paletteer_d(ggsci, light_uchicago) +
     labs(x = """", 
          y = ""Number of Nobel Laureates"",
          title = ""Mobility Among Nobel Laureates in the Sciences"",
          caption = ""Source: Kaggle
          Visualization @Frau_Dr_Barber"") +
     theme(
           plot.caption = element_text(size = 9),
           axis.line = element_blank(),
           axis.ticks = element_blank(),
           legend.position = ""none"",
           ) 

save_plot(""nobel.png"", plot, base_height = 4, base_width = 6)
","2019-20"
"381",793,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-05-27_wine-ratings.R","library(tidyverse)
library(ggridges)
library(ggthemes)

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

wine_color <- function(variety) {
     case_when(
          variety %in% c(""Riesling"", ""Pinot Gris"", ""Sauvignon Blanc"",
                         ""White Blend"", ""Sparkling Blend"", ""Portuguese White"",
                         ""Pinot Grigio"", ""Chardonnay"") ~ ""White"",
          variety %in% c(""Zinfandel"", ""Syrah"", ""Red Blend"", ""Portuguese Red"",
                         ""Bordeaux-style Red Blend"", ""Tempranillo"", ""Pinot Noir"",
                         ""Merlot"", ""Malbec"", ""Cabernet Sauvignon"") ~ ""Red"",
          variety == ""Ros"" ~ ""Ros""
     )
}

# best $20 wines by variety
p1 <- wine_ratings %>% 
     filter(price <= 20) %>%
     mutate(Color = wine_color(variety)) %>%
     add_count(variety) %>% 
     filter(n >= 700) %>% #remove wines with low numbers of reviews for less-cluttered graph
     ggplot(aes(points, fct_reorder(variety, points))) +
     stat_density_ridges(aes(fill = Color), quantile_lines = TRUE, quantiles = 2) +
     scale_fill_manual(values = c(""firebrick"", ""rosybrown2"", ""lightyellow"")) +
     xlim(81, 92) +
     labs(title = ""Best Wines under $20"",
          fill = """",
          caption = ""\nSource: Kaggle
     Visualization @Frau_Dr_Barber"") +
     theme_wsj(color = ""gray"") +
     theme(plot.title = element_text(hjust = 1),
           plot.caption = element_text(size = 10))

ggsave(""wine.png"", p1, dpi = ""retina"", height = 6, width = 5.5, units = ""in"")
","2019-21"
"382",794,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-06-03_ramen-ratings.R","library(tidyverse)
library(tidytext)
library(widyr)
library(igraph)
library(ggraph)

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

ramen_words <- ramen_ratings %>%
     unnest_tokens(word, variety) %>% 
     anti_join(stop_words, by = ""word"")

top_ramen_words <- ramen_words %>%
     count(word, sort = TRUE) %>%
     head(125)

ramen_words_correlation <- ramen_words %>%
     filter(word %in% top_ramen_words$word) %>% 
     pairwise_cor(word, review_number, sort = TRUE)

set.seed(13)
ramen_words_correlation %>%
     filter(correlation > 0.13) %>% 
     graph_from_data_frame() %>% 
     ggraph(layout = ""fr"") + 
     geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
     geom_node_point(color = ""#C3272B"", size = 3) +
     geom_node_text(aes(label = name), repel = TRUE) +
     labs(title = ""Co-occuring Words in Ramen Flavors"",
          subtitle = ""among the 125 most common words\n"",
          caption = ""\nSource: TheRamenRater.com
          Visualization @Frau_Dr_Barber"") +
     set_graph_style(family = ""Century Schoolbook"") +
     theme_void()+ 
     theme(text = element_text(family = ""Century Schoolbook""),
          plot.title = element_text(hjust = 0.5),
          plot.subtitle = element_text(hjust = 0.5),
          plot.margin = margin(0.25, 0.25, 0.25, 0.25, ""in"")) 

ggsave(""ramen.png"", dpi = 300, width = 7, height = 5, units = ""in"")
","2019-22"
"383",795,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-07-02_media-franchises.R","library(tidyverse)
library(ggthemes)
library(patchwork)

# load and clean datasets ----
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

#film revenue data from https://www.boxofficemojo.com/
hp_movie_revenue <- read_csv2(""hp_movie_revenue.csv"") %>%
     janitor::clean_names() %>% 
     mutate_at(vars(contains(""gross"")), parse_number) %>% 
     mutate(release = lubridate::mdy(release))

#book revenue from https://en.wikipedia.org/wiki/List_of_best-selling_books
hp_book_revenue <- read_csv2(""hp_book_revenue.csv"") %>% 
     janitor::clean_names()

# graphing ----
house_colors <- c(""#9c1203"", ""#FFC500"", ""#033807"", ""#00165e"", ""#000000"", ""#8A8F81"")

background <- ""#f8f2e4""

#overall revenue graph
overall <- media_franchises %>% 
     filter(str_detect(franchise, ""Harry Potter"")) %>% 
     distinct() %>% 
     mutate(revenue_category = fct_reorder(revenue_category, revenue)) %>% 
     ggplot(aes(revenue_category, revenue, fill = revenue_category)) +
     geom_col(show.legend = FALSE) +
     coord_flip() +
     scale_fill_manual(values = rev(house_colors)) +
     labs(x = """",
          y = ""Revenue\n(in billions)"",
          title = ""Overall"",
          caption = ""Source: Wikipedia"") +
     theme_classic() +
     theme(text = element_text(family = ""Garamond""),
           line = element_blank(),
           panel.background = element_rect(fill = background),
           panel.grid.major.x = element_line(color = ""black"", linetype = ""dotted""),
           axis.title.x = element_text(family = ""AbleNew"", size = rel(1.5)),
           axis.text.y = element_text(size = rel(1.7)),
           plot.title = element_text(family = ""AbleNew"", size = rel(2))
          )

#film revenue graph
film <- hp_movie_revenue %>%
     arrange(release) %>% 
     mutate(title = str_c(c(1:6, ""7a"", ""7b"", ""."", "".""), "". "", title),
            title = fct_reorder(title, release),
            adjusted_gross = adjusted_gross / 10^6) %>% 
     ggplot(aes(fct_rev(title), adjusted_gross)) +
     geom_col(fill = house_colors[1], show.legend = FALSE) + 
     coord_flip() +
     labs(x = """",
          y = ""Adjusted gross revenue\n(in millions)"",
          title = ""Film Revenue"",
          caption = ""Source: Box Office Mojo"") +
     theme_classic() +
     theme(text = element_text(family = ""Garamond""),
           line = element_blank(),
           panel.background = element_rect(fill = background),
           panel.grid.major.x = element_line(color = ""black"", linetype = ""dotted""),
           axis.title.x = element_text(family = ""AbleNew"", size = rel(1.5)),
           axis.text.y = element_text(size = rel(1.5)),
           plot.title = element_text(family = ""AbleNew"", size = rel(2))
     )

#book revenue graph
book <- hp_book_revenue %>% 
     mutate(book = str_c(1:7, "". "", book)) %>% 
     ggplot(aes(fct_rev(book), approximate_sales_million)) +
     geom_col(fill = house_colors[3], show.legend = FALSE) +
     coord_flip() +
     labs(x = """",
          y = ""Approximate sales\n(in millions)"",
          title = ""Books Sales"",
          caption = ""Source: Wikipedia"") +
     theme_classic() +
     theme(text = element_text(family = ""Garamond""),
           line = element_blank(),
           panel.background = element_rect(fill = background),
           panel.grid.major.x = element_line(color = ""black"", linetype = ""dotted""),
           axis.title.x = element_text(family = ""AbleNew"", size = rel(1.5)),
           axis.text.y = element_text(size = rel(1.5)),
           plot.title = element_text(family = ""AbleNew"", size = rel(2)),
           plot.margin = margin(0, 10, 0, 0, ""lines"")
     )

#title & caption
title <- ggplot(data.frame(x = 1, y = 1:10)) +
     labs(x = NULL, y = NULL,
          title = ""The Magical World of Harry Potter Revenue"",
          subtitle = ""The franchise has grossed an estimated 35 billion\nRevenue comes primarily from the box office, books, and merch\n""
          ) +
     theme(line = element_blank(),
           rect = element_rect(fill = ""transparent""),
           plot.title = element_text(family = ""Harry P"", size = rel(6)),
           plot.subtitle = element_text(family = ""AbleNew"", size = rel(2.1)),
           panel.background = element_rect(fill = ""transparent""),
           plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
           panel.border = element_rect(color = ""transparent""),
           axis.text = element_blank())

caption <- ggplot(data.frame(x = 1, y = 1:10)) +
     labs(x = NULL, y = NULL,
          caption = ""Visualization by Frau_Dr_Barber\n(Slytherin House)"") +
     theme(line = element_blank(),
           rect = element_rect(fill = ""transparent""),
           plot.caption = element_text(family = ""AbleNew"", size = rel(1.2)),
           panel.background = element_rect(fill = ""transparent""),
           plot.background = element_rect(fill = ""transparent"", color = ""transparent""),
           panel.border = element_rect(color = ""transparent""),
           axis.text = element_blank())

#combine plots using patchwork
title + 
     (overall + film + book + plot_layout(widths = c(0.95, 0.75, 0.75))) + 
     caption +
     plot_layout(nrow = 3, heights = c(0, 20, 0)) +
     plot_annotation(theme = theme_wsj())

ggsave(""harry_potter.png"", height = 7.5, width = 18, units = ""in"")
","2019-27"
"384",796,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-07-09_womens-world-cup.R","library(tidyverse)
library(paletteer)

wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
logo <- png::readPNG(""uswnt.png"")
logo <- grid::rasterGrob(logo, interpolate = TRUE) 
usa_blue <- ""#1D2642""
usa_red <- ""#BB222E""
grey_palette <- paletteer_dynamic(""cartography"", ""grey.pal"", 17, direction = 1)
grey_palette <- grey_palette[1:11]

wwc_outcomes %>%
     mutate(
          place = case_when( #assign revere place order for graphing
               round == ""Final"" & win_status == ""Won"" ~ 5,
               round == ""Final"" & win_status == ""Lost"" ~ 4,
               round == ""Third Place Playoff"" & win_status == ""Won"" ~ 3,
               round == ""Third Place Playoff""& win_status == ""Lost"" ~ 2,
               round == ""Quarter Final"" & win_status == ""Lost"" ~ 1
          )
     ) %>%
     filter(!is.na(place)) %>%
     mutate(highlight = if_else(team == ""USA"", ""yes"", ""no"")) %>% 
     ggplot(aes(year, place, group = team)) +
     annotation_custom(logo, xmin = 2003, xmax = 2007, ymin = 3.95, ymax = 4.95) +
     geom_line(aes(color = team), size = 1) +
     geom_point(aes(color = team), size = 6) +
     labs(x = ""World Cup"",
          y = """",
          title = ""\nThe US Women's Team is the Winningest Team\nin World Cup History"",
          subtitle = ""The women's team is more successful and brings in more revenue than the men's team, 
          yet they are paid significantly less - around 38% of what the men make."",
          caption = ""Source: data.world
          Visualization: Frau_Dr_Barber""
     ) +
     geom_text(data = . %>% filter(year == 2019, place > 1), 
               aes(label = team, x = 2021, family = ""Roboto Condensed"")) +
     scale_x_continuous(breaks = c(1991, 1995, 1999, 2003, 2007, 2011, 2015, 2019),
                        expand = c(.05, .05)) +
     scale_y_continuous(labels = c(""5th-8th\n(Quarter Finals)"",
                                   ""4th"", ""3rd"", ""2nd"", ""1st"")) +
     scale_color_manual(values = c(sample(grey_palette, 17, replace = TRUE), usa_red)) +
     theme_minimal() +
     theme(legend.position = ""none"",
           panel.grid.major.y = element_blank(),
           panel.grid.minor = element_blank(),
           text = element_text(color = usa_blue, family = ""Roboto Condensed""),
           axis.text.x = element_text(size = 14),
           axis.text.y = element_text(size = 14),
           axis.title.x = element_text(size = 14),
           plot.title = element_text(size = 18, face = ""bold""),
           plot.margin = margin(0, 1, 0, 0, unit = ""cm""))

ggsave(""wwc.png"")
","2019-28"
"385",797,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-08-30_simpsons-guest-stars.Rmd","---
title: 'Tidy Tuesday: Simpsons Guest Stars'
date: '2019-08-30'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


```{r load packages, get data}
library(tidyverse)
library(cowplot)

simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")
```


```{r names to graph}
top_stars <- simpsons %>% 
    count(guest_star, name = ""total_n"", sort = TRUE) %>% 
    head(8) 
```


```{r plot extras, echo=FALSE}
simpsons_palette <- c(
    ""#FC0209"", # bart red
    ""#fed90f"", # simpsons yellow
    ""#46732EFF"", # Flanders green 
    ""#0363C3"", # marge blue
    ""#d1b271"", # lightbrownbeige
    ""#7A491E"", # beige 
    ""#000000"",  # black
    ""#424f46""  # greyish-blue
)

# quick but messy (manual) way to get the axis labels how I want
x_labels <- c("""", ""S1"", """", """", """", ""S5"", """", """", """", """",
              ""S10"", """", """", """", """", ""S15"", """", """", """", """",
              ""S20"", """", """", """", """", ""S25"", """", """", """", """", ""S30"",
              """", """", """", """")

y_labels <- c(""Marcia Wallace\n(Edna Krabappel)"", 
              ""Phil Hartman\n(Troy McClure & Others)"",
              ""Joe Mantegna\n(Fat Tony)"",
              ""Maurice LaMache\n(Various Roles)"",
              ""Kelsey Grammer\n(Sideshow Bob)"", 
              ""Frank Welker\n(Various Roles)"",
              ""Jon Lovitz\n(Various Roles)"",
              ""Kevin Michael Richardson\n(Various Roles)"")
```


```{r final plot, fig.width=8, fig.height=5}
simpsons %>%
    count(season, guest_star) %>%
    inner_join(top_stars, by = ""guest_star"") %>% 
    filter(season != ""Movie"") %>% # editorial choice; its not a season
    mutate(guest_star = fct_reorder(guest_star, total_n),
           season = fct_inseq(season)) %>% 
    ggplot(aes(season, guest_star, label = total_n)) +
    geom_point(aes(fill = guest_star, size = n), shape = 23, show.legend = FALSE) +
    geom_text(data = . %>% distinct(guest_star, total_n) %>% arrange(desc(total_n)),
              aes(x = 33.5, y = 8:1, label = total_n), family = ""Akbar"",
              size = 4, hjust = 0.5) +
    annotate(""text"", x = 33.5, y = 8.5, label = ""# epi"", family = ""Akbar"", 
             hjust = 0.5, size = 4) +
    scale_size(range = c(3, 8)) +
    scale_x_discrete(position = ""top"", limits = 0:34, labels = x_labels) +
    scale_y_discrete(labels = rev(y_labels)) +
    labs(x = NULL, y = NULL,
         title = ""The Most Frequent Simpsons Guest Stars by Season"",
         caption = ""source: Wikipedia
         Visualization @Frau_Dr_Barber""
         ) +
    scale_fill_manual(values = rev(simpsons_palette)) +
    theme_minimal_grid(font_family = ""Akbar"") +
    theme(plot.title.position = ""plot"") #low this new feature of ggplot
```
","2019-35"
"386",798,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-09-17_National-park-visits.R","library(tidyverse)

# get data
park_visits <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-17/national_parks.csv"")
centroids <- read_csv(""~/Downloads/National_Park_Service__Park_Unit_Centroids.csv"") %>% 
    rename_all(tolower) %>% #downloaded from https://public-nps.opendata.arcgis.com/datasets/national-park-service-park-unit-centroids
    mutate(label = str_extract(unit_name, ""^.*(?=(National Park))""))
usa_df <- map_data(""state"")

# calculate average visits per year for last 10 years
ave_visits <- park_visits %>%
    mutate(year = parse_integer(year)) %>% 
    filter(year >= 2006, unit_type == ""National Park"") %>%
    group_by(unit_code) %>% 
    summarise(ave_visit = mean(visitors, na.rm = TRUE)) %>% 
    ungroup() 

# graph
centroids %>% 
    left_join(ave_visits) %>%
    filter(!state %in% c(""AK"", ""HI"")) %>% 
    ggplot(aes(x, y)) +
    geom_polygon(data = usa_df, aes(long, lat, group = group),
                 fill = ""white"", color = ""#99542c"", size = 0.25) +
    geom_point(aes(size = ave_visit), color = ""#2d4b1e"") +
    ggrepel::geom_text_repel(data = . %>% filter(!unit_code %in% c(""GRSM"", ""DRTO"", ""VIIS"")),
                             aes(label = label), family = ""National Park"", size = 2.1) +
    coord_map(xlim = c(-123, -69.5), ylim = c(25, 48.1)) +
    scale_size_area(""Average annual visits"", breaks = c(1e+7, 3e+7, 5e+7),
                    labels = c(""10 million"", ""30 million"", ""50 million"")) +
    annotate(""text"", x = -77, y = 30, size = 4, hjust = 0,
             family = ""National Park"", color = ""white"",
             label = glue::glue(""Great Smoky
                        Mountains NP
                        sees the most
                        visitors annually"")
    ) +
    annotate(""segment"", xend = -81.75, yend = 35.3, x = -75, y = 33.75,
             arrow = arrow(length = unit(0.03, ""npc"")),
             color = ""#2d4b1e"", size = 0.5) +
    labs(title = ""The United States National Parks"",
         subtitle = ""Point size corresponds to average number of visitors (2006-2016)"") +
    # National Park font downloaded from https://nationalparktypeface.com/
    cowplot::theme_map(font_size = 16, rel_tiny = 0.75,
                       font_family = ""National Park"") + 
    theme(text = element_text(color = ""white""),
          legend.position = ""bottom"",
          legend.justification = ""center"",
          plot.background = element_rect(fill = ""#99542c"")
    ) 

ggsave(""national_parks.png"", width = 7, height = 5)
","2019-38"
"387",799,"https://github.com/ameliabedelia/tidy_tuesday","ameliabedelia","tidy_tuesday","code/2019-11-05_commuting.R","library(tidyverse)
library(cowplot)
library(glue)

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

commute_mode %>%
    filter(mode == ""Bike"", !is.na(state_region)) %>%
    mutate(
        fraction = percent / 100,
        city_size = glue::glue(""{city_size}
                               cities""),
        state_region = fct_reorder(state_region, fraction)
    ) %>% 
    ggplot(aes(city_size, fraction)) +
    geom_boxplot(aes(fill = city_size), notch = TRUE, outlier.size = 1,
                 color = ""white"", show.legend = FALSE) +
    scale_y_continuous(trans = ""log10"",
                       labels = scales::percent) +
    facet_wrap(vars(fct_rev(state_region)), nrow = 1) +
    labs(x = """", y = NULL,
         title = ""Nobody Bikes to Work in the US - less than 1%!"",
         subtitle = ""More people cycle to work in bigger cities and in the western US. Ridership is equally low throughout the south."",
         caption = glue::glue(""Source: ACS - US Census
                              Visualization @frau_dr_barber"")) +
    cowplot::theme_minimal_hgrid(font_family = ""Roboto Condensed"",
                                 rel_tiny = 10/14) +
    cowplot::panel_border() +
    scale_fill_manual(values = c(""#81A7A6"", ""#5F799C"", ""#374685"")) +
    theme(plot.background = element_rect(fill = ""grey23""),
          axis.text = element_text(color = ""grey85""),
          text = element_text(color = ""white""))

ggsave(here::here(""plots"", ""bike_commuting.png""))
","2019-45"
"388",801,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-08-06","jas1","tidytuesday","jas1_weeks/2019/2019-08-06/readme.rmd","
---
title: ""Tidy tuesday challenge: Week 2019-08-06 Bob Ross""
author: ""julio""
date: ""2019-08-04""
output: html_document
---

# Tidy tuesday challenge:  Week 2019-08-06 Bob Ross

keep it simple:

## Objectives: 

**general:**

* work on data, 
* practice, 
* get better on your workflow,
* get better on your skills: import, tidy , understand( transform, visualize,model ) , communicate


** this week **

### Data:
 
 Week 2019-08-06 Bob Ross
 
### objectives:

Seen voronoi & brickr stuff, really liked it.

AI art its quite interesting , nevertheless got short time to invest.

initial some data explore, and last the voronoi.

## details:


## import data
```{r echo=FALSE,message=FALSE,warning=FALSE}
library(magrittr) # para el %T>%
library(tidyverse)
# library(sf)
library(dplyr)
library(stringr)#;
# library(rebus)#; install.packages('rebus')
# library(tidytext)
library(prophet)


# install.packages(""Rcpp"")
# remotes::install_github(""tylermorganwall/rayshader"")
# library(rayshader)
library(lubridate)
library(ggforce)
library(ggrepel)

library(arules)#install.packages('arules')
library(arulesViz)#install.packages('arulesViz')
library(igraph)

```


```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")
bob_ross_processed <- bob_ross %>% 
    janitor::clean_names() %>% 
    mutate(title=str_remove_all(title,'""'))
```

# explore data


```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed %>% head()

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed %>% glimpse()

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed %>% skimr::skim()


```

we can see that we got a lot with "" tree "" a nd another column "" trees"" they might be the same stuff. 
lets check.

```{r echo=FALSE,message=FALSE,warning=FALSE}
bob_ross_processed_trees <- bob_ross_processed %>% 
    mutate(id=paste0(episode,title)) %>% 
    select(id,tree,trees) %>% filter(trees==1 | tree == 1)

bob_ross_processed_trees %>% select(tree,trees) %>% table()

bob_ross_processed_trees %>% filter(trees==0)
bob_ross_processed_trees %>% filter(trees==1)

```

after looking at data, we see there is no tree alone, 
when tree exist, might or might not be with a group of them.

then decided to doble check at the internet to see the images. 
to my criteria there are some ""TREES==0"" that are not that way.
ex: WINTER CABIN ; WESTERN EXPANSE, etc

also ""TREE"" alone, do not exist., so ill be droping ""TREES"", and keep tree
or ... or can keep the focus on this difference as it took a while :p 


# elements thogether >> association rules :D 

as we need to see the problem as transactions
we can see every paint as a transaction, and every element as a item. 
the collection of elements its the itemset of the transaction

ive done this before and will be cool to explore this on an unknown subject :)

based on previous work and other references: 

- https://twitter.com/jspairani/status/1083717747173928960
- https://michael.hahsler.net/research/arules_RUG_2015/demo/#association-rules
- https://www.datacamp.com/community/tutorials/market-basket-analysis-r
- https://stackoverflow.com/questions/44677670/exporting-a-network-produced-with-visnetwork-for-r

first we need to make the transactions object 

```{r echo=FALSE,message=FALSE,warning=FALSE}
elements_picture <- bob_ross_processed %>%  
    tibble::rownames_to_column() %>% # to get transactions id's
    mutate(rowname=as.integer(rowname)) %>% 
    rename(r_id=rowname) %>% 
    gather(element,appear,-episode,-title,-r_id) %>% 
    filter(appear==1)




transactions <- elements_picture %>% select(r_id,element) %>% arrange(r_id) %>% rename(itemset=element)
# elements_picture_graph_data <- elements_picture %>% select(TITLE,ELEMENT)

data_file <- here::here(""jas1_weeks"",""2019"",""2019-08-06"",""tx_file.txt"")
write.csv(transactions,file = data_file,row.names=FALSE,fileEncoding = ""UTF-8"")

tx <- read.transactions(data_file ,
                        format = ""single"",
                        sep = "","",
                        cols = c(""r_id"", ""itemset""),
                        rm.duplicates = TRUE)

# transactions %>% distinct(itemset)

```

after getting the transactions loaded, want to make default package item frequency plot but as ggplot.

```{r echo=FALSE,message=FALSE,warning=FALSE}

# summary(tx)
# itemFrequencyPlot(tx,topN=20,type=""absolute"")
# itemFrequencyPlot(tx,topN=20,type=""relative"")

item_freq <- tx %>% itemFrequency()
item_freq_names <- item_freq %>% names()
tx_for_plot <- data.frame(element=item_freq_names,freq=item_freq,stringsAsFactors = FALSE) %>%
    as_tibble() %>%
    mutate(element=fct_reorder(element,freq))
    
set.seed(42)
freq_elements_plot <- tx_for_plot %>% 
ggplot(aes(element,freq,fill=element)) + 
geom_col() + 
scale_y_continuous(breaks = seq(0,1,0.25))+
theme_light()+
theme(legend.position = ""none"")+
coord_flip()+
    labs(title=""Frequency of Elements of Bob Ross paintings"",
         # subtitle="""",
         x="""",
         y=""frequency"",
         caption = ""#TidyTuesday""
         )
freq_elements_plot
ggsave(freq_elements_plot,filename = ""freq_elements_plot.png"",height = 8,width = 6)
```

## items as absolute values

```{r echo=FALSE,message=FALSE,warning=FALSE}

# summary(tx)
# itemFrequencyPlot(tx,topN=20,type=""absolute"")
# itemFrequencyPlot(tx,topN=20,type=""relative"")

item_freq_count <- tx %>% itemFrequency(type=""absolute"")
item_freq_names_count <- item_freq_count %>% names()
tx_for_plot_count <- data.frame(element=item_freq_names,count=item_freq_count,stringsAsFactors = FALSE) %>%
    as_tibble() %>%
    mutate(element=fct_reorder(element,count))
    
set.seed(42)
freq_elements_plot_count <- tx_for_plot_count %>% 
ggplot(aes(element,count,fill=element)) + 
geom_col() + 
scale_y_continuous(breaks = seq(0,375,25))+
theme_light()+
theme(legend.position = ""none"",
      axis.text.x=element_text(angle=90))+
coord_flip()+
    labs(title=""Count of Elements of Bob Ross paintings"",
         #subtitle="""",
         x="""",
         y="""",
         caption = ""#TidyTuesday""
         )
freq_elements_plot_count
ggsave(freq_elements_plot_count,
       filename = ""freq_elements_plot_count.png"",
       height = 8,width = 5)
```

# association rules rules

```{r echo=FALSE,message=FALSE,warning=FALSE}

rules <- apriori(tx,
             parameter=list(supp=0.01,
                            conf=0.8,
                            maxlen=10))

subset_rules <- which(colSums(is.subset(rules, rules)) > 1)
length(subset_rules)
no_redundant_rules <- rules[-subset_rules] # remove subset rules.
length(no_redundant_rules)
# rules

 # inspect(sort(rules))

# inspect(head(sort(rules), n=10))
#


# plot(head(sort(rules, by = ""lift""), n=50),
#      method = ""graph"",
#      control=list(cex=.8))
# 

element_visnet <- plot(head(sort(no_redundant_rules, by = ""lift""), n=50),
     method = ""graph"",
     engine=""htmlwidget"",
     control=list(cex=.8))

element_visnet %>% 
    visNetwork::visSave( file = ""bob_ross_rules.html"")
# visNetwork::visExport(type = ""png"", name = ""network"",
#   label = paste0(""Export as png""), background = ""#fff"",
#   float = ""right"", style = NULL, loadDependencies = TRUE)


```


# tried some graph stuff till i remembered arules :D

```{r echo=FALSE,message=FALSE,warning=FALSE}

# graph_from_picture <- igraph::graph_from_data_frame(elements_picture_graph_data) %>% as_tbl_graph()
# igraph::V(graph_from_picture)$type <- igraph::V(graph_from_picture)$name == elements_picture_graph_data$TITLE
# igraph::V(graph_from_picture)$color <- if_else(igraph::V(graph_from_picture)$type == 1,""#FF0000"",""#0000FF"")
# 
# 
# # visNetwork::visIgraph(igraph_network)
# visNetwork::visIgraph(graph_from_picture) %>% 
#     visNetwork::visIgraphLayout(randomSeed = 42, layout=""layout_as_bipartite"")
# 
# 
# 
#     ggplot(aes(x=TITLE,y=element,fill=as.factor(appear)))+
#     geom_tile()+
#     theme(axis.text.x = element_text(angle=90))
    # labs()
```

## bob ross voronoi

code from: https://github.com/othomantegazza/code-tidytuesday/blob/master/2-32-painting-voronoi.R
he inspired on: https://chichacha.netlify.com/2018/11/12/utilizing-k-means-to-extract-colours-from-your-favourite-images/

wanted to do this at least once, so here to pick a picture: 
i like auroras ... so lets look some samples on google

i didnt like them much, there are better ones :D 

```{r}
bob_ross_processed %>% filter(fire==1)
```



```{r echo=FALSE,message=FALSE,warning=FALSE}
#https://github.com/othomantegazza/code-tidytuesday/blob/master/2-32-painting-voronoi.R
# Most steps are taken form:
# https://chichacha.netlify.com/2018/11/12/utilizing-k-means-to-extract-colours-from-your-favourite-images/


# set up ------------------------------------------------------------------


library(tidyverse)
library(imager)
library(ggvoronoi) # install.packages(""ggvoronoi"")
library(grid)

# background color
bg_color <- ""#E8EDEF""

# Get image ---------------------------------------------------------------

image_path <- ""2-32-bob-ross-sunset.Rdata""


if(!file.exists(image_path)) {
  # img <- load.image(""https://fivethirtyeight.com/wp-content/uploads/2014/04/campfire_banner1.jpg"")
  img <- load.image(""campfire_banner1.jpg"")
  save(img, file = image_path)
} else {
  load(image_path)
}


# analyze -----------------------------------------------------------------

# number of pixel?
dim(img)[1]*dim(img)[2]

# colours: hex value for every pixel
hex_pix <- 
  img  %>% 
  as.data.frame(wide = ""c"") %>% 
  mutate(hexval = rgb(c.1,c.2,c.3))

# luminosity for every pixes
grey_pix <- 
  img %>% 
  grayscale() %>% 
  as.data.frame()

# merge
hex_pix <- 
  hex_pix %>%
  inner_join(grey_pix)


# sample pixels ------------------------------------------------------------

set.seed(42); hex_pix_mini <- 
  hex_pix %>% 
  sample_n(2500, weight = value) # more likely if luminosity is higher 
  
# colors named vectors
# for plotting
pix_colors <- 
  hex_pix_mini %>% 
  pull(hexval) %>% 
  {purrr::set_names(x = .,
                   nm = .)}

# range of axis
range_x <- c(0, dim(img)[1])
range_y <-  c(dim(img)[2], 0)

p <- 
  hex_pix_mini %>% 
  ggplot(aes(x = x,
             y = y)) +
  # geom_point(aes(colour = hexvalue)) +
  ggvoronoi::geom_voronoi(aes(fill = hexval),
                          colour = bg_color,
                          size = .2) +
  scale_y_reverse(limits = range_y,
                  expand = expand_scale(mult = .01)) +
  scale_x_continuous(limits = range_x,
                     expand = expand_scale(mult = .01)) +
  scale_fill_manual(values = pix_colors, guide = FALSE) +
  coord_fixed() +
  theme_void() +
  theme(plot.background = element_rect(fill = bg_color),
        plot.margin = margin(0,0,0,0)) +
    labs(title = ""Voronoi test on: S03E10 - CAMPFIRE"",
         subtitle = ""Bob Ross paint , voronoi code by @othomn, @chisatini"",
         caption = ""#TidyTuesday"")

# svglite::svglite(file = ""plots/2-32-painting-voronoi.svg"")
# p %>% print()
# dev.off()
ggsave(plot = p ,filename = ""voronoi_2.png"")


# decorate plot with grid and save ----------------------------------------
# 
# # png parameters
# img_height <- 2800
# img_width <- 2300
# 
# # position of bottom left corner
# img_x <- .2
# img_y <- .18
# 
# # and plot size
# plot_width <- 1 - img_x - .05
# plot_height <- 1 - img_y - .05
# 
# # save
# png(file = ""2-32-painting-voronoi.png"",
#     height = img_height,
#     width = img_width,
#     res = 300)
# grid.newpage()
# # background
# grid.rect(gp = gpar(fill = ""#838798""))
# # plot
# p %>% print(vp = viewport(x = img_x, y = img_y, 
#                           just = c(0, 0),
#                           height = plot_height,
#                           width = plot_width))
# # side caption
# grid.text(label = str_wrap(""Voronoi tesselation of one of Bob Ross paintigs. Inspired by @chisatini's blog."",
#                            width = 14),
#           x = img_x - .003, y = .945,
#           hjust = 1, vjust = 1, gp = gpar(size = 14, lineheight = 1,
#                                           col = bg_color))
# # signature
# grid.text(label = ""Painting by Bob Ross | Plot by @othomn"",
#           x = .92, y = .1,
#           hjust = 1, vjust = 1, gp = gpar(fontsize = 10, lineheight = 1,
#                                           col = bg_color))
# dev.off()
# 
# 
# # save json for d3 --------------------------------------------------------
# 
# library(jsonlite)
# 
# hex_pix_mini %>% 
#   toJSON() %>%
#   {paste(""var hexpix = "", .)} %>% 
#   cat(file = ""d3/json_data/2-32-painting-voronoi.js"")

```


#tweet: 

2019-08-13 #TidyTuesday #rstats Roman Emperors ! 
Explored time spans of roman emperors. Some birth dates were NA, so imputed somes values based on wikipedia aproximated dates. The ones imputed are commented.
img & code: https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-08-13



# communicate

other stuff that was not on the plot is: 
got the max date of dynasties and eras.

## resources: 

- wikipedia for emperor missing dates.
","2019-32"
"389",836,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-07-02","jas1","tidytuesday","jas1_weeks/2019/2019-07-02/readme.rmd","
---
title: ""Tidy tuesday challenge: Week 2019-07-02 Media Franchise revenues""
author: ""julio""
date: ""2019-06-25""
output: html_document
---

# Tidy tuesday challenge: Week 2019-07-02 Media Franchise revenues

keep it simple:

## Objectives: 

**general:**

* work on data, 
* practice, 
* get better on your workflow,
* get better on your skills: import, tidy , understand( transform, visualize,model ) , communicate


** this week **

### Data:

Media Franchise revenues

### objectives:

check the data and do something.

## details:


## import data
```{r echo=FALSE,message=FALSE,warning=FALSE}
library(magrittr) # para el %T>%
library(tidyverse)
# library(sf)
library(dplyr)
library(stringr)#;
library(rebus)#; install.packages('rebus')
library(tidytext)

# install.packages(""Rcpp"")
# remotes::install_github(""tylermorganwall/rayshader"")
library(rayshader)


```


```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")
```

# explore data


```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises %>% head()

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
glimpse(media_franchises)

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises %>% skimr::skim()

```



```{r echo=FALSE,message=FALSE,warning=FALSE}
media_franchises %>% 
    count(creators,owners) %>%
    mutate(creators=fct_reorder(creators,n)) %>% 
    ggplot(aes(x=creators,y=n,fill=owners))+
    geom_col()+
    coord_flip()+
    theme(legend.position = ""none"")

media_franchises %>% 
    count(owners) %>%
    mutate(creators=fct_reorder(owners,n)) %>% 
    ggplot(aes(x=owners,y=n,fill=owners))+
    geom_col()+
    coord_flip()+
    theme(legend.position = ""none"")

media_franchises %>% 
    mutate(year_origin=lubridate::ymd(paste0(year_created,""-01-01""))) %>%
    mutate(year_now=lubridate::ymd(paste0(lubridate::year(lubridate::today()),""-01-01""))) %>% 
    mutate(years_elapsed=lubridate::year(year_now)-lubridate::year(year_origin)) %>% 
    mutate(revenue_years=revenue/years_elapsed*1000) %>% 
    ggplot(aes(x=years_elapsed,
               y=revenue,color=revenue_category))+
    geom_point()

media_franchises %>% 
    mutate(year_origin=lubridate::ymd(paste0(year_created,""-01-01""))) %>%
    mutate(year_now=lubridate::ymd(paste0(lubridate::year(lubridate::today()),""-01-01""))) %>% 
    mutate(years_elapsed=lubridate::year(year_now)-lubridate::year(year_origin)) %>% 
    mutate(revenue_years=revenue/years_elapsed*1000) %>% 
    ggplot(aes(x=years_elapsed,
               y=revenue_years,color=revenue_category))+
    geom_point()
```


```{r echo=FALSE,message=FALSE,warning=FALSE}



data_processed <- media_franchises %>% 
    group_by(franchise) %>% 
    summarise(year_created_min=min(year_created),total_revenue=sum(revenue)) %>% 
    mutate(year_origin=lubridate::ymd(paste0(year_created_min,""-01-01""))) %>%
    mutate(year_now=lubridate::ymd(paste0(lubridate::year(lubridate::today()),""-01-01""))) %>% 
    mutate(years_elapsed=lubridate::year(year_now)-lubridate::year(year_origin)) %>% 
    mutate(revenue_years=total_revenue/years_elapsed*1000) %>% 
    mutate(franchise=fct_reorder(franchise,years_elapsed))
```


```{r echo=FALSE,message=FALSE,warning=FALSE}
background_diff <- ""#bad8df""

plot_out <- data_processed %>%            
    ggplot(aes(x=year_now-(years_elapsed/2),
               y=franchise,
               color=franchise))+
    # geom_col()+
    geom_errorbarh(aes(xmin = year_origin, 
                       xmax = year_now), 
                  size = .5, alpha = 0.8)+
    scale_x_date(date_breaks = ""5 years"",date_labels = ""%Y"")+
    # coord_flip()+
    theme_light()+
    theme(legend.position = ""none"",
          axis.text.x = element_text(angle=90))+
    labs(title=""Which Franchises are longer living?"",
         x="""",y="""",caption=""#tidytuesday"")+
    
    geom_vline(xintercept = lubridate::ymd(c(""1920-01-01"",
                                             ""1930-01-01"",
                                             ""1940-01-01"",
                                             ""1950-01-01"",
                                             ""1960-01-01"",
                                             ""1970-01-01"",
                                             ""1980-01-01"",
                                             ""1990-01-01"",
                                             ""2000-01-01"",
                                             ""2010-01-01"",
                                             ""2020-01-01"")),
               linetype='dashed')+ 
  # Expand y axis scale so that the legend can fit
  scale_y_discrete(
    expand = expand_scale(add=c(0.65,1))
  )     +
    
# rectangle with years.
    geom_rect(
    mapping = aes(xmin = lubridate::ymd(""2022-01-01""), xmax = lubridate::ymd(""2026-01-01"") , 
                  ymin = -Inf, ymax = Inf),
    fill = ""white"",
    color = ""white""
  ) +
  # Add rectangle with correct banground color for the differences
  geom_rect(
    mapping = aes(xmin = lubridate::ymd(""2022-01-01""), xmax = lubridate::ymd(""2026-01-01"") , 
                  ymin = -Inf, ymax = Inf),
    fill = background_diff,
    color = background_diff
  ) +
  # Add Differences values
  geom_text(
    # Bold face
    fontface = ""bold"",
    # Font size
    size = 4,
    # Font Color
    colour = ""black"",
    # Position
    mapping = 
      aes(
        x = lubridate::ymd(""2024-05-01""),
        y = franchise,
        label = years_elapsed
      )
  ) +
  # Insert Title of Differences
  geom_text(
    # Bold face
    fontface = ""bold"",
    # Font size
    size = 4,
    # Cor
    colour = ""#333333"",
    # Set text a little above the dots
    nudge_y = 2,
    # Position
    mapping = 
      aes(
        x = lubridate::ymd(""2024-01-01""),
        y = franchise,
        label = 
          # If Country is Germany, plot values
          ifelse(str_detect(franchise,""Winnie""),
                 # Value_if_True
                 ""Years"",
                 #Value_if_False
                 """"
          )
      )
  )

plot_out

ggsave(filename = ""franchise_ages.png"",plot = plot_out,height = 20,width = 10)

```


#tweet: 

2019-07-02 #TidyTuesday #rstats media franchises! 
Explored which are the longer living media franchises.


# communicate

well almost there, some errors on the years elapsed label :/.

credit of the bar to: 

https://ogustavo.com/post/dotplot-ggplot/





","2019-27"
"390",837,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-02-26","jas1","tidytuesday","jas1_weeks/2019/2019-02-26/readme.rmd","---
title: ""Tidy tuesday challenge: Week 2019-02-26 french train delays""
author: ""julio""
date: ""2019-03-03""
output: html_document
---

# Tidy tuesday challenge: Week 2019-02-26 french train delays

keep it simple:

## Objectives: 

**general:**

* work on data, 
* practice, 
* get better on your workflow,
* get better on your skills: import, tidy , understand( transform, visualize,model ) , communicate


** this week **

### Data:

this week data its related to PhDs Awarded by Field

### objectives:

- issues on git syhcroing.
- just went to a graph visualization. showing how are linked from/to , and if its tgv as color.

## details:

- selected small trains dataset

## import data

```{r echo=FALSE,message=FALSE,warning=FALSE}
library(dplyr)
# library(Rcpp) #; install.packages(""Rcpp"")
library(skimr) #; install.packages(""skimr"")
# library(circlepackeR) #; devtools::install_github(""jeromefroe/circlepackeR"")
# library(data.tree)  #; install.packages(""data.tree"")

library(igraph)
library(visNetwork)
library(ggplot2)

```



```{r echo=FALSE,message=FALSE,warning=FALSE}
small_trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/small_trains.csv"") 

color_palette <- c(""blue"",""green"",""red"")
uniques_graph <- small_trains %>%    
        rename(from=departure_station) %>%
        rename(to=arrival_station) %>% 
        group_by(from,to) %>% 
        summarize(total_delay=sum(avg_delay_all_departing+avg_delay_all_arriving)) %>% 
        # mutate(is_tgv=str_detect(from,""TGV"")|str_detect(to,""TGV"")) %>% 
        # mutate(color=if_else(is_tgv,'red','blue')) %>%
        mutate(intervals=if_else(total_delay<=2000,""0-2k"",
                                 if_else(total_delay>4000,"">4k"",""2k1-4k""))) %>% 
        mutate(color=case_when (
            total_delay<=2000 ~ color_palette[1],
            total_delay>4000 ~ color_palette[3],
            total_delay>2000 & total_delay<=4000 ~ color_palette[2]))
        


hist(uniques_graph$total_delay)
boxplot(uniques_graph$total_delay)

```


```{r echo=FALSE,message=FALSE,warning=FALSE}
glimpse(small_trains) 


small_trains %>% 
    count(service)

```

```{r echo=FALSE,message=FALSE,warning=FALSE}
skimr::skim(phd_raw) 


```

## tidy

always wante to try circle pack, so there we go: prepare data: deprecated -- shifted to the shiny app of the guy as i wan to have a functional deployable that i can give other people.
not just my pc.

```{r echo=FALSE,message=FALSE,warning=FALSE}
# library(circlepackeR) #; devtools::install_github(""jeromefroe/circlepackeR"")
# 
# phd_processed <- phd_raw %>% filter(year==2008) %>% select(-year) %>%  
#         mutate(path_string = paste(""phds"", broad_field, major_field, field, sep = ""/""))
# # sample: http://shiny.rstudio.com/gallery/submitbutton-demo.html
# # UI
# 
# # library(data.tree)
# # phd_processed_circler <- data.tree::as.Node(phd_processed)
# 
# 
# phd_processed %>% count(field) %>%  filter(n>1)
# 
# phd_processed %>% filter(field==""Environmental toxicologyc"")
# 
# circlepackeR::circlepackeR(phd_raw)
# 
# 
# 
# phd_processed2 <- phd_raw %>% filter(year==2008) %>% select(-year) %>% 
#     mutate(from=) %>% mutate( to="""")
# 
# 
# # Libraries
# library(ggraph)
# library(igraph)
# library(tidyverse)
# library(viridis)
#  
# # We need a data frame giving a hierarchical structure. Let's consider the flare dataset:
# edges=flare$edges
# vertices = flare$vertices
# mygraph <- graph_from_data_frame( edges, vertices=vertices )
#  
# # Control the size of each circle: (use the size column of the vertices data frame)
# # png(""~/Dropbox/R_GG/R_GRAPH/#314_custom_circle_packing1.png"", height = 480, width=480)
# ggraph(mygraph, layout = 'circlepack', weight=""size"") + 
#   geom_node_circle() +
#   theme_void()


```

## visualize

as i want interactive for the shiny app im using package: circlepackeR: canceled.
using the guy shiny app as ive made some stuff with that library before should not be complex.

```{r echo=FALSE,message=FALSE,warning=FALSE}
# library(circlepackeR)
# library(data.tree)
# library(treemap)#;install.packages(""treemap""); install.packages(""httpuv""); install.packages(""mime"")
# 
# data(GNI2014)
# head(GNI2014)
# 
# GNI2014$pathString <- paste(""world"", 
#                             GNI2014$continent, 
#                             GNI2014$country, 
#                             sep = ""/"")
# population <- as.Node(GNI2014)
# 
# circlepackeR(population, size = ""population"", color_min = ""hsl(56,80%,80%)"", 
#              color_max = ""hsl(341,30%,40%)"")


```


## communicate

### issues with git 

remeber any step on command line, you previous gotta be on the repository folder. 
like: 'cd /user/me/git/tidytuesday'

got issues with git syncrho. 
generally use windows desktop , now on linux notebook
i got the repo on dropbox folder. so config of windows its shared on dropbox and autosynchroed.
that causes issues as both computers got different context. 

- on windows got the  autocrlf, to true. 

so when i downloaded from github, it transformed the lf, to crlf > making the linux version see 'differences' just when i downloaded the repo.

to solve this i've set it to false:

git config --global core.autocrlf false

- issues on this computer sychro, on windows i use notepad++ , it wont work right on linux, so as alternative i use atom. 

nevertheless, it is not so happy when using terminal, at least on my experience at setting it as default editor. 
after commiting and filling the message on the editor, and closing it ( file & atom ) , the terminal keeps saying waiting to close ... 

i used this command to set atom as default:

git config --global core.editor ""atom --wait""

i used this one to fall back to default editor on my notebook 
( my default is pluma, you gotta search which is the name of your default editor. )

git config --global core.editor ""pluma""


as i already was in the problem, of getting commited or undone things ... 
i just fall back to previous commit that ive done. 

to know which was i looked at: 

git log

and see the log searching for the commit that i was the last to submit.
then when i see: 
Merge: 75253ed 354de7b

the id to reset its the 1st part '75253ed'

WARNING: THIS WILL DROP WHATEVER YOU HAVE DONE AFTER THAT POINT !

if you decide to move further, to do the reset all you need to go is: 

git reset --hard 75253ed3

Then after that i resinchroed to the current week data, uploads like: 

git pull https://github.com/rfordatascience/tidytuesday.git master

it was quite time consuming to debug this, so ill just go for one interesing visualization and try to reproduce.


### shiny app of graph data using gist

several lesons learnt

- for shiny deploy: https://shiny.rstudio.com/tutorial/written-tutorial/lesson7/
- couldnt make work the URL stuff, so switchetd to gist
- it worked ok from gist. followed the gist tutorial shown there. 
","2019-9"
"391",838,"https://github.com/jas1/tidytuesday/tree/master/jas1_weeks/2019/2019-02-26","jas1","tidytuesday","jas1_weeks/2019/2019-02-26/shiny_app/app.R","
# imports -----------------------------------------------------------------

library(dplyr)
library(readr)
library(skimr) #; install.packages(""skimr"")
library(igraph)
library(visNetwork)
library(shiny)
library(shinydashboard)
library(stringr)


# load data ---------------------------------------------------------------

# load data
small_trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/small_trains.csv"") 

# filter data
df_for_graph <- small_trains %>% 
    select(departure_station,arrival_station,year,month,journey_time_avg,total_num_trips) %>% 
    rename(from=departure_station) %>% 
    rename(to=arrival_station)


color_palette <- c(""blue"",""green"",""red"")
uniques_graph <- small_trains %>%    
    rename(from=departure_station) %>%
    rename(to=arrival_station) %>% 
    group_by(from,to) %>% 
    summarize(total_delay=sum(avg_delay_all_departing+avg_delay_all_arriving)) %>% 
    # mutate(is_tgv=str_detect(from,""TGV"")|str_detect(to,""TGV"")) %>% 
    # mutate(color=if_else(is_tgv,'red','blue')) %>%
    mutate(intervals=if_else(total_delay<=2000,""0-2k"",
                             if_else(total_delay>4000,"">4k"",""2k1-4k""))) %>% 
    mutate(color=case_when (
        total_delay<=2000 ~ color_palette[1],
        total_delay>4000 ~ color_palette[3],
        total_delay>2000 & total_delay<=4000 ~ color_palette[2]))


# make directed graph
trains_graph <- igraph::graph_from_data_frame(uniques_graph,directed = TRUE)


# UI ----------------------------------------------------------------------
header <- dashboardHeader(
    title=""Tidy tuesday challenge: Week 2019-02-26 french train delays"",
    titleWidth = 770#,
    #dropdownMenu(dropdownMenuOutput(""msg_menu""))
)
sidebar <- dashboardSidebar(
    sidebarMenu(
        menuItem(""French Trains As Graph"",
                 tabName = ""graph_pov""
        ),
        menuItem(""Contact"", 
                 href=""https://www.juliospairani.com"" )
    )
)

body <- dashboardBody(
    tabItems(
        # TAB graph pov --------------------------------------------------------------------------
        tabItem(tabName = ""graph_pov"",
                visNetworkOutput(""output_network"")
                )# end of graph pov
        ) # tab items end
    )# body end

ui <- dashboardPage(header, sidebar, body)


# SERVER ------------------------------------------------------------------
server <- function(input, output,session) {
    reactive_network <- reactive({
        set.seed(12345)
        visNetwork:::visIgraph(trains_graph) %>% 
            visNetwork:::visOptions(  selectedBy= list(variable = ""label""), # esto hace aparecer combos en la red.
                                      highlightNearest = list(enabled = TRUE, hover = TRUE))
    })
    
    output$output_network <- renderVisNetwork({

        reactive_network()
    })
}



# shiny app ---------------------------------------------------------------
shinyApp(ui = ui, server = server)","2019-9"
"392",900,"https://github.com/KCachel/kathleen-tidy-tuesdays/tree/master/2019-07-23","KCachel","kathleen-tidy-tuesdays","2019-07-23/tidy_tuesday_7_23_2019.R","library(tidyverse)
library(lubridate)
library(openintro) #convert state abb to full


wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


wildlife <- wildlife_impacts %>%
  filter(state != ""N/A"") %>% 
  filter(state != ""NA"") %>%
  filter(state != ""AC"") %>%
  mutate(year  = year(incident_date)) %>%
  mutate(state = abbr2state(state)) %>%
  select(state, year, operator)
#American Airlines

AA <- wildlife %>%
  filter(operator == ""AMERICAN AIRLINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()
base_size <- 9
#plot american
ggplot(data = AA, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#ece7f2"", high=""#2b8cbe"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""American Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 

ggsave(""2019-07-23/american.png"", width = 7, height = 7)

#United Airlines
united <- wildlife %>%
  filter(operator == ""UNITED AIRLINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()

#plot united
ggplot(data = united, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#ffeda0"", high=""#f03b20"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""United Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 
ggsave(""2019-07-23/united.png"", width = 7, height = 7)

#Delta
delta <- wildlife %>%
  filter(operator == ""DELTA AIR LINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()

#plot delta
ggplot(data = delta, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#e5f5e0"", high=""#31a354"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""Delta Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 
ggsave(""2019-07-23/delta.png"", width = 7, height = 7)

#Southwest
southwest<- wildlife %>%
  filter(operator == ""SOUTHWEST AIRLINES"") %>%
  filter(state != ""NA"") %>%
  group_by(year, state) %>%
  tally()

#plot southwest
ggplot(data = southwest, mapping = aes(x = year, y = state,  fill = n)) +
  geom_tile() + 
  theme_grey(base_size = base_size) + 
  scale_fill_gradient(low=""#e7e1ef"", high=""#dd1c77"", limits = c(1,250)) +
  labs(x = ""Year"", y = ""State"", title = ""Southwest Airlines Birdstrikes"") + 
  theme(panel.grid.major.x=element_blank(), #no gridlines
        panel.grid.minor.x=element_blank(), 
        panel.grid.major.y=element_blank(), 
        panel.grid.minor.y=element_blank(),
        panel.background=element_rect(fill=""white""), # background=white
        axis.text.x = element_text(angle=45, hjust = 1,vjust=1,size = 9,face = ""bold""),
        plot.title = element_text(size=16,face=""bold""),
        axis.text.y = element_text(size = 8)) +
  labs(fill=""Birdstrikes"") 

ggsave(""2019-07-23/southwest.png"", width = 7, height = 7)

","2019-30"
"393",901,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-04-16/tidy_tuesday_4_16_2019.R","# Kathleen Cachel

library(tidyverse)
library(reshape2)
library(scales)
library(ggdark)
library(ggthemes)
library(ggpomological)

women_research_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/Economist_women-research.csv"")

research_titles <- c(""country"",
                     ""Health sciences"",
                     ""Physical sciences"",
                     ""Engineering"",
                     ""Computer science, maths"",
                     ""Women inventors"")

# remove rows with NA values
# update Column Names
women_research_clean <- women_research_raw %>% 
  na.omit() %>% 
  set_names(nm = research_titles) %>% 
  filter(country != ""Country"" & country != ""Brazil"" & country != ""Denmark"" & country !=""Britain"" &
           country != ""France"" & country != ""United Kingdom"") %>% 
  gather(field, percent, `Health sciences`:`Women inventors`)

#make men version
men_research_clean <- women_research_clean %>%
  mutate(percent = 1 - as.numeric(percent))

#create new gender column
women_research_clean$gender <- ""female""
men_research_clean$gender <- "" amale""

#update type in women data frame
women_research_clean$percent <- as.numeric(women_research_clean$percent)

#union rows to make one big tidy data set
research_clean <- union(women_research_clean, men_research_clean)




#plotting
united_research <-  unite(research_clean, field_gender, field, gender, sep = ""."", remove = FALSE)


ggplot(data=united_research, aes(x=field, y=percent, fill=field_gender)) + 
  geom_bar(stat=""identity"") + 
  facet_grid(country~., switch = ""y"")+
  scale_fill_manual(breaks = c(""Women inventors.female"", ""Physical sciences.female"",""Health sciences.female"", ""Engineering.female"", ""Computer science, maths.female""),
                    values = c(""#efedf5"", ""#756bb1"",""#e5f5e0"" , ""#31a354"",""#deebf7"", ""#3182bd"",
                               ""#fde0dd"", ""#c51b8a"",""#fff7bc"", ""#d95f0e""), 
                    labels =c(""Women inventors"", ""Physical sciences"",""Health sciences"", ""Engineering"", ""Computer science & Math""),
                    name = ""Field:"")+
  coord_flip()+
  theme_economist_white( base_size = 14)+
  theme(axis.text.y = element_blank(),
        legend.position = ""bottom"",
        strip.text.y = element_text(angle = 180),
        legend.text = element_text(size =10, face = ""bold"")
  )+
  labs(x = """", y = ""Percent of total field that are Women"",
       title = ""Still a man's world"",
       subtitle = ""Women among researchers with papers published 2011-2015 *"",
       caption = ""Sources: 'Gender in the Global Research Landscape' by Elsevier *Indexed in Scopus"")+
  scale_y_continuous(labels = percent)+
  geom_hline(yintercept=.50, linetype=""dashed"", 
             color = ""red"", size=2)

ggsave(""my_women_researcher_plot.png"", width = 10.5, height = 8)


","2019-16"
"394",902,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-06-04/tidy_tuesday_6_4_2019.R","library(tidyverse)
library(ggthemes)
library(ggdark)
library(LaCroixColoR)
ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

summary(ramen_ratings)

#Find the top 20 producing countries 
ramen_topcountries <- ramen_ratings %>%
  group_by(country,style) %>%
  tally() %>%
  arrange(-n) %>%
  #head(20) %>%
  inner_join(ramen_ratings)

#Find average ratings per country:
country_average <- ramen_topcountries %>%
  group_by(country,style) %>%
  summarize(
    avg = mean(stars, na.rm = TRUE)
  ) %>%
  arrange(-avg)

topcountrieslist <- ramen_topcountries %>% 
  group_by(country) %>%
  summarize(
    avg = mean(stars, na.rm = TRUE)
  ) %>%
  arrange(-avg) %>%
  head(25) %>% 
  select(country)

country_averagestyle <- filter(country_average, style == ""Bowl"" |
                                 style == ""Cup"" |
                                 style == ""Pack"") %>%
  inner_join(topcountrieslist)

# Create palette
pal <- c(""#803515"", ""#F0B630"", ""#E6442E"")

###gplot
ggplot(country_averagestyle, aes(avg, country, fill = style)) +
  #geom_point(size = 4) +
  geom_bar(stat = ""identity"")
  dark_mode() +
  scale_fill_manual(values = pal, name = ""Style:"") +
    coord_flip()
  labs(x = """", y = ""Country"", title = ""Average Ramen Rating by Country"") +
  theme(legend.position = ""top"",
        axis.text.x=element_text(size=11, face = ""bold"", hjust = 1, color = ""#666C1C""),
        axis.text.y = element_text(size = 10, color = ""#666C1C""),
        axis.title.y = element_text(color = ""#666C1C"", face = ""bold""),
        legend.title = element_text(color = ""#666C1C"", size = 12, face = ""bold""),
        legend.text = element_text(color = ""#666C1C"", face = ""bold""),
        plot.title = element_text(color = ""#666C1C"", face = ""bold"")) 



","2019-23"
"395",903,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-06-18/R_rainclouds.R","### Script from : https://github.com/RainCloudPlots/RainCloudPlots/blob/master/tutorial_R/R_rainclouds.R
### This script creates an R function to generate raincloud plots, then simulates
### data for plots. If using for your own data, you only need lines 1-80.
### It relies largely on code previously written by David Robinson
### (https://gist.github.com/dgrtwo/eb7750e74997891d7c20)
### and the package ggplot2 by Hadley Wickham

# Check if required packages are installed ----
packages <- c(""cowplot"", ""readr"", ""ggplot2"", ""dplyr"", ""lavaan"", ""smooth"", ""Hmisc"")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}

# Load packages ----
library(ggplot2)

# Defining the geom_flat_violin function ----
# Note: the below code modifies the
# existing github page by removing a parenthesis in line 50

""%||%"" <- function(a, b) {
  if (!is.null(a)) a else b
}

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = ""ydensity"",
                             position = ""dodge"", trim = TRUE, scale = ""area"",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}


#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
  ggproto(""GeomFlatViolin"", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            # ymin, ymax, xmin, and xmax define the bounding rectangle for each group
            data %>%
              group_by(group) %>%
              mutate(
                ymin = min(y),
                ymax = max(y),
                xmin = x,
                xmax = x + width / 2
              )
          },
          
          draw_group = function(data, panel_scales, coord) {
            # Find the points for the line to go all the way around
            data <- transform(data,
                              xminv = x,
                              xmaxv = x + violinwidth * (xmax - x)
            )
            
            # Make sure it's sorted properly to draw the outline
            newdata <- rbind(
              plyr::arrange(transform(data, x = xminv), y),
              plyr::arrange(transform(data, x = xmaxv), -y)
            )
            
            # Close the polygon: set first and last point the same
            # Needed for coord_polar and such
            newdata <- rbind(newdata, newdata[1, ])
            
            ggplot2:::ggname(""geom_flat_violin"", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          
          draw_key = draw_key_polygon,
          
          default_aes = aes(
            weight = 1, colour = ""grey20"", fill = ""white"", size = 0.5,
            alpha = NA, linetype = ""solid""
          ),
          
          required_aes = c(""x"", ""y"")
  )

","2019-25"
"396",904,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-06-18/tidy_tuesday_6_18_2019.R","library(tidyverse)
library(ggthemes)
library(ggdark)
library(magick)
library(grid)
library(gridExtra)
library(gganimate)
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

summary(bird_counts)

top8birds <- bird_counts %>%
  group_by(species) %>%
  summarize(s = sum(how_many_counted)) %>%
  arrange(-s) %>%
  head(8) %>%
  inner_join(bird_counts) %>%
  filter(species != ""European Starling"")

b <- ggplot(data = top8birds, aes(y = how_many_counted, x = species, fill = species)) +
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .8) +
  geom_point(aes(y = how_many_counted, color = species), position = position_jitter(width = .15), size = .5, alpha = 0.8) +
  geom_boxplot(width = .1, outlier.shape = NA, alpha = 0.5) +
  #expand_limits(x = 1) +
  guides(fill = FALSE) +
  guides(color = FALSE) +
  scale_color_brewer(palette = ""Spectral"") +
  scale_fill_brewer(palette = ""Spectral"") +
  coord_flip() +
  theme_bw()


a <- ggplot(top8birds, aes(x = total_hours, y = how_many_counted, color = species)) + 
  geom_point(size = 3.5) +
  scale_color_brewer(palette = ""Spectral"") + 
  theme_bw()
  
a + transition_time(year) +
  labs(title = ""Year: {frame_time}"")+
  shadow_wake(wake_length = 0, alpha = FALSE)

p <- ggplot(data = top8birds, aes(y = how_many_counted, x = year, color = species)) +
  geom_line(stat= 'identity')+
  scale_color_brewer(palette = ""Spectral"") +
  theme_bw()

p + transition_reveal(year)
","2019-25"
"397",905,"https://github.com/KCachel/kathleen-tidy-tuesdays","KCachel","kathleen-tidy-tuesdays","2019-07-30/tidy_tuesday_7_30_2019.R","library(tidyverse)
library(lubridate)
library(ggridges)
library(viridis)
library(ggdark)
library(LaCroixColoR)
# clean dataset from lizawood's github
url <- ""https://raw.githubusercontent.com/lizawood/apps-and-games/master/PC_Games/PCgames_2004_2018_raw.csv""

# read in raw data
raw_df <- url %>% 
  read_csv() %>% 
  janitor::clean_names() 

# clean up some of the factors and playtime data
clean_df <- raw_df %>% 
  mutate(price = as.numeric(price),
         score_rank = word(score_rank_userscore_metascore, 1),
         average_playtime = word(playtime_median, 1),
         median_playtime = word(playtime_median, 2),
         median_playtime = str_remove(median_playtime, ""\\(""),
         median_playtime = str_remove(median_playtime, ""\\)""),
         average_playtime = 60 * as.numeric(str_sub(average_playtime, 1, 2)) +
           as.numeric(str_sub(average_playtime, 4, 5)),
         median_playtime = 60 * as.numeric(str_sub(median_playtime, 1, 2)) +
           as.numeric(str_sub(median_playtime, 4, 5)),
         metascore = as.double(str_sub(score_rank_userscore_metascore, start = -4, end = -3))) %>% 
  select(-score_rank_userscore_metascore, -score_rank, -playtime_median) %>% 
  rename(publisher = publisher_s, developer = developer_s)



pub <- clean_df %>% 
  filter(publisher == ""Paradox Interactive"") %>%
  mutate( release_date = mdy(release_date)) %>%
  mutate( release_date = year(release_date)) %>%
  arrange(release_date) %>%
  filter(price != ""NA"")
  
  

ggplot(pub, aes(x = price, y = release_date, group = release_date, fill = ..x..)) + 
  geom_density_ridges_gradient() +
  scale_fill_viridis(option= 'B', name = ""Game Price [$]"") +
  dark_theme_grey() +
  labs(title = 'Are Paradox Interactive video game prices increasing?') +
  theme(legend.position = ""bottom"",
        axis.text.x=element_text(size=11, face = ""bold"", hjust = 1, color = ""deeppink""),
        axis.text.y = element_text(size = 10, color = ""deeppink"", face = ""bold""),
        axis.title.x = element_text(color = ""deeppink"", face = ""bold""),
        legend.title = element_text(color = ""deeppink"", size = 12, face = ""bold""),
        legend.text = element_text(color = ""deeppink"", face = ""bold""),
        plot.title = element_text(color = ""deeppink"", face = ""bold""))

ggsave(""2019-07-30/paradox.png"", width = 7, height = 7)

","2019-31"
"398",921,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-04-10 CopaMundial.R","library(tidyverse)

partidos_fifa_copa_mundial_procesado <- readr::read_delim(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-04-10/partidos.txt"",delim = ""\t"")

partidos <- partidos_fifa_copa_mundial_procesado

head(partidos)

## Organizacin de los datos

partidos <- partidos %>% 
  mutate(partido_orden = as.numeric(gsub(""[()]"", """", partido_orden)))

## Grafico exploratorio de cantidad de goles por Copa

partidos %>% 
  group_by(anio) %>% 
  summarize(num_partidos = n(), goles = sum(equipo_1_final,equipo_2_final), rate = goles/num_partidos) %>% 
  ggplot(aes(anio, rate)) +
  geom_col() + geom_smooth()

## Cantidad de partidos ganados en Mundiales por Pas
  
partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(ganador, sort = TRUE) %>% 
  ggplot(aes(fct_reorder(ganador, n), n, fill = ganador, label = n)) + 
  geom_col() +
  geom_text(hjust = -0.2) +
  coord_flip() +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Cantidad de partidos ganados en Mundiales por Pas"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Pas"",
       y = ""Cantidad de partidos ganados"") 

## Pas con mayor cantidad de partidos ganados por Copa Mundial

partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(anio, ganador, sort = TRUE) %>% 
  group_by(anio) %>% 
  mutate(posicion = rank(-n, ties.method = ""first"")) %>% 
  ungroup() %>% 
  filter(posicion <= 1) %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas con mayor cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 

## Identificando el partido final de cada Copa

max_partidos <- partidos %>% 
  group_by(anio) %>% 
  summarize(max_partido = max(partido_orden))

## Definiendo el ganar de cada partido, este si incluye el Empate

ganador_partido <- partidos %>% 
  mutate(ganador = case_when(
    equipo_1_final > equipo_2_final ~ equipo_1,
    equipo_1_final < equipo_2_final ~ equipo_2,
    TRUE ~ ""Empate"")) 

## Seleccionando el ganador del ltimo partido de cada copa con su nmero de partidos ganados

campeon <- ganador_partido %>% 
  semi_join(max_partidos, by = c(""partido_orden"" = ""max_partido"", ""anio"" = ""anio"")) %>% 
  select(anio, ganador)

## Grfico del Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial

ganador_partido %>% 
  count(anio, ganador, sort = TRUE) %>% 
  right_join(campeon, by = c(""anio"", ""ganador"")) %>% 
  filter(ganador != ""Empate"") %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 
  
","2019-15"
"399",922,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-04-15 EU_balance.R","library(tidyverse)


eu_balance <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")


## Just factor declarations for country and account_type

eu_balance <- eu_balance %>% 
  mutate(country = as_factor(country),
         account_type = as_factor(account_type))

## Did a percentual balance growth, but at the end didn't use it

eu_balance %>% 
  filter(year %in% c(2009,2015), account_type == ""current"") %>% 
  spread(key = ""year"", value = ""value"") %>% 
  mutate(balance_growth = (`2015` - `2009`) / `2015`) -> eu_balance_growth 

min(eu_balance_growth$`2009`)
min(eu_balance_growth$`2015`)

## Graph 2009 to 2015 Growth relationship of Current Values by Country

eu_balance_growth %>% 
  mutate(`2009` = `2009` + 56192,
         `2015` = `2015` + 18091) %>% ## Had to add values for the log transformation
  ggplot(aes(x = `2009`, y = `2015`, col = country, label = country)) +
  geom_jitter(alpha = 0.5) +
  geom_text(vjust = -0.5) +
  scale_x_log10() + 
  scale_y_log10() + 
  labs(title = ""2009 to 2015 Growth relationship of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""2009 \n log10 value"",
       y = ""2015 \n log10 value"") +
  theme_light() +
  theme(legend.position = ""none"")

## 2009 to 2015 Growth of Current Values by Country

eu_balance_growth %>% 
  select(country, `2009`,`2015`) %>% 
  mutate(country = fct_reorder(country, `2015`)) %>% 
  gather(key = year, value = value, `2009`:`2015`, -country) %>% 
  ggplot(aes(x = country, y = value, group = country, col = year)) + 
  geom_point(size = 2) +
  geom_path(arrow = arrow(length = unit(1.5, ""mm""), type = ""closed""), col = ""DarkBlue"") + 
  coord_flip() +
  labs(title = ""2009 to 2015 Growth of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""Country"",
       y = ""2009 to 2015 value"") +
  theme_light() 
","2019-15"
"400",923,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-04-30 Birds.R","library(tidyverse)
library(lubridate)
Sys.setlocale(""LC_TIME"", ""C"")

bird_collisions_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

head(bird_collisions_raw)

## Tidy the Dates

bird_collisions <- bird_collisions_raw %>% 
  mutate_at(vars(-date), as_factor) %>% 
  mutate(month = months(ymd(date)),
         day = weekdays(ymd(date)))
  

library(FactoMineR)
library(""factoextra"")

## Correspondence analysis

bird_mca <- bird_collisions %>% 
  filter(flight_call != c(""Rare"", ""No""),
         genus %in% c(""Melospiza"", ""Zonotrichia"", ""Catharus"", ""Junco"", ""Setophaga"")) %>% 
  select(genus, habitat, locality, month) %>% 
  MCA(ncp = 5, graph = FALSE)

fviz_mca_var(bird_mca, col.var = ""cos2"", 
             repel = TRUE, # Avoid text overlapping
             ggtheme = theme_minimal()) + 
  labs(title = ""Flight call birds Correspondence analysis by genus, habitat, locality and month \nfor Genus top 5 bird crashers"", 
       caption = ""Winger BM, Weeks BC, Farnsworth A, Jones AW, Hennen M, Willard DE (2019)\nNocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. \nProceedings of the Royal Society B 286(1900): 20190364."")



","2019-18"
"401",924,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-06-04 Ramen ratings.R","library(tidyverse)
library(countrycode)
library(ggridges)


ramen_ratings_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")


## Cargar fuentes de windows
library(extrafont)
loadfonts(device = ""win"")


ramen_ratings <- ramen_ratings_raw %>% 
  filter(style %in% c(""Bowl"", ""Cup"", ""Pack"", ""Tray"")) %>% 
  mutate(continent = countrycode(sourcevar = country, 
                                 origin = ""country.name.en"", 
                                 destination = ""continent"")) %>% 
  filter(!is.na(continent))


## Density ridges plot

ramen_ratings %>% 
  ggplot(aes(x = stars, y = continent, fill = continent, group = continent)) + 
  geom_density_ridges(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

## Violin plot

ramen_ratings %>% 
  ggplot(aes(x = continent, y = stars, fill = continent, group = continent)) + 
  geom_violin(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  coord_flip() + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))
","2019-23"
"402",925,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-07-25 Play Store.Rmd","---
title: ""Datos aplicaciones Google""
author: ""R para la ciencia de datos - DlanyR""
date: ""25/7/2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

apps <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-07-24/apps_googleplaystore.csv"")

glimpse(apps)

```

## Explorar los datos

```{r}

apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(categoria = fct_reorder(categoria, n)) %>% 
  ggplot(aes(x = categoria, y = n, label = n)) + 
  geom_col() + 
  geom_text(hjust = 1, col = ""white"") +
  coord_flip() + 
  labs(title = ""Cantidad de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia absoluta"",
       caption = ""Fuente de datos: Kaggle"")

perc_redondeado <- function(x){
    paste(round(x, 3)*100, ""%"", sep = """")
}


apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(perc = n / sum(n),
         perc_acum = cumsum(perc),
         categoria = fct_reorder(categoria, -n)) %>% 
  ggplot(aes(categoria, perc)) + 
  geom_col() + 
  geom_point(aes(x = categoria, y = perc_acum, group = 1)) +
  geom_line(aes(x = categoria, y = perc_acum, group = 1)) + 
  geom_text(aes(x = categoria, y = perc_acum, group = 1, label = perc_redondeado(perc_acum)),
            vjust = -1, angle = 30, size = 3.5) + 
  theme_light() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = ""Pareto de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia relativa"",
       caption = ""Fuente de datos: Kaggle"")
  


```

","2019-30"
"403",926,"https://github.com/delany-ramirez/test1","delany-ramirez","test1","2019-08-06 Bob Ross.R","library(tidyverse)
library(janitor)
library(RColorBrewer)
library(extrafont)

font_import()
loadfonts(device = ""win"")


bob_ross_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")

glimpse(bob_ross_raw)

bob_ross <- bob_ross_raw %>% 
  gather(key = ""element"", value = ""presence"", APPLE_FRAME:WOOD_FRAMED) %>% 
  filter(presence != 0) %>% 
  separate(col = EPISODE, into = c(""season"", ""episode""), sep = ""E"") %>% 
  mutate(season = parse_number(season),
         season = factor(season),
         episode = parse_integer(episode)) %>% 
  clean_names() %>% 
  select(-presence)

bob_ross_season_top10 <- bob_ross %>% 
  group_by(season) %>% 
  count(element, sort = TRUE) %>% 
  slice(1:10) %>% 
  ungroup() 

getPalette = colorRampPalette(brewer.pal(9, ""Greens""))

bob_ross_season_top10 %>% 
  ggplot(aes(season, n, fill = element, label = paste(str_to_lower(element), n, sep = "" ""))) + 
  geom_col() + 
  geom_text(position = ""stack"", size = 3, hjust = 1) + 
  coord_flip() + 
  labs(title = ""Bob Ross Top 10 word-element by Season"",
       x = ""Season"",
       y = ""Number of episodes mentioned"",
       caption = ""Data Source: 538"") + 
  scale_fill_manual(values = getPalette(22)) + 
  theme_minimal() + 
  theme(legend.position = ""none"",
        text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

","2019-32"
"404",927,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-04-10 CopaMundial.R","library(tidyverse)

partidos_fifa_copa_mundial_procesado <- readr::read_delim(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-04-10/partidos.txt"",delim = ""\t"")

partidos <- partidos_fifa_copa_mundial_procesado

head(partidos)

## Organizacin de los datos

partidos <- partidos %>% 
  mutate(partido_orden = as.numeric(gsub(""[()]"", """", partido_orden)))

## Grafico exploratorio de cantidad de goles por Copa

partidos %>% 
  group_by(anio) %>% 
  summarize(num_partidos = n(), goles = sum(equipo_1_final,equipo_2_final), rate = goles/num_partidos) %>% 
  ggplot(aes(anio, rate)) +
  geom_col() + geom_smooth()

## Cantidad de partidos ganados en Mundiales por Pas
  
partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(ganador, sort = TRUE) %>% 
  ggplot(aes(fct_reorder(ganador, n), n, fill = ganador, label = n)) + 
  geom_col() +
  geom_text(hjust = -0.2) +
  coord_flip() +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Cantidad de partidos ganados en Mundiales por Pas"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Pas"",
       y = ""Cantidad de partidos ganados"") 

## Pas con mayor cantidad de partidos ganados por Copa Mundial

partidos %>% 
  filter(equipo_1_final != equipo_2_final) %>% 
  mutate(ganador = if_else(equipo_1_final > equipo_2_final, equipo_1, equipo_2)) %>% 
  count(anio, ganador, sort = TRUE) %>% 
  group_by(anio) %>% 
  mutate(posicion = rank(-n, ties.method = ""first"")) %>% 
  ungroup() %>% 
  filter(posicion <= 1) %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas con mayor cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 

## Identificando el partido final de cada Copa

max_partidos <- partidos %>% 
  group_by(anio) %>% 
  summarize(max_partido = max(partido_orden))

## Definiendo el ganar de cada partido, este si incluye el Empate

ganador_partido <- partidos %>% 
  mutate(ganador = case_when(
    equipo_1_final > equipo_2_final ~ equipo_1,
    equipo_1_final < equipo_2_final ~ equipo_2,
    TRUE ~ ""Empate"")) 

## Seleccionando el ganador del ltimo partido de cada copa con su nmero de partidos ganados

campeon <- ganador_partido %>% 
  semi_join(max_partidos, by = c(""partido_orden"" = ""max_partido"", ""anio"" = ""anio"")) %>% 
  select(anio, ganador)

## Grfico del Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial

ganador_partido %>% 
  count(anio, ganador, sort = TRUE) %>% 
  right_join(campeon, by = c(""anio"", ""ganador"")) %>% 
  filter(ganador != ""Empate"") %>% 
  ggplot(aes(x = as_factor(anio), y = n, col = ganador, label = ganador)) +
  geom_point() +
  geom_text(angle = 45, vjust = 1) +
  theme_minimal() + 
  theme(legend.position = ""none"") +
  labs(title = ""Pas campeon con relacin a la cantidad de partidos ganados por Copa Mundial"",
       subtitle = ""DatosDeMircoles"",
       caption = ""Fuente: Open Public Domain Football Data"",
       x = ""Copa Mundial"",
       y = ""Cantidad de partidos ganados"") 
  
","2019-15"
"405",928,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-04-15 EU_balance.R","library(tidyverse)


eu_balance <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")


## Just factor declarations for country and account_type

eu_balance <- eu_balance %>% 
  mutate(country = as_factor(country),
         account_type = as_factor(account_type))

## Did a percentual balance growth, but at the end didn't use it

eu_balance %>% 
  filter(year %in% c(2009,2015), account_type == ""current"") %>% 
  spread(key = ""year"", value = ""value"") %>% 
  mutate(balance_growth = (`2015` - `2009`) / `2015`) -> eu_balance_growth 

min(eu_balance_growth$`2009`)
min(eu_balance_growth$`2015`)

## Graph 2009 to 2015 Growth relationship of Current Values by Country

eu_balance_growth %>% 
  mutate(`2009` = `2009` + 56192,
         `2015` = `2015` + 18091) %>% ## Had to add values for the log transformation
  ggplot(aes(x = `2009`, y = `2015`, col = country, label = country)) +
  geom_jitter(alpha = 0.5) +
  geom_text(vjust = -0.5) +
  scale_x_log10() + 
  scale_y_log10() + 
  labs(title = ""2009 to 2015 Growth relationship of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""2009 \n log10 value"",
       y = ""2015 \n log10 value"") +
  theme_light() +
  theme(legend.position = ""none"")

## 2009 to 2015 Growth of Current Values by Country

eu_balance_growth %>% 
  select(country, `2009`,`2015`) %>% 
  mutate(country = fct_reorder(country, `2015`)) %>% 
  gather(key = year, value = value, `2009`:`2015`, -country) %>% 
  ggplot(aes(x = country, y = value, group = country, col = year)) + 
  geom_point(size = 2) +
  geom_path(arrow = arrow(length = unit(1.5, ""mm""), type = ""closed""), col = ""DarkBlue"") + 
  coord_flip() +
  labs(title = ""2009 to 2015 Growth of Current Values by Country"",
       subtitle = ""Source: The Economist"",
       x = ""Country"",
       y = ""2009 to 2015 value"") +
  theme_light() 
","2019-15"
"406",929,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-04-30 Birds.R","library(tidyverse)
library(lubridate)
Sys.setlocale(""LC_TIME"", ""C"")

bird_collisions_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

head(bird_collisions_raw)

## Tidy the Dates

bird_collisions <- bird_collisions_raw %>% 
  mutate_at(vars(-date), as_factor) %>% 
  mutate(month = months(ymd(date)),
         day = weekdays(ymd(date)))
  

library(FactoMineR)
library(""factoextra"")

## Correspondence analysis

bird_mca <- bird_collisions %>% 
  filter(flight_call != c(""Rare"", ""No""),
         genus %in% c(""Melospiza"", ""Zonotrichia"", ""Catharus"", ""Junco"", ""Setophaga"")) %>% 
  select(genus, habitat, locality, month) %>% 
  MCA(ncp = 5, graph = FALSE)

fviz_mca_var(bird_mca, col.var = ""cos2"", 
             repel = TRUE, # Avoid text overlapping
             ggtheme = theme_minimal()) + 
  labs(title = ""Flight call birds Correspondence analysis by genus, habitat, locality and month \nfor Genus top 5 bird crashers"", 
       caption = ""Winger BM, Weeks BC, Farnsworth A, Jones AW, Hennen M, Willard DE (2019)\nNocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. \nProceedings of the Royal Society B 286(1900): 20190364."")



","2019-18"
"407",930,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-06-04 Ramen ratings.R","library(tidyverse)
library(countrycode)
library(ggridges)


ramen_ratings_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")


## Cargar fuentes de windows
library(extrafont)
loadfonts(device = ""win"")


ramen_ratings <- ramen_ratings_raw %>% 
  filter(style %in% c(""Bowl"", ""Cup"", ""Pack"", ""Tray"")) %>% 
  mutate(continent = countrycode(sourcevar = country, 
                                 origin = ""country.name.en"", 
                                 destination = ""continent"")) %>% 
  filter(!is.na(continent))


## Density ridges plot

ramen_ratings %>% 
  ggplot(aes(x = stars, y = continent, fill = continent, group = continent)) + 
  geom_density_ridges(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

## Violin plot

ramen_ratings %>% 
  ggplot(aes(x = continent, y = stars, fill = continent, group = continent)) + 
  geom_violin(alpha = 0.4) + 
  facet_wrap(. ~ style, scales = ""free"") + 
  coord_flip() + 
  labs(title = ""Ramen rating distribution by continent"",
       x = ""Stars"",
       y = ""Continent"",
       caption = ""Data source: The Ramen Rater."")+
  theme(text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))
","2019-23"
"408",931,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-07-25 Play Store.Rmd","---
title: ""Datos aplicaciones Google""
author: ""R para la ciencia de datos - DlanyR""
date: ""25/7/2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

apps <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-07-24/apps_googleplaystore.csv"")

glimpse(apps)

```

## Explorar los datos

```{r}

apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(categoria = fct_reorder(categoria, n)) %>% 
  ggplot(aes(x = categoria, y = n, label = n)) + 
  geom_col() + 
  geom_text(hjust = 1, col = ""white"") +
  coord_flip() + 
  labs(title = ""Cantidad de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia absoluta"",
       caption = ""Fuente de datos: Kaggle"")

perc_redondeado <- function(x){
    paste(round(x, 3)*100, ""%"", sep = """")
}


apps %>% 
  count(categoria, sort = TRUE) %>% 
  mutate(perc = n / sum(n),
         perc_acum = cumsum(perc),
         categoria = fct_reorder(categoria, -n)) %>% 
  ggplot(aes(categoria, perc)) + 
  geom_col() + 
  geom_point(aes(x = categoria, y = perc_acum, group = 1)) +
  geom_line(aes(x = categoria, y = perc_acum, group = 1)) + 
  geom_text(aes(x = categoria, y = perc_acum, group = 1, label = perc_redondeado(perc_acum)),
            vjust = -1, angle = 30, size = 3.5) + 
  theme_light() + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(title = ""Pareto de aplicaciones por Categora en Play Store"",
       x = ""Categora"",
       y = ""Frecuencia relativa"",
       caption = ""Fuente de datos: Kaggle"")
  


```

","2019-30"
"409",932,"https://github.com/delany-ramirez/tidytuesday","delany-ramirez","tidytuesday","2019-08-06 Bob Ross.R","library(tidyverse)
library(janitor)
library(RColorBrewer)
library(extrafont)

font_import()
loadfonts(device = ""win"")


bob_ross_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")

glimpse(bob_ross_raw)

bob_ross <- bob_ross_raw %>% 
  gather(key = ""element"", value = ""presence"", APPLE_FRAME:WOOD_FRAMED) %>% 
  filter(presence != 0) %>% 
  separate(col = EPISODE, into = c(""season"", ""episode""), sep = ""E"") %>% 
  mutate(season = parse_number(season),
         season = factor(season),
         episode = parse_integer(episode)) %>% 
  clean_names() %>% 
  select(-presence)

bob_ross_season_top10 <- bob_ross %>% 
  group_by(season) %>% 
  count(element, sort = TRUE) %>% 
  slice(1:10) %>% 
  ungroup() 

getPalette = colorRampPalette(brewer.pal(9, ""Greens""))

bob_ross_season_top10 %>% 
  ggplot(aes(season, n, fill = element, label = paste(str_to_lower(element), n, sep = "" ""))) + 
  geom_col() + 
  geom_text(position = ""stack"", size = 3, hjust = 1) + 
  coord_flip() + 
  labs(title = ""Bob Ross Top 10 word-element by Season"",
       x = ""Season"",
       y = ""Number of episodes mentioned"",
       caption = ""Data Source: 538"") + 
  scale_fill_manual(values = getPalette(22)) + 
  theme_minimal() + 
  theme(legend.position = ""none"",
        text = element_text(family = ""Maiandra GD""),
        plot.background = element_rect(fill='#fff7ec'),
        plot.title = element_text(color='black',
                                  size=20),
        strip.text = element_text(size = 9),
        strip.background = element_rect(color = ""#efe3d2"", fill = '#f7e9d7'),
        panel.background = element_rect(color = ""#efe3d2"", fill = '#fff7ec'))

","2019-32"
"410",996,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190129-milk_production/milk_production.Rmd","Eeysirhc","tidytuesday","20190129-milk_production/milk_production.Rmd","---
title: ""TidyTuesday: Milk Production""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 1/29/2019 ([source](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-29))

```{r}
library(tidyverse)
library(scales)
library(lubridate)
library(ggmap)
library(gganimate)
library(ggthemes)
library(transformr)

milk_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/state_milk_production.csv"")
milk <- milk_raw
```

```{r}
usa <- as_tibble(map_data(""state""))
usa$region <- str_to_title(usa$region)
usa <- usa %>%
  rename(state = region)

milk_parsed <- milk %>%
  select(-region) %>%
  mutate(milk_10billion = milk_produced / 10000000000,
         year = as.integer(year)) %>%
  full_join(usa) %>%
  filter(!is.na(year), !is.na(long), !is.na(lat))
```

```{r}
milk_animation <- milk_parsed %>%
  ggplot(aes(long, lat, group = group, fill = milk_10billion)) +
  geom_polygon(color = 'black') +
  scale_fill_gradient2(low = ""gray97"", mid = ""steelblue"", high = ""midnightblue"", midpoint = 2.5) +
  theme_map(base_size = 15) + 
  coord_map() +
  labs(x = NULL,
       y = NULL,
       fill = NULL,
       title = ""Milk production per 10 billion pounds"",
       subtitle = ""Year: {round(frame_time)}"",
       caption = ""Source: USDA"") +
  transition_time(year)

animate(milk_animation, height = 800, width = 800)
anim_save(""milkproduction.gif"")
```
","2019-5"
"411",997,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181127-baltimore_bridges/baltimore_bridges.Rmd","Eeysirhc","tidytuesday","20181127-baltimore_bridges/baltimore_bridges.Rmd","---
title: ""TidyTuesday: Baltimore Bridges""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 11/27/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-11-27

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(ggmap)

bridges_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-27/baltimore_bridges.csv"")

bridges <- bridges_raw
```

### Do bridge conditions get better over time?
```{r}
# manually reorder bridge_condition factors
x <- bridges
x$bridge_condition <- as.factor(x$bridge_condition)
x$bridge_condition <- factor(x$bridge_condition, levels = c(""Poor"", ""Fair"", ""Good""))

x %>%  
  filter(yr_built >= 1900) %>% # removing 2017 due to outlier
  select(lat, long, yr_built, bridge_condition, avg_daily_traffic) %>%
  group_by(yr_built, bridge_condition) %>%
  summarize(avg_daily_traffic = mean(avg_daily_traffic)) %>%
  ggplot() + 
  geom_col(aes(yr_built, avg_daily_traffic, fill = bridge_condition),
           alpha = 0.3) +
  scale_y_continuous(label = comma_format(), 
                     limits = c(0, 223000)) +
  scale_fill_brewer(palette = 'Set1') +
  scale_color_brewer(palette = 'Set1') +
  geom_smooth(aes(yr_built, avg_daily_traffic, 
                  color = bridge_condition),
              se = FALSE) +
  theme_bw(base_size = 15) +
  labs(x = """",
        y = """",
        title = ""Baltimore bridges: average daily traffic over time"",
       subtitle = ""Applied smoothing to highlight differences in bridge conditions and dampen outliers"",
       fill = ""Bridge Condition"",
       color = ""Bridge Condition"") 

```

### Is the improvement consistent across all bridge owners?
```{r}
x %>%
  select(owner, bridge_condition, yr_built) %>% 
  filter(owner != ""Army"", owner != ""National Park Service"", owner != ""Navy/Marines"", 
         owner != ""Other Local Agencies"", owner != ""Private (other than railroad)"",
         owner != ""Town or Township Highway Agency"", owner != ""Other State Agencies"") %>%
  filter(yr_built > 1958) %>%
  ggplot() + 
  geom_density(aes(x = yr_built, fill = bridge_condition, color = bridge_condition), 
               alpha = 0.3) +
  facet_wrap(~owner) +
  theme_bw(base_size = 15) +
  scale_fill_brewer(palette = 'Set1') +
  scale_color_brewer(palette = 'Set1') +
  labs(x = """",
       y = """",
       fill = ""Bridge Condition"",
       color = ""Bridge Condition"",
       title = ""Baltimore bridges: status of conditions over time by owner"") +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank())
  
```






### How much does it cost to maintain the bridge per car?
```{r}
# replace NA with 0
bridges$total_improve_cost_thousands[is.na(bridges$total_improve_cost_thousands)] <- 0

bridges %>% 
  filter(yr_built >= 1900) %>%
  select(lat, long, yr_built, bridge_condition, avg_daily_traffic, total_improve_cost_thousands) %>%
  mutate(cost_car_improve = total_improve_cost_thousands / avg_daily_traffic) %>% 
  group_by(yr_built, bridge_condition) %>%
  ggplot() +
  geom_col(aes(yr_built, cost_car_improve, fill = bridge_condition)) +
  scale_y_continuous(label = dollar_format()) + 
  facet_grid(bridge_condition ~ .) + 
  theme_bw()

```

### Validating lat/long data to fit Baltimore map
```{r}
# note to self: coordinates from file not matching ggmap so come back to this at a later time

baltimore <- as_tibble(map_data(""county"", regions = ""maryland,baltimore""))

bridges %>%
  full_join(baltimore) %>%
  group_by(lat, long) %>%
  ggplot() + 
  geom_point(aes(long, lat)) +
  geom_polygon(data = baltimore, aes(long, lat, group = group), fill = NA, color = 'black')

```

","2018-48"
"412",998,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190101-rtweet_data/rtweet_data.Rmd","Eeysirhc","tidytuesday","20190101-rtweet_data/rtweet_data.Rmd","---
title: ""TidyTuesday: rtweet data""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 01/01/2019

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-01

```{r}
# LOAD PACKAGES AND PARSE DATA
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(tidytext)
library(topicmodels)

tweets_raw <- as_tibble(readRDS(""rstats_tweets.rds""))
```

### Parse data and identify top users
```{r}
# IDEA BEHIND THIS IS TO FILTER OUT BOTS

# FIND TOP USERS
top_interactions <- tweets_raw %>%
  select(screen_name, favorite_count, retweet_count) %>%
  group_by(screen_name) %>%
  summarize(favorite = sum(favorite_count),
            retweet = sum(retweet_count)) %>%
  group_by(screen_name) %>%
  mutate(total = sum(favorite, retweet)) %>%
  arrange(desc(total)) %>%
  head(12) 

# JOIN TOP USERS WITH RAW DATASET
tweets <- tweets_raw %>% 
  inner_join(top_interactions, by='screen_name')

# FINAL DATA PROCESSING
tweets_parsed <- tweets %>% 
  select(screen_name, text) %>%
  group_by(screen_name) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  filter(!grepl(""https|t.co|http|bit.ly|kindly|goo.gl|rstats|amp"", word)) # REMOVE EXTRA STOP WORDS
```

### What are the most significant keywords for each #rstats Twitter user?
```{r}
tweets_tfidf <- tweets_parsed %>%
  count(screen_name, word, sort = TRUE) %>%
  ungroup() %>%
  bind_tf_idf(word, screen_name, n)

tweets_tfidf %>%
  filter(!near(tf, 1)) %>%
  arrange(desc(tf_idf)) %>%
  group_by(screen_name) %>%
  distinct(screen_name, word, .keep_all = TRUE) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>%
  ggplot(aes(word, tf_idf, fill = screen_name)) + 
  geom_col(show.legend = FALSE) +
  facet_wrap(~screen_name, ncol = 4, scales = ""free"") +
  coord_flip() +
  theme_light() +
  labs(x = """",
       y = """",
       title = ""Highest TF-IDF words for top #rstats Twitter users"",
       caption = ""Source: data from {rtweet} package"") +
  scale_fill_brewer(palette = 'Paired')
```

### What are the topics and highest proability keywords for each?
```{r}
tweet_words <- tweets_parsed %>%
  count(screen_name, word, sort = TRUE) %>%
  ungroup()

tweet_dtm <- tweet_words %>%
  cast_dtm(screen_name, word, n)

tweets_lda <- LDA(tweet_dtm, k=12, control = list(seed = 2008))

tidy_lda <- tidy(tweets_lda)

top_terms <- tidy_lda %>% 
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  group_by(topic, term) %>%
  arrange(desc(beta)) %>%
  ungroup() %>%
  mutate(term = factor(paste(term, topic, sep = ""__""),
                       levels = rev(paste(term, topic, sep = ""__"")))) %>%
  ggplot(aes(term, beta, fill = as.factor(topic))) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  scale_x_discrete(labels = function(x) gsub(""__.+$"", """", x)) +
  scale_fill_brewer(palette = 'Paired') +
  labs(title = ""Top 10 terms in each LDA topic from #rstats"",
       caption = ""Source: data from {rtweet} package"",
       x = """",
       y = """") +
  theme_light() +
  facet_wrap(~topic, ncol = 4, scales = ""free"")
```
","2019-1"
"413",999,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181211-nyc_restaurants/nyc_restaurants.Rmd","Eeysirhc","tidytuesday","20181211-nyc_restaurants/nyc_restaurants.Rmd","---
title: ""TidyTuesday: NYC Restaurant Inspections""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 12/11/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-12-11

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(lubridate)
library(ebbr)

nyc_restaurants_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-11/nyc_restaurants.csv"")

nyc_restaurants <- nyc_restaurants_raw %>%
  filter(inspection_date != '01/01/1900') #%>% # filter out establishments which have not been inspected yet
  #filter(grepl(""A|B|C"", grade)) %>% # filter those without grades
  #filter(!grepl(""Missing"", boro))
```


### Does a high score equate to a high grade?
```{r}
nyc_restaurants %>%
  select(score, grade) %>%
  drop_na(score) %>%
  group_by(grade) %>%
  summarize(min = min(score),
            mean = mean(score),
            median = median(score),
            max = max(score))
   

nyc_restaurants %>%
  select(score, grade) %>%
  drop_na(score) %>%
  ggplot() + 
  geom_density(aes(score, fill = grade)) +
  theme_bw()

```

No, there is an inverse relationship between grade and score. Thus, a lower score == A (higher grade)



### What is the average score by cuisine type?
```{r}
scores <- nyc_restaurants %>%
  select(cuisine_description, score) %>%
  group_by(cuisine_description) %>%
  na.omit() %>%
  summarize(mean = mean(score),
            total = n(),
            low = qbeta(0.025, mean + 0.5, total - mean + 0.5),
            high = qbeta(0.975, mean + 0.5, total - mean + 0.5),
            segment = ifelse(mean >= 21.336, ""above"", 
                             ifelse(mean <= 17.665, ""below"", ""average""))) %>%
  na.omit()

summary(scores$mean)
#1stQ: 17.665
#3rdQ: 21.336

scores %>%
  filter(total > 100) %>%
  arrange(desc(total)) %>%
  select(cuisine_description, low, mean, high, total, segment) %>% 
  ggplot() +
  geom_point(aes(reorder(cuisine_description, -mean), mean, color = segment),
             size = 2) + 
  geom_errorbar(aes(x=cuisine_description, ymin=mean-low, ymax=mean+high, color = segment),
                size = 0.5) +
  coord_flip() +
  theme_bw(base_size = 10) +
  labs(x = """",
       y = """",
       title = ""Average inspection score for NY restaurants by cuisine"",
       subtitle = ""Best score of \""5.733\""; minimum 100 inspections per cruisine type"",
       caption = ""Source: NYC Open Data"") + 
  scale_color_brewer(palette = 'Accent', direction = -1) +
  theme(legend.position = 'none')

```



### What is the rate of inspection grade of ""A"" by cuisine type (added 12/16/2018)
```{r}
cuisine_grades <- nyc_restaurants %>%
  select(cuisine_description, grade) %>%
  na.omit() %>%
  group_by(cuisine_description) %>%
  count(grade) %>%
  mutate(total = sum(n),
         pct_total = n/total) %>%
  ungroup()

ebb_cuisine_grades <- cuisine_grades %>%
  add_ebb_estimate(n, total) %>%
  filter(grade == ""A"") %>%
  arrange(desc(.fitted)) %>%
  filter(n >= 100) %>%
  head(30) 

ebb_cuisine_grades %>%
  select(cuisine_description, ""Empirical Bayes Rate""=.fitted, ""Measured Rate""=.raw, .low, .high) %>%
  gather(key, value, -cuisine_description, -.low, -.high) %>%
  ggplot() + 
  geom_point(aes(reorder(cuisine_description, value), value, color = key), size = 3) +
  geom_errorbar(aes(ymin = .low, ymax = .high, x=cuisine_description), color = ""gray50"") +
  scale_y_continuous(labels = percent_format(round(1))) +
  coord_flip() +
  theme_minimal(base_size = 15) +
  labs(x = """",
       y = """",
       title = ""Rate of NYC restaurant inspections with a final grade of \'A\' by cuisine type"",
       subtitle = ""95% credible intervals with a minimum of 100 inspections"",
       caption = ""Source: NYC Open Data"") +
  scale_color_brewer(palette = 'Set1', direction = -1) +
  theme(legend.title=element_blank())

```





### What is the distribution of scores based on cuisine ?
```{r}
top_cuisines <- nyc_restaurants %>%
  select(cuisine_description, score) %>%
  count(cuisine_description) %>%
  arrange(desc(n)) %>%
  top_n(20)

# density by score
nyc_restaurants %>%
  select(cuisine_description, score) %>% 
  left_join(top_cuisines) %>% 
  drop_na(n) %>%
  ggplot() + 
  geom_density(aes(score, fill = cuisine_description, color = cuisine_description), 
               alpha = 0.1) +
  scale_x_log10() +
  theme_bw()

```




### Is there a difference in scores by cuisine for each boro ?
```{r}
nyc_restaurants %>%
  select(cuisine_description, boro, score) %>%
  group_by(cuisine_description, boro) %>%
  na.omit() %>%
  summarize(mean = mean(score),
            total = n(),
            low = qbeta(0.025, mean + 0.5, total - mean + 0.5),
            high = qbeta(0.975, mean + 0.5, total - mean + 0.5)) %>%
  na.omit() %>% 
  top_n(50) %>% 
  select(cuisine_description, boro, low, mean, high, total) %>% 
  ggplot() +
  geom_point(aes(reorder(cuisine_description, mean), mean)) + 
  geom_errorbar(aes(x=cuisine_description, ymin=mean-low, ymax=mean+high)) +
  coord_flip() +
  theme_bw() +
  facet_wrap(~boro)

```

","2018-50"
"414",1000,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181218-cetaceans/cetaceans.Rmd","Eeysirhc","tidytuesday","20181218-cetaceans/cetaceans.Rmd","---
title: ""TidyTuesday: Cetaceans Dataset""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 12/18/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-12-18

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(lubridate)
library(tidytext)

cetaceans_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-18/allCetaceanData.csv"")

cetaceans <- cetaceans_raw
```



```{r}
# most notable deaths between M vs F?
cetaceans %>% 
  select(sex, COD) %>%
  filter(sex != ""U"") %>%
  na.omit() %>%
  mutate(sex = replace(sex, str_detect(sex, ""F""), ""Female""), 
         sex = replace(sex, str_detect(sex, ""M""), ""Male"")) %>%
  unnest_tokens(bigram, COD, token = ""ngrams"", n = 2) %>%
  count(sex, bigram) %>%
  bind_tf_idf(bigram, sex, n) %>%
  arrange(desc(tf_idf)) %>%
  filter(tf_idf > 0.0011) %>%
  ggplot() +
  geom_col(aes(reorder(bigram, tf_idf), tf_idf, fill = sex)) +
  coord_flip() +
  scale_fill_brewer(palette = 'Set2',
                    name = """") +
  labs(x = """",
       y = """",
       title = ""Bigrams with highest TF-IDF for cause of death between Female and Male Cetacean (reported)"",
       caption = ""Source: The Pudding"") +
  theme_bw(base_size = 15) 

```



```{r}
# what is the primary cause of death between Born vs Capture?
cod_acquisition_ratio <- cetaceans %>%
  select(acquisition, COD) %>%
  filter(acquisition == 'Born' | acquisition == 'Capture') %>%
  na.omit() %>%
  mutate(COD = tolower(COD)) %>%
  count(COD, acquisition) %>%
  filter(sum(n) >= 10) %>%
  ungroup() %>%
  spread(acquisition, n, fill = 0) %>%
  mutate_if(is.numeric, funs((. + 1) / sum(. +1))) %>%
  mutate(logratio = log(Born / Capture)) %>%
  arrange(desc(logratio))
  
cod_acquisition_ratio %>%
  arrange(abs(logratio)) %>%
  group_by(logratio < 0) %>%
  top_n(10, abs(logratio)) %>%
  ungroup() %>%
  mutate(COD = reorder(COD, logratio)) %>%
  ggplot() +
  geom_col(aes(COD, logratio, fill = logratio < 0)) +
  coord_flip() +
  scale_fill_brewer(palette = 'Accent',
                    name = """", 
                    labels = c(""Born"", ""Capture"")) +
  theme_bw(base_size = 15) +
  labs(x = """",
       y = ""Log Odds Ratio (Born / Capture)"",
       title = ""Comparing the odds ratio of words for cause of death \n  between Cetacean's captured from the ocean or born in captivity (reported)"",
       caption = ""Source: The Pudding"")

```





```{r}
# group birth years by decade for better segmentation of analysis
cetaceans_age <- cetaceans %>% 
  select(species, sex, acquisition, status, birthYear, originDate, statusDate) %>% 
  mutate(statusDate = replace_na(statusDate, ""2017-05-07""), # BASED ON DATA DICTIONARY
         statusYear = year(statusDate),
         originYear = year(originDate),
         birthYear = year(as.Date(birthYear, format = ""%Y"")),
         age_years = statusYear - birthYear) %>%
  filter(age_years >= 0)


### average life span
cetaceans_age %>% 
  group_by(species) %>% 
  filter(status == 'Died', acquisition == 'Capture') %>% 
  View()

```




```{r}
# raw cause of death
cetaceans %>% 
  select(COD) %>%
  na.omit() %>%
  unnest_tokens(word, COD) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) %>%
  mutate(pct_total = n/sum(n)) %>%
  filter(n > 30) %>%
  ggplot() + 
  geom_col(aes(reorder(word, pct_total), pct_total)) +
  coord_flip() +
  theme_bw(base_size = 10) +
  labs(x = """",
       y = """",
       title = ""Top terms as reported for the cause of Cetacean death"") +
  scale_y_continuous(labels = percent_format(round(1)))

# does not give a whole lot of information so bigram may be btter

cetaceans %>% 
  select(COD) %>%
  na.omit() %>%
  unnest_tokens(bigram, COD, token = ""ngrams"", n = 2) %>%
  count(bigram, sort = TRUE) %>%
  mutate(pct_total = n/sum(n)) %>%
  filter(n > 12) %>%
  filter(bigram != ""due to"") %>%
  ggplot() + 
  geom_col(aes(reorder(bigram, pct_total), pct_total)) + 
  coord_flip() + 
  theme_bw(base_size = 10) +
  labs(x = """",
       y = """") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

# mostly old age and pneumonia but may require additional data cleaning

```

","2018-51"
"415",1001,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190115-space_launches/space_launches.Rmd","Eeysirhc","tidytuesday","20190115-space_launches/space_launches.Rmd","---
title: ""TidyTuesday: Space Launches""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-15
```{r}
# LOAD PACKAGES AND PARSE DATA
library(tidyverse)
library(RColorBrewer)
library(forcats)
library(scales)
library(ebbr)
library(grid)

launches_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")

launches <- launches_raw %>%
  filter(launch_year >= '1960')
```

### Trophy for most space launches over time?
```{r}
countries <- launches %>%
  count(state_code, sort = TRUE) %>%
  filter(n >= 100)

launches %>%
  inner_join(countries) %>%
  # INCOMING NASTY IFELSE CODE (NEED TO REFACTOR)
  mutate(state_code = ifelse(state_code == 'RU', 'Russia / Soviet Union',
                             ifelse(state_code == 'SU', 'Russia / Soviet Union', 
                                    ifelse(state_code == 'US', 'United States',
                                           ifelse(state_code == 'CN', 'China',
                                                  ifelse(state_code == 'IN', 'India',
                                                         ifelse(state_code == 'F', 'France',
                                                                ifelse(state_code == 'J', 'Japan', state_code)))))))) %>%
  ggplot() + 
  geom_density(aes(launch_year, fill = state_code, color = state_code),
               alpha = 0.2) +
  theme_light() +
  scale_color_brewer(palette = 'Set1') +
  scale_fill_brewer(palette = 'Set1') +
  labs(x = """",
       y = """",
       title = ""Distribution of space launches over time by country"",
       subtitle = ""Minimum of 100 launches"",
       caption = ""Source: The Economist"",
       fill = ""Country"",
       color = ""Country"") +
  scale_y_continuous(labels = percent_format(round(1)))
```

### Who has a better success rate: private, startup or states ?
```{r}
launches %>%
  mutate(category = ifelse(category == 'O', 1, 0)) %>%
  select(launch_year, agency_type, category) %>%
  group_by(launch_year, agency_type) %>%
  summarize(success = sum(category),
            total = n(),
            rate = success / total) %>%
  ungroup() %>%
  add_ebb_estimate(success, total) %>%
  mutate(agency_type = str_to_title(agency_type)) %>%
  ggplot() +
  geom_line(aes(launch_year, .fitted, color = agency_type), 
            size = 1) +
  geom_ribbon(aes(x = launch_year, ymin = .low, ymax = .high, fill = agency_type),
              alpha = 0.1) +
  theme_light() +
  scale_fill_brewer(palette = 'Set1') +
  scale_color_brewer(palette = 'Set1') +
  labs(x = """",
       y = """",
       caption = ""Source: The Economist"",
       title = ""Success rate of space launches by type"",
       subtitle = ""Empirical Bayes rate @ 95% credible interval"",
       color = ""Type"",
       fill = ""Type"") +
  scale_y_continuous(labels = percent_format(round(1)),
                     limits = c(0,1))
```

### Success rate for each country by agency type ?
```{r}
# APPLY EMPIRICAL BAYESIAN STATS TO DATASET
launches_parsed <- launches %>%
  mutate(category = ifelse(category == 'O', 1, 0),
         agency_type = str_to_title(agency_type)) %>%
  select(launch_year, state_code, agency_type, category) %>%
  group_by(state_code, agency_type) %>%
  summarize(success = sum(category),
         total = n(),
         rate = success / total) %>%
  ungroup() %>%
  add_ebb_estimate(success, total) 

# PLOT THE GRAPH
launches_parsed %>%  
  filter(total >= 10) %>%
  select(""Empirical Bayes Rate""=.fitted, 
         ""Measured Rate""=.raw, 
         everything()) %>%
  gather(key, value, `Empirical Bayes Rate`:`Measured Rate`) %>%
    # INCOMING NASTY IFELSE CODE (NEED TO REFACTOR)
  mutate(state_code = ifelse(state_code == 'RU', 'Russia',
                             ifelse(state_code == 'SU', 'Soviet Union', 
                                    ifelse(state_code == 'US', 'United States',
                                           ifelse(state_code == 'CN', 'China',
                                                  ifelse(state_code == 'IN', 'India',
                                                         ifelse(state_code == 'F', 'France',
                                                                ifelse(state_code == 'J', 'Japan', 
                                                                       ifelse(state_code == 'IL', 'Israel', state_code))))))))) %>%
  ggplot() +
  geom_point(aes(x=reorder(state_code, value), y=value, color = key), size = 4) +
  geom_errorbar(aes(x = state_code, ymin = .low, ymax = .high), size = 0.5, color = ""gray50"") +
  geom_hline(data=launches_parsed, aes(yintercept = median(.fitted)), color = 'salmon', linetype = 'dashed', size = 1) +
  coord_flip() +
  theme_light(base_size = 15) +
  scale_y_continuous(labels = percent_format(round(1)),
                     limits = c(0,1)) +
  labs(x = """",
       title = ""Estimated success rate of space launches per country by type"",
       subtitle = ""with 95% credible interval and 10+ launches"",
       y = """",
       caption = ""Source: The Economist"",
       color = """") +
  scale_color_brewer(palette = 'Paired', direction = -1) +
  facet_grid(agency_type~.)
  
```

```{r}
# EMPIRICAL BAYES MIXTURE MODELING AND EXPECTATION-MAXIMIZATION
rockets <- launches %>%
  select(type, state_code, category) %>%
  mutate(category = ifelse(category == 'O', 1, 0)) %>%
  group_by(type, state_code) %>%
  summarize(success = sum(category),
         total = n()) %>%
  ungroup() %>%
  add_ebb_estimate(success, total) 

mm <- ebb_fit_mixture(rockets, success, total, clusters = 5)

# CHECK INITIAL RESULTS
ggplot(mm$assignments, aes(success / total, fill = .cluster)) +
  geom_histogram(position = 'identity', alpha = 0.8, binwidth = .05) 

launches %>%
  inner_join(mm$assignments) %>%
  mutate(.cluster = ifelse(.cluster == '1', 'Excellent', 
                           ifelse(.cluster == '2', 'Horrible',
                                  ifelse(.cluster == '3', 'Good',
                                         ifelse(.cluster == '4', 'Bad',
                                                ifelse(.cluster == '5', 'Average', .cluster))))),
         .cluster = fct_relevel(.cluster, c(""Excellent"", ""Good"", ""Average"", ""Bad"", ""Horrible"")),
         state_code = ifelse(state_code == 'RU', 'Russia / USSR',
                             ifelse(state_code == 'SU', 'Russia / USSR', 
                                    ifelse(state_code == 'US', 'United States',
                                           ifelse(state_code == 'CN', 'China',
                                                  ifelse(state_code == 'IN', 'India',
                                                         ifelse(state_code == 'F', 'France',
                                                                ifelse(state_code == 'J', 'Japan', 
                                                                       ifelse(state_code == 'IL', 'Israel', state_code))))))))) %>%
  group_by(launch_year, .cluster) %>%
  mutate(count = n()) %>%
  filter(grepl(""China|France|Japan|Russia|United"", state_code)) %>%
  ggplot() +
  geom_col(aes(launch_year, count, fill = .cluster), position = 'fill') +
  facet_grid(state_code~.) +
  theme_light(base_size = 15) +
  scale_fill_brewer(palette = 'Spectral', direction = -1) +
  labs(x = """",
       y = """",
       title = ""Composition of space launch performance by country"",
       subtitle = ""Assigned via mixture modeling and expectation-maximization"",
       caption = ""Source: The Economist"",
       fill = ""Cluster"") +
  scale_y_continuous(labels = percent_format())
```
","2019-3"
"416",1002,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190205-housing_prices/app.R","Eeysirhc","tidytuesday","20190205-housing_prices/app.R","
# Author: https://twitter.com/Eeysirhc
# Data project for tidytuesday week of 2/5/2019
# Source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-02-05

# LOAD PACKAGES
library(tidyverse)
library(scales)
library(shiny)

# PARSE DATA
state_hpi_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")
state_hpi <- state_hpi_raw %>%
  group_by(state, year) %>%
  summarize(us_avg = mean(us_avg),
            price_index = mean(price_index)) %>%
  mutate(pct_diff = (price_index / us_avg) - 1,
         segment = ifelse(pct_diff > 0, 'above', 'below'),
         segment = str_to_title(segment))



# UI 
ui <- fluidPage(
  ""Housing Price Index: US Average vs State"",
  selectInput(inputId = ""select_state"",
              label = ""Choose a state"",
              c(state.abb)),
  plotOutput(""hpi1""),
  plotOutput(""hpi2"")
)



# SERVER
server <- function(input, output, session) {
  
  output$hpi1 <- renderPlot({
    state_hpi %>%
      filter(state == input$select_state) %>%
      group_by(year, state) %>%
      summarize(price_index = mean(price_index),
                us_avg = mean(us_avg)) %>% 
      ggplot() +
      geom_line(aes(year, price_index), size = 2, color = 'steelblue') +
      geom_col(aes(year, us_avg), alpha = 0.3, fill = 'grey54') +
      theme_bw() +
      labs(x = NULL,
           y = ""Housing Price Index"") + 
      theme_bw(base_size = 15) + 
      scale_y_continuous(limits = c(0,300)) 
  })
  
  output$hpi2 <- renderPlot({
    state_hpi %>%
      filter(state == input$select_state) %>%
      ggplot() + 
      geom_col(aes(year, pct_diff, fill = segment), alpha = 0.8) +
      geom_hline(yintercept = 0, lty = 'dashed') +
      scale_fill_brewer(palette = 'Set1', direction = -1) +
      scale_y_continuous(labels = percent_format(round(1))) +
      theme_bw(base_size = 15) +
      theme(legend.position = 'top') +
      labs(x = NULL,
           y = ""Difference to US Average"",
           fill = NULL,
           caption = ""\n Source: Freddie Mac House Price Index\n Author: eeysirhc"")
    })  
}



# APP
shinyApp(ui, server)
","2019-6"
"417",1003,"https://github.com/Eeysirhc/tidytuesday/blob/master/20181204-medium_articles/medium_articles.Rmd","Eeysirhc","tidytuesday","20181204-medium_articles/medium_articles.Rmd","---
title: ""TidyTuesday: Medium Article Metadata""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 12/4/2018

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-12-04

```{r}
# load packages and parse data
library(tidyverse)
library(scales)
library(RColorBrewer)
library(forcats)
library(ggcorrplot)
library(tidytext)
library(stringr)

articles_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-04/medium_datasci.csv"")

articles <- articles_raw
```

### Who are the top authors in terms of total articles?
```{r}
top_authors <- articles %>%
  select(author) %>%
  group_by(author) %>%
  count() %>%
  arrange(desc(n)) %>%
  na.omit() %>%
  head(10)

top_authors %>%
  ggplot() + 
  geom_col(aes(reorder(author, n), n), 
           fill = ""darkslategray4"",
           alpha = 0.8) + 
  coord_flip() +
  theme_bw(base_size = 15) +
  labs(x = """",
       y = """",
       title = ""Top 10 authors on Medium in terms of total articles published"")
```

### Are there differences in words used between the titles and subtitles for articles ?
```{r}
data(stop_words)

tidy_authors <-
  articles %>%
  inner_join(top_authors) %>%
  select(title, subtitle, author) %>%
  na.omit() %>%
  mutate(text = paste(title, "" "", subtitle)) %>%
  select(author, text) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)

tidy_authors %>%
  group_by(author) %>%
  mutate(word = str_extract(word, ""[a-z']+"")) %>%
  count(word, sort = TRUE) %>%
  mutate(proportion = n / sum(n)) %>%
  select(-n) %>%
  spread(author, proportion) %>% 
  gather(author, proportion, `AI Hawk`:`Synced`) %>%
  ggplot(aes(x=proportion, y=`Yves Mulkers`, color = abs(`Yves Mulkers` - proportion))) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1, hjust = 1) +
  geom_abline(color = ""darkslategray4"", linetype = 2) +
  scale_color_gradient(limits = c(0, 0.01), 
                       low = ""salmon"", high = ""blue"") +
  scale_x_log10(labels = percent_format(round(1))) +
  scale_y_log10(labels = percent_format(round(1))) +
  labs(y = ""Yves Mulkers"",
       x = """",
       title = ""Comparing the word frequencies for the top 10 authors on Medium (title & subtitle only)"",
       subtitle = "" \""Top 10\"" defined as the total number of articles published"") +
  theme_bw(base_size = 15) +
  theme(legend.position = ""none"") +
  facet_wrap(~author, ncol = 3)
```


### Is there a relationship between reading time and claps by article?
```{r}
# Plot to see if there are any trends
articles %>%
  select(reading_time, claps, tag_ai:tag_machine_learning) %>%
  gather(tag = tag_ai:tag_machine_learning) %>% 
  select(-value) %>% 
  group_by(key, reading_time) %>%
  summarize(claps = sum(claps)) %>% 
  ggplot(aes(reading_time, claps, fill = key)) + 
  geom_col() +
  facet_wrap(~key) +
  scale_y_continuous(labels = comma_format()) +
  scale_x_continuous(limits = c(0,25)) +
  theme_bw() + 
  theme(legend.position = 'none') +
  labs(x = """",
       y = """",
       title = ""Relationship between reading time of article and total number of claps"",
       subtitle = ""The 'sweet spot' is 5 minutes"")

# What about correlation?
articles_tags <- 
  articles %>%
  select(reading_time, claps, tag_ai:tag_machine_learning) 
articles_correlations <- round(cor(articles_tags), 1)

ggcorrplot(articles_correlations, hc.order = TRUE, 
           type = ""lower"", 
           lab = TRUE, 
           lab_size = 3, 
           method=""circle"", 
           colors = c(""salmon"", ""white"", ""steelblue""), 
           title=""Correlogram of article tags"", 
           ggtheme=theme_bw)

# No clear relationship but perhaps there might be something between the different tags ?
```
","2018-49"
"418",1004,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190122-incarceration_trends/incarceration_trends.Rmd","Eeysirhc","tidytuesday","20190122-incarceration_trends/incarceration_trends.Rmd","---
title: ""TidyTuesday: Incarceration Trends""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 1/22/2019 ([source](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-22))

```{r}
# LOAD PACKAGES AND PARSE DATA
library(tidyverse)
library(scales)
library(lubridate)
library(RColorBrewer)

prison_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/prison_population.csv"")

# DELETE THIS LATER
prison %>% 
  write_csv(""prison_population.csv"")

prison <- prison_raw
```


```{r}
# PROCESS RAW DATA
total <- prison %>%
  filter(pop_category != 'Total' & pop_category != 'Male' & pop_category != 'Female') %>% 
  select(county_name, urbanicity, pop_category, population, prison_population) %>%
  na.omit() %>% 
  group_by(county_name, urbanicity, pop_category) %>%
  summarize(population = sum(population),
            prison_population = sum(prison_population)) %>%
  ungroup() %>%
  group_by(county_name, urbanicity) %>%
  mutate(pct_population = population / sum(population),
         pct_prisoner = prison_population / sum(prison_population))
```

### What is the proportion of population:prisoners per demographic ?
```{r}
total %>%
  filter(pop_category != 'Other') %>%
  ggplot() + 
  geom_point(aes(pct_population, pct_prisoner),
             alpha = 0.1, size = 2, color = 'grey') +
  geom_smooth(aes(pct_population, pct_prisoner, color = pop_category),
              size = 1.2,
             se = FALSE) +
  theme_light(base_size = 15) +
  scale_y_continuous(labels = percent_format()) +
  scale_x_continuous(labels = percent_format()) +
  labs(x = ""County Population"",
       y = ""Prisoner Population"",
       color = """",
       title = ""Comparison of county to prison population by ethnicity from 1970 to 2016"",
       subtitle = ""Specific groups are overrepresented in the prisoner population"",
       caption = ""Source: Vera Institute of Justice"") +
  geom_abline(linetype = 'dashed') +
  scale_color_brewer(palette = 'Set1') +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        legend.position = 'top',
        panel.background = element_rect(fill = 'gray97',
                                        color = 'gray97',
                                        size = 0.5, linetype = 'solid'))
```


### Does urbanicity play a role ?
Answer: variations between different races but long answer short...not really.
```{r}
total %>%
  filter(pop_category != 'Other') %>%
  ggplot() + 
  geom_point(aes(pct_population, pct_prisoner),
             alpha = 0.1, size = 2, color = 'grey') +
  geom_smooth(aes(pct_population, pct_prisoner, color = urbanicity),
              se = FALSE) +
  theme_light() +
  scale_y_continuous(labels = percent_format()) +
  scale_x_continuous(labels = percent_format()) +
  labs(x = ""County Population (%)"",
       y = ""Prisoner Population (%)"",
       color = ""Urbanicity"") +
  facet_wrap(~pop_category) +
  geom_abline(linetype = 'dashed')
```
","2019-4"
"419",1005,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190305-women_workforce/women_workforce.Rmd","Eeysirhc","tidytuesday","20190305-women_workforce/women_workforce.Rmd","---
title: ""TidyTuesday: Women in the Workforce""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 3/05/2019 ([source](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-03-05))

```{r}
library(tidyverse)
library(scales)
library(lubridate)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")
```

```{r}
jobs_gender %>%
  filter(year == '2016') %>%
  mutate(male_diff = ((((total_earnings_male/total_earnings)-1)*workers_male)/total_workers),
         female_diff = (((total_earnings_female/total_earnings)-1)*workers_female)/total_workers) %>%
  ggplot() +
  geom_jitter(aes(total_earnings, female_diff), 
              color = 'salmon',
              alpha = 0.5,
              size = 2.5) +
  geom_jitter(aes(total_earnings, male_diff), 
              color = 'steelblue',
              alpha = 0.5, 
              size = 2.5) +
  geom_hline(yintercept = 0, color = 'grey54', lty = 'dashed') +
  facet_wrap(~major_category) +
  scale_x_continuous(labels = dollar_format(),
                     limits = c(0,200000)) +
  scale_y_continuous(labels = percent_format(round(1)),
                     limits = c(-0.3,0.3)) +
  labs(x = ""Average Median Earnings"",
       y = ""Difference from Average"",
       caption = ""Graphic: @eeysirhc\nSource: Bureau of Labor Statistics"",
       title = ""2016 Earnings Differences (Weighted) by Job Sector"",
       subtitle = ""Blue = Male; Red = Female"") +
  theme_bw(base_size = 15) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        plot.subtitle = element_text(size = 12),
        legend.position = 'none')
```

","2019-10"
"420",1006,"https://github.com/Eeysirhc/tidytuesday/blob/master/20190108-tv_golden_age/tv_golden_age.Rmd","Eeysirhc","tidytuesday","20190108-tv_golden_age/tv_golden_age.Rmd","---
title: ""R Notebook""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Analyzing data for #tidytuesday week of 01/08/2019

source: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-08

```{r}
# LOAD PACKAGES AND PARSE DATA

library(tidyverse)
library(RColorBrewer)
library(forcats)
library(lubridate)
library(broom)

tv_data_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"")

tv_data <- tv_data_raw
```

```{r}
# K-MEANS CLUSTERING
tv_data_summarized <- tv_data %>%
  group_by(title, genres, date) %>%
  summarize(min_rating = min(av_rating),
            avg_rating = mean(av_rating),
            max_rating = max(av_rating),
            min_share = min(share),
            avg_share = mean(share),
            max_share = max(share)) %>%
  ungroup()

kclust_data <- tv_data_summarized %>%
  select(-title, -genres, -date)

kclust_results <- kmeans(kclust_data, center = 9)
```

```{r}
# CHECK OUTPUT DATA
tv_data_summarized %>%
  left_join(augment(kclust_results, kclust_data)) %>%
  mutate(title = factor(title)) %>%
  group_by(.cluster) %>%
  ggplot() +
  geom_boxplot(aes(.cluster, avg_rating, fill = .cluster),
               show.legend = FALSE,
               alpha = 0.5) +
  theme_light() +
  labs(x = ""Cluster #"",
       y = ""Average Rating"",
       caption = ""Source: The Economist"",
       title = ""Average rating distribution for each cluster assignment"") +
  scale_fill_brewer(palette = 'Paired')

tv_data_summarized %>%
  left_join(augment(kclust_results, kclust_data)) %>%
  mutate(title = factor(title)) %>%
  group_by(.cluster) %>%
  ggplot(aes(avg_rating, log10(avg_share)+1, color = .cluster)) +
  geom_point(alpha = 0.7, size = 3, show.legend = FALSE) +
  theme_light() +
    labs(x = ""Average Rating"",
       y = ""Share (log10)"",
       caption = ""Source: The Economist"",
       title = ""Relationship between Average Rating and Shares by cluster assignment"") +
  scale_fill_brewer(palette = 'Paired')
```

```{r}
# FINALIZE PLOT
tv_data_summarized %>%
  left_join(augment(kclust_results, kclust_data)) %>%
  mutate(title = factor(title),
         five_years = 5 * (year(date) %/% 5 )) %>%
  group_by(.cluster) %>%
  top_n(20, avg_rating) %>%
  ggplot(aes(avg_rating, log10(avg_share)+1, label = title, color = .cluster)) + 
  geom_text(show.legend = FALSE) +
  facet_wrap(~five_years) +
  theme_light() +
  labs(x = ""Average Rating"",
       y = ""Share (log10)"",
       caption = ""Source: The Economist"",
       title = ""Top TV Shows Every 5yrs by Average Rating and Shares (log10)"",
       subtitle = ""Note: duplicates indicate multiple seasons"") 
```
","2019-2"
"421",1007,"https://github.com/abichat/tidytuesday/blob/master/scripts/script_2019-07-02.R","abichat","tidytuesday","scripts/script_2019-07-02.R","library(gameofthrones)
library(ggchicklet)
library(hrbrthemes)
library(tidyverse)
library(glue)

#### Data ####

media_franchises <- 
  read_csv(""data/data_2019-07-02.csv"", col_types = ""ccddccc"") %>% 
  unique()


#### Table ####

df_biggest <- 
  media_franchises %>%
  group_by(franchise, revenue_category, year_created) %>%
  summarise(revenue = sum(revenue)) %>%
  ungroup() %>%
  mutate(revenue_category = fct_reorder(revenue_category, 
                                        revenue, sum, .desc = TRUE),
         franchise = fct_lump(franchise, n = 15, w = revenue)) %>%
  filter(franchise != ""Other"") %>%
  mutate(franchise = str_remove_all(franchise, ""^.*/ ""), 
         franchise = str_remove_all(franchise, "" &.*$""), 
         franchise = glue(""{franchise} ({year_created})""),
         franchise = fct_reorder(franchise, revenue, sum)) %>% 
  filter(revenue > 0.5)


#### Plot ####

ggplot(df_biggest) +
  aes(x = franchise, y = revenue, fill = revenue_category) +
  geom_chicklet(width = 0.75, color = NA, radius = grid::unit(4, ""pt"")) +
  scale_fill_got_d(option = ""Daenerys"") +
  coord_flip() +
  guides(fill = guide_legend(override.aes = list(size = 10))) +
  labs(x = NULL, y = ""Revenue (B$)"", fill = NULL, 
       title = ""Highest Grossing Media Franchises"", 
       caption = ""Source: Wikipedia\n@_abichat for #TidyTuesday"") +
  theme_ft_rc() +
  theme(legend.position = c(0.8, 0.3),
    plot.title = element_text(color = ""#929299"", hjust = 0.5, size = 25),
    axis.title.x = element_text(size = 18),
    axis.text.x = element_text(size = 14),
    axis.text.y = element_text(size = 14),
    legend.text = element_text(size = 15),
    plot.caption = element_text(size = 10),
    plot.margin = margin(15, 15, 15, 15))

ggsave(""plots/plot_2019-07-02.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019-27"
"422",1009,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-03-19.R","library(tidyverse)
library(ggimage)
library(sf)

##### Data ####

combined_data <- read_csv(""data/data_2019-03-19.csv"", col_types = ""cccdddddddd"")


#### Function ####

plot_pie <- function(df) {
  ggplot(df) +
    aes(x = 0, y = stops_per_year, fill = driver_race) +
    geom_col(position = ""fill"", show.legend = FALSE, color = ""grey30"") +
    coord_polar(theta = ""y"") +
    scale_fill_manual(values = c(Black = ""#3C2C2B"", Hispanic = ""#B27A58"", 
                                 White = ""#F8DED2"")) +
    theme_void() +
    theme_transparent()
}


#### Get maps ####

sf_connecticut <-
  maps::map(""county"", plot = FALSE, fill = TRUE) %>%
  st_as_sf() %>%
  separate(ID, into = c(""state"", ""county""), sep = "","") %>% 
  filter(state == ""connecticut"")

mat_coord_cent <-
  sf_connecticut %>%
  st_centroid() %>%
  arrange(county) %>%
  st_coordinates()

sf_adjacent <-
  maps::map(""state"", plot = FALSE, fill = TRUE) %>%
  st_as_sf() %>%
  filter(ID %in% c(""connecticut"", ""massachusetts"",
                   ""new york"", ""rhode island""))


#### Tables ####

data_CT <-
  combined_data %>%
  filter(state == ""CT"") %>%
  select(location, driver_race, stops_per_year)

df_pie <-
  data_CT %>%
  arrange(location) %>%
  group_by(location) %>%
  nest() %>%
  mutate(total = map_dbl(data, ~ sum(pull(., stops_per_year))),
         total = total / 10 ^ 5 / 1.1,
         pie = map(data, plot_pie)) %>%
  mutate(x = mat_coord_cent[, 1],
         y = mat_coord_cent[, 2])


#### Plots ####

p_legend <-
  ggplot(df_pie$data[[1]]) +
  aes(x = 0, y = stops_per_year, fill = driver_race) +
  geom_col(position = ""fill"",color = ""grey30"") +
  scale_fill_manual(values = c(Black = ""#3C2C2B"", Hispanic = ""#B27A58"", 
                               White = ""#F8DED2"")) +
  guides(fill = guide_legend(title = ""Driver race"")) +
  theme(legend.background = element_rect(fill=""#d2ecf8""))

leg <- cowplot::get_legend(p_legend)

df_pie <-
  df_pie %>% 
  add_row(total = 0.5, pie = list(leg), x = -71.75, y = 41.1)

p <-
  ggplot() +
  geom_sf(data = sf_adjacent, fill = ""#f8f1d2"") +
  geom_sf(data = sf_connecticut, fill = ""#d2f8de"") +
  coord_sf(xlim = c(-73.7, -71.75), ylim = c(41.05, 42.05)) +
  theme_void() +
  theme(panel.background = element_rect(fill = ""#d2ecf8"", color = ""grey30""),
        panel.grid = element_line(colour = NA),
        plot.title = element_text(hjust = 0.5, face = ""bold"", 
                                  size = 20, lineheight = 0.1),
        plot.caption = element_text(size = 12)) +
  labs(title = ""\nRepartition of annual traffic stops by race in Connecticut\n"",
       caption = ""Source: Stanford Open Policing Project\n@_abichat for #TidyTuesday\n"")

p + geom_subview(data = df_pie, aes(x = x, y = y, subview = pie, 
                                    width = total, height = total))

ggsave(""plots/plot_2019-03-19.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019-12"
"423",1010,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-03-26.R","library(tidyverse)
library(ggwordcloud)
library(patchwork)

#### Data ####

seattle_pets <- read_csv(""data/data_2019-03-26.csv"", col_types = ""ccccccc"")


#### Table ####

data_count <-
  seattle_pets %>%
  drop_na(animals_name) %>%
  count(species, animals_name, sort = TRUE) %>%
  filter(n > 5) %>%
  group_split(species)


#### Plots ####

p_cat <-
  ggplot(data_count[[1]]) +
  aes(label = animals_name, size = n, color = n) +
  geom_text_wordcloud_area(mask = png::readPNG(""ressources/img_2019-03-26_cat.png""), 
                           rm_outside = TRUE) +
  theme_minimal() +
  scale_color_gradient(low = ""darkblue"", high = ""blue"")

p_dog <-
  ggplot(data_count[[2]]) +
  aes(label = animals_name, size = n, color = n) +
  geom_text_wordcloud_area(mask = png::readPNG(""ressources/img_2019-03-26_dog.png""), 
                           rm_outside = TRUE) +
  theme_minimal() +
  scale_color_gradient(low = ""darkred"", high = ""red"")

p_all <-
  p_dog + p_cat + 
  plot_annotation(title = ""Most used names for dogs and cats in Seattle"",
                  caption = ""Source: Seattle's open data portal\n@_abichat for #TidyTuesday"",
                  theme = theme(text = element_text(size = 12, family = ""Arial Rounded MT Bold""),
                                plot.title = element_text(hjust = 0.5, face = ""bold"", 
                                                          size = 20, lineheight = 0.1)))

set.seed(42)
ggsave(plot = p_all, ""plots/plot_2019-03-26.png"", width = 29, height = 12, units = ""cm"", dpi = ""retina"")

","2019-13"
"424",1011,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-02.R","library(tidyverse)
library(lubridate)

#### Data ####

bike_traffic <- read_csv(""data/data_2019-04-02.csv"", col_types = ""cccdd"")


#### Functions ####

my_max <- partial(max, na.rm = TRUE)
my_mean <- partial(mean, na.rm = TRUE)


#### Tables ####

traffic <-
  bike_traffic %>%
  mutate(date = mdy_hms(date)) %>%
  filter(crossing != ""Sealth Trail"") %>%
  mutate(
    year = year(date),
    month = month(date, label = TRUE, abbr = FALSE),
    week = week(date),
    weekday = weekdays(date),
    crossing = fct_reorder(crossing, bike_count, my_max, .desc = TRUE)
  )

traffic_per_month <-
  traffic %>%
  group_by(year, month, crossing) %>%
  summarise(day = mean(date), total_bike = my_mean(bike_count))

traffic_per_week <-
  traffic %>%
  group_by(year, month, week, crossing) %>%
  summarise(day = mean(date), total_bike = my_mean(bike_count))

traffic_per_day <-
  traffic %>%
  group_by(year, month, week, weekday, crossing) %>%
  summarise(day = mean(date), total_bike = my_mean(bike_count))


#### Plot ####

ggplot(traffic_per_day) +
  aes(x = day, y = total_bike, group = crossing) +
  geom_line(color = ""#a57259"", alpha = 0.3) +
  geom_line(data = traffic_per_week, color = ""#a57259"") +
  geom_line(data = traffic_per_month, color = ""#73503e"") +
  scale_y_continuous(limits = c(NA, 80)) +
  facet_wrap(~ crossing) +
  labs(x = ""Date"", y = ""Average number of bikes per hour"",
       title = ""Use of bike lanes in Seattle"", 
       subtitle = ""Smoothed per day, week and month"",
       caption = ""Source: Seattle Department of Transportation\n@_abichat for #TidyTuesday"") +
  ggthemes::theme_economist()

ggsave(""plots/plot_2019-04-02.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019-14"
"425",1012,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-09.R","library(tidyverse)
library(gganimate)

#### Data ####

grand_slam_timeline <- read_csv(""data/data_2019-04-09.csv"", col_types = ""cdccc"")


#### Tables ####

ordered_outcomes <-c(""Absent"", ""Lost Qualifier"", ""Qualification Stage 1"", 
                     ""Qualification Stage 2"", ""1st Round"", ""2nd Round"", 
                     ""3rd Round"", ""4th Round"", ""Quarterfinalist"", 
                     ""Semi-finalist"", ""Finalist"", ""Won"")

df_frenchOpen <-
  grand_slam_timeline %>%
  mutate(outcome = as_factor(outcome)) %>%
  mutate(player = str_remove_all(player, ""^/* "")) %>%
  filter(tournament == ""French Open"") %>%
  group_by(player) %>%
  mutate(
    winner = ""Won"" %in% outcome,
    begining = min(year),
    median = median(year)
  ) %>%
  ungroup() %>%
  filter(winner == TRUE) %>%
  mutate(
    outcome = fct_explicit_na(outcome, ""Absent""),
    outcome = fct_collapse(outcome, Absent = c(""Retired"")),
    outcome = fct_relevel(outcome, ordered_outcomes)
  )

ordered_players <-
  df_frenchOpen %>% 
  arrange(median, begining) %>% 
  pull(player) %>% 
  unique()

df_frenchOpen <- mutate(df_frenchOpen,
                        player = factor(player, level = ordered_players))


#### Plot ####

p <-
  df_frenchOpen %>%
  ggplot() +
  aes(x = year, y = outcome, group = player) +
  geom_line(aes(color = gender), show.legend = FALSE) +
  geom_point() +
  labs(x = ""Year"", y = ""Outcome"",
       title = ""Outcomes at Roland-Garros for {closest_state}"",
       caption = ""Source: Wikipedia\n@_abichat for #TidyTuesday"") +
  theme_minimal() +
  theme(plot.margin = margin(5.5, 9, 5.5, 5.5),
        plot.title = element_text(face = ""bold""))

anim <-
  p +
  transition_states(player) +
  enter_fade() +
  exit_fade()

animate(anim, nframes = 12 * length(ordered_players))

anim_save(""plots/plot_2019-04-09.gif"")
","2019-15"
"426",1013,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-23.R","library(tidyverse)
library(lubridate)
library(ggpomological)

#### Data ####

anime <- read_csv(""data/data_2019-04-23.csv"")


#### Tables ####

df_movies <-
  anime %>%
  filter(type == ""Movie"") %>% 
  select(title_english, start_date, score, scored_by, source) %>% 
  filter(scored_by > 10000) %>% 
  drop_na() %>% 
  unique() %>% 
  mutate(year = year(start_date)) %>% 
  mutate(ntop = dense_rank(desc(score)), 
         nbot = dense_rank(score)) %>% 
  arrange(ntop) %>% 
  filter(ntop %in% 1:10 | nbot %in% 1:10) %>% 
  mutate(title_english = fct_reorder(title_english, score),
         source = fct_collapse(source, 
                               ""Other"" = ""Other"", 
                               ""Other"" = ""Unknown"", 
                               ""Novel"" = ""Light novel""))

middle <- mean(range(df_movies$score))
min <- min(range(df_movies$score))
max <- max(range(df_movies$score))

seg_top <-
  seq(middle, max, length.out = 100) %>%
  tibble(x = ., xend = lag(x)) %>%
  drop_na() %>%
  mutate(alpha = 0.5 + (row_number() - 1) / (2 * n()))

df_seg_top <-
  df_movies %>%
  select(title_english, score) %>%
  filter(score > middle) %>%
  mutate(data = rerun(n(), seg_top)) %>%
  unnest(data) %>%
  filter(xend < score)

seg_bot <-
  seq(min, middle, length.out = 100) %>%
  tibble(xend = ., x = lead(xend)) %>%
  drop_na() %>%
  mutate(alpha = 1 - (row_number() - 1) / (2 * n()))

df_seg_bot <-
  df_movies %>%
  select(title_english, score) %>%
  filter(score < middle) %>%
  mutate(data = rerun(n(), seg_bot)) %>%
  unnest(data) %>%
  filter(x > score)

df_seg <- bind_rows(df_seg_bot, df_seg_top)


#### Plot ####

ggplot(df_movies) +
  aes(x = score, y = title_english) +
  geom_segment(data = df_seg, aes(x = x, y = title_english, xend = xend, 
                                  yend = title_english, alpha = alpha),
               size = 1) +
  geom_segment(data = df_seg, aes(x = x, y = title_english, xend = xend, 
                                  yend = title_english, alpha = alpha ), 
               size = 1) +
  geom_point(aes(fill = source, shape = source), size = 3.5) +
  geom_label(aes(x = middle, label = title_english, fill = source), 
             color = ""white"", show.legend = FALSE, 
             size = 4, family = ""Luminari"") +
  labs(x = ""Score (out of 10)"", y = NULL, 
       fill = ""Type"", shape = ""Type"", 
       title = ""Best and worst anime movies"", 
       caption = ""Source: MyAnimeList\n@_abichat for #TidyTuesday"") +
  theme_pomological_plain() +
  guides(alpha = FALSE) +
  scale_shape_manual(values = 21:25) +
  scale_fill_pomological() +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = ""bottom"",
    text = element_text(size = 15, family = ""Luminari""),
    plot.title = element_text(hjust = 0.5, face = ""bold"", size = 20)
  )

ggsave(""plots/plot_2019-04-23.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019-17"
"427",1014,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-04-30.R","library(harrypotter)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(ggimage)
library(cowplot)
library(ggtree)
library(yatah)

#### Data ####

bird_collisions <-
  read_csv(""data/data_2019-04-30.csv"") %>%
  mutate(species = paste(genus, species))
  
months <- 
  as_factor(c(""January"", ""February"", ""March"", ""April"", 
              ""May"", ""June"", ""July"", ""August"", ""September"", 
              ""October"", ""November"", ""December"")) 

font <- ""Trattatello""


#### Tables and data ####

collision_per_month <-
  bird_collisions  %>%
  mutate(month = months[month(date)], 
         month = fct_drop(month),
         monthyear = floor_date(date, unit = ""month"")) %>% 
  count(species, month, monthyear) %>% 
  group_by(species, month) %>% 
  summarise(mean = mean(n)) %>% 
  ungroup()

most_collision_per_month <- 
  collision_per_month %>% 
  group_by(species) %>% 
  summarise(total = sum(mean)) %>% 
  top_n(n = 15)

ymax <- max(most_collision_per_month$total)

species_most <- most_collision_per_month$species

taxonomy <-
  bird_collisions %>% 
  select(family, genus, species) %>% 
  filter(species %in% species_most) %>% 
  taxtree(root = ""Passerine"")


#### Plots ####

# Insets

ggcol_inset <- function(df) {
  s <- round(sum(df$mean))
  ggplot(df) +
    aes(x = 0, y = mean, fill = month) +
    geom_col(position = position_stack(reverse = T)) +
    geom_text(x = 0, y = s, label = s, family = font, hjust = -0.2) +
    scale_fill_hp(discrete = TRUE, option = ""HarryPotter"", 
                  name = """", direction = -1, drop = FALSE) +
    ylim(c(0, ymax + 1)) +
    coord_flip() +
    theme_inset()
}

splitlist <-
  collision_per_month %>% 
  filter(species %in% species_most) %>% 
  group_by(species) %>% 
  group_split() %>% 
  set_names(species_most) %>% 
  `[`(taxonomy$tip.label) %>% 
  set_names(seq_along(species_most))

inset_cols <- map(splitlist, ggcol_inset)


# Legend

p_legend <-
  splitlist[[1]] %>% 
  ggplot() +
  aes(x = 0, y = mean, fill = month) +
  geom_col(position = position_stack(reverse = T)) +
  scale_fill_hp(discrete = TRUE, option = ""HarryPotter"", 
                name = """", direction = -1, drop = FALSE) +
  theme_wsj() +
  theme(legend.text = element_text(family = font, size = 15), 
        legend.direction = ""vertical"", legend.box = ""vertical"") 

legend <- get_legend(p_legend)


# Taxonomy

ptree <-
  ggtree(taxonomy, alpha = 0.8, color = ""grey"") +
  geom_nodelab(geom = ""label"", family = font, size = 4) +
  geom_tiplab(hjust = 1, vjust = -0.6, family = font, size = 5)


# Final plot

inset(ptree, inset_cols, width = 1, height = 1, hjust = -0.46) + 
  geom_subview(x = 1.75, y = 4.5, subview = legend) +
  xlim(NA, 1.88) +
  labs(title = ""\n\nNumber of bird collisions per month in Chicago\n"",
       caption = ""Source: Winger et al, 2019\n@_abichat for #TidyTuesday"") +
  theme_wsj() +
  theme(plot.title = element_text(family = font, hjust = 0.5, 
                                  face = ""bold"", size = 25,
                                  lineheight = 0.1), 
        plot.caption = element_text(family = font, size = 15), 
        panel.grid = element_blank(), axis.text = element_blank(),
        axis.line = element_blank(), axis.ticks = element_blank())

ggsave(""plots/plot_2019-04-30.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")




","2019-18"
"428",1015,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-07.R","library(tidyverse)
library(cowplot)
library(scales)

#### Data ####

student_ratio <- read_csv(""data/data_2019-05-07.csv"", col_types = ""ccccddcc"")

oecd <-
  tribble(~country, ~shortname,
          ""Australia"", ""Australia"",
          ""Austria"", ""Austria"",
          ""Belgium"", ""Belgium"",
          ""Canada"", ""Canada"",
          ""Chile"", ""Chile"",
          ""Czechia"", ""Czechia"",
          ""Denmark"", ""Denmark"",
          ""Estonia"", ""Estonia"",
          ""Finland"", ""Finland"",
          ""France"", ""France"", 
          ""Germany"", ""Germany"",
          ""Greece"", ""Greece"",
          ""Hungary"", ""Hungary"",
          ""Iceland"", ""Iceland"",
          ""Ireland"", ""Ireland"", 
          ""Israel"", ""Israel"",
          ""Italy"", ""Italy"",
          ""Japan"", ""Japan"",
          ""Republic of Korea"", ""South Korea"",
          ""Latvia"", ""Latvia"", 
          ""Lithuania"", ""Lithuania"", 
          ""Luxembourg"", ""Luxembourg"",
          ""Mexico"", ""Mexico"", 
          ""Netherlands"", ""Netherlands"",
          ""New Zealand"", ""New Zealand"",
          ""Norway"", ""Norway"", 
          ""Poland"", ""Poland"", 
          ""Portugal"", ""Portugal"", 
          ""Slovakia"", ""Slovakia"", 
          ""Slovenia"", ""Slovenia"", 
          ""Spain"", ""Spain"", 
          ""Sweden"", ""Sweden"", 
          ""Switzerland"", ""Switzerland"",
          ""Turkey"", ""Turkey"",
          ""United Kingdom of Great Britain and Northern Ireland"", ""UK"",
          ""United States of America"", ""USA"")


#### Table ####

df_oecd <-
  student_ratio %>%
  inner_join(oecd, by = ""country"") %>%
  filter(indicator == ""Primary Education"") %>%
  mutate(shortname = fct_reorder(shortname, student_ratio, .desc = TRUE))


#### Plot ####

p_ocde <-
  ggplot(df_oecd) +
  aes(x = student_ratio, y = shortname) +
  geom_point(color = ""grey90"", alpha = 0.7, size = 3) +
  scale_x_continuous(breaks = pretty_breaks()) +
  annotate(""text"", x = 21, y = 25, size = 8, family = ""MV Boli"", color = ""grey90"", 
           label = ""Average number of students per professor\nin primary school for OECD members"") +
  labs(x = ""Ratio"", y = NULL,
       caption = ""Source: UNESCO Institute of Statistics\n@_abichat for #TidyTuesday"") +
  theme(panel.grid.major = element_line(color = ""grey80"", size = 0.05), 
        axis.ticks = element_blank(), 
        axis.line = element_blank(), 
        text = element_text(color = ""grey90"", family = ""MV Boli""), 
        plot.caption = element_text(size = 13), 
        axis.text = element_text(color = ""grey90"", family = ""MV Boli""), 
        axis.text.y = element_text(size = 13))

ggdraw() +
  draw_image(""ressources/img_2019-05-07.jpg"", scale = 1.5) + 
  draw_plot(p_ocde)

ggsave(""plots/plot_2019-05-07.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019-19"
"429",1016,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-14.R","library(LaCroixColoR)
library(tidyverse)
library(ggthemes)
library(ggimage)

#### Data and ressources ####

nobel_winners <- read_csv(""data/data_2019-05-14.csv"",
                          col_types = ""dccccdccDccccccDcc"")

df_countrycode <-
  tribble(~country, ~code, 
          ""United States of America"", ""US"",
          ""Germany"", ""DE"",
          ""United Kingdom"", ""GB"",
          ""France"", ""FR"",
          ""Japan"", ""JP"",
          ""Netherlands"", ""NL"",
          ""Sweden"", ""SE"",
          ""Russia"", ""RU"",
          ""Canada"", ""CA"",
          ""Austria"", ""AT"")


#### Tables ####

countries <-
  nobel_winners %>%
  filter(category == ""Chemistry"") %>%
  count(birth_country, sort = TRUE) %>%
  head(n = 10) %>%
  pull(birth_country)

nobel_counts <-
  nobel_winners %>%
  filter(birth_country %in% countries, category == ""Chemistry"") %>%
  select(prize_year, birth_country) %>%
  arrange(prize_year) %>%
  group_by(birth_country) %>%
  mutate(n_prize = n(),
         first_prize = min(prize_year),
         last_prize = max(prize_year),
         cum = row_number()) %>%
  ungroup()

nobel_counts <-
  nobel_counts %>%
  filter(cum == 1) %>%
  mutate(cum = 0) %>%
  bind_rows(nobel_counts) %>%
  arrange(prize_year, cum) %>%
  mutate(birth_country = fct_reorder(birth_country, n_prize, .desc = TRUE))

first_last_nobel <-
  nobel_counts %>%
  select(birth_country, n_prize, first_prize, last_prize) %>%
  unique() %>%
  left_join(df_countrycode, by = c(""birth_country"" = ""country""))


#### Plot ####

ggplot(nobel_counts) +
  aes(x = prize_year, y = cum, group = birth_country) +
  geom_line(aes(color = birth_country)) +
  geom_point(data = first_last_nobel, y = 0,
             aes(x = first_prize, y = n_prize, color = birth_country)) +
  geom_flag(data = first_last_nobel, size = 0.03, asp=2,
            aes(x = last_prize, y = n_prize, image = code)) +
  scale_color_manual(values = lacroix_palette(""PeachPear"", n = 10, type = ""continuous"")) +
  scale_y_continuous(limits = c(NA, 60)) +
  labs(title = ""Number of chemistry Nobel prizes by birth country"", color = NULL,
       caption = ""Source: The Nobel Prize\n@_abichat for #TidyTuesday"") +
  theme_wsj(color = ""gray"") +
  theme(legend.position = ""bottom"", 
        plot.caption = element_text(size = 12), 
        plot.title = element_text(size = 25),
        legend.text = element_text(family = ""mono""))

ggsave(""plots/plot_2019-05-14.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")


","2019-20"
"430",1017,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-21.R","library(countrycode)
library(treemapify)
library(tidyverse)
library(janitor)
library(glue)

#### Data and ressources ####

waste_vs_gdp <-
  read_csv(""data/data_2019-05-21.csv"", col_types = ""ccdddd"") %>%
  rename(WastePC = `Per capita plastic waste (kilograms per person per day)`,
         Population = `Total population (Gapminder)`)

olympic_colors <- c(Oceania = ""#00A651"", Africa = ""#000000"", Asia = ""#FCB131"", 
                    Europe = ""#0081C8"", Americas = ""#EE334E"")


#### Tables ####

df_waste <-
  waste_vs_gdp %>%
  select(Entity, Code, Year, WastePC, Population) %>%
  drop_na() %>%
  mutate(TotalWaste = WastePC * Population,
         Continent1 = countrycode(Entity, origin = ""country.name"", 
                                  destination = ""continent"", warn = FALSE),
         Continent2 = countrycode(Code, origin = ""iso3c"", 
                                  destination = ""continent"", warn = FALSE),
         Continent = coalesce(Continent1, Continent2),
         Continent1 = NULL, Continent2 = NULL) %>%
  filter(Year == 2010, !is.na(Continent)) %>%
  group_by(Continent) %>%
  mutate(Country_TTW = fct_lump(Entity, n = 9, w = TotalWaste)) %>%
  ungroup()

df_waste_sum <-
  df_waste %>%
  group_by(Continent, Country_TTW) %>%
  summarise(TotalWaste = sum(TotalWaste)) %>%
  mutate(rank = min_rank(TotalWaste)) %>%
  ungroup() %>%
  mutate(label = case_when(Country_TTW == ""Other"" ~ glue(""Other {Continent}""),
                           Country_TTW == ""Democratic Republic of Congo"" ~ ""DR Congo"",
                           TRUE ~ Country_TTW),
         label = case_when(Continent == ""Oceania"" ~ glue('{label} - {round(TotalWaste/10^6, 1)} kT'),
                           TRUE ~ glue('{label}\n{round(TotalWaste/10^6, 1)} kT')))


#### Plot ####

ggplot(df_waste_sum) +
  aes(area = TotalWaste, subgroup = Continent) +
  geom_treemap(aes(fill = Continent, alpha = rank), size = 0.5, color = ""white"") +
  geom_treemap_text(aes(label = label), color = ""white"", 
                    family = ""Basicdots"", place = ""topleft"", grow = FALSE) +
  scale_fill_manual(values = olympic_colors) +
  scale_alpha(range = c(0.3, 1)) +
  labs(title = ""Daily amount of plastic waste entering the ocean"",
       caption = ""Source: Our World in Data\n@_abichat for #TidyTuesday"") +
  theme(legend.position = ""none"",
        title = element_text(family = ""Andale Mono"", hjust = 0.5, size = 20),
        plot.caption = element_text(family = ""Andale Mono"", size = 10))

ggsave(""plots/plot_2019-05-21.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019-21"
"431",1018,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-05-28.R","library(ggpomological)
library(tidyverse)
library(ggridges)

#### Data ####

wine_ratings <- read_csv(""data/data_2019-05-28.csv"", col_types = ""dcccddcccccccc"")


#### Tables ####

best_french_wines <-
  wine_ratings %>%
  filter(country == ""France"") %>%
  select(country, variety, points) %>%
  group_by(variety) %>%
  summarise(mean = mean(points), n = n()) %>%
  filter(n > 50) %>%
  arrange(desc(mean), n) %>%
  head(9) %>%
  pull(variety)

df_best_french_wines <-
  wine_ratings %>%
  select(country, variety, points) %>%
  filter(country == ""France"", variety %in% best_french_wines) %>%
  mutate(variety = fct_reorder(variety, desc(points)))


#### Plot ####

ggplot(df_best_french_wines) +
  aes(x = points, y = variety) +
  geom_density_ridges(aes(fill = variety, color = variety), alpha = 0.9) +
  geom_text(aes(label = variety), x = 80, nudge_y = 0.3, 
            family = ""Chopin Script"", size = 7, hjust = 0) +
  scale_fill_pomological() +
  scale_color_pomological() +
  scale_x_continuous(limits = c(80, 100)) +
  expand_limits(y = c(NA, 10.7)) +
  labs(x = ""Score"", title = ""Best French Wines"", 
       caption = ""Source: WineEnthusiast\n@_abichat for #TidyTuesday"") +
  theme_pomological() +
  theme(text = element_text(family = ""Chopin Script"", size = 20), 
        plot.title = element_text(size = 30, hjust = 0.5), 
        axis.text.x = element_text(size = 12), 
        axis.text.y = element_blank(), 
        axis.title.y = element_blank(), 
        legend.position = ""none"")

ggsave(""plots/plot_2019-05-28.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019-22"
"432",1019,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-06-18.R","library(tidyverse)
library(ggthemes)
library(cowplot)

#### Data ####

bird_counts <- read_csv(""data/data_2019-06-18.csv"", col_types = ""dccddd"") 


#### Table ####

df_diff <-
  bird_counts %>% 
  select(species_latin, year, how_many_counted_by_hour) %>% 
  drop_na(how_many_counted_by_hour) %>% 
  filter(year %in% c(1957, 1967, 1977, 1987, 1997, 2007, 2017)) %>%
  mutate(year = paste0(""Y"", year)) %>% 
  spread(year, how_many_counted_by_hour) %>% 
  mutate(diff1707 = Y2017 - Y2007,
         diff0797 = Y2007 - Y1997,
         diff9787 = Y1997 - Y1987,
         diff8777 = Y1987 - Y1977,
         diff7767 = Y1977 - Y1967,
         diff6757 = Y1967 - Y1957) %>% 
  mutate(species_latin = fct_lump(species_latin, n = 20, w = Y2017)) %>%
  filter(species_latin != ""Other"") %>% 
  mutate(species_latin = fct_reorder(species_latin, desc(diff1707)))


#### Plots ####

p1707 <-
  ggplot(df_diff) +
  aes(x = diff1707, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff1707 > 0)) +
  geom_point(aes(color = diff1707 > 0, size = Y2017)) +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""right"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 2017 and 2007"",
       subtitle = ""Area are proportional to the number of observations per hour during the current year (2017)"",
       caption = ""Source: Bird Studies Canada\n@_abichat for #TidyTuesday"") +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", plot.caption = element_text(hjust = 0),
        title = element_text(size = 12), axis.text = element_text(size = 10))

p0797 <-
  ggplot(df_diff) +
  aes(x = diff0797, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff0797 > 0)) +
  geom_point(aes(color = diff0797 > 0, size = Y2007)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 2007 and 1997"",
       subtitle = ""Area are proportional to the number of observations per hour during the current year (2007)"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""right"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", 
        title = element_text(size = 8), axis.text = element_text(size = 6),
        plot.margin = margin(0.5, 0.1, 0.5, 0.5, ""lines""))

p9787 <-
  ggplot(df_diff) +
  aes(x = diff9787, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff9787 > 0)) +
  geom_point(aes(color = diff9787 > 0, size = Y1997)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 1997 and 1987"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""left"") +
  expand_limits(y = c(NA, 21)) +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", 
        title = element_text(size = 4), axis.text = element_text(size = 4),
        plot.margin = margin(0.5, 0.5, 0.5, 0.1, ""lines""))

p8777 <-
  ggplot(df_diff) +
  aes(x = diff8777, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff8777 > 0)) +
  geom_point(aes(color = diff8777 > 0, size = Y1987)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 1987 and 1977"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""left"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  scale_size_continuous(range = c(1, 4)) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", title = element_text(size = 1.8), 
        axis.text.x = element_text(size = 2), axis.text.y  = element_blank(), 
        panel.grid.major = element_line(size = 0.1),
        plot.margin = margin(t = 0.1, r = 0, b = 0, l = 0, unit = ""pt""))

p7767 <-
  ggplot(df_diff) +
  aes(x = diff7767, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff7767 > 0)) +
  geom_point(aes(color = diff7767 > 0, size = Y1977)) +
  labs(x = NULL, y = NULL,
       title = ""Difference in number of observations per hour between 1977 and 1967"") +
  scale_x_continuous(position = ""top"") +
  scale_y_discrete(position = ""left"") +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  scale_size_continuous(range = c(1, 3)) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", 
        title = element_text(size = 1), axis.text = element_blank(), 
        panel.grid.major = element_line(size = 0.05),
        plot.margin = margin(t = 0.1, r = 0, b = 0, l = 0, unit = ""pt""))

p6757 <-
  ggplot(df_diff) +
  aes(x = diff6757, y = species_latin) +
  geom_segment(aes(xend = 0, yend = species_latin, color = diff6757 > 0)) +
  geom_point(aes(color = diff6757 > 0, size = Y1967)) +
  labs(x = NULL, y = NULL) +
  scale_color_manual(values = c(""TRUE"" = ""#77AB43"", ""FALSE"" = ""#FF2700"")) +
  scale_size_continuous(range = c(1, 2)) +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"", axis.text = element_blank(), 
        panel.grid.major = element_line(size = 0.05),
        plot.margin = margin(t = 0.1, r = 0, b = 0, l = 0, unit = ""pt""))

ggdraw(p1707) +
  draw_plot(p0797, x = 0, y = 0.1, width = 0.609, height = 0.609) +
  draw_plot(p9787, x = 0, y = 0.2, width = 0.355, height = 0.355) +
  draw_plot(p8777, x = 0.15, y = 0.255, width = 0.13, height = 0.13) +
  draw_plot(p7767, x = 0.182, y = 0.262, width = 0.079, height = 0.079) +
  draw_plot(p6757, x = 0.192, y = 0.267, width = 0.04, height = 0.04) 

ggsave(""plots/plot_2019-06-18.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019-25"
"433",1020,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-06-25.R","library(tidyverse)
library(lubridate)
library(gganimate)
library(lwgeom)
library(sf)

#### Data ####

ufo_sightings <-
  read_csv(""data/data_2019-06-25.csv"", col_types = ""cccccdcccdd"") %>%
  mutate(date_time = mdy_hm(date_time),
         date = as_date(date_time),
         year = year(date))


#### Maps ####

world <- st_as_sf(rworldmap::getMap(resolution = ""low""))
graticule <- st_graticule(lat = c(-89.9, seq(-80, 80, 20), 89.9))

lats <- c(90:-90, -90:90, 90)
longs <- c(rep(c(180, -180), each = 181), 180)
outline <-
  list(cbind(longs, lats)) %>%
  st_polygon() %>%
  st_sfc(crs = ""+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"")

crs_wintri <- ""+proj=wintri +datum=WGS84 +no_defs +over""
world_wintri <- st_transform_proj(world, crs = crs_wintri)
graticule_wintri <- st_transform_proj(graticule, crs = crs_wintri)
outline_wintri <- st_transform_proj(outline, crs = crs_wintri)


#### Tables ####

df_ufo <-
  ufo_sightings %>%
  filter(year >= 1980)

coord_wintri <-
  df_ufo %>%
  drop_na(longitude, latitude) %>%
  st_as_sf(coords = c(""longitude"", ""latitude""), crs = 4326) %>%
  lwgeom::st_transform_proj(crs = crs_wintri) %>%
  `$`(geometry) %>%
  map(as.matrix) %>%
  reduce(rbind)

df_ufo$longitude_wintri <- coord_wintri[, 1]
df_ufo$latitude_wintri <- coord_wintri[, 2]
  

#### Plot ####

anim <-
  df_ufo %>% 
  ggplot() + 
  geom_sf(data = outline_wintri, fill = ""black"", color = NA) + 
  geom_sf(data = graticule_wintri, color = ""gray30"", size = 0.25/.pt) +
  geom_sf(data = world_wintri, fill = ""forestgreen"", color = NA, size = 0.5/.pt) + 
  geom_sf(data = outline_wintri, fill = NA, color = ""grey30"", size = 0.5/.pt) + 
  geom_point(aes(x = longitude_wintri, y = latitude_wintri, alpha = encounter_length), 
             color = ""red"") + # points
  coord_sf(datum = NA, expand = FALSE) +
  labs(x = NULL, y = NULL, title = ""Reported UFO in {current_frame}"", 
       caption = ""Source: National UFO Reporting Center \n@_abichat for #TidyTuesday"") +
  theme_void() +
  theme(plot.margin = margin(6, 1.5, 3, 1.5), legend.position = ""none"",
        plot.title = element_text(size = 20, hjust = 0.5, face = ""bold""), 
        plot.caption = element_text(size = 12)) +
  transition_manual(year) +
  enter_appear() +
  exit_shrink()

animate(anim, width = 29, height = 19, units = ""cm"", res = 320, nframes = 170)

anim_save(""plots/plot_2019-06-25.gif"")




","2019-26"
"434",1021,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-07-23.R","library(wesanderson)
library(tidyverse)
library(cowplot)
library(waffle)
library(scales)

#### Data ####

wildlife_impacts <- 
  read_csv(""data/data_2019-07-23.csv"", col_types = ""Tcccccccccdddcdddcccd"") %>% 
  mutate(phase_of_flt = str_to_title(phase_of_flt))

levels_phase_of_flt <- c(""Parked"", ""Taxi"", ""Take-Off Run"", ""Climb"", ""En Route"", 
                         ""Descent"", ""Approach"", ""Landing Roll"")

levels_damage <- c(""None"", ""Minor"", ""Damaged"", ""Substantial"", ""Unknown"")

color_damage <- c(wes_palette(name = ""FantasticFox1"")[c(3, 2, 1, 5)], ""grey80"")
names(color_damage) <- levels_damage


#### Tables ####

df_phase_damage_height <-
  wildlife_impacts %>%
  select(phase_of_flt, damage, height) %>%
  filter(phase_of_flt %in% levels_phase_of_flt) %>%
  mutate(phase_of_flt = factor(phase_of_flt, levels = levels_phase_of_flt)) %>%
  mutate(damage = fct_recode(damage, None = ""N"", Minor = ""M"", 
                             Damaged = ""M?"", Substantial = ""S""),
    damage = fct_explicit_na(damage, ""Unknown""),
    damage = fct_relevel(damage, levels_damage))

df_phase_damage_count <-
  df_phase_damage_height %>%
  count(phase_of_flt, damage) %>%
  mutate(n = ceiling(n / 10))

df_height <-
  df_phase_damage_height %>%
  group_by(phase_of_flt) %>%
  summarise(n = n(), height = median(height, na.rm = TRUE)) %>%
  mutate(y = ceiling(n / 100) + 1,
         height = paste(round(height, 0), ""ft"")) 


#### Plots ####

p <-
  df_phase_damage_count %>%
  ggplot() +
  geom_waffle(aes(fill = damage, values = n), flip = TRUE, color = ""white"", 
              n_rows = 10, radius = unit(1, ""pt"")) +
  geom_text(data = df_height, aes(y = y, label = height), 
            x = 5.5, nudge_y = 1.9, family = ""Ink Free"") +
  facet_wrap(~ phase_of_flt, nrow = 1, strip.position = ""bottom"") +
  scale_y_continuous(labels = function(x) comma(x * 1000), expand = c(0, 1.7)) +
  scale_fill_manual(values = color_damage) +
  labs(x = NULL, y = NULL, fill = ""Damage"", 
       caption = ""Source: FAA\n@_abichat for #TidyTuesday"") +
  theme_minimal(base_family = ""Ink Free"") +
  theme(
    axis.text.x = element_blank(),
    strip.text = element_text(size = 12),
    panel.grid = element_blank(),
    legend.direction = ""horizontal"",
    legend.position = c(0.57, 0.69),
    legend.justification = ""right"",
    legend.title = element_text(size = 13),
    legend.text = element_text(size = 13),
    axis.title.y.right = element_blank()
  )


ggdraw(p) +
  draw_label(""Number of impacts between flights and wildlife since 1990 in the US"",
             x = 0.4, y = 0.81, fontfamily = ""Ink Free"", size = 20) +
  draw_label(""Each square represents 10 collisions, figures correspond to median collision height"", 
             x = 0.35, y = 0.75, fontfamily = ""Ink Free"", size = 13) +
  draw_label(""Count"", x = 0.02, y = 0.15, fontfamily = ""Ink Free"", angle = 90, size = 13)


ggsave(""plots/plot_2019-07-23.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
  
","2019-30"
"435",1022,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-08-20.R","library(tidyverse)
library(ggexpanse)
library(cowplot)

#### Data ####

nuclear_explosions <- 
  read_csv(""data/data_2019-08-20.csv"", col_types = ""cddcccdddddddccc"") %>% 
  mutate(country = fct_lump(country, n = 5, other_level = ""Pakistan \n& India""),
         country = fct_infreq(country))


#### Tables ####

df_ts <- 
  nuclear_explosions %>% 
  group_by(year, country, .drop = FALSE) %>% 
  summarise(count = n()) 

df_count <- count(nuclear_explosions, country)


#### Plot ####

p_count <-
  ggplot(df_count) +
  aes(x = country, y = n, fill = country) +
  geom_col(color = NA) +
  coord_flip() +
  scale_fill_expanse() +
  labs(x = NULL, y = NULL,
       title = ""Total per country"") +
  theme_expanse(grid = ""XY"", 
                plot_title_size = 15,
                axis_text_size = 9) +
  theme(legend.position = ""none"", 
        panel.grid.major.y = element_blank(),
        plot.background = element_rect(color = alpha(expanse_cols$white, 1/2)),
        plot.margin = unit(c(10, 10, 10, 10), ""points""))

p_year <-
  ggplot(df_ts) +
  aes(x = year, y = count, fill = country) +
  geom_area(color = NA) +
  scale_fill_expanse() +
  labs(x = NULL, y = ""Count"", fill = ""Device deployed by"",
       title = ""Number of nuclear explosions per year and country"",
       caption = ""Source: SIPRI\n@_abichat for #TidyTuesday"") +
  theme_expanse(grid = ""XY"", 
                plot_title_size = 22,
                caption_size = 11,
                axis_title_size = 10) +
  theme(legend.position = ""none"", plot.margin = unit(c(20, 20, 20, 20), ""points""))

ggdraw(p_year) +
  draw_plot(p_count, .528, .47, .4, .4)

ggsave(""plots/plot_2019-08-20.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")
","2019-34"
"436",1023,"https://github.com/abichat/tidytuesday","abichat","tidytuesday","scripts/script_2019-09-24.R","library(ggeconodist)
library(tidyverse)
library(ggthemes)
library(cowplot)
library(scales)

#### Data ####

school_diversity <- read_csv(""data/data_2019-09-24.csv"", col_types = ""cccccdddddddcdc"")


#### Tables ####

df_diversity <-
  school_diversity %>% 
  select(LEAID, ST, SCHOOL_YEAR, White) %>%
  group_by(LEAID) %>%
  mutate(N = n()) %>%
  ungroup() %>%
  filter(N == 2) %>%
  group_by(ST, SCHOOL_YEAR) %>%
  mutate(N = n()) %>%
  ungroup() %>%
  filter(N > 10) %>%
  ungroup() %>%
  select(-N) %>%
  mutate(ST = fct_reorder(ST, White, .desc = TRUE), 
         White = White / 100)


#### Plot ####

# Legend 

p_legend <-
  ggplot(df_diversity) +
  aes(x = SCHOOL_YEAR, y = White, fill = SCHOOL_YEAR) +
  geom_col(alpha = 0.2) +
  scale_fill_tableau() +
  theme_econodist() +
  labs(fill = ""School Year"") +
  theme(legend.position = ""bottom"", legend.direction = ""horizontal"", 
        legend.title = element_text(family = ""EconSansCndLig"", color = ""#3b454a"", size = 10),
        legend.text = element_text(family = ""EconSansCndLig"", color = ""#3b454a"", size = 10))

legend <- get_legend(p_legend)

# Final plot 

p <-
  ggplot(df_diversity) +
  aes(x = ST, y = White, fill = SCHOOL_YEAR) +
  geom_econodist(tenth_col = ""#b07aa1"", ninetieth_col = ""#591a4f"",
                 show.legend = FALSE) +
  scale_y_continuous(labels = percent) +
  scale_fill_tableau() +
  labs(x = NULL, y = NULL, 
       title = ""Evolution of the Proportion of Whites in US Schools"",
       caption = ""Source: The Washington Post\n@_abichat for #TidyTuesday"") +
  theme_econodist() +
  theme(title = element_text(size = 15))

ggdraw(p) +
  draw_plot(legend, x = -0.305, y = -0.465) + 
  draw_plot(econodist_legend_grob(tenth_col = ""#b07aa1"", ninetieth_col = ""#591a4f""),
            x = 0.35, y = 0.027) 

ggsave(""plots/plot_2019-09-24.png"", width = 29, height = 21, units = ""cm"", dpi = ""retina"")

","2019-39"
"437",1026,"https://github.com/Christensen-David/TidyTuesday/tree/master/2019_7_30_Video_Games","Christensen-David","TidyTuesday","2019_7_30_Video_Games/2019_7_30_TidyTuesday_Video_Games.r","#by: David C
#TidyTuesday for 7/30/19
library(tidyverse)
library(ggplot2)
library(tokenizers)
library(RColorBrewer)
video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

#formatting dates
  video_games$release_date<-as.Date(strftime(strptime(video_games$release_date,""%b %d, %Y""),""%Y-%m-%d""))
#viz of count of releases over time
ggplot(data=video_games, aes(x=release_date)) + geom_bar(aes(fill=..count..), stat=""bin"", binwidth=5)+labs(title = ""After SimCity"",subtitle = ""Count of video game releases over time"" )

#formating  owners to see games with 1M owners
video_games$owners<-as.factor(video_games$owners)
t<-unique(video_games$owners) #list of groupings
video_games$million.Owners<-""no""
video_games$million.Owners[which(video_games$owners %in% t[1:4])]<-""yes""
#list of games with 1M+ owners
blockbusters<-video_games[which(video_games$million.Owners ==""yes""),] 

#basic view of pricing for games with over 1,000,000 owners
p <- ggplot(data = blockbusters, aes(x = release_date, y=price,  na.rm = TRUE)) + 
  geom_col(color = ""#00AFBB"", size =1)
p +labs(title = ""It costs $x9.99"", subtitle = ""Hit video game pricing over time (games with over 1,000,000 owners)"") + scale_y_continuous(breaks=c(9.99,19.99, 29.99, 39.99,49.99,59.99,89.99))

#wordcloud of title words
text <- paste(video_games$game, collapse = '\n') 

#tokenize the individual words
words <- tokenizers::tokenize_words(text) #list of words from text
#add words to a table
tab <- table(words[[1]])
#turn obj into a data frame
tab <- data_frame(word = names(tab), count = as.numeric(tab))
#remove numbers & ULRS
tab$word <- tab$word %>% gsub('[0-9]', '', .) %>% gsub('http\\S+\\s*', '',.)%>% gsub('[a-z]+[.]+[a-z]', '', .)

#read in an English language word frequncy table (a local file)
wf <- read_csv('word_frequency.csv')
#join frequncy table to table of words
tab.jned<- inner_join(tab, wf)

#filter common words and stop words based on fequency and remove language columm
tab.flter<-filter(tab.jned, frequency < 0.3) %>% select(.,-language)
#find any words from original table that did not join to English language frequency table
t<-setdiff(tab$word,tab.jned$word)
tab.other<-tab %>% filter(word %in% t) %>%add_column(frequency=0) %>% arrange(., desc(count))
#of other possible words, short words removed
tab.other<- tab.other %>% filter(nchar(word)>3)

#add those word to the filtered word list
tab.final <-rbind(tab.flter,tab.other) 
#arrange by count of occurances
tab.final<-arrange(tab.final, desc(count))
head(tab.final,10)
#finally, the wordcloud
wordcloud::wordcloud(words = tab.final$word, freq = tab.final$count, scale=c(9,.5),min.freq = 1,
                     max.words=100, random.order=FALSE, rot.per=0.35, 
                     colors=brewer.pal(8, 'Dark2'))



","2019-31"
"438",1027,"https://github.com/ch-bu/tidytuesday/blob/master/2019-06-12/meteorites.R","ch-bu","tidytuesday","2019-06-12/meteorites.R","library(tidyverse)
library(lubridate)
library(hrbrthemes)
library(ggthemes)
library(cowplot)

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  mutate(
    log_mass = log(mass)
  )

mass_limit <- 10000000

small_impacts <- meteorites %>%
  filter(mass < mass_limit)

huge_impacts <- meteorites %>%
  filter(mass >= mass_limit)

world <- ggplot() + 
  borders(""world"", colour = ""#5b616b"", fill = ""#5b616b"") +
  theme_map() +
  coord_map(projection = ""mollweide"", orientation = c(90, 0, 0)) +
  geom_point(data = small_impacts, color = ""#f9e0de"",
             aes(x = long, y = lat, size = mass), alpha = .1) +
  annotate(""text"", x = -123 - 50, y = 45.4 - 30, color = ""#f1f1f1"", hjust = 0,
           fontface = ""italic"",
           label = ""In 1902 the meteorite\nWillamette crashed in the US.\nIt was 7.8 square meters long\nand weight 15.5 tons"") +
  geom_segment(aes(x = -123, y = 45.4, 
                   xend = -123 - 30, yend = 45.4 - 15), color = ""#f1f1f1"") +
  annotate(""text"", x = 17.9 + 20, y = -19.6 - 30, color = ""#f1f1f1"", hjust = 0,
           fontface = ""italic"",
           label = ""Huba is the biggest meteorite ever\nfound on earth. It weighs 60 tons\nand has landed around\n80,000 years ago"") +
  geom_segment(aes(x = 17.9, y = -19.6, 
                   xend = 17.9 + 30, yend = -19.6 - 15), color = ""#f1f1f1"") +
  geom_point(data = huge_impacts, color = ""#dd361c"",
             aes(x = long, y = lat, size = mass), alpha = .6) +
  theme(
    plot.title = element_text(color = ""#f1f1f1"", hjust = 0.5,
                              margin = margin(b = 15),
                              size = 30,
                              face = ""bold"",
                              family = ""Titillium Web""),
    plot.subtitle = element_text(color = ""#aeb0b5"", hjust = 0.5,
                              margin = margin(b = 35),
                              size = 20,
                              family = ""Titillium Web""),
    plot.background  = element_rect(fill  = ""#323a45"", color = NA),
    panel.background = element_rect(fill  = ""#323a45"", 
                                    color = ""#323a45"")
  ) +
  guides(
    size = ""none"",
    color = ""none""
  ) +
  labs(
    title = ""Meteorites falling on earth"",
    subtitle = ""Red dots indicate meteorite impacts with a mass\nbigger than 11 tons""
  )

ggdraw(world) +
  theme(
    plot.background = element_rect(fill = ""#323a45""),
    panel.background = element_rect(fill = ""#323a45"", color = ""#323a45""),
    plot.margin = unit(c(1, 1, 1, 1), ""cm"")
  ) 


","2019-24"
"439",1028,"https://github.com/ch-bu/tidytuesday/blob/master/2019-05-20/global_plastic_waste.R","ch-bu","tidytuesday","2019-05-20/global_plastic_waste.R","library(tidyverse)
library(janitor)
library(ggrepel)


coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

waste_data <- waste_vs_gdp %>%
  clean_names() %>%
  setNames(c(""entity"", ""code"", ""year"", ""waste"",
             ""gdp"", ""population"")) %>%
  drop_na(waste, gdp)

mismanaged_data <- mismanaged_vs_gdp %>%
  clean_names() %>%
  setNames(c(""entity"", ""code"", ""year"", ""mismanaged_plastic"",
             ""gdp"", ""population"")) %>%
  drop_na(mismanaged_plastic, gdp)

data <- waste_data %>%
  full_join(mismanaged_data) %>%
  mutate(
    waste_ratio = mismanaged_plastic / waste
  ) 

good_guys_data <- tibble(x = seq(0, 0.75, by = .001),
                          y = x * .4)
medium_guys_data <- tibble(x = seq(0, 0.75, by = .001),
                           ymin = x * .4,
                           ymax = x * .7)
bad_guys_data <- tibble(x = seq(0, 0.75, by = .001),
                           ymin = x * .7,
                           ymax = x * 1)

data_bad_countries <- data %>%
  filter(waste_ratio > .7, waste > 0.2)

data_good_guys <- data %>% 
  filter(waste_ratio < .4, waste > 0.5, waste < 0.8)

ggplot(data, aes(x = waste, y = mismanaged_plastic)) + 
  # geom_abline(slope = 1, color = ""#e5e5e5"") +
  # geom_abline(slope = .7, color = ""#E5E5E5"") +
  # geom_abline(slope = .4, color = ""#E5E5E5"") +
  geom_ribbon(mapping = aes(x = x, ymax = y, ymin = 0), fill = ""#fceaea"",
              data = good_guys_data, inherit.aes = FALSE,
              alpha = .6) +
  geom_ribbon(mapping = aes(x = x, ymax = ymax, ymin = ymin), fill = ""#f39696"",
              data = medium_guys_data, inherit.aes = FALSE,
              alpha = .6) +
  geom_ribbon(mapping = aes(x = x, ymax = ymax, ymin = ymin), fill = ""#e72d2d"",
              data = bad_guys_data, inherit.aes = FALSE,
              alpha = .7) +
  annotate(""segment"", x = 0.223, xend = 0.223, y = 0, yend = 0.178, 
           color = ""#515151"", linetype = 2) +
  annotate(""segment"", x = 0.223, xend = 0.75, y = 0.178, yend = 0.184, 
           color = ""#515151"", linetype = 2) +
  geom_point(show.legend = FALSE, alpha = .8, size = 3,
             color = ""#969696"", pch = 21, fill = ""#cacaca"") +
  annotate(""text"", family = ""Open Sans"", color = ""#2e0909"",
           x = 0.41, y = 0.39,  hjust = 0, fontface = 2, size = 7,
           label = ""70% to 100%"") +
  annotate(""text"", family = ""Open Sans"",
           x = 0.53, y = 0.30,  hjust = 0, fontface = 2, size = 7,
           label = ""40% to 70%"") +
  annotate(""text"", family = ""Open Sans"",
           x = 0.60, y = 0.15,  hjust = 0, fontface = 2, size = 7,
           label = ""0% to 40%"") +
  annotate(""segment"", x = 0.17, xend = 0.21, y = 0.22, yend = 0.19, 
           color = ""#515151"") +
  annotate(""text"", family = ""Open Sans"",
           x = 0.06, y = 0.25,  hjust = 0, size = 3.5,
           label = ""For example, a person in Tonga\nproduces 0.22 kg of\nplastic waste per day,\n0.18 kg of which is not\nproperly disposed of"") +
  geom_text_repel(family = ""Open Sans"", aes(label = entity), 
                  fontface = ""italic"",
                  data = data_bad_countries, color = ""#170404"") +
  geom_text_repel(family = ""Open Sans"", aes(label = entity), 
                  fontface = ""italic"",
                  data = data_good_guys, color = ""#170404"") +
  coord_cartesian(ylim = c(0, 0.5), xlim = c(0, 0.72)) +
  scale_x_continuous(labels = function(x) paste(x, ""kg"")) +
  scale_y_continuous(labels = function(x) paste(x, ""kg""), position = ""right"") +
  theme(
    plot.background = element_rect(fill = ""white""),
    panel.background = element_rect(fill = ""white""),
    plot.title = element_text(family = ""Open Sans"", face = ""bold"",
                              hjust = 0, margin = margin(t = 20, b = 10), size = 30),
    plot.subtitle = element_text(family = ""Open Sans"", color = ""#515151"",
                                 hjust = 0, margin = margin(b = -140), size = 23),
    plot.margin = unit(c(1, 2, 1, 1), ""cm""),
    axis.text.y.right = element_text(size = 10, family = ""Open Sans"", margin = margin(r = 20)),
    axis.text.x = element_text(size = 10, family = ""Open Sans""),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.x = element_text(margin = margin(t = 15, b = 15),
                                color = ""#515151"", hjust = 1,
                                size = 10, family = ""Open Sans""),
    axis.title.y = element_text(size = 10, family = ""Open Sans"", 
                                color = ""#515151"", hjust = 0)

  ) +
  labs(
    x = ""Amout of plastic waste per capita in kg/day"",
    y = ""Not properly disposed plastic waste per capita in kg/day"",
    title = ""Who doesn't care\nabout plastic waste?"",
    subtitle = ""Percentage of plastic waste\nthat is not properly disposed of,\nper country""
  )







","2019-20"
"440",1029,"https://github.com/ch-bu/tidytuesday/blob/master/2019-06-04/ramen.R","ch-bu","tidytuesday","2019-06-04/ramen.R","library(tidyverse)
library(broom)
library(hrbrthemes)

theme_set(theme_modern_rc(axis_title_size = 13))

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

ramen_ratings_processed <- ramen_ratings %>%
  mutate(
    style = fct_lump(style, 4),
    country = fct_lump(country, 12),
    brand = fct_lump(brand, 20)
  ) %>%
  drop_na(style)

model_terms <- lm(stars ~ brand + country + style, ramen_ratings_processed) %>%
  tidy(conf.int = TRUE) %>%
  filter(term != ""(Intercept)"") %>%
  arrange(desc(estimate)) %>%
  extract(term, c(""category"", ""term""), ""^([a-z]+)([A-Z].*)"") 

grey_color <- ""#e7e7e7""
soft_grey <- ""#7e7e7e""
supersoft_grey <- ""#dbdbdb""
text_color <- ""#22222b""
green_color <- ""#00c18d""

model_terms %>%
  filter(category == ""country"") %>%
  mutate(term = fct_reorder(term, estimate)) %>%
  rename(country = term) %>%
  ggplot(aes(estimate, country)) +
  geom_point(color = green_color, size = 4) +
  geom_vline(xintercept = 0, lty = 2, color = soft_grey) +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), 
                 color = green_color, height = .2) +
  annotate(""text"", color = ""#383840"", x = -0.45, y = 10.3,
           hjust = 0,
           fontface = ""italic"",
           label = ""The estimates to the right of\nthis value indicate an overall\npositive relationship with\nthe ramen rating.\nValues on the left indicate\nnegative relationship."") +
  geom_curve(aes(x = -0.02, y = 10.3, xend = -0.1, yend = 10.1),
             curvature = -0.2, color = soft_grey, size = 0.05) +
  labs(
    x = ""Regression estimates"",
    y = ""Country of origin"",
    title = ""How does the country of origin\naffects the rating of ramens?"",
    subtitle = ""Regression coefficients predicting ramen\nratings by country of origin""
  ) +
  scale_color_continuous() +
  theme(
    plot.title = element_text(margin = margin(b = 10), 
                              color = text_color,
                              size = 22,
                              family = ""Open Sans""),
    plot.subtitle = element_text(margin = margin(b = 45), 
                                 color = text_color,
                                 size = 17,
                                 family = ""Open Sans""),
    axis.title.x = element_text(margin = margin(t = 15),
                                color = soft_grey),
    axis.text.x    = element_text(color = text_color,
                                  margin = margin(t = 15)),
    axis.text.y    = element_text(color = text_color),
    axis.title.y = element_text(margin = margin(r = 15),
                                color = soft_grey),
    panel.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.major.y = element_line(color = supersoft_grey),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = grey_color),
    plot.margin = unit(c(1, 2, 1, 1), ""cm"")
  )



","2019-23"
"441",1030,"https://github.com/ch-bu/tidytuesday/blob/master/2019-05-14/nobel_prize.R","ch-bu","tidytuesday","2019-05-14/nobel_prize.R","library(tidyverse)
library(hrbrthemes)
library(lubridate)
library(gghighlight)

theme_set(theme_ipsum_rc())

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")


# Wie lange braucht es fr die Gewinner, einen Nobelpreis zu bekommen?

winners <- nobel_winners %>%
  filter(laureate_type == ""Individual"") %>%
  select(prize_year, category, full_name, birth_date) %>%
  mutate(
    birth_year = year(birth_date),
    age_won    = prize_year - birth_year
  ) %>%
  select(-birth_date)

peace_prices <- winners %>%
  filter(category == ""Peace"")


winners %>%
  ggplot(aes(x = prize_year, y = age_won)) +
  geom_point(color = ""#cccccc"") +
  geom_smooth(aes(group = category), color = ""#cccccc"", se = FALSE) +
  geom_point(data = peace_prices, 
             aes(x = prize_year, y = age_won), color = ""blue"") +
  geom_smooth(data = peace_prices, 
              aes(x = prize_year, y = age_won), color = ""blue"", se = FALSE) +
  labs(
    x = ""Prize year"",
    y = ""Age won""
  ) 








","2019-20"
"442",1031,"https://github.com/ch-bu/tidytuesday/blob/master/2019-06-18/christmas_bird_counts.R","ch-bu","tidytuesday","2019-06-18/christmas_bird_counts.R","library(tidyverse)
library(hrbrthemes)
library(emojifont)
library(stringr)

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

total_count_per_year <- bird_counts %>%
  mutate(
    year = year - year %% 5
  ) %>%
  group_by(year) %>%
  summarise(
    total_count = sum(how_many_counted_by_hour)
  )

european_starling <- bird_counts %>%
  mutate(
    year = year - year %% 5
  ) %>%
  filter(species %in% c(""European Starling"")) %>%
  group_by(year) %>%
  summarise(
    counted = sum(how_many_counted_by_hour)
  ) %>%
  left_join(total_count_per_year, by = ""year"") %>%
  mutate(
    label = fontawesome('fa-twitter')
  ) %>%
  drop_na()

text_color = ""#939599""

european_starling %>%
  ggplot(aes(x = year, y = total_count)) +
  geom_segment(
    aes(x = year, xend = year, y = counted, yend = total_count), colour = ""#52565c""
  ) +
  geom_text(aes(label = label), family='fontawesome-webfont', size = 10,
            color = ""#fcf594"") +
  geom_text(aes(x = year, y = total_count, label = round(total_count, 0)), 
            family='Open Sans', size = 5, nudge_x = 0, 
            nudge_y = 220, color = text_color) +
  geom_text(data = european_starling, aes(x = year, y = counted, label = label), 
            family='fontawesome-webfont', color = ""#ff7a8a"", size = 10) +
  geom_text(data = european_starling, aes(x = year, y = counted, label = round(counted, 0)), 
            family='Open Sans', size = 5, nudge_x = 0, 
            nudge_y = -220, color = text_color) +
  annotate(""text"", x = 1967, y = 2774,
           hjust = 0,
           fontface = ""italic"", label = ""Yellow birds indicate the total\nnumber of birds counted per\nhour in a given that year"",
           color = ""#fcf594"") +
  annotate(""text"", x = 1980, y = 200,
           hjust = 0,
           fontface = ""italic"", label = ""Red birds indicate the total number of\nEuropean Starlings counted per\nhour in a given that year"",
           color = ""#ff7a8a"") +
  labs(
    title = str_to_title(""The European Starling - the celebrity among the birds""),
    subtitle = ""The European Starling is one of the most common birds. In 2004 there were about\n310 million individuals occupying an area of 8,870,000 square kilometer. That is\nabout the largest size of the Roman Empire."",
    x = """",
    y = ""Average total count per hour""
  ) +
  scale_x_continuous(breaks = seq(from = 1950, to = 2015, by = 5 )) +
  theme_modern_rc() +
  theme(
    plot.background = element_rect(fill = ""#282c34""),
    panel.background = element_rect(fill = ""#282c34"", color = ""#282c34""),
    plot.title = element_text(margin = margin(b = 10), 
                              color = ""#ffffff"",
                              size = 23,
                              family = ""Open Sans""),
    plot.subtitle = element_text(margin = margin(b = 65), 
                                 color = ""#bebfc2"",
                                 size = 18,
                                 family = ""Open Sans""),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.text.x = element_text(color = ""#686b70"", margin = margin(t = 20)),
    axis.ticks.x = element_line(color = ""#3d4148"")
  )

         
  
  
  
  
  
  
  
  
  













","2019-25"
"443",1032,"https://github.com/ch-bu/tidytuesday/blob/master/2019-07-09/tidytuesday_world_cup_women.R","ch-bu","tidytuesday","2019-07-09/tidytuesday_world_cup_women.R","library(tidyverse)
library(ggthemes)
library(countrycode)
library(viridis)
library(rayshader)

wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

world <- map_data(""world"") %>%
  filter(region != ""Antarctica"") 

outcomes <- wwc_outcomes %>% 
  left_join(codes, by = ""team"") %>% 
  count(year, team) %>% 
  select(-n) %>% 
  count(team, sort = TRUE) %>% 
  left_join(codes, by = ""team"") %>% 
  mutate(
    country = gsub(""United States"", ""USA"", country) %>% 
      gsub(""China PR"", ""China"", .) %>% 
      gsub(""Ivory Coast (Cte d'Ivoire)"", ""Ivory Coast"", .)
  ) %>% 
  rename(region = country) %>% 
  left_join(world, by = ""region"")

(p <- ggplot() + 
  geom_map(data = world, map = world,
           aes(long, lat, group = group, map_id = region), 
           color = ""#2a2a2a"", fill = NA) +
  theme_map() +
  geom_map(data = participants, map = world,
           aes(fill = n, map_id = region),
           color = ""#282828"", size = 0.15, alpha = .8) +
  coord_map(xlim = c(-180, 180)) +
  scale_fill_viridis(option=""viridis"", breaks = c(1, 2, 3, 4, 5, 6, 7, 8)) +
  guides(
    fill = guide_legend(title.position = ""bottom"",
                        ncol = 2)
  ) +
  labs(
    title = str_to_title(""Which countries represent womens' soccer?""),
    fill = ""# of participations\nin World Cup"",
    caption = ""Source: data.world | Graphic: Christian Burkhart"",
    subtitle = str_to_title(""The higher a country, the more often it took\npart in the womens' World Cup"")
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, 
                              size = 16,
                              color = ""black"",
                              face = ""bold"",
                              family = ""Lato"",
                              margin = margin(b = 7)),
    plot.subtitle = element_text(hjust = 0.5, 
                              size = 14,
                              color = ""black"",
                              family = ""Lato"",
                              margin = margin(b = 35)),
    plot.caption = element_text(
      size = 10, 
      color = ""#5f5f5f"",
      face = ""italic"",
      family = ""Lato""
    ),
    plot.margin = unit(c(1, 1, 1, 1), ""cm"")
    # legend.direction = ""horizontal""
  ))


plot_gg(p, width = 8, height = 5, multicore = TRUE, scale = 200,
        zoom = 0.55, theta = -10, phi = 60)
render_snapshot(clear = TRUE)



","2019-28"
"444",1047,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-02-12/US_R_and_D_Funding.Rmd","---
title: ""US R&D Funding - TidyTuesday 02-11-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---


```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

tt_data<-tt_load(""2019-02-12"")
tt_data
```


```{r visualize}

delta<-function(x,index){
  x<-x[order(index)]
  delta<-c(NA,(x[seq(2,length(x))]-x[seq(1,length(x)-1)]))
  delta[delta==Inf]<-0
  delta
}

tt_data$fed_r_d_spending%>%
  group_by(department)%>%
  mutate(delta_budget=delta(rd_budget,year)/1e9,
         delta_direction=ifelse(delta_budget>0,""green"",""red""))%>%
  mutate(delta_budget=ifelse(is.na(delta_budget)|is.nan(delta_budget),0,delta_budget),
         totalSum=cumsum(delta_budget))%>%
  ggplot()+
  geom_segment(aes(x=year,     xend = year,
                   y=totalSum, yend = totalSum-delta_budget,
                   color=I(delta_direction)),
               size=2) +
  facet_wrap(department~.,
             scales = ""free_y"",
             strip.position = ""top"",
             ncol = 3) +
  ggtitle(label = ""US R&D Dollars"") +
  ylab(""? in Research and Development Dollars (Billions)"") +
  xlab(""Year"")

ggsave(""US_R&D_Funding.png"")

```


","2019-7"
"445",1048,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-02-19/PhDs_Awarded_by_Field.Rmd","---
title: ""PhDs Awarded by Field - TidyTuesday 02-19-2019""
output:
  html_output: default
  word_output:
    toc: true
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

tt_data<-tt_load(2019,8)
tt_data
```

```{r visualize}
delta<-function(x,index){
  delta<-c(NA,(x[seq(2,length(x))]-x[seq(1,length(x)-1)]))
  delta[abs(delta)==Inf]<-0
  delta
}
total_delta<-function(x,index){
  x_sum<-vector(""numeric"",length(unique(index)))
  names(x_sum)<-as.character(unique(index))

  for(i in unique(index)){
    x_vals<-x[index==i]
    if(all(is.na(x_vals))){
      x_sum[as.character(i)]<-NA
    }else{
      x_sum[as.character(i)]<-sum(x_vals,na.rm = TRUE)
    }
  }
  MinYear<-min(names(x_sum)[!is.na(x_sum)])
  MaxYear<-max(names(x_sum)[!is.na(x_sum)])
  x_sum[MaxYear]-x_sum[MinYear]
}
cumsum_alt<-function(delta,dirval){
  #get first non-na location
  loc<-which(!is.na(dirval))[1]
  baseval<-dirval[loc]
  delta[loc]<-ifelse(is.na(delta[loc]),baseval,delta[loc]+baseval)
  cumsum(delta)
}
wrap_header <- function(text) {
  wtext <- paste(strwrap(text,width=30),collapse="" \n "")
  return(wtext)
}

tt_data$phd_by_field%>%
  #calculate values by field
  group_by(field)%>%
  mutate(delta_phds=delta(n_phds,year),
         delta_direction=ifelse(delta_phds>0,""blue"",""red""),
         totalSum=cumsum_alt(delta_phds,n_phds),
         total_delta_phds=total_delta(n_phds,year))%>%
  ungroup()%>%
  filter(total_delta_phds%in%sort(unique(total_delta_phds),decreasing = TRUE)[1:10])%>%
  mutate(field_alt=sapply(field,wrap_header))%>%
  arrange(desc(total_delta_phds))%>%
  ggplot()+
  geom_segment(aes(x=year,     xend = year,
                   y=totalSum, yend = totalSum-delta_phds,
                   color=I(delta_direction)),
               size=3) +
  facet_wrap(field_alt~.,
             scales = ""free"",
             strip.position = ""top"",
             ncol = 5) +
  scale_x_continuous(breaks = c(2010,2015),
                     minor_breaks = seq(2008,2017))+
  ggtitle(label = ""Graduation Rates"",
          subtitle = ""Fields with Greatest Increase in Graduates"") +
  ylab(""Number of PhD Graduates"") +
  xlab(""Year"")+
  theme_linedraw()

ggsave(""2019-02-19/PhD_Grad_Rates.png"")

```


","2019-8"
"446",1049,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-02-25/Train_delays_over_time.Rmd","---
title: ""Time to Grand Salami - TidyTuesday 04-10-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
library(lubridate)

tt_data<-tt_load(""2019-04-09"")
tt_data
```

```{r transform}


time_since_win<-function(dat){
  
  dat<-dat %>% arrange(rolling_win_count)
  
  df<-data.frame(dat[1,]) %>% 
    mutate(age=abs(floor(as.numeric(difftime(date_of_birth,tournament_date,units = ""days""))/365)),
           delta_days=0)
  
  if(nrow(dat)>1){
    win <-seq(2,nrow(dat))
    df_wins<-data.frame(dat[win,]) %>% 
        mutate(age=abs(floor(as.numeric(difftime(tournament_date,date_of_birth,units = ""days""))/365)),
               delta_days=floor(as.numeric(difftime(tournament_date,dat[win-1,""tournament_date""][[1]],units = ""days""))))
    df<-bind_rows(df,df_wins)
  }
  return(df)
}

# is there a relationship between  age and the time between next grand slam?

t_wins<-tt_data$grand_slams%>%
  left_join(tt_data$player_dob%>%select(name,date_of_birth))%>%
  group_by(name)%>%
  do({time_since_win(.)})


t_wins%>%
  filter(rolling_win_count>1) %>% 
  mutate(age_decile=cut(age,
                        breaks=c(0,20,30,40,50,Inf))) %>%
  group_by(name,age_decile)%>%
  summarize(rolling_win_count = max(rolling_win_count),
            mean_delta_days = mean(delta_days),
            gender = unique(gender),
            nwins_decile=n()) %>% 
  ggplot()+
  geom_jitter(aes(x=mean_delta_days,
                   y= nwins_decile,
                  color=rolling_win_count))+
  facet_grid(age_decile~gender)

```





","2019-8"
"447",1050,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-03-06/Gender_Employment_Percents.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=10)
tt_data
```

```{r transform}


#cluster groupings over the years

lp<-tt_data$employed_gender%>%
  plot_ly(  x = ~year, y = ~full_time_female, name = 'Full Time Female', type = 'scatter', mode = 'lines+marker', line=list(color =""orange"")) %>%
  add_trace(x = ~year, y = ~part_time_female, name = 'Part Time Female', mode = 'lines+marker', line=list(color =""orange"",  dash = 'dash')) %>%
  add_trace(x = ~year, y = ~full_time_male,   name = 'Full Time Male',   mode = 'lines+marker', line=list(color =""green"")) %>%
  add_trace(x = ~year, y = ~part_time_male,   name = 'Part Time Male',   mode = 'lines+marker', line=list(color =""green"",  dash = 'dash')) %>% 
  add_trace(x = ~year, y = ~total_full_time,  name = 'Total Full Time',  mode = 'lines+marker', line=list(color =""black"")) %>%
  add_trace(x = ~year, y = ~total_part_time,  name = 'Total Part Time',  mode = 'lines+marker', line=list(color =""black"",  dash = 'dash')) %>% 
  layout(title = 'Gender Employment Over time',
         xaxis =list(title = 'Year') ,
         yaxis = list(title = 'Percent Employed as Full or Part Time' ))%>%
  layout(showlegend = FALSE)

lp$sizingPolicy$padding <- ""0""

saveWidget(lp,
           ""Percent_Employed_by_Gender.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""Employment Types by Gender"")


```





","2019-10"
"448",1051,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-03-13/Boardgames.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=11)

# tt_data
```

```{r transform}


#cluster groupings over the years

three_d_boardgames<-tt_data$board_games %>%
  filter()
  mutate(labs=paste0(""<div><p>"",name,""</p><img href=\""https:"",image,""\""/a></div>"")) %>% 
  plot_ly(
    x = ~year_published,
    y = ~min_age,
    z = ~average_rating,
    color = ~ expansion, colors = c('#BF382A', '#0C4B8E'),
    hovertext = labs) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Publish Year'),
                     yaxis = list(title = 'Minimum Recommended Age'),
                     zaxis = list(title = 'Average Rating')),
         title = 'Board Games for All')

three_d_boardgames$sizingPolicy$padding <- ""0""

saveWidget(three_d_boardgames,
           ""BoardGame_Ratings.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""BoardGame Ratings cloud - TidyTuesday March 13, 2019"")


```





","2019-11"
"449",1052,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-04-10/Tennis_Stars.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=11)

# tt_data
```

```{r transform}


#cluster groupings over the years

three_d_boardgames<-tt_data$board_games %>%
  filter()
  mutate(labs=paste0(""<div><p>"",name,""</p><img href=\""https:"",image,""\""/a></div>"")) %>% 
  plot_ly(
    x = ~year_published,
    y = ~min_age,
    z = ~average_rating,
    color = ~ expansion, colors = c('#BF382A', '#0C4B8E'),
    hovertext = labs) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Publish Year'),
                     yaxis = list(title = 'Minimum Recommended Age'),
                     zaxis = list(title = 'Average Rating')),
         title = 'Board Games for All')

three_d_boardgames$sizingPolicy$padding <- ""0""

saveWidget(three_d_boardgames,
           ""BoardGame_Ratings.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""BoardGame Ratings cloud - TidyTuesday March 13, 2019"")


```





","2019-15"
"450",1053,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-04-24/ANIME.Rmd","---
title: ""Women in the Workforce - TidyTuesday 03-06-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=17)

# tt_data
```

```{r transform}


#cluster groupings over the years

tv_anime<-tt_data$tidy_anime %>%
  filter(type==""TV"") %>% 
  mutate(start_year=lubridate::year(start_date)) %>% 
  group_by(genre) %>% 
  filter(n()>2000) %>% 
  group_by(genre,start_year) %>% 
  summarise(mean_episodes=mean(episodes,na.rm=TRUE),
            mean_score=mean(score,na.rm=TRUE),
            n=n())%>% 
  group_by(start_year) %>% 
  mutate(perc= n / sum(n))


ggplot()+
  geom_bar(data=tv_anime,aes(x=start_year,
                y=perc,
                fill=genre,
                group=genre), stat=""identity"") + 
  scale_y_continuous(labels=scales::percent) + 
  scale_fill_brewer(palette=""Set3"")

  
  
### deep learning model to predict genres & score based on the description/year?


three_d_boardgames$sizingPolicy$padding <- ""0""

saveWidget(three_d_boardgames,
           ""BoardGame_Ratings.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""BoardGame Ratings cloud - TidyTuesday March 13, 2019"")


```





","2019-17"
"451",1054,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-01/bird_collisions.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=18)

tt_data
```

```{r transform}


#cluster groupings over the years

mp_birds<-tt_data$bird_collisions %>%
  filter(locality==""MP"") %>% 
  left_join(tt_data$mp_light) %>% 
  filter(!is.na(light_score))


summarized_collisions<-mp_birds %>% 
  group_by(habitat,stratum,date,flight_call) %>% 
  summarise(ncollisions=n(),
            light_score=mean(light_score))

ggplot(summarized_collisions)+
  geom_point(data=summarized_collisions,
             aes(x=date,
                 y=light_score,
                 size=ncollisions), alpha=.1) + 
  geom_point(aes(x=date,
                 y=light_score,
                 colour=habitat,
                 size=ncollisions)) +
  facet_grid(habitat~stratum)
  

```





","2019-18"
"452",1055,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-08/student_ratios.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
# devtools::install_github(""thebioengineer/tidytuesdayR"")
library(tidytuesdayR)
library(tidyverse)
library(rvest)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt_data<-tt_load(2019,week=19)

tt_data
```

```{r transform}

#download wikipeida information
happiness_score<-read_html(""https://en.wikipedia.org/wiki/World_Happiness_Report"") %>% 
  html_nodes("".wikitable"") %>% 
  html_table(fill=TRUE) %>% 
  `[[`(2) %>% 
  janitor::clean_names() %>% 
  select(overall_rank,country,score,gdp_per_capita) %>% 
  mutate(overall_rank = as.integer(overall_rank),
         score = as.numeric(score),
         gdp_per_capita = as.numeric(gdp_per_capita))


#cluster groupings over the years
ratio_2017<-tt_data$student_teacher_ratio %>%
  filter(year==""2017"") %>% 
  filter(country %in% happiness_score$country) %>% 
  inner_join(happiness_score) %>% 
  arrange(overall_rank) %>% 
  mutate(country=factor(country,levels = unique(country))) %>% 
  mutate(indicator=factor(indicator,levels= c(
    ""Pre-Primary Education"",""Primary Education"",
    ""Lower Secondary Education"",""Upper Secondary Education"", ""Secondary Education"",
     ""Tertiary Education"", ""Post-Secondary Non-Tertiary Education"")))



#nothing too interesting, just that it appears as though there is a larger difference in student ratio among ""happier"" countries 
ggplot(ratio_2017)+
  geom_tile(aes(y=country,x=indicator, fill=student_ratio))
  

```





","2019-19"
"453",1056,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-15/nobels.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

```

```{r transform}

#download wikipeida information
nobel_laureate_locations<-nobel_winners %>% 
  group_by(birth_country,organization_country,death_country,category) %>% 
  summarize(n=n()) %>% 
  arrange(n=desc(n))




nobel_laureate_birth_locations<-nobel_winners %>% 
  group_by(birth_country,organization_country,category) %>% 
  summarize(n=n()) %>% 
  arrange(n=desc(n))

nobel_laureate_death_locations<-nobel_winners %>% 
  group_by(organization_country,death_country,category) %>% 
  summarize(n=n()) %>% 
  arrange(n=desc(n))


node_Labels<-c(unique(nobel_laureate_locations$birth_country),
               unique(nobel_laureate_locations$organization_country),
               unique(nobel_laureate_locations$death_country))


length_birth_country<-length(unique(nobel_laureate_locations$birth_country))
length_organization_country<-length(unique(nobel_laureate_locations$birth_country))
length_death_country<-length(unique(nobel_laureate_locations$death_country))

node_birth_country<-setNames(seq(0,length_birth_country-1),unique(nobel_laureate_locations$birth_country))
node_organization_country<-setNames(seq(length_birth,length_birth+length_organization_country-1),unique(nobel_laureate_locations$organization_country))
node_death_country<-setNames(seq(length_birth+length_organization_country,length_birth+length_organization_country+length_death_country-1),unique(nobel_laureate_locations$death_country))




link_to_the_past_birth<-data.frame(
  source = node_birth_country[nobel_laureate_birth_locations$birth_country],
  target = node_organization_country[nobel_laureate_birth_locations$organization_country],
  value  = nobel_laureate_birth_locations$n,
  label  = nobel_laureate_birth_locations$category
)

link_to_the_past_death<-data.frame(
  source = node_organization_country[nobel_laureate_death_locations$organization_country],
  target = node_death_country[nobel_laureate_death_locations$death_country],
  value  = nobel_laureate_death_locations$n,
  label  = nobel_laureate_death_locations$category
)

link_to_the_past<-bind_rows(list(link_to_the_past_birth,link_to_the_past_death))

p <- plot_ly(
    type = ""sankey"",
    
    node = list(
      label = node_Labels,
      color =rep(""blue"",length(node_Labels)),
      pad = 5,
      thickness = 20,
      line = list(
        color = ""black"",
        width = 0.5
      )
    ),

    link = list(
      source = link_to_the_past$source,
      target = link_to_the_past$target,
      value  = link_to_the_past$value,
      label  = link_to_the_past$label
    )
  ) %>% 
  layout(
    title = ""Nobel - Laureate Locations"",
    font = list(
      size = 10
    )
)

p
  

```





","2019-20"
"454",1057,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-21/garbage.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-05-21"")
tt
```

```{r transform}


outputdataset<-tt$`per-capita-mismanaged-plastic-waste-vs-gdp-per-capita` %>% 
  
  rename(mismanaged_plastic = `Per capita mismanaged plastic waste (kilograms per person per day)`,
         gdp=`GDP per capita, PPP (constant 2011 international $) (Rate)`,
         total_pop =`Total population (Gapminder)`) %>% 
  
  left_join(  tt$`per-capita-plastic-waste-vs-gdp-per-capita` %>% 
              rename(total_plastic = `Per capita plastic waste (kilograms per person per day)`,
                     total_pop =`Total population (Gapminder)`) %>% 
                select(-`GDP per capita, PPP (constant 2011 international $) (constant 2011 international $)`,
                       -total_pop),
            by = c(""Entity"",""Code"",""Year"")) %>% 
  mutate( ratio_plastic = mismanaged_plastic/total_plastic ) %>% 
  filter(!is.na(ratio_plastic),
         !is.na(gdp))


#dichotomize ratio by GDP?
  
gdp_ratio<-ggplot(outputdataset)+
  geom_point(aes(x=gdp,
                 y=ratio_plastic,
                 text=Entity))+
  ggtitle(""Ratio of Mismanaged Plastic to Total Plastic by GDP in 2010"")+
  ylab(""Mismanaged/Total Plastic Waste Ratio"")+
  xlab(""Log 10 of Per Capita GDP ($)"")+
  # geom_density(aes(x=ratio_plastic,fill=HighGDP))+
  scale_x_log10()+
  geom_rug()
  
gdp_ratio_plotly<-ggplotly(gdp_ratio)

gdp_ratio_plotly$sizingPolicy$padding <- ""0""

saveWidget(gdp_ratio_plotly,
           ""2019-05-21/Plastic_Ratio_vs_GDP.html"",     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""atio of Mismanaged Plastic to Total Plastic by GDP in 2010 - TidyTuesday May 22, 2019"")

ggsave(""2019-05-21/Plastic_Ratio_vs_GDP.png"",gdp_ratio)


```





","2019-21"
"455",1058,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-05-28/winery_overtime.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(janitor)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-05-28"")
tt
```

```{r transform}


wine_trends<-tt$`winemag-data-130k-v2` %>% 
  
  select(country,points,title,variety) %>% 
  
  mutate(year = gsub(""(.*)([12][90]\\d{2})(.*)"",""\\2"",title),
         year = as.numeric(year,format=""%Y"")) %>% 
  
  filter(!is.na(year)) %>% 
  
  group_by(variety) %>% 

  filter(n()>5000) %>%  #keep only the most common wines
  
  filter(year < 2019, year > 1995) %>% 
  
  ungroup



#dichotomize ratio by GDP?
  
wine_trend_plot <- ggplot(wine_trends)+
  geom_point(aes(x=year,
                 y=points,
                 color = variety,
                 text=title))+
  geom_smooth(aes(x=year,
                 y=points,
                 color = variety))


```





","2019-22"
"456",1059,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-06-03/ramen_ratings.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(janitor)
library(pause)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-06-04"")
tt
```

```{r transform}

ramen_ratings<-tt$ramen_ratings

join<-function(...,by){
  return(list(...,inner_join(...,by)))
}


ramen_bowl <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Bowl"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""bowl"")  %>%
  mutate(name=paste(brand,variety,sep="" - ""))
  
ramen_cup <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Cup"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""cup"")  %>>>%
  mutate(name=paste(brand,variety,sep="" - ""))

ramen<-bind_rows(ramen_bowl,ramen_cup)


ramen_plot<-ggplot(ramen) +
  geom_point(aes(x=pack_stars,y=alt_stars, color = altstyle, text=name))+
  geom_abline(aes(slope=1,intercept=0))+
  ylab(""Ramen Bowl/Cup Stars"")+
  xlab(""Ramen Pack Stars"")+
  ggtitle(""Pack or Bowl/Cup- Which to choose?"")+
  theme_bw()
  
  

ggplotly(ramen_plot)



```





","2019-22"
"457",1060,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-06-17/christmas_birds.Rmd","---
title: ""Chicago Bird Collisions - TidyTuesday 05-01-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(rvest)

# devtools::install_github(""ropensci/plotly"") #the dev 
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-06-18"")
tt
```

```{r transform}

get_wiki_info<-function(bird_name){
  print(bird_name)
  read_html(paste0(""https://en.wikipedia.org/wiki/"",bird_name)) %>% 
    html_nodes("".infobox"") %>% 
    html_table() %>% 
    `[[`(1) %>% 
    set_names(c(""desc"",""value"")) %>% 
    filter(grepl("":|(IUCN)"",desc)) %>% 
    pull(value) %>% 
    set_names(c(""Conservation_Status"",""Kingdom"",""Phylum"",""Class"",""Order"",""Family"",""Genus"",""Species""))
}

Bird_info<-tt$bird_counts %>% 
  pull(species_latin) %>% 
  unique() %>% 
  map(~try(get_wiki_info(.x),silent = TRUE))

Bird_info %>% 
  lapply(function(x){if(!inherits(x,""try-error"")){x}}) %>% 
  do.call('rbind',.)

  
bird_info<-tt$bird_counts %>% 
  pull()
  
  
join<-function(...,by){
  return(list(...,inner_join(...,by)))
}


ramen_bowl <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Bowl"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""bowl"")  %>%
  mutate(name=paste(brand,variety,sep="" - ""))
  
ramen_cup <- ramen_ratings %>% 
  filter(style%in%c(""Pack"")) %>% 
  select(brand,variety,country,pack_stars = stars) %//% 
  
  ramen_ratings %>% 
  filter(style%in%c(""Cup"")) %>% 
  select(brand,variety,country,alt_stars = stars) %>>>%
  
  inner_join(by=c(""brand"",""variety"",""country"")) %>% 
  
  mutate(altstyle=""cup"")  %>>>%
  mutate(name=paste(brand,variety,sep="" - ""))

ramen<-bind_rows(ramen_bowl,ramen_cup)


ramen_plot<-ggplot(ramen) +
  geom_point(aes(x=pack_stars,y=alt_stars, color = altstyle, text=name))+
  geom_abline(aes(slope=1,intercept=0))+
  ylab(""Ramen Bowl/Cup Stars"")+
  xlab(""Ramen Pack Stars"")+
  ggtitle(""Pack or Bowl/Cup- Which to choose?"")+
  theme_bw()
  
  

ggplotly(ramen_plot)



```





","2019-24"
"458",1061,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-07-01/media_franchises.Rmd","---
title: ""Media Franchises- TidyTuesday 07-02-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

library(igraph)
library(htmlwidgets)

tt<-tt_load(""2019-07-02"")
tt
```

```{r transform}


revenue<-tt$media_franchises %>% 
  mutate(original_media=case_when(
                               original_media %in% 
                                 c(""Digital pet"") ~ ""Home Video/Entertainment"",
                               original_media %in% 
                                 c(""Animated film"",""Film"",""Musical theatre"") ~ ""Box Office"",
                               original_media %in%
                                 c(""Comic book"",""Comic strip"",""Manga"",""Visual novel"") ~ ""Comic or Manga"",
                               original_media %in%
                                 c(""Book"",""Novel"") ~ ""Book sales"",
                               original_media %in%
                                 c(""Greeting card"") ~ ""Merchandise, Licensing & Retail"",
                               original_media %in%
                                 c(""Video game"") ~ ""Video Games/Games"",
                               original_media %in%
                                 c(""Animated cartoon"",""Animated series"",""Anime"",""Cartoon"",
                                   ""Cartoon character"",""Television series"") ~ ""TV""
                               )) %>% 
  group_by(revenue_category,original_media) %>% 
  summarise(total_revenue=sum(revenue))

revenue_nodes<-graph_from_data_frame(revenue)
E(revenue_nodes)$width <- 1+E(revenue_nodes)$weight/12

plot(revenue_nodes,edge.curved=.2)


revenue_d3<-data.frame()

ggplotly(ramen_plot)



```





","2019-26"
"459",1062,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-07-09/Womens_world_cup.Rmd","---
title: ""Womens World Cup - TidyTuesday 07-09-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load(""2019-07-09"")
tt
```

```{r transform}


wwc_distance<-tt$wwc_outcomes %>%
  group_by(year,team) %>% 
  summarize(best_round = case_when(
    ""Final""               %in% round ~ ""Final"",
    ""Third Place Playoff"" %in% round ~""Third Place Playoff"",
    ""Semi Final""          %in% round ~ ""Semi Final"",
    ""Quarter Final""       %in% round ~ ""Quarter Final"",
    ""Round of 16""         %in% round ~ ""Round of 16"",
    ""Group""               %in% round ~ ""Group"")) %>%
  ungroup %>% 
  mutate(best_round=factor(best_round,c(""Final"",""Third Place Playoff"",""Semi Final"",""Quarter Final"",
                                       ""Round of 16"",""Group"")))

theme_bare <- theme(
  axis.line = element_blank(), 
  axis.ticks = element_blank(), 
  #axis.ticks.length = unit(0, ""lines""), # Error 
  axis.ticks.margin = unit(c(0,0,0,0), ""lines""), 
  legend.position = ""none"", 
  panel.background = element_rect(fill = ""black""), 
  panel.border = element_blank(), 
  panel.grid.major = element_blank(), 
  panel.grid.minor = element_blank(), 
  plot.background = element_rect(fill = ""gray""))

ggplot(wwc_distance)+
  geom_line(aes(x=year,y=abs(as.numeric(best_round)-7),color=team,size=1.5))+
  theme_bare+
  scale_y_continuous(breaks=c(6:1),
                     labels=levels(wwc_distance$best_round))+
  ylab(""Best Round Achieved"")+
  xlab(""World Cup Year"")+
  ggtitle(""World Cup Finishes"")


ggsave(""Womens_World_Cup_Finishes.png"")


```





","2019-28"
"460",1063,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-07-15/Tidyest_of_tuesday.Rmd","---
title: ""Tidyest of Tuesdays - TidyTuesday 07-15-2019""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load(""2019-07-16"")
tt
```

```{r transform}

wwc_distance<-tt$r4ds_members 

```





","2019-28"
"461",1064,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-08-28/tidy_simpsons.Rmd","---
title: ""Simpsons Guest Appearances""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load_gh(""2019-08-27"")
tt
```

```{r transform}

guest_appearances <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")



roles <- guest_appearances %>% 
  select(season,number,guest_star,role) %>% 
  rowwise() %>% 
  do(data.frame(season     = .$season,
                number     = .$number,
                guest_star = .$guest_star,
                role       = trimws(strsplit(.$role,"";"")[[1]])))


roles_ot <- roles %>% 
  distinct(season,guest_star,role) %>% 
  group_by(season,guest_star) %>% 
  summarize(nroles = n()) %>% 
  ungroup()


ggplot(roles_ot)+
  geom_density(aes(x=nroles))+
  facet_wrap(season~.)

  

```





","2019-35"
"462",1065,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-09-03/moores_law.Rmd","---
title: ""Moores Law""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)

tt<-tt_load(""2019-09-03"")
tt
```

```{r transform}

gpu_plot<-tt$gpu %>% 
  filter(!is.na(process)) %>% 
  mutate(details=paste(""Year Released:"",date_of_introduction,""<br>"",
                       ""Manufacturer:"",manufacturer_s,""<br>"",
                       ""Processor:"",processor)) %>% 
  ggplot() +
  scale_x_log10()+
  scale_y_log10()+
  geom_point(aes(x     = process,
                 y     = transistor_count,
                 color = designer_s,
                 label = details ))

ggplotly(gpu_plot)


roles_ot <- roles %>% 
  distinct(season,guest_star,role) %>% 
  group_by(season,guest_star) %>% 
  summarize(nroles = n()) %>% 
  ungroup()


ggplot(roles_ot)+
  geom_density(aes(x=nroles))+
  facet_wrap(season~.)

  

```





","2019-36"
"463",1066,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-09-10/Amusing_Injuries.Rmd","---
title: ""Amusing Injuries""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)
library(geofacet)

tt<-tt_load(""2019-09-10"")
tt
```

```{r transform}

injuries_by_state<-tt$saferparks %>% 
  select(state      = acc_state,
         industry   = industry_sector,
         operator   = op_error,
         mechanical = mechanical,
         employee   = employee,
         age        = age_youngest) %>% 
  mutate(operator = if_else(is.na(operator),0,1),
         mechanical = if_else(is.na(mechanical),0,1),
         employee = if_else(is.na(employee),0,1),
         other = as.numeric((operator + mechanical + employee) == 0 ))

injured_plots<-injuries_by_state %>% 
  gather(error_type,at_fault,operator,mechanical,employee,other) %>% 
  filter(at_fault == 1) %>% 
  ggplot(aes(x=age, fill = error_type)) +
  geom_density() +
  theme_bw() +
  facet_grid(industry~error_type)+
  theme(legend.position = NULL)


ggplotly(injured_plots)

```





","2019-37"
"464",1067,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-09-17/park_visits.Rmd","---
title: ""National Parks""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)
library(ggridges)
library(geofacet)

tt<-tt_load(""2019-09-17"")
tt
```

```{r transform}

top_state_park <- tt$national_parks %>% 
  filter(year==""Total"",
         !is.na(parkname)) %>% 
  group_by(state) %>% 
  summarise(bestPark=parkname[which.max(visitors)])


nparks<-tt$national_parks %>% 
  filter(year!=""Total"",
         !is.na(parkname)) %>% 
  mutate(year = as.Date(paste0(""01-01-"",year),format=""%m-%d-%Y"")) %>% 
  select(parkname,year,region,state,unit_type,visitors) %>% 
  filter(parkname %in% top_state_park$bestPark) %>% 
  group_by(region,parkname) %>% 
  mutate(regional_park_max = max(visitors)) %>% 
  group_by(parkname) %>% 
  mutate(visitors = visitors/max(visitors),
         age = min(year)) %>% 
  arrange(region,desc(age),year) %>% 
  ungroup %>% 
  mutate(
    region = factor(region,levels=unique(region)),
    parkname = factor(parkname,levels=unique(parkname))
  )

park_attendees<-nparks %>% 
  ggplot(aes(x = year,
           y = parkname,
           height=visitors,
           fill = region))+
  geom_ridgeline()+
  facet_grid(region~.,
             scales = ""free_y"",
             space = ""free_y"")+
  theme_minimal()+
  ggtitle(""Park Attendance Over Time (Normalized by maximal attendance)"")+
  theme(axis.text.y = element_text(vjust = -.25))
park_attendees

ggsave(filename = file.path(here::here(),""2019-09-17"",""Park_Attendance.png""),
       plot     = park_attendees,
       device   = ""png"",
       height   = 20,
       width    = 10)

```


```{r delta attendees percent}


delta<-function(x,index){
  x<-x[order(index)]
  delta<-c(NA,(x[seq(2,length(x))]-x[seq(1,length(x)-1)]))
  delta[delta==Inf]<-0
  delta
}

top_region_park <- tt$national_parks %>% 
  filter(year==""Total"",
         !is.na(parkname)) %>% 
    group_by(region) %>% 
  summarise(bestPark=parkname[which.max(visitors)])

tt$national_parks%>%
  filter(year!=""Total"",
         !is.na(parkname)) %>% 
  filter(parkname %in% top_region_park$bestpark) %>% 
  group_by(parkname)%>%
  arrange(year) %>% 
  mutate(delta_visitors=delta(visitors,year),
         delta_direction=ifelse(delta_visitors>0,""green"",""red""))%>%
  mutate(delta_visitors=ifelse(is.na(delta_visitors)|is.nan(delta_visitors),0,delta_visitors),
         totalSum=cumsum(delta_visitors))%>%
  ggplot()+
  geom_segment(aes(x=year,     xend = year,
                   y=totalSum, yend = totalSum-delta_visitors,
                   color=I(delta_direction)),
               size=2) +
  facet_wrap(department~.,
             scales = ""free_y"",
             strip.position = ""top"",
             ncol = 3) +
  ggtitle(label = ""US R&D Dollars"") +
  ylab(""? in visitors()"") +
  xlab(""Year"")



```
","2019-38"
"465",1068,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-01/pizza_party.Rmd","---
title: ""Pizza Party!!!""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(leaflet)
library(rvest)
library(htmlwidgets)

tt<-tt_load(""2019-10-01"")
tt
```

```{r transform}

pizzas <- tt$pizza_barstool %>% 
  filter(review_stats_community_average_score > 0) %>% 
  mutate(score_scaled = scale(review_stats_community_average_score)) %>% 
  select(name,
         address = address1,
         latitude,
         longitude,
         price = price_level,
         score = review_stats_community_average_score,
         score_scaled) %>% 
  rowwise() %>% 
  mutate(label=paste0(
    name,""<br>"",
    address,""<br>"",
    ""Score: "",round(score,2),""<br>"",
    ""Price: "",paste(rep(""$"",price+1),collapse=""""))
    )

```

```{r leaflet_plot}

calcColor<-function(x,colors,...,granularity=100){
  colfunc <- colorRampPalette(colors,...)
  colors<-colfunc(granularity)
  newx<-round((granularity-1 ) * ((x - min(x)) / (max(x) - min(x))))+1
  colors[newx]
}

calcRadius<-function(x,maxsize=100,minsize=5,method=scale_sigmoid){
    oneScaled<-((x - min(x)) / (max(x) - min(x)))
    (maxsize - minsize) * method(oneScaled)  + minsize;
}
scale_sigmoid<-function(x){
  (tanh((x-.5)*2*pi)+1)/2
}
scale_linear<-function(x){
  x
}

ll <- leaflet(pizzas) %>% 
  addTiles() %>%
  addCircleMarkers(
    lng= ~longitude,
    lat= ~latitude,
    radius = ~calcRadius(score_scaled,maxsize = 20,minsize=1,scale_sigmoid),
    popup = ~label,
    color = ~calcColor(price,color=c(""white"",""#ce0000"")),
    stroke = FALSE,
    fillOpacity = 0.5
  )

ll

```

","2019-40"
"466",1069,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-08/power_lifting_IPF.Rmd","---
title: ""The lift of POWER""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)

tt<-tt_load(""2019-10-08"")
tt
```

Do doping have an effect?

```{r transform}

doping_competitors <- tt$ipf_lifts %>% 
  filter(place==""DD"") %>% 
  pull(name)
  

# first event of doping for each person and center at that event
center_first_dope_event <- tt$ipf_lifts %>% 
  filter(name %in% doping_competitors) %>% 
  group_by(name) %>% 
  arrange(date) %>% 
  mutate(
    first_dope = min(date[place==""DD""]),
    npriordope = sum(date < first_dope),
    npostdope  = sum(date > first_dope)
  ) %>% 
  filter(npriordope > 0, npostdope >0) %>% 
  mutate(days_centered_first_dope = as.numeric(date - first_dope)) %>% 
  gather(""lift"",""kg"",starts_with(""best"")) %>% 
  group_by(name,lift) %>% 
  arrange(days_centered_first_dope) %>% 
  mutate(best_prior_dope = max(kg[days_centered_first_dope<0]),na.rm=TRUE) %>% 
  mutate(normalized_kg = kg/best_prior_dope) %>% 
  group_by(name) %>% 
  mutate(caught_again = any(place[days_centered_first_dope>0]==""DD""),
         better_post_dope = all(normalized_kg[days_centered_first_dope>0]>1.01)) %>% 
  ungroup()
  

```

```{r plot}

center_first_dope_event %>% 
  filter(!is.na(kg)) %>% 
  mutate( `DQed for Doping` = place==""DD"") %>% 
  mutate( caught_again = factor(if_else(
    caught_again,""DQ'ed for doping again"",""Never caught doping again""),
    levels = c(""Never caught doping again"",""DQ'ed for doping again""))) %>% 
  ggplot(aes(
    x=days_centered_first_dope,
    y=normalized_kg
    ))+
  geom_point(
    aes(color=`DQed for Doping`),
    alpha = .5
    )+
  geom_line(
    aes(group=name),
    alpha = .5
    )+
  geom_smooth()+
  geom_hline(
    aes(yintercept=1)
    )+
  facet_grid(lift~sex+caught_again, scales = ""free_y"")+
  scale_y_continuous(
    breaks = c(.5,.75,.9,1,1.1,1.25,1.5)
  )+
  theme_bw()+
  theme(legend.position = ""bottom"")+
  ggtitle(""Straight Dope"",""Athletes caught for doping after first offense tended to increase\n their best 3 lifts unlike athletes that were not caught again on average. \nThis might lend itself to the idea of needing more testing \nfor the athletes that continued to trend up at a high rate."")

ggsave(""2019-10-08/doping_results.png"")


```


```{r}

center_first_dope_event %>% 
  select(name,date,place,event,days_centered_first_dope) %>% 
  mutate(post_dope = days_centered_first_dope>0) %>% 
  distinct() %>% 
  group_by(name,post_dope) %>% 
  summarise(rank = mean(as.numeric(place),na.rm = TRUE)) %>% 
  spread(post_dope,rank) %>% 
  mutate(better_post = `TRUE` < `FALSE`) %>% 
  gather(post_dope,rank,`TRUE`,`FALSE`) %>% 
  ggplot(aes(x=post_dope,y=rank))+
  geom_boxplot()+
  geom_jitter(height = 0)+
  facet_grid(~better_post)+
  geom_line(aes(group=name))+
  scale_y_continuous(breaks = 1:10)


```
","2019-41"
"467",1070,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-15/EPA_EPA.Rmd","---
title: ""EPA EPA""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(plotly)
library(htmlwidgets)

tt<-tt_load(""2019-10-15"")
tt
```

Do doping have an effect?

```{r transform}

small_epa_cars <- tt$big_epa_cars %>% 
  select(highway08,co2,drive,fuelType,make,model,year,cylinders) %>% 
  distinct(make,model,fuelType,cylinders,.keep_all = TRUE) %>% 
  filter(co2>0) %>% 
  mutate( gco2pergallon = co2 * highway08 ) %>% 
  group_by(make) %>% 
  filter(n()>20) %>% 
  ungroup %>% 
  mutate(
    year = lubridate::as_date(paste0(year,""-01-01"")),
    drive = case_when(
      drive == ""All-Wheel Drive"" ~ ""4-Wheel Drive"",
      drive == ""Part-time 4-Wheel Drive"" ~ ""4-Wheel Drive"",
      TRUE ~ drive
    ),
    fuelType = case_when(
      grepl(""Gasoline"",fuelType) ~ ""Gasoline"",
      grepl(""Premium"",fuelType) ~ ""Premium"",
      grepl(""Regular"",fuelType) ~ ""Regular"",
      TRUE ~ fuelType
    ),
    cylinders = as.character(cylinders)
  )


```

```{r plot}

efficiency <- small_epa_cars %>% 
  mutate( year = lubridate::year(as.character(year))) %>% 
  mutate( Make = paste(make,""<br>Model:"",model,""<br>Year:"",year,""<br>Cylinders:"",cylinders)) %>%
  ggplot(aes(
    x=highway08,
    y=co2
    ))+
  geom_point(
    aes(color = drive,
        label = Make),
    alpha = .5
  )+
  facet_grid( ~ fuelType  )+
  theme_bw()+
  theme(legend.position = ""bottom"",legend.title = element_text(""Drivetrain Type"")) +
  ggtitle(""EPA EPA"",""Grams of CO2 produced vs Highway MPG, colored by make"")+
  ylab(""Tailpipe CO2 [grams/mile]"")+
  xlab(""Highway MPG"")



efficiency_plotly <- ggplotly(efficiency)%>%
  layout(legend = list(orientation = 'h',
                       x = 0.1, y = -0.1))

```


```{r}

efficiency_plotly$sizingPolicy$padding <- ""0""



saveWidget(efficiency_plotly,
           file.path(here::here(),""2019-10-15"",""bi_epa_mtcars.html""),     
           selfcontained = FALSE,
           libdir = ""lib"",
           title = ""CO2 vs Highway MPG"")

ggsave(file.path(here::here(),""2019-10-15"",""bi_epa_mtcars.png""),
       efficiency)


```","2019-42"
"468",1071,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","2019-10-29/squirrelly.Rmd","---
title: ""EPA EPA""
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r load_libraries}
library(tidyverse)
library(tidytuesdayR)
library(lubridate)
library(plotly)

tt<-tt_load(""2019-10-29"")
tt
```

```{r transform}



git_squirrelly <- tt$nyc_squirrel %>% 
  group_by(hectare) %>% 
  count() %>% 
  ungroup %>% 
  mutate(NS = substring(hectare,0,2),
         EW = substring(hectare,3)) %>% 
  select(-hectare) %>% 
  spread(EW,n) %>% 
  gather(EW,n,-NS)
 


```

```{r plot}

squirrelly <- git_squirrelly %>% 
  mutate(EW = factor(EW,levels = rev(unique(EW)))) %>% 
  ggplot(aes(
    y=EW,
    x=NS
    ))+
  geom_tile(
    aes(fill = n),
    # shape = 15,
    # size = 5
    width = .9,
    height = .9
    )+
  coord_equal()+
  theme_minimal()+
  theme(legend.position = ""right"",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()
        ) +
  ggtitle(""Squirrel Observations in Central Park(NYC)"")+
  xlab(""Hectare ID (North-South)"")+
  ylab(""Hectare ID (East-West)"")+
  scale_fill_continuous(low=""lightgreen"",high=""darkgreen"")


squirrelly_plotly <- ggplotly(squirrelly)%>%
  layout(legend = list(orientation = 'h',
                       x = 0.1, y = -0.1))

```


```{r}

# squirrelly_plotly$sizingPolicy$padding <- ""0""
# 
# 
# saveWidget(squirrelly_plotly,
#            file.path(here::here(),""2019-10-29"",""squirrelly.html""),     
#            selfcontained = FALSE,
#            libdir = ""lib"",
           # title = ""Squirrel locations in "")

ggsave(file.path(here::here(),""2019-10-29"",""squirrelly.png""),
       squirrelly,
       width = 10,
       height = 3)


```","2019-44"
"469",1076,"https://github.com/ethantenison/TidyTuesday-","ethantenison","TidyTuesday-","2019-06-24/README.rmd","## Lessons from Tidy Tuesday 

******

Tidy Tuesday is a terrific opportunity to practice wrangling data and chart visualizations in R. Interesting data sets are available each week. Other R enthusiasts provide feedback and seeing their charts generates ideas.

Below are lessons that I have learned from my submissions.

| Week        | Data Set | Lesson                    | Function       | Package |
| :--:        |:--:      |:--:                       |:--:            |:--:     |
|`2019-06-24` | UFOs     | Customize legend position |legend.position |ggplot2  |","2019-25"
"470",1077,"https://github.com/ethantenison/TidyTuesday-","ethantenison","TidyTuesday-","2019-06-24/UFOs_Over_Texas.R","#First R submission 
library(tidyverse)
library(janitor)
library(lubridate)
library(extrafont)
library(ggdark)


        ufo_raw<- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"") 
        clean_names ()


        map_borders <-  map_data(""state"", region = NULL) %>% filter (region == ""texas"")  
        
        ufo <- ufo_raw %>% select (date_time, city_area, state, latitude, longitude, encounter_length) %>%
        
        filter (
                state == ""tx"",
                latitude > 25,      # remove borders erroneously listed as TX outside of state borders
                latitude < 38,      # remove borders erroneously listed as TX outside of state borders
                longitude < -90     # remove borders erroneously listed as TX outside of state borders
                )  %>%
        mutate(
                encounter_length = encounter_length/3600,              #convert seconds to hours
                date_time = as.Date(date_time, format = ""%m/%d/%Y"")
                ) 
                



        ggplot () +#plot Texas borders
                geom_polygon (data = map_borders, aes(x = long, y = lat, group = group), 
                color = ""black"", fill = ""#303030"", size = 1.15) +
                
        #plot UFO encounters
        geom_point (data = ufo, aes (x = longitude, y = latitude, size = encounter_length), color = ""green"") +
        
        #Clifton encounter annotation
        annotate(""text"",label = ""42 day encounter\nin Clifton in 1966."",size = 3, hjust = 0, color = ""magenta"", family = ""Rockwell"",
               x = -92.57639, y = 31.78222, xmax = -83.5) +
        
        geom_curve(
                aes(x = -92.5, y = 31.7, xend = -97.57639, yend = 31.78222),
                arrow = arrow(length = unit(0.2, ""cm"")), 
                size = 0.4, color = ""magenta"", curvature = -0.3
        ) +
        coord_fixed(1.3) +
        scale_size_continuous(breaks = c(1, 10, 100)) +
        dark_mode(theme_minimal()) +
        theme(text = element_text(family = ""Rockwell"", color = ""green""),
        plot.title = element_text(hjust = 0.5, size = 18),
        plot.caption = element_text(hjust = 0, size = 8),
        legend.title = element_text(size = 10, hjust = 0.5, vjust = 0.5),
        legend.text = element_text(size = 9, hjust = 0.5, vjust = 0.5),
        legend.position = c(0.82,0.18),
        legend.justification=c(0, 1), 
        legend.key.size = unit(0.1, 'lines'),
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank()
        ) +
        labs(
        title = ""UFOs over Texas\n"",
        size = ""Encounter (hrs)"",
        caption = ""\nEach dot represents a reported UFO sighting between 1910 and 2014.  
                \nSource: National UFO Reporting Center  | Visualization: Ethan Tenison @sassyStatistics""
        ) +
ggsave(""ufo.png"", height =3.85)

","2019-25"
"471",1078,"https://github.com/ethantenison/TidyTuesday-","ethantenison","TidyTuesday-","2019-07-09/WWC_Top12.Rmd","---
title: ""WWC Wins""
author: ""Ethan Tenison""
date: ""7/12/2019""
output: html_document
---
### 1a. Source WWC data
```{r source, warning = TRUE, results = FALSE, message = FALSE}
library(dplyr)        ## data wrangling
library(tidyr)        ## data wrangling
library(purrr)        ## data wrangling and iteration
library(stringr)      ## data wrangling
library(rvest)        ## webscraping
library(polite)       ## webscraping (Github only pkg)
library(ggplot2)      ## plotting
library(scales)       ## plotting scales
library(ggimage)      ## images for flags
library(ggforce)      ## plotting text labels
library(cowplot)      ## plotting grid
library(glue)         ## text
library(ggrepel)      ## plotting text labels
library(magick)       ## plotting
library(ggtextures)   ## soccer ball emoji as geom_col()
library(extrafont)    ## fonts: Roboto Condensed

    wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
    squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
    codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
```

### 2.  Transform WWC data
```{r transform, message = F}
#separating the top 10 countrie 
top10_countries <- c(""USA"", ""GER"", ""NOR"", ""SWE"", ""BRA"", ""CHN"", ""ENG"", ""JPN"", ""FRA"", ""CAN"")
top10 <- filter(wwc_outcomes, team %in% top10_countries)

#creating an object that contains flag ISO codes to use with geom_flags
flag_data <- data.frame(
  image = c(""us"", ""de"", ""no"",  ""se"", ""br"", ""cn"", ""gb-eng"", ""jp"", ""fr"", ""ca""),
  x = c(10, 20,30,40,50,60, 70,80,90,100),
  y = c(-10, -10,-10,-10,-10,-10,-10,-10,-10,-10)
)

```

### 3. Visualize data
```{r plot}
   library (ggdark)
   library(ggimage)
   library(ggforce)

      #raw plot the win status of top 10 
      rawplot <- ggplot(data = top10, aes(x =factor(team), fill = factor(win_status))) 
              + geom_bar()+ coord_flip()+ geom_text(aes(label=..count..), stat = ""count"", position = position_stack(0.5)) 
              + scale_x_discrete(limits=c(""CAN"",""FRA"", ""ENG"", ""JPN"", ""CHN"", ""BRA"", ""SWE"", ""NOR"", ""GER"", ""USA"")) 
              + dark_theme_minimal() +theme(axis.title.x=element_blank(), line =     axis.text.x=element_blank(),axis.ticks.x=element_blank()) + theme(axis.title.y=element_blank()) 
              + theme(plot.title = element_text(size=18, hjust = 2)) 
              + theme(legend.title = element_blank()) 
              + labs(title = ""Women's World Cup: Top 10 Winners from 1991 to 2019\n"",caption = ""\nSource: data.world  |     Visualization: Ethan Tenison @SassyStatistics"") 
      
      #Add flags to y-axis
      axis_image <- axis_canvas(rawplot, axis = 'y') + 
  draw_image(""https://upload.wikimedia.org/wikipedia/en/a/a4/Flag_of_the_United_States.svg"", 
             y = 49.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/b/ba/Flag_of_Germany.svg"", 
             y = 44, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/d/d9/Flag_of_Norway.svg"", 
             y = 38.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/4/4c/Flag_of_Sweden.svg"", 
             y = 33, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/0/05/Flag_of_Brazil.svg"", 
             y = 27.5, scale = 3.5) +
   draw_image(""https://upload.wikimedia.org/wikipedia/commons/f/fa/Flag_of_the_People%27s_Republic_of_China.svg"", 
             y = 22, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/1/1b/Flag_of_Japan_%281870%E2%80%931999%29.svg"", 
             y = 16.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/b/be/Flag_of_England.svg"", 
             y = 11, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/en/c/c3/Flag_of_France.svg"", 
             y = 5.5, scale = 3.5) +
  draw_image(""https://upload.wikimedia.org/wikipedia/commons/1/1f/Flag_of_Canada_%281964%29.svg"", 
             y = 0, scale = 3.5) 
  
     
        top10 <- ggdraw(insert_yaxis_grob(rawplot, 
  axis_image, position = ""left""))
        
      
```


### 4.  Save data
```{r}

ggsave(""wwc_top10_teams.png"", width = 14, height = 12)

```
","2019-28"
"472",1095,"https://github.com/cienciadedatos/datos-de-miercoles","cienciadedatos","datos-de-miercoles","datos/2019/2019-05-01/ejemplos_visualizacion.Rmd","---
title: ""Ejemplos de visualizacin""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
load(""comercio_hispanoamerica_mundo_agregado.rda"")

if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(tidyverse, treemapify)
```

```{r}
comercio_chile_mundo <- comercio_hispanoamerica_mundo_agregado %>% 
  filter(codigo_iso_origen == ""chl"")

comercio_chile_mundo %>% 
  mutate(
    region = ifelse(pais_destino_pertenece_a_hispanoamerica == 1, ""Hispanoam\u00e9rica"", ""Otras regiones"")
  ) %>% 
  group_by(anio, region) %>% 
  summarise(valor_exportado_dolares = sum(valor_exportado_dolares, na.rm = T)) %>% 
  ggplot(aes(x = anio, y = valor_exportado_dolares, fill = region)) +
    geom_col(position = ""dodge2"") +
    labs(
      x = ""A\u00f1o"", 
      y = ""Valor Exportado (D\u00f3lares)"", 
      title = ""Exportaciones de Chile por A\u00f1o y Regi\u00f3n""
    ) +
    coord_flip() +
    theme_bw() +
    theme(legend.position = ""bottom"")
```

```{r}
comercio_chile_mundo_2017 <- comercio_chile_mundo %>% 
  filter(anio == 2017) %>% 
  group_by(anio, nombre_comunidad_producto, color_comunidad_producto) %>% 
  summarise(valor_exportado_dolares = sum(valor_exportado_dolares, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(
    etiquetas = paste0(nombre_comunidad_producto, ""\n"", round(100*valor_exportado_dolares/sum(valor_exportado_dolares), 2), ""%"")
  )

comercio_chile_hispanoamerica_2017 <- comercio_chile_mundo %>% 
  filter(anio == 2017, pais_destino_pertenece_a_hispanoamerica == 1) %>% 
  group_by(anio, nombre_comunidad_producto, color_comunidad_producto) %>% 
  summarise(valor_exportado_dolares = sum(valor_exportado_dolares, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(
    etiquetas = paste0(nombre_comunidad_producto, ""\n"", round(100*valor_exportado_dolares/sum(valor_exportado_dolares), 2), ""%"")
  )
```

```{r}
ggplot(comercio_chile_mundo_2017, 
       aes(area = valor_exportado_dolares, fill = nombre_comunidad_producto, label = etiquetas)) +
  geom_treemap() +
  geom_treemap_text(colour = ""white"",
                    place = ""centre"",
                    grow = F,
                    reflow = T) +
  scale_fill_manual(values = comercio_chile_mundo_2017$color_comunidad_producto) +
  labs(title = ""Exportaciones de Chile a nivel Mundial (2017)"") +
  theme_bw() +
  theme(legend.position = ""none"")

ggplot(comercio_chile_hispanoamerica_2017, 
       aes(area = valor_exportado_dolares, fill = nombre_comunidad_producto, label = etiquetas)) +
  geom_treemap() +
  geom_treemap_text(colour = ""white"",
                    place = ""centre"",
                    grow = F,
                    reflow = T) +
  scale_fill_manual(values = comercio_chile_hispanoamerica_2017$color_comunidad_producto) +
  labs(title = ""Exportaciones de Chile a nivel de Hispanoam\u00e9rica (2017)"") +
  theme_bw() +
  theme(legend.position = ""none"")
```

","2019-18"
"473",1096,"https://github.com/cienciadedatos/datos-de-miercoles","cienciadedatos","datos-de-miercoles","datos/2019/2019-10-23/README.Rmd","---
title: 'Constitucin Abierta: Una Nueva Constitucin Para Chile'
author: ""Pach""
date: ""10/23/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduccin

Durante el ao 2016, en Chile se llev a cabo un proceso de consulta a los ciudadanos chilenos con la finalidad de conocer sus principales preocupaciones y cmo llevar estas a una nueva Constitucin Poltica de la Repblica.

Inicialmente el proceso de consulta fue llevado a cabo con poca transparencia, pero afortunadamente la presin de la sociedad civil llev a hacer disponibles pblicamente las actas de estos encuentros de debate ciudadano.

La forma de reunir las opiones fue registrar actas de encuentros en los cuales los vecinos de distintas comunas del pas se reunieron a debatir y manifiestar sus puntos de acuerdo y desacuerdo respecto de Derechos Humanos, Salud, Educacin, Pensiones, entre otros.

El sitio web del proyecto Constitucin Abierta (DCC UChile) estableca que: ""Los datos del Proceso Constituyente deben estar disponibles abiertamente para todas y todos los chilenos.""

Estos datos provienen de un proceso impulsado por el Departamento de Ciencias de la Computacin de la Universidad de Chile, el cual se dedic a reunir de manera paralela las actas de las instancias de participacin.

# Paquetes

Sugerimos usar el tidyverse para manipular y visualizar los datos. Para visualizar usando mapas, se podra usar el paquete `chilemaps` disponible en github.com/pachamaltese/chilemaps.

```{r}
library(tidyverse)
```

# Datasets

Contienen los conceptos clave discutidos y la justificacin de los acuerdos o desacuerdos.

## Conceptos

Resume los tpicos tratados durante las reuniones, si hubo acuerdo o no y su justificacin. Incluye los datos geogrficos (comuna y regin) del lugar de encuentro.

```{r}
load(""~/datos-de-miercoles/datos/2019/2019-10-23/01-conceptos.rdata"")
conceptos
```

La columna `idELA` permite unir con la tabla `memoria`.

## Memoria

Sintetiza el nimo sostenido durante el encuentro.

```{r}
load(""~/datos-de-miercoles/datos/2019/2019-10-23/02-memoria.rdata"")
memoria
```
","2019-43"
"474",1097,"https://github.com/cienciadedatos/datos-de-miercoles","cienciadedatos","datos-de-miercoles","datos/2019/2019-10-23/exportar-sql-a-rdata.R","library(RMariaDB)
library(tidyverse)

# sacar datos de sql ----

con <- dbConnect(RMariaDB::MariaDB(), group = ""constitucionabierta"")

dbListTables(con)

# comuna <- tbl(con, ""Comuna"") %>% collect() %>% as_tibble()
conceptos <- tbl(con, ""Conceptos"") %>% collect() %>% as_tibble()
ela <- tbl(con, ""ELA"") %>% collect() %>% as_tibble()
memoria <- tbl(con, ""Memoria"") %>% collect() %>% as_tibble()

# arreglar comunas ----

# este dataset viene de github.com/pachamaltese/chilemaps
load(""~/datos-de-miercoles/datos/2019/2019-10-23/territorial_codes.rda"")

conceptos <- conceptos %>% 
  left_join(ela) %>% 
  select(-c(id, tema, estado, numeroConcepto, esOtros)) %>% 
  mutate(
    comuna = iconv(comuna, from = ""UTF-8"", to = ""ASCII//TRANSLIT"", sub = """"),
    comuna = str_trim(comuna),
    comuna = str_replace_all(comuna, ""[^[:alnum:]|[:space:]]"", """"),
    comuna = str_to_title(comuna)
  ) %>%
  mutate(
    comuna = str_replace_all(comuna, "" De "", "" de ""),
    comuna = str_replace_all(comuna, "" Del "", "" del ""),
    comuna = str_replace_all(comuna, "" La "", "" la ""),
    comuna = str_replace_all(comuna, "" Las "", "" las ""),
    comuna = str_replace_all(comuna, "" Los "", "" los ""),
    comuna = str_replace_all(comuna, "" Y "", "" y ""),
    comuna = str_replace_all(comuna, ""Ohiggins"", ""OHiggins"")
  ) %>% 
  mutate(
    comuna = case_when(comuna == ""La Calera"" ~ ""Calera"",
                       comuna == ""Coyhaique"" ~ ""Coihaique"",
                       comuna == ""San Vicente de Tagua Tagua"" ~ ""San Vicente"",
                       comuna == ""Aysen"" ~ ""Aisen"",
                       comuna == ""Paihuano"" ~ ""Paiguano"",
                       TRUE ~ comuna)
  ) %>% 
  left_join(territorial_codes, by = c(""comuna"" = ""commune_name"")) %>% 
  # select(comuna:commune_id) %>% 
  # distinct() %>% 
  # filter(is.na(region_id))
  select(idELA:fecha, id_comuna = commune_id, comuna, id_region = region_id, region = region_name)

# guardar ----

# save(comuna, file = ""01-comuna.rdata"", compress = ""xz"")
save(conceptos, file = ""01-conceptos.rdata"", compress = ""xz"")
# save(ela, file = ""03-ela.rdata"", compress = ""xz"")
save(memoria, file = ""02-memoria.rdata"", compress = ""xz"")
","2019-43"
"475",1100,"https://github.com/benmoretti/tidytuesdays/tree/master/2019-03-26","benmoretti","tidytuesdays","2019-03-26/seattle_pet_names.R","#' tidytuesday 20-03-26
#' Seattle Pet Names


# Libraries ---------------------------------------------------------------

library(tidyverse)
library(lubridate)
library(zipcode)
library(timetk)
library(leaflet)
library(janitor)

# Gather ------------------------------------------------------------------

data(zipcode)

seattle_pets_tbl <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")


# Condition ---------------------------------------------------------------

seattle_pets_conditioned_tbl <- seattle_pets_tbl %>%
  clean_names() %>%
  mutate(
    license_issue_date = mdy(license_issue_date)
  ) %>%
  inner_join(zipcode, by = c(""zip_code""=""zip"")) %>%
  tk_augment_timeseries_signature()



# Visualise ---------------------------------------------------------------

# map the location of cats in 2018 by zip code
seattle_pets_conditioned_tbl %>%
  filter(
    species == ""Cat"",
    year == 2018
  ) %>%
  count(zip_code, latitude, longitude) %>%
  leaflet() %>% addTiles() %>% addCircleMarkers()


common_names_plot <- seattle_pets_tbl %>%
  count(animals_name, species) %>%
  spread(species, n) %>%
  filter(
    ! is.na(Cat),
    ! is.na(Dog),
    ! is.na(Pig)
  ) %>%
  select(-Goat) %>%
  mutate(total = Cat + Dog + Pig) %>%
  gather(species, count, -animals_name, -total) %>%
  drop_na(animals_name) %>%
  mutate(
    animals_name = fct_reorder(animals_name, total)
  ) %>%
  ggplot(aes(animals_name, count)) +
  geom_col(aes(fill=species)) +
  theme_light() +
  scale_fill_viridis_d() +
  coord_flip() +
  theme(legend.position = ""bottom"") +
  labs(
    title = ""Common Seattle Pet Names"",
    x = ""Animal Name"",
    y = ""Count"",
    fill = ""Animal Species"",
    subtitle = ""Source: Seattle Open Data"",
    caption = ""#tidytuesday / 2019-03-26 / @benmoretti""
  ) 

ggsave(""2019-03-26/common_names.png"", common_names_plot)  
  
","2019-13"
"476",1101,"https://github.com/benmoretti/tidytuesdays/blob/master/2019-03-12/boardgames.R","benmoretti","tidytuesdays","2019-03-12/boardgames.R","#' boardgames.R


# Libraries ---------------------------------------------------------------

library(tidyverse)
library(janitor)
library(vapoRwave)
library(extrafont)


# Gather ------------------------------------------------------------------

board_games_tbl <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"") %>% clean_names()


# Visualise -------------------------------------------------------------------


# Top 8 Board Games Mechanics vs Time ------------------------------------

# get a character array of the top 8 mechanics
top_8_mechanics <- board_games_tbl %>% 
  separate_rows(mechanic, sep = "","") %>% 
  count(mechanic) %>%
  arrange(desc(n)) %>%
  drop_na(mechanic) %>%
  slice(1:8) %>%
  pull(mechanic)

# just a simple line plot but using vapoRwave theme
board_games_tbl %>% 
  separate_rows(mechanic, sep = "","") %>%
  filter(mechanic %in% top_8_mechanics) %>%
  count(mechanic, year_published) %>%
  ggplot(aes(year_published, n)) +
  geom_line(aes(colour=mechanic), size=2) +
  floral_shoppe() + 
  scale_color_floralShoppe() +
  labs(
    title = ""Top 8 Board Games' Mechanics vs Time"",
    subtitle = ""Source: boardgamegeek.com / @benmoretti"",
    x = ""Year"",
    y = ""Number of Games""
  ) +
  theme(
    legend.position = ""bottom""
  )
  
ggsave(""2019-03-12/Growth_vs_time.png"")


# The average rating for the top game of each year vs time -------------------------------------

board_games_tbl %>%
  group_by(year_published) %>%
  arrange(desc(average_rating)) %>%
  slice(1) %>%
  ungroup() %>%
  ggplot(aes(year_published, average_rating)) +
  geom_point(aes(size=users_rated), colour=""#E3D26F"") +
  geom_smooth(se=FALSE, linetype=""dashed"", colour = ""#FAA275"") +
  floral_shoppe() + 
  scale_colour_floralShoppe() +
  labs(
    title = ""The average rating for the top game of each year vs time"",
    subtitle = ""Source: boardgamegeek.com / @benmoretti"",
    x = ""Year"",
    y = ""Average Rating""
  ) +
  theme(
    legend.position = ""bottom""
  )

ggsave(""2019-03-12/rating_vs_time.png"")

","2019-11"
"477",1102,"https://github.com/benmoretti/tidytuesdays/blob/master/2019-02-26/french_trains.R","benmoretti","tidytuesdays","2019-02-26/french_trains.R","#' french_trains.R
#'
#' @author Ben Moretti
#'
#' @description Reads data for the 26 Feb 2019 #tidytuesday - French Trains - and visualises using ggalluvial


# Libraries -----------------------------------------------------------------

library(tidyverse)
library(lubridate)
library(ggalluvial)
library(gganimate)

# Gather ------------------------------------------------------------------

trains_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")


# Condition ---------------------------------------------------------------

# select data for paris departures for july 2017
paris_2017_trips <- trains_raw %>% 
  filter(
    year == 2017,
    month == 7,
    str_detect(departure_station, ""PARIS"")
  ) %>% 
  select(departure_station, arrival_station, total_num_trips, month) 

# check that it's in alluvial format - should return true
is_alluvia_form(paris_2017_trips, axes = 1:2, silent = TRUE)  

# Plot --------------------------------------------------------------------

# create alluvial plot
paris_2017_trips %>%
  ggplot(aes(y = total_num_trips, axis1 = departure_station, axis2 = arrival_station)) +
  geom_alluvium(aes(fill = departure_station)) +
  guides(fill = FALSE) +
  geom_label(stat = ""stratum"",
             label.strata = TRUE,
             size = 2) +
  scale_x_discrete(limits = c(""Departure"", ""Arrival""),
                   expand = c(0.05, 0.05)) +
  scale_fill_viridis_d() +
  theme_minimal() +
  theme(legend.position = ""none"") +
  labs(
    title = ""Train trips departing from Paris stations in July 2017"",
    y = ""Total Number of Trips"",
    subtitle = ""Source: SNCF"",
    caption = ""#tidytuesday by @benmoretti""
  ) 


# Output ------------------------------------------------------------------


#save png
ggsave(""2019-02-26/paris_july_2017_trains.png"", units = ""mm"", width=297, height=210)
","2019-9"
"478",1103,"https://github.com/benmoretti/tidytuesdays/blob/master/2019-02-19/phds_by_field.R","benmoretti","tidytuesdays","2019-02-19/phds_by_field.R","#' phds_by_field.R
#' 
#' R script for 19 February 2019 #TidyTuesday 
#'


# Libraries ---------------------------------------------------------------

library(tidyverse)
library(collapsibleTree)
library(skimr)
library(magrittr)
library(tidyquant)


# Configuration -----------------------------------------------------------

# define source url
source_url <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv""


# Gather ------------------------------------------------------------------

# read + tidy
phd_by_field_tbl <- read_csv(source_url) %>%
  replace_na(list(n_phds = 0)) %>%
  mutate_if(is.character, factor)
  

# Visualise ---------------------------------------------------------------

# collapsible tree for top two levels in hierarchy
phd_by_field_tbl %>%
  group_by(broad_field, major_field) %>% 
  summarise(
    n_major_field_phds = sum(n_phds)
  ) %>%
  ungroup() %>%
  collapsibleTreeSummary(
    hierarchy = c(""broad_field"", ""major_field""),
    attribute = ""n_major_field_phds"",
    nodeSize = ""n_major_field_phds"",
    fillFun = colorspace::rainbow_hcl,
    collapsed = FALSE
  )

# heat map Heatmap for number of PhDs in Agricultural sciences and natural resources
phd_by_field_tbl %>%
  mutate(
    date = lubridate::make_date(year=year)
  ) %>%
  filter(major_field == ""Agricultural sciences and natural resources"") %>%
  arrange(field) %>%
  ggplot(aes(date, field)) +
  geom_raster(aes(fill=n_phds)) +
  theme_tq() +
  scale_fill_gradient(low = palette_light()[[1]], high = palette_light()[[5]]) +
  labs(
    title = ""#TidyTuesday, 19 February 2019"",
    subtitle = ""Heatmap for number of PhDs in Agricultural sciences and natural resources"",
    x = ""Year"",
    y = """",
    caption = ""By @benmoretti""
  )

# Annual relative difference plot of PhDs in Agricultural sciences and natural resources
phd_by_field_tbl %>%
  group_by(broad_field, major_field, field) %>%
  arrange(year) %>%
  mutate(
    previous_year_n_phds = lag(n_phds),
    annual_change_pc = (n_phds - previous_year_n_phds) / previous_year_n_phds
  ) %>%
  select(-previous_year_n_phds) %>%
  filter(! is.na(annual_change_pc)) %>%
  mutate(
    date = lubridate::make_date(year=year)
  ) %>%
  filter(major_field == ""Agricultural sciences and natural resources"") %>%
  ggplot(aes(date, annual_change_pc)) +
  geom_point() +
  geom_smooth(colour=palette_light()[[6]]) +
  geom_segment(aes(yend=annual_change_pc, xend=date)) +
  scale_y_continuous(labels=scales::percent) +
  theme_tq() +
  facet_wrap(vars(field), scales=""free_y"") +  
  labs(
    title = ""#TidyTuesday, 19 February 2019"",
    subtitle = ""Annual relative difference plot of PhDs in Agricultural sciences and natural resources"",
    x = ""Year"",
    y = ""Change"",
    caption = ""By @benmoretti""
  )

","2019-8"
"479",1117,"https://github.com/cpdavis/tidytuesday/tree/master/data/2019/2019-06-25","cpdavis","tidytuesday","data/2019/2019-06-25/tt_062519.Rmd","---
title: ""Tidy Tuesday: UFO Encounters""
author: ""Charles Davis""
date: ""6/25/2019""
output:
  html_document:
    toc: yes
  html_notebook:
    code_folding: hide
    df_print: paged
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)

setwd(""~/Desktop/tidytuesday/data/2019/2019-06-25"")
ufo = read.csv(""ufo_sightings.csv"")

```

OK. What can we ask with this dataset?

- Do the number of UFO sighting vary by country? Does the length of UFO encounter vary by country?

```{r country}

ufo %>% 
  group_by(country) %>%
  summarise(count=n())

ufo %>%
  group_by(country) %>%
  summarise(avg_length=mean(encounter_length, na.rm=TRUE))

```

So it's pretty clear that the US is the main UFO hotspot. Let's focus our attention there. Are there particularly good UFO-viewing spots in the US? 

```{r state n}

# first we need to load in some map data

state_map <- map_data(""state"")
stateInfo=cbind.data.frame(abb=tolower(state.abb), name=tolower(state.name))
state <- inner_join(state_map, stateInfo, by=c(""region""=""name""))

# let's check the counts of UFO sightings by state

state_n <- ufo %>%
  dplyr::filter(country == ""us"") %>%
  group_by(state) %>%
  summarise(count=n())

state_n <- inner_join(state, state_n, by=c(""abb""=""state""))
state_n$abb <- as.factor(state_n$abb)

ggplot(data=state, mapping=aes(x=long, y=lat, group=group)) + 
  geom_polygon(data=state_n, aes(fill=count), color=""white"") +
  theme_void() +
  labs(fill=""number of encounters"") +
  scale_fill_gradientn(colors=RColorBrewer::brewer.pal(name=""Greens"", n=48))

```

OK. That's kind of boring. Where more people live, more people see aliens. But maybe there are places where UFO encounters are particularly long. 

```{r state len}

ufo %>% 
  dplyr::filter(country == ""us"") %>% 
  ggplot(aes(x=as.factor(encounter_length))) + 
  geom_histogram(stat=""count"") +
  theme(axis.title.x = element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())

# since the data are clearly skewed, we'll do the rest of the analysis on log-transformed encounter length

state_len <- ufo %>%
  dplyr::filter(country == ""us"") %>%
  group_by(state) %>%
  summarise(avg_length=mean(log(encounter_length), na.rm=TRUE))

state_len <- inner_join(state, state_len, by=c(""abb""=""state""))
state_len$abb <- as.factor(state_len$abb)

length_plot <- ggplot(data=state, mapping=aes(x=long, y=lat, group=group)) + 
  geom_polygon(data=state_len, aes(fill=avg_length), color=""white"") +
  theme_void() +
  labs(fill=""encounter length in log(min)"") +
  scale_fill_gradientn(colors=RColorBrewer::brewer.pal(name=""Greens"", n=48)) +
  ggtitle(""Length of UFO encounters across the United States"") +
  theme(plot.title = element_text(size=32, face=""bold""), legend.position = ""bottom"") 
length_plot

alien_plot <- ggdraw() + 
  draw_plot(length_plot) +
  draw_image(""~/Desktop/tidytuesday/data/2019/2019-06-25/alien.jpg"", scale=0.3, width=1.8, height=0.5)
alien_plot
```

Aha! As we might expect, New Mexico and Arizona are right up there. The clear skies of Maine also seem conducive to UFO sightings.","2019-27"
"480",1119,"https://github.com/Nicey80/tidytuesday/blob/master/2019-07-02/19-07-02.R","Nicey80","tidytuesday","2019-07-02/19-07-02.R","media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

library(tidyverse)

m2 <- media_franchises %>% 
    group_by(original_media, year_created) %>%
    summarise(revenue=sum(revenue)) %>% 
    as_tibble()

m2 %>% 
    filter(!original_media %in% c(""Cartoon"",""Cartoon character"",""Comic strip"", ""Digital pet"",""Greeting card"", ""Musical theatre"",""Visual novel"")) %>% 
    ggplot(aes(year_created,revenue))+
    geom_area(aes(group=original_media, fill=original_media))+
    facet_grid(original_media~.)+
    theme(strip.background = element_blank(), strip.text.y = element_blank())+#legend.position = 'none')+
    labs(title = ""The rise of visual media at the expense of imagination (book reading)"",
         subtitle = ""Animation/Visual stimuli have overtaken the need to visualise content from books"",
         x="""")

","2019-27"
"481",1120,"https://github.com/Nicey80/tidytuesday/blob/master/2019-06-25/2019-06-25.R","Nicey80","tidytuesday","2019-06-25/2019-06-25.R","library(tidyverse)
library(lubridate)
library(gganimate)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

ufo_sightings2 <- ufo_sightings %>% 
    mutate(date=as_date(date_time, format='%m/%d/%Y %H:%M', tz='utc')) %>% 
    mutate(YR=year(date))

library(maps)

world_map <- map_data(""world"")

p <- ggplot() + 
    geom_polygon(data=world_map,aes(x=long, y=lat,group=group), col=""gray50"") +
    theme_dark()+
    theme(axis.title = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.line = element_blank(),
          panel.grid = element_blank(),
          panel.background = element_rect(fill=""gray10""))+
    geom_point(data = ufo_sightings2, aes(longitude,latitude, group=YR), colour=""green"", size=0.1)+
    labs(title = 'UFO Sightings by Year: {frame_time}') +
    transition_time(YR) +
    ease_aes('linear')+
    shadow_mark(alpha=alpha/2)
p

p2 <- animate(p, end_pause = 10, duration=15, nframes=109)
p2

anim_save('UFO.gif')
","2019-22"
"482",1121,"https://github.com/cginer/tidytuesday/blob/master/20190618_birds.Rmd","cginer","tidytuesday","20190618_birds.Rmd","---
title: ""Tidy Tuesday 2019 week 25""
author: ""Carla Giner-Delgado""
date: ""18 June 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

This week's `#TidyTuesday` data is about BIRDS! And not only birds, but birds from North America. I happen to love birds and I've been living in the US East Coast for few months now. During this time I've learned about new species that have become my new bird friends in this part of the world. (With the help of patient birder friends from Brown University Birding Club, [Audubon Society of Rhode Island](https://twitter.com/RIAudubon) and Brooklyn Bird Club.) I have also found some old bird friends from Europe too, such as pigeons, house sparrows and starlings.

The data was cleaned by [Sharleen](https://twitter.com/_sharleen_w) from [Bird Studies Canada](https://twitter.com/BirdsCanada). It records the number of birds counted in a popular Christmas bird watching event held in Hamilton area of Ontario since 1921.

For my `#TidyTuesday` contribution I've added some personal annotations to the dataset. I have classified the birds in ""Old friends"" (birds I knewn from Europe), ""New friends"" (bird species that I now can identify fairly easily and know their common names) and ""Others"" (birds that I haven't seen or that I still can't identify easily or haven't learned their names).

```{r packages}
# To read the data set
library(readr)

# Data manipulation
library(dplyr)

# Visualization
library(ggplot2)
library(ggbeeswarm) # geom_quasirandom
```

## Get the data

```{r getdata}
bird_counts <- read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"",
    col_types = cols(col_integer(), col_character(), col_character(),
                     col_double(), col_double(), col_double())
    )
```

```{r explore, eval=FALSE}
# Quick look at the dataset and summaries by year
head(bird_counts)

bird_counts %>%
    group_by(year) %>%
    summarize(n = n(),
              num_species_listed = length(unique(species)),
              num_species_counted = length(unique(species[how_many_counted > 0])),
              total_counted = sum(how_many_counted),
              mean_counted_total = mean(how_many_counted),
              mean_counted = mean(how_many_counted[how_many_counted > 0]))

```

# Add my personal annotations

```{r annotations}
old_friends <- c(""Herring Gull"", ""European Starling"", ""House Sparrow"", ""Mallard"", ""Barn Swallow"", ""Rock Pigeon"")
new_friends <- c(""American Robin"", ""Blue Jay"", ""Downy Woodpecker"", ""Black-capped Chickadee"", ""Canada Goose"", ""Eastern Towhee"", ""House Finch"", ""Wood Duck"", ""Red-tailed Hawk"", ""Red-winged Blackbird"", ""Wild Turkey"", ""Spotted Sandpiper"", ""Northern Cardinal"", ""Double-crested Cormorant"", ""Northern Mockingbird"", ""American Goldfinch"", ""Mourning Dove"", ""American Crow"", ""Ring-billed Gull"")

bird_counts <- bird_counts %>%
    mutate(Class = factor(
        case_when(species %in% new_friends ~ ""New friends"",
                  species %in% old_friends ~ ""Old friends"",
                  TRUE ~ ""Others""),
        levels = c(""Others"", ""New friends"", ""Old friends"")))

```


```{r plot_annotations, fig.height=3}
ggplot(bird_counts %>% filter(year %in% ""1921""), aes("""", fill = Class)) +
    geom_bar() +
    coord_flip() +
    scale_fill_viridis_d(begin = 0.1, end = 0.8, direction =  -1) +
    labs(x = NULL, y = ""Number of species"", title = ""Personal classification of birds in the data"",
         subtitle = ""There are still many birds to learn about!"") +
    scale_x_discrete(expand = c(0, 0), breaks = NULL) +
    scale_y_continuous(expand = c(0, 0 ))
```

I still don't know most of the birds spotted in Hamilton at Christmas!

## Summarize data per bird

Are birds I know common? (must be)

```{r summary_birds}
summary_birds <- bird_counts %>%
    group_by(species, species_latin, Class) %>%
    summarize(
        mean_counted_by_hour = mean(how_many_counted_by_hour, na.rm = TRUE),
        variance_counted_by_hour = var(how_many_counted_by_hour, na.rm = TRUE),
        years_spotted = sum(how_many_counted > 0)) %>%
    mutate(
        Regularity = case_when(years_spotted < 5 ~ ""Rare"",
                               years_spotted < 94/2 ~ ""Less than half of the years"",
                               years_spotted < 95-5 ~ ""More than half of the years"",
                               years_spotted > 94-5 ~ ""Very common"")
    )

```

```{r mean_count}
ggplot(summary_birds %>% filter(mean_counted_by_hour > 0), aes(Class, mean_counted_by_hour)) +
    geom_quasirandom(aes(colour = Class), show.legend = FALSE, na.rm = TRUE) +
    geom_text(data = summary_birds %>% filter(species %in% c(""Wood Duck"", ""Spotted Sandpiper"", ""Barn Swallow"")),
              aes(label = species), size = 2.5, nudge_x = 0.28) +
    geom_text(data = summary_birds %>% filter(species %in% c(""Eastern Towhee"")),
              aes(label = species), size = 2.5, nudge_x = -0.33) +
    scale_y_log10(breaks = c(0.0001, 0.01, 1, 100),
                  labels = c(""0.0001"", ""0.01"", ""1"", ""100"")) +
    annotation_logticks(sides = ""l"") +
    scale_colour_viridis_d(begin = 0.1, end = 0.8, direction =  -1) +
    labs(x = NULL, y = ""Mean bird count per hour"", title = ""Bird abundance"",
         subtitle = ""Most birds I know are fairly common"") +
    theme_minimal()
```


## Look at abundance temporal trends (of friends)

```{r}
# Impute number of hours in years that have NAs (several years between 1921 and 1950)
# I'm going to use Downy Woodpecker as reference, because it's spotter every year at a similar rate
downys_per_hour_1929_1950 <- bird_counts %>%
    filter(species %in% ""Downy Woodpecker"" & year <= 1950) %>%
    pull(how_many_counted_by_hour) %>%
    mean(na.rm = TRUE)

bird_counts_imputed <- bird_counts %>%
    group_by(year) %>%
    # Use Downy woodpecker to estimate total_hours
    mutate(total_hours = if_else(
        is.na(total_hours),
        round(how_many_counted[species %in% ""Downy Woodpecker""] / downys_per_hour_1929_1950),
        total_hours)) %>%
    # Fill counts/h those years
    mutate(how_many_counted_by_hour = if_else(
        is.na(how_many_counted_by_hour),
        how_many_counted/total_hours,
        how_many_counted_by_hour))

# Order by mean abundance
bird_order <- summary_birds %>%
    arrange(mean_counted_by_hour) %>%
    pull(species)
bird_counts_imputed <- bird_counts_imputed %>%
    mutate(species = factor(species, levels = bird_order))
```


```{r}
ggplot(bird_counts_imputed %>%
           filter(Class %in% c(""New friends"", ""Old friends"") & how_many_counted_by_hour),
       aes(year, species, size = how_many_counted_by_hour, colour = Class)) +
    geom_point(show.legend = c(colour = FALSE)) +
    scale_size_area(max_size = 7, breaks = c(1, 10, 100, 400), name = ""Birds per hour"") +
    scale_colour_viridis_d(begin = 0.1, end = 0.8, direction =  -1, drop = FALSE) +
    scale_x_continuous(expand = c(0.04, 0)) +
    facet_grid(rows = vars(Class), scales = ""free"", space =""free"") +
    theme_minimal() +
    labs(title = ""Temporal trends"",
         subtitle = ""Downy Woodpecker sigthings are used to impute\nthe total counting hours for some years before 1950"")
```

","2019-25"
"483",1142,"https://github.com/LaineyJ/TidyTuesdays/tree/master/2019-06-11","LaineyJ","TidyTuesdays","2019-06-11/Meteorite Data Cleaning.Rmd","---
title: ""Meteorite Impacts""
output: html_notebook
---

```{r setup, include = FALSE}
library(""tidyverse"")
library(""mgcv"")
library(""maps"")
library(""extrafont"")
library(""ggrepel"")
library(""dummies"")
library(""corrplot"")
library(""grid"")
library(""gridExtra"")

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  filter(!is.na(lat))
```

## Filter to US and Iowa meteorites
```{r}
filter_meteorites <- function(boundaries) {
  met_filter <- in.out(as.matrix(boundaries[, c(""lat"",""long"")]),
                      as.matrix(meteorites[, c(""lat"", ""long"")]))
  met_filtered <- meteorites[met_filter, ]
}

us <- map_data(""state"")
iowa <- map_data(""state"", ""iowa"")

meteorites_us <- filter_meteorites(us)
meteorites_ia <- filter_meteorites(iowa)
```
***

## Plot Iowa meteorites
```{r}
plt_iowa <- meteorites_ia %>%
  ggplot(aes(x = long,
             y = lat,
             size = mass,
             color = fall)) + 
  geom_point(na.rm = TRUE) +
  borders(""state"", ""iowa"")

plt_iowa <- plt_iowa +
  scale_color_brewer(name = ""Falls vs. Finds"", palette = ""Dark2"") +
  scale_size_continuous(name = ""Mass (g)"",
                        labels = scales::comma) +
  geom_text_repel(aes(label = paste(name, year, sep = "", "")),
                  size = 3.5,
                  color = ""black"",
                  point.padding = 0.5,
                  min.segment.length = 5,
                  family = ""Segoe UI"") +
  labs(title = ""Meteorite Impacts in Iowa by Mass and Fall Type"",
       subtitle = ""Meteorite \""falls\"" were identified shortly after their fall;
Meteorite \""finds\"" were identified at a later date
"") +
  theme(text = element_text(family = ""Segoe UI""),
        plot.background = element_rect(fill = ""whitesmoke""),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(family = ""Franklin Gothic Medium""),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        legend.background = element_rect(fill = ""whitesmoke""))
plt_iowa
```
***

## Find proportion of falls vs. finds
```{r}
met_dummies <- function(df) {
  fall_dummies <- dummy(df$fall)
  df$fall_bin <- fall_dummies[, 1]
  df
}

meteorites_us <- suppressWarnings(met_dummies(meteorites_us))
meteorites_ia <- suppressWarnings(met_dummies(meteorites_ia))

us_mean <- mean(meteorites_us$fall_bin)
ia_mean <- mean(meteorites_ia$fall_bin)
```
Overall proportion of falls in the US is `r us_mean`, vs. `r ia_mean` in Iowa  

***

## Correlation of falls vs. mass
```{r}
cor_df <- meteorites_us[, c(5, 7, 11)]
cor_df <- rename(cor_df,
                 Year = year,
                 Mass = mass,
                 Fell = fall_bin)

cor_mat <- cor(cor_df, use = ""complete.obs"")
return_corrplot <- function() {
  correls <- corrplot(cor_mat,
                      method = ""color"",
                      type = ""upper"",
                      bg = ""whitesmoke"",
                      diag = FALSE,
                      outline = TRUE,
                      addCoef.col = ""black"",
                      tl.col = ""black"",
                      cl.pos = ""n"")
}
```
***

## Returning Graphs
```{r}
plt_iowa

return_corrplot()
```

","2019-24"
"484",1143,"https://github.com/LaineyJ/TidyTuesdays/tree/master/2019-06-11","LaineyJ","TidyTuesdays","2019-06-11/Meteorite Falls Script.R","library(""tidyverse"")
library(""mgcv"")
library(""maps"")
library(""extrafont"")
library(""ggrepel"")
library(""dummies"")
library(""corrplot"")
library(""grid"")
library(""gridExtra"")


# Read and Format Data ----------------------------------------------------

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  filter(!is.na(lat))

filter_meteorites <- function(boundaries) {
  met_filter <- in.out(as.matrix(boundaries[, c(""lat"",""long"")]),
                      as.matrix(meteorites[, c(""lat"", ""long"")]))
  met_filtered <- meteorites[met_filter, ]
}

us <- map_data(""state"")
iowa <- map_data(""state"", ""iowa"")

meteorites_us <- filter_meteorites(us)
meteorites_ia <- filter_meteorites(iowa)

plt_iowa <- meteorites_ia %>%
  ggplot(aes(x = long,
             y = lat,
             size = mass,
             color = fall)) + 
  geom_point(na.rm = TRUE) +
  borders(""state"", ""iowa"")


# Plot Iowa ---------------------------------------------------------------

plt_iowa <- plt_iowa +
  scale_color_brewer(name = ""Falls vs. Finds"", palette = ""Dark2"") +
  scale_size_continuous(name = ""Mass (g)"",
                        labels = scales::comma) +
  geom_text_repel(aes(label = paste(name, year, sep = "", "")),
                  size = 3.5,
                  color = ""black"",
                  point.padding = 0.5,
                  min.segment.length = 5,
                  family = ""Segoe UI"") +
  labs(title = ""Meteorite Impacts in Iowa by Mass and Fall Type"",
       subtitle = ""Meteorite \""falls\"" were identified shortly after their fall;
Meteorite \""finds\"" were identified at a later date
"") +
  theme(text = element_text(family = ""Segoe UI""),
        plot.background = element_rect(fill = ""whitesmoke""),
        panel.background = element_blank(),
        panel.grid = element_blank(),
        plot.title = element_text(family = ""Franklin Gothic Medium""),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        legend.background = element_rect(fill = ""whitesmoke""))

met_dummies <- function(df) {
  fall_dummies <- dummy(df$fall)
  df$fall_bin <- fall_dummies[, 1]
  df
}


# Correlations ------------------------------------------------------------

meteorites_us <- suppressWarnings(met_dummies(meteorites_us))
meteorites_ia <- suppressWarnings(met_dummies(meteorites_ia))

us_mean <- mean(meteorites_us$fall_bin)
ia_mean <- mean(meteorites_ia$fall_bin)

cor_df <- meteorites_us[, c(5, 7, 11)]
cor_df <- rename(cor_df,
                 Year = year,
                 Mass = mass,
                 Fell = fall_bin)

cor_mat <- cor(cor_df, use = ""complete.obs"")
return_corrplot <- function() {
  correls <- corrplot(cor_mat,
                      method = ""color"",
                      type = ""upper"",
                      bg = ""whitesmoke"",
                      diag = FALSE,
                      outline = TRUE,
                      addCoef.col = ""black"",
                      tl.col = ""black"",
                      cl.pos = ""n"")
}

plot(plt_iowa)

return_corrplot()

ggsave(""IowaMeteorites.jpeg"", plt_iowa, width = 11.5, height = 8, units = ""in"", dpi = 320)
","2019-24"
"485",1144,"https://github.com/s01ren/TidyTuesdaySubmissions/tree/master/20190625","s01ren","TidyTuesdaySubmissions","20190625/TT_20190625.R","# ------------------------------------------------------------------------
#
# TIDY TUESDAY 2019-06-25
#
# ------------------------------------------------------------------------


# load packages -----------------------------------------------------------
library(sp)
library(tidyverse)
library(viridis)


# mapping table -----------------------------------------------------------
mapping_city_district <- tribble(
  ~city, ~district,
  'aachen', 'Stdteregion Aachen',
  'ansbach', 'Ansbach (Kreisfreie Stadt)',
  'babenhausen', 'Darmstadt',
  'bad pyrmont', 'Hameln-Pyrmont',
  'bamberg', 'Bamberg (Kreisfreie Stadt)',
  'baumholder', 'Birkenfeld',
  'bensheim', 'Darmstadt',
  'berlin', 'Berlin',
  'bierenbachtal', 'Oberbergischer Kreis',
  'biesenthal', 'Barnim',
  'bitburg', 'Eifelkreis Bitburg-Prm',
  'bocholt', 'Borken',
  'bochum', 'Bochum',
  'bremen', 'Bremen',
  'buchholz', 'Heidekreis',
  'chemnitz', 'Chemnitz',
  'cologne', 'Kln',
  'darmstadt', 'Darmstadt',
  'dresden', 'Dresden',
  'elbingen', 'Westerwaldkreis',
  'emlichheim', 'Grafschaft Bentheim',
  'emmelshausen', 'Rhein-Hunsrck-Kreis',
  'erfurt', 'Erfurt',
  'erlangen', 'Erlangen',
  'frankfurt', 'Frankfurt (Oder)',
  'frankfurt am main', 'Frankfurt am Main',
  'freiburg', 'Freiburg im Breisgau',
  'fulda', 'Fulda',
  'gelsenkirchen', 'Gelsenkirchen',
  'grafenhausen', 'Waldshut',
  'hamburg', 'Hamburg',
  'hanau', 'Main-Kinzig-Kreis',
  'hannover', 'Region Hannover',
  'haus', 'Freyung-Grafenau',
  'heidelberg', 'Heidelberg',
  'heilbronn', 'Heilbronn',
  'kaiserlautern', 'Kaiserslautern (Kreisfreie Stadt)',
  'kassel', 'Kassel',
  'kelsterbach', 'Gro-Gerau',
  'kirchzell', 'Miltenberg',
  'lampertheim', 'Bergstrae',
  'langenleiten', 'Rhn-Grabfeld',
  'magdeburg', 'Magdeburg',
  'mainz', 'Mainz',
  'mannheim', 'Mannheim',
  'maugenhard', 'Lrrach',
  'miesau', 'Kaiserslautern',
  'mittenwald', 'Garmisch-Partenkirchen',
  'muenster', 'Mnster',
  'munich', 'Mnchen (Kreisfreie Stadt)',
  'neckarsulm', 'Heilbronn',
  'neumarkt', 'Neumarkt in der Oberpfalz',
  'neuseddin', 'Potsdam-Mittelmark',
  'neuruppin', 'Ostprignitz-Ruppin',
  'neuss', 'Bergstrae',
  'nurenburg', 'Nrnberg',
  'obernheim', 'Zollernalbkreis',
  'osnabruck', 'Osnabrck (Kreisfreie Stadt)',
  'ottersberg', 'Verden',
  'ramstein', 'Kaiserslautern',
  'ransbach-baumbach', 'Westerwaldkreis',
  'regensburg', 'Regensburg',
  'schafhausen', 'Alzey-Worms',
  'schwalmtal', 'Vogelsbergkreis',
  'schweinfurt', 'Schweinfurt',
  'schwetzingen', 'Rhein-Neckar-Kreis',
  'sembach', 'Kaiserslautern',
  'senftenberg', 'Oberspreewald-Lausitz',
  'siegen', 'Siegen-Wittgenstein',
  'staufen', 'Breisgau-Hochschwarzwald',
  'stuttgart', 'Stuttgart',
  'trier', 'Trier',
  'waldorf', 'Ahrweiler',
  'weiden', 'Weiden in der Oberpfalz',
  'weissenburg', 'Weienburg-Gunzenhausen',
  'werder', 'Potsdam-Mittelmark',
  'wildflecken', 'Bad Kissingen',
  'zehdenick', 'Oberhavel',
  'zirndorf', 'Frth (Kreisfreie Stadt)'
)

# import map of German Laender --------------------------------------------
shape_de_level_1 <- readRDS(url(""https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_DEU_1_sp.rds"", encoding = ""utf-8""))
tmp1 <- data.frame(id = rownames(shape_de_level_1@data), shape_de_level_1@data)
tmp1$id <- as.character(tmp1$id)
tmp2 <- fortify(shape_de_level_1)
LAENDER <- 
  tmp1 %>% 
  left_join(tmp2, by = ""id"")
rm(tmp1, tmp2)


# import map of German districts ------------------------------------------
shape_de_level_2 <- readRDS(url(""https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_DEU_2_sp.rds"", encoding = ""utf-8""))
tmp1 <- data.frame(id = rownames(shape_de_level_2@data), shape_de_level_2@data)
tmp1$id <- as.character(tmp1$id)
tmp2 <- fortify(shape_de_level_2)
DISTRICTS <- 
  tmp1 %>% 
  left_join(tmp2, by = ""id"") %>% 
  mutate(
    NAME_2 = str_replace(NAME_2, ""M?nchen"", ""Mnchen"") %>% 
      str_replace(""F?rth"", ""Frth"") %>% 
      str_replace(""Osnabr?ck"", ""Osnabrck"")
  )
rm(tmp1, tmp2)


# import UFO sightings ----------------------------------------------------
ufo_raw <- readr::read_csv(
  file = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv""
)

UFO_DISTR <- ufo_raw %>% 
  filter(country == ""de"") %>% 
  #filter(encounter_length <= 86400/2) %>% 
  mutate(encounter_length = case_when(encounter_length > 10000 ~ 10000, TRUE ~ encounter_length)) %>% 
  rowwise() %>% 
  mutate(city = trimws(str_split(city_area, ""\\("", n = 2)[[1]][1])) %>% 
  left_join(mapping_city_district, by = ""city"") %>% 
  select(district, encounter_length) %>% 
  ungroup() %>% 
  group_by(district) %>% 
  summarise(encounter_length = sum(encounter_length, na.rm = TRUE))
UFO_DISTR


# join plot data ----------------------------------------------------------
PLOT_DISTR_UFO <- DISTRICTS %>% 
  left_join(UFO_DISTR, by = c(""NAME_2"" = ""district"")) %>% 
  mutate(encounter_length = replace_na(encounter_length, 0))

# plot map ----------------------------------------------------------------
ggplot(data = PLOT_DISTR_UFO, aes(x = long, y = lat, group = group)) + 
  geom_polygon(aes(fill = encounter_length), col = ""white"") + 
  geom_polygon(data = LAENDER, aes(x = long, y = lat, group = group), col = ""black"", fill = NA) + 
  # STYLING -----------------------------------------------------------------
  theme_classic() + 
  theme(
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.ticks = element_blank(),
    axis.line = element_blank(),
    plot.title=element_text(size=14, face=""bold""),
    legend.position = ""bottom"",
    aspect.ratio = mapasp(shape_de_level_1)
  ) + 
  labs(
    title = ""UFO sightings in Germany by encounter length"",
    caption = ""TidyTuesday 2019-06-25""
  ) + 
  #scale_fill_gradient(low = ""#bdc3c7"", high = ""#3CD070"", name = ""Encounter length"")
  scale_fill_viridis(
    option = ""magma"", 
    direction = -1,
    name = ""Encounter length in seconds"",
    # here we use guide_colourbar because it is still a continuous scale
    guide = guide_colorbar(
      direction = ""horizontal"",
      barheight = unit(2, units = ""mm""),
      barwidth = unit(50, units = ""mm""),
      draw.ulim = F,
      title.position = 'top',
      # some shifting around
      title.hjust = 0.5,
      label.hjust = 0.5
    ))
ggsave(""./ufo_germany.png"")








","2019-26"
"486",1189,"https://github.com/carleshf/tidytuesday","carleshf","tidytuesday","2019-04-23/2019-04-23.Rmd","---
title: ""TidyTuesday / Anime Data (2019-04-23)""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(ggthemr)
library(cowplot)
```

# Download data

```{r, message=FALSE, warning=FALSE}
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")
```

# Create new variables and filter data-set

```{r}
tidy_anime <- tidy_anime %>% 
  mutate(start_date_lub = ymd(start_date)) %>% 
  mutate(year = floor_date(start_date_lub, unit = ""year"")) %>% 
  mutate(decade = year(floor_date(start_date_lub, unit = years(10)))) %>% 
  mutate(decade_fac = as.factor(decade)) %>% 
  filter(!is.na(decade), !is.na(score))
```

# Create plots

```{r, fig.width=10}
ggthemr(""flat dark"")
p1 <- ggplot(tidy_anime, aes(x = genre, y = decade_fac, fill = score)) +
  geom_tile() +
  scale_fill_distiller(palette = ""Spectral"", limits = c(0, 10), name = ""Score"") +
  theme(
    legend.position = ""none"",
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)
  ) +
  xlab(""Genre"") + ylab(""Decade"") +
  ggtitle(""Score by genre and decade"")
p2 <- ggplot(tidy_anime, aes(x = source, y = decade_fac, fill = score)) +
  geom_tile() +
  scale_fill_distiller(palette = ""Spectral"", limits = c(0, 10)) +
  theme(
    legend.position = ""none"",
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  xlab(""Source"") + ylab("""") +
  ggtitle(""Score by source and decade"")

pg <- plot_grid(
  plot_grid(p1, p2, ncol = 2, rel_widths = c(0.66, 0.33)),
  plot_grid(get_legend(p1 + theme(legend.position = ""bottom"")), 
            ggdraw() + draw_label(""Source: MyAnimeList""),
            ncol = 2),
  ncol = 1, rel_heights = c(0.9, 0.1)
)
pg

ggsave(pg, file = ""anime_score_by_genre_source_decade.png"")
```","2019-17"
"487",1190,"https://github.com/carleshf/tidytuesday","carleshf","tidytuesday","2019-06-11/2019-06-11.Rmd","---
title: ""TidyTuesday / Meteorite Impacts (2019-06-11)""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(imager)
library(ggthemes)
```

# Download data

```{r, message=FALSE, warning=FALSE}
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")
```

```{r}
meteorites <- meteorites %>% mutate(log_mass = log(mass + 1))
```

# Prepare data and simple plot

```{r, fig.width=10}
world <- ggplot() +
  borders(""world"", colour = ""#353535"", fill = ""#353535"") +
  theme_map()

meteorites2 <- meteorites %>% filter(year >= 2010)

plot_meteor <- world + 
  geom_point(data = meteorites2, aes(x = long, y = lat, size = log_mass), color = ""#ffa500"", alpha = 0.7) +
  theme(legend.position = ""none"")

ggsave(plot_meteor, file = ""plot_meteor.jpg"")

plot_meteor
```

# Create ASCII plot

```{r, fig.width=10}
im <- load.image(""plot_meteor.jpg"") 

# Select characters to use
asc <- gtools::chr(38:126)

# Convert to grayscale
g.chr <- function(chr) implot(imfill(50, 50, val = 1),text(25, 25, chr, cex = 5)) %>% grayscale %>% mean

# Map characters to grayscale
g <- map_dbl(asc, g.chr)

char <- asc[order(g)]
#Convert image to grayscale, resize, convert to data.frame
d <- grayscale(im) %>% imresize(.1)  %>% as.data.frame
d <- d %>% mutate(qv = cut_width(value, 0.01) %>% as.integer) # Better is cut_number, but for real pictures only
d <- mutate(d,char=char[qv])

ascii_plot <- ggplot(d,aes(x,y)) + 
  geom_text(aes(label=char),size=1) + 
  scale_y_reverse() +
  theme_clean() +
  theme(
    panel.border = element_blank(),
    panel.grid = element_blank(),
    axis.title = element_blank(),
    axis.text = element_blank(),
    axis.line = element_blank(),
    axis.ticks = element_blank()
  )
ggsave(ascii_plot, file = ""ascii_meteor.png"")

ascii_plot
```
","2019-24"
"488",1191,"https://github.com/carleshf/tidytuesday","carleshf","tidytuesday","2019-06-18/2019-06-18.Rmd","---
title: ""TidyTuesday / Christmas Bird Counts (2019-06-18)""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(stringsAsFactors = FALSE)
```

# Load libraries

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(cowplot)
library(ggthemes)
```

# Download data

```{r, message=FALSE, warning=FALSE}
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")
```

```{r}
dim(bird_counts)
bird_counts <- bird_counts %>% filter(how_many_counted > 0)
dim(bird_counts)
```

# Plot occurrences of birds (top and bottom)

```{r}
bird_species <- data.frame(table(bird_counts$species))
bird_species <- bird_species[order(bird_species$Freq, decreasing = TRUE), ]
head(bird_species, n = 25)
```

```{r, fig.width=12}
plot_species <- plot_grid(
  head(bird_species, n = 15) %>% 
    ggplot(aes(x= factor(Var1, levels = rev(Var1)), y = Freq)) + 
    geom_bar(stat = ""identity"") +
    theme_wsj() +
    coord_flip() +
    ggtitle(""Top 15 species\nobserved across years"") +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.caption = element_text(size = 10)
    ) +
    labs(caption = "" ""),
  bird_species %>% 
    filter(Freq > 1) %>% 
    tail(n = 15) %>% 
    ggplot(aes(x= factor(Var1, levels = rev(Var1)), y = Freq)) + 
    geom_bar(stat = ""identity"") +
    theme_wsj() +
    coord_flip() +
    ggtitle(""Bottom 15 species\nobserved across years"") +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.caption = element_text(size = 10)
    ) + 
    labs(caption = ""Source: Bird Studies Canada""),
  ncol = 2
)

ggsave(plot_species, file = ""plot_species_count.png"", width = 12)

plot_species
```



# Plot count per year and count per hour for top 3

```{r, fig.width=12}
plot_many_year <- function(dt, name, min, max) {
  dt %>% 
    filter(species == name) %>% 
    ggplot(aes(x = year, y = how_many_counted)) +
    geom_line() +
    ggtitle(name) +
    theme_wsj() + 
    ylim(min, max) +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      axis.title = element_text(family = ""mono"", size = 10)
    ) +
    xlab(""Year"") + ylab(""How many counted"")
}

plot_many_hour <- function(dt, name, min, max) {
  dt %>% 
    filter(species == name) %>%
    ggplot(aes(x = total_hours, y = how_many_counted_by_hour)) + 
    geom_point() +
    ggtitle(name) +
    theme_wsj() +
    ylim(min, max) +
    theme(
      plot.title = element_text(size = 14, hjust = 0.5),
      axis.title = element_text(family = ""mono"", size = 10),
      plot.caption = element_text(size = 10)
    ) +
    xlab(""Total hours"") + ylab(""How many counted by hour"")
}

plot_bird <- plot_grid(
  plot_many_year(bird_counts, ""American Tree Sparrow"", 0, 2700),
  plot_many_year(bird_counts, ""Blue Jay"", 0, 2700),
  plot_many_year(bird_counts, ""Downy Woodpecker"", 0, 2700),
  plot_many_hour(bird_counts, ""American Tree Sparrow"", 0, 15) +
    labs(caption = "" ""),
  plot_many_hour(bird_counts, ""Blue Jay"", 0, 4) + 
    labs(caption = "" ""),
  plot_many_hour(bird_counts, ""Downy Woodpecker"", 0, 2) + 
    labs(caption = ""Source: Bird Studies Canada""),
  ncol = 3
)

ggsave(plot_bird, file = ""plot_bird_count.png"", width = 12)

plot_bird
```

","2019-25"
"489",1198,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_2019_06_18_Code.R","#Tidy Tuesday Date 2019-06-18
#By Richard Johansen
#Twitter: @Johansen_PhD
#GitHub: RAJohansen

#load tidyverse!
library(tidyverse)

# Load Data
df <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_2019_06_18/bird_counts.csv"")

# Explore year and species grouping
df %>% group_by(year, species) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted))

# Still too many individual observations
# Group by just year or just species

df %>% group_by(year) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted))

df %>% group_by(species) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted))

# Create time series of counts
lims <- as.Date(strptime(c(""1921-06-17"",""2018-06-19""), format = ""%Y-%m-%d""))    

df$year <- as.character(df$year)
df$year <- as.Date(df$year, ""%Y"")
df %>% group_by(year) %>% 
  summarise(count_mean = mean(how_many_counted),
            count_sum = sum(how_many_counted)) %>% 
ggplot(aes(year,count_mean))+
  geom_point(size = 2)+
  geom_smooth(se =FALSE) +
  labs(title = ""Christmas Bird Counts for \nHamilton, Ontario, Canada"",y = ""Bird Counts\n(mean)"", x = ""\n Year"") +
  scale_x_date(date_labels =""%Y"" , date_breaks = ""6 year"", limits =lims) +
  scale_y_continuous(name=""Cumulative\nTotal"", breaks = seq(0,600, by = 100)) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, size = 16),
        axis.text.x=element_text(angle=0,vjust = 0.5,size = 12),
        axis.text.y=element_text(size = 12),
        axis.title.y=element_text(angle = 0,size = 12, vjust = 0.5,face=""bold""),
        axis.title.x=element_text(face=""bold""))


jpeg(""jpegs/Xmas_Bird_Counts_2019_06_18.jpeg"", width = 12, height = 8, units = 'in', res = 600)
dev.off()

","2019-25"
"490",1321,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-05-07","allisonhorst","allison-tidy-tuesdays","2019-05-07/tidy_tuesday_5_7_19.R","# Tidy Tuesday 5/7/2019
# Student:teacher class size ratios (global)

# Attach packages
library(tidyverse)
library(janitor)
library(sf)

# Get data:

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

# Averaged across all indicators (levels) and years...

students_all <- student_ratio %>%
  group_by(country_code) %>%
  summarize(
      mean_ratio = mean(student_ratio, na.rm = TRUE)
    ) %>%
  ungroup() %>%
  rename(iso3 = country_code)

# Get global map data, join to student_2016 data:

globe <- st_read(dsn = ""2019-05-07"", layer = ""TM_WORLD_BORDERS_SIMPL-0.3"") %>%
  st_transform(4326) %>%
  clean_names() %>%
  full_join(students_all)

# Plot a single map...

ggplot() +
  geom_sf(data = globe,
          aes(fill = mean_ratio),
          color = ""white"",
          size = 0.1
          ) +
  coord_sf(datum = NA) +
  scale_fill_gradientn(colors = c(""royalblue1"",""magenta"",""orange"",""gold""),
                       name = ""Average student-teacher ratio"") +
  labs(title = ""#tidytuesday: student-teacher ratios\n(average across all years & levels in dataset)"") +
  theme_void() +
  theme(legend.position = c(0.2, 0.35), legend.direction = ""vertical"",
        plot.background = element_rect(fill = ""gray10"", color = NA),
        panel.background = element_rect(fill = ""gray10"", color = NA),
        legend.background = element_rect(fill = NA, color = NA),
        legend.key = element_rect(fill = ""gray10"", colour = NA),
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8),
        text =  element_text(color = ""white""),
        title =  element_text(color = ""white""),
        plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(size = 32)
  )

# plot.margin = margin(1, 1, 1, 1, ""cm"")

ggsave(""images/student_ratios_map.png"", width = 8, height = 5)

# Some extra code to test...
","2019-19"
"491",1322,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-04-23","allisonhorst","allison-tidy-tuesdays","2019-04-23/tidy_tuesday_4_23_19.R","# Tidy Tuesday 4/23/19
# Allison Horst
# Anime!

# Goals this week: fun!

#######
# Load packages
#######

library(tidyverse)
library(ggdark)
library(extrafont)

#######
# Get data
#######

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

########
# Go exploring
########

# Simplify with all shows:

all_shows <- tidy_anime %>%
  select(-synopsis, - background) %>%
  distinct(name, .keep_all = TRUE)

# Find and keep shows from the top 10 most common genres (by # of shows in genre):
top_genres <- tidy_anime %>%
  select(-synopsis, -background) %>%
  filter(genre != ""NA"") %>%
  group_by(genre) %>%
  tally() %>%
  arrange(-n) %>%
  head(6) %>%
  inner_join(tidy_anime)

# No real difference in scores for top genres:
ggplot(top_genres, aes(x = score)) +
  geom_density(aes(fill = genre)) +
  facet_wrap(~genre)

# Change in scores over time?
ggplot(top_genres, aes(x = start_date, y = score)) +
  geom_point() +
  geom_line(aes(color = genre))

# Cumulative sum over time?
time_df <- top_genres %>%
  mutate(show = 1) %>%
  arrange(genre, start_date) %>%
  select(genre, name, start_date, show) %>%
  group_by(genre) %>%
  mutate(totes = cumsum(show))

ggplot(time_df, aes(x = start_date, y = totes)) +
  geom_line(aes(color = genre))

# OK, actually that wasn't that exciting. I'll try something else.

ggplot(top_genres, aes(x = score, y = popularity)) +
  geom_point(aes(color = genre), alpha = 0.5) +
  facet_wrap(~genre) + # This is kind of weird
  theme_dark() +
  scale_color_manual(values = c(""red"",""orange"",""yellow"",""purple"",""black"",""white""))

# FINAL GRAPH STUFF: Relationship btwn popularity and score for all shows...

# Make function for nice scientific notation (help from: https://stackoverflow.com/questions/10762287/how-can-i-format-axis-labels-with-exponents-with-ggplot2-and-scales/45867076)

scientific_10 <- function(x) {
  parse(text=gsub(""e"", ""%*% 10^"", scales::scientific_format()(x)))
}

# Add: 'label = scientific_10' argument in scale_y_continuous for scientific notation

# Then a graph of score vs. popularity:

ggplot(all_shows, aes(x = score, y = popularity)) +
  geom_hex(bins = 50,
           binwidth = c(0.2, 430)) +
  scale_fill_gradientn(colors = c(""slateblue4"",
                                  ""brown1"",
                                  ""orange"",
                                  ""yellow"",
                                  ""white""),
                       name = ""Number of shows:"") +
  guides(fill = guide_colourbar(ticks = TRUE,
                                barwidth = 20,
                                barheight = 0.5,
                                direction = ""horizontal"",
                                title.position = ""top"")) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,0),
                     limits = c(0,10),
                     breaks = seq(0,10, by = 2)) +
  scale_y_reverse() +
  labs(x = ""Score (higher = better)"",
       y = ""Popularity\n(lower = higher popularity)"",
       title = ""Anime (update)"") +
  ggdark::dark_theme_bw() +
  theme(text = element_text(family = ""Carrois Gothic SC""),
       # panel.spacing.x = unit(1.0, ""lines""),
       # panel.spacing.y = unit(1.0, ""lines""),
        legend.position = ""bottom"",
       plot.margin=unit(c(1,1,1,1),""cm"")
  )

ggsave(""anime.png"", width = 8, height = 7)
","2019-17"
"492",1323,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-04-09","allisonhorst","allison-tidy-tuesdays","2019-04-09/tidy_tuesday_4_9_19.R","# Tidy Tuesday 4/9/2019
# Allison Horst
# Tennis Grand Slam Champions

library(tidyverse)
library(RColorBrewer)
library(wesanderson)
library(ggpomological)
library(extrafont)
library(LaCroixColoR)
library(ggdark)

# font_import()

# Get data:
# player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

# grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

# This seems like excessive grouping and ungrouping, mer?

past_qual <- c(""Won"",""Finalist"",""Semi-finalist"",""Quarterfinalist"", ""4th Round"", ""3rd Round"", ""2nd Round"", ""1st Round"")

sum_table <- grand_slam_timeline %>%
  filter(!is.na(outcome), outcome %in% past_qual) %>%
  group_by(player, gender, outcome) %>%
    tally() %>%
  ungroup() %>%
  group_by(gender) %>%
  group_split() # This is pretty cool! First time using group_split()

# Access the separate tibbles (probably bad practice, but wanted to try using group_splitanyway...)

male_players <- sum_table[[2]]
female_players <- sum_table[[1]]


# Top 20 males by # appearances after qualification (doesn't include absence/retire data)
top_male_appear <- male_players %>%
  group_by(player) %>%
  summarize(
    appearances = sum(n)
  ) %>%
  arrange(-appearances) %>%
  head(20)

# Top females by # appearances after qualification (doesn't include absence/retire data)
top_female_appear <- female_players %>%
  group_by(player) %>%
  summarize(
    appearances = sum(n)
  ) %>%
  arrange(-appearances) %>%
  head(20)

vec_m <- unique(top_male_appear$player)
vec_f <- unique(top_female_appear$player)

# Joins to keep top 10 by total appearances beyond qualifying round

m_appear <- top_male_appear %>%
  inner_join(male_players) %>%
  mutate(player = as.factor(player)) %>%
  mutate(outcome = as.factor(outcome))

f_appear <- top_female_appear %>%
  inner_join(female_players) %>%
  mutate(player = as.factor(player)) %>%
  mutate(outcome = as.factor(outcome))

# Relevel by top players
f_appear$player <- fct_relevel(f_appear$player, vec_f)
m_appear$player <- fct_relevel(m_appear$player, vec_m)

# Relevel outcome
f_appear$outcome <- fct_relevel(f_appear$outcome,""Won"", ""Finalist"",""Semi-finalist"",""Quarterfinalist"",""4th Round"", ""3rd Round"",""2nd Round"",""1st Round"")

m_appear$outcome <- fct_relevel(m_appear$outcome,""Won"", ""Finalist"",""Semi-finalist"",""Quarterfinalist"",""4th Round"", ""3rd Round"",""2nd Round"",""1st Round"")

# Then make a graph that shows the level reached after qualifiers for each:

# pal <- wes_palette(8, name = ""FantasticFox1"", type = ""continuous"")
# Create palette:
pal <- lacroix_palette(""PassionFruit"", n = 8, type = ""continuous"")

# Graph of female top appearances:
ggplot(f_appear, aes(x = reorder(player, desc(player)), y = n)) +
  geom_col(aes(fill = outcome)) +
  dark_mode(theme_pomological(base_family = ""Courier New"", base_size = 12)) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,90)) +
  scale_fill_manual(values = pal, name = ""Outcome:"") +
  labs(x = """", y = ""Number of appearances\n(beyond qualifiers)"", title = ""Grand Slam appearances & outcomes"") +
  theme(legend.position = ""bottom"",
        axis.text.x=element_text(size=11, face = ""bold"", hjust = 1, color = ""deeppink""),
        axis.text.y = element_text(size = 10, color = ""chartreuse"", face = ""bold""),
        axis.title.x = element_text(color = ""cyan3"", face = ""bold""),
        legend.title = element_text(color = ""deeppink"", size = 12, face = ""bold""),
        legend.text = element_text(color = ""chartreuse"", face = ""bold""),
        plot.title = element_text(color = ""cyan3"", face = ""bold""),
        panel.border = element_rect(colour = ""cyan3"")) +
  coord_flip()

# Save it:
ggsave(""my_tennis_plot.png"", width = 8, height = 7)


# Male version:
ggplot(m_appear, aes(x = reorder(player, desc(player)), y = n)) +
  geom_col(aes(fill = outcome)) +
  theme_pomological(base_family = ""Courier New"",
                    base_size = 12) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0,80)) +
  scale_fill_manual(values = pal,
                    name = ""Outcome:"") +
  labs(x = """", y = ""Number of appearances\n(beyond qualifiers)"",
       title = ""Grand Slam Appearances Colorblast"") +
  theme(legend.position = ""bottom"",
        axis.text.x=element_text(size=10, face = ""bold"", angle = 50, hjust = 1),
        axis.text.y = element_text(size = 10, color = ""slateblue4"")) +
  coord_flip()

ggsave(""my_tennis_plot_m.png"", width = 8, height = 7)




","2019-15"
"493",1350,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-04-30","allisonhorst","allison-tidy-tuesdays","2019-04-30/tidy_tuesday_4_30_19.R","# Tidy Tuesday 4/30/19
# Allison Horst
# Bird collisions in Chicago

# Goals:
# Try circle packing?

#----------------
# Get data:

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

# mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

#----------------
# Get packages:

library(tidyverse)
library(lubridate)
library(ggmosaic)
library(packcircles)
library(ggrepel)

#----------------
# Some wrangling for exploration:

# Total collision counts by locality, flight_call, habitat, stratum:
bird_sum <- bird_collisions %>%
  filter(flight_call != ""Rare"") %>%
  group_by(locality, flight_call, habitat, stratum) %>%
  tally()

# Counts of collisions by year (Chicago):
bird_year <- bird_collisions %>%
  mutate(year = year(date)) %>%
  filter(locality == ""CHI"") %>%
  group_by(year, family, flight_call) %>%
  tally()

# Counts of collisions by family:
bird_tot <- bird_collisions %>%
  group_by(flight_call, family) %>%
  tally()

#----------------
# Some exploratory graphs:

# Plot collisions over years:
ggplot(bird_year, aes(x = year, y = n)) +
  geom_point(aes(color = family,
                 pch = flight_call))

# Mosaic plot by flight call (works, but not interesting)
ggplot(bird_sum) +
  geom_mosaic(aes(weight = n,
                  x = product(locality, habitat),
                  fill = flight_call))

#----------------
# Circle packing try...

# Make circles!

circles <- packcircles::circleProgressiveLayout(bird_tot$n, sizetype='area')

data <- data.frame(bird_tot, circles) %>%
  mutate(id = row_number())

data_vertices <- circleLayoutVertices(circles, npoints=100)
data_join <- full_join(data, data_vertices)
data_min_join <- left_join(data, data_vertices)

# Create final circle graph:

ggplot() +
  geom_polygon(data = data_join,
               aes(x, y,
                   group = id,
                   fill = factor(flight_call)),
               color = ""NA"") +
   geom_polygon(data = data_vertices,
               aes(x, y, group = id),
               size = 0.5,
               fill = NA,
               color = NA) +
  scale_fill_manual(values = c(""darkorange"",""cyan4"",""slateblue1""),
                    breaks = c(""No"",""Rare"", ""Yes""),
                    name = ""Flight call?"") +
  geom_text_repel(data = data_min_join,
                  aes(x, y, label = family, size = radius),
                  segment.size = 0.2,
                  min.segment.length = 0.4,
                  segment.color = ""black"",
                  color = ""black"",
                  force = 35,
                  family = ""Arial"",
                  fontface = ""italic""
                  ) +
  scale_radius(range = c(2,8), guide = ""none"") +
  labs(x = """", y = """",
       title = ""Bird collisions in Chicago by family"",
       subtitle = ""Circle areas ~ Number of collisions"") +
  theme_void() +
  theme(legend.position = ""bottom"",
        legend.text = element_text(color = ""black"", size = 10),
        legend.title = element_text(color = ""black"", size = 12),
        text = element_text(family = ""Arial"")
        ) +
  coord_equal()

ggsave(""2019-04-30/bird_collision_circles.png"")

#--------------
# Testing github update...



","2019-18"
"494",1351,"https://github.com/allisonhorst/allison-tidy-tuesdays/tree/master/2019-05-20","allisonhorst","allison-tidy-tuesdays","2019-05-20/tidy_tuesday_5_20_19.R","# Tidy Tuesday 5/19/2019
# Global plastics
# Allison Horst

# Attache packages:
library(tidyverse)
library(janitor)
library(extrafont)
library(treemapify)

# Get the data:
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>% clean_names()

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>% clean_names()

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>% clean_names()

# Make df names and column names more manageable:
coastal <- coast_vs_waste %>%
  rename(mis_plastic = mismanaged_plastic_waste_tonnes,
         coast_pop = coastal_population,
         tot_pop_gm = total_population_gapminder)

mis_gdp <- mismanaged_vs_gdp %>%
  rename(mis_plastic_percap = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day,
         gdp_per_cap = gdp_per_capita_ppp_constant_2011_international_rate,
         tot_pop_gm = total_population_gapminder)

waste_gdp <- waste_vs_gdp %>%
  rename(plast_waste_percap = per_capita_plastic_waste_kilograms_per_person_per_day,
         gdp_per_cap = gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
         tot_pop_gm = total_population_gapminder)

# Join them together (only includes 2010 data when NAs removed...)
# NEED TO DOUBLE CHECK THESE JOINS, UNITS & CONVERSIONS...
all_join <- full_join(coastal, mis_gdp) %>% # join
  full_join(waste_gdp) %>% # again
  drop_na(mis_plastic) %>% # get rid of NAs (only keeps 2010)
  filter(entity != ""World"") %>% # No world total
  mutate(tot_plastic_2010 = tot_pop_gm*plast_waste_percap*365) %>% # calc totals (ANNUAL KG)
  mutate(mis_plastic_kg = mis_plastic*907.185) %>%  # Convert from tons to kg (1 ton = 907.185 kg)
  mutate(perc_mismanaged = mis_plastic_kg/tot_plastic_2010) %>%
  arrange(-tot_plastic_2010)

# Coastal pop vs. mismanaged plastics
ggplot(all_join, aes(x = coast_pop, y = mis_plastic)) +
  geom_point()

ggplot(all_join, aes(x = gdp_per_cap, y = perc_mismanaged)) +
  geom_point()

# Test log (base-10) scale?
ggplot(all_join, aes(x = log10(coast_pop), y = log10(mis_plastic))) +
  geom_point() # Eh. I think log scales are hard to think about.

# Treemap?

ggplot(all_join, aes(area = tot_plastic_2010, label = entity, fill = tot_plastic_2010)) +
  geom_treemap(color = ""white"", start = ""topleft"") +
  geom_treemap_text(min.size = 4, place = ""center"", family = ""Carrois Gothic"", color = ""white"", start = ""topleft"") +
  scale_fill_gradientn(colors = c(""black"",""green3"")) +
  theme(legend.position = ""NA"") +
  labs(title = ""Total plastics, 2010"") +
  theme(text = element_text(family = ""Carrois Gothic""))

ggsave(""2019-05-20/plastic_treemap.png"", width = 8, height = 8)
","2019-20"
"495",1352,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-04-16/tidy_tuesday_04_16_19.R","# Tidy Tuesday 4/16/19
# Allison Horst
# Take a decent graph, and make it an absolute abomination


#######
# Load packages
#######

library(tidyverse)
library(extrafont)
library(RColorBrewer)
library(lubridate)
library(ggdark)
library(cowplot)

#######
# Get data (needed here: brexit, corbyn, dogs)
#######

# Thanks to Sarah Leo and The Economist for these (""Mistakes, We've Drawn a Few"") data!

# brexit <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv"")

# corbyn <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/corbyn.csv"")

# dogs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

#eu_balance <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")

#pensions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/pensions.csv"")

#trade <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/trade.csv"")

#women_research <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")

#########
# Corbyn Facebook Abomination
#########

corbyn_graph <- ggplot(corbyn, aes(x = political_group, y = log(avg_facebook_likes))) +
  geom_bar(stat = ""identity"", width = 1, aes(fill = political_group), color = ""black"") +
  scale_fill_brewer(palette = ""Greens"",
                    name = ""Never give in, never relevel"") +
  theme(plot.title = element_text(size = 30,
                             family = ""Times New Roman"",
                             color = ""green"",
                             face = ""italic""),
        axis.text.x = element_blank(),
        axis.text.y = element_text(size = 8,
                                   color = ""white"",
                                   angle = 20,
                                   vjust = -0.5),
        axis.title.x = element_text(size = 20,
                                    family = ""Courier New"",
                                    color = ""black""),
        axis.title.y = element_text(size = 14,
                                    color = ""navy"",
                                    family = ""Impact""),
        panel.background = element_rect(color = ""black"",
                                        fill = ""yellow"",
                                        size = 2),
        legend.title = element_text(size = 12,
                                    color = ""brown4""),
        legend.text = element_text(family = ""Times New Roman"", size = 11),
        legend.background = element_rect(fill = ""tan""),
        panel.grid.major = element_line(color = ""red""),
        plot.background = element_rect(fill = ""hotpink""),
        strip.background = element_rect(fill = ""darkgreen""),
        strip.text = element_text(color = ""skyblue"",
                                  face = ""bold"",
                                  family = ""Arial Rounded MT Bold"",
                                  size = 8)
        ) +
  labs(x = ""must polar"",
       y = ""log scale\nsuch easy interpretation"",
       title = ""So good"",
       subtitle = ""Artisanal color palette"",
       caption = ""tag: dataviz comp submission"") +
  scale_y_continuous(limits = c(0,10)) +
  coord_polar() +
  facet_wrap(~political_group)


#########
# Brexit MaxGross
#########

# Some wrangling:
brexit_2 <- brexit %>%
  mutate(date = dmy(date)) %>% # YAY lubridate!
  gather(""response"",""percent"",-date) # 100th time I've had to learn gather this year...


# And another rave:
brexit_graph_1 <- ggplot(brexit_2, aes(x = date, y = percent, group = response)) +
  geom_area(position = ""identity"",
            aes(fill = response, color = response),
            alpha = 0.5,
            size = 0.7,
            lty = 1) +
  scale_fill_manual(values = c(""purple"",""yellow""),
                    name = ""Brexit:"",
                    breaks=c(""percent_responding_right"", ""percent_responding_wrong""),
                    labels=c(""It's right!"", ""It's wrong!"")) +
  scale_color_manual(values = c(""magenta"",""orange""),
                     name = ""Brexit:"",
                     breaks=c(""percent_responding_right"", ""percent_responding_wrong""),
                     labels=c(""It's right!"", ""It's wrong!"")) +
  coord_cartesian(ylim = c(40, 48)) +
  scale_x_date(expand = c(0,0),
               breaks = ""4 months"",
               date_labels = ""%b %Y"") +
  dark_mode(theme_pubclean()) +
  theme(
    legend.position = ""top"",
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  labs(x = ""Date"", y = ""Percentage Responding\n(Brexit right or wrong?)"")

# Also I want to make one like the better version...

# Wrangling for dates:
brexit_3 <- brexit %>%
  mutate(date = dmy(date))

brexit_graph <- ggplot(brexit_3) +
  geom_point(aes(x = date,
                 y = percent_responding_right),
             color = ""orange"",
             size = 3,
             pch = 6) +
  geom_point(aes(x = date,
                 y = percent_responding_wrong),
             color = ""purple"",
             size = 3,
             pch = 5) +
  dark_mode(theme_pubclean()) +
  theme(
    text = element_text(family = ""Tahoma""),
    legend.position = ""top""
  ) +
  geom_smooth(aes(x = date,
                  y = percent_responding_right),
              color = ""darkorange"",
              fill = ""orange"",
              span = 5,
              lty = 6) +
  geom_smooth(aes(x = date,
                  y = percent_responding_wrong),
              color = ""purple"",
              fill = ""magenta"",
              span = 5,
              lty = 11) +
  labs(x = ""Date"",
       y = ""Percent of respondents"",
       title = ""Brexit opinions"",
       subtitle = ""Who is Loess anyway?"") +
  scale_x_date(""Date"",
               date_labels = ""%b %Y"",
               date_breaks = ""6 months""
               )

brex_graph


###########
# And one more quick one just so I can practice with ggpubr (dogs)
###########

# Gather
dogs_2 <- dogs %>%
  gather(""param"", ""val"", -year)

dog_graph <- ggplot(dogs_2, aes(x = year, y = val, group = param)) +
  geom_point(aes(color = param, pch = param), size = 4) +
  geom_line(aes(color = param)) +
  scale_color_manual(values = c(""blue"",""black"")) +
  scale_x_continuous(limits = c(2005, 2016),
                     breaks = seq(2005, 2016),
                     expand = c(0,0)) +
  scale_y_continuous(limits = c(0,50),
                     minor_breaks = seq(0,50, by = 2),
                     expand = c(0,0)) +
  theme(legend.position = ""top"",
        plot.background = element_rect(fill = ""lightgoldenrod""),
        axis.text.x = element_text(angle = 90)
        ) +
  labs(x = ""Year"", y = ""Size-o-meter"", title = ""Adopt a shelter dog!"")


##########
# COWPLOT! Multiple graph layouts.
##########

ggdraw() +
  draw_plot(corbyn_graph, x = 0, y = 0.5, height = 0.5, width = 1) +
  draw_plot(dog_graph, x = 0, y = 0, width = 0.5, height = 0.5) +
  draw_plot(brexit_graph_1, x = 0.52, y = 0, width = 0.5, height = 0.5) +
  draw_plot_label(label = c(""A"", ""B"", ""C""), size = 20, colour = ""purple"",
                  x = c(0, 0, 0.52), y = c(0.98, 0.5, 0.5))

ggsave(""cowplot_test.png"", width = 8, height = 10, units = ""in"")

write_csv(dogs_2, ""my_dog_file.csv"")
","2019-16"
"496",1353,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-05-14/tidy_tuesday_5_14_19.R","# Nobel Prize Winners
# #tidytuesday 5/14/2019

# Allison Horst

# Goal: Create a timeline of women who've won the Nobel Prize

# Get data on Nobel Prize winners (more information here: https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-05-14):

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

# Load packages:

library(tidyverse)
library(lubridate)
library(extrafont)

# Some wrangling

nobels <- nobel_winners %>%
  mutate(yrand = rnorm(969, mean = 0, sd = 1)) %>%
  filter(laureate_type == ""Individual"")


# Create random sequences for year jitter:

set.seed(1001)
r_seq <- rnorm(48, mean = 0, sd = 10)

set.seed(1002)
r_seq_2 <- rnorm(939, mean = 0, sd = 0)


# Add columns with jittered year (using sequences above)

women_nobels <- nobel_winners %>%
  filter(laureate_type == ""Individual"") %>%
  filter(gender == ""Female"") %>%
  mutate(f_yrand = 1) %>%
  mutate(year_jitter = prize_year + r_seq)

all_nobels <- nobels %>%
  mutate(all_rand = 1) %>%
  mutate(year_jitter_all = prize_year + r_seq_2) %>%
  mutate(gender = fct_relevel(gender, ""Male"", ""Female"")) %>%
  mutate(category = fct_relevel(category, ""Physics"",""Economics"",""Chemistry"",""Medicine"",""Literature"",""Peace""))

# Make text
text_df <- data.frame(
  label = c(""Physics: 2/222"",""Economics: 2/83"",""Chemistry: 4/194"", ""Medicine: 12/227"", ""Literature: 14/113"", ""Peace: 14/100""),
  category = c(""Physics"",""Economics"",""Chemistry"",""Medicine"",""Literature"",""Peace""),
  x = c(1905,1905,1905),
  y = c(1,2,3)
)

# Chemistry, Economics, Literature, Medicine, Peace, Physics

# women_nobels$rand_val <- r_seq
#
# women_nobels_jitteryear <- women_nobels %>%
# mutate(jitter_year = prize_year + rand_val)

# Physics: 2/222
#

# Trying geom_linerange

ggplot(women_nobels, aes(y = f_yrand, ymin = 0, x = year_jitter, ymax = f_yrand)) +
  geom_linerange(size = 1) +
  geom_text(aes(label = full_name),
            angle = 50,
            vjust = 0,
            hjust = -0.05,
            size = 2)

# This all looks hideous and the y-axis doesn't make sense.

# Trying with all nobel winners:

ggplot(all_nobels, aes(y = all_rand,
                       ymin = 0,
                       x = year_jitter_all,
                       ymax = all_rand)) +
  geom_linerange(size = 1.5,
                 aes(color = gender),
                 alpha = 0.4) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,1), limits = c(1901, 2016), breaks = c(1901,2016)) +
  scale_color_manual(values = c(""mediumorchid4"",""cyan"")) +
  facet_wrap(~category, ncol = 1, strip.position = ""left"") +
  theme_minimal() +
  labs(title = ""Individual Nobel Prize Winners\n1901 - 2016"") +
  theme(panel.background = element_rect(fill = ""black""),
        plot.background = element_rect(fill = ""black""),
        legend.position = ""bottom"",
        legend.title = element_blank(),
        legend.text = element_text(color = ""gray60"", size = 10),
        strip.text = element_text(color = ""gray60"", size = 9),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_text(color = ""gray70""),
        plot.margin=unit(c(1,1,1,1.2),""cm""),
        plot.title = element_text(color = ""gray60""),
        text = element_text(family = ""Trebuchet MS"")
  )


ggplot(all_nobels, aes(y = all_rand,
                       ymin = 0,
                       x = year_jitter_all,
                       ymax = all_rand)) +
  geom_linerange(size = 1.5,
                 aes(color = gender),
                 alpha = 0.4) +
  scale_y_continuous(expand = c(0,0)) +
  scale_x_continuous(expand = c(0,1), limits = c(1901, 2016), breaks = c(1901,2016)) +
  scale_color_manual(values = c(""mediumorchid4"",""cyan"")) +
  facet_wrap(~category, ncol = 1, strip.position = ""left"") +
  theme_minimal() +
  theme(panel.background = element_rect(fill = ""black""),
        plot.background = element_rect(fill = ""black""),
        legend.position = ""NA"",
        legend.title = element_blank(),
        legend.text = element_blank(),
        strip.text = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_blank(),
        plot.margin=unit(c(1,1,1,1.2),""cm""),
        plot.title = element_text(color = ""gray60""),
        text = element_text(family = ""Trebuchet MS"")
  )
ggsave(""2019-05-14/nobel_winners_vague.png"", width = 7, height = 7)

# Get some summary counts:

nobel_sum <- nobel_winners %>%
  filter(laureate_type == ""Individual"") %>%
  group_by(category, gender) %>%
  tally()

# Physics: 2/222
# Economics: 2/83
# Chemistry: 4/194
# Medicine: 12/227
# Literature: 14/113
# Peace: 14/100


","2019-20"
"497",1354,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-05-28/tidy_tuesday_5_28_19.R","#######
# Tidy Tuesday 5/28/2019
# Wine ratings
#######

# Attach packages
library(tidyverse)
library(extrafont)
library(ggdark)

# Get the data:
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

# A bunch of wrangling (much unnecessary) + exploration station:

# Find the points-to-price ratios:
wine_deal <- wine_ratings %>%
  select(points, price, title) %>% # Only keep these columns
  mutate(pp_ratio = points/price) %>% # Find the points:price ratio
  arrange(-pp_ratio) # Arrange by high-to-low ratio

# Checking counts for each wine type (don't really care):
wine_counts <- wine_ratings %>%
  group_by(title) %>%
  tally() %>%
  arrange(-n)

# Find the top 15 countries with them most reviews:
country_counts <- wine_ratings %>%
  group_by(country) %>%
  tally() %>%
  arrange(-n) %>%
  head(15) %>%
  select(country)

# Find the median point:price ratio for those 15 countries:
# Note: something is effed here. (not reproducible right now)
country_medians <- wine_deal %>%
  inner_join(wine_ratings) %>%
  inner_join(country_counts) %>%
  group_by(country) %>%
  summarize(
    med_ratio = median(pp_ratio, na.rm = TRUE)
  ) %>%
  arrange(-med_ratio)

# Join to have prices, number, ratio in single table, relevel by medians:
wine_all <- wine_deal %>%
  inner_join(wine_ratings) %>%
  inner_join(wine_counts) %>%
  inner_join(country_counts) %>%
  select(title, pp_ratio, country, variety,n) %>%
  drop_na(country) %>%
  mutate(country = as.factor(country)) %>% # Not necessary?
  mutate(country = fct_relevel(country, country_medians$country))

# Violin plot of points:price ratios by country
ggplot(wine_all, aes(x = reorder(country, desc(country)), y = pp_ratio)) +
  geom_violin(aes(color = country, fill = country), width = 1.0) +
  geom_boxplot(fill = NA, color = ""white"", width = 0.4, size = 0.3, outlier.color = NA) +
  labs(x = ""Country\n"",y = ""\nPoints-per-price ratio (higher = better)"", title = ""Wine points:price ratio (sweet deal metric) by country"", subtitle = ""*For the 15 countries with the highest number of reviews in Kaggle dataset"") +
  dark_mode(theme_minimal()) +
  theme(legend.position = ""NA"",
        text = element_text(family = ""Muli""),
        plot.subtitle = element_text(size = 8, face = ""italic"")) +
  coord_flip()

# ggsave(""2019-05-28/wine_deals.png"", width = 7, height = 5)
","2019-22"
"498",1355,"https://github.com/allisonhorst/allison-tidy-tuesdays","allisonhorst","allison-tidy-tuesdays","2019-06-04/tidy_tuesday_6_4_19.R","#################
# Tidy Tuesday 6/4/2019
# Allison Horst
# Ramen ratings!

# ""This week's dataset is a ramen ratings dataset from The Ramen Rater. H/t to Data is Plural.""
##################

# Attach packages
library(tidyverse)
library(LaCroixColoR)
library(extrafont)
library(ggbeeswarm)
library(ggridges)

# Get the data
ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

# Find the most commonly rated brands:
ramen_common <- ramen_ratings %>%
  group_by(brand) %>%
  tally() %>%
  arrange(-n) %>%
  head(20) %>%
  inner_join(ramen_ratings)

# Brand medians:
brand_medians <- ramen_common %>%
  group_by(brand) %>%
  summarize(
    medians = median(stars, na.rm = TRUE)
  ) %>%
  arrange(-medians)

# Relevel brand factor levels by median
ramen_common$brand <- fct_relevel(ramen_common$brand, levels = brand_medians$brand)

# Palette specs
pal <- lacroix_palette(""Berry"", n = 20, type = ""continuous"")

# Only keep those brands from the original df, plot
ramen_top_brands <- ramen_common %>%
  filter(brand %in% unique(ramen_common$brand))

ggplot(ramen_top_brands, aes(x = reorder(brand, desc(brand)), y = stars)) +
  # geom_quasirandom(aes(color = brand),
  #              alpha = 0.3,
  #              size = 1) +
  geom_jitter(size = 1,
              alpha = 0.3,
              aes(color = brand),
              width = 0.1) +
  geom_boxplot(size = 0.2,
               aes(fill = brand),
               alpha = 0.8,
               outlier.alpha = 0) +
  geom_point(data = brand_medians, aes(x = brand, y = medians),
             color = ""gray10"",
             fill = ""gray10"",
             size = 2,
             pch = 21) +
  coord_flip() +
  theme_minimal() +
  theme(text = element_text(family = ""Josefin Sans""),
        legend.position = ""NA"",
        panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_line(color = ""gray90""),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_line(color = ""gray90""),
        plot.subtitle = element_text(color = ""gray50""),
        plot.caption = element_text(color = ""gray50"")) +
  scale_color_manual(values = pal) +
  scale_fill_manual(values = pal) +
  labs(x = ""Ramen Brand"",
       y = ""Rating (5 = best)\n"",
       title = ""Ramen ratings by brand*"",
       subtitle = ""Data from The Ramen Rater"",
       caption =
         ""*for 20 brands with most observations (n) in dataset"")

ggsave(""2019-06-04/ramen_by_brand.png"", width = 6, height = 6 )

# Just more messing around...

pal_2 <- pal <- lacroix_palette(""Apricot"", n = 5, type = ""continuous"")

ramen_ratings %>%
  filter(brand %in% unique(ramen_common$brand)) %>%
  ggplot(., aes(brand, stars)) +
  geom_quasirandom(aes(color = brand), alpha = 0.5, size = 2) +
  coord_flip() +
  scale_color_manual(values = pal) +
  theme_light() +
  theme(
    text = element_text(family = ""Muli""),
    legend.position = ""NA""
  )

# Hm cool.
# Now investigating by country:

# Top 20 countries with most ratings
common_countries <- ramen_ratings %>%
  group_by(country) %>%
  tally() %>%
  arrange(-n) %>%
  head(20) %>%
  inner_join(ramen_ratings) # Join back. Cool.

# Find median order for factor releveling:
country_medians <- common_countries %>%
  group_by(country) %>%
  summarize(
    medians = median(stars, na.rm = TRUE)
  ) %>%
  arrange(-medians)

# Use that order to relevel the country factor levels in common_countries
common_countries$country <- fct_relevel(common_countries$country, levels = country_medians$country)


# Plot ramen by country

pal_3 <- lacroix_palette(""Berry"", n = 20, type = ""continuous"")


ggplot(common_countries, aes(x = reorder(country, desc(country)), y = stars)) +
  geom_quasirandom(alpha = 0.3,
                   aes(color = country)) +
  geom_boxplot(alpha = 0.6,
               size = 0.2,
               color = ""black"",
               aes(fill = country),
               outlier.color = NA) +
  geom_point(data = country_medians, aes(x = country, y = medians),
             color = ""gray20"",
             size = 3,
             pch = 19) + #124 is vertical line
  scale_y_continuous() +
  scale_fill_manual(values = pal_3) +
  scale_color_manual(values = pal_3) +
  theme_minimal() +
  coord_flip() +
  theme(
    legend.position = ""NA"",
    panel.grid.minor.x = element_blank(),
    text = element_text(family = ""Josefin Sans"")
  ) +
  labs(y = ""Rating (5 = better)"",
       x = ""Country Produced"",
       title = ""Ramen ratings by production country*"",
       subtitle = ""Data from The Ramen Rater"")

ggsave(""2019-06-04/ramen.png"", width = 5, height = 5)


# Switch side of axis labels (y)
# Add (n = #) to each row for number of observations
# Add caption with *Only 20 countries with highest # observations included

####################
# FINAL GGRIDGES GRAPH
####################
# Some other weird tests of things
# ggridges?
# Using the ramen_top_brands dataset

pal_4 <- lacroix_palette(""Coconut"", n = 20, type = ""continuous"")

ggplot(ramen_top_brands, aes(x = stars, y = brand)) +
  geom_density_ridges(scale = 7,
                      aes(fill = brand),
                      size = 0.3,
                      color = ""NA"") +
  scale_fill_manual(values = pal_4) +
  scale_color_manual(values = pal_4) +
  scale_x_continuous(breaks = c(0,1,2,3,4,5), limits = c(0,5), expand = c(0,0)) +
  theme_minimal() +
  theme(text = element_text(family = ""Carrois Gothic""),
        legend.position = ""NA"",
        panel.grid.minor.x = element_blank(),
        panel.grid.major.y = element_line(color = ""gray90""),
        panel.grid.major.x = element_line(color = ""gray90""),
        panel.grid.minor.y = element_blank(),
        plot.subtitle = element_text(color = ""gray50""),
        plot.caption = element_text(color = ""gray50""),
        plot.title = element_text(size = 18),
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.y = element_text(size = 12)
        ) +
  labs(x = ""Rating (5 = best)\n"",
       y = ""Ramen Brand\n"",
       title = ""Ramen ratings by brand*"",
       subtitle = ""Data from The Ramen Rater"",
       caption =
         ""*for 20 brands with most observations (n) in dataset"")

ggsave(""2019-06-04/ramen_ggridges.png"", width = 7, height = 7)
","2019-23"
"499",1392,"https://github.com/l2nguyen/tidy_tues/blob/master/2019/April16/brexit.R","l2nguyen","tidy_tues","2019/April16/brexit.R","library(tidyverse)
library(ggthemes)

brexit <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv"")

brexit_manip <- brexit %>%
  gather(key = ""response"", value = ""percent"", -date) %>%
  mutate(date = lubridate::dmy(date),
         response = recode(response,
                           ""percent_responding_right"" =""Right"",
                           ""percent_responding_wrong"" = ""Wrong"")
         )

ggplot(brexit_manip, aes(x=date, y=percent, col=response)) +
  geom_point(alpha = 0.2) +
  geom_smooth(se=FALSE) +
  geom_text(data = filter(brexit_manip, date==max(date)),
             aes(label=response),
             nudge_y = -0.5) +
  scale_color_manual(values = c(""#2554C7"",""#B31423"")) +
  theme_economist() +
    scale_x_date(date_breaks = ""1 year"", date_labels=""%Y"") +
  scale_y_continuous(breaks=seq(38, 50, by=2),
                     limits = c(38,50)) +
  labs(
    title = ""Bremorse"",
    subtitle = ""In hindsight, do you think it was right or wrong to vote to leave the EU?"",
    y = ""% responding"",
    caption = ""Source: Economist""
  ) +
  theme(
    legend.position = ""none"",
    plot.title = element_text(size = 14, hjust=0),
    plot.caption = element_text(hjust = 0, face = ""bold""),
    axis.title.x = element_blank(),
    axis.title.y.left = element_text(size=9, face=""italic"", angle = 0,
                                     margin= margin(0,-55,0,0)
                                     ),
    axis.ticks.length = unit(0.2, ""cm"")
    )","2019-23"
"500",1393,"https://github.com/phillynerd/TidyTuesday/tree/master/RamenRatings_6-6-2019","phillynerd","TidyTuesday","RamenRatings_6-6-2019/BestRamenCountries.R","
#Data####
RamenRaw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

#Data Dictionary####
#review_number	integer	Ramen review number, increasing from 1
#brand-	character	Brand of the ramen
#variety-	character	The ramen variety, eg a flavor, style, ingredient
#style-	character	Style of container (cup, pack, tray,
#country-	character	Origin country of the ramen brand
#stars-	double	0-5 rating of the ramen, 5 is best, 0 is worst
 
#Libraries####                                   

#devtools::install_github(""dill/emoGG"") 
library(tidyverse)
library(tidylog)
library(skimr)
library(visdat)
library(emoGG)

emoGG::emoji_search(""ramen"")
emoGG::geom_emoji()
#exploring
vis_miss(RamenRaw) #remove those with no ratings, v small percent; can also remove those w no style listed.
skim(RamenRaw)

RamenClean<- RamenRaw %>% 
  filter(is.na(stars) == F, is.na(style) == F) %>% 
  mutate(style = factor(style),
         country = factor(country))

#which countries produce the highest rated ramen
RamenClean %>% 
  group_by(country) %>% 
  summarize(AvgRating = mean(stars),
            NReviews = n()) %>% 
  ggplot(aes(y = reorder(country, AvgRating),x = AvgRating)) +
  geom_segment(aes(x = 0, xend = AvgRating, yend = country), color = ""#e0dabc"", size = 1.5) +
  geom_emoji(emoji = ""1f365"", size = .03) +
  geom_vline(xintercept = mean(RamenClean$stars), color = ""red"")+
  geom_text(aes(label = NReviews), size = 3, hjust = -.5) +
  labs(title = ""Which Countries Produce the Best Ramen?"",
       x = ""Average Rating Across All Products (0-5)"",
       caption = ""Numbers represent total N of reviews per country\nData: TheRamenRater.com|Viz: @phillynerd"") +
  scale_x_continuous(limits = c(0,5)) +
  add_emoji(emoji = ""1f35c"") +
  theme(panel.grid = element_blank(),
       panel.background = element_rect(fill = ""#9b9999""),
       axis.title.y = element_blank() ) +
  annotate(geom = ""text"", 
           x = mean(RamenClean$stars), y = 0, 
           label = paste0(""Overall Avg: "", round(mean(RamenClean$stars),1)),
           angle = 90,
           hjust = -.2, vjust = -.5, size = 4)
 
 
","2019-23"
"501",1398,"http://github.com/bwenden/TidyTuesdays/tree/master/Wines_2019-05-28","bwenden","TidyTuesdays","Wines_2019-05-28/Script.R","library(tidyverse)
library(tidytext)
library(ggthemes)

#Import data
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
  select(-X1) %>%
  distinct()

###Extract flavors and taste characteristics
wine_words <- wine_ratings %>%
  unnest_tokens(description_word, description) %>%
  anti_join(stop_words, by = c(""description_word"" = ""word"")) %>%
  filter(!str_detect(description_word, ""[:digit:]"")) %>%
  add_count(description_word)

  
###Percentage of occurrences of the words in the review score range
###I used the classification system from WineEnthusiast

description_words <- wine_words %>%
  filter(n >= 20) %>%
  mutate(score = case_when((points<=82) ~ ""Acceptable"",
                           (points >= 83)&(points<= 86) ~ ""Good"",
                           (points >= 87)&(points<= 89) ~ ""Very Good"",
                           (points >= 90)&(points<= 93) ~ ""Excellent"",
                           (points >= 94)&(points<= 97) ~ ""Superb"",
                           (points >=98) ~ ""Classic"" )) %>%
  count(description_word, score, sort = TRUE) %>%
  group_by(description_word) %>%
  mutate(percent = n / sum(n)) 

###Enrichment analysis
wine_words_enrichment <- wine_words %>%
  filter(n >= 20) %>%
  mutate(score = case_when((points<=82) ~ ""Acceptable"",
                           (points >= 83)&(points<= 86) ~ ""Good"",
                           (points >= 87)&(points<= 89) ~ ""Very Good"",
                           (points >= 90)&(points<= 93) ~ ""Excellent"",
                           (points >= 94)&(points<= 97) ~ ""Superb"",
                           (points >=98) ~ ""Classic"" )) %>%
  select(description_word, score) %>%
  add_count(score, name = ""Total_word_number_in_score"") %>%
  add_count(description_word, name = ""Total_occurrence"") %>%
  add_count(description_word, score, name = ""word_occurrence_in_this_score"") %>%
  add_count(name = ""Total_words"") %>%
  distinct() %>%
  group_by(score) %>%
  mutate(
    pvalue = phyper(
      q = word_occurrence_in_this_score,
      m = Total_occurrence,
      n = Total_words - Total_occurrence,
      k = Total_word_number_in_score,
      lower.tail = F, log.p = FALSE),
    qvalue = p.adjust(pvalue, method = ""fdr"")
  )
  
wine_words_enrichment %>%
  group_by(score) %>%
  mutate(rank = rank(qvalue, ties.method = ""first"")) %>%
  filter(rank <= 10) %>%
  ungroup() %>%
  mutate(qvalue = ifelse(qvalue == 0, (min(qvalue[qvalue > 0])), qvalue)) %>%
  arrange(rank) %>% 
  ggplot(aes(y = qvalue, x = fct_reorder(description_word, -rank)))+
  geom_point(aes(color = qvalue, size = word_occurrence_in_this_score/Total_word_number_in_score), alpha = 0.5)+
  scale_color_gradient(low = ""#c03728"", high=""#f5c04a"", 
                       trans = ""log"",
                       breaks = c(1e-250, 1e-150,1e-50))+
  scale_size_continuous(labels = scales::percent_format(accuracy = 1))+
  coord_flip()+
  facet_wrap(~fct_relevel(score,c(""Classic"", ""Superb"", ""Excellent"", ""Very Good"", ""Good"",""Acceptable"")),
             scales = ""free"")+
  scale_y_log10()+
  theme_tufte()+
  labs(y = """", x = """", 
       color = ""Enrichment\nadjusted p.value"",
       size = ""Word occurrence"",
       title = ""Which words are preferentially used to describe superb or bad wines?"",
       caption = ""Source: Wine Enthusiast - 2017\nVisualization by Bndicte Wenden @cherrysearch"")+
  theme(legend.position = ""bottom"",
        legend.direction = ""horizontal"",
        title = element_text(color = ""#6f5438"", size = 14),
        strip.text = element_text(size = 12, face = ""italic"",color = ""#6f5438""),
        axis.text.y = element_text(size = 10, color = ""#6f5438""),
        plot.background = element_rect(fill = ""#fffeea""),
        axis.line.y.left = element_line(color = ""#6f5438""),
        axis.ticks.y.left = element_blank(),
        panel.spacing.x = unit(2, ""lines""),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.title = element_text(size = 12, color = ""#6f5438""),
        legend.text = element_text(size = 10,color = ""#6f5438"")
  )

ggsave(""TidyTuesday_wines.png"", width = 12, height = 7)
","2019-22"
"502",1399,"https://github.com/alyssamv/tidytuesdays/blob/master/2019/GlobalWaste_0521/GlobalWaste.Rmd","alyssamv","tidytuesdays","2019/GlobalWaste_0521/GlobalWaste.Rmd","---
title: ""GlobaPlasticWaste""
author: ""Alyssa Vanderbeek""
date: ""5/21/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(countrycode)
library(ggplot2)
library(ggalt)
library(ggthemes)
library(ggpubr)
library(gridExtra)
library(ggrepel)
```

This week's TidyTuesday dataset looks at global plastic waste disposal in 2010. We also get information about county 2011 GDP, and coastal and total population according to Gapminder. Below, I load in the data and create datasets to work with.

```{r data}
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>%
  janitor::clean_names() %>%
  filter(year == 2010)

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>%
  purrr::set_names(c(""entity"", ""code"", ""year"", ""mismanaged_waste_percap"", ""gdp_per_capita"", ""total_pop"")) %>%
  filter(year == 2010) %>%
  dplyr::select(entity, mismanaged_waste_percap, gdp_per_capita)

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>%
  purrr::set_names(c(""entity"", ""code"", ""year"", ""per_capita_plastic"", ""gdp_per_capita"", ""total_pop"")) %>%
  filter(year == 2010) %>%
  dplyr::select(entity, per_capita_plastic)

# code taken from https://github.com/meensrinivasan/tidytuesdaysubmissions/blob/master/nobel/nobel.R. Gets 'codelist' dataset from the countrycode package and 
codes <- codelist %>%
  select(iso3c, country.name.en, region, continent) %>%
  janitor::clean_names() %>%
  filter(!is.na(continent) & !is.na(region)) %>%
  left_join(CoordinateCleaner::countryref %>% 
              select(iso3, capital.lon, capital.lat), by = c(""iso3c"" = ""iso3"")) %>%
  distinct() %>%
  filter(!is.na(capital.lon) & !is.na(capital.lat))

# master data set of waste information for 2010 across three datasets
waste <- coast_vs_waste %>%
  left_join(mismanaged_vs_gdp, by = ""entity"") %>%
  left_join(waste_vs_gdp, by = ""entity"") %>%
  left_join(codes %>%
              dplyr::select(country_name_en, capital.lon, capital.lat, continent), by = c(""entity"" = ""country_name_en"")) %>% # left_join only the long/lat of capital city for each country
  mutate(total_gdp = gdp_per_capita*total_population_gapminder,
         entity = recode(entity, # recode country names in order to match map data below
                         ""United Kingdom"" = ""UK"",
                         ""United States"" = ""USA"",
                         ""Trinidad & Tobago"" = ""Trinidad"",
                         ""Cote d'Ivoire"" = ""Ivory Coast"",
                         ""Democratic Republic of Congo"" = ""Democratic Republic of the Congo"",
                         ""Congo"" = ""Republic of Congo"",
                         ""Hong Kong"" = ""China"",
                         ""British Virgin Islands"" = ""Virgin Islands"",
                         ""Saint Vincent and the Grenadines"" = ""Saint Vincent""),
         percent_mismanaged = mismanaged_waste_percap / per_capita_plastic,
         percent_global_contbn = mismanaged_plastic_waste_tonnes / sum(mismanaged_plastic_waste_tonnes, na.rm = T))

# map data from ggplot
world <- ggplot2::map_data(""world"") %>%
  filter(region != ""Antarctica"") %>%
  left_join(waste, by = c(""region"" = ""entity""))

countries = world %>%
  group_by(region) %>%
  slice(1) %>%
  mutate(percap_waste_cat = cut(mismanaged_waste_percap,
                                breaks = c(0, 0.01, 0.025, 0.05, 0.10, 0.30)),
         percap_waste_cat_rev = forcats::fct_rev(percap_waste_cat))
```

Let's take a look at some of the data.

```{r}
waste %>%
  select(-entity, -code, -capital.lon, -capital.lat, -year) %>%
  skimr::skim()
```

Based on this summary of selected variables (those related to GDP and waste), it looks like there are at least 50 countries with missing information. Let's see which they are.

```{r}
waste %>%
  select(-code, -capital.lon, -capital.lat, -year) %>%
  filter(is.na(mismanaged_plastic_waste_tonnes) | is.na(mismanaged_waste_percap) | is.na(per_capita_plastic)) %>%
  select(entity)
```

So the above countries are missing all information related to all the above areas of interest. I wonder where the countries with missing information fall in terms of GDP and total population. 

```{r}
gdp_quant50 = quantile(waste$total_gdp, na.rm = T)[3]
pop_quant50 = quantile(waste$total_population_gapminder, na.rm = T)[3]

gdp_vs_pop = waste %>%
  mutate(missing = ifelse(is.na(mismanaged_plastic_waste_tonnes) | 
                            is.na(mismanaged_waste_percap) | 
                            is.na(per_capita_plastic), ""Missing"", ""Available"")) %>% 
  ggplot( aes(x = total_population_gapminder, y = total_gdp, color = missing)) +
  geom_point(alpha = 0.8, size = 3) +
  viridis::scale_color_viridis(discrete = T) +
  coord_cartesian(xlim = c(0,25000000), ylim = c(0, 250000000000)) + # zoom in to exclude outliers
  geom_hline(yintercept = gdp_quant50, linetype = ""dashed"", size = 0.25) +
  annotate(""text"", label = ""50th percentile GDP"", x = 2.26*10^7, y = gdp_quant50 + 0.5*10^10, size = 3) +
  labs(
    x = ""Total population, according to Gapminder"",
    y = ""Total GDP (2011)"",
    subtitle = ""Among countries with available GDP, it seems that most of those with missing data on waste and waste\nmanagement (44/49) have annual GDP of $50 billion or less (50th percentile, designated by dashed line)."",
    color = ""Availability of waste data""
  ) +
  theme(axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        plot.title = element_text(size = 20),
        legend.position = ""bottom"",
        panel.background = element_rect(fill = 'grey', colour = ""black""),
        plot.background = element_rect(fill = 'white', colour = 'white'))


gdp_percap_hist = waste %>%
  mutate(missing = ifelse(is.na(mismanaged_plastic_waste_tonnes) | 
                            is.na(mismanaged_waste_percap) | 
                            is.na(per_capita_plastic), ""missing"", ""available"")) %>%
  ggplot(aes(x = gdp_per_capita, fill = missing)) +
  geom_histogram(position = ""dodge"") +
  viridis::scale_fill_viridis(discrete = T) +
  labs(
    x = ""GDP per capita"",
    y = ""Number of countries"",
    subtitle = ""Countries with missing waste and waste management data are skewed more to the left than those with data\navailable; the majority of them have lower GDP per capita."",
    caption = ""Source: Our World in Data \n@VanderbeekAM ""
  ) +
  theme(axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        plot.title = element_text(size = 20),
        legend.position = ""none"",
        panel.background = element_rect(fill = 'grey', colour = ""black""),
        plot.background = element_rect(fill = 'white', colour = 'white'))

cowplot::plot_grid(gdp_vs_pop, gdp_percap_hist, 
                   nrow = 2, 
                   rel_heights = c(2, 1),
                   labels = ""AUTO"")

ggsave(""./figures/GlobalWaste-pop_vs_gdp.png"", height = 12, width = 8)
```

This figure also gives us some information about the distribution of population and GDP across the world. There are some outliers in both, with significantly large population and GDP, not shown in the scatter plot (China, India, and the USA).

Now we can start to look at the waste information for countries where available.

```{r}
# relationship between per capita plastic waste (all) vs GDP per capita
ggplot(waste, aes(x = per_capita_plastic, y = gdp_per_capita)) +
  geom_point()

# relationship between per capita plastic waste (all) vs GDP per capita
ggplot(waste, aes(x = mismanaged_waste_percap, y = gdp_per_capita)) +
  geom_point()

## From this we cal see that there is a trend such that richer countries have less per capita waste (all waste and mismanaged).
```

Now I want to present the above information as a map

```{r}
# China is the leading contributer of mismanaged waste
china = world %>%
  filter(region == ""China"") %>%
  slice(1) %>%
  mutate(label = ""2nd in GDP\n1st in population"")

usa = world %>%
  filter(region == ""USA"") %>%
  slice(1) %>%
  mutate(label = ""1st in GDP\n3rd in population"")

india = world %>%
  filter(region == ""India"") %>%
  slice(1) %>%
  mutate(label = ""3rd in GDP\n2nd in population"")

# # world map
# world %>%
#   mutate(percap_waste_cat = cut(mismanaged_waste_percap,breaks = c(0, 0.01, 0.025, 0.05, 0.10, 0.30)),
#          gdppercap_levels = cut(gdp_per_capita, breaks = quantile(gdp_per_capita, na.rm = T))) %>% # create categorical variable that breaks down the mismanaged waste per cap into discrete intervals
#   ggplot() + 
#   geom_cartogram(
#     map = world,
#     aes(x = long, y = lat, map_id = region, fill = percap_waste_cat),
#     color = ""black"", size = 0.125#, alpha = 0.8
#   ) +
#   viridis::scale_fill_viridis(discrete = T)  +
#   labs(
#     x = NULL, y = NULL,
#     title = ""Mismanaged waste per capita (kg/day) in 2010"",
#     subtitle = """",
#     caption = ""Source: Our World in Data \n@VanderbeekAM "",
#     fill = """"
#     ) +
#   theme_void() +
#   theme(plot.title = element_text(hjust = 0.5, size = 15)) +
#   theme(plot.subtitle = element_text(hjust = 0.5)) +
#   theme(legend.position = ""bottom"") +
#   guides(fill = guide_legend(nrow = 2)) +
#   geom_text(data = china, 
#             aes(x = capital.lon, y = capital.lat, label = ""China""), 
#             nudge_x = -15, nudge_y = -5) + 
#   geom_label(data = china, 
#              aes(x = capital.lon, y = capital.lat, label = label), 
#              size = 2.5, nudge_x = 31, nudge_y = -19) +
#   annotate(""segment"", x = 130, xend = 115, y = 25, yend = 30, colour = ""black"", size = 1)
# 
# ggsave(""./2019/GlobalWaste_0521/mismanaged_waste.png"", width = 14, height = 8)



## create custom legend using geom_bar

# 
# waste_cat_count = countries %>%
#   group_by(percap_waste_cat_rev) %>%
#   summarise(freq = length(percap_waste_cat_rev))
# 
# waste_cat_count %>%
#   ggplot(aes(x = 1, y = freq, fill = percap_waste_cat_rev)) +
#   geom_bar(stat = ""identity"", width = 0.04, color = ""black"", size = 0.2) + 
#   viridis::scale_fill_viridis(direction = -1, discrete = T) +
#   scale_x_continuous(limits = c(0.5, 1.5)) +
#   #coord_flip() + 
#   #theme_void() + 
#   theme(legend.position = ""none"") +
#   geom_text(aes(label = rev(freq)), 
#             position = position_stack(vjust = 0.5)
#             #position = position_dodge(width = 0.1) 
#             #nudge_x = -0.05
# )
# 
# countries %>%
#   left_join(waste_cat_count, by = ""percap_waste_cat"") %>%
#   ggplot(aes(x = 1, y = percap_waste_cat_rev, fill = percap_waste_cat)) +
#   geom_bar(stat = ""identity"", width = 0.05) + 
#   viridis::scale_fill_viridis(discrete = T) +
#   scale_x_continuous(limits = c(0.5, 1.5)) +
#   coord_flip() + 
#   theme_void() + 
#   theme(legend.position = ""none"") +
#   geom_text(aes(label = unique(percap_waste_cat)), vjust=-1)
# 
# data.frame(breaks = c(rep(""0"", 4),
#                       rep(""0.01"", 5),
#                       rep(""0.025"", 6),
#                       rep(""0.05"", 10),
#                       rep(""0.10"", 20),
#                       rep(""0.30"", 60))) %>% # create categorical variable that breaks down the mismanaged waste per cap into discrete intervals
#   ggplot(aes(x = 1, y = breaks, fill = breaks)) +
#   geom_bar(stat = ""identity"", width = 0.05) + 
#   #theme_void() + 
#   viridis::scale_fill_viridis(discrete = T) +
#   scale_x_continuous(limits = c(0.5, 1.5))

```


```{r}
world %>%
  mutate(pct_global_mismanaged_cat = cut(percent_global_contbn, breaks = c(0, 0.0025, 0.005, 0.01, 0.02, 0.06, 0.14))) %>% 
  ggplot() + 
  geom_cartogram(
    map = world,
    aes(x = long, y = lat, map_id = region, fill = pct_global_mismanaged_cat),
    color = ""black"", size = 0.125#, alpha = 0.8
  ) +
  viridis::scale_fill_viridis(discrete = T)  +
  labs(
    x = NULL, y = NULL,
    title = ""In 2010, there was 63,709,265 tonnes of mismanaged plastic waste across the globe."",
    subtitle = ""The map below shows each country's level of contribution to this global total.\nChina stands out as contributing to 13.8% of all mismanaged plastic."",
    caption = ""Source: Our World in Data \n@VanderbeekAM "",
    fill = """"
    ) +
  theme_void() +
  theme(plot.title = element_text(size = 15, face = ""bold""),
        plot.subtitle = element_text(),
        legend.position = ""bottom"",
        plot.background = element_rect(fill = ""beige"")) +
  guides(fill = guide_legend(nrow = 1)) +
  geom_text(data = china, 
            aes(x = capital.lon, y = capital.lat, label = ""China (13.8%)""), 
            fontface = ""bold"", size = 3, nudge_x = -15, nudge_y = -5) + 
  geom_label(data = china, 
             aes(x = capital.lon, y = capital.lat, label = label), 
             size = 2.5, nudge_x = 20, nudge_y = -19) +
  geom_text(data = usa, 
            aes(x = capital.lon, y = capital.lat, label = ""USA (0.4%)""), 
            fontface = ""bold"", color = ""white"", size = 3, nudge_x = -22, nudge_y = 0) + 
  geom_label(data = usa, 
             aes(x = capital.lon, y = capital.lat, label = label), 
             size = 2.5, nudge_x = -50, nudge_y = -10) +
  geom_text(data = india, 
            aes(x = capital.lon, y = capital.lat, label = ""India (0.9%)""), 
            fontface = ""bold"", size = 3, nudge_x = 0, nudge_y = -10) + 
  geom_label(data = india, 
             aes(x = capital.lon, y = capital.lat, label = label), 
             size = 2.5, nudge_x = 0, nudge_y = -20)

ggsave(""./figures/GlobalWaste-pct_global_mismanaged_waste.png"", width = 14, height = 8)
```


```{r}
waste %>%
  select(per_capita_plastic,
         mismanaged_waste_percap,
         gdp_per_capita) %>%
  drop_na() %>% 
  cor() %>%
  corrplot::corrplot(method = ""ellipse"")

countries %>%
  mutate(gdp_cat = cut(gdp_per_capita, breaks = c(660.211, 3479.155, 9942.427, 22740.972, 125140.838))) %>%
  filter(!is.na(continent) & !is.na(gdp_cat)) %>%
  ggplot(aes(y = percent_mismanaged, x = continent, color = gdp_cat)) +
  geom_boxplot(fill = ""white"") +
  geom_point() +
  geom_jitter(width = 0.2, alpha = 0.8) +
  labs(
    x = """",
    y = ""Percent of country's plastic waste that is mismanaged"",
    title = ""Richer countries have more resources to put towards plastic waste management."",
    subtitle = ""We can see below how, globally, the higher a country's GDP per capita, the smaller portion of its plastic waste is mismanaged."",
    color = ""GDP per capita (percentiles)""
  ) +
  scale_color_colorblind(labels = c(""25th percentile"",
                                    ""50th percentile"",
                                    ""75th percentile"",
                                    ""100th percentile"")) +
  theme_bw() +
  theme(legend.position = ""right"",
        plot.title = element_text(size = 15, face = ""bold""))
  
ggsave(""./figures/GlobalWaste-country_pct_mismanaged_boxplot.png"", width = 10, height = 7)
```

","2019-21"
"503",1400,"https://github.com/alyssamv/tidytuesdays/blob/master/2019/WineRatings_0528/WineRatings.Rmd","alyssamv","tidytuesdays","2019/WineRatings_0528/WineRatings.Rmd","---
title: ""WineRatings""
author: ""Alyssa Vanderbeek""
date: ""5/28/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

library(tidyverse)
library(ggthemes)
library(treemapify)
library(kableExtra)
library(formattable)
library(condformat)
library(ggalluvial)
library(GGally)
```

```{r}
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"") %>%
  select(-1)

# number of wines by country
n_wines = wine_ratings %>%
  group_by(country) %>%
  summarise(n_wines = n()) %>%
  arrange(desc(n_wines)) %>%
  mutate(tier = NA)

n_wines$tier[1:3] = 1
n_wines$tier[4:12] = 2
n_wines$tier[13:44] = 3

```

Lots of character variables in this dataset. I want to get an idea for the unique values available.

```{r}
unique(wine_ratings$country) # 44 countries
unique(wine_ratings$province) # 426 provinces
sort(unique(wine_ratings$region_1)) # 1230 regions (1). 
sort(unique(wine_ratings$region_2)) # 17 regions (2). 

sort(unique(wine_ratings$variety)) # 707 varieties 

unique(wine_ratings$taster_name) # 19 different tasters
```

Off the bat I know that I want to classify each wine as red, white, rose, or sparkling, but I will need some externl dataset for that. There are too many (707) individual varieties for me to manually classify. Perhaps I could take only the most well-known varieties and classify them manually.

Now to look at the distributions of the numeric values (price and points):

```{r}
wine_ratings %>%
  select(price, points) %>%
  skimr::skim() # points are approx normal. price seems skewed; closer look

prices = wine_ratings %>%
  group_by(country) %>%
  mutate(med_price = median(price, na.rm = T)) %>%
  ungroup() %>%
  filter(!is.na(med_price))  %>%
  left_join(n_wines %>% select(country, tier), by = ""country"") %>%
  mutate(country = fct_reorder(country, med_price))

global_median_price = median(prices$med_price)

prices %>%
  filter(country != ""NA"") %>%
  ggplot(aes(y = log(price), x = country, fill = ""grey"")) +
  geom_boxplot() +
  geom_hline(yintercept = log(global_median_price)) +
  scale_fill_identity() +
  scale_x_discrete()  +
#  annotate(""text"", y = 6, x = 30, label = ""test"") +
  facet_grid(tier~., scales = ""free_y"", space = ""free_y"") +
  theme_bw() +
  labs(
    x = NULL,
    y = ""Bottle price (log-scale)"",
    title = ""The global median price of a bottle of wine is $28."",
    subtitle = ""The distribution of wine price by country is shown below in log-scale. Note how the\nmajority of each country's price distribution falls below the global median, even in log-scale.\nThis suggests a highly skewed pricing, which is reflected in that out of 130k wines, only a\nhandful cost more than a few hundred dollars. Countries that produce more wine\n(Tiers 1, 2) are most responsible for this skew."",
    caption = ""Data Source: WineEnthusiast \nTwitter: @VanderbeekAM ""
  ) +
  coord_flip() +
  theme(plot.title = element_text(size = 15, face = ""bold""),
        plot.subtitle = element_text(size = 9),
        axis.text.y = element_text(size = 10, face = ""bold""),
        panel.grid = element_blank())

ggsave(""./figures/WineRatings_boxplot_countryprice.png"", height = 10, width = 7)
```

Price is pretty skewed, so I will either use a log-scale or create a categorical variable with intervals when using price in any analysis/viz.

Now I want to check how many wines fall into different categories:
```{r}
sort(table(wine_ratings$country)) # this could be displayed as a tree plot


# viz as treemap
ggplot(n_wines, aes(area = n_wines, fill = n_wines, label = country,
                    subgroup = tier)) +
  treemapify::geom_treemap() +
  geom_treemap_text(colour = ""white"", 
                    place = ""centre"", 
                    grow = TRUE) +
  geom_treemap_subgroup_border(color = ""black"") +
  scale_fill_gradient2(midpoint = 25000) +
  labs(fill = ""Number of wines"",
       title = ""The US, France, and Italy produce the majority of wines being rated."",
       subtitle = ""Out of 44 countries, the US leads with 54,504 wines, followed by France (22,093) and Italy (19,540).\nChina, Egypt, and Slovakia each produced one wine."",
    caption = ""Data Source: WineEnthusiast \nTwitter: @VanderbeekAM ""
    ) +
  theme(plot.title = element_text(size = 15, face = ""bold""))

ggsave(""./figures/WineRatings_treemap_nwines.png"", width = 8, height = 6)
```


The distribution of counts for wine variety are very skewed, even in log-scale.

```{r}
sort(table(wine_ratings$variety), decreasing = F)# top 3 varieties: Pinot Noir, Chardonnay, Cabernet Sauvignon
```


Looking at the different wine tasters, not all tasters try wines from all available countries. Some specialize, such as Alexander Peartree, who tried 415 wines only from the US. Roger Voss tried the most wines, at 25,514. 

```{r}
table(wine_ratings$taster_name, wine_ratings$country) %>% View

sort(table(wine_ratings$taster_name))

wine_ratings %>%
  filter(!is.na(taster_name)) %>%
  group_by(taster_name) %>%
  summarise(n_wines = n(),
            avg_rating = mean(points)) %>%
  arrange(desc(n_wines))


wine_ratings %>%
  filter(!is.na(taster_name)) %>%
  ggplot(aes(y = points, x = taster_name)) +
  geom_violin() +
  coord_flip()
```

What are the distribution of ratings for different countries?
```{r}

  
wine_ratings %>%
  filter(country %in% n_wines$country[1:10]) %>% 
  left_join(n_wines, by = ""country"") %>%
  arrange(desc(n_wines)) %>%
  mutate(country = reorder(as.factor(country), n_wines)) %>% # order countries by number of wines 
  ggplot(aes(y = points, x = country, fill = country)) +
  geom_violin() +
  geom_hline(yintercept = median(wine_ratings$points), linetype = ""dashed"") +
  viridis::scale_fill_viridis(discrete = T, alpha = 0.9) +
  labs(
    y = ""Rating"",
    x = NULL,
    title = ""Distribution of wine ratings for the top 10 wine producers."",
    subtitle = ""Countries are sorted by number of wines produced; US with the most (54,504),\nGermany with the least (2,165). The dashed line designates the global median rating (88)."",
    caption = ""Data Source: WineEnthusiast \nTwitter: @VanderbeekAM ""
    ) +
  coord_flip() +
  theme_bw() +
  theme(legend.position = ""none"",
        axis.text.y = element_text(size = 10, face = ""bold""),
        axis.text.x = element_text(size = 12),
        plot.title = element_text(size = 15, face = ""bold""))

ggsave(""./figures/WineRatings_country_rating_dist.png"", height = 10, width = 7)
```

I'm going to group countries into tiers, based on the number of wines produced. Then I can look at ratings by tier.

```{r}


taster_ratings_tier = wine_ratings %>%
  left_join(n_wines, by = ""country"") %>%
  group_by(taster_name, tier) %>%
  summarise(n = n(),
            avg_rating = mean(points)) 

plot_table = taster_ratings_tier %>%
  select(-avg_rating) %>%
  spread(key = tier, value = n, fill = ""--"") %>%
  left_join(taster_ratings_tier %>%
              select(-n) %>%
              mutate(avg_rating = round(avg_rating, 2)) %>%
              spread(key = tier, value = avg_rating, fill = ""--""), 
            by = ""taster_name"") %>%
  left_join(wine_ratings %>%
              left_join(n_wines, by = ""country"") %>%
              group_by(taster_name) %>%
              summarise(n = n(),
                        avg_rating = round(mean(points), 2)),
            by = ""taster_name"") %>%
  mutate(`1.x` = ifelse(`1.y` == ""--"", `1.y`, paste0(`1.y`, ""\n("", `1.x`, "")"")),
         `2.x` = ifelse(`2.y` == ""--"", `2.y`, paste0(`2.y`, ""\n("", `2.x`, "")"")),
         `3.x` = ifelse(`3.y` == ""--"", `3.y`, paste0(`3.y`, ""\n("", `3.x`, "")"")),
         n = ifelse(avg_rating == ""--"", avg_rating, paste0(avg_rating, ""\n("", n, "")""))) %>%
  `colnames<-`(c(""Taster"", ""Tier 1"", ""Tier 2"", ""Tier 3"", ""one"", ""two"", ""three"" , ""Overall average rating"", ""overall_r"")) 


# avg_row = data.frame(Taster = ""All tasters"", 
#             one = sum(as.numeric(plot_table$one), na.rm = T), 
#             two = sum(as.numeric(plot_table$two), na.rm = T), 
#             three = sum(as.numeric(plot_table$three), na.rm = T), 
#             'Tier_1' = mean(as.numeric(plot_table$`Tier_1`), na.rm = T), 
#             `Tier_2` = mean(as.numeric(plot_table$`Tier_2`), na.rm = T), 
#             `Tier_3` = mean(as.numeric(plot_table$`Tier_3`), na.rm = T), 
#             overall_n = sum(as.numeric(plot_table$overall_n)), 
#             Overall = mean(as.numeric(plot_table$Overall), na.rm = T))
# 
# do.call(cbind, c(as.data.frame(plot_table), avg_row)) %>% View

condformat(plot_table) %>%
  rule_fill_gradient(columns = `Tier 1`, 
                     expression = as.numeric(one), 
                     #limits = c(1, 25537), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  rule_fill_gradient(columns = `Tier 2`, 
                     expression = as.numeric(two), 
                     #limits = c(1, 25537), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  rule_fill_gradient(columns = `Tier 3`, 
                     expression = as.numeric(three), 
                     #limits = c(1, 25537), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  rule_fill_gradient(columns = `Overall average rating`, 
                     expression = as.numeric(overall_r), 
                     #limits = c(1, 26244), 
                     low = ""lightgoldenrod1"", 
                     high = ""indianred"") %>%
  show_columns(columns = c(8, 1, 2:4)) %>%
  theme_htmlTable(caption = ""Average ratings by tasters. Tiers are defined by the number of wines contributed (by country). The number of wines tasted by the taster is given in parentheses. A total of 129,971 wines were rated in the dataset: 96,137 in Tier 1 (producing more than 10,000 wines); 31,267 in Tier 2 (producing between 1,000 and 10,000 wines); 2,567 in Tier 3 (producing less than 1,000 wines). Tier 1 wines seem to have higher average ratings than lower tiers, though these differences are slight."")

```

Last thing I will do today is make a parallel plot.

```{r}
ggplot(wine_ratings, aes(x = ))
```

","2019-22"
"504",1411,"https://github.com/andrewgeisler/tidytuesday-projects/blob/master/2019-05-21/global_plastic_waste_explore.R","andrewgeisler","tidytuesday-projects","2019-05-21/global_plastic_waste_explore.R","library(tidyverse)
library(lubridate)
library(ggplot2)
library(gganimate)
library(countrycode)
library(png)
library(ggridges)


### READ DATA SETS ---
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

####
# For Year 2010 Extract
# - Total population
# - Tonnes of Mismanaged Waste
# - Per Capita Mismanged Waste
# - Per Capita GPD
# - Per Capita Waste

df_total_pop_2010 <- coast_vs_waste %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Total population (Gapminder)`
  )

df_plaste_waste_tonnes_2010 <- coast_vs_waste %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Mismanaged plastic waste (tonnes)`
  )

df_mismanged_waste_2010 <- mismanaged_vs_gdp %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Per capita mismanaged plastic waste (kilograms per person per day)`
  )

df_gpd_2010 <- mismanaged_vs_gdp %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `GDP per capita, PPP (constant 2011 international $) (Rate)`
  )

df_waste_per_cap_2010 <- waste_vs_gdp %>%
  filter(Year == 2010) %>%
  select(
    Entity,
    Code,
    Year,
    `Per capita plastic waste (kilograms per person per day)`
  )

### CREATE DF FOR JOINED 2010 DATA
df_2010 <- reduce(
  list(df_gpd_2010, df_mismanged_waste_2010, df_plaste_waste_tonnes_2010, df_total_pop_2010, df_waste_per_cap_2010),
  left_join
)

### LOOK UP COUNTRY CODE
df_2010 <- df_2010 %>%
  mutate(
    Continent = countrycode(Code, origin = ""iso3c"", destination = ""continent""),
    Continent = factor(Continent),
    Year = factor(Year)
  ) %>%
  filter(!is.na(Continent))

### FUNCTION TO REPLACE NA'S WITH MEIAN VALUES
f_replace_na_with_median <- function(x) {
  median <- median(x, na.rm = T)
  case_when(is.na(x) ~ median, TRUE ~ x)
}

### INPUT MISING VALUES STRATIFIED BY CONTINENT

df_2010 <- df_2010 %>%
  group_by(Continent) %>%
  mutate_if(is.numeric, f_replace_na_with_median)

## CODE TTO HAS AN EXTREMELY UNUSUAL PER CAPITA WASTE.
## REPLACING WITH CONTINENT MEDIA
df_2010 <- df_2010 %>%
  group_by(Continent) %>%
  mutate(`Per capita plastic waste (kilograms per person per day)` = case_when(
    Code == ""TTO"" ~ median(`Per capita plastic waste (kilograms per person per day)`),
    TRUE ~ `Per capita plastic waste (kilograms per person per day)`
  ))

## CALCULATE PERCENT OF WASTE THAT IS MISMANAGED
df_2010 <- df_2010 %>%
  mutate(
    `Per Capita Mismanged Waste Percent` =
      `Per capita mismanaged plastic waste (kilograms per person per day)` / `Per capita plastic waste (kilograms per person per day)`
  )

### CUT GDP INTO QUANTILES
df_2010 <- df_2010 %>%
  ungroup() %>%
  mutate(
    `GDP Quantile` = cut(`GDP per capita, PPP (constant 2011 international $) (Rate)`,
      breaks = quantile(`GDP per capita, PPP (constant 2011 international $) (Rate)`, probs = seq(0, 1, 0.2)),
      labels = c(
        ""0-20"",
        ""20-40"",
        ""40-60"",
        ""60-80"",
        ""80-100""
      ),
      right = FALSE,
      include.lowest = TRUE
    ),
    `GDP Quantile` = `GDP Quantile`
  )


p_percent_waste <- df_2010 %>%
  ggplot() +
  theme_minimal() +
  geom_density_ridges(
    aes(
      y = Continent, x = `Per Capita Mismanged Waste Percent`,
      fill = Continent, color = Continent
    ),
    alpha = 0.25, show.legend = F, jittered_points = TRUE
  ) +
  scale_y_discrete(limits = rev(levels(df_2010$Continent))) +
  scale_x_continuous(
    labels = scales::percent,
    limits = c(0, 1)
  ) +
  theme(axis.title = element_text(size = 8)) +
  labs(x = 'Percent of Total Plastic Waste', y = '')

p_animated <- p_percent_waste +
  transition_states(`GDP Quantile`,
    transition_length = 2,
    state_length = 0,
    wrap = F
  ) +
  ggtitle(""Mismanaged Plastic Waste - 2010\nPer Capita GDP Percentile: {closest_state}"")

## SAVE ANIMATION ---- 
animate(p_animated, height = 450, width =800)
anim_save(filename = '2019-05-21/percent_plastic_waste_animated.gif')




","2019-21"
"505",1418,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-04-23_Anime Dataset.R","### Load libraries 
library(tidyverse)
library(ggplot2)

### Read tidy *.csv
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

### Select variables
tidy_anime %>%
  select(name, type, source, studio, episodes, rating,
         scored_by, rank, popularity, members, favorites) %>%
  
  ### Extract unique elements  
  unique() %>%
  
  ### Arrange in descending order and select the first 10 elements
  arrange(desc(episodes)) %>% 
  head(10) %>%
  
    ### Plot
    ggplot(aes(x=reorder(name, episodes), y = episodes, fill = name)) +
    geom_col() +
    coord_flip() +
    labs(title = ""How many episodes?"",
         subtitle = ""Top 10"", 
         x = """", 
         y = ""Number of episodes"", 
         caption = ""Data source: MyAnimeList.net \n @_apuglisi_ #TidyTuesday Week 17"") +
    theme(legend.position = ""none"",
          plot.background = element_rect(fill = ""#000000""),
          plot.title = element_text(colour = ""#ffffff"", size = 16, hjust = 0.5), 
          plot.subtitle = element_text(colour = ""#ffffff"", size = 13, hjust = 0.5),
          plot.caption = element_text(colour = ""#ffffff""),
          panel.background = element_rect(fill = ""#edeaf2""),
          axis.title.x = element_text(colour = ""#ffffff""),
          axis.text = element_text(colour = ""#ffffff"", size = 14))

ggsave(""2019-04-23_Anime Dataset.png"")
","2019-17"
"506",1419,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-04-30_Chicago Bird Collisions.R","### Load libraries
library(tidyverse)
library(ggplot2)
library(RColorBrewer)

### Get the data
bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

### MP as locality + left join with mp_light
bird_collisions_complete <- bird_collisions %>%
  filter(locality == ""MP"") %>%
  left_join(mp_light, by = ""date"") %>%
  filter(!is.na(light_score))
  
### Plot       
bird_collisions_complete %>%
  ggplot(aes(flight_call, light_score, fill = flight_call)) +
  geom_violin() +
  annotate(""rect"", xmin = 1.8, xmax = 2.2, ymin = 7, ymax = 10.5, alpha = .2) +
  annotate(""text"", x = 2.3, y = 6, label = ""Why?"") +
  annotate(""segment"", x = 2.3, xend = 2.2, y = 6.4, yend = 7) +
  scale_fill_brewer(palette = ""Blues"") +
  labs(
    title = ""Flight call vs Light score @ McCormick Place, 2000-2016"",
    x = ""Flight call"",
    y = ""Light score"",
    caption = ""Source: https://doi.org/10.1098/rspb.2019.0364 \n @_apuglisi_ #TidyTuesday Week 18"") +
  theme(
    legend.position = ""none"",
    plot.title = element_text(size = 16),
    plot.caption = element_text(size = 10),
    plot.background = element_rect(fill = ""#f7d78c""),
    panel.background = element_rect(fill = ""#edeff2""))

ggsave(""2019-04-30_Chicago Bird Collisions.png"")
","2019-18"
"507",1420,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-07_Global Student to Teacher Ratios.R","### Load libraries
library(tidyverse)
library(ggplot2)
library(extrafont)
library(ggthemes)
loadfonts(device = ""win"")

### Get the data
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

### Subset student_ratio
ratio_all <- student_ratio %>%
  rename(ratio = student_ratio) %>%
  select(-c(edulit_ind, country_code, flag_codes, flags)) %>%
  na.omit()

### Plot
ratio_all %>%
  filter(country %in% c(""Italy"", ""Greece"", ""Spain"", ""Portugal"")) %>%
  
  ggplot(aes(x = year, y = ratio, color = indicator)) +
  geom_line(size = 1) +
  geom_point(size = 3.5) +
  facet_wrap(~ country, scales = ""free"") +
  labs(
    title = ""Student-teacher ratios in Greece, Italy, Portugal and Spain: 2012-2016"",
    x = ""Year"",
    y = ""Student-teacher ratio"",
    caption = ""Data source: UNESCO Institute of Statistics\n @_apuglisi #TidyTuesday Week 19"") +
  theme_solarized_2() +
  theme(
    axis.title = element_text(size = 15, family = ""Courier New"", face = ""bold""),
    axis.text = element_text(size = 13, family = ""Courier New""),
    legend.position = ""bottom"",
    legend.title = element_blank(),
    legend.spacing.x = unit(0.5, 'cm'),
    legend.text = element_text(size = 13, family = ""Courier New""),
    panel.spacing.x = unit(0.5, 'cm'),
    panel.spacing.y = unit(1, 'cm'),
    plot.margin = unit(c(0.5,1,0.5,1), 'cm'),
    plot.title = element_text(size = 17, family = ""Courier New"", face = ""bold""),
    strip.text.x = element_text(size = 15, family = ""Courier New"", face = ""bold"")
  )
","2019-19"
"508",1421,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-14_Nobel winners.R","### Load packages
library(tidyverse)
library(tidytext)
library(patchwork)

### Get the data
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

### Select distinct values of the column Motivation
motivations <- nobel_winners %>%
  filter(!is.na(motivation)) %>%
  select(motivation) %>%
  distinct()

### Tokenize motivations and remove stop words
motivations_tokenized <- motivations %>%
  unnest_tokens(word, motivation) %>%
  anti_join(stop_words)

### Plot 1 - Most used words
motivations_most_used_words <- motivations_tokenized %>%
  count(word) %>%
  arrange(desc(n)) %>%
  head(10) %>%
  
    ggplot(aes(x = reorder(word, n), y = n, fill = word, label = n)) +
    geom_col(show.legend = FALSE) +
    geom_text(aes(label = n), hjust = 1.2, color = ""white"") +
    coord_flip() +
    labs(
      title = ""10 most-used words"",
      x = """",
      y = ""Word frequency""
    ) +
    theme(
      panel.background = element_rect(color = ""#e6cb00"")
  )

### Plot 2 - Most used POS
motivations_pos <- motivations_tokenized %>%
  inner_join(parts_of_speech) %>%
  na.omit() %>%
  count(pos) %>%
  arrange(desc(n)) %>%
  head(3) %>%
  
    ggplot(aes(x = reorder(pos, n), y = n, fill = pos)) +
    geom_col(show.legend = FALSE) +
    geom_text(aes(label = n), vjust = 1.2, color = ""white"") +
    labs(
      title = ""3 most-used parts of speech"",
      x = ""Parts of speech"",
      y = """"
    ) +
  theme(
    panel.background = element_rect(color = ""#322bff"")
  )

### Plot 3 - Sentiment
motivations_sentiment <- motivations_tokenized %>%
  inner_join(sentiments) %>%
  filter(lexicon == ""nrc"") %>%
  count(sentiment) %>%
  arrange(desc(n)) %>%
  head(5) %>%
  
    ggplot(aes(x = reorder(sentiment, n), y = n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    geom_text(aes(label = n), vjust = 1.2, color = ""white"") +
    labs(
      title = ""Top 5 sentiments"",
      x = ""Sentiment"",
      y = """"
    ) +
    theme(
      panel.background = element_rect(color = ""#ff2f2b"")
    )

### Final plot
motivations_most_used_words + motivations_pos / motivations_sentiment +
  plot_annotation(
    title = ""Nobel Prize's motivations: a text analysis"",
    caption = ""Data source: The Nobel Foundation via Kaggle \n @_apuglisi_ #TidyTuesday Week 20""
  )
","2019-20"
"509",1422,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-21_Global Plastic Waste.R","## Load packages
library(tidyverse)
library(extrafont)

## Get the data
mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

## Join dataframes, clean up column names, reorder columns and add a ratio
global_plastic_waste <- mismanaged_vs_gdp %>%
  left_join(waste_vs_gdp) %>%
  select(-c(Code, `GDP per capita, PPP (constant 2011 international $) (Rate)`)) %>%
  set_names(
    ~ str_to_lower(.) %>%
    str_remove_all(""(\\(.+$|,.+$)"") %>%
    str_remove_all("" $"") %>%
    str_replace_all("" "", ""_"")
  ) %>%
  na.omit() %>%
  select(entity, year, per_capita_mismanaged_plastic_waste, 
         per_capita_plastic_waste, gdp_per_capita, total_population) %>%
  mutate(mismanaged_plastic_waste_ratio = round(per_capita_mismanaged_plastic_waste/per_capita_plastic_waste, digits = 3), 
         gdp_per_capita = round(gdp_per_capita, digits = 2))

## Plot
ggplot(global_plastic_waste, aes(x = gdp_per_capita, y = mismanaged_plastic_waste_ratio, label = entity)) +
  geom_jitter(colour = ""#ce1e11"") +
  scale_x_continuous(breaks = seq(0, 120000, 20000)) +
  labs(
    title = ""(Mis)managing plastic waste around the world (2010)"",
    caption = ""Data source: https://ourworldindata.org/plastic-pollution \n @_apuglisi_ #TidyTuesday Week 21"",
    x = ""GDP per capita ($)"",
    y = ""Mismanaged plastic waste ratio""
  ) +
  theme(
    plot.margin = unit(c(0.5,0.5,0.3,0.5), 'cm'),
    plot.background = element_rect(fill = ""#ce1e11""),
    panel.background = element_rect(fill = ""#11ce44""),
    plot.title = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 17),
    plot.caption = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 10),
    axis.title.x =  element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 13, vjust = -0.5),
    axis.title.y = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff"", size = 13, vjust = 2),
    axis.text = element_text(family = ""Berlin Sans FB"", colour = ""#ffffff""),
    axis.ticks = element_line(colour = ""#ffffff"")
  )
","2019-21"
"510",1423,"https://github.com/alessandropuglisi/tidy-tuesday","alessandropuglisi","tidy-tuesday","2019-05-28_Wine ratings.R","## Load packages
library(tidyverse)
library(extrafont)
library(ggrepel)

## Get data
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

## Drop X1 column, drop NAs, group by tasters and summarize
wine_tasters <- wine_ratings %>%
  select(-X1) %>%
  drop_na(taster_name, description, points) %>%
  group_by(taster_name) %>%
  summarize(points_mean = mean(points), mean_description_length = mean(stringi::stri_length(description)))
  
## Plot
ggplot(wine_tasters, aes(x = points_mean, y = mean_description_length, color = taster_name, label = taster_name)) +
  geom_jitter() +
  geom_label_repel(family = ""Gabriola"", size = 5) +
  labs(
    title = ""Any correlation between points and description length?"",
    x = ""Points (mean)"",
    y = ""Description length (mean)""
  ) +
  theme(
    plot.background = element_rect(fill = ""#722F37""),
    plot.title = element_text(family = ""Gabriola"", color = ""#ffffff"", size = 18),
    axis.title = element_text(family = ""Gabriola"", color = ""#ffffff"", size = 15),
    axis.text = element_text(family = ""Gabriola"", color = ""#ffffff"", size = 15),
    axis.ticks = element_line(color = ""#ffffff""),
    legend.position = ""none""
  )
","2019-22"
"511",1425,"https://github.com/ChrisWoodsSays/TidyTuesday/tree/master/2019/2019-05-20","ChrisWoodsSays","TidyTuesday","2019/2019-05-20/TidyTuesday19052019.R","library(tidyverse)
library(gganimate)
library(countrycode)
setwd(""~/Documents/GitHub/TidyTuesday"")

# Get Nobel Prize Winners
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

# Determine to 10 Countries
topCountries <- nobel_winners %>%
    group_by(birth_country) %>%
    summarise(n = n()) %>%
    na.omit() %>%
    top_n(10)

# Tidy Winners
# - Take just country in brackets where there is such
# - Change UK country names to UK
# - Get ISO country code
winnersTidy <-
    nobel_winners %>%
    mutate(birth_country = gsub("".*\\((.*)\\).*"", ""\\1"", birth_country),
           birth_country = gsub(""Scotland|Northern Ireland"", ""United Kingdom"", birth_country),
           birthCountryCode = countrycode(birth_country, 'country.name', 'iso3c')
    ) %>%
    select(prize_year, category,birth_date,birth_country,birthCountryCode) %>%
    filter(complete.cases(.))

# Count Prizes by Country, Category and Year
counts <- winnersTidy %>%
    filter(birth_country %in% topCountries$birth_country) %>%
    group_by(birthCountryCode, category, prize_year) %>%
    summarise(prizes = n()) %>%
    mutate(cumPrizes=cumsum(prizes),
           birthCountryName = countrycode(birthCountryCode, 'iso3c', 'country.name'))

# Plot Animated Chart
g = ggplot(counts, aes(x = birthCountryName, y = category, 
                       colour = birthCountryName)) + 
    geom_point(aes(size = cumPrizes), alpha=0.6) + 
    scale_size_continuous(range = c(2, 40)) +
    transition_reveal(prize_year) + 
    labs(title = 'Top 10 Nobel Prize Winning Countries', 
         subtitle = ""Year: {frame_along}"",
         y = 'Prize Category') + 
    theme_minimal() + 
    theme(
        plot.title = element_text(size=22),
        axis.title = element_blank()) +
    scale_color_brewer(palette = ""RdYlBu"") +
    theme(legend.position = ""none"") +
    theme(plot.margin = margin(5.5, 5.5, 5.5, 5.5))
animate(g, fps = 10, width = 750, height = 450)
anim_save(""nobelprizes.gif"")","2019-20"
"512",1426,"https://github.com/samprohaska/tidy-tuesday/blob/master/2019-04-16/tidy-tuesday_2019-04-16.R","samprohaska","tidy-tuesday","2019-04-16/tidy-tuesday_2019-04-16.R","# Import data

library(tidyverse)
women_research <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")

library(stringr)
women_research$field <-
  str_replace_all(women_research$field, 'Women inventores', 'Patent applications') %>%
  str_wrap(20)

# Plot 1: Grouped by field

library(plotly)

women_research %>%
  plot_ly(x = ~percent_women * 100, y = ~field, color = ~country, type = 'bar') %>%
  layout(title = 'Share of published women researchers, by field (2011-2015)',
         barmode = 'group',
         xaxis = list(title = ""Women's representation in academic publishing (2011-2015)"",
                      ticksuffix = ""%"",
                      range = c(0,100)),
         yaxis = list(title = ''),
         font = list(family = 'Raleway',
                     color = '#34495e'),
         annotations = list(
           text = 'Data: Elsevier, via The Economist',
           x = 80,
           y = -0.4,
           showarrow = FALSE
         ))

# Plot 2: Grouped by country

women_research %>%
  plot_ly(x = ~percent_women * 100, y = ~country, color = ~field, type = 'bar') %>%
  layout(title = ""Women's representation in academic publishing (2011-2015)"",
         barmode = 'group',
         xaxis = list(title = 'Women, as % of total published authors',
                      ticksuffix = ""%"",
                      range = c(0,100)),
         yaxis = list(title = ''),
         font = list(family = 'Raleway',
                     color = '#34495e'),
         annotations = list(
           text = 'Data: Elsevier, via The Economist',
           x = 80,
           y = -0.4,
           showarrow = FALSE
         ))
","2019-16"
"513",1427,"https://github.com/samprohaska/tidy-tuesday/blob/master/2019-05-21/tidy-tuesday_2019-05-21.Rmd","samprohaska","tidy-tuesday","2019-05-21/tidy-tuesday_2019-05-21.Rmd","---
title: ""Tidy Tuesday: Plastic Waste""
author: ""Samuel Prohaska""
date: ""5/21/2019""
output: html_document
---

First, import the data and clean up the column names.

```{r}
library(tidyverse)
library(readr)
library(janitor)
library(ggthemes)
library(wesanderson)

coast_vs_waste <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")

mismanaged_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

waste_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

dat <- list(coast_vs_waste, mismanaged_vs_gdp, waste_vs_gdp)
dat <- lapply(dat, clean_names)

mismanaged <- dat[[2]]
mismanaged <- rename(mismanaged, plastic_waste_misman = ""per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day"")

waste <- dat[[3]]
waste <- rename(waste, plastic_waste = ""per_capita_plastic_waste_kilograms_per_person_per_day"")
```

Now that the data's easier to work with, join the 'mismanaged' and 'waste' data. This is necessary in order to find the proportion of plastic mismanaged.

```{r}
df <- mismanaged %>%
  select(code, year, plastic_waste_misman) %>%
  left_join(waste, by = c(""code"", ""year""))

df <- rename(df, gdppc = ""gdp_per_capita_ppp_constant_2011_international_constant_2011_international"")
```

From there, set up the theme (done in advance as it's rather lengthy), slightly filter, data and create the plot.

```{r}
my_theme <- theme_classic() +
  theme(
    plot.background = element_rect(fill = ""#fbf8f4""),
    text = element_text(family = ""Raleway"", color = ""#34495e""),
    axis.title.x = element_text(color = ""#34495e"", face = ""bold""),
    axis.ticks.y = element_line(color = ""#34495e"", size = 0.2),
    axis.line.y = element_line(color = ""#34495e"", size = 0.5),
    axis.text = element_text(color = ""#34495e""),
    axis.ticks.x = element_line(color = ""#34495e"", size = 0.5),
    axis.line.x = element_line(color = ""#34495e"", size = 0.5),
    axis.title.y = element_text(color = ""#34495e"", face = ""bold""),
    plot.title = element_text(hjust = 0, color = ""#34495e"", face = ""bold""),
    plot.subtitle = element_text(hjust = 0, color = ""#34495e""),
    plot.caption = element_text(color = ""#34495e"", face = ""italic""),
    legend.title = element_text(colour = ""#34495e"", size = 9, face = ""bold""),
    legend.background = element_rect(fill = NA)
  )

# ggplot takes care of most of this filtering anyway
# (non-2010 values should be NA), but I wanted to be sure.
# `plastic_waste <1` was added to remove Trinidad and Tobago's
# whopping 3.6 tonnes per capita, as it threw off the scale.
df_plot <- df %>%
  filter(year == 2010, is.na(plastic_waste_misman) == FALSE, plastic_waste < 1)

df_plot %>%
  ggplot(aes(
    x = gdppc,
    y = (plastic_waste_misman / plastic_waste) * 100,
    color = plastic_waste
  )) +
  geom_point(size = 1, alpha = 0.9) +
  scale_color_gradient(low = wes_palette(""Zissou1"")[1], high = wes_palette(""Zissou1"")[5]) +
  stat_smooth(method = ""auto"",
              alpha = 0.2,
              color = ""#34495e"",
              size = 0.8,
              weight = 0.8,
              ullrange = TRUE,
              se = FALSE) +
  scale_x_log10() +
  ylim(0, 100) +
  my_theme +
  labs(
    title = ""Plastic Waste (Mis)management, by Country"",
    caption = ""Source: Our World in Data"",
    x = ""GDP per capita, logarithmic (2011 US $)"",
    y = ""Mismanaged waste, as % of total"",
    color = ""Plastic waste
(tonnes/capita)""
  )
```
","2019-21"
"514",1428,"https://github.com/samprohaska/tidy-tuesday/blob/master/2019-04-23/tidy-tuesday_2019-04-23.Rmd","samprohaska","tidy-tuesday","2019-04-23/tidy-tuesday_2019-04-23.Rmd","---
title: ""Tidy Tuesday 2019-04-23""
output: html_notebook
---

Data import and setup:

```{r}
library(tidyverse)
library(ggthemes)
library(lubridate)
library(gganimate)
library(gifski)
library(extrafont)
library(lemon)

tidy_anime <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

df_anime <- tidy_anime %>% distinct(animeID, .keep_all = TRUE)

df_anime <- df_anime %>% 
    filter(type != 'Unknown') %>%
    select(name, type, score, scored_by, start_date) %>% 
    mutate(year = year(start_date)) %>% 
    arrange(-year) %>% 
    na.omit()
```

Plotting with gganimate:

```{r}
gg <- df_anime %>% 
    ggplot(aes(x = score, y = scored_by, color = type, group = type)) +
    geom_point(size = 0.4, alpha = 0.5, aes(group = seq_along(start_date))) +
    theme(
        plot.background = element_rect(fill = '#fbf8f4'),
        text = element_text(family = 'Raleway', color = '#34495e'),
        axis.title.x = element_text(color = '#34495e', size = 18, face = 'bold'),
        axis.ticks.y = element_line(color = '#34495e', size = 0.2),
        axis.line.y = element_line(color = '#34495e', size = 0.5),
        axis.text = element_text(color = '#34495e', size = 16),
        axis.ticks.x = element_line(color = '#34495e', size = 0.5),
        axis.line.x = element_line(color = '#34495e', size = 0.5),
        legend.position = ""none"",
        panel.grid.major.y = element_line(color = '#34495e', size = 0.2),
        axis.title.y = element_text(color = '#34495e', size = 18, face = 'bold'),
        plot.title = element_text(hjust = 0, color = '#34495e', face = 'bold', size = 32),
        plot.subtitle = element_text(hjust = 0, color = '#34495e', size = 26),
        plot.caption = element_text(color = '#34495e', size = 16, face = 'italic')
    ) +
    scale_y_log10() +
    scale_color_manual(values = economist_pal()(7)) +
    facet_rep_wrap(~ type) +
    labs(title = 'Quantity & Quality', subtitle = 'MyAnimeList Ranking Frequency vs. Avg Score, by medium') +
    theme(
        strip.text.x = element_text(color = ""#34495e"", size = 22, face = 'bold'),
        strip.background = element_rect(fill = NA, colour = '#34495e')) +
    transition_reveal(start_date) +
    labs(caption = 'Released by: {frame_along}', x = 'Average Score',y = 'Number of Rankers (log)' ) +
    enter_fade()

animate(gg, height = 720, width = 1280, nframes = 110, end_pause = 5)
anim_save('mal_tidy-tuesday.gif')
```
","2019-17"
"515",1432,"https://github.com/leepingtay/tidytuesday_projects/tree/master/2019/2019-05-14","leepingtay","tidytuesday_projects","2019/2019-05-14/R_Nobel_LeePing_Tay.R","################################################################################################
# R TidyTuesday Data Exploratory Analysis
# Last Revision: 05/18/2019
#
# Author:
# Lee Ping Tay
#
# Description:
# Nobel Laureate Publications
#
# Introduction:
# The datasets can be obtained from github
# (https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-05-14)
# 
# The dataset contains information such as Nobel prize winners' name, country, prize 
# name, and category between 1901 and 2016.
#
#
# This script is used to explore Nobel prize winner dataset which comes from Kaggle
# and create data visualization.
#
# Contents: 
# Libraries and Environment
# Data Import and Preprocessing
# Data Wrangling / Data Visualization
#
################################################################################################
# Libraries and Environment
################################################################################################

#setwd(""/Users/leepingtay/Documents/Projects/Project_R"")

library(tidyverse)
library(circlize)


################################################################################################
# Data Import and Preprocessing
################################################################################################

# read csv files
nobel_winners <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

################################################################################################
#  Data Wrangling / Data Visualization
################################################################################################

dim(nobel_winners)   # 969  18

# Data cleaning on country
nobel_country <- nobel_winners %>%
  rename(country = death_country) %>% 
  mutate(country = ifelse(is.na(country), birth_country, country)) %>% 
  mutate(country = recode(country, 
                          `Canada` = 'CA',
                          `West Germany (Germany)` = 'Germany',
                          `Netherlands` = 'NL',
                          `Switzerland`= ""CHE"",
                          `United States of America` = 'USA', 
                          `United Kingdom`= 'UK'))

# top 10 nobel prize winners' countries
top10_nobel_country <- nobel_country %>%
  select(country, category) %>%
  filter(!is.na(country)) %>% 
  group_by(country, category) %>% 
  tally() %>% 
  mutate(sum_count = sum(n)) %>% 
  arrange(-sum_count) %>% 
  distinct(country, sum_count) %>% 
  head(10) %>% 
  select(country)

# data for the plot
data_nobel <- top10_nobel_country %>% 
  left_join(nobel_country, by=""country"") %>% 
  select(country, category) %>% 
  group_by(country, category)


# Percentage of top 10 Nobel winners by countries
nrow(data_nobel)/nrow(nobel_country)*100   # 74.4%


## circular network plot
grid.col = c(Japan = ""#1B9E77"", UK = ""#00008B"", Germany = ""#FFCE00"",
             USA = ""#E7298A"", France = ""#66A61E"", Sweden = ""#9370DB"",
             CHE = ""#FF3030"", Italy = ""#98F5FF"", CA= ""#104E8B"", NL = ""#EE7600"")

chordDiagram(data_nobel, 
             directional = 1, 
             diffHeight  = -0.04,
             grid.col=grid.col)

title(main = ""Top 10 Countries with the most Nobel Prize Winners"")



","2019-20"
"516",1433,"https://github.com/leepingtay/tidytuesday_projects/tree/master/2019/2019-04-23","leepingtay","tidytuesday_projects","2019/2019-04-23/R_Anime_WordCloud_LeePing_Tay.R","################################################################################################
# R TidyTuesday Data Exploratory Analysis
# Last Revision: 04/23/2019
#
# Author:
# Lee Ping Tay - joylp.tay@gmail.com
#
# Description:
#
# Introduction:
# The datasets can be obtained from github
# (https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-04-23)
# 
# The dataset contains information about animeID, name, genre, episodes, score, rank,
# popularity, favorites, and synopsis.
#
# This script is used to explore Anime dataset which comes from Kaggle and create data 
# visualization.
#
# Contents: 
# Libraries and Environment
# Data Import and Preprocessing
# Data Wrangling / Data Visualization
#
################################################################################################
# Libraries and Environment
################################################################################################

library(tidyverse)
library(tidytext)
library(ggwordcloud)

################################################################################################
# Data Import and Preprocessing
################################################################################################

# read csv files
tidy_anime <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

################################################################################################
#  Data Wrangling / Data Visualization
################################################################################################

dim(tidy_anime)  # 77911    28

# Extract synopsis
df_synopsis <- tidy_anime %>%
               select(synopsis)
  
dim(df_synopsis)  # 77911     1

# Extract words from df_synopsis
common_words <- df_synopsis %>%
                unnest_tokens(word, synopsis)  
  
# Remove common stopwords
data(stop_words)

common_words <- common_words %>%
                anti_join(stop_words) 


# Filter some extra stopwords
common_words <- common_words %>%
                filter(!(word %in% c(""source"", ""mal"", ""written"", ""rewrite"", ""named"", ""series"",
                                     ""begins"", ""called"")))

nrow(common_words)   # 3326867


# Generate top common words 
top_common_words <- common_words %>%
  count(word, sort = TRUE) %>%
  filter(n > 5000) %>%
  mutate(word = reorder(word, n))

dim(top_common_words)  # 32  2

dev.off()

# Word Cloud on top common words
p1 <- ggplot(top_common_words,
             aes(label = word,
                 size = n,
                 color = factor(sample.int(10, nrow(top_common_words), replace = TRUE)),
                 angle = 0)) +
             geom_text_wordcloud_area() +
             scale_size_area(max_size = 24) +
             theme_minimal() +
             labs(caption = ""\nSource: Kaggle | Graphic: Lee Ping Tay / @runjollyrun"")
p1

ggsave(filename = ""wordcloud_synopsis.png"", p1, width = 7, height = 5, dpi = 300, 
       units = ""in"", device='png')

dev.off()
","2019-17"
"517",1434,"https://github.com/leepingtay/tidytuesday_projects/tree/master/2019/2019-04-16","leepingtay","tidytuesday_projects","2019/2019-04-16/R_Economist_LeePing_Tay.R","################################################################################################
# R TidyTuesday Data Exploratory Analysis
# Last Revision: 04/16/2019
#
# Author:
# Lee Ping Tay - joylp.tay@gmail.com
#
# Description:
#
# Introduction:
# The datasets can be obtained from github
# (https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-04-16)
# 
# The dataset contains information about women in research with papers published between
# 2011 to 2015. Data include country name, field of study, and percentage of total 
# by field of study.
#
# This script is used to explore data on women in research and create data 
# visualization.
#
# Contents: 
# Libraries and Environment
# Data Import and Preprocessing
# Data Wrangling / Data Visualization
#
################################################################################################
# Libraries and Environment
################################################################################################

#setwd(""Documents/Projects/Project_R"")

library(tidyverse)
library(viridis)

################################################################################################
# Data Import and Preprocessing
################################################################################################

# read csv files
women_research <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")

################################################################################################
#  Data Wrangling / Data Visualization
################################################################################################

dim(women_research)  #60 3

# Rename some countries
women_research1 <- women_research %>% 
                   mutate(country = case_when(country==""United Kingdom""~""UK"",
                                              country==""United States""~""US"",
                                              TRUE~country))

# Create Bubble Chart
p1 <- ggplot(women_research1, aes(x = country, y = percent_women)) +
      geom_point(aes(size = percent_women, colour = field), alpha=.8) + 
      scale_size(range = c(1,6)) +
      scale_alpha(guide = 'none') +
      theme(panel.background = element_blank(), axis.line = element_line(colour = ""black""),
            text = element_text(size=9),
            legend.position=""bottom"", legend.box = ""horizontal"") +
      scale_color_viridis(discrete = TRUE, option = ""D"")+
      scale_fill_viridis(discrete = TRUE) +
      guides(colour = guide_legend(override.aes = list(size=3)), size=FALSE) +
      labs(title=""Women in Research with Papers Published 2011-15"",
           x = ""Country"",
           y = ""Percentage of total by field"",
           caption = ""\nSource: The Economist | Graphic: Joy Tay / @runjollyrun"")
p1

ggsave(filename = ""women_research.png"", p1, width = 7, height = 4, dpi = 300, 
       units = ""in"", device='png')

","2019-16"
"518",1435,"http://github.com/oranwutang/tidytuesdays_p/tree/master/14-5-2019","oranwutang","tidytuesdays_p","14-5-2019/Nobel.R","library(tidyverse)
library(magrittr)
# install.packages(""remotes"")
# remotes::install_github(""dgrtwo/drlib"") # drlibr includes the functions used for correctly sorting data within facets

nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

nobel_winner_all_pubs$journal<-gsub(""proceedings of the national academy of sciences of the united states of america"", ""PNAS"", nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$journal<-gsub(""journal of the chemical society chemical communications"", ""J Chem Soc, Chem Commun"", nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$journal<-gsub(""journal of the american chemical society"", ""J. Am. Chem. Soc."", nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$journal <- str_to_title(nobel_winner_all_pubs$journal)

nobel_winner_all_pubs$category <- str_to_title(nobel_winner_all_pubs$category)

nobel_winner_all_pubs %>% 
  filter(is_prize_winning_paper==""YES"", !is.na(journal)) %>% 
  select(journal, category) %>% 
  group_by(category, journal) %>% 
  count() %>% 
  group_by(category) %>% 
  arrange(desc(n)) %>% 
  slice(1:15) %>% 
  ggplot(aes(drlib::reorder_within(x=journal, by=n, within=category), y=n))+
  geom_col(aes(fill=n))+ 
  drlib::scale_x_reordered() + 
  facet_wrap(~category, scales = ""free"")+ 
  labs(x="""", y="""", title = ""Top 15 Journals Publishing Laureate Articles"")+
  theme_minimal()+
  theme(plot.title = element_text(size=26))+
  scale_fill_viridis_c(option = ""inferno"")+
  coord_flip()
","2019-20"
"519",1437,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","April 23 2019/anime.R","library(tidyverse)
library(magrittr)
library(lubridate)
library(lisa)

raw_anime<-readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/raw_anime.csv"")
clean_raw<-raw_anime %>%   # Aired
  mutate(aired = str_remove(aired, ""\\{""),
         aired = str_remove(aired, ""\\}""),
         aired = str_remove(aired, ""'from': ""),
         aired = str_remove(aired, ""'to': ""),
         aired = word(aired, start = 1, 2, sep = "","")) %>% 
  separate(aired, into = c(""start_date"", ""end_date""), sep = "","") %>% 
  mutate(start_date = str_remove_all(start_date, ""'""),
         start_date = str_sub(start_date, 1, 10),
         end_date = str_remove_all(start_date, ""'""),
         end_date = str_sub(end_date, 1, 10)) %>%
  mutate(start_date = lubridate::ymd(start_date),
         end_date = lubridate::ymd(end_date)) %>% 
  # Drop unranked or unpopular series
  filter(rank != 0,
         popularity != 0)


clean_raw$start_date<-ymd(clean_raw$start_date)
clean_raw$end_date<-ymd(clean_raw$end_date)

# weight(x, weights, digits = 0)
clean_raw %>% filter(start_date>""1970-1-1"" & rating!=""None"") %>%
  ggplot(aes(x=start_date, y=score, color=rating)) + 
  geom_point(alpha=0.04) +
  geom_smooth(se = FALSE, size=1.4) + 
  scale_color_manual(values = rev(lisa$ReneMagritte)) + 
  theme_minimal() +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background=element_rect(fill=""transparent"",colour=NA),
        plot.background=element_rect(fill=""transparent"",colour=NA),
        legend.key = element_rect(fill = ""transparent"", colour = ""transparent""),
        legend.position = c(0.3, 0.15),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12), 
        plot.title = element_text(size = 18))+
  labs(x=""Start Date"", y= ""Score"", color=""Rating"",
       title = ""Score of anime\ncategories over time"",
       subtitle = ""Violence and profanity are on the rise"")

","2019-17"
"520",1438,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","April 29 2019 Birds/birds.R","library(tidyverse)
library(magrittr)

joined<-left_join(bird_collisions %>% filter(locality==""MP""), mp_light , by = ""date"")

joined %>%
  filter(!is.na(light_score)&family!=""Laniidae""&family!=""Icteridae"") %>% 
  group_by(family) %>% 
  mutate(MedianLight=median(light_score)) %>% 
  ggplot(aes(x=reorder(family, -light_score, FUN=median), y=light_score))+
  geom_boxplot(aes(fill=MedianLight))+
  scale_fill_gradient(low=""NA"", high=""steelblue"")+
  ggthemes::theme_solarized()+
  theme(panel.grid = element_blank(),
        legend.position = ""NA"")+
  coord_flip()+
  ylab(""Light Score"")+
  xlab(""Family"")+
  labs(title=""Birds' collisions vary according\nto Light Score"",
          caption=""Source:\nhttps://doi.org/10.1098/rspb.2019.0364\nhttps://doi.org/10.5061/dryad.8rr0498"")
","2019-17"
"521",1439,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","May 6 2019/Students_Teachers.R","library(tidyverse)
library(magrittr)
library(lubridate)
library(ggpubr)


student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

student_ratio$country <- str_replace(student_ratio$country, pattern = ""United Kingdom of Great Britain"", replacement = ""UK"")

# First Chart, grouping by year:

a <- student_ratio %>% 
  group_by(country, indicator, year) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
    geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point(aes(size=as.factor(year)), alpha=0.3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())


a<-set_palette(a, ""nejm"")

b <- student_ratio %>% 
  group_by(country, indicator, year) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(-25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
  geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point(aes(size=as.factor(year)), alpha=0.3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())

b <- set_palette(b, ""nejm"")


arranged<-ggarrange(a, b, common.legend = TRUE, legend = ""bottom"")

chartByYear<-annotate_figure(arranged,
                top = text_grob(""The 25 highest and lowest Student/Teacher Ratios\n by countries and year"", face = ""bold"", size = 14))

chartByYear
#Second Chart, not grouping by year

a <- student_ratio %>% 
  group_by(country, indicator) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
  geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point(alpha=0.3, size=3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())


a<-set_palette(a, ""nejm"")

b <- student_ratio %>% 
  group_by(country, indicator) %>%
  summarise(Ratio=mean(student_ratio, na.rm = TRUE)) %>%  
  arrange(-Ratio) %>% 
  filter(!is.na(Ratio)) %>% 
  ungroup() %>% 
  top_n(-25) %>% 
  ggplot(aes(x=reorder(country, Ratio), y=Ratio, color=indicator))+
  geom_segment(aes(x=reorder(country, Ratio), y= 0, xend=country, yend=Ratio), size=1)+
  geom_point( alpha=0.3, size=3)+
  theme_minimal()+coord_flip()+xlab("""")+
  ggpubr::theme_pubr()+
  theme(legend.title = element_blank())

b <- set_palette(b, ""nejm"")


arranged<-ggarrange(a, b, common.legend = TRUE, legend = ""bottom"")

chartWOYear<-annotate_figure(arranged,
                             top = text_grob(""The 25 highest and lowest Student/Teacher Ratios\n by countries"", face = ""bold"", size = 14))

chartWOYear
","2019-18"
"522",1488,"https://github.com/mdonertas/tidytuesday","mdonertas","tidytuesday","20190416/20190416.Rmd","---
title: ""Economist's 'Mistakes, weve drawn a few'""
output: html_notebook
---

# Data description

Sarah Leo from The Economist went through the Economist's archives and found 7 examples of charts that were in need of improvement.

""I grouped our crimes against data visualisation into three categories: charts that are (1) misleading, (2) confusing and (3) failing to make a point. For each, I suggest an improved version that requires a similar amount of space??an important consideration when drawing charts to be published in print.""

She was nice enough to include the raw data as .csv files, where I have included both the raw and tidied formats for your graphing fun!

# Setup

```{r message=F, warning=F}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(ggpubr)
```

# Get the data

```{r message=FALSE, warning=FALSE}
brexit <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv"")

corbyn <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/corbyn.csv"")

dogs <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/dogs.csv"")

eu_balance <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/eu_balance.csv"")

pensions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/pensions.csv"")

trade <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/trade.csv"")

women_research <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")
```

# Jeremy Corbyn Facebook Likes

## Original Post

![[link](https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368)](https://cdn-images-1.medium.com/max/2600/1*9QE_yL3boSLqopJkSBfL5A.png)

## Recreation

```{r}
corbyn_clean <- corbyn %>%
    rename(name = political_group) %>%
    na.omit()
corbyn_clean
```

```{r}
p_corbyn <- corbyn_clean %>%
    mutate(name = name %>% fct_reorder(avg_facebook_likes) %>% fct_rev()) %>%
    ggplot(aes(y = avg_facebook_likes, x = name, fill = factor(rank(avg_facebook_likes)))) +
    geom_bar(stat = 'identity') +
    coord_flip() +
    theme_economist(dkpanel = T, base_size = 12) +
    xlab('') + ylab('') +
    ggtitle('Left-click','Average number of likes per Facebook post, 2016') +
    scale_fill_brewer(type = 'seq', palette = 8) +
    guides(fill = F) +
    theme(axis.text.y = element_text(hjust = 1),
          panel.grid.major.y = element_blank(),
          panel.grid.major.x = element_line(),
          plot.title = element_text(color = 'darkred', face = 'bold'),
          plot.subtitle = element_text(color = 'gray40', face = 'italic')) +
    scale_y_continuous(labels = scales::comma) +
    labs(caption = 'Source: Facebook')
```

```{r, fig.align='centre'}
p_corbyn
```

```{r, echo = F}
ggsave('./corbyn.pdf', p_corbyn, units = 'cm', height = 8, width = 16)
ggsave('./corbyn.png', p_corbyn, units = 'cm', height = 8, width = 16)
```

# Dog Size

## Original Post

![[link](https://medium.economist.com/mistakes-weve-drawn-a-few-8cdd8a42d368)](https://cdn-images-1.medium.com/max/2600/1*H21mduPmvzot3oaMThNfFQ.png)

## Recreation

```{r}
head(dogs)
```

```{r}
p_dogs <- dogs %>%
    mutate(year = lubridate::ymd(dogs$year, truncated = 2L)) %>%
    ggplot(aes(x = year)) + 
    geom_line(aes(y = avg_neck, color = 'Neck Size'), size = 3) +
    geom_line(aes(y = (avg_weight+1)*2, color = 'Weight'), size = 3) +
    scale_y_continuous(sec.axis = sec_axis(~./2 - 1, name = ""Weight**, kg"",), 
                       limits = c(38,45)) +
    theme_economist(base_size = 12) +
    scale_x_date() + 
    scale_colour_manual(values = c(""darkred"", ""steelblue3"")) +
    ggtitle('Fit as a butcher\'s dog','Characteristics of registered with the UK\'s\nKennel Club, average when fully grown') +
    guides(color = F) +
    xlab('') +
    ylab('Neck Size*, cm') +
    labs(caption = '*Where at least 100 are registered per year\n**Where at least 50 are registered per year\nSources: Kennel Club; The Economist') +
    theme(axis.title.y.left = element_text(angle = 0, colour = 'darkred', 
                                           face = 'italic', hjust = 0, 
                                           margin = margin(0,-80,0,0)),
          axis.title.y.right = element_text(angle = 0, colour = 'steelblue3', 
                                            face = 'italic', hjust = 1, 
                                            margin = margin(0,0,0,-70), 
                                            vjust = 1),
          axis.text.y.right = element_text(margin = margin(0,0,0,10)),
          plot.subtitle = element_text(margin = margin(0,0,20,0)))
```

```{r, fig.align='centre'}
p_dogs
```

```{r, echo = F}
ggsave('./dogs.pdf', p_dogs, units = 'cm', height = 10, width = 10)
ggsave('./dogs.png', p_dogs, units = 'cm', height = 10, width = 10)
```

## My attempt

```{r}
p_dogs2 <- dogs %>%
  # mutate(year = lubridate::ymd(dogs$year, truncated = 2L)) %>%
  ggplot(aes(x = avg_weight, y = avg_neck, color = year)) +
  geom_point(size = 2) +
  geom_path(size = 1,arrow = arrow(length = unit(8,""pt""))) +
  geom_label(data = filter(dogs, year %in% c(2006, 2015)),
             aes(label = year, fill = year),
             color = 'white', nudge_y = -0.2) +
  theme_economist() +
  theme(legend.position = 'right') +
  ggtitle('Fit as a butcher\'s dog','Characteristics of registered with the UK\'s Kennel Club,\naverage when fully grown') +
  xlab('Weight**, kg') + ylab('Neck Size*, cm') +
  scale_y_continuous(breaks = 42:44, limits = c(42,44.4)) +
  scale_x_continuous(breaks = 18:20, limits = c(18,20.6)) +
  labs(caption = '*Where at least 100 are registered per year\n**Where at least 50 are registered per year\nSources: Kennel Club; The Economist') +
  scale_color_gradient(low = 'lightsteelblue3', high = 'steelblue4', breaks = c(2006,2015), guide = F) +
  scale_fill_gradient(low = 'lightsteelblue3', high = 'steelblue4', breaks = c(2006,2015), guide =F) +
  coord_fixed(ratio = 100*((max(dogs$avg_neck)-min(dogs$avg_neck))/max(dogs$avg_neck)) / (100*((max(dogs$avg_weight)-min(dogs$avg_weight))/max(dogs$avg_weight))))
```

```{r, fig.align='centre'}
p_dogs2
```

```{r, echo = F}
ggsave('./dogs2.pdf', p_dogs2, units = 'cm', height = 10, width = 12)
ggsave('./dogs2.png', p_dogs2, units = 'cm', height = 10, width = 12)
```

## Women research

```{r}
p_women <- women_research %>% 
    mutate(country = fct_reorder(country, percent_women)) %>%
    mutate(field = fct_reorder(field, percent_women)) %>%
    ggplot(aes(y = field, x = country, fill = percent_women)) +
    geom_tile() +
    scale_fill_gradient2(midpoint = 0.5, low = '#084594', high = '#99000D', 
                         mid = 'snow', breaks = c(0,0.5,1), limits = c(0,1)) +
    theme_economist(base_size = 12) +
    theme(legend.position = 'right',
          axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
          axis.text.y = element_text(hjust = 1),
          panel.grid = element_blank(),
          axis.ticks = element_blank()) +
    guides(fill = guide_colorbar('% Women')) +
    xlab('') + ylab('') +
    ggtitle('Still a man\'s world', 'Women among researchers with papers published*\n2011-15') +
    labs(caption = '*Indexed in Scopus\nSources: \'Gender in the Global Research Landscape\' by Elsevier; The Economist\nPlot by @melikedonertas')
```

```{r, fig.align='centre'}
p_women
```

```{r, echo = F}
ggsave('./women.pdf', p_women, units = 'cm', height = 10, width = 18)
ggsave('./women.png', p_women, units = 'cm', height = 10, width = 18)
```
","2019-16"
"523",1511,"https://github.com/rladies-ames/tidytuesday/blob/master/data/2019/2019-01-29/r-ladies-ames-soln.Rmd","rladies-ames","tidytuesday","data/2019/2019-01-29/r-ladies-ames-soln.Rmd","---
title: ""Milk Production in the US""
author: ""R-Ladies Ames""
date: ""2/5/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For our first foray into #TidyTuesday, we went back in time. We felt cows were more appropos for R-Ladies Ames than mortgage data. 

```{r pkgs}
library(tidyverse)
library(janitor)
library(visdat)
library(sf)
library(USAboundaries)
# devtools::install_github('thomasp85/gganimate')
library(gganimate)
```

```{r getdat}
cheese <- read_csv(""clean_cheese.csv"")
fluid_milk <- read_csv(""fluid_milk_sales.csv"")
milkfacts <- read_csv(""milk_products_facts.csv"")
cowfacts <- read_csv(""milkcow_facts.csv"")
state_milk <- read_csv(""state_milk_production.csv"")
```

```{r glimpsedat}
glimpse(cheese)
glimpse(fluid_milk)
glimpse(cowfacts)
glimpse(milkfacts)
glimpse(state_milk)
```

## Make a map of milk

```{r usamap}
usa <- us_states()
usa <- usa %>% filter(name != ""Alaska"", name != ""Hawaii"", jurisdiction_type != ""territory"")

usa <- usa %>% filter(name != ""District of Columbia"")

usa_milk <- usa %>% left_join(state_milk, by = c(""name"" = ""state""))
# usa_milk %>% filter(year == 1970) %>% 
# ggplot() + 
#   geom_sf(aes(fill = milk_produced)) + 
#   scale_fill_distiller(name = paste(""Pounds of Milk Year"", i), palette = ""YlOrBr"", direction = 2) + 
#   coord_sf() + 
#   theme_void() + 
#   theme(panel.grid = element_line(color = 'white'))
```


# Now we animate over years

```{r ggani}

usa_milk %>% mutate(year = as.integer(year), milk_produced = milk_produced/10^9) %>% 
ggplot() +
  geom_sf(aes(fill = milk_produced)) +
  scale_fill_distiller(name = ""Billions of Pounds of\nMilk Produced"", palette = ""YlOrBr"", direction = 2) + 
  #facet_wrap(~year)
  labs(title = ""Milk Production in {frame_time}"") + 
   # Here comes the gganimate specific bits
  transition_time(year) 
# anim_save(filename = ""milk.gif"", animation = last_animation())
```




","2019-5"
"524",1515,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2018/2018-09-04/readme.rmd","# Fast food entree data

* Data from [fastfoodnutrition.com](https://fastfoodnutrition.org/mcdonalds/chart) 
* Please notice that I really only took entrees - feel free to select ALL food, sides, drinks, desserts, etc.

At the request of the website owner - I have removed web-scraping guide.
","2018-36"
"525",1516,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2018/2018-09-25/raw/invasive_species.R","library(tidyverse)

df <- read_csv(""afr_species.csv"") %>% 
        janitor::clean_names() %>% 
        select(species:origin)

df %>% write_csv(""africa_species.csv"")

df1 <- read_csv(""table1.csv"") %>% janitor::clean_names()
tab_1 <- df1 %>% 
        select(rank:o_tt) %>% 
        bind_rows(df1 %>% 
                          select(rank_1:o_tt_1) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        bind_rows(df1 %>% 
                          select(rank_2:o_tt_2) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        filter(!is.na(rank)) %>% 
        rename(""invasion_threat"" = o_tt)

df2 <- read_csv(""table2.csv"") %>% janitor::clean_names()
tab_2 <- df2 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df2 %>% 
                select(""country"" = x4, ""ti_ct"" = ti_ct_millions_1) %>% 
                        mutate(rank = parse_number(country),
                               country = str_extract(country, ""[:alpha:].*$""),
                               ti_ct = parse_number(ti_ct) * 1000000) %>% 
                        filter(!is.na(rank))
        ) %>% 
        bind_rows(df2 %>% 
                          select(""country"" = x7, ""ti_ct"" = ti_ct_millions_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000) %>% 
                          filter(!is.na(rank))
                
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df3 <- read_csv(""table3.csv"") %>% janitor::clean_names()
tab_3 <- df3 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions, 
               ""gdp_mean"" = x4, ""gdp_proportion"" = proportion_of) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_ct = parse_number(ti_ct) * 1000000,
               gdp_mean = parse_number(gdp_mean) * 1000000,
               gdp_proportion = as.numeric(gdp_proportion)
        ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x6, ""ti_ct"" = ti_ct_millions_1, 
                                 ""gdp_mean"" = x9, ""gdp_proportion"" = proportion_of_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x11, ""ti_ct"" = ti_ct_millions_2, 
                                 ""gdp_mean"" = x14, ""gdp_proportion"" = proportion_of_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df4 <- read_csv(""table4.csv"") %>% janitor::clean_names()
tab_4 <- df4 %>% 
        select(""country"" = rank_country, ""ti_cs"" = ti_cs_millions_us) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:].*$""),
               ti_cs = parse_number(ti_cs) * 1000000
               ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_1, ""ti_cs"" = ti_cs_millions_us_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
                  ) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_2, ""ti_cs"" = ti_cs_millions_us_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:].*$""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_cs)

df6 <- read_csv(""table6.csv"") %>% janitor::clean_names()
tab_6 <- df6 %>% 
        select(species, ""max_impact_percent"" = maximum_reported_species) %>%
        filter(!is.na(species)) %>% 
        mutate(rank = 1:n(),
               species = species,
               max_impact_percent = parse_number(max_impact_percent)
        ) %>% 
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species, 
                                 ""max_impact_percent"" = maximum_reported_species_1) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>%
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species_1, 
                                 ""max_impact_percent"" = maximum_reported) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:].*$""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>% 
        filter(!is.na(species))

tab_list <- list(table_1 = tab_1, table_2 = tab_2, table_3 = tab_3, table_4 = tab_4, table_6 = tab_6)

tab_list %>% 
        names() %>% 
        walk(~ write_csv(tab_list[[.]], glue::glue(""{.}.csv"")))
","2018-39"
"526",1517,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2018/2018-09-25/raw/readme.rmd","# Raw tabular data

Table data extracted from supplementary PDF via [Tabula](https://tabula.technology/) open-source software. 

This ended up being super messy - cleaning script found below.

[Cleaning Script](https://github.com/rfordatascience/tidytuesday/blob/master/data/2018-09-25/raw/invasive_species.R)
","2018-39"
"527",1518,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-01-22/example_code.R","# Load Library
library(tidyverse)

# Read in raw data from Vera
df_raw <- read_csv(""https://raw.githubusercontent.com/vera-institute/incarceration_trends/master/incarceration_trends.csv"")

# Check out the data structure
df_raw %>% str()

# add a row id (for later joining)
df <- df_raw %>% 
  mutate(row_id = row_number())

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong

df_population <- df %>% 
  select(yfips:land_area, -total_pop, row_id) %>% 
  gather(pop_category, population, total_pop_15to64:white_pop_15to64) %>% 
  mutate(pop_category = case_when(str_detect(pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(pop_category, ""white"") ~ ""White"",
                                  str_detect(pop_category, ""black"") ~ ""Black"",
                                  str_detect(pop_category, ""female"") ~ ""Female"",
                                  str_detect(pop_category, ""male_pop"") ~ ""Male"",
                                  str_detect(pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(pop_category, ""total"") ~ ""Total"",
                                  str_detect(pop_category, ""native"") ~ ""Native American"",
                                  str_detect(pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# select only the gather columns and gather to tidy structure
# VERY important to have females listed above males or else case_when will label wrong
df_prison_pop <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_prison_pop:white_prison_pop, row_id) %>% 
  gather(prison_pop_category, prison_population, total_prison_pop:white_prison_pop) %>% 
  mutate(prison_pop_category = case_when(str_detect(prison_pop_category, ""asian"") ~ ""Asian"",
                                  str_detect(prison_pop_category, ""white"") ~ ""White"",
                                  str_detect(prison_pop_category, ""black"") ~ ""Black"",
                                  str_detect(prison_pop_category, ""female"") ~ ""Female"",
                                  str_detect(prison_pop_category, ""male_prison"") ~ ""Male"",
                                  str_detect(prison_pop_category, ""latino"") ~ ""Latino"",
                                  str_detect(prison_pop_category, ""total"") ~ ""Total"",
                                  str_detect(prison_pop_category, ""native"") ~ ""Native American"",
                                  str_detect(prison_pop_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Left join the two dataframes together
# I used all the common columns including row_id

full_prison_pop_df <- left_join(df_population, df_prison_pop, 
          by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                 ""pop_category"" = ""prison_pop_category"", ""urbanicity"", ""region"",
                 ""division"", ""commuting_zone"", ""metro_area"", ""land_area"", ""row_id"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone)) 

# Summary data to get rate per 100000 by group

summ_prison <- full_prison_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(prison_population)/sum(population) * 100000) %>% 
  ungroup()

# Test plot looks good
ggplot(summ_prison, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category)

# More gathers to get pre-trial data
df_pretrial <- df %>% 
  select(yfips:county_name, urbanicity:land_area, total_jail_pretrial:male_jail_pretrial) %>% 
  gather(pretrial_category, pretrial_population, total_jail_pretrial:male_jail_pretrial) %>% 
  mutate(pretrial_category = case_when(str_detect(pretrial_category, ""asian"") ~ ""Asian"",
                                  str_detect(pretrial_category, ""white"") ~ ""White"",
                                  str_detect(pretrial_category, ""black"") ~ ""Black"",
                                  str_detect(pretrial_category, ""female"") ~ ""Female"",
                                  str_detect(pretrial_category, ""male_jail"") ~ ""Male"",
                                  str_detect(pretrial_category, ""latino"") ~ ""Latino"",
                                  str_detect(pretrial_category, ""total"") ~ ""Total"",
                                  str_detect(pretrial_category, ""native"") ~ ""Native American"",
                                  str_detect(pretrial_category, ""other"") ~ ""Other"",
                                  TRUE ~ NA_character_))

# Pretrial dataset joined with population numbers
pretrial_pop_df <- left_join(df_population, df_pretrial, 
                         by = c(""yfips"", ""fips"", ""year"", ""state"", ""county_name"", 
                                ""pop_category"" = ""pretrial_category"", ""urbanicity"", ""region"",
                                ""division"", ""commuting_zone"", ""metro_area"", ""land_area"")) %>% 
  select(-c(yfips, fips, metro_area, land_area, row_id, commuting_zone))

# Summary data to get rate per 100000 by group
summ_pretrial <- pretrial_pop_df %>% 
  na.omit() %>% 
  group_by(year, urbanicity, pop_category) %>% 
  summarize(rate_per_100000 = sum(pretrial_population)/sum(population) * 100000) %>% 
  ungroup()

# plot matches Vera plot
ggplot(summ_pretrial, aes(x = year, y = rate_per_100000, color = urbanicity)) +
  geom_line() +
  facet_wrap(~pop_category) +
  labs(title = ""Rate per 100,000 by county type and population group"")

# Write files to .csv
write_csv(summ_prison, ""prison_summary.csv"")
write_csv(summ_pretrial, ""pretrial_summary.csv"")
write_csv(full_prison_pop_df, ""prison_population.csv"")
write_csv(pretrial_pop_df, ""pretrial_population.csv"")
","2019-4"
"528",1519,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-02-05/r-ladies-ames-soln.Rmd","---
title: ""R-Ladies Ames Do Tidy Tuesday""
author: ""Sam Tyner, Haley Jeppson, Annette O'Connor, Soyoung Park""
date: ""2/5/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r pkgs}
library(tidyverse)
```

```{r getdata}
mort <- read_csv(""mortgage.csv"")
recess <- read_csv(""recessions.csv"")
hpi <- read_csv(""state_hpi.csv"")
```

```{r glimpse}
glimpse(mort)
glimpse(recess)
glimpse(hpi)
```


## Start by tidying the mortgage data 

DO COW DATA INSTEAD!!!!!
","2019-6"
"529",1520,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-02-19/r-ladies-ames-soln.Rmd","---
title: ""R Ladies Ames Solution""
author: ""Sam Tyner, Kat Goode, Jing Zhao""
date: ""2/19/2019""
output: github_document
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Get data 

```{r dat}
library(tidyverse)
library(plotly)
phd_field <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")
phd_field %>% count(year)
head(phd_field)
```

## All PhDs 

```{r alldegress}
phd_field %>% group_by(year) %>% summarise(total = sum(n_phds, na.rm = T)) %>% 
  ggplot(aes(x = year,y = total)) + 
  geom_line() + 
  scale_x_continuous(breaks = 2008:2017)
```

## Most popular 

```{r popular}
phd_field %>% group_by(broad_field) %>% 
  summarize(total = sum(n_phds, na.rm = T)) %>% 
  arrange(desc(total))
```

```{r popular2}
phd_field %>% group_by(major_field) %>% 
  summarize(total = sum(n_phds, na.rm = T)) %>% 
  arrange(desc(total))
```

```{r popular3}
phd_field %>%group_by(field) %>% 
  summarize(total = sum(n_phds, na.rm = T)) %>% 
  arrange(desc(total))
```



```{r algebra}
phd_field %>% filter(field == ""Algebra"") %>% 
  ggplot(aes(year, n_phds)) + 
  geom_line()
```


```{r stats}
phd_field %>% filter(str_detect(field, ""Statistics""))  %>% 
  ggplot(aes(year, n_phds, color = field)) + 
  geom_line()
```


```{r alltime}
p <- phd_field %>% 
  ggplot(aes(year, n_phds, group = field)) + 
  geom_line(alpha = .3) + 
  facet_wrap(~broad_field)
p
#ggplotly(p)
```

```{r psych}
p <- phd_field %>% filter(broad_field == ""Psychology and social sciences"") %>% 
  ggplot(aes(year, n_phds, group = field)) + 
  geom_line(alpha = .5) + 
  facet_wrap(~major_field, scales = ""free_y"")
p
#ggplotly(p)
```

```{r byfield}
phd_field %>% group_by(year, broad_field) %>% summarise(total = sum(n_phds, na.rm = T)) %>% 
  ggplot(aes(x = year, y = total, color = broad_field)) +
  geom_line()
```

```{r byfield2}
phd_field %>% group_by(year, broad_field) %>% filter(!is.na(n_phds)) %>% count() %>% 
  ggplot(aes(year, n, color = broad_field)) + 
  geom_line() + 
  ggtitle(""How many subfields are included in the broad fields?"")
```


```{r byfield3}
p <- phd_field %>% filter(broad_field == ""Other"") %>% 
  ggplot(aes(year, n_phds, group = field)) + 
  geom_line() + 
  facet_wrap(~major_field)
p
#ggplotly(p)
```","2019-8"
"530",1521,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-05/r-ladies-ames-soln.Rmd","---
title: ""R Ladies Ames Solution""
author: ""Sam Tyner, Miranda Tilton""
date: ""3/5/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r getdat}
library(tidyverse)
jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")
earnings_female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"") 
employed_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"") 
```


```{r jobs}
head(jobs_gender)
head(earnings_female)
```

```{r earningsfemale}
earnings_female %>% mutate(total = str_detect(group, ""Total"")) %>% 
ggplot() + 
  geom_line(aes(x = Year, y = percent, group = group, color = group)) + 
  scale_color_brewer(palette = ""Reds"") + 
  facet_grid(total ~ ., space = ""free"", scales = ""free_y"")
```

```{r jobsgender}
head(jobs_gender)
jobs_gender %>% 
  ggplot() + 
  geom_line(aes(x = year, y=  percent_female, group =occupation, color = major_category))
```","2019-10"
"531",1522,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-12/r-ladies-ames-soln.Rmd","---
title: ""R Ladies Ames' Solution""
author: ""Sam Tyner""
date: ""3/12/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = ""center"", out.width = ""75%"", message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
bgdat <- read_csv(""board_games.csv"")
glimpse(bgdat)
```

What is the relationship between year and playing time? 

```{r}
ggplot(data = bgdat) + 
  geom_linerange(aes(x = year_published, y = (min_playtime + max_playtime)/2, ymin = min_playtime, ymax = max_playtime, group = game_id)) + 
  labs(x = ""Year Published"", y = ""Playtime (minutes)"")
```

Which games have playtime more than 20,000 minutes (about two weeks)?!? 

```{r}
bgdat %>% filter(min_playtime > 10000) %>% glimpse()
```
Wow, that's dedication. Let's remove those extremes.  

```{r}
bgdat <- bgdat %>% filter(min_playtime < 10000)
ggplot(data = bgdat) + 
  geom_linerange(aes(x = year_published, y = (min_playtime + max_playtime)/2, ymin = min_playtime, ymax = max_playtime, group = game_id)) + 
  labs(x = ""Year Published"", y = ""Playtime (minutes)"")
```

It would be nice to facet this by category, but the category variable is strange: 

```{r}
bgdat$category %>% head()
```

Let's clean this up a bit.

```{r}
bgdat$category %>% str_count("","") %>% max(na.rm=T)
```

One game has 14 categories! 

```{r}
bgdat %>% mutate(ncat = str_count(category, "","") + 1) %>% 
  arrange(desc(ncat)) %>% select(name, category, ncat) %>% head
```

Now, we'll split category up and only keep the first 2 categories for simplicity. 

```{r}
bgdat2 <- bgdat %>% separate(category, into = c(""firstcat"", ""secondcat""), sep = "","")
bgdat2 %>% count(firstcat)
```

There are still a lot of categories, but there are many different categories of war games. Let's make all of them just ""War"".

```{r out.width= ""100%""}
bgdat2 <- bgdat2 %>% mutate(firstcat = ifelse(str_detect(firstcat, ""War""), ""War"", firstcat), secondcat = ifelse(str_detect(secondcat, ""War""), ""War"", secondcat))
bgdat2 %>% count(firstcat)
bgdatcats <- bgdat2 %>% count(firstcat)
bgdatcats %>%  
  ggplot(aes(x = reorder(firstcat, n), weight = n)) + 
  geom_bar() + 
  coord_flip()
# only use categories with > 250 games (at least 2.5% of the games but have the category to be used)
bgdatcats2 <- bgdatcats %>% filter(n > 250)
bgdat3 <- bgdat2 %>% filter(firstcat %in% bgdatcats2$firstcat)
# facet by firstcat
ggplot(data = bgdat3) + 
  geom_linerange(aes(x = year_published, ymin = min_playtime, ymax = max_playtime, group = game_id)) + 
  labs(x = ""Year Published"", y = ""Playtime (minutes)"") + 
  facet_wrap(~firstcat, scales = ""free"")
# what about the mean of the min & max? 
ggplot(data = bgdat3) + 
  geom_point(aes(x=year_published , y = (min_playtime + max_playtime)/2, color = firstcat))
bgdat3 %>% mutate(mean_play = (min_playtime + max_playtime)/2) %>% 
  filter(mean_play < 1440) %>% # only look at games with less than a day of play time 
ggplot(aes(x = year_published, y = mean_play)) + 
  geom_point() + 
  geom_smooth() + 
  facet_wrap(~firstcat, scales = ""free"")
```

In the most popular games, it looks like the average game play has remained fairly stable over time. 
","2019-11"
"532",1523,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-19/r-ladies-ames-soln.Rmd","---
title:  ""R-Ladies Ames Solution""
author: ""Sam Tyner, Amanda Rae""
date: ""3/19/2019""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r getdat}
library(tidyverse)
combined_data <- read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")
head(combined_data)
```

Since we're in Iowa, let's isolate the Iowa data 

```{r iowadat}
iowa <- filter(combined_data, state == ""IA"")
iowa
```

No Iowa. `r emo::ji(""sad"")`. 

Dowload Iowa data directly from [the SOPP website](https://openpolicing.stanford.edu/data/). (Not on Gitub because it's too large.) 

```{r iowadat2}
iowa <- read_rds(""iowa.rds"")
glimpse(iowa)
summary(iowa$date)
dim(iowa)
```

Lets only get the last 3 or so years in the data since there are over 2 million rows. 

```{r last5}
library(lubridate)
iowa %>% mutate(year = year(date)) %>% 
  filter(year >= 2013, !is.na(date)) -> iowa
head(iowa)
dim(iowa)
```

View the missingness with [`visdat`](http://dx.doi.org/10.21105/joss.00355). 

```{r miss}
library(visdat)
vis_dat(iowa, warn_large_data = FALSE)
```

```{r location}
count(iowa, location)
count(iowa, department_name)
```

","2019-12"
"533",1524,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-03-26/r-ladies-ames-soln.Rmd","---
title: ""R-Ladies Ames Solution""
date: ""March 26, 2019"" 
author: ""Sam Tyner, Stephanie Reinders""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align=""center"")
```

# Read the data in 

```{r getdat}
library(tidyverse)
pets <- read_csv(""seattle_pets.csv"")
head(pets)
```

Parsing dates & zip codes: 

```{r dates}
library(lubridate)
pets %>% 
  mutate(date = parse_date(license_issue_date, format = ""%B %d %Y""), 
         zip = parse_integer(zip_code)) -> pets
# check for missings 
pets %>% filter(is.na(date))
pets %>% filter(is.na(zip))
pets %>% filter(is.na(zip), !is.na(zip_code))

# if zip_code is not NA, only take the first 5 digits 
pets <- pets %>% 
  mutate(zip = ifelse((!is.na(zip_code) & is.na(zip)), parse_integer(str_sub(zip_code, 1, 5)), zip))
head(pets)
```

First letter of the animals' names by species. 

```{r lets}
pets %>% 
  mutate(first_letter = toupper(str_sub(animals_name, 1,1))) -> pets 
pets %>% 
  ggplot() + 
  geom_bar(aes(x = first_letter, fill = species)) 
```


```{r weird}
pets %>% filter(!(first_letter %in% LETTERS) , !(is.na(animals_name)))
# only 12 that are non-alpha
``` 

```{r lets2}
pets %>% filter(first_letter %in% LETTERS, species %in% c(""Cat"", ""Dog"")) %>% 
  ggplot() + 
  geom_bar(aes(x = first_letter, fill = species), position = ""dodge"")
pets %>% filter(first_letter %in% LETTERS, species %in% c(""Goat"", ""Pig"")) %>% 
  ggplot() + 
  geom_bar(aes(x = first_letter, fill = species), position = ""dodge"")
```

```{r goats}

filter(pets, species == ""Goat"") %>% 
  select(animals_name) %>% count(animals_name) %>% arrange(desc(n))

filter(pets, species == ""Pig"") %>% 
  select(animals_name) %>% count(animals_name) %>% arrange(desc(n))

```

Distribution of letters in Cats vs Dogs 

```{r chisq}
pets %>% filter(species %in% c(""Cat"", ""Dog""), first_letter %in% LETTERS) %>% 
  group_by(species, first_letter) %>% count() -> test

# ?chisq.test

cats <- (test %>% filter(species == ""Cat""))$n
dogs <- (test %>% filter(species == ""Dog""))$n

chisq.test(cats, dogs, correct = FALSE)
```

","2019-13"
"534",1525,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-04-09/tennis_pros.rmd","---
title: ""Men's and Women's Tennis""
author: ""Thomas Mock""
date: ""4/6/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
library(lubridate)
library(janitor)
```

### Get Women's Slams Records

I couldn't find a great source of historical dates for the grand slam winner's dates but they are consistently within a few days of each other based off my cursory examination. I fully ackowledge that the dates used for the tournament date are only estimations.

```{r}
raw_slams <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_women%27s_singles_champions"") %>% 
  html_table(fill = TRUE) %>% 
  .[[3]] %>% 
  janitor::clean_names()

clean_slams <- raw_slams %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove(name, """")),
         name = str_trim(str_remove(name, ""Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          TRUE ~ name)) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Female"") %>% 
  group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()
```


 
### Get Mens Slams Records

```{r}

raw_slams_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_men%27s_singles_champions"") %>% 
  html_nodes(xpath = '//*[@id=""mw-content-text""]/div/table[1]') %>% 
  html_table(fill = TRUE) %>% .[[1]] %>% janitor::clean_names()

clean_slams_men <- raw_slams_men %>% 
  filter(year >= 1968) %>%
  gather(key = ""grand_slam"", ""winner"", australian_open:us_open) %>% 
  separate(col = winner, sep = ""\\("", into = c(""winner"", ""win_count"")) %>% 
  separate(col = win_count, sep = ""/"", into = c(""rolling_win_count"", ""total_win_count"")) %>% 
  separate(col = winner, into = c(""country"", ""winner""), sep = "":"", fill = ""left"") %>% 
  mutate(winner = str_trim(winner),
         rolling_win_count = as.integer(rolling_win_count),
         total_win_count = as.integer(str_extract(total_win_count, ""[:digit:]+""))) %>% 
  rename(name = winner) %>% 
  mutate(name = str_trim(str_remove_all(name, ""|"")),
         name = str_trim(str_remove(name, ""Amateur era tennis ends|Open era tennis begins|Tournament date changed""))) %>% 
  filter(str_length(name) > 4) %>% 
  mutate(tournament_date = case_when(grand_slam == ""australian_open"" ~ paste0(year, ""-01-10""),
                                     grand_slam == ""french_open"" ~ paste0(year, ""-06-09""),
                                     grand_slam == ""us_open"" ~ paste0(year, ""-09-09""),
                                     grand_slam == ""wimbledon"" ~ paste0(year, ""-07-14""),
                                     TRUE ~ NA_character_),
         tournament_date = lubridate::ymd(tournament_date),
         gender = ""Male"") %>% 
  select(-country) %>% 
   group_by(name) %>% 
  arrange(tournament_date) %>% 
  mutate(rolling_win_count = row_number()) %>% 
  ungroup()

```

### Get the Dates of Birth for women

This got the majority of women but I had to manually add birthdates for Ann and Chris.

```{r}
clean_dob <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[2]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  mutate(name = case_when(str_detect(name, ""Goolagong"") ~ ""Evonne Goolagong Cawley"",
                          str_detect(name, ""Reid"") ~ ""Kerry Melville Reid"",
                          str_detect(name, ""Vicario"") ~ ""Arantxa Snchez Vicario"",
                          TRUE ~ name)) %>% 
  bind_rows(tibble(name = c(""Ann Haydon-Jones"",""Chris O'Neil""),
                   date_of_birth = c(lubridate::dmy(""7 October 1938""), lubridate::dmy(""19 March 1956""))))

dob_df <- clean_dob %>% 
  select(date_of_birth, name)
```

### Combine to get approx age at each tourney

```{r}
age_slams <- left_join(clean_slams, dob_df, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))
```

### MEN

```{r}
clean_dob_men <- read_html(""https://en.wikipedia.org/wiki/List_of_Grand_Slam_singles_champions_in_Open_Era_with_age_of_first_title"") %>% 
  html_table(fill = TRUE) %>% 
  .[[1]] %>% 
  janitor::clean_names() %>% 
  select(name, ""grand_slam"" = tournament, date_of_birth, date_of_first_title) %>% 
  mutate(name = str_trim(str_remove(name, ""\\*"")),
         grand_slam = str_trim(str_remove(grand_slam, ""[:digit:]+"")),
         date_of_birth = lubridate::dmy(date_of_birth),
         date_of_first_title = lubridate::dmy(date_of_first_title),
         age = date_of_first_title - date_of_birth) %>% 
  bind_rows(tibble(name = ""William Bowrey"",
                   date_of_birth = lubridate::dmy(""25 December 1943"")))

dob_df_men <- clean_dob_men %>% 
  select(date_of_birth, name)
```

### Combine

```{r}
age_slams_men <- left_join(clean_slams_men, dob_df_men, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

age_slams_men %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step()
```

### Total Combine

```{r}
grand_slams <- bind_rows(clean_slams, clean_slams_men) %>% 
  select(-total_win_count)
```

```{r}
player_dob <- bind_rows(clean_dob, clean_dob_men)
```

```{r}
age_slams_comb <- left_join(grand_slams, player_dob, by = c(""name"")) %>% 
  mutate(age = tournament_date - date_of_birth) %>%
  group_by(name, age, gender) %>% 
  summarize(counts = n()) %>% 
  group_by(name) %>% 
  mutate(total_wins = cumsum(counts)) %>% 
  arrange(desc(total_wins))

# test plot
age_slams_comb %>% 
  ggplot(aes(x = age, y = total_wins, group = name)) +
  geom_point() +
  geom_step() +
  facet_wrap(~gender)
```


```{r}
write_csv(grand_slams, ""grand_slams.csv"")
write_csv(player_dob, ""player_dob.csv"")
```


### Tennis Timeline Performance

I thought this was interesting data that could lead to some unique plots.

```{r}
yr_1968_1970 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[12]]
clean_1968_1970 <- yr_1968_1970 %>% 
  set_names(nm = paste0(names(yr_1968_1970), ""_"", yr_1968_1970[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1964_AUS`:`1970_USA`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year)) %>% 
  filter(year >= 1968)

yr_1971_1977 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)_(1884%E2%80%931977)"") %>% 
  html_table(fill = TRUE) %>% 
  .[[13]]

clean_1971_1977 <- yr_1971_1977 %>% 
  set_names(nm = paste0(names(yr_1971_1977), ""_"", yr_1971_1977[1,])) %>% 
  filter(Player_Player != ""Player"") %>% 
  gather(key = year_tourn, value = outcome, `1971_AUS`:`1977_AUSD`) %>% 
  separate(col = year_tourn, into = c(""year"", ""tournament""), sep = ""_"") %>% 
  rename(player = Player_Player) %>% 
  mutate(year = as.integer(year))

names(yr_1968_1970) %>% unique() %>% .[. != ""Player""] %>% as.integer()
```

I re-factored into a function but there were some gotchas in the data that limited where I could apply the function. Given I will never use it again I will somewhat break DRY principles for my own sake.

```{r}

get_timeline <- function(table_num){
  
  Sys.sleep(5)
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    filter(Player_Player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    rename(player = Player_Player) %>%
    mutate(year = as.integer(year))
}
```

# Collect women's timeline

```{r}

clean_1978_2012 <- 5:9 %>%
  map(get_timeline) %>%
  bind_rows()

```

```{r}
df_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(women)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[10]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}
final_timeline <- bind_rows(list(clean_1968_1970, clean_1971_1977, clean_1978_2012, clean_2013_2019)) %>% 
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Female"")

```

```{r}
final_timeline %>% group_by(tournament) %>% count(sort = TRUE)
```

### MENS Timeline

The function works a bit nicer here and I have further re-factored it.

```{r}
get_timeline_men <- function(table_num){
  Sys.sleep(5)
  
  url <- ""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)""
  
  df <- read_html(url) %>% html_table(fill = TRUE) %>% .[[table_num]]
  
  year_range <- names(df) %>% 
    unique() %>% 
    .[. != ""Player""] %>%
    na.omit() %>% 
    as.integer()
  
  year_min <- min(year_range)
  year_max <- max(year_range)
  
  tourn_list <- df %>% janitor::clean_names() %>% slice(1) %>% unlist(., use.names = FALSE) %>% .[!is.na(.)]
  
  first_tourn <- tourn_list[2]
  last_tourn <- tourn_list[length(tourn_list)] 

  
  df %>%
    set_names(nm = paste0(df[1,], ""_"", names(df))) %>%
    janitor::clean_names(""all_caps"") %>% 
    select(-matches(""NA"")) %>% 
    select(player = PLAYER_PLAYER, matches(""AUS|FRA|WIM|USA"")) %>% 
    select(-matches(""NA|`NA`"")) %>% 
    filter(player != ""Player"") %>%
    gather(key = year_tourn, value = outcome,
           paste(first_tourn, year_min, sep = ""_""):paste(last_tourn, year_max, sep = ""_"")) %>%
    separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
    mutate(year = as.integer(year))
}
```


```{r}
men_2013_2019 <- read_html(""https://en.wikipedia.org/wiki/Tennis_performance_timeline_comparison_(men)"")  %>% 
    html_table(fill = TRUE) %>% 
    .[[8]]

clean_2013_2019 <- df_2013_2019 %>% 
  set_names(nm = paste0(df_2013_2019[1,], ""_"", names(df_2013_2019))) %>%
  filter(Player_Player != ""Player"") %>%
  select(-31) %>% 
  gather(key = year_tourn, value = outcome,
         paste(""AUS"", ""2013"", sep = ""_""):paste(""AUS"", ""2019"", sep = ""_"")) %>%
  separate(col = year_tourn, into = c(""tournament"", ""year""), sep = ""_"") %>%
  rename(player = Player_Player) %>%
  mutate(year = as.integer(year)) %>% 
  select(-contains(""2019""))
```

```{r}

clean_men_1967_2019 <- 3:10 %>% 
  map(get_timeline_men) %>% 
  bind_rows() %>% 
  filter(year > 1967)

final_timeline_men <- clean_men_1967_2019 %>%  
  mutate(outcome = case_when(outcome == ""W"" ~ ""Won"",
                             outcome == ""F"" ~ ""Finalist"",
                             outcome == ""SF"" ~ ""Semi-finalist"",
                             outcome == ""QF"" ~ ""Quarterfinalist"",
                             outcome == ""4R"" ~ ""4th Round"",
                             outcome == ""3R"" ~ ""3rd Round"",
                             outcome == ""2R"" ~ ""2nd Round"",
                             outcome == ""1R"" ~ ""1st Round"",
                             outcome == ""RR"" ~ ""Round-robin stage"",
                             outcome == ""Q2"" ~ ""Qualification Stage 2"",
                             outcome == ""Q1"" ~ ""Qualification Stage 1"",
                             outcome == ""A"" ~ ""Absent"",
                             str_detect(outcome, ""Retired"") ~ ""Retired"",
                             outcome == ""-"" ~ NA_character_,
                             outcome == ""LQ"" ~ ""Lost Qualifier"",
                             TRUE ~ NA_character_),
         tournament = case_when(str_detect(tournament, ""AUS"") ~ ""Australian Open"",
                                str_detect(tournament, ""USA"") ~ ""US Open"",
                                str_detect(tournament, ""FRA"") ~ ""French Open"",
                                str_detect(tournament, ""WIM"") ~ ""Wimbledon"",
                                TRUE ~ NA_character_)) %>% 
  filter(!is.na(tournament)) %>% 
  mutate(gender = ""Male"")

```


```{r}
both_timeline <- bind_rows(final_timeline, final_timeline_men) %>% 
  filter(str_length(player) > 4) %>% 
  filter(year <= 2019)

anti_timeline <- both_timeline %>% 
  filter(year == 2019 & tournament != ""Australian Open"")

combined_timeline <- anti_join(both_timeline, anti_timeline)
```

```{r}
write_csv(combined_timeline, ""grand_slam_timeline.csv"")
```

","2019-15"
"535",1526,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-04-16/economist-mistakes.R","library(tidyverse)
library(here)
library(janitor)

### Brexit Raw

brexit_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_brexit.csv""))

brexit_clean <- brexit_raw %>% 
  set_names(nm = .[3,]) %>% 
  clean_names() %>% 
  slice(4:nrow(.))

brexit_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""brexit.csv""))

### corbyn

corbyn_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_corbyn.csv""))

corbyn_clean <- corbyn_raw %>% 
  set_names(nm = ""political_group"", ""avg_facebook_likes"") %>% 
  na.omit()

corbyn_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""corbyn.csv""))

### dogs

dogs_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_dogs.csv""))

dogs_clean <- dogs_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""year"", ""avg_weight"", ""avg_neck""))

dogs_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""dogs.csv""))

### EU Balance

eu_balance_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_eu-balance.csv""))


names_eu <- eu_balance_raw %>% 
  .[1,] %>% 
  as.character()

datapasta::vector_paste_vertical(names_eu)  

clean_names_eu <- c(""country"",
              ""current_2009"",
              ""current_2010"",
              ""current_2011"",
              ""current_2012"",
              ""current_2013"",
              ""current_2014"",
              ""current_2015"",
              ""budget_2009"",
              ""budget_2010"",
              ""budget_2011"",
              ""budget_2012"",
              ""budget_2013"",
              ""budget_2014"",
              ""budget_2015"")

eu_current <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""current"")) %>% 
  select(-starts_with(""budget"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_budget <- eu_balance_raw %>% 
  set_names(nm = clean_names_eu) %>% 
  filter(country != ""Country"") %>% 
  gather(year, value, starts_with(""budget"")) %>% 
  select(-starts_with(""current"")) %>% 
  separate(year, into = c(""account_type"", ""year""))

eu_balance_clean <- bind_rows(eu_current, eu_budget)

eu_balance_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""eu_balance.csv""))

### Pensions

pensions_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_pensions.csv""))

pensions_clean <- pensions_raw %>% 
  na.omit() %>% 
  set_names(nm = c(""country"", ""pop_65_percent"", ""gov_spend_percent_gdp""))

pensions_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""pensions.csv""))

### Trade

trade_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_us-trade-manufacturing.csv""))

trade_clean <- trade_raw %>% 
  set_names(nm = c(""year"", ""trade_deficit"", ""manufacture_employment"")) %>% 
  mutate(trade_deficit = trade_deficit * 1e9,
         manufacture_employment = manufacture_employment * 1e6) %>% 
  na.omit()

trade_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""trade.csv""))

### Women
women_research_raw <- read_csv(here(""2019"", ""2019-04-16"", ""Economist_women-research.csv""))

women_research_raw[1,] %>% 
  as.character() %>% 
  datapasta::vector_paste_vertical()

research_names <- c(""country"",
  ""Health sciences"",
  ""Physical sciences"",
  ""Engineering"",
  ""Computer science, maths"",
  ""Women inventores"")

women_research_clean <- women_research_raw %>% 
  na.omit() %>% 
  set_names(nm = research_names) %>% 
  filter(country != ""Country"") %>% 
  gather(field, percent_women, `Health sciences`:`Women inventores`)

women_research_clean %>% write_csv(here(""2019"", ""2019-04-16"", ""women_research.csv""))

","2019-16"
"536",1527,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-05-14/nobel_winners.R","library(tidyverse)
library(here)
library(janitor)

# read in the specific category/field datasets and the overall winners

nobel_winners <- read_csv(here(""2019"", ""2019-05-14"", ""archive.csv"")) %>% 
  janitor::clean_names() %>% 
  rename(""prize_year"" = year,
         ""gender"" = sex)

chem_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Chemistry publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""chemistry"")

med_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Medicine publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""medicine"")

physics_pubs <- read_csv(here(""2019"", ""2019-05-14"", ""Physics publication record.csv"")) %>% 
  janitor::clean_names() %>% 
  mutate(category = ""physics"")

all_pubs <- bind_rows(chem_pubs, med_pubs, physics_pubs)

all_pubs %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winner_all_pubs.csv""))

nobel_winners %>% 
  write_csv(here(""2019"", ""2019-05-14"", ""nobel_winners.csv""))




nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

nobel_winner_all_pubs %>% 
  distinct(category)","2019-20"
"537",1528,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-07-02/revenue.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/List_of_highest-grossing_media_franchises""

df <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE) %>% 
  .[[2]]

clean_money <- df %>% 
  set_names(nm = c(""franchise"", ""year_created"", ""total_revenue"", ""revenue_items"",
                   ""original_media"", ""creators"", ""owners"")) %>% 
  mutate(total_revenue = str_remove(total_revenue, ""est.""),
         total_revenue = str_trim(total_revenue),
         total_revenue = str_remove(total_revenue, ""[$]""),
         total_revenue = word(total_revenue, 1, 1),
         total_revenue = as.double(total_revenue))

clean_category <- clean_money %>% 
  separate_rows(revenue_items, sep = ""\\["") %>% 
  filter(str_detect(revenue_items, ""illion"")) %>% 
  separate(revenue_items, into = c(""revenue_category"", ""revenue""), sep = ""[$]"") %>% 
  mutate(revenue_category = str_remove(revenue_category, ""  ""),
         revenue_category = str_remove(revenue_category, regex("".*\\]"")),
         revenue_category = str_remove(revenue_category, ""\n"")) 

clean_df <- clean_category %>% 
  mutate(revenue_category = case_when(
    str_detect(str_to_lower(revenue_category), ""box office"") ~ ""Box Office"",
    str_detect(str_to_lower(revenue_category), ""dvd|blu|vhs|home video|video rentals|video sales|streaming|home entertainment"") ~ ""Home Video/Entertainment"",
    str_detect(str_to_lower(revenue_category), ""video game|computer game|mobile game|console|game|pachinko|pet|card"") ~ ""Video Games/Games"",
    str_detect(str_to_lower(revenue_category), ""comic|manga"") ~ ""Comic or Manga"",
    str_detect(str_to_lower(revenue_category), ""music|soundtrack"") ~ ""Music"",
    str_detect(str_to_lower(revenue_category), ""tv"") ~ ""TV"",
    str_detect(str_to_lower(revenue_category), ""merchandise|licens|mall|stage|retail"") ~ ""Merchandise, Licensing & Retail"",
    
    TRUE ~ revenue_category)) %>% 
  mutate(revenue = str_remove(revenue, ""illion""),
         revenue = str_trim(revenue),
         revenue = str_remove(revenue, "" ""),
         revenue = case_when(str_detect(revenue, ""m"") ~ paste0(str_extract(revenue, ""[:digit:]+""), ""e-3""),
                             str_detect(revenue, ""b"") ~ str_extract(revenue, ""[:digit:]+""),
                             TRUE ~ NA_character_),
         revenue = format(revenue, scientific = FALSE),
         revenue = parse_number(revenue)) %>%
  mutate(original_media = str_remove(original_media, ""\\[.+"")) 

sum_df <- clean_df %>%
  group_by(franchise, revenue_category) %>% 
  summarize(revenue = sum(revenue))

total_sum_df <- clean_df %>% 
  group_by(franchise) %>% 
  summarize(revenue = sum(revenue)) %>% 
  arrange(desc(revenue))

metadata_df <- clean_df %>% 
  select(franchise:revenue_category, original_media:owners, -total_revenue)

final_df <- left_join(sum_df, metadata_df, 
                      by = c(""franchise"", ""revenue_category"")) %>% 
  distinct(.keep_all = TRUE)

final_df
write_csv(final_df, ""media_franchises.csv"")
","2019-27"
"538",1529,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-07-09/wwc_cleaning.R","library(tidyverse)
library(here)

# read in the datasets
df <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""wwc_results.xlsx"")) %>% 
  mutate(Year = as.integer(Year))

df_2019 <- read_csv(here(""2019"", ""2019-07-09"", ""wwc_2019.csv""))

squads <- readxl::read_xlsx(here(""2019"", ""2019-07-09"", ""Womens Squads.xlsx"")) %>% 
  janitor::clean_names()

# bind datasets to include 2019
df_all <- bind_rows(df, df_2019) %>% 
  janitor::clean_names()

# add win, tie status
df_both <- df_all %>% 
  group_by(year) %>% 
  mutate(yearly_game_id = row_number(),
         winner = case_when(score_1 > score_2 ~ ""Team 1 Win"",
                   score_2 > score_1 ~ ""Team 2 Win"",
                   score_1 == score_2 ~ ""Tie"",
                   TRUE ~ NA_character_)) 

# grab team 1/score 1
df_team_1 <- df_both %>% 
  select(year:score_1, round, yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 1)

# grab team2/score 2
df_team_2 <- df_both %>% 
  select(year, team_2:yearly_game_id, winner) %>% 
  set_names(nm = c(""year"", ""team"", ""score"", ""round"", ""yearly_game_id"", ""winner"")) %>% 
  mutate(team_num = 2)

# attach team1/team2 datasets together
# Assign winner, loser, tie,
# Correct for shootout wins in knockout stages

df_tidy <- bind_rows(df_team_1, df_team_2) %>% 
  arrange(year, yearly_game_id) %>% 
  mutate(win_status = case_when(team_num == as.integer(str_extract(winner, ""[:digit:]"")) ~ ""Won"",
                            team == ""USA"" & round == ""Final"" & year == 1999 ~ ""Won"",
                            team == ""NOR"" & round == ""Round of 16"" & year == 2019 ~ ""Won"",
                            team == ""JPN"" & round == ""Final"" & year == 2011 ~ ""Won"",
                            team == ""CHN"" & round == ""Quarter Final"" & year == 1995 ~ ""Won"",
                            team == ""FRA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""USA"" & round == ""Quarter Final"" & year == 2011 ~ ""Won"",
                            team == ""GER"" & round == ""Quarter Final"" & year == 2015 ~ ""Won"",
                            team == ""BRA"" & round == ""Third Place Playoff"" & year == 1999 ~ ""Won"",
                            round == ""Group"" & winner == ""Tie"" ~ ""Tie"",
                            TRUE ~ ""Lost"")) %>% 
  select(-winner)

# confirm no double winners/losers
df_tidy %>% 
  filter(round != ""Group"") %>% 
  group_by(year, round, yearly_game_id) %>% 
  count(win_status, sort = TRUE) %>% 
  filter(n >1)

# output to csv
df_tidy %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""wwc_outcomes.csv""))

squads %>% 
  write_csv(here(""2019"", ""2019-07-09"", ""squads.csv""))


# data dictionaries for TidyTuesday
tomtom::create_dictionary(df_tidy)
tomtom::create_dictionary(squads)
","2019-28"
"539",1530,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-09-03/moores_law.R","library(tidyverse)
library(rvest)

url <- ""https://en.wikipedia.org/wiki/Transistor_count""

tables <- url %>% 
  read_html() %>% 
  html_table(fill = TRUE)

df1 <- tables %>% chuck(1) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df1_clean <- df1 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = str_sub(date_of_introduction, 1, 4),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
    ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)


df1_clean %>%
  mutate() 
df2 <- tables %>% chuck(2) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df2_clean <- df2 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+"")
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double)

df3 <- tables %>% chuck(4) %>% 
  janitor::clean_names() %>% 
  as_tibble()

df3

df3_clean <- df3 %>% 
  mutate(
    # transistor_count = gsub(""\\[[^\\]]*\\]"", """", transistor_count, perl=TRUE),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""\\[[^\\]]*\\]""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_remove(transistor_count, ""[:punct:]+""),
    transistor_count = str_extract(transistor_count, ""[:digit:]+""),
    date_of_introduction = if_else(
      str_length(date_of_introduction) >= 5,
      str_sub(date_of_introduction, -4),
      str_sub(date_of_introduction, 1, 4)),
    process = str_remove(process, "",""),
    process = str_extract(process, ""[:digit:]+""),
    area = str_extract(area, ""[:digit:]+""),
    bit_units = case_when(
      str_detect(capacity_bits, ""bit"") ~ ""Bits"",
      str_detect(capacity_bits, ""kb"") ~ ""kb"",
      str_detect(capacity_bits, ""Mb"") ~ ""Mb"",
      str_detect(capacity_bits, ""Gb"") ~ ""Gb"",
      TRUE ~ """"
                 )
  ) %>% 
  mutate_at(.vars = vars(transistor_count:date_of_introduction, process:area), as.double) %>% 
  select(chip_name, capacity_bits, bit_units, everything()) %>% 
  mutate(capacity_bits = str_extract(capacity_bits, ""[:digit:]+""))

df3_clean

write_csv(df1_clean, here::here(""2019"", ""2019-09-03"", ""cpu.csv""))
write_csv(df2_clean, here::here(""2019"", ""2019-09-03"", ""gpu.csv""))
write_csv(df3_clean, here::here(""2019"", ""2019-09-03"", ""ram.csv""))

tomtom::create_dictionary(df1_clean)

cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")
gpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")
ram <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")

","2019-36"
"540",1531,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-09-17/parks.R","library(tidyverse)
library(rvest)

df_raw <- read_csv(here::here(""2019/2019-09-17/All National Parks Visitation 1904-2016.csv"")) 

df <- df_raw %>% 
  janitor::clean_names() %>%
  mutate(date = lubridate::mdy_hms(year)) %>% 
  select(date, gnis_id, geometry:year_raw)

df %>% 
  write_csv(here::here(""2019/2019-09-17/national_parks.csv""))


# Get pop data

url <- ""https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_historical_population""

raw_html <- url %>% 
  read_html() %>% 
  html_table()

pop_df <- raw_html %>% 
  chuck(5) %>% 
  gather(key = ""state"", value = ""pop"", AL:DC) %>% 
  rename(""year"" = 1) %>% 
  mutate(pop = str_remove_all(pop, "",""),
         pop = as.double(pop))

pop_df %>% 
  write_csv(here::here(""2019/2019-09-17"", ""state_pop.csv""))

# Get gas prices

url2 <- ""https://www.energy.gov/eere/vehicles/fact-915-march-7-2016-average-historical-annual-gasoline-pump-price-1929-2015""

raw_gas <- url2 %>% 
  read_html() %>% 
  html_table()

gas <- raw_gas %>% 
  chuck(1) %>% 
  set_names(nm = c(""year"", ""gas_current"", ""gas_constant"")) %>%   
  as_tibble() %>% 
  filter(!str_detect(year, ""Source"")) %>% 
  mutate(year = as.double(year),
         gas_current = as.double(gas_current),
         gas_constant = as.double(gas_constant))

gas %>% 
  write_csv(here::here(""2019/2019-09-17"", ""gas_price.csv""))
","2019-38"
"541",1532,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-09-24/RLA_solution.Rmd","---
title: ""TidyTuesday_9_24_19""
author: ""Stephanie Reinders""
date: ""9/24/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Load the data
```{r}
d <- read.csv('school_diversity.csv')
```

## Explore the data
```{r}
str(d)
```

```{r}
head(d)
```



```{r}
d %>% filter(SCHOOL_YEAR=='2016-2017') %>% group_by(SCHOOL_YEAR,ST,) %>% summarize(nasian = mean(Asian)) %>% arrange(desc(nasian))
```

## Gather racial group data into a single column
```{r}
d <- d %>% gather(""racial_group"",""value"",6:11)
```


```{r}
d %>% filter(SCHOOL_YEAR=='2016-2017') %>% group_by(racial_group,ST) %>% summarize(mean = mean(value))
```


","2019-39"
"542",1533,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-10-08/RLA_10_8_19_meeting.Rmd","---
title: ""RLA_10_8_19""
author: ""Stephanie Reinders""
date: ""10/8/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r}
d <- data.frame('ipf_lifts.csv')

```



","2019-41"
"543",1534,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-10-15/RLA_10_15_19.Rmd","---
title: ""RLA_10_15_19""
author: ""Stephanie Reinders""
date: ""10/15/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r get_data}
d <- read.csv('big_epa_cars.csv')
```

```{r basic_info}
dim(d)
str(d)
```

```{r explore_makes_and_models}

allmakes <- unique(d$make) %>% sort() 

d %>% 
  group_by(make,model,year) %>%
  select(make,model,year)

```

```{r}
t <- d %>% 
  filter(make==""Toyota"", model==""Corolla"") %>%
  select(year,make,model,trany,id,displ,youSaveSpend)

t_auto_1.6 <- t %>% filter(trany==""Automatic 4-spd"",displ==1.6)
```

```{r}
t %>% ggplot(aes(year,youSaveSpend,group=interaction(trany,displ),color=interaction(trany,displ))) +
  geom_point() +
  geom_hline(yintercept=0, linetype=""dashed"", color = ""red"") +
  ylab(""youSaveSpend ($)"") +
  labs(color=""transmition and engine displacement"")
```


```{r}
t %>% 
  filter(trany %in% c(""Automatic 3-spd"",""Automatic 4-spd"",""Automatic (AV-S10)"",""Automatic (S5)"",""Automatic (variable gear ratios)"")) %>%
      ggplot(aes(year,youSaveSpend)) +
        geom_point() +
        geom_hline(yintercept=0, linetype=""dashed"", color = ""red"") +
        facet_wrap(trany~displ) +
        ylab(""youSaveSpend ($)"") +
        theme(legend.position = ""none"")
```","2019-42"
"544",1535,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-10-22/RLA_10_22_19.Rmd","---
title: ""RLA_10_22_19""
author: ""Stephanie Reinders""
date: ""10/22/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

```{r}
d <- read.csv('horror_movies.csv')
```

```{r}
summary(d)
```

```{r}
d %>% filter(language == ""Japanese"") %>% 
  ggplot(aes(review_rating)) +
  geom_histogram(binwidth=1)
```

```{r}
d2 <- separate(d,language, into = c(""language1"",""language2""), extra = ""merge"")
```

```{r}
rating <- d2 %>%
  group_by(language1) %>%
  summarize(n=n(),
            mean_rating = mean(review_rating))
rating
``` 

```{r}
d2 %>% filter(language1==""English"") %>%
  select(review_rating)
```



```{r}  
rating %>% 
  ggplot(aes(language1,mean_rating,fill=mean_rating)) +
  geom_bar(stat=""identity"",position=""dodge"") + 
  coord_flip()
```


","2019-43"
"545",1536,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-11-05/RLA_11_5_19.Rmd","---
title: ""RLA_11_5_19""
author: ""Stephanie Reinders""
date: ""11/5/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Data on Bicycling and Walking to Work in the US
```{r}
d <- read.csv('commute.csv')
```

```{r}
summary(d)
```

## Iowa Bicyclists and Walkers
```{r}
d %>% filter(state=='Iowa',mode=='Bike') %>% 
  ggplot(aes(x=as.factor(city),y=percent,color=city)) +
  geom_point() +
  coord_flip()
```


```{r}
d %>% filter(state=='Iowa',mode=='Walk') %>% 
  ggplot(aes(x=as.factor(city),y=percent,color=city)) +
  geom_point() +
  coord_flip()
```


","2019-45"
"546",1537,"https://github.com/rladies-ames/tidytuesday","rladies-ames","tidytuesday","data/2019/2019-11-05/bike_walk.R","# Load Packages -----------------------------------------------------------

library(tidyverse)
library(readxl)
library(here)
library(glue)
library(janitor)

# Read in Data ------------------------------------------------------------

table_num <- 1:6

# Generic read function for this dataset

supp_read <- function(number, ...){
  read_excel(here(""2019"", ""2019-11-05"", glue::glue(""supplemental-table{number}.xlsx"")), ...)
}

# 3 datasets for bikes, each of which has a corresponding City Size

small_bike <- supp_read(1, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"", 
         percentage_of_workers = as.numeric(percentage_of_workers),
         margin_of_error_2 = as.numeric(margin_of_error_2))

medium_bike <- supp_read(2, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_bike <- supp_read(3, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_bike <- bind_rows(small_bike, medium_bike, large_bike) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Bike"")


# 3 datasets for walking, each of which has a corresponding City Size

small_walk <- supp_read(4, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Small"")

medium_walk <- supp_read(5, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Medium"")

large_walk <- supp_read(6, skip = 5) %>% 
  clean_names() %>% 
  mutate(city_size = ""Large"")

# Combine datasets

full_walk <- bind_rows(small_walk, medium_walk, large_walk) %>% 
  set_names(nm = c(""city"", ""n"", ""percent"", ""moe"", ""city_size"")) %>% 
  mutate(mode = ""Walk"")

# Built in state-level datasets
state_df <- tibble(
  state = state.name,
  state_abb = state.abb,
  state_region = as.character(state.region)
)

# Combine bike and walk data in tidy setup

full_commute <- 
  bind_rows(full_bike, full_walk) %>% 
  filter(!is.na(n),
         # There are some government-related areas that don't align with cities
         !str_detect(tolower(city), ""government|goverment"")) %>% 
  separate(city, into = c(""city"", ""state""), sep = "", "") %>% 
  select(city, state, city_size, mode, everything()) %>% 
  left_join(state_df, by = c(""state""))

full_commute %>% 
  write_csv(here(""2019"", ""2019-11-05"", ""commute.csv""))

# ACS Data ----------------------------------------------------------------

acs_data <- read_csv(here(""2019"", ""2019-11-05"", ""table_3.csv""))

age_data <- acs_data %>% 
  slice(1:6)

gender_data <- acs_data %>% 
  slice(9:10) %>% 
  rename(""gender"" = age)

race_data <- acs_data %>% 
  slice(13:18) %>% 
  rename(""race"" = age)

children_data <- acs_data %>% 
  slice(20:24) %>% 
  rename(""children"" = age)

income_data <- acs_data %>% 
  slice(27:36) %>% 
  rename(""income"" = age)

education_data <- acs_data %>% 
  slice(39:43) %>% 
  rename(""education"" = age)

","2019-45"
"547",1538,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-15/space_shuttle.Rmd","trevinflick","tidytuesday","2019-01-15/space_shuttle.Rmd","---
title: ""Space Launches""
author: ""Trevin Flickinger""
date: ""1/16/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggthemes)

launches <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv"")

agencies <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/agencies.csv"")
```

```{r}
launches %>%
  count(type, sort = TRUE)
```

Let's take a look at the Space Shuttle

```{r}
space_shuttle <- launches %>%
  filter(type == ""Space Shuttle"")

space_shuttle <- space_shuttle %>%
  arrange(launch_date)

space_shuttle$launch_number <- c(1:135)
```

```{r}
days_between_launches <- tail(space_shuttle$launch_date, -1) - head(space_shuttle$launch_date, -1)

space_shuttle$days_til_next <- c(tail(space_shuttle$launch_date, -1) - head(space_shuttle$launch_date, -1), 0)

space_shuttle %>%
  filter(days_til_next > 0) %>%
  ggplot(aes(days_til_next)) +
  geom_freqpoly()

```

```{r}
space_shuttle %>%
  ggplot(aes(x = launch_date, y = launch_number)) +
  geom_line(size = 0.5) +
  geom_point() +
  annotate(""text"", x=as.Date(""1986-01-28""), y=40, 
           label = ""Challenger disaster"", size = 3.5) +
  annotate(""segment"", x=as.Date(""1986-01-28""), 
           xend=as.Date(""1986-01-28""),
           y=25, yend = 36, color = ""black"") +
  annotate(""text"", x=as.Date(""2003-01-16""), y=125, 
           label = ""Columbia disaster"", size = 3.5) +
  annotate(""segment"", x=as.Date(""2003-01-16""), 
           xend=as.Date(""2003-01-16""),
           y=113, yend = 121, color = ""black"") +
  labs(title = ""Space Shuttle Launches Over Time"",
       caption = ""TidyTuesday 01/08/2019, source:The Economist"") +
  theme_fivethirtyeight()
  
ggsave(""space_shuttle.png"")
  
```


","2019-3"
"548",1539,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-29/cheeses.R","trevinflick","tidytuesday","2019-01-29/cheeses.R","library(tidyverse)
library(gganimate)
library(ggthemes)

milk <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/state_milk_production.csv"")
cheese <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/clean_cheese.csv"")

cheese %>% 
  summarise_at(vars(2:13), sum, na.rm = TRUE) %>%
  gather(cheese, amount) %>%
  arrange(desc(amount))

## Make an 'other' category

cheese$Other <- rowSums(cheese[,c(""Other Dairy Cheese"", ""Muenster"", ""Blue"", ""Brick"",
                                  ""Swiss"", ""Cream and Neufchatel"")], na.rm = TRUE)

cheese %>% 
  select(Year,
         Cheddar,
         ""American"" = ""American Other"",
         Mozzarella,
         ""Italian"" = ""Italian other"",
         ""Processed"" = ""Processed Cheese"",
         ""Spreads"" = ""Foods and spreads"",
         Other) %>%
  gather(cheese, amount, -Year) %>%
  ggplot(aes(x = Year, y = amount, group = cheese)) +
  geom_path() +
  geom_text(aes(label = cheese), 
            nudge_x = 1,
            nudge_y = 0.3) +
  labs(x = """", y = ""Average Consumption in Pounds per Person"",
       title = ""What's causing Mozzarella's rise in consumption?"",
       subtile = ""Average American cheese consumption 1970-2017"",
       caption = ""TidyTuesday 01/29/19 source:USDA"") +
  theme_light() +
  transition_reveal(along = Year) +
  ease_aes('linear')

anim_save(""cheese.gif"", last_animation())
","2019-5"
"549",1540,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-09","trevinflick","tidytuesday","2018-10-09/plot.R","# install rstan and rethinking packages

# install.packages(""rstan"", repos = ""https://cloud.r-project.org/"", dependencies=TRUE)
# install.packages(c(""coda"",""mvtnorm"",""devtools"",""loo""))
# library(devtools)
# devtools::install_github(""rmcelreath/rethinking"")

library(rstan)
library(readr)
library(ggplot2)
library(dplyr)
library(tidyverse)
library(rethinking)
library(ggthemes)

turnout <- read_csv(""voter_turnout.csv"")

turnout$pct <- turnout$votes / turnout$eligible_voters

# create new column if year is a midterm
midterm <- c(1982, 1986, 1990, 1994, 1998, 2002, 2006, 2010, 2014)
turnout$midterm <- ifelse(turnout$year %in% midterm, 1, 0)

us <- turnout %>%
  filter(state == ""United States"") %>%
  select(year, us_pct = pct)

turnout <- left_join(turnout, us, by = ""year"") %>%
  filter(year >= 1998)

# find the states with na values
state_na <- turnout %>%
  filter(is.na(votes))

# lag variable
turnout <- turnout %>%
  arrange(state, year) %>%
  group_by(state) %>%
  mutate(last_vote = lag(pct, n = 2))

# let's impute the missing data for minnesota
minnesota <- turnout %>%
  filter(state == ""Minnesota"")

# prep data
data_list <- list(
  usa = minnesota$us_pct,
  last_vote = minnesota$last_vote,
  pct = minnesota$pct
)

# model for missing data
m <- map2stan(
  alist(
    usa ~ dnorm(mu,sigma),
    mu <- a + bP*pct +bL*last_vote,
    pct ~ dnorm(nu,sigma_N),
    last_vote ~ dnorm(nu,sigma_N),
    a ~ dnorm(0,100),
    bP ~ dnorm(0,10),
    bL ~ dnorm(0,10),
    nu ~ dnorm(0.5,1),
    sigma_N ~ dcauchy(0,1),
    sigma ~ dcauchy(0,1)
  ),
  data = data_list, iter = 1e4, chains = 2
)

# extract imputed means
# precis(m, depth=2)

# drop columns from data frame
turnout <- turnout %>%
  select(year, state, pct)

imputed <- tibble(
  year = c(2000, 2002, 2004),
  state = c(""imp"", ""imp"", ""imp""),
  votes = c(2458303, NA, 2842912),
  eligible_voters = c(3506432, 3518184, 3609185),
  imputed_mean = c(NA, 0.57, NA),
  imputed_std = c(NA, 0.05, NA)
)

imputed$pct <- imputed$votes / imputed$eligible_voters
imputed <- imputed %>% replace_na(list(pct = 0.57))

imputed <- imputed %>%
  select(year, state, pct)

turnout <- rbind(turnout, imputed)

turnout %>%
  ggplot(aes(x = year, y = pct, group = state)) +
  geom_line(alpha = 0.15) +
  geom_line(data = filter(turnout, state == ""imp""), aes(x = year, y = pct), color = ""blue"", size = 1, linetype = 3) +
  geom_line(data = filter(turnout, state == ""United States""), aes(x = year, y = pct), color = ""black"", size = 1) +
  geom_line(data = filter(turnout, state == ""Minnesota""), aes(x = year, y = pct), color = ""blue"", size = 1) + 
  scale_x_continuous(limits = c(1998,2016), breaks = c(2000, 2004, 2008, 2012)) +
  scale_y_continuous(limits = c(0,1), labels = scales::percent) +
  geom_text(data = filter(turnout, year == 2014 & state == ""United States""),
            aes(label = state, x = year + 1.45, y = pct), size = 3.5, color = ""black"") +
  geom_text(data = filter(turnout, year == 2014 & state == ""Minnesota""),
            aes(label = state, x = year + 1.25, y = pct), size = 3.5, color = ""blue"") +
  annotate(geom = ""text"", x = 2012, y = 0.80, label = ""Presidential election"", size = 3.5) +
  annotate(geom = ""text"", x = 2010, y = 0.27, label = ""Midterm election"", size = 3.5) +
  labs(x = """", y = """", title = ""United States Voter Turnout: 1998-2014"",
       subtitle = ""Minnesota turnout imputed for 2002 election"",
       caption = ""TidyTuesday 10/09/18, source:data.world"") +
  theme_fivethirtyeight()
  
  





  



","2018-41"
"550",1541,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-16","trevinflick","tidytuesday","2018-10-16/college_majors.R","library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(ggthemes)

# read in the data
all_ages <- read_csv(""all-ages.csv"")
grad_students <- read_csv(""grad-students.csv"")
majors_list <- read_csv(""majors-list.csv"")
recent_grads <- read_csv(""recent-grads.csv"")
women_stem <- read_csv(""women-stem.csv"")

# drop missing values
recent_grads <- recent_grads %>%
  drop_na(Total)

# earnings by major category
recent_grads %>%
  group_by(Major_category) %>%
  summarize(
    count = n(),
    earnings = mean(Median),
    Max = max(Median)
  )

# filter out major categories with < 8 majors
big_category <- recent_grads %>%
  filter(Major_category != ""Interdisciplinary"" &
           Major_category != ""Communications & Journalism"" &
           Major_category != ""Law & Public Policy"" &
           Major_category != ""Industrial Arts & Consumer Services"") 

# plot
big_category %>%
  ggplot(aes(x = reorder(Major_category, -Median, mean),
             y = Median)
         ) +
  geom_dotplot(binaxis = ""y"", stackdir = ""center"", 
               dotsize = 0.5) +
  stat_summary(fun.y=mean, geom=""point"", shape = 18,
               size=3, color=""red"") +
  geom_text(data = filter(big_category, Major == ""PETROLEUM ENGINEERING""),
            aes(label = ""Petroleum Engineering""), size = 3, 
            hjust = -0.05, vjust = 0.3) +
  geom_text(data = filter(big_category, Major == ""PETROLEUM ENGINEERING""),
            aes(label = ""($110,000)""), size = 3, 
            hjust = -0.55, vjust = 2.5) +
  geom_text(data = filter(big_category, Major_category == ""Arts"" &
                            Median == 50000),
            aes(label = ""Miscellaneous Fine Arts""), size = 3, 
            hjust = -0.05, vjust = 0.3) +
  geom_text(data = filter(big_category, Major_category == ""Physical Sciences"" &
                            Median == 62000),
            aes(label = ""Astronomy and Astrophysics""), size = 3, 
            hjust = -0.05, vjust = 0.3) +
  labs(x = """", y = """",
       title = ""Earnings for Recent College Grads"",
       caption = ""TidyTuesday 10/16/18, source:fivethirtyeight"") +
  theme_fivethirtyeight() +
  theme(text = element_text(size = 10),
        axis.text.x = element_text(angle = 60, hjust = 1)) 









","2018-42"
"551",1542,"https://github.com/trevinflick/tidytuesday/blob/master/2019-03-26/seattle-pet-names.Rmd","trevinflick","tidytuesday","2019-03-26/seattle-pet-names.Rmd","---
title: ""Pet Names""
author: ""Trevin Flickinger""
date: ""3/26/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(ggthemes)
library(kableExtra)

seattle_pets <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")

seattle_pets$license_issue_date <- as.Date(seattle_pets$license_issue_date,
                                           ""%B %d %Y"")

seattle_pets$animals_name <- str_replace(seattle_pets$animals_name, "" \\(.*\\)"", """")
seattle_pets$animals_name <- str_replace(seattle_pets$animals_name, "" \\\"".*\\\"""", """")
seattle_pets$animals_name <- str_replace(seattle_pets$animals_name, "" \\\'.*\\\'"", """")

seattle_pets$name_length <- nchar(seattle_pets$animals_name)

pets_2018 <- seattle_pets %>% filter(year(license_issue_date) == 2018)
```

# Most popular names

```{r}
top_names <- pets_2018 %>% drop_na(animals_name) %>%
  count(animals_name, sort = TRUE) %>%
  head(20)
```

```{r}
top_names %>% 
  mutate(animals_name = fct_reorder(animals_name, n)) %>%
  ggplot() +
  geom_col(aes(x = animals_name, y = n)) +
  coord_flip() +
  labs(title = ""Most popular pet names in Seattle in 2018"",
       x = """", y = """") +
  theme_light()
```

# Most popular dog names

```{r}
dogs_2018 <- pets_2018 %>% drop_na(animals_name) %>%
  filter(species == ""Dog"")

top_dogs <- dogs_2018 %>%
  count(animals_name, sort = TRUE)
```

# Most popular cat names

```{r}
cats_2018 <- pets_2018 %>% drop_na(animals_name) %>%
  filter(species == ""Cat"")

top_cats <- cats_2018 %>%
  count(animals_name, sort = TRUE)
```


```{r}
top_dogs %>% 
  mutate(animals_name = fct_reorder(animals_name, n)) %>%
  head(20) %>%
  ggplot() +
  geom_col(aes(x = animals_name, y = n)) +
  coord_flip() +
  labs(title = ""Most popular dog names in Seattle in 2018"",
       x = """", y = """") +
  theme_light()
```

# Dogs names that end in y or ie

```{r}
dogs_y_ie <- dogs_2018[(str_ends(dogs_2018$animals_name, ""y"") |
          str_ends(dogs_2018$animals_name, ""ie"")), ]
```

# Cats that end in y or ie

```{r}
cats_y_ie <- cats_2018[(str_ends(cats_2018$animals_name, ""y"") |
          str_ends(cats_2018$animals_name, ""ie"")), ]
```

# 24% of cats and 30% of dogs end in y or ie

```{r}
dogs_y_ie %>% count(animals_name, sort = TRUE) %>% View()
cats_y_ie %>% count(animals_name, sort = TRUE) %>% View()
```

# comparing fenway vs wrigley

```{r}
pets_2018 %>% filter(animals_name == ""Fenway"" | 
                       animals_name == ""Wrigley"") %>%
  ggplot(aes(animals_name)) +
  geom_bar(aes(fill = animals_name)) +
  scale_fill_manual(values = c(""#BD3039"",""#0E3386""), guide = FALSE) +
  coord_flip() +
  labs(x = """", y = """",
       title = ""Pets in Seattle named after ballparks"",
       caption = ""@trevin_flick"") +
  theme_fivethirtyeight()
  
ggsave(""mlb-pets.png"")
```


# 10 longest dog names

```{r}
dogs_2018 %>% arrange(desc(name_length)) %>%
  head(10) %>%
  kable() %>% 
  kable_styling()
```

```{r}
cats_2018 %>% arrange(desc(name_length)) %>%
  head(10) %>%
  kable() %>% 
  kable_styling()
```


### Extra code


# Most popular cat names

```{r}
top_cats <- pets_2018 %>% filter(species == ""Cat"") %>% 
  drop_na(animals_name)
```

# Duplicate license numbers

```{r}
pets_2018 %>% 
  group_by(license_number) %>% 
  filter(n() > 1) %>%
  arrange(license_number) %>%
  View()
```

# Most popular type of pet

```{r}
pets_2018 %>% drop_na(species) %>%
  count(species, sort = TRUE)
```




","2019-13"
"552",1543,"https://github.com/trevinflick/tidytuesday/blob/master/2019-02-19/us_phd.Rmd","trevinflick","tidytuesday","2019-02-19/us_phd.Rmd","---
title: ""TidyTuesday Week 8""
author: ""Trevin Flickinger""
date: ""2/19/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)

phd_field <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")
```

```{r}
phd_field %>%
  group_by(field) %>%
  summarize(sd_phd = sd(n_phds, na.rm = TRUE)) %>%
  arrange(desc(sd_phd)) %>%
  View()

phd_field %>%
  group_by(year) %>%
  summarise(total_phd = sum(n_phds, na.rm = TRUE)) %>%
  ggplot(aes(year, total_phd)) +
  geom_line(size = 1.5, color = ""blue"") +
  scale_x_continuous(breaks = seq(2008, 2016, by = 4)) +
  labs(x = """", y = """", 
       title = ""Total number of PhD's awarded in the US per year"",
       subtitle = ""Data from 2008-2017 via NSF"") +
  theme_fivethirtyeight()
```

```{r}
ggsave(""total_phds.png"")
```


```{r}
phd_field %>%
  group_by(broad_field, year) %>%
  summarise(total_phd = sum(n_phds, na.rm = TRUE)) %>%
  ggplot(aes(year, total_phd, color = broad_field)) +
  geom_line(size = 1.5) +
  scale_x_continuous(breaks = seq(2008, 2016, by = 4)) +
  labs(x = """", y = """", 
       title = ""Total number of PhD's awarded in the US per year"",
       subtitle = ""Data from 2008-2017 via NSF"")
```

```{r}
phd_field %>%
  group_by(field, year) %>%
  summarise(total_phd = sum(n_phds, na.rm = TRUE)) %>%
  filter(field %in% c(""Social sciences"", ""Physics"", ""Computer science"", ""Clinical psychology"", ""Other economics"")) %>%
  ggplot(aes(year, total_phd, color = field)) +
  geom_point() +
  geom_line(size = 1.5) +
  scale_x_continuous(breaks = seq(2008, 2016, by = 4)) +
  labs(x = """", y = """", 
       title = ""Total number of PhD's awarded in the US per year"",
       subtitle = ""Data from 2008-2017 via NSF"")
```

```{r}

```

","2019-8"
"553",1544,"https://github.com/trevinflick/tidytuesday/blob/master/2019-03-05/women_workers.Rmd","trevinflick","tidytuesday","2019-03-05/women_workers.Rmd","---
title: ""tidy tuesday march 5""
author: ""Trevin Flickinger""
date: ""3/5/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(scales)
library(ggthemes)

jobs_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")

jobs_2016 <- jobs_gender %>% filter(year == 2016)
```

# Top 20 occupations by percent of female workers

```{r}
jobs_2016 %>% select(occupation, percent_female, workers_female, total_earnings, total_earnings_female) %>% 
  arrange(desc(percent_female)) %>%
  top_n(20, wt = percent_female)
```

# Top 20 occupations by percent of male workers

```{r}
jobs_2016 %>% 
  mutate(percent_male = 100 - percent_female) %>%
  select(occupation, percent_male, workers_male, total_earnings, total_earnings_male) %>% 
  arrange(desc(percent_male)) %>%
  top_n(20, wt = percent_male)
```

# Jobs where female workers earn more compared to men

```{r}
jobs_2016 %>% mutate(pay_diff = total_earnings_female - total_earnings_male) %>% 
  filter(total_earnings_female > total_earnings_male) %>% 
  View()
```


```{r}
employed_gender <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"")
```

```{r}
employed_gender %>%
  mutate(last_year_female = lag(full_time_female),
         last_year_male = lag(full_time_male),
         female_delta = full_time_female - last_year_female,
         male_delta = full_time_male - last_year_male) %>%
  View()
```


```{r}
employed_gender %>%
  ggplot(aes(year)) + 
  geom_line(aes(y = full_time_male, color = ""blue"")) +
  geom_line(aes(y = full_time_female, color = ""red"")) +
  geom_line(aes(y = total_full_time, color = ""black"")) +
  scale_y_continuous(labels = function(x) paste0(x, ""%"")) +
  scale_color_manual(name = """",
                     values = c(""red""=""red"",""blue""=""blue"",""black""=""black""),
                     labels = c(""Total"",""Male"",""Female"")) +
  labs(title = ""Percent of full time workers from 1968-2016"",
       x="""", y="""", caption = ""source: Census Bureau"") +
  annotate(""rect"", xmin = 1993, xmax = 1994, ymin = 70, ymax = 93,
        alpha = .2) +
  theme_fivethirtyeight()
```

```{r}
ggsave(""pct_workers.png"")
```


```{r}
employed_gender %>%
  ggplot(aes(year)) + 
  geom_line(aes(y = part_time_male, color = ""blue"")) +
  geom_line(aes(y = part_time_female, color = ""red"")) +
  scale_y_continuous(labels = function(x) paste0(x, ""%"")) +
  scale_color_manual(name = ""Gender"",
                     values = c(""red""=""red"",""blue""=""blue""),
                     labels = c(""Male"",""Female"")) +
  labs(title = ""Percent of part time workers from 1968-2016"",
       x="""", y="""") +
  theme_fivethirtyeight()
```


```{r}
earnings_female <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"")
```

```{r}
earnings_female %>%
  ggplot(aes(Year, percent, color = group)) +
  geom_line(size = ifelse(earnings_female$group == ""25-34 years"", 1.5, 1.0))
```





","2019-10"
"554",1545,"https://github.com/trevinflick/tidytuesday/blob/master/2019-02-05/home_price_index.Rmd","trevinflick","tidytuesday","2019-02-05/home_price_index.Rmd","---
title: ""Housing Info""
author: ""Trevin Flickinger""
date: ""2/4/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(prophet)
library(ggthemes)

hpi <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")
```

How do the states compare?

```{r}
# Max
hpi %>% group_by(state) %>%
  summarise(max_hpi = max(price_index)) %>%
  arrange(desc(max_hpi))

# Median
hpi %>% group_by(state) %>%
  summarise(avg_hpi = median(price_index)) %>%
  arrange(desc(avg_hpi)) %>%
  View()

# Mean
hpi %>% group_by(state, year) %>%
  summarise(avg_hpi = median(price_index)) %>%
  arrange(desc(avg_hpi)) %>%
  View()
```

```{r}
hpi_year <- hpi %>%
  group_by(state, year) %>%
  summarise(avg_hpi = mean(price_index))

us_year <- hpi %>%
  group_by(year) %>%
  summarise(avg_hpi = mean(us_avg))
```


# Let's do some plots

```{r}
hpi_year %>%
  ggplot() + 
  geom_line(aes(x = year, y = avg_hpi)) +
  facet_wrap( ~ state)
  
```

```{r}
midwest <- c(""OH"", ""MI"", ""IN"", ""IL"", ""WI"", ""MN"", ""ND"", ""SD"", ""NE"", ""KS"", ""MO"", ""IA"")

hpi_year %>%
  filter(state %in% midwest) %>%
  ggplot() + 
  geom_line(aes(x = year, y = avg_hpi)) +
  facet_wrap( ~ state) +
  labs(title = ""Midwest U.S. Price Index"")
```

Okay, let's do some predictions

```{r}
state_m <- hpi %>%
  mutate(year_month = as.Date(""0000-01-01"") + years(year) + months(month - 1)) %>%
  select(ds = year_month, state, y = price_index) %>%
  nest(-state) %>% 
  mutate(m = map(data, prophet))

state_future <- state_m %>%
  mutate(future = map(m, make_future_dataframe, periods = 120, freq = ""month""))

state_forecast <- state_future %>%
  mutate(forecast = map2(m, future, predict))

tidy_forecast <- state_forecast %>%
  unnest(forecast)

state_forecast %>%
  unnest(data) %>%
  ggplot() + 
  geom_line(aes(ds, y)) + 
  geom_ribbon(data = tidy_forecast, aes(as.Date(ds), ymin = yhat_lower, ymax = yhat_upper)) +
  facet_wrap( ~ state, scales = ""free_y"") 
```

```{r}
mw <- state_forecast %>%
  unnest(data) %>%
  filter(state %in% midwest)

mw_forecast <- tidy_forecast %>%
  filter(state %in% midwest)

mw$state <- state.name[match(mw$state,state.abb)]
mw_forecast$state <- state.name[match(mw_forecast$state,state.abb)]

mw %>%
  ggplot() + 
  geom_line(aes(ds, y)) + 
  geom_ribbon(data = mw_forecast, aes(as.Date(ds), ymin = yhat_lower, ymax = yhat_upper), alpha = 0.3,
              fill = ""blue"") +
  facet_wrap( ~ state, scales = ""free_y"") +
  labs(x = """", y = """", 
       title = ""Forecasted Midwest House Price Index"",
       subtitle = ""based on Freddie Mac data 1975-2018"") +
  theme_fivethirtyeight()
```

```{r}
mw %>%
  ggplot() + 
  geom_line(aes(ds, y)) + 
  geom_ribbon(data = mw_forecast, aes(as.Date(ds), ymin = yhat_lower, ymax = yhat_upper), alpha = 0.3,
              fill = ""blue"") +
  facet_wrap( ~ state, scales = ""free_y"") +
  labs(x = """", y = """", 
       title = ""Forecasted Midwest House Price Index"",
       subtitle = ""based on Freddie Mac data 1975-2018"") +
  theme_fivethirtyeight()

ggsave(""midwest_hpi.png"", plot = last_plot())
```


","2019-6"
"555",1546,"https://github.com/trevinflick/tidytuesday/tree/master/2019-03-12","trevinflick","tidytuesday","2019-03-12/board-games.Rmd","---
title: ""Board Games""
author: ""Trevin Flickinger""
date: ""3/13/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggthemes)
board_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")
```

# Do board games ratings change based on published date?

```{r}
board_games %>%
  group_by(year_published) %>%
  summarise(total = n(),
            total_ratings = sum(users_rated),
            average_ratings = sum(users_rated * average_rating) / sum(users_rated)) %>%
  filter(total > 20) %>%
  ggplot(aes(x = year_published, y = average_ratings)) +
  geom_point(aes(size = total)) +
  labs(x = ""Year Published"",
       y = ""Average Rating"",
       title = ""Board Games are getting better over time"",
       subtitle = ""based on years with at least 20 games"",
       size = ""Total games"",
       caption = ""Data source: Board Game Geek, by: @trevin_flick"") +
  theme_light()
```

```{r}
ggsave(""board-games.png"")
```


```{r}
board_games %>% 
  ggplot(aes(x = users_rated, y = average_rating)) +
  geom_point() +
  labs(x = ""Number of user ratings"",
         y = ""Average rating"",
         title = ""Good games have more ratings"")
```


```{r}
board_games %>%
  filter(playing_time < 1440) %>%
  ggplot(aes(x = playing_time, y = average_rating)) +
  geom_point() +
  labs(x = ""Playing time"",
         y = ""Average rating"",
         title = """")
```


# Let's look at how mechanics of a game effect the rating

```{r}
board_games_tidy <- board_games %>%
  separate(mechanic, sep = "","", into = paste(""mechanic"", 1:17, sep = ""_""))
```

```{r}
mechanics <- board_games_tidy %>%
  gather(game, name, mechanic_1:mechanic_17, na.rm = TRUE)
```

```{r}
mechanics %>%
  group_by(name) %>%
  summarise(total = n(),
            total_ratings = sum(users_rated),
            average_ratings = sum(users_rated * average_rating) / sum(users_rated)) %>%
  arrange(desc(total_ratings)) %>%
  View()
```



","2019-11"
"556",1547,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-23","trevinflick","tidytuesday","2018-10-23/movies.Rmd","---
title: ""#TidyTuesday: Horror Movies and Profit""
author: ""Trevin Flickinger""
date: ""10/23/2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(scales)
library(zoo)
library(ggthemes)
```

## Data Prep

```{r}
# read in the data
movies <- read_csv(""movie_profit.csv"")

# drop column of numbers from 1-3401
movies <- movies %>%
  select(-one_of(""X1""))

# convert column to date type
movies$release_date <- mdy(movies$release_date)

# create new columns for year, month, day
movies <- movies %>%
  separate(release_date, c(""year"", ""month"", ""day""), ""-"", remove = FALSE)

# filter out years with less than 100 movies and movies that made money in the US
filter_movies <- movies %>%
  filter(year >= 1998 & year <= 2016)

```

## Exploratory Data Analysis

# When do movies usually get released?

```{r}
by_year <- movies %>%
  group_by(year) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

movies %>%
  ggplot(aes(year)) +
  geom_bar() +
  theme(text = element_text(size = 10),
        axis.text.x = element_text(angle = 90, hjust = 1))

movies %>%
  ggplot(aes(month)) +
  geom_bar() +
  theme(text = element_text(size = 10),
        axis.text.x = element_text(angle = 90, hjust = 1))

```

## How much do movies make by genre?
```{r}
filter_movies %>%
  ggplot(aes(genre, worldwide_gross)) +
  geom_boxplot() +
  coord_flip() +
  scale_y_continuous(labels = dollar_format())
```


## How much do movies make by month?

```{r}
filter_movies %>%
  ggplot(aes(month, worldwide_gross)) +
  geom_boxplot() +
  coord_flip() +
  scale_y_continuous(labels = dollar_format())
```

## Movies by genre and month

# by total gross
```{r}
filter_movies %>%
  group_by(month, genre) %>%
  summarize(total_gross = sum(worldwide_gross)) %>%
  ggplot(aes(month, total_gross, fill = genre)) +
  geom_col(position = position_dodge()) +
  scale_fill_manual(""legend"", values = c(""Action"" = ""#F0E442"",
                                         ""Adventure"" = ""#009E73"",
                                         ""Comedy"" = ""#56B4E9"",
                                         ""Drama"" = ""#E69F00"",
                                         ""Horror"" = ""#000000"")) +
  scale_y_continuous(labels = dollar_format())
```

```{r}
by_distributor <- filter_movies %>%
  group_by(distributor) %>%
  summarize(count = n(),
            total = sum(worldwide_gross),
            avg = median(worldwide_gross)) %>%
  arrange(desc(total)) %>%
  head(10)
```

```{r}
movies_top_dis <- inner_join(filter_movies, by_distributor, by = ""distributor"")
```

```{r}
top_by_dis <- movies_top_dis %>%
  group_by(distributor) %>%
  top_n(1, worldwide_gross)
```


```{r}
movies_top_dis %>%
  mutate(distributor = fct_reorder(distributor, worldwide_gross)) %>%
  ggplot(aes(distributor, worldwide_gross, fill = distributor, position = 'dodge')) +
  geom_boxplot() +
  coord_flip() +
  scale_y_continuous(labels = dollar_format()) +
  expand_limits(y = c(0, 1600000000)) +
  geom_text(data = top_by_dis, aes(distributor, worldwide_gross, label = movie), 
            check_overlap = TRUE,
            position = position_dodge(width = 0.75),
            inherit.aes = TRUE,
            size = 2.5, 
            hjust = -0.25) +
  labs(x = """", y = """",
       title = ""Top 10 Film Distributors by Total Worldwide Gross Revenue"",
       subtitle = ""(from 1998-2016)"",
       caption = ""TidyTuesday 10/23/18, source:fivethirtyeight"") +
  theme_fivethirtyeight() +
  guides(fill=FALSE) +
  theme(text = element_text(size = 8),
        axis.text.x = element_text(angle = 30, hjust = 1))

ggsave(""movies.png"")
```


```{r}
knitr::knit_exit()
```

This is scrap work.



## Production cost vs Worldwide gross

```{r}
filter_movies %>%
  ggplot(aes(worldwide_gross, production_budget)) +
  geom_point() +
  scale_y_log10()
```

# by avg gross
```{r}
filter_movies %>%
  group_by(month, genre) %>%
  summarize(avg_gross = median(worldwide_gross)) %>%
  ggplot(aes(month, avg_gross, fill = genre)) +
  geom_col(position = position_dodge()) +
  scale_fill_manual(""legend"", values = c(""Action"" = ""#F0E442"",
                                         ""Adventure"" = ""#009E73"",
                                         ""Comedy"" = ""#56B4E9"",
                                         ""Drama"" = ""#E69F00"",
                                         ""Horror"" = ""#000000"")) +
  scale_y_continuous(labels = dollar_format())
```








","2018-43"
"557",1548,"https://github.com/trevinflick/tidytuesday/tree/master/2019-02-12","trevinflick","tidytuesday","2019-02-12/r_d_spending.Rmd","---
title: 'TidyTuesday: Week 7'
author: ""Trevin Flickinger""
date: ""2/13/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(scales)

fed_rd <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")

energy_spend <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/energy_spending.csv"")

climate_spend <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/climate_spending.csv"")
```

```{r}
fed_rd_year <- fed_rd %>%
  group_by(year) %>%
  summarise(rd_total = sum(rd_budget),
            total = mean(total_outlays),
            pct_of_tot = rd_total / total)

dod <- fed_rd %>%
  filter(department == ""DOD"") %>%
  mutate(pct_of_tot = rd_budget / total_outlays)

non_def <- fed_rd %>%
  filter(department != ""DOD"") %>%
  group_by(year) %>%
  summarise(rd_total = sum(rd_budget),
            total = mean(total_outlays),
            pct_of_tot = rd_total / total)

ggplot() +
  geom_line(data = fed_rd_year, aes(year, pct_of_tot, color = ""black"")) +
  geom_line(data = dod, aes(year, pct_of_tot, color = ""red"")) +
  geom_line(data = non_def, aes(year, pct_of_tot, color = ""blue"")) +
  scale_y_continuous(labels = percent_format()) + 
  scale_color_manual(name = """",
                     values = c(""black""=""black"",""red""=""red"",""blue""=""blue""),
                     labels = c(""Total"",""Nondefense"",""Defense"")) +
  labs(title = ""R&D budget as a percent of Total Federal Budget"",
       subtitle = ""Data from 1976-2017"",
       caption = ""@trevin_flick, source:AAAS"") +
  theme_fivethirtyeight()
  
ggsave(""rd_as_pct.png"")
```

","2019-7"
"558",1549,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-01/tidytuesday.R","trevinflick","tidytuesday","2019-01-01/tidytuesday.R","library(tidyverse)
library(lubridate)
library(scales)
library(ggthemes)

tidytuesday <- read_rds(""tidytuesday_tweets.rds"")

# What users get the most retweets and favorites?

tidytuesday %>%
  group_by(screen_name, followers_count) %>%
  summarise(retweet_total = sum(retweet_count),
            favorite_total = sum(favorite_count)) %>%
  arrange(desc(favorite_total)) %>% 
  View()
  

# How has the popularity of #TidyTuesday changed since it's inception?

tidytuesday$created_at <- ymd_hms(tidytuesday$created_at)
tidytuesday$week <- week(tidytuesday$created_at)

# When did David Robinson start his screencast?
tidytuesday %>%
  filter(screen_name == ""drob"") %>%
  View()

tidytuesday %>%
  filter(week == 30) %>%
  View()

tidy_by_week <- tidytuesday %>%
  group_by(week) %>%
  summarise(retweet_total = sum(retweet_count),
            favorite_total = sum(favorite_count)) %>%
  arrange(week)

tidy_by_week %>%
  mutate(week = week - 13) %>%
  ggplot(aes(x=week, y=favorite_total)) +
  annotate(""text"", x=29, y=1240, 
           label=""David Robinson's first screencast"") +
  annotate(""text"", x=17, y=40,
           label=""#rstats p-hackathon challenge"") +
  geom_line(size=1.5) +
  scale_x_continuous(breaks = c(1,10,20,30,38)) +
  labs(y="""", x="""",
       title = ""#TidyTuesday popularity over time"",
       subtitle = ""Total Twitter favorites each week"",
       caption = ""TidyTuesday 01/01/2019, source:rtweet"") +
  theme_fivethirtyeight()


","2019-1"
"559",1550,"https://github.com/trevinflick/tidytuesday/tree/master/2018-12-04","trevinflick","tidytuesday","2018-12-04/medium.Rmd","---
title: ""Medium Articles""
author: ""Trevin Flickinger""
date: ""12/4/2018""
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
```

Dataset from Kaggle:
[Original data](https://www.kaggle.com/harrisonjansma/medium-stories)


```{r}
medium <- read_csv(""Medium_Clean.csv"")
```

```{r}
medium %>%
  sample_n(10) %>%
  View()
```


```{r}
medium %>%
  sample_n(10000, replace = FALSE) %>%
  ggplot(aes(Reading_Time, Claps)) +
  geom_point() +
  labs(x = ""Reading Time in Minutes"",
       y = ""Claps"",
       title = ""There is a sweet spot around 5-10 minutes for number of claps"",
       subtitle = ""(Random sample of 10,000 articles)"") 
```

Number of tags for each topic

```{r}
n_tags <- medium %>%
  select(Tag_writing:Tag_ai) %>%
  summarise_all(sum) %>%
  gather()
```

```{r}
medium %>%
  filter(Tag_food == 1) %>%
  summarise(avg_reading_time = mean(Reading_Time),
            avg_claps = mean(Claps))
```

```{r}
medium$Reading_Time <- as.numeric(medium$Reading_Time) 
```


Gather avg. reading time and number of claps for each tag

(there's probably an easier way to do this)

```{r}
medium_tags <- medium %>%
  select(Reading_Time, Claps, Tag_ai:Tag_writing) %>%
  group_by_if(is.integer) %>%
  summarise(claps = mean(Claps),
            reading = mean(Reading_Time))

medium_tags$n_tags <- rowSums( medium_tags[,1:95] )

medium_tags <- medium_tags %>%
  filter(n_tags == 1) %>%
  select(-n_tags)

medium_tags[medium_tags == 0] <- NA

medium_tags <- medium_tags %>%
  select(Tag_writing:Tag_ai, claps, reading) %>%
  gather(na.rm = TRUE)

tag_data <- cbind(medium_tags[1:95,], medium_tags[96:190,])
tag_data <- cbind(tag_data, medium_tags[191:285,])

colnames(tag_data) <- c(""tag"", ""x"", ""y"", ""claps"", ""z"", ""reading"")

tag_data <- tag_data %>%
  select(tag, claps, reading)

tag_data <- cbind(tag_data, n_tags[1:95,2])

tag_data$claps <- round(tag_data$claps)
tag_data$reading <- round(tag_data$reading, digits = 2)

tag_data$tag <- gsub(""Tag_"", """", tag_data$tag)

names(tag_data)[4] <- ""Articles""
```


Plotting the data

```{r warning=FALSE, message=FALSE}
library(plotly)

p <- plot_ly(
  tag_data, x = ~reading, y = ~claps,
  text = ~paste(""Tag: "", tag,
                ""<br>Articles: "", Articles),
  size = ~Articles, color = ~Articles
) %>%
  layout(title = 'Engagement for Medium Articles',
         yaxis = list(title = 'Average number of claps'),
         xaxis = list(title = 'Average reading time'))
```

```{r}
api_create(p, filename = ""tidytuesday-medium"")
```

Link to an interactive plotly graph

[Plotly Graph](https://plot.ly/~trevin_flick/1/)








","2018-49"
"560",1551,"https://github.com/trevinflick/tidytuesday/tree/master/2018-12-11","trevinflick","tidytuesday","2018-12-11/nyc_restaurants.Rmd","---
title: 'TidyTuesday: NYC Restaurants'
author: ""Trevin Flickinger""
date: ""12/11/2018""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(janitor)
library(stringr)
library(lubridate)
library(ggthemes)
```

```{r}
restaurants <- read_csv(""NYC_Restaurant_Inspections.csv"")
```

Filter out restaurants that haven't been inspected yet.
```{r}
nyc_restaurants <- restaurants %>%
  janitor::clean_names() %>%
  select(-phone, -grade_date, -record_date, -building, -street) %>%
  filter(!is.na(action))

nyc_restaurants$inspection_date <- mdy(nyc_restaurants$inspection_date)
```

```{r}
nyc_restaurants %>%
  count(year(inspection_date))
```


```{r}
by_date <- nyc_restaurants %>%
  count(camis, inspection_date) %>%
  group_by(camis)

by_date <- by_date[order(by_date$inspection_date, by_date$n),]
```


```{r}
n_visits <- by_date %>% count(camis, sort = TRUE)

grades <- nyc_restaurants %>%
  select(camis, inspection_date, grade, cuisine_description) %>%
  filter(!is.na(grade))


```

```{r}
by_date_grade <- left_join(by_date, grades, by = c(""camis"" = ""camis"", ""inspection_date"" = ""inspection_date""))

by_date_grade <- filter(by_date_grade, !is.na(grade))

by_date_grade <- unique(by_date_grade)
```


```{r}
grade_2017 <- by_date_grade %>% 
  group_by(camis) %>% 
  filter(year(inspection_date) == 2017) %>%
  slice(which.max(inspection_date)) %>%
  data.frame()
```

```{r}
grade_2017 %>% count(cuisine_description, sort = TRUE) %>% View()
```

```{r}
grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = fct_lump(cuisine_description, n = 19))

grade_2017 <- grade_2017 %>%
  mutate(grade = fct_lump(grade, n = 3))
```

```{r}
grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = str_replace(cuisine_description, ""Caf/Coffee/Tea"", ""Coffee""))

grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = str_replace(cuisine_description, ""Latin \\(Cuban, Dominican, Puerto Rican, South & Central American\\)"", 
                                           ""Latin""))

grade_2017 <- grade_2017 %>%
  mutate(cuisine_description = str_replace(cuisine_description, ""Juice, Smoothies, Fruit Salads"", ""Smoothies""))
```

```{r}
grade_2017 <- transform(grade_2017, cuisine_description = factor(cuisine_description,
                                                                 levels = c(""American"",
                                                                 ""Other"",
                                                                 ""Chinese"",
                                                                 ""Coffee"",
                                                                 ""Pizza"",
                                                                 ""Italian"",
                                                                 ""Mexican"",
                                                                 ""Latin"",
                                                                 ""Japanese"",
                                                                 ""Bakery"",
                                                                 ""Caribbean"",
                                                                 ""Donuts"",
                                                                 ""Spanish"",
                                                                 ""Pizza/Italian"",
                                                                 ""Chicken"",
                                                                 ""Hamburgers"",
                                                                 ""Sandwiches"",
                                                                 ""Smoothies"",
                                                                 ""Asian"",
                                                                 ""Jewish/Kosher"")))
```



```{r}
grade_2017 %>%
  ggplot(aes(cuisine_description, fill=grade)) + geom_bar() + coord_flip() + scale_y_log10() +
  labs(x="""", y="""", title=""2017 NYC Restaurant Health Grades by Cuisine"",
       subtitle=""x-axis count of restaurants on log-scale"",
       caption = ""TidyTuesday 12/11/18, source:fivethirtyeight"") +
  theme_fivethirtyeight()

ggsave(""nyc_grades.png"")
```



```{r}
by_date_grade %>% 
  filter(year(inspection_date) == 2017 & grade == ""B"") %>%
  ggplot(aes(inspection_date, n, group = camis)) + geom_step()
```


```{r}
by_date_grade %>%
  filter(grade == ""A"" | grade == ""B"" | grade == ""C"") %>%
  ggplot(aes(n, stat(count), fill=grade)) + geom_density(alpha = 0.6)
```






","2018-50"
"561",1552,"https://github.com/trevinflick/tidytuesday/tree/master/2018-09-25","trevinflick","tidytuesday","2018-09-25/clean.R","library(dplyr)
library(readr)
library(purrr)
library(tidyr)

table1 <- read_csv(""table1.csv"")
table2 <- read_csv(""table2.csv"")
table3 <- read_csv(""table3.csv"")
table4 <- read_csv(""table4.csv"")
table6 <- read_csv(""table6.csv"")

# clean table1

table_1 <- table1 %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, everything())

write_csv(table_1, ""table_1.csv"")

# clean table2

table2 <- table2[-1, ]
  
table_2 <- table2 %>%
  separate(X1, into = c(""Rank"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(X4, into = c(""Rank_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  separate(X7, into = c(""Rank_2"", ""Country_2""), sep = "" "", extra = ""merge"") %>%
  select_if(~sum(!is.na(.)) > 0) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, Country, TICt = ""TICt  (millions"")

write_csv(table_2, ""table_2.csv"")


# clean table3

table3 <- table3[-1, ]

table_3 <- table3 %>%
  separate(X1, into = c(""Rank"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(X6, into = c(""Rank_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  separate(X11, into = c(""Rank_2"", ""Country_2""), sep = "" "", extra = ""merge"") %>%
  select_if(~sum(!is.na(.)) > 0) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, Country, TICt = ""TICt  (millions"", meanGDP = ""X4"", propGDP = ""proportion of"")

write_csv(table_3, ""table_3.csv"")

# clean table4

table_4 <- table4 %>%
  separate(""Rank Country"", into = c(""Rank"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(""Rank Country_1"", into = c(""Rank_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  separate(""Rank Country_2"", into = c(""Rank_2"", ""Country_2""), sep = "" "", extra = ""merge"") %>%
  select_if(~sum(!is.na(.)) > 0) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(Rank, Country, TICs = ""TICs  (millions US$)"")

write_csv(table_4, ""table_4.csv"")

# clean table6

table6 <- table6[-1, ]

table_6 <- table6 %>%
  separate(""maximum reported Species"", into = c(""max_impact_pct"", ""Country""), sep = "" "", extra = ""merge"") %>%
  separate(""maximum reported Species_1"", into = c(""max_impact_pct_1"", ""Country_1""), sep = "" "", extra = ""merge"") %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 3)]) %>%
  map_df(simplify) %>%
  drop_na() %>%
  select(species = Species, max_impact_pct)

write_csv(table_6, ""table_6.csv"")














","2018-39"
"562",1553,"https://github.com/trevinflick/tidytuesday/tree/master/2018-09-25","trevinflick","tidytuesday","2018-09-25/plot.R","library(ggplot2)
library(dplyr)
library(ggthemes)

table_3$TICt <- gsub(""\\$"", """", table_3$TICt)
table_3$TICt <- as.numeric(gsub("","", """", table_3$TICt))

table_3$meanGDP <- gsub(""\\$"", """", table_3$meanGDP)
table_3$meanGDP <- as.numeric(gsub("","", """", table_3$meanGDP))

table_3 %>%
  ggplot(aes(log(meanGDP), log(TICt), label = Country)) +
  geom_point(alpha = 0.5,
             color = ifelse(table_3$propGDP > 0.25, ""red"", ""black"")) +
  geom_text_repel(data = filter(table_3, log(TICt) > 11 | log(TICt) < 2 | propGDP > 0.25),
                  segment.color = ""grey50"",
                  segment.size = 0.5) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) + 
  ylab('Total Invasion Cost [log scale]') + 
  xlab('GDP [log scale]') +
  labs(caption = ""TidyTuesday 9/25/18, source:Paini et al, 2016"")


","2018-39"
"563",1554,"https://github.com/trevinflick/tidytuesday/blob/master/2019-01-08/imdb-dramas.R","trevinflick","tidytuesday","2019-01-08/imdb-dramas.R","library(tidyverse)
library(lubridate)
library(ggthemes)

imdb <- read_csv(""IMDb_Economist_tv_ratings.csv"")

# Shows with the most seasons
top_30 <- imdb %>%
  group_by(title) %>%
  summarise(n = n(),
            avg_rating = mean(av_rating)) %>%
  arrange(desc(n)) %>% 
  head(30)

# How are shows rated?
summary(imdb$av_rating)

# Shows with only one season
one_and_done <- imdb %>%
  group_by(title) %>%
  filter(n() == 1, seasonNumber == 1)

# Shows with multiple seasons
multiple_seasons <- imdb %>%
  group_by(title) %>%
  filter(n() > 1)

binded_data <- rbind(one_and_done, multiple_seasons)

# Plot how many seasons each show has
binded_data %>%
  count(title) %>%
  ggplot(aes(n)) +
  geom_bar() +
  theme_fivethirtyeight() +
  labs(x = ""Number of seasons"", y="""",
       title = ""Most dramas only have one season"")
  

binded_data$seasons <- c(rep(""one"",nrow(one_and_done)),
                         rep(""multiple"",nrow(multiple_seasons)))

# Plot shows with one season compared to multiple seasons
binded_data %>%
  ggplot(aes(av_rating, fill = seasons)) +
  geom_density(alpha = 0.4) +
  labs(x = ""Average rating"", y = """",
       subtitle = ""Comparing dramas with only one season to dramas with multiple"",
       caption = ""TidyTuesday 01/08/2019, source:IMDB"") +
  theme_fivethirtyeight()

rating_by_show <- binded_data %>%
  group_by(title) %>%
  summarise(seasons = n(),
            avg_rating = mean(av_rating),
            avg_share = mean(share))

rating_by_show %>%
  ggplot(aes(seasons, avg_rating)) +
  geom_boxplot(aes(group = cut_width(seasons, 1))) +
  labs(y = ""Average Rating"", x = ""Number of seasons"",
       title = ""Dramas with fewer seasons show more variability in avg. rating"") +
  theme_economist()
  
  

","2019-2"
"564",1555,"https://github.com/trevinflick/tidytuesday/tree/master/2018-11-27","trevinflick","tidytuesday","2018-11-27/maryland_bridges.R","library(readr)
library(dplyr)
library(forcats)
library(stringr)
library(ggplot2)
library(ggthemes)

#### CLEANING THE DATA ####
bridges <- read_csv(""baltimore_bridges.csv"")

bridges %>% count(responsibility, sort = TRUE)
bridges <- bridges %>%
  mutate(responsibility = fct_lump(responsibility, n = 4))

bridges$vehicles <- as.numeric(str_replace_all(bridges$vehicles, "" vehicles"", """"))


#### EXPLORING DATA WITH PLOTS ####

# avg_daily_traffic and vehicles are same column

bridges %>% ggplot(aes(avg_daily_traffic)) + geom_histogram()

bridges %>% ggplot(aes(vehicles)) + geom_histogram()

bridges %>% ggplot(aes(yr_built)) + geom_histogram()

bridges %>% filter(yr_built < 1900) %>% View()

# two extreme outliers for improvement costs $300,000,000
bridges %>% filter(total_improve_cost_thousands < 38000) %>%
  ggplot(aes(avg_daily_traffic, total_improve_cost_thousands)) + geom_point()

bridges %>%
  ggplot(aes(yr_built, avg_daily_traffic, color = bridge_condition)) + 
  geom_point(aes(fill=bridge_condition)) +
  scale_y_log10()

bridges %>%
  ggplot(aes(yr_built, stat(count), fill=bridge_condition)) + 
  geom_density(alpha = 0.6, position = ""stack"") +
  scale_fill_manual(values = c(""#ffffbf"", ""#91bfdb"", ""#fc8d59""), 
                    breaks=c(""Poor"",""Fair"",""Good""),
                    name=""Bridge Condition"") +
  labs(x="""", y="""",
       title = ""The State of Maryland Bridges"",
       subtitle = ""Year built factors into condition"",
       caption = ""TidyTuesday 11/27/18, source:Federal Highway Administration"") +
  theme_fivethirtyeight()


","2018-48"
"565",1556,"https://github.com/trevinflick/tidytuesday/tree/master/2018-10-02","trevinflick","tidytuesday","2018-10-02/easter.R","library(tidyverse)
library(readr)
library(ggplot2)
library(ggthemes)


us_births <- readr::read_csv(""us_births_2000-2014.csv"")
easter_dates <- readr::read_csv(""easter_dates.csv"")

easter_dates <- easter_dates %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 5)]) %>%
  map_df(simplify) %>%
  select(month_day = ""Easter Date"", year = ""Years"") %>%
  arrange(year)

easter_dates <- easter_dates %>%
  separate(month_day, c(""month"", ""date_of_month""), sep = "" "")

months <- c(""January"", ""February"", ""March"", ""April"", ""May"", ""June"",
            ""July"", ""August"", ""September"", ""October"", ""November"", ""December"")

easter_dates$month <- match(easter_dates$month, months)

easter_dates <- easter_dates %>%
  mutate(year = as.numeric(year),
         month = as.numeric(month),
         date_of_month = as.numeric(date_of_month)) %>%
  unite(day, c(""year"", ""month"", ""date_of_month""), sep = ""-"")


week_before <- apply(easter_dates, 1, function(x) {seq.Date(as.Date(x['day']), by = ""-1 day"", length.out = 14)})

week_after <- apply(easter_dates, 1, function(x) {seq.Date(as.Date(x['day']) + 1, by = ""+1 day"", length.out = 14)})

easter <- data.frame(week_before, week_after) %>%
  unclass() %>%
  split(names(.)[seq(length(.) / 30)]) %>%
  map_df(simplify) %>%
  select(day = ""X1"")

easter$day <- as.Date(easter$day, origin = ""1970-01-01"")

easter <- easter %>%
  separate(day, c(""year"", ""month"", ""date_of_month""), sep = ""-"") %>%
  mutate(year = as.numeric(year),
         month = as.numeric(month),
         date_of_month = as.numeric(date_of_month)) %>%
  arrange(year, month, date_of_month)

easter <- left_join(easter, us_births, by = c(""year"", ""month"", ""date_of_month""))

easter$day <- rep(c(1:28), 15)

easter_births <- easter %>%
  group_by(day) %>%
  summarise(
    avg_births = mean(births)
  ) 

# avg birth non easter sundays
easter_births %>%
  filter(day == 7 | day == 21 | day == 28) %>%
  summarise(
    avg_births = mean(avg_births)
  )

day_effect <- us_births %>%
  group_by(day_of_week) %>%
  summarise(
    avg_by_day = mean(births)
  ) %>%
  slice(rep(1:n(), times = 4))

easter_births <- easter_births %>%
  mutate(mult_adj_births = avg_births / day_effect$avg_by_day,
         add_adj_births = avg_births - day_effect$avg_by_day)

# unadjusted plot

easter_births %>%
  ggplot(aes(day, avg_births)) +
  geom_point() +
  geom_point(data = filter(easter_births, day == 14), color = ""yellow"") +
  geom_text(data = filter(easter_births, day == 14), label = ""Easter"", 
            nudge_x = 2, nudge_y = -100) +
  geom_line() +
  geom_hline(yintercept = 7285, color = ""red"") +
  geom_text(data = filter(easter_births, day == 7), label = ""non-Easter Sunday avg."", vjust = 1.5, 
            color = ""red"", size = 3) +
  labs(x = """", y = ""births"", title = ""Fewer babies are born on Easter"",
       subtitle = ""U.S. births: two weeks before and after Easter \n(average births 2000-2014)"") +
  labs(caption = ""TidyTuesday 10/02/18, source:Fivethirtyeight"") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text())

# adjusted for day of week

easter_births %>%
  ggplot(aes(day, add_adj_births)) +
  geom_point() +
  geom_point(data = filter(easter_births, day == 14), color = ""yellow"") +
  geom_text(data = filter(easter_births, day == 14), label = ""Easter"",
            nudge_y = -.01)  +
  geom_line() +
  labs(x = """", y = ""births"", title = ""Fewer babies are born on Easter"",
       subtitle = ""U.S. births: two weeks before and after Easter \n(average births 2000-2014)"") +
  labs(caption = ""TidyTuesday 10/02/18, source:Fivethirtyeight"") +
  theme_fivethirtyeight() +
  theme(axis.title = element_text())










","2018-40"
"566",1557,"https://github.com/trevinflick/tidytuesday/tree/master/2019-02-26","trevinflick","tidytuesday","2019-02-26/trains.Rmd","---
title: ""Tidy Tuesday Week 9""
author: ""Trevin Flickinger""
date: ""2/26/2019""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(ggthemes)
library(scales)

trains <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")
```

```{r}
trains$date <- paste(trains$year, trains$month, 01, sep=""-"") %>% ymd() %>% as.Date()
```


```{r}
trains %>% group_by(date) %>%
  summarise(total_trips = sum(total_num_trips)) %>%
  ggplot(aes(date, total_trips)) +
  geom_line() +
  labs(x = """", y = """", 
       title = ""Total number of train trips in France"") + 
  theme_fivethirtyeight()
```


```{r}
trains %>% group_by(date) %>%
  summarise(total_cancel = sum(num_of_canceled_trains)) %>%
  ggplot(aes(date, total_cancel)) +
  geom_line(size = 1.25) +
  labs(x = """", y = """", 
       title = ""Total number of canceled trains in France"",
       subtitle = ""2015-2018"",
       caption = ""TidyTuesday week 9, source: SNCF"") + 
  theme_fivethirtyeight()
  
# ggsave(""france_trains.png"")
```

```{r}
trains %>% group_by(date) %>%
  summarise(pct_cancel = sum(num_of_canceled_trains) / (sum(num_of_canceled_trains) + sum(total_num_trips))) %>%
  ggplot(aes(date, pct_cancel)) +
  geom_line(size = 1.25) +
  labs(x = """", y = """", 
       title = ""Percentage of trains canceled in France"",
       subtitle = ""2015-2018"",
       caption = ""TidyTuesday week 9, source: SNCF"") + 
  scale_y_continuous(labels = scales::percent) +
  theme_fivethirtyeight()
```

```{r}
ggsave(""canceled_pct.png"")
```


```{r}
trains %>% group_by(date) %>%
  summarise(avg_delay_depart = sum(avg_delay_all_departing),
            avg_delay_arrive = sum(avg_delay_all_arriving)) %>%
  ggplot() +
  geom_line(aes(date, avg_delay_depart), color = ""black"") +
  geom_line(aes(date, avg_delay_arrive), color = ""blue"")
  labs(x = """", y = """", 
       title = ""Avg delay trains in France"") + 
  theme_fivethirtyeight()
```





","2019-9"
"567",1560,"https://github.com/hmetcalfe1/tidytuesday","hmetcalfe1","tidytuesday","tidytues2019/tt_jan19/tt_08012019/tt08012019.R","#tidytuesday 08012019
library(tidyverse)

importfile<-""tidytues2019/tt_jan19/tt_08012019/IMDb_Economist_tv_ratings.csv""
exportfile<-""tidytues2019/tt_jan19/tt_08012019/08012019.pdf""
  
tvdata <- read_csv(importfile)
tvdata

ggplot(data = tvdata) +
  geom_point(mapping = aes(x=date,y=av_rating))
    
ggsave(exportfile)
","2019-32"
"568",1561,"https://github.com/hmetcalfe1/tidytuesday","hmetcalfe1","tidytuesday","tidytues2019/tt_jan19/tt_29012019/tt29012019.R","#tidytuesday 29012019
rm(list=ls())
library(tidyverse)

importfile<-""tidytues2019/tt_jan19/tt_29012019/clean_cheese.csv""
exportfile<-""tidytues2019/tt_jan19/tt_29012019/29012019.png""

chdata <- read_csv(importfile)

chdata<-mutate(chdata,
       OtherCheese=rowSums(chdata[6:11],na.rm = TRUE)
       )

ggplot(data = chdata,aes(x=Year)) +
  geom_line(mapping = aes(y=Cheddar), colour=""deepskyblue3"")+
  geom_line(mapping = aes(y=Mozzarella), colour=""deeppink3"")+
  geom_line(mapping = aes(y=`American Other`), colour=""yellow3"")+
  geom_line(mapping = aes(y=`Italian other`), colour=""forestgreen"")+
  geom_line(mapping = aes(y=OtherCheese), colour=""chocolate3"")+
  ylab(""Per capita consumption ofcheese / pounds"")+
  geom_text(aes(x = 2011, y = 11.5, label = ""Mozzarella""), color = ""deeppink3"") + 
  geom_text(aes(x = 2011, y = 9, label = ""Cheddar""), color = ""deepskyblue3"")+
  geom_text(aes(x = 2011, y = 4.5, label = ""Other American Type Cheeses""), color = ""yellow3"") + 
  geom_text(aes(x = 2011, y = 2, label = ""Other Italian Type Cheeses""), color = ""forestgreen"")+
  geom_text(aes(x = 2011, y = 6.5, label = ""Other Cheeses""), color = ""chocolate3"")+
  theme_bw()

ggsave(exportfile)
","2019-5"
"569",1562,"https://github.com/hmetcalfe1/tidytuesday","hmetcalfe1","tidytuesday","tidytues2019/tt_mar19/tt_12032019/tt12032019.R","#tidytuesday 12032019

# Load Packages -----------------------------------------------------------
library(tidyverse)
library(reshape2)
library(gridExtra)


# Read in data ------------------------------------------------------------

importfile<-""tidytues2019/tt_mar19/tt_12032019/board_games.csv""

bgdata <- read_csv(importfile)

bgcategories<-str_split(bgdata$category,"","")%>%
  unlist()%>%
  unique()

#Create new columns for each category  ------------------------------------------------------------------------
for (i in 1:length(bgcategories)){
  categoryis<-bgcategories[i]
  
  for (j in 1:nrow(bgdata)){
    cattrue<-grepl(categoryis, bgdata$category[j])
    if (isTRUE(cattrue)) {
      myval<-1
    } else {
      myval<-0
    }
    
    if(j==1){
      mycol<-myval
    }
    else{
      mycol<-rbind(mycol,myval)
    }
  }
  if(i==1){
    catcols<-as.data.frame(mycol)
  }
  else{
    catcols2<-as.data.frame(mycol)
    catcols<-cbind(catcols,catcols2)
  }
  
}
names(catcols)<-bgcategories
bgdata<-cbind(bgdata,catcols)


# create a new data frame with the game idsand a list of catergori --------

catsid <- cbind(catcols,bgdata$game_id)
long_cats <- melt(catsid, id=""bgdata$game_id"")
long_cats <- filter(long_cats,value==""1"")
names(long_cats)[1]<-""game_id""

valid_column_names <- make.names(names=names(bgdata), unique=TRUE, allow_ = TRUE)
names(bgdata) <- valid_column_names

bgratings<-select(bgdata,game_id,name,year_published,average_rating)

bg_catdata<-left_join(long_cats, bgratings, by = ""game_id"")

# Create graphics ---------------------------------------------------------

exportfile<-""tidytues2019/tt_mar19/tt_12032019/12032019.png""

a<-ggplot(data = bg_catdata%>%filter(variable==""Religious""|variable==""Political""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
b<-ggplot(data = bg_catdata%>%filter(variable==""Word Game""|variable==""Number""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
c<-ggplot(data = bg_catdata%>%filter(variable==""Pirates""|variable==""Science Fiction""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
d<-ggplot(data = bg_catdata%>%filter(variable==""Humor""|variable==""Horror""),aes(x=year_published,y=average_rating,colour=variable)) +
  geom_point()+
  geom_smooth(se=FALSE)+
  ylab(""Average Rating"")+
  theme_bw()
p<-grid.arrange(a,b,c,d)

ggsave(exportfile,p)
","2019-11"
"570",1585,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2018-11-27","tanyaberde","tidytuesday","data/2018-11-27/baltimoreBridges.R","# Tidy Tuesday 2018-11-27 Baltimore Bridges
# Constanza de Dios

# Read data
bridges <- read.csv(""baltimore_bridges.csv""
                 ,header=T)

dat <- bridges
library(tidyverse)

dat1 <- dat %>% 
  mutate(age = 2018 - yr_built, # Calculate age of each bridge as of year 2018
         time_insp = 18 - inspection_yr # Calculate time since last inspection
)



g <- ggplot(dat1) +
  aes(x = age
      , y = avg_daily_traffic/10^3
      # , alpha = bridge_condition
      , color = factor(time_insp)
      ) +
  geom_point(stat=""identity""
             , size = 1.5
             ) +
  # scale_alpha_discrete(breaks=c(""Good"",""Fair"",""Poor""), breaks=1:3) + # Reorder labels of bridge condition
  scale_color_brewer(type = ""qual"", palette=3) +
  labs(x = ""Age as of 2018"", y = ""Average Daily Traffic (thousands)""
       # , alpha = """"
       ,color = ""Years since last inspection""
       ) +
  facet_grid(vars(bridge_condition), vars(county)) +
  ggtitle(""Correlation between traffic and age of bridges across Maryland counties"") +
  theme_bw()


print(g)

ggsave(""MDbridges.png""
       ,plot = g
       ,width=12
       ,height=4)
","2018-48"
"571",1586,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-01-29","tanyaberde","tidytuesday","data/2019-01-29/dairy.R","require(tidyverse)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milk_products_facts.csv'
url2 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/fluid_milk_sales.csv'

milkProductsData <- read_csv(url1)
milkSalesData <- read_csv(url2)

# Get the data from the fluid_milk_sales dataset to get production
milkSales_df <- milkSalesData %>% 
  filter(milk_type==""Total Production"") %>% 
  mutate(millions_of_pounds = pounds/1000000)

# left_join this to milkProductsData
milkProdCons_df <- left_join(milkSales_df, milkProductsData,
                             by = c(""year""))

# Make the products into one column
milkProdRatio_df <- milkProdCons_df %>% 
  select(year:dry_whey) %>% 
  gather(product_type, ave_consump, fluid_milk:dry_whey) %>% 
  mutate(product_type = case_when(
                            str_detect(product_type, ""fluid_milk"") ~ ""Milk"",
                            str_detect(product_type, ""fluid_yogurt"") ~ ""Yogurt"",
                            # str_detect(product_type, ""butter"") ~ ""Butter"",
                            str_detect(product_type, ""cheese_american"") ~ ""American Cheese"",
                            str_detect(product_type, ""cheese_other"") ~ ""Other Cheese"",
                            str_detect(product_type, ""cheese_cottage"") ~ ""Cottage Cheese"",
                            str_detect(product_type, ""evap_cnd_canned_whole_milk"") ~ ""Evaporated/Canned Whole Milk"",
                            str_detect(product_type, ""evap_cnd_bulk_whole_milk"") ~ ""Evaporated/Canned Bulk Whole Milk"",
                            str_detect(product_type, ""evap_cnd_bulk_and_can_skim_milk"") ~ ""Evaporated/Canned Bulk and Can Skim Milk"",
                            str_detect(product_type, ""frozen_ice_cream_regular"") ~ ""Regular Ice Cream"",
                            str_detect(product_type, ""frozen_ice_cream_reduced_fat"") ~ ""Reduced-Fat Ice Cream"",
                            str_detect(product_type, ""frozen_sherbet"") ~ ""Sherbet"",
                            str_detect(product_type, ""frozen_other"") ~ ""Other Frozen Milk Product"",
                            str_detect(product_type, ""dry_whole_milk"") ~ ""Dry Whole Milk"",
                            str_detect(product_type, ""dry_nonfat_milk"") ~ ""Dry Nonfat Milk"",
                            str_detect(product_type, ""dry_buttermilk"") ~ ""Dry Buttermilk"",
                            str_detect(product_type, ""dry_whey"") ~ ""Dry Whey/Milk Protein"",
                            TRUE ~ NA_character_)) %>% 
  mutate(product_form = case_when(
    str_detect(product_type, ""Butter"") ~ ""Butter/Cheese"",
    str_detect(product_type, ""Cheese"") ~ ""Butter/Cheese"",
    str_detect(product_type, ""Yogurt"") ~ ""Fluid"",
    str_detect(product_type, ""Canned"") ~ ""Canned"",
    str_detect(product_type, ""Ice Cream"") ~ ""Frozen"",
    str_detect(product_type, ""Sherbet"") ~ ""Frozen"",
    str_detect(product_type, ""Frozen"") ~ ""Frozen"",
    str_detect(product_type, ""dry"") ~ ""Dry"",
    str_detect(product_type, ""Milk"") ~ ""Fluid"",
    TRUE  ~ NA_character_
  ))

milkRatio <- milkProdRatio_df %>%
  mutate(prop = ((ave_consump*10000)/millions_of_pounds)) 
  # select(-c(""milk_type"",""pounds""))

# Filter required rows for the labels
prodLabs <- milkRatio[milkRatio$year == 2016, ] # since 2016 gets plotted on the rightmost
prodLabs$label <- prodLabs$product_type


# Plot
g <- ggplot(milkRatio,
            aes(x = year, y = log10(prop)
                , color = product_type
                , linetype = product_form
                , label = product_type
                )) +
  geom_text_repel(data=prodLabs
            , aes(label=label)
            , size=4
            , direction = ""both""
  ) +
  geom_line(stat=""identity"", size = 1.1
            # ,show.legend = FALSE
  ) +
  labs(x = ""Year"", y = ""Ratio of ave. personal consumption to total milk production (.001 lb)""
       , linetype=""Form""
       , subtitle = ""*Ratio log-transformed""
       ) +
  guides(color=FALSE) +
  ggtitle(""Consumption-to-Production ratio of US Dairy Products"") +
  theme_minimal(base_size = 12)

print(g)

ggsave(""milkProducts.png""
       ,plot = g
       ,width=9
       ,height=7)
","2019-5"
"572",1587,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-01-15","tanyaberde","tidytuesday","data/2019-01-15/spaceLaunches.R","require(tidyverse)
require(ggplot2)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/agencies.csv'
dat1 <- read_csv(url1)
url2 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv'
dat2 <- read_csv(url2)

# Bin the years in decades (10)

## First make new variables
## Decade
dat2$decade = ifelse(1960 <= launch_year & launch_year <= 1969, 1960
                    ,ifelse(1970 <= launch_year & launch_year <= 1979, 1970
                            ,ifelse(1980 <= launch_year & launch_year <= 1989, 1980
                                    ,ifelse(1990 <= launch_year & launch_year <= 1999, 1990
                                            ,ifelse(2000 <= launch_year & launch_year <= 2009, 2000
                                                    ,2010)))))

## Get average number of successes every decade for each agency, just for state launch providers

### First count number of successes and failures for each agency & decade
categ <- dat2 %>% 
  filter(agency_type %in% c(""state"")) %>% 
  group_by(state_code, decade, category) %>%
  tally

### Then count total attempts
total <- dat2 %>% 
  filter(agency_type %in% c(""state"")) %>% 
  group_by(state_code, decade) %>% 
  tally

categ_total <- merge(categ,total,by=c(""state_code"",""decade"")) # Join the two tables 

categ_total <- categ_total %>%
  filter(category %in% c(""O"")) %>%  # Only include the successes
    mutate(success_rate = n.x/n.y)


# Plot
g <- ggplot(categ_total,
  aes(x = decade, y = success_rate, fill = state_code )) +
  geom_bar(stat=""identity"",size=1.5
            ) +
# scale_fill_brewer(type = ""qual"", palette=2) +
  facet_wrap(~state_code) +
  labs(x = ""Country"", y = ""Success Rate"") +
  ggtitle(""Success rate of state-sponsored launches relative to total attempts per decade"") +
  theme_minimal()

print(g)
","2019-3"
"573",1588,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-12","tanyaberde","tidytuesday","data/2019-02-12/fedSpending.R","require(tidyverse)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/climate_spending.csv'
url3 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv'

fed.dat <- read_csv(url3)
clim.dat <- read_csv(url1)

# Summarize using 5-year bins
fed.dat <- fed.dat %>% 
  mutate(bin = case_when (
    (year >= 1976 & year <= 1980) ~ ""1976-80"",
    (year >= 1981 & year <= 1985) ~ ""1981-85"",
    (year >= 1986 & year <= 1990) ~ ""1986-90"",
    (year >= 1991 & year <= 1995) ~ ""1991-95"",
    (year >= 1996 & year <= 2000) ~ ""1996-00"",
    (year >= 2001 & year <= 2005) ~ ""2001-05"",
    (year >= 2006 & year <= 2010) ~ ""2006-10"",
    (year >= 2011 & year <= 2015) ~ ""2011-15"",
    (year >= 2016 & year <= 2017) ~ ""2016-17"",
    TRUE ~ NA_character_)
    )

fed.ave.dat <- fed.dat %>% 
  group_by(department,bin) %>% 
  summarise(rd_budget=mean(rd_budget,na.rm=T),
            total_outlays=mean(total_outlays,na.rm=T),
            discretionary_outlays=mean(discretionary_outlays,na.rm=T),
            gdp=mean(gdp,na.rm=T)) %>% 
  na.omit()
  

g <- ggplot(fed.ave.dat,
            aes(x=gdp
                ,y=rd_budget
                ,colour=bin
                )) +
  geom_point() +
  facet_wrap(~department) +
  labs(x = ""GDP"", y = ""R&D Budget"",colour=""Years"",subtitle = ""* Note year correlates with GDP"") +
  ggtitle(""Research & Development budget as a function of GDP, allotted by department"") +
  theme_minimal()
g

#============================================================
total.outlays <- fed.dat %>% 
  select(year,total_outlays) %>% 
  distinct()

clim.total.dat  <- left_join(clim.dat,total.outlays,by=c(""year"")) %>% 
  mutate(prop.spending = (gcc_spending/total_outlays)*100)

h <- ggplot(clim.total.dat,
            aes(x=year
                ,y= prop.spending
                ,fill=department
                )) +
  geom_area(colour=""grey50"") +
  labs(x = ""Year"", y = ""Percent of total federal spending"",fill=""Department"") +
  ggtitle(""Proportion of R&D Climate Change spending to total federal government spending by department"") +
  theme_minimal()
h

#============================================================

ggsave(""deptBudgets.png"",g,width=9,height=7)

ggsave(""climateSpending.png"",h,width=9,height=7)
","2019-7"
"574",1589,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-01-22","tanyaberde","tidytuesday","data/2019-01-22/prisonHolds.R","
require(tidyverse)
require(ggplot2)

# Get the data
url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-22/incarceration_trends.csv'

incarc_dat <- read_csv(url1)

# Add a row ID for later joining if needed
d2 <- incarc_dat %>% 
  mutate(row_id = row_number())

# Have other_state coded above _state_ or else case_when will mislabel
holds <- d2 %>% 
  select(yfips:total_pop_15to64, urbanicity:land_area, jail_from_state_prison:jail_from_ice, row_id) %>% 
  gather(agency, pop_count, jail_from_state_prison:jail_from_ice) %>% 
  mutate(agency = case_when(str_detect(agency, ""other_state_prison"") ~ ""Out-of-State Prison"",
                                str_detect(agency, ""from_state_prison"") ~ ""State Prison"",
                                str_detect(agency, ""other_state_jail"") ~ ""Out-of-State Jail"",
                                str_detect(agency, ""from_state_jail"") ~ ""State Jail"",
                                str_detect(agency, ""_fed"") ~ ""All Federal Authorities"",
                                str_detect(agency, ""_ice"") ~ ""ICE or INS"",
                                TRUE ~ NA_character_))

holds2 <- holds %>% 
  mutate(ratio = (pop_count/total_pop_15to64)*100)


# Summary of number of individuals held for other agencies, depending on urbanicity and year

holds_summ <- holds2 %>% 
  na.omit() %>% 
  group_by(year, urbanicity, agency) %>% 
  summarize(average_prop = mean(ratio),
            average_total_pop = mean(total_pop_15to64),
            average_pop_count = mean(pop_count)) %>% 
  ungroup()


# Plot
g <- ggplot(holds_summ,
            aes(x = year, y = average_prop, color = agency )) +
  geom_line(stat=""identity"",size=1.1
  ) +
  scale_color_brewer(type = ""div"") +
  facet_wrap(~urbanicity) +
  labs(x = ""Year"", y = ""Proportion to facility population aged 15-64"", color=""Agency"") +
  ggtitle(""Prisoners being held for in-state or external authorities, per urbanicity category"") +
  theme_minimal(base_size = 12)


print(g)

ggsave(""holds.png""
       ,plot = g
       ,width=9
       ,height=7)
","2019-4"
"575",1590,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-19","tanyaberde","tidytuesday","data/2019-02-19/cleaningTimeData.R","rm(list=ls())

## Comment out one of the below lines as needed; adjust range of years in line 55 accordingly
# xfilename <- ""2017_031"" ## 2017
# xfilename <- ""2016_031"" ## 2016
# xfilename <- ""2015_031"" ## 2015
xfilename <- ""2014_031"" ## 2014
# xfilename <- ""2013_031"" ## 2013

#================================================================================
require(tidyverse)
df <- readxl::read_excel(paste(""data/"",xfilename,"".xlsx"",sep="""")
                         , skip=1) %>% ### skip=1 for 2014 and 2013 data
  rename(field_time = `Field of study and time to degree`) %>% # Rename the conjunctive column to something simpler
  filter(!is.na(field_time)) %>% 
  mutate( # Clean up weird names with superscripts
    field_time = case_when(field_time == ""Otherc"" ~ ""Other"",
                           field_time == ""Life sciencesb"" ~ ""Life sciences"",
                           field_time == ""Since starting doctoral programa"" ~ ""Since starting doctoral program"",
                            TRUE ~ field_time
                           ))

# Manually grabbed the broad fields (based on indentation)
major_fields <- c(""Life sciences"", 
                  ""Physical sciences and earth sciences"", 
                  ""Mathematics and computer sciences"",
                  ""Psychology and social sciences"", 
                  ""Engineering"",
                  ""Education"",
                  ""Humanities and arts"",
                  ""Other"",
                  ""All fields"")

# Manually grabbed time to degree
times_to_degree <- c(""Since bachelor's"",
                    ""Since starting graduate school"",
                    ""Since starting doctoral program"")


# Un-cross the first column which right now has time to degree AND field in one. Create new columns based on the matching of major and time to degree variables
df <- df %>% 
  mutate(time_to_degree = case_when(field_time %in% times_to_degree ~ field_time,
                                TRUE ~ NA_character_),
  major_field = case_when(field_time %in% major_fields ~ field_time,
                            TRUE ~ NA_character_))

# Use tidyr::fill() to fill in the repeats of each major/broad field
df_time <- df %>% 
  fill(major_field, .direction = ""down"") %>% 
  fill(time_to_degree, .direction = ""down"") %>%
  filter(!field_time %in% major_fields) ## Now take out the rows under field_time that have no values (since they're headers), 
                                        ## which happen to be the major_fields

# Gather the years, remove the commas, and rename to appropriate columns
df_clean <- df_time %>% 
  gather(year, md_years, `1990`:`2015`) %>% ## First gather the to-be-created vars on the left
  mutate(year = factor(parse_number(year)),
         md_years = parse_number(md_years)) %>% ## readr::parse_number() turns the character values into numeric values
  # rename(field = Field) %>% 
  select(major_field = major_field, time_to_degree, year, md_years)

# # Check to confirm numbers match
# df_clean %>% 
#   group_by(major_field, year) %>% 
#   summarize(sum(md_years, na.rm = TRUE))

# Write to .csv
df_clean  %>%
  write_csv(paste(xfilename,"".csv"",sep=""""))
","2019-8"
"576",1591,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-19","tanyaberde","tidytuesday","data/2019-02-19/phds.R","require(tidyverse)
require(ggrepel)

url1 <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv'

phd_field_dat <- read_csv(url1)



## Get total Phds per year
total_phds <- phd_field_dat %>% 
  group_by(year) %>% 
  summarize(year_n_phds = sum(n_phds, na.rm=T))

## Left join this with the master dataset, and bin the years in case needed later
phd_field_dat2 <- left_join(phd_field_dat, total_phds, by=c(""year"")) %>% 
  mutate(percent = (n_phds/year_n_phds)*100,
         bin = case_when (
           (year >= 2008 & year <= 2010) ~ 2010,
           (year >= 2011 & year <= 2013) ~ 2013,
           (year >= 2014 & year <= 2016) ~ 2016,
           (year == 2017) ~ 2017,
           TRUE ~ NA_real_
           )
         )

# Quick summary by field and year/bin
broad_summ <- phd_field_dat2 %>% 
  group_by(year,broad_field) %>% 
  rename(fld = broad_field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))

major_summ <- phd_field_dat2 %>% 
  group_by(year,major_field,broad_field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))
            
socsci_summ <- phd_field_dat2 %>% 
  filter(broad_field==""Psychology and social sciences"") %>% 
  group_by(bin,major_field,field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))

psyc_summ <- phd_field_dat2 %>% 
  filter(major_field==""Psychology"") %>% 
  group_by(year,field) %>% 
  summarize(n_phds = sum(n_phds, na.rm=T),
            percent = sum(percent, na.rm=T))

# Filter required rows for the labels in plot g
plotLabs <- major_summ[major_summ$year == 2008, ] # since 2008 gets plotted on the left
plotLabs$label <- plotLabs$major_field


# Plots

## Broad areas
g <- ggplot(major_summ
            ,aes(x=year
                 ,y=log(percent)
                 ,colour=major_field
                 )) +
  geom_line(size=0.8) +
  geom_point(size=0.8) +
  geom_label_repel(data=plotLabs,
                  aes(label=label,alpha=.9)
                  , size=3.5
                  , direction = ""both""
                  ) +
  facet_wrap(~broad_field) +
  scale_x_continuous(breaks=c(2008:2017)) +
  guides(colour=F,alpha=F) +
  ggtitle(""Proportion of PhDs in broad areas of study"") +
  labs(x=""Year"",y=""Share of total annual PhDs (%, log-transformed)"",
       caption = ""Data source: NSF National Center for Science and Engineering Statistics"") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=.5))

print(g)

## Psychology
i <- ggplot(psyc_summ
            ,aes(x=year
                 ,y=log(percent)
                 ,colour=field
            )) +
  geom_line(size=0.8) +
  geom_point(size=0.8) +
  # geom_label_repel(data=plotLabs3,
  #                  aes(label=label,alpha=.9)
  #                  , size=3.5
  #                  , direction = ""both""
  # ) +
  facet_wrap(~field) +
  scale_x_continuous(breaks=c(2008:2017)) +
  guides(colour=F) +
  ggtitle(""Proportion of PhDs in psychology"") +
  labs(x=""Year"",y=""Share of total annual PhDs (%, log-transformed)""
       , caption = ""Data source: NSF National Center for Science and Engineering Statistics"") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=.5))

print(i)

#============================================================

ggsave(""phdsBroadFields.png"",g,width=12,height=7)
ggsave(""phdsPsyc.png"",i,width=12,height=7)
","2019-8"
"577",1592,"https://github.com/tanyaberde/tidytuesday/tree/master/data/2019-02-19","tanyaberde","tidytuesday","data/2019-02-19/timeAnalyses.R","rm(list=ls())

require(tidyverse)
dat1 <- ""cleaned_annual_data/2015_031.csv""
dat2 <- ""cleaned_annual_data/2016_031.csv""
dat3 <- ""cleaned_annual_data/2017_031.csv""

dat_15 <- read_csv(dat1)
dat_16 <- read_csv(dat2)
dat_17 <- read_csv(dat3)

dat_merge1 <- rbind(dat_15,dat_16)
dat_merge2 <- rbind(dat_merge1, dat_17)

master_dat <- dat_merge2 %>% 
  arrange(year,major_field,time_to_degree)
#=============================================
all_grad <- master_dat %>% 
  filter(time_to_degree %in% c(""Since starting graduate school"",""Since starting doctoral program"")) %>% 
  na.omit()
  
socsci_dat <- master_dat %>% 
  filter(major_field==""Psychology and social sciences"") %>% 
  arrange(year,time_to_degree)

socsci_grad <- socsci_dat %>% 
  filter(time_to_degree==""Since starting graduate school"") %>% 
  na.omit()

# Plots

g <- ggplot(data=socsci_grad,
            aes(x=year
                ,y=md_years
                # ,fill=time_to_degree
                )) +
  geom_bar(stat=""identity"")
print(g)

h <- ggplot(data=all_grad,
            aes(x=year
                ,y=md_years
                ,colour=time_to_degree
            )) +
  geom_line(stat=""identity"",size=0.8) +
  facet_wrap(~major_field) +
  scale_color_brewer(type=""qual"", palette=2) +
  labs(color=""Starting point"") +
  ggtitle(""Time to complete PhD across major fields"") +
  labs(x=""Year"",y=""Median number of years""
       , subtitle = ""Since beginning graduate school""
       , caption = ""Data source: NSF National Center for Science and Engineering Statistics from years 2015-2017"") +
  theme_minimal(base_size=12) +
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=.5))

print(h)

ggsave(""completionYears.png"",h,width=12,height=7)
","2019-8"
"578",1600,"https://github.com/markswitajski/TidyTuesday","markswitajski","TidyTuesday","2019-02-12/2019-02-12.R","library(tidyverse)

funding <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"") %>% 
  filter(department == ""DOD"")

fund_plot =
  ggplot() +
  geom_line(data = funding, aes(x = year, y = rd_budget/1000000000), size = 1) +
  geom_rect(aes(xmin=2009, xmax=2017, ymin=0, ymax=Inf, fill = ""Democrat""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=2001, xmax=2009, ymin=0, ymax=Inf, fill = ""Republican""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1993, xmax=2001, ymin=0, ymax=Inf, fill = ""Democrat""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1981, xmax=1993, ymin=0, ymax=Inf, fill = ""Republican""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1977, xmax=1981, ymin=0, ymax=Inf, fill = ""Democrat""), color = NA, alpha = 0.25) +
  geom_rect(aes(xmin=1974, xmax=1977, ymin=0, ymax=Inf, fill = ""Republican""), color = NA, alpha = 0.25) +
  
  scale_fill_manual(""President's Party"",
                    values = c('blue', 'red'),  
                    guide = guide_legend(override.aes = list(alpha = 0.1))) +
  
  scale_x_continuous(breaks = seq(1976, 2017, 4)) +
  scale_y_continuous(breaks = seq(0, 100, 20)) +
  
  labs(
    title = ""Dept. of Defense Spending on\nResearch & Development vs Presidential Party"",
    x = ""Year"",
    y = ""Annual Budget (Billions USD)\n"") +
    
  theme_minimal(16) +
  theme(plot.title = element_text(size=16, hjust = 0.5),
        axis.text.y = element_text(hjust = 0),
        legend.position = ""right"",
        legend.text = element_text(size = 10),
        legend.title = element_text(size = 12)
  )


fund_plot

ggsave(filename = ""20190212_Federal_Budget_DOD_by_Party.jpg"", width=20, height=10, units=""cm"", scale=1.6)
","2019-7"
"579",1601,"https://github.com/markswitajski/TidyTuesday","markswitajski","TidyTuesday","2019-02-19/2019-02-19.R","library(tidyverse)
library(gganimate)

degrees <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"") %>% 
  filter(major_field == ""Mathematics and statistics"" & !is.na(n_phds))

phds <- 
  ggplot(degrees, aes(x = reorder(field, n_phds), y = n_phds)) +
  geom_bar(stat = ""identity"", fill= ""#810F7C"") +
  coord_flip() + 
  
  theme_minimal(16) +
  theme(plot.title = element_text(size = 18, face = ""bold""),
        plot.subtitle = element_text(size = 13.5, color = ""gray40"", face = ""bold""),
        axis.title.x = element_text(size = 15, color = ""gray40"", face = ""bold""),
        axis.title.y = element_text(size = 15, color = ""gray40"", face = ""bold"")) +

  labs(
    title = ""What Are Young\nMathematicians Studying?"",
    subtitle = 'Year: {frame_time}', x = 'Field of Study', y = 'Number of PhDs Awarded') +
    transition_time(year) +
    ease_aes('quintic-in-out')

phds

anim_save(filename = ""20190219_Mathematics_PhDs.gif"", width = 40)
","2019-8"
"580",1602,"https://github.com/markswitajski/TidyTuesday","markswitajski","TidyTuesday","2019-03-05/2019-03-05.R","setwd(""~/TidyTuesday/2019-03-05"")
library(tidyverse)
library(cowplot)

jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/jobs_gender.csv"")
earnings_female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"") 
employed_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"") 

plot1 <- 
  ggplot(employed_gender, aes(x = year)) +
  geom_line(aes(y = full_time_female), color = ""darkgreen"", size = 2) +
  geom_line(aes(y = full_time_male), color = ""goldenrod"", size = 2) +
  geom_ribbon(aes(ymin = (full_time_female + 0.5), ymax = (full_time_male - 0.5)), fill = ""lightblue"", alpha = 0.5) +
  
  geom_text(aes(x = 1990, y = 95, label = ""Men""), color = ""goldenrod"") + 
  geom_text(aes(x = 1990, y = 70, label = ""Women""), color = ""darkgreen"") +
  
  ylim(0, 100) +
  
  theme_minimal(16) +
  theme(plot.title = element_text(size = 18, face = ""bold""),
        plot.subtitle = element_text(size = 13.5, color = ""gray40"", face = ""bold""),
        axis.title.x = element_text(size = 15, color = ""gray40"", face = ""bold""),
        axis.title.y = element_text(size = 15, color = ""gray40"", face = ""bold"")) +
  
  labs(
    x = '',
    y = 'Percent of Full-Time Workers'
  )
  

plot2 <- 
  ggplot(employed_gender, aes(x = year)) +
  geom_line(aes(y = part_time_female), color = ""darkgreen"", size = 2) +
  geom_line(aes(y = part_time_male), color = ""goldenrod"", size = 2) +
  geom_ribbon(aes(ymin = (part_time_male + 0.5), ymax = (part_time_female - 0.5)), fill = ""lightblue"", alpha = 0.5) +
  
  geom_text(aes(x = 1990, y = 7, label = ""Men""), color = ""goldenrod"") + 
  geom_text(aes(x = 1990, y = 32, label = ""Women""), color = ""darkgreen"") +
  
  ylim(0, 100) +
  
  theme_minimal(16) +
  theme(plot.title = element_text(size = 18, face = ""bold""),
        plot.subtitle = element_text(size = 13.5, color = ""gray40"", face = ""bold""),
        axis.title.x = element_text(size = 15, color = ""gray40"", face = ""bold""),
        axis.title.y = element_text(size = 15, color = ""gray40"", face = ""bold"")) +
  
  labs(
    x = '',
    y = 'Percent of Part-Time Workers'
  )

p <- plot_grid(plot1, plot2)

title <- ggdraw() + draw_label(""Gender gap between full-time and part-time employees"", fontface='bold')
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1))


ggsave(filename = ""20190305_Full_and_Part_Time_Rates_by_Gender.png"", width=16, height=10, units=""cm"", scale=1.6)
","2019-10"
"581",1623,"https://github.com/jasonmstevensphd/TidyTuesday_JMS","jasonmstevensphd","TidyTuesday_JMS","Tidy_Tuesday_2018_08_21.Rmd","---
title: ""Tidy Tuesday Week 21""
author: ""@jasonmstevens""
date: ""8/20/2018""
output:
  html_document:
    theme: journal
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## How A Booming Population And Climate Change Made Californias Wildfires Worse Than Ever

This is my take on the 2018 August 21 dataset provided by rfordatascience/tidytuesday.

<br>

The data for this study can be found here:

<p>

<https://github.com/rfordatascience/tidytuesday/tree/master/data/week21>

<br>

All the following code for this exercise can be found at my github repo here:

<p>

<https://github.com/jasonmstevensphd/tidytuesday/tree/2018_08_21>

<br>

Lastly, the corresponding article from Buzzfeed can be found here:

<p>

<https://www.buzzfeednews.com/article/peteraldhous/california-wildfires-people-climate>

<br>

Here we go!

###Initial Exploration of the Dataset

```{r Libraries, message=FALSE, warning=FALSE, EVAL=FALSE, include=FALSE}

# This is where we import our libraries and files. We'll also add some information to be included on our plots

library(knitr)
library(tidyverse)
library(RColorBrewer)
library(lubridate)

Cal_Fires <- read_csv(""week21_calfire_frap.csv"") %>%
  mutate(Alarm_Date = ymd(alarm_date)) %>%
  mutate(Contained_Date = ymd(cont_date)) %>%
  mutate(Year = year(Alarm_Date)) %>%
  rename(Fire_Name = fire_name) %>%
  mutate(cause2 = case_when(cause == 1 | cause == 17 ~ ""Natural"",
                            cause == 14 | is.na(cause) ~ ""Unknown"",
                            cause != 1 | cause != 14 | cause != 17 ~ ""Human""))

Time_of_Analysis <- now(tz = ""America/New_York"")
Analyst <- ""@jasonmstevens""

plot <-        theme(plot.background = element_rect(fill = ""white""))+
               theme(panel.background = element_rect(fill = ""white"",
                                                     colour=""grey50""))+
               theme(plot.title = element_text(face = ""bold"", 
                                  size = 18,
                                  color = ""navy""))+
               theme(axis.title = element_text(face = ""bold"", size = 16))+
               theme(aspect.ratio = 3.5/5)

```

<br>

To start, I imported the calfires_week21_frap.csv and I employed the case_when function that the original auther used to assign cause_2 as it's not explicitly clear what the numbers correlate to in the dataset. This was a nice example of ""case_when"" that I'll definitely add to my repretoire. 

```{r Barplot of California Wildfires, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Cal_Fires_Bar <- Cal_Fires %>%
  group_by(Year) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Year, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires"")+
  labs(x = ""Year"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Bar

```

Text

```{r California Wildfires by Month, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Cal_Fires_Month <- Cal_Fires %>%
  mutate(Month = month(Alarm_Date, label = TRUE)) %>%
  group_by(Month) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Month, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires\nby Month Since 1950"")+
  labs(x = ""Month"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Month
  

```

```{r Active Season California Wildfires, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Active_Season <- c(""Aug"", ""Sep"", ""Oct"")

Cal_Fires_Active <- Cal_Fires %>%
  mutate(Month = month(Alarm_Date, label = TRUE)) %>%
  filter(Month %in% Active_Season) %>%
  group_by(Year) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Year, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires\n During Active Season by Year"")+
  labs(x = ""Year"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Active
  
```

```{r Quiet Season California Wildfires, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}

Active_Season <- c(""Aug"", ""Sep"", ""Oct"")

Cal_Fires_Quiet <- Cal_Fires %>%
  mutate(Month = month(Alarm_Date, label = TRUE)) %>%
  filter(!(Month %in% Active_Season)) %>%
  group_by(Year) %>%
  summarize(Burned_Acres = sum(gis_acres), na.rm = TRUE) %>%
  ggplot(aes(Year, Burned_Acres))+
  geom_smooth()+
  geom_bar(stat = ""identity"")+
  ggtitle(""Acres Burned for California Wildfires\n During Quiet Season by Year"")+
  labs(x = ""Year"", y = ""Acres Burned"",
       subtitle = paste(""Generated by"", Analyst, ""on"", Time_of_Analysis))+
  plot

Cal_Fires_Quiet

ggsave(Cal_Fires_Quiet, filename = ""Cal_Fire_Quiet.png"")
  
```","2018-34"
"582",1626,"https://github.com/adanvers/tidyTuesday","adanvers","tidyTuesday","tidyTuesday_2019_1_8_tvDramas.Rmd","---
title: 'Tidy Tuesday Jan 8 2019: TV Dramas'
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(ggplot2)
```

This is the first contribution to Tidy Tuesdays of Alex Danvers.

The data set contains information on TV Dramas from 1990 to 2018, including ratings, shares, and secondary categorizations of the shows.

In this document I explore changes in the common secondary classifications of dramas over time. This may give insight into the kinds of dramas that have been popular across different decades--dramas mixed with action, or with comedy, etc.

# Read in the Data

```{r read and explore data}
# read in data
tvData <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-08/IMDb_Economist_tv_ratings.csv"")

### examine basic characteristics of data
dim(tvData)
head(tvData)

# we should convert the date info from an integer to a date format
tvData$dateFormatted <- date(tvData$date)

# then we can save just the year, to simplify future viewing
tvData$year <- year(tvData$dateFormatted)

# what range does the data span?
range(tvData$dateFormatted)

# how many unique shows?
length(unique(tvData$title))

# how many genres?
length(unique(tvData$genres))
# 97! but this includes ""combo genres""
```

The data set had a single genre variable, saved as a string, that includes multiple categorizations, separated by commas. Each TV show can have 1, 2, or 3 categorizations. This means that assessments of the secondary categorizations of TV shows are not mutually exclusive: more action shows doesn't necessarily mean less of other shows, because the total number of secondary categories is not constant from year to year. 

```{r create genre categorizations}
# create list of all genres
genres <- unique(unlist(strsplit(as.character(tvData$genres), "","")))

# looping through each genre to create dummy codes
for (i in 1:length(genres)) {
  tvData[,genres[i]] <- as.numeric(grepl(genres[i], as.character(tvData$genres)))
}

# examine overall rates of all categories
colMeans(tvData[,genres])

# save the most common secondary categories
commonCats <- which(colMeans(tvData[,genres]) > .10)

# create a data set that contains the proportion of genre by year
genreProps <- tvData %>%
  group_by(year) %>%
  summarise_at(mean, .vars=genres) %>%
  gather(key=""genreCat"", value=""Proportion"", genres[2:length(genres)])
```

# Create the Final Plot

In the plot below, we plot the change over time in common secondary categorizations of TV dramas.

A red dotted line has been placed at the 25% mark, for ease of reference.

Plots also have a black loess line superimposed on them to track the shape of the data.

```{r plot}
ggplot(data=genreProps[which(genreProps$genreCat %in% names(commonCats)),], aes(y=Proportion, x=year))+
  geom_line(aes(color=genreCat))+
  geom_point(aes(color=genreCat))+
  geom_line(stat=""smooth"", method=""loess"", se=FALSE, color=""black"", lty=1, alpha=0.75)+
  theme_bw()+
  facet_grid(.~genreCat)+
  geom_hline(yintercept=0.25, lty=2, color=""red"")+
  theme(legend.position=""none"", plot.title=element_text(hjust=0.5))+
  labs(title=""Common Secondary Categorizations \n of Dramas from '90 to '18"")+
  scale_x_continuous(breaks=c(1990,2000,2010),
                     labels=c(""'90"",""'00"",""'10""))
```

This plot suggests that drama/comedies were most common in the early 90's, but declined to below 25% by ~95. Around 95 there was a brief spike in drama/action shows, but this trend was shortlived. From around 2000 to 2010 the number of drama/crime shows increased, but they have declined in recent years. 

There was also a small rise in drama/romance shows from 1990 to ~2005, but the proportion of these shows has declined in the last decade. There were small fluctuations in the proportion of drama/mysteries over this time period, and this genre is now in decline.

Currently the most popular secondary genre for a drama is crime.

","2019-2"
"583",1631,"https://github.com/grwllrnc/TidyTuesday/tree/master/2019-2-19","grwllrnc","TidyTuesday","2019-2-19/phd_by_field.Rmd","---
title: ""#TidyTuesday: PhDs Awarded by Field""
author: ""grwllrnc""
date: ""19 Februar 2019""
output: html_document
---

```{r}
library(tidyverse)

# set ggplot2 theme
theme_set(theme_light())
```

```{r}
# read data
data <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv"")

# clean that mess
data <- data %>%
  mutate(broad_field = str_to_title(broad_field),
         field = str_replace(field, ""Anthropology, generalj"", ""Anthropology, general""),
         field = str_to_title(field))
```

### Which fields of study have the highest change in number of graduates over time (greatest variance)?

```{r}
# Standard Deviation of Fields of Study
sd_top5 <- data %>%
  group_by(field) %>%
  mutate(sd_field = sd(n_phds, na.rm = TRUE)) %>%
  ungroup() %>%
  filter(sd_field > quantile(sd_field, 0.95, na.rm = TRUE)) %>%
  mutate(field = fct_reorder(field, sd_field))

sd_top5 %>%
  ggplot(aes(field, sd_field, color = broad_field, size = n_phds)) +
  geom_point() +
  coord_flip() +
  scale_color_discrete(name = ""Broad Field"") +
  scale_size_continuous(name = ""# of Graduates"") +
  labs(title = ""Fields of Study with Highest Change in Number of Graduates over Time"",
       subtitle = ""Sorted by Standard Deviation, Top 5%"",
       caption = ""#tidytuesday, 2019-02-19 | @grwllrnc\nData source: National Science Foundation, nsf.gov"",
       x = ""Field of Study"",
       y = ""Standard Deviation of # of Awarded PhDs"")

ggsave(""../Tidy Tuesday/Variance 1.png"", units = ""cm"", width = 29.7, height = 21)
```


```{r}
# Fields of Study with Highest Change in Number of Graduates over Time (top 5%)
selected_fields <- as.character(unique(sd_top5$field))
  
# Change over time of each field (top 5%)
# Facet plot
data %>%
  filter(field %in% selected_fields) %>%
  group_by(field) %>%
  mutate(sd_field = sd(n_phds, na.rm = TRUE)) %>%
  ungroup() %>%
  ggplot(aes(year, n_phds)) +
  geom_line() +
  scale_x_continuous(breaks = c(2009, 2011, 2013, 2015, 2017)) +
  facet_wrap(~ fct_reorder(field, desc(sd_field)), scale = ""free_y"") +
  labs(title = ""Fields of Study with Highest Change in Number of Graduates over Time"",
       subtitle = ""Sorted by Standard Deviation, Top 5%"",
       caption = ""#tidytuesday, 2019-02-19 | @grwllrnc\nData source: National Science Foundation, nsf.gov"",
       x = ""Year"",
       y = ""# of Awarded PhDs"")

ggsave(""../Tidy Tuesday/Variance 2.png"", units = ""cm"", width = 21, height = 21)
```
","2019-8"
"584",1642,"https://github.com/andrewsris/Tidy_Tuesday/blob/master/2019_01_29/doc/lab_notebook/EDA_2019_01_29.Rmd","andrewsris","Tidy_Tuesday","2019_01_29/doc/lab_notebook/EDA_2019_01_29.Rmd","---
title: ""EDA_2019_01_29""
author: ""Andrew Srisuwananukorn""
date: ""2/2/2019""
output: html_document
---

#Introduction
- exploration of cheese data provided by Thomas Mock of Tidy Tuesday
https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-29

- Also inspired by clustering methods DataCamp lesson by Dmitry 

#Import libraries
```{r}
library(tidyverse)
library(ggplot2)
library(purrr)
library(cluster)
library(dendextend)

```


#Import Data
```{r}
raw_cheese_df <- read_csv(""/Users/Andrewsris/Box/Tidy_Tuesday/2019_01_29/data/1_original/clean_cheese.csv"") 
cheese_df <- raw_cheese_df %>% 
  gather(key = Cheese, value = value, 2:ncol(raw_cheese_df)) %>% 
  spread(key = names(raw_cheese_df)[1], value = ""value"") %>% 
  filter(!str_detect(Cheese, ""Total""))
```

#Scale data
This is unneceesary for this specific data frame, as the scale is the same for each feature. However I am including this section for future datasets, when i use similar methods.

```{r}
scaled_cheese_df <- cheese_df %>% column_to_rownames(""Cheese"") %>% scale() 
scaled_dist_cheese <- scaled_cheese_df %>% dist()
```

#Hierarchical clustering
Distance = ""euclidian""
hierarchical clustering method = ""complete""
```{r}
hc_cheese <- hclust(scaled_dist_cheese, method = ""complete"")

#By visual inspection, optimal k=2
hc_cheese %>% as.dendrogram() %>% set(""branches_k_color"", h = 10) %>% plot()
par(mar = c(5,4,1,6)) #Reset margins: bottom, left, top, right
hc_cheese %>% as.dendrogram() %>% 
  set(""branches_k_color"", k = 2) %>% 
  set(""labels_cex"", 0.75) %>% 
  plot(horiz = TRUE,
       main = ""Hierarchical Clustering by Cheese Consumption"", 
       sub = ""k=2 by visual inspection"") %>% 
  abline(v = 15, lty = 2)

#Assign cluster groups
clusters_hc <- cutree(hc_cheese, k = 2)

```

#K-means analysis
```{r}
#We will use the elbow plot to determine optimal k
# Use map_dbl to run many models with varying value of k (centers)
tot_withinss <- map_dbl(1:10,  function(k){
  model <- kmeans(x = scaled_dist_cheese, centers = k)
  model$tot.withinss
})

# Generate a data frame containing both k and tot_withinss
elbow_df <- data.frame(
  k = 1:10 ,
  tot_withinss = tot_withinss
)
ggplot(elbow_df, aes(x = k , y = tot_withinss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:10) + 
  labs(title = ""Elbow Plot for K-means clustering of Cheese Consumption"",
       subtitle = ""Optimal k=2 by visual inspection of elbow point"",
       y = ""Total within squared sums"",
       x = ""k"") +
  geom_point(data = elbow_df %>% filter(k == 2), aes(x = k, y = tot_withinss, color = ""red"", size = 3), show.legend = FALSE)

#Optimal k = 2
km_cheese <- kmeans(scaled_dist_cheese, centers = 2)
clusters_km <- km_cheese$cluster


```

#PAM and silhouette
- pam is from the cluster pacakage
```{r}
#using the silhouette technique to determine optimal k

# Use map_dbl to run many models with varying value of k
sil_width <- map_dbl(2:10,  function(k){
  model <- pam(x = scaled_dist_cheese, k = k)
  model$silinfo$avg.width
})

# Generate a data frame containing both k and sil_width
sil_df <- data.frame(
  k = 2:10,
  sil_width = sil_width
)

# Plot the relationship between k and sil_width
ggplot(sil_df, aes(x = k, y = sil_width)) +
  geom_line() +
  scale_x_continuous(breaks = 2:10) +   
  labs(title = ""Silhouette Plot for K-means clustering of Cheese Consumption"",
       subtitle = ""Optimal k=2 by maximal silhouette width"",
       y = ""Average silhouette width"",
       x = ""k"") +
  geom_point(data = sil_df %>% filter(k == 2), aes(x = k, y = sil_width, color = ""red"", size = 3), show.legend = FALSE)

#Optimal k = 2
pam_cheese <- pam(scaled_dist_cheese, k = 2)
plot(silhouette(pam_cheese))

clusters_pam <- pam_cheese$clustering

```


#Merge df
```{r}
total_cheese <- mutate(cheese_df, 
               cluster_hc = clusters_hc,
               cluster_km = clusters_km,
               cluster_pam = clusters_pam) %>% gather(-c(""Cheese"",""cluster_km"", ""cluster_hc"", ""cluster_pam""), key = ""year"", value = ""eaten"")

total_cheese %>% ggplot(aes(x = year, y = eaten, color = factor(cluster_km))) + 
  geom_line(aes(group = Cheese),show.legend = FALSE) + 
  geom_smooth(aes(group = cluster_km), na.rm=TRUE, show.legend = FALSE) +
  geom_text(data = total_cheese %>% filter(year == 2013), 
            aes(label = Cheese), size = 2.5, nudge_y = 0.5, show.legend = FALSE) +
  scale_x_discrete(breaks = seq(1970,2015, 5)) +
  theme(axis.text.x = element_text(angle = 45)) +
  labs(title = ""Average cheese consumption from USDA"",
       subtitle = ""Optimal k=2 by Elbow method of K-means cluster analysis"",
       y = ""Average cheese consumption (lbs per person)"",
       x = ""Year""
       )
```

","2019-5"
"585",1647,"https://github.com/brfry/tidy_tuesday/blob/master/2019/tidy_tuesday_01152019_space.R","brfry","tidy_tuesday","2019/tidy_tuesday_01152019_space.R","# libraries
library(tidyverse)
library(RColorBrewer)

#===============================================================================

# read in data
agencies_df <- read_csv(""data/agencies.csv"")
launches_df <- read_csv(""data/launches.csv"")

#===============================================================================

# set colors and themes. idk which theme i like so there are two for now.
colors_four = RColorBrewer::brewer.pal(5, ""Dark2"")[5:2]

colors_space <- c(""#542788"", 
                  ""#35978f"",
                  ""#7f3b08"",
                  ""#bf812d"",
                  ""#9ebcda""
                   )
        
colors_space2 <- c(""#542788"", 
                   ""#35978f"",
                   ""#00441b"",
                   ""#006d2c"",
                   ""#b30000"",
                   ""#9ebcda""
)

# theme with custom colors
theme_space <- list(theme_bw(),  scale_color_manual(values = colors_space),
                    scale_fill_manual(values = colors_space))

theme_space2 <- list(theme_bw(),  scale_color_manual(values = colors_space2),
                     scale_fill_manual(values = colors_space2))
#===============================================================================

# explore launches
launches_df %>%
        count(type, sort = TRUE) %>%
        top_n(10, n) %>%
      #  mutae(launch_date = lubridate::ymd(launch_date))) %>%
      #  group_by(type) %>%
      #  summarise()
        ggplot(aes(x = type, y = n)) +
        geom_point()

#===============================================================================

# how have launches changed by agency type and number over time:
launches_df %>%
        group_by(launch_year, agency_type, type) %>%
        summarise(count = n()) %>%
        rename(Agency = agency_type) %>%
        ggplot(aes(x = launch_year, y = count, fill = Agency)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""The Changing Space Industry"", y = ""Number of Launches"",
             x = ""Year"") +
        theme_space

#===============================================================================

# filtering for state only:
launches_df %>%
        filter(agency_type == ""state"") %>%
        group_by(launch_year, state_code) %>%
        summarise(count = n()) %>%
        rename(State = state_code) %>%
        mutate(Nations = ifelse(State == ""US"", ""United States"",
                               ifelse(State == ""CN"", ""China"",
                                      ifelse(State == ""SU"", ""Soviet Union"",
                                             ifelse(State == ""RU"", ""Russia"",
                                                    ifelse(State == ""IN"", ""India"",
                                             ""Other"")))))) %>%
        mutate(Nations = factor(Nations, levels = c(""United States"", ""China"", 
                                                  ""Soviet Union"", ""Russia"", 
                                                  ""India"", ""Other""))) %>%
        ggplot(aes(x = launch_year, y = count, fill = Nations)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""Nation State Launches"", y = ""Number of Launches"",
             x = ""Year"") +
        theme_space2 

#===============================================================================

# just compare private vs startup
launches_df %>%
        filter(agency_type != ""state"") %>%
        group_by(launch_year, agency_type, state_code) %>%
        summarise(count = n()) %>%
        mutate(state_code = ifelse(state_code == ""US"", ""United States"",
                                   ifelse(state_code == ""RU"", ""Russia"",
                                          ifelse(state_code == ""J"", ""Japan"",
                                                 ifelse(state_code == ""F"", ""France"",
                                                        "" Cayman Islands""))))) %>%
        ggplot(aes(x = launch_year, y = count, fill = agency_type)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""Private and Startup Launches"", y = ""Number of Launches"",
             x = ""Year"") +
        facet_grid(state_code~.) +
        theme_space2 #+ scale_fill_viridis_d(name = "" "")

#===============================================================================

# filtering for private and startup only and comparing all companies
launches_df %>%
        filter(agency_type != ""state"") %>%
        group_by(launch_year, agency, state_code) %>%
        summarise(count = n()) %>%
        mutate(state_code = ifelse(state_code == ""US"", ""United States"",
                                   ifelse(state_code == ""RU"", ""Russia"",
                                          ifelse(state_code == ""J"", ""Japan"",
                                                 ifelse(state_code == ""F"", ""France"",
                                                        "" Cayman Islands""))))) %>%
        ggplot(aes(x = launch_year, y = count, fill = agency)) +
        geom_bar(stat = ""identity"") + 
        labs(title = ""Private and Startup Launches"", y = ""Number of Launches"",
             x = ""Year"") +
        facet_grid(state_code~.) +
        theme_space2 + scale_fill_viridis_d(name = ""Company Code"")


#===============================================================================
","2019-3"
"586",1650,"https://github.com/mpodell/tidytuesday/tree/master/2019-01-15","mpodell","tidytuesday","2019-01-15/space_race.R","## 2019-01-15 #TidyTuesday Project 
## Author: Michael O'Dell
## File create date: 2019-01-15
## Copyright 2019 Michael O'Dell
## License: MIT


# SET ENVIRONMENT ---------------------------------------------------------

library(tidyverse)



# LOAD DATA ---------------------------------------------------------------

agencies <- read_csv(""../../../tidytuesday/data/2019/2019-01-15/agencies.csv"")
launches <- read_csv(""../../../tidytuesday/data/2019/2019-01-15/launches.csv"")


# EXPLORE DATA ------------------------------------------------------------

dim(launches)
str(launches)
# check for missing values:
apply(apply(launches, 2, is.na), 2, sum)
# lots of missing agencies
# lots of missing variants--likely many vehicles do not have variants
# a few missing launch dates (but no missing years)
# some missing missions
apply(launches, 2, function(x) {length(unique(x))})
# tag has a unique entry for each row.
# launch and Julian dates are almost unique (several launches on some days)
# similarly missions map almost 1:1 with launches.
# the launch history spans 62 years
# there are 366 unique launch vehicles with 73 variants
# agency_type: private, startup, and state
# type: generic organization (O)
#       launch agency (LA), 
#       launch vehicle manufacturer (LV), 
#       satellite manufacturer (PL), 
#       rocket experimenter (RE), 
#       engine/motor manufacturer (E) 
#       launch site (LS)

apply(launches %>% select(-tag,
                          -JD,
                          -launch_date,
                          -mission), 2, table)

# all the missing agencies are state code SU (USSR)
launches %>% 
  filter(
    is.na(agency)
  ) %>% 
  select(
    state_code
  ) %>% table


dim(agencies)
str(agencies)
# check for missing values:
apply(apply(agencies, 2, is.na), 2, sum)
# nothing missing.
apply(agencies, 2, function(x) {length(unique(x))})
# INVESTIGATE: launches indicates 41 agencies. However, agencies list 74
# INVESTIGATE: agencies indicate 43 launches while launches indicates 5726
# agencies and launches agree on the number of state codes (17)
# USEFUL: agencies provide full names for agencies (launches$agency <> agencies$ucode)
# lots of missing short_english_names and english_names
# agency_type includes: private, startup, and state
# INVESTIGATE: do agencies and launches agency_types match?

apply(agencies, 2, table)
# lat and lon are blank so not very useful
# location looks to be the agency hq location-not the launch location.

# Why the discrepancy between files in agencies?
setdiff(launches$agency, agencies$ucode)  # US, BR, CH & others missing from agencies$ucode
agencies %>%
  filter(
    ucode %in% intersect(launches$agency, agencies$ucode)
  ) %>%
  select(
    ucode,
    name
  ) %>% print(n = Inf)
# commercial launch orgs are common to both files

agencies %>%
  select(
    ucode,
    name
  ) %>% print(n = Inf)

launches %>%
  select(
    agency,
    agency_type
  ) %>% unique %>% print(n = Inf)

## so launches seems to consolidate all agencies for a state under a single country code.
launches %>%
  filter(
    agency_type == ""state""
  ) %>%
  select(
    agency,
    state_code
  ) %>% table
# state code SU has no ocurrances of an agency as noted above.


# Why the discrepancy between files in number of launches?
sum(agencies$count) - nrow(launches) # agencies is missing 20 launches
with(launches, table(category))


# Do agencies and launches agency_type match?
table(launches$agency_type)
agencies %>% 
  group_by(
    agency_type
  ) %>%
  summarize(
    count = sum(count)
  )
# nope. agencies is missing 20 launches over all categories.
# agencies does not seem to add value. Just use launces.

launches %>% 
  filter(
    state_code == ""I-ESA""
  ) %>% select(type, mission, category, launch_year)


# POSE QUESTION AND PLOT FOR ANSWER ---------------------------------------

## Do different agency types have different learning curves?
## Hypothesis:  state agencies will be cautious and lead, 
##              private firms will build on state knowledge and contracts but will be
##                cautious given that they rely on state support
##              startups will be quick, move up the learning curve quickly but cut corners

# Over all states
launches %>%
  group_by(
    state_code,
    agency_type
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    # persistence = n(),
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>%
  ggplot(
    aes(experience, launch_success, color = agency_type)
  ) +
  geom_smooth(se = FALSE) +
  labs(title = ""Learning Curves by Agency Type\n(All Countries)"", 
       x = ""Experience (years)"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)


# Just states with state, private, and start-ups
varied <- launches %>%
  select(
    state_code, 
    agency_type
  ) %>%
  unique %>%
  group_by(
    state_code
  ) %>%
  summarize(
    eco = n()
  ) 


launches %>%
  filter(
    state_code %in% (varied %>% filter(eco > 2) %>% select(state_code))
  ) %>%
  group_by(
    state_code,
    agency_type
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    # persistence = n(),
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>%
  ggplot(
    aes(experience, launch_success, color = agency_type)
  ) +
  geom_smooth() +
  labs(title = paste0(""Learning Curves by Agency Type\n("", 
                      (varied %>% filter(eco > 2) %>% select(state_code)), "" only)""), 
       x = ""Experience (years)"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)



p <- launches %>%
  filter(
    state_code %in% (varied %>% filter(eco > 2) %>% select(state_code))
  ) %>%
  group_by(
    state_code,
    agency_type
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    # persistence = n(),
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>%
  ggplot(
    aes(launch_year, launch_success, color = agency_type)
  ) +
  geom_smooth() +
  labs(title = paste0(""Learning Curves by Agency Type\n("", 
                      (varied %>% filter(eco > 2) %>% select(state_code)), "" only)""), 
       x = ""Year"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)


# learning curve by countries with state only; state + private; & state, private, + startup
launches %>%
  left_join(., varied, by = ""state_code"") %>%
  group_by(
    state_code
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>% 
  ggplot(
    aes(experience, launch_success, color = factor(eco))
  ) +
  geom_smooth() +
  labs(title = ""Learning Curves by Agency Type Count\n(All Countries)"", 
       x = ""Experience (years)"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)

# by year
launches %>%
  left_join(., varied, by = ""state_code"") %>%
  group_by(
    state_code
  ) %>%
  mutate(
    country_start = min(launch_year),
    experience = launch_year - country_start,
    launch_success = ifelse(category == ""O"", 1, 0)
  ) %>% 
  ggplot(
    aes(launch_year, launch_success, color = factor(eco))
  ) +
  geom_smooth() +
  labs(title = ""Learning Curves by Agency Type Count\n(All Countries)"", 
       x = ""Year"", y = ""Annual Launch Success Rate"",
       color = ""Agency Type"") +
  scale_y_continuous(labels = scales::percent)

file_name <- ""tidytuesday_2019-01-15_mpo.jpeg""

jpeg(file = file_name, 
     width = 9, height = 6, units = ""in"", pointsize = 4, res = 300)

p

dev.off()


","2019-3"
"587",1721,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","data/2018-09-04/readme.rmd","# Fast food entree data

* Data from [fastfoodnutrition.com](https://fastfoodnutrition.org/mcdonalds/chart) 
* Please notice that I really only took entrees - feel free to select ALL food, sides, drinks, desserts, etc.

At the request of the website owner - I have removed web-scraping guide.
","2018-36"
"588",1722,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","data/2018-09-25/raw/invasive_species.R","library(tidyverse)

df <- read_csv(""afr_species.csv"") %>% 
        janitor::clean_names() %>% 
        select(species:origin)

df %>% write_csv(""africa_species.csv"")

df1 <- read_csv(""table1.csv"") %>% janitor::clean_names()
tab_1 <- df1 %>% 
        select(rank:o_tt) %>% 
        bind_rows(df1 %>% 
                          select(rank_1:o_tt_1) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        bind_rows(df1 %>% 
                          select(rank_2:o_tt_2) %>% 
                          set_names(""rank"", ""country"", ""o_tt"")
        ) %>% 
        filter(!is.na(rank)) %>% 
        rename(""invasion_threat"" = o_tt)

df2 <- read_csv(""table2.csv"") %>% janitor::clean_names()
tab_2 <- df2 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:]+""),
               ti_ct = parse_number(ti_ct) * 1000000) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df2 %>% 
                select(""country"" = x4, ""ti_ct"" = ti_ct_millions_1) %>% 
                        mutate(rank = parse_number(country),
                               country = str_extract(country, ""[:alpha:]+""),
                               ti_ct = parse_number(ti_ct) * 1000000) %>% 
                        filter(!is.na(rank))
        ) %>% 
        bind_rows(df2 %>% 
                          select(""country"" = x7, ""ti_ct"" = ti_ct_millions_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_ct = parse_number(ti_ct) * 1000000) %>% 
                          filter(!is.na(rank))
                
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df3 <- read_csv(""table3.csv"") %>% janitor::clean_names()
tab_3 <- df3 %>% 
        select(""country"" = x1, ""ti_ct"" = ti_ct_millions, 
               ""gdp_mean"" = x4, ""gdp_proportion"" = proportion_of) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:]+""),
               ti_ct = parse_number(ti_ct) * 1000000,
               gdp_mean = parse_number(gdp_mean) * 1000000,
               gdp_proportion = as.numeric(gdp_proportion)
        ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x6, ""ti_ct"" = ti_ct_millions_1, 
                                 ""gdp_mean"" = x9, ""gdp_proportion"" = proportion_of_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>%
        bind_rows(df3 %>% 
                          select(""country"" = x11, ""ti_ct"" = ti_ct_millions_2, 
                                 ""gdp_mean"" = x14, ""gdp_proportion"" = proportion_of_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_ct = parse_number(ti_ct) * 1000000,
                                 gdp_mean = parse_number(gdp_mean) * 1000000,
                                 gdp_proportion = as.numeric(gdp_proportion)
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_ct)

df4 <- read_csv(""table4.csv"") %>% janitor::clean_names()
tab_4 <- df4 %>% 
        select(""country"" = rank_country, ""ti_cs"" = ti_cs_millions_us) %>% 
        mutate(rank = parse_number(country),
               country = str_extract(country, ""[:alpha:]+""),
               ti_cs = parse_number(ti_cs) * 1000000
               ) %>% 
        filter(!is.na(rank)) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_1, ""ti_cs"" = ti_cs_millions_us_1) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
                  ) %>%
        bind_rows(df4 %>% 
                          select(""country"" = rank_country_2, ""ti_cs"" = ti_cs_millions_us_2) %>% 
                          mutate(rank = parse_number(country),
                                 country = str_extract(country, ""[:alpha:]+""),
                                 ti_cs = parse_number(ti_cs) * 1000000
                          ) %>% 
                          filter(!is.na(rank))
        ) %>% 
        rename(""invasion_cost"" = ti_cs)

df6 <- read_csv(""table6.csv"") %>% janitor::clean_names()
tab_6 <- df6 %>% 
        select(species, ""max_impact_percent"" = maximum_reported_species) %>%
        filter(!is.na(species)) %>% 
        mutate(rank = 1:n(),
               species = species,
               max_impact_percent = parse_number(max_impact_percent)
        ) %>% 
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species, 
                                 ""max_impact_percent"" = maximum_reported_species_1) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:]+""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>%
        bind_rows(df6 %>% 
                          select(""species"" = maximum_reported_species_1, 
                                 ""max_impact_percent"" = maximum_reported) %>%
                          filter(species != ""% impact"") %>% 
                          mutate(rank = 1:n(),
                                 species = str_extract(species, ""[:alpha:]+""),
                                 max_impact_percent = parse_number(max_impact_percent)
                          )
        ) %>% 
        filter(!is.na(species))

tab_list <- list(table_1 = tab_1, table_2 = tab_2, table_3 = tab_3, table_4 = tab_4, table_6 = tab_6)

tab_list %>% 
        names() %>% 
        walk(~ write_csv(tab_list[[.]], glue::glue(""{.}.csv"")))
","2018-39"
"589",1723,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","data/2018-09-25/raw/readme.rmd","# Raw tabular data

Table data extracted from supplementary PDF via [Tabula](https://tabula.technology/) open-source software. 

This ended up being super messy - cleaning script found below.

[Cleaning Script](https://github.com/rfordatascience/tidytuesday/blob/master/data/2018-09-25/raw/invasive_species.R)
","2018-39"
"590",290,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 03-09-2019.R","
# Database ----------------------------------------------------------------



cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")



# Packages to upload ------------------------------------------------------

library(tidyverse)
library(sunburstR)

SB2<-cpu%>%
  mutate(path2 = paste(date_of_introduction, designer, process, area, sep=""-"")) %>%
  filter(date_of_introduction %in% c(2005:2019)) %>%
  select(path2, transistor_count) 


SB_2 <- as.data.frame(sapply(SB2,gsub,pattern=""-NA-NA"",replacement=""""))
SB_2 <- as.data.frame(sapply(SB2,gsub,pattern=""-NA"",replacement=""""))


p2 <- sunburst(SB_2, legend=FALSE)
p2


# Alternative -------------------------------------------------------------


sb3 <- sund2b(SB_2, width=""100%"")




# Data checking -----------------------------------------------------------


SByear<-cpu%>% group_by(date_of_introduction)%>%
  summarise(count=sum(transistor_count))
","2019-36"
"591",291,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 04-11-2019.R","# Upload the data ---------------------------------------------------------

commute_mode <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-11-05/commute.csv"")

# Upload packages ---------------------------------------------------------

library(readxl)
library(tidyverse)
library(readxl)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggalt)
library(scales)
library(hrbrthemes)


View(commute_mode)

# Prepare the data --------------------------------------------------------


data<-commute_mode %>% group_by(state_region,mode)%>%summarize(total=sum(n)) %>% spread(mode,total) %>%
 mutate (diff=round(Walk-Bike,1),
            label=ifelse(diff>0, paste0(""+"",comma_format()(diff)), paste0(diff))) %>%
  filter(state_region!=""NA"")






# Ggplot ------------------------------------------------------------------


g<-ggplot(data, aes(x = Walk, xend = Bike, y=reorder(state_region,Walk))) + 
  geom_dumbbell(colour = ""#dddddd"",
                size = 3,
                colour_x = ""#228b34"",
                colour_xend = ""#1380A1"")+
  labs(
    title = ""Bicycling and Walking to Work in the United States: 2008-2012"",
    subtitle = ""Number of commuters and difference by Region"",
    caption = ""\n Source:Tidy Tuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") + theme(legend.position = ""bottom"",
                    legend.box = ""vertical"")  + 
  geom_text(data = filter(data, state_region == ""Northeast""),
                                                          aes(x = Walk, y = state_region),
                                                          label = ""Walk"", fontface = ""bold"",
                                                          size=3,
                                                          color = ""#e13d3d"",
                                                          vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""Northeast""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""West""),
            aes(x = Walk, y = state_region),
            label = ""Walk"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""West""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8)+
  geom_text(data = filter(data, state_region == ""North Central""),
            aes(x = Walk, y = state_region),
            label = ""Walk"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""North Central""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""South""),
            aes(x = Walk, y = state_region),
            label = ""Walk"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8) +
  geom_text(data = filter(data, state_region == ""South""),
            aes(x = Bike, y = state_region),
            label = ""Bike"", fontface = ""bold"",
            size=3,
            color = ""#e13d3d"",
            vjust = -1.8)
  

g2<-g + 
  geom_rect(aes(xmin=950000, xmax=1150000, ymin=-Inf, ymax=Inf), fill=""#d3d3d3"") +
  geom_text(aes(label=label, y=state_region, x=1050000), fontface=""bold"", size=3.5, color=""#008000"") +
  geom_text(aes(x=1050000, y=4.03, label=""Number of commuters""),
            size=3.5, vjust=-3, fontface=""bold"") +
  scale_x_continuous(breaks = c(100000, 300000, 500000, 700000), limits = c(-1, 1150000), label=comma_format()) + 
  theme_ipsum_rc(grid=""XY"")


g2 + geom_label(aes(x = 612611, y = 3.7, label = ""Northeast: Highest number of commuters who walked to work""), 
           hjust = 0, 
           vjust = 0.5, 
           lineheight = 0.8,
           colour = ""#648aed"", 
           fill = ""#f7f7f7"", 
           label.size = NA, 
           family=""Helvetica"", 
           size = 3) +theme(legend.position = ""top"",
                            legend.box = ""horizontal"",
                            plot.background=element_rect(fill=""#f7f7f7""))

","2019-44"
"592",292,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 05-08-2019.R","
# Upload the data ---------------------------------------------------------

bob_ross <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")
str(bob_ross)
colnames(bob_ross)
View(bob_ross)


# Data wrangling ----------------------------------------------------------


library(tidyverse)
test<-bob_ross%>%gather(Painting,value,3:69) %>%group_by(Painting)%>%summarise(total=sum(value))%>% arrange(total)

View(test)

test10<-top_n(test,10)


# Data visualization ------------------------------------------------------

library(hrbrthemes)
ggplot<-test10 %>% ggplot( aes(x=reorder(Painting,total), y=total)) +
  geom_bar(stat=""identity"", fill=""#69b3a2"", width=0.6) +
  coord_flip() +
  
  theme_ipsum() +
  
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.text = element_text(hjust = 0.5)
  ) + ylab(""total"") +
  xlab(""Paiting"") +
  labs(
    title = ""Bob Ross - painting by the numbers - Top 10"",
    subtitle = ""TidyTuesday 5.8.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") 




ggplot+geom_text(aes(label=total),hjust=-0.5) 
","2019-31"
"593",293,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 07-5-2019.R","
# Upload the data ---------------------------------------------------------

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")


# Create average student ratio ---------------------------------------------

library(dplyr)
student_ratio<-student_ratio%>%group_by(country)%>%mutate(mean = mean(student_ratio, na.rm = TRUE))


# Prepare the colour palette ----------------------------------------------


library(plotly)

# light grey boundaries
l <- list(color = toRGB(""grey""), width = 0.5)

# specify map projection/options
g <- list(
  showframe = FALSE,
  showcoastlines = FALSE,
  projection = list(type = 'Mercator')
)


# Plotly graph ------------------------------------------------------------



p <- plot_geo(student_ratio) %>%
  add_trace(
    z = ~student_ratio, color = ~student_ratio, colors = 'Blues',
    frame = ~year, 
    text =  ~paste('</br> Country: ', country,
                     '</br> Year: ', year,
                     '</br> Global Student to Teacher Ratios(%): ', round(student_ratio,2)), 
    
    
    hoverinfo = ""text""
  , locations = ~country_code, marker = list(line = l)
  ) %>%
  colorbar(title = 'Global Student to Teacher Ratios') %>%
  layout(
    title = 'Global Student to Teacher Ratios<br><a href=""http://data.uis.unesco.org/index.aspx?queryid=180"">UNESCO Institute of Statistics</a>',
    annotations = 
      list(text = ""#TidyTuesday 07.05.2019<br>@Juanma_MN"", 
           showarrow = F, xref='paper', yref='paper', 
           xref = 'paper', x = 0,
           yref = 'paper', y = 1,
           font=list(size=10, color=""black"")),
    geo = g
  )

p


","2019-19"
"594",294,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 13-8-2019.R","
# Upload the data ---------------------------------------------------------

library(ggplot2)
library(hrbrthemes)

library(gridExtra)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

View(emperors)

colnames(emperors)
str(emperors)

library(dplyr)
library(lubridate)


# Calculate the reign length ----------------------------------------------

reign_start <- as.POSIXct(emperors$reign_start, format = ""%Y-%m-%d"")
reign_end<- as.POSIXct(emperors$reign_end, format = ""%Y-%m-%d"")
View(emperors)


empeorers2<-emperors %>% mutate(elapsed_time = (reign_start %--% reign_end)/ddays(1)) %>% select(""name"", ""reign_start"",
                                                                                                 ""reign_end"", ""elapsed_time"", ""rise"",""cause"",""killer"",""dynasty"",""era"")
View(emperors)
View(empeorers2)


empeorers3<-empeorers2%>%group_by(dynasty)%>%summarize(average=round(sum(elapsed_time),0))    # for first graph




empeorers4<-empeorers2%>%group_by(dynasty,rise)%>%summarize(average=round(sum(elapsed_time),0)) %>%
  arrange(-average)   # for second graph





# First graph -------------------------------------------------------------



g<- ggplot(empeorers3, aes(x=reorder(dynasty,average), y=average)) +
  geom_bar(stat=""identity"", fill=""#69b3a2"", width=0.6) +
  coord_flip() +
  
  theme_ipsum() +
  
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.text = element_text( size=48 )
  ) +
  
  ylim(0,60000) +
  
  ylab(""Total time in days"") +
  
  xlab("""") +
  
  labs(
    title = ""Roman Emperors Dataset"",
    subtitle = ""Total length of reign by dynasty (in days)"",
    caption = ""\n Source: TidyTuesday 13.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")

g1<-g + geom_text(aes(label=average),hjust=-0.5) 



# Second graph --------------------------------------------------------------




g2<- ggplot(empeorers4, aes(reorder(dynasty,average))) +
  geom_bar(aes(y = average, fill = rise),stat=""identity"") +
  scale_fill_brewer(palette = ""Set3"") +
  coord_flip() +
  theme_ipsum()   + 
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position=""bottom"",
    axis.text = element_text( size=48 )
  ) +
  ylim(0,60000) +
  ylab(""Total time in days"") +
  xlab("""") +
  
  labs(
    title = ""Roman Emperors Dataset"",
    subtitle = ""Total length of reign by dynasty (in days)"",
    caption = ""\n Source: TidyTuesday 13.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")




grid.arrange(g1,g2, ncol=2)

","2019-33"
"595",295,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 14-08-2019.R","# Upload the data ---------------------------------------------------------

library(ggplot2)
library(hrbrthemes)
library(dplyr)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")




# Calculate the reign length ----------------------------------------------

reign_start <- as.POSIXct(emperors$reign_start, format = ""%Y-%m-%d"")
reign_end<- as.POSIXct(emperors$reign_end, format = ""%Y-%m-%d"")



empeorers2<-emperors %>% mutate(elapsed_time = (reign_start %--% reign_end)/ddays(1)) %>% select(""name"", ""reign_start"",
                                                                                                 ""reign_end"", ""elapsed_time"", ""rise"",""cause"",""killer"",""dynasty"",""era"")


empeorers4<-empeorers2%>%group_by(dynasty,rise)%>%summarize(total=round(sum(elapsed_time),0)) %>%
  arrange(-total)   # for second graph



# Order the column by total -----------------------------------------------


empeorers4$dynasty <- factor(empeorers4$dynasty, levels = c(""Theodosian"",""Flavian"",""Julio-Claudian"",""Severan"",""Gordian"", ""Valentinian"", 
                                                            ""Nerva-Antonine"",""Constantinian""))




g2<- ggplot(empeorers4, aes(dynasty)) +
  geom_bar(aes(y = total, fill = rise),stat=""identity"") +
  scale_fill_brewer(palette = ""Set3"") +
  coord_flip() +
  theme_ipsum_tw()  + 
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position=""bottom"",
    axis.text = element_text( size=48 )
  ) +
  ylim(0,60000) +
  ylab(""Total time in days"") +
  xlab("""") +
  
  labs(
    title = ""Roman Emperors Dataset"",
    subtitle = ""Total length of reign by dynasty (in days)"",
    caption = ""\n Source: TidyTuesday 14.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")
g2
","2019-33"
"596",296,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 14-10-2019.R","# Upload the data ---------------------------------------------------------

big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")


# Upload packages ---------------------------------------------------------

library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggalt)
library(scales)
library(hrbrthemes)


# Prepare the data --------------------------------------------------------


Electric_car<-big_epa_cars %>% filter(fuelType1 == ""Electricity"") %>% group_by(make)%>% select(make, cityE,highwayE) %>%
  summarise(avg_city_consumption=round(mean(cityE,na.rm=TRUE),1),
            avg_highway_consumption=round(mean(highwayE,na.rm=TRUE),1)) %>% na.omit()




# dumbbell graph ----------------------------------------------------------


ggplot(Electric_car, aes(x = avg_city_consumption, xend = avg_highway_consumption, y=reorder(make,avg_city_consumption))) + 
  geom_dumbbell(colour = ""#e5e5e5"",
                size = 3,
                colour_x = ""#228b34"",
                colour_xend = ""#1380A1"")+
  theme_ipsum_rc()  +
  labs(
    title = ""Electric vehicles - Average City VS Highway consumption"",
    subtitle = ""TidyTuesday 14.10.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = ""Consumption in kw-hrs/100 miles"",
    y = """") + theme(legend.position = ""top"",
                    legend.box = ""horizontal"",
                    plot.background=element_rect(fill=""#f7f7f7"")) +
 geom_text(data = filter(Electric_car, make == ""Plymouth""),
            aes(x = avg_highway_consumption, y = make),
            label = ""Highway"", fontface = ""bold"",
            color = ""#395B74"",
            vjust = 4) +
  geom_text(data = filter(Electric_car, make == ""Plymouth""),
            aes(x = avg_city_consumption, y = make),
            label = ""City"", fontface = ""bold"",
            color = ""#228b34"",
            vjust = 4)


","2019-41"
"597",297,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 14-5-2019.R","
# Upload the data ---------------------------------------------------------

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
View(nobel_winners)


# Upload the necessary packages -------------------------------------------

library(dplyr)
library(plotly)


# Prepare the data for plotly ---------------------------------------------

test<-nobel_winners%>%mutate(birth_year= format(birth_date,'%Y'))
View(test)

test_2<-test %>% mutate(winning_age=(as.numeric(prize_year)-as.numeric(birth_year))) %>% select(full_name,winning_age)

View(test_2)
test_3<-test_2 %>%   mutate(
    decade=case_when(
      test_2$winning_age %in% 10:20 ~ ""10-20"",
      test_2$winning_age %in% 21:30 ~ ""21-30"",
      test_2$winning_age %in% 31:40 ~ ""31-40"",
      test_2$winning_age %in% 41:50 ~ ""41-50"",
      test_2$winning_age %in% 51:60 ~ ""51-60"",
      test_2$winning_age %in% 61:70 ~ ""61-70"",
      test_2$winning_age  %in% 71:80 ~ ""71-80"",
      test_2$winning_age  %in% 81:90 ~ ""81-90"",
      test_2$winning_age %in% 91:100 ~ ""91-100"",
      TRUE ~ as.character(test_2$winning_age)
    )
  ) %>% group_by(decade) %>%
  summarize(n=n(), na.rm=TRUE)%>%  select(decade, n)

test_4<-test_3%>%filter(decade != ""NA"")
View(test_4)


# Plotly ------------------------------------------------------------------


t <- list(
  family = ""sans serif"",
  size = 16,
  color = 'black')
m <- list(
  l = 50,
  r = 50,
  b = 100,
  t = 100,
  pad = 4
)
p_3 <- plot_ly(test_4,
             y = ~n,
             x = ~decade,
             type = ""bar"",   
             text =  ~paste('</br> Age range: ', decade,
                            '</br> Total number of winners: ', round(n,2)),
             hoverinfo = ""text"",
             marker = list(color = 'rgb(158,202,225)',
                           line = list(color = 'rgb(8,48,107)', width = 1.5))) %>%
  layout(title = ""Nobel prize winners - Age Range"", font=t, autosize = F, width = 800, height = 600, margin = m)%>%
  layout(
    xaxis = list(title = """"),
    yaxis = list(title = """"),
    annotations = 
      list(text = ""#TidyTuesday 14.05.2019<br>@Juanma_MN"", 
           showarrow = F, xref='paper', yref='paper', 
           xref = 'paper', x = 0,
           yref = 'paper', y = 1.2,
           font=list(size=8, color=""black""))) %>%
  layout(
    
    annotations = 
      list(text = ""There are 31 winners with no date of birth"", 
           showarrow = F, xref='paper', yref='paper', 
           xref = 'paper', x = 1,
           yref = 'paper', y = -0.2,
           font=list(size=10, color=""black"")))
    
p_3



","2019-20"
"598",298,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 17-7-2019.R","
# Upload file -------------------------------------------------------------

library(readr)
r4ds_members <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")
View(r4ds_members)
colnames(r4ds_members)



# Upload packages ---------------------------------------------------------

library(ggplot2)
library(tidyverse)
library(lubridate)
library(dplyr)



# Data wrangling ----------------------------------------------------------

a1<-r4ds_members%>%mutate(month=format(r4ds_members$date,""%B""))%>% select(-1)%>%
  group_by(month)%>%
  summarise(total_membership=sum(total_membership),
            total_full_members= sum(full_members),
            total_daily_active_members= sum(daily_active_members),
            total_messages_in_public_channels= sum(messages_in_public_channels),
            total_messages_in_private_channels= sum(messages_in_private_channels),
            total_messages_in_d_ms= sum(messages_in_d_ms)) 


# Prepare the data for heatmap --------------------------------------------

a1<-a1[c(5,4,8,1,9,7,6,2,12,11,10,3),]
View(a1)

## add and index column
a1_2 <-a1  %>% mutate(id = row_number())

## Pass the first column to the number
library(dplyr)
a1_2 <- a1[, -(1)]
View(a1_2)

rownames(a1_2) <- a1$month



# heatmap -----------------------------------------------------------------


library(d3heatmap)

d3heatmap(a1_2, scale = ""column"", colors = ""GnBu"", dendrogram = ""none"", 
          
          xaxis_font_size = ""6pt"", yaxis_font_size = ""7pt"", 
          xaxis_height = 160, yaxis_width = 160,
          theme= ""dark"",
          show_grid = TRUE,
          brush_color = ""#0000FF"")

# https://rdrr.io/github/rstudio/d3heatmap/man/d3heatmap.html




","2019-29"
"599",299,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 17-9-2019.R","# Upload the data ---------------------------------------------------------

park_visits <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-17/national_parks.csv"")



# Packages to upload ------------------------------------------------------



library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(scales)
library(tidyverse)
library(streamgraph)
library(viridis)
library(hrbrthemes)
library(plotly)



# First graph - Multipoint ------------------------------------------------



park_visits1<-park_visits%>% 
  filter(parkname %in% c(""Gateway"",""George Washington Memorial Parkway"", ""Golden Gate"", ""Lake Mead"", ""Natchez Trace"") &
           year %in% c( ""1980"", ""1995"", ""2015"")) %>%
  select(year,parkname,visitors)%>% 
  spread(year,visitors)


View(park_visits1)


park_visits1$parkname <- factor(park_visits1$parkname, levels = c(""Natchez Trace"",
                                                                  ""George Washington Memorial Parkway"",
                                                                  ""Gateway"",
                                                                  ""Lake Mead"",
                                                                  ""Golden Gate""
))



names(park_visits1)[2]<-""Second""
names(park_visits1)[3]<-""Third""
names(park_visits1)[4]<-""Fourth""

ggplot() +
  
  geom_segment(
    data = gather(park_visits1, measure, val, -parkname) %>% 
      group_by(parkname) %>% 
      top_n(-1) %>% 
      slice(1) %>%
      ungroup(),
    aes(x = 4000000, xend = 20000000, y = parkname, yend = parkname),
    linetype = ""blank"", size = 0.3, color = ""gray80""
  ) +
  
  geom_segment(
    data = gather(park_visits1, measure, val, -parkname) %>% 
      group_by(parkname) %>% 
      summarise(start = range(val)[1], end = range(val)[2]) %>% 
      ungroup(),
    aes(x = start, xend = end, y = parkname, yend = parkname),
    color = ""gray80"", size = 2
  ) +
  # reshape the data frame & plot the points
  geom_point(
    data = gather(park_visits1, measure, value, -parkname),
    aes(value, parkname, color = measure), 
    size = 4
  )  + 
  geom_text(data = filter(park_visits1, parkname== ""Lake Mead""),
            aes(x = Second, y = parkname),
            label = ""2000"", fontface = ""bold"",
            color = ""#F7BC08"",
            vjust = -2) +
  geom_text(data = filter(park_visits1, parkname == ""Lake Mead""),
            aes(x = Third, y = parkname),
            label = ""2005"", fontface = ""bold"",
            color = ""#F7BC08"",
            vjust = -2)  +
  geom_text(data = filter(park_visits1, parkname == ""Lake Mead""),
            aes(x = Fourth, y = parkname),
            label = ""2015"", fontface = ""bold"",
            color = ""#F7BC08"",
            vjust = -2) +
  theme_ft_rc()+
  labs(
    title = ""National Park Visits"",
    subtitle = ""TidyTuesday 17.9.2019 - Top 5 parks by total number of visitors"",
    caption = ""Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = ""Number of visitors"",
    y = """")   + theme(legend.position="""") + theme(legend.title = element_blank()) +
  scale_x_continuous(label = unit_format(unit = ""m"", scale = 1e-6), breaks=c(5000000,10000000,15000000,20000000))







# area --------------------------------------------------------------------

park_visitArea<-park_visits%>% 
  filter(parkname %in% c(""Gateway"",""George Washington Memorial Parkway"", ""Golden Gate"", ""Lake Mead"", ""Natchez Trace"") &
           year %in% c(1950:2016)) %>%
  select(year,parkname,visitors)



park_visitArea$year<-as.numeric(park_visitArea$year)
#park_visitArea$visitors<-comma_format()(park_visitArea$visitors)

?comma_format

p2 <- park_visitArea%>% 
  ggplot(aes(x=year, y=visitors, fill=parkname, 
             text =paste(""Park name:"", parkname))) +
  geom_area() +
  scale_fill_viridis(discrete = TRUE)  +
  theme_ipsum() +
  theme(legend.position=""none"")  +
  scale_y_continuous(label = unit_format(unit = ""m"", scale = 1e-6))+
  scale_x_continuous(breaks=c(1950,1970,1990, 2010, 2016))+
  labs(
    title = ""National Park - Top 5 by Number of visitors"",
    subtitle = ""TidyTuesday 17.9.2019 - Top 5 parks by number of visitors"",
    caption = ""Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette=""YlGnBu"")




ggplotly(p2, tooltip=c(""text"",""x"", ""y""))
","2019-38"
"600",300,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 19-08-2019 (2).R","
# First ggridges ----------------------------------------------------------

nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")


# Upload the necessary packages -------------------------------------------

library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(dplyr)


test4<-nuclear_explosions%>%group_by(country,year)%>% filter(country %in% c(""CHINA"", ""FRANCE"", ""UK"", ""USA"", ""USSR"")) %>%
  summarize(total=n()) 

View(test4)


# ggplot ------------------------------------------------------------------


ggplot(test4, aes(x=year,y= reorder(country,desc(country)), fill = country, group = country)) +
  geom_density_ridges2(scale = 0.8)  + 
  scale_color_ipsum() +
  theme_ipsum_rc()+
  labs(
    title = ""Nuclear Explosions"",
    subtitle = ""TidyTuesday 19.8.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette = ""Spectral"") + theme(legend.position = """",
                                                  legend.box = """") +
  scale_x_continuous(
    limits = c(1940, 2005),
    expand = c(0, 0)
  )








","2019-33"
"601",301,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 19-08-2019.R","# Upload the dataset ------------------------------------------------------

nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")


# Upload the necessary packages -------------------------------------------

library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(dplyr)
library(plotly)
library(scales)

#change to decade to make the ""group_by"" functiom better.

nuclear_explosions$year[nuclear_explosions$year%in% c(1940:1949)] <- ""1940-1949""
nuclear_explosions$year[nuclear_explosions$year%in% c(1950:1959)] <- ""1950-1959""
nuclear_explosions$year[nuclear_explosions$year%in% c(1960:1969)] <- ""1960-1969""
nuclear_explosions$year[nuclear_explosions$year%in% c(1970:1979)] <- ""1970-1979""
nuclear_explosions$year[nuclear_explosions$year%in% c(1980:1989)] <- ""1980-1989""
nuclear_explosions$year[nuclear_explosions$year%in% c(1990:1999)] <- ""1990-1999""
View(nuclear_explosions)



test2<-nuclear_explosions%>%group_by(country,year)%>%
  summarize(total=n())



# Plotly ------------------------------------------------------------------


p <- plot_ly(test2, x = ~year, y = ~total, type = 'bar', color = ~country, name = ~country,
             text =  ~paste('</br> Country: ', country,
                            '</br> Decade: ', year,
                            '</br> Nuclear Explosions: ', comma_format()(total)),
             hoverinfo = ""text"") %>%
  layout(yaxis = list(title = ''), 
         xaxis = list(title = ''),
         barmode = 'stack')%>%
  layout(title = 
           list(
             text = ""Nuclear Explosions by decade"", 
             xanchor = ""middle"",
             font = list(
               family = ""times New Roman"", 
               color = ""#1E86FF"", 
               size = 20
             )
           )
  ) 

p%>% layout(annotations = list(
  list(x = 1, xanchor = ""right"", y = 800, showarrow = F, ax = 0, ay = 1, align = ""down"",
       text = ""TidyTuesday 19.8.2019
       Visualization: JuanmaMN 
       (Twitter @Juanma_MN)"")))



","2019-33"
"602",302,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 20-05-2019.R","
# Upload the data ---------------------------------------------------------

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

View(waste_vs_gdp)

colnames(waste_vs_gdp)

## name
names(waste_vs_gdp)[1]<- ""Country""
names(waste_vs_gdp)[4]<- ""Per_capita_plastic_waste""
names(waste_vs_gdp)[5]<- ""GDP_per_capita""
names(waste_vs_gdp)[6]<- ""Population""

View(waste_vs_gdp)


#############   omit na rows

data_plotly<-na.omit(waste_vs_gdp)  # Data for 2010 because for the rest of years we don't have all variables.


View(data_plotly)
colnames(data_plotly_Health_Education)

colnames(data_plotly)

library(plotly)
library(scales)
p_Tidy_Tuesday <-   plot_ly(data_plotly, 
                                x = ~GDP_per_capita, 
                                y = ~Per_capita_plastic_waste, 
                                color = ~Country, 
                                size = ~Population,
                                text =  ~paste('</br> Country: ', Country,
                                               '</br> Year: ', Year,
                                               '</br> Total population (Gapminder): ', comma_format()(Population),
                                               '</br> Per capita plastic waste (kilograms per person per day): ', Per_capita_plastic_waste,
                                               '</br> GDP per capita, PPP: ', round(GDP_per_capita,2)), 
                                
                                
                                hoverinfo = ""text"",
                                type = 'scatter',
                                mode = 'markers'
) %>%
  
  layout(xaxis = list(range = c(0, 130000), title = 'GDP per capita, PPP'),
         yaxis = list(range = c(0,5), title = 'Per capita plastic waste (kilograms per person per day)'),
         title = 'Per capita plastic waste VS GDP per capita by country',
         annotations = 
           list(text = ""#TidyTuesday"", 
                showarrow = F, xref='paper', yref='paper', 
                xref = 'paper', x = 0,
                yref = 'paper', y = 1,
                font=list(size=12, color=""black""))
)


p_Tidy_Tuesday


","2019-20"
"603",303,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 22-10-2019.R","# Packages ----------------------------------------------------------------

library(tidyverse)
library(anytime)
library(ggplot2)
library(waffle)


# Upload data -------------------------------------------------------------

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")
colnames(horror_movies)



# Prepare the data for geom_waffle ----------------------------------------

horror_movies_review<-horror_movies%>% select(3,6)%>%na.omit()


horror_movies_review_2<-horror_movies_review%>%  
  mutate(release_year_3=anydate(horror_movies_review$release_date),
         release_year_2=dmy(horror_movies_review$release_date)) %>%
  mutate(mycol = coalesce(release_year_2,release_year_3)) %>%
  mutate(Year=format(mycol,""%Y"")) %>% select(6,2)


# View(horror_movies_review_2)

horror_movies_review_2$review_rating<-as.numeric(horror_movies_review_2$review_rating)



horror_movies_review_3<-horror_movies_review_2%>%
  mutate(
    Review_Rating=case_when(
      horror_movies_review_2$review_rating >= 1 & horror_movies_review_2$review_rating < 5 ~ ""Less than 5"",
      horror_movies_review_2$review_rating >= 5 & horror_movies_review_2$review_rating < 7 ~ ""Between 5 & 6.9"",
      horror_movies_review_2$review_rating >= 7  ~ ""Higher than 7"",
      TRUE ~ as.character(horror_movies_review_2$review_rating)
    )
  ) %>% select(1,3)



horror_movies_review_3 %>%
  count(Year, Review_Rating) -> waffle

#View(waffle)



# waffle ------------------------------------------------------------------


ggplot(waffle, aes(fill = Review_Rating, values = n)) +
  geom_waffle(color = ""white"", size = .25, n_rows = 10, flip = T) +
  facet_wrap(~Year, nrow = 1, strip.position = ""bottom"") +
  scale_x_discrete() + 
  scale_y_continuous(labels = function(x) x * 10, # make this multiplyer the same as n_rows
                     expand = c(0,0)) +
  scale_fill_manual(values = c(""#E7B800"",""#00AFBB"",""#FC4E07"")) +
  coord_equal() +
  labs(
    title = ""Horror movie metadata - Number of rating reviews by Year"",
    subtitle = ""What year received higher reviews?\n"",
    x = """",
    y = ""Number of Reviews\n"",
    caption =""\n Source: TidyTuesday 22.10.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)""
  ) +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = ""bold"", hjust = 0.5),
        plot.subtitle = element_text(size=9, face = ""italic"", hjust = 0.5),
        plot.caption = element_text(size = 8, face = ""italic"", color = ""black""),
        axis.title=element_text(size=8),
        legend.position = ""bottom"",
        panel.grid = element_blank(),
        axis.ticks.y = element_line(),
        legend.title = element_blank()) +
  guides(fill = guide_legend(reverse = TRUE)) 





","2019-43"
"604",304,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 23-07-2019.R","wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")

View(wildlife_impacts)

# Understand the data -----------------------------------------------------

unique(wildlife_impacts$operator)

unique (wildlife_impacts$damage)

unique (wildlife_impacts$time_of_day)

unique(wildlife_impacts$damage)




# Tidyverse ---------------------------------------------------------------

library (tidyverse)
library(hrbrthemes)
library (ggridges)
library(dplyr)
library(ggplot2)


# Prepare the data --------------------------------------------------------

data_damage<-wildlife_impacts%>% group_by(incident_month,incident_year,time_of_day,operator, damage)%>% filter(!is.na(time_of_day) & damage %in% c(""N"", ""M"", ""S"")) %>%summarize(n=n())


# Graph -------------------------------------------------------------------


ggplot(data_damage, aes(x=incident_year,y = reorder(time_of_day,desc(time_of_day)), fill = operator, group = interaction(operator,time_of_day))) +
  geom_density_ridges2(scale = 0.9) + 
  theme_ft_rc(grid=""X"")+
  labs(
    title = ""Wildlife strikes 1990-2018"",
    subtitle = ""TidyTuesday 23.7.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette = ""Spectral"") + scale_x_continuous(breaks=seq(1990,2018,4))





#scale=1 to avoid overlap



# geom_dumbbell -----------------------------------------------------------------


library(tidyverse)
library(ggplot2)
library(gridExtra)
library(ggalt)
library(scales)
library(hrbrthemes)


data_damage_2<-wildlife_impacts%>% group_by(operator,incident_year)%>%  filter (incident_year %in% c(""1990"", ""2018"")) %>%summarize(n=n())


spread<-spread(data_damage_2,incident_year,n)

View(spread)



ggplot(spread, aes(x = `1990`, xend = `2018`, y=operator)) + 
  geom_dumbbell(colour = ""#dddddd"",
                size = 3,
                colour_x = ""#FAAB18"",
                colour_xend = ""#1380A1"")+
  labs(x=NULL, y=NULL, title=""ggplot2 geom_dumbbell with dot guide"") +
  theme_ft_rc(grid=""X"")  +
  labs(
    title = ""Wildlife strikes 1990-2018"",
    subtitle = ""TidyTuesday 23.7.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") + theme(legend.position = ""bottom"",
                    legend.box = ""vertical"")  + geom_text(data = filter(spread, operator == ""UNITED AIRLINES""),
                                                          aes(x = `2018`, y = operator),
                                                          label = ""2018"", fontface = ""bold"",
                                                          color = ""#395B74"",
                                                          vjust = -2) +
                                                geom_text(data = filter(spread, operator == ""UNITED AIRLINES""),
                                                          aes(x = `1990`, y = operator),
                                                          label = ""1990"", fontface = ""bold"",
                                                          color = ""#F7BC08"",
                                                          vjust = -2)
","2019-30"
"605",305,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 23-09-2019.R","# Upload the data ---------------------------------------------------------

school_diversity <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-24/school_diversity.csv"")


# Data manipulation -------------------------------------------------------

school_diversity2<-school_diversity %>% filter(SCHOOL_YEAR == ""1994-1995"") %>%
  select(2,6:10,12)%>%top_n(10,Total)
  


# Prepare the data for heatmap --------------------------------------------

school_diversity3<-school_diversity2%>% mutate(id = row_number())

school_diversity3<-school_diversity2[, -(1)]
rownames(school_diversity3) <- school_diversity2$LEA_NAME

View(school_diversity3)


school_diversity3[,1:5]<-round(school_diversity3[,1:5],2)







school_diversity3[,6]<-lapply(school_diversity3[,6], comma_format())

View(school_diversity3)



library(heatmaply)

library(d3heatmap)
d3heatmap(school_diversity3, scale = ""column"", colors = ""GnBu"", dendrogram = ""none"",xaxis_font_size = ""7pt"", yaxis_font_size = ""7pt"", show_legend = show.legend,main = ""TidyTuesday"")







","2019-38"
"606",306,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 27-08-2019.R","
# Upload the dataset ------------------------------------------------------

simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")


simpsons2<-simpsons



# Upload the packages -----------------------------------------------------

library(ggplot2)
library(tidyverse)#
library(plotly)
library(hrbrthemes)


# Top 10 ------------------------------------------------------------------

top_10<-simpsons%>% group_by(guest_star)%>%summarise(n=n())%>%top_n(10, wt=n)
View(top_10)
unique(top_10$guest_star)


# Group the seasons -------------------------------------------------------

simpsons2$season[simpsons2$season %in% c(1:10)] <- ""First 10 seasons""
simpsons2$season[simpsons2$season %in% c(11:20)] <- ""Season 11-20""
simpsons2$season[simpsons2$season %in% c(21:30)] <- ""Season 21-30""




top<-simpsons2 %>%
  filter(guest_star %in% c(""Marcia Wallace"",  
                           ""Phil Hartman"",
                           ""Joe Mantegna"",
                           ""Maurice LaMarche"",
                           ""Frank Welker"",
                           ""Kelsey Grammer"",
                           ""Jon Lovitz"",
                           ""Kevin Michael Richardson"",
                           ""Jackie Mason"",
                           ""Glenn Close""))%>% 
  group_by(season,guest_star)%>%summarise(n=n())




View(top)

top$guest_star <- factor(top$guest_star, levels = c(
  ""Glenn Close"",
  ""Jackie Mason"",
  ""Kevin Michael Richardson"",
  ""Jon Lovitz"",
  ""Kelsey Grammer"",
  ""Frank Welker"",
  ""Maurice LaMarche"",
  ""Joe Mantegna"",
  ""Phil Hartman"",
  ""Marcia Wallace""))



gS<- ggplot(top, aes(guest_star)) +
  geom_bar(aes(y = n, fill = season),stat=""identity"") +
  scale_fill_brewer(palette = ""Set3"") +
  coord_flip() +
  theme_ipsum_tw()  + 
  theme(
    panel.grid.minor.y = element_blank(),
    panel.grid.major.y = element_blank(),
    legend.position=""bottom"",
    axis.text = element_text( size=48 )
  ) +
  ylim(0,180) +
  ylab(""Total Episodes"") +
  xlab("""") + 
  theme(legend.title = element_blank()) +
  labs(
    title = ""Simpsons Guest Stars - Top 10"",
    subtitle = ""Total Guest Stars per season"",
    caption = ""\n Source: TidyTuesday 27.8.2019
      Visualization: JuanmaMN (Twitter @Juanma_MN)"")
gS


ggplotly(gS)







","2019-35"
"607",307,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 28-10-2019.R","
# Upload the packages -----------------------------------------------------

library(tidyverse)
library(sunburstR)

# Upload the data ---------------------------------------------------------

nyc_squirrels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

View(nyc_squirrels)



# Work with the date ------------------------------------------------------


nyc_squirrels$date <- as.character(nyc_squirrels$date)

nyc_squirrels$date <- as.Date(nyc_squirrels$date, ""%m%d%Y"")


# Prepare the data for SunburstR ------------------------------------------


#Extract month, day of week

nyc_squirrels<-nyc_squirrels%>%mutate(month=format(nyc_squirrels$date,""%B""),
                                      day=format(nyc_squirrels$date,""%A"")) %>% select(shift,age,primary_fur_color,
                                                                                      day) %>%
  group_by(shift,age,primary_fur_color,day) %>%
  summarise(n=n())

# Prepare for sunburst

nyc_squirrels2<-nyc_squirrels%>%
  mutate(path2 = paste(day,shift,age,primary_fur_color, sep=""-"")) 

nyc_squirrels3<-nyc_squirrels2%>%ungroup()%>%select(path2,n)   #ungroup is necessary
  
nyc_squirrels3<- as.data.frame(sapply(nyc_squirrels3,gsub,pattern=""-NA"",replacement=""""))
nyc_squirrels3<- as.data.frame(sapply(nyc_squirrels3,gsub,pattern=""-NA-NA"",replacement=""""))
nyc_squirrels3<- as.data.frame(sapply(nyc_squirrels3,gsub,pattern=""-NA-NA-NA"",replacement=""""))


# Upload the packages -----------------------------------------------------




p2 <- sunburst(nyc_squirrels3,legend=FALSE,
               width = ""100%"",
               height = 600,
               colors = c(""#e6d8ad"",""#e6e6ad"",""#add8e6"", ""#ade6d8"", ""#e6adbb""),
               withD3=TRUE,
               valueField = ""size"")



","2019-43"
"608",308,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 29-4-2019.R","
# Upload data -------------------------------------------------------------

mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

View(mp_light)


# Group by month ---------------------------------------------------------


library(dplyr)
library(lubridate)

mp_light_2<-mp_light %>% group_by(month=floor_date(date, ""month"")) %>%
  summarize(amount=sum(light_score))

View(mp_light_2)
library(xts)



# Prepare the data for dygraphs--------------------------------------------

 
mp_light_3<- as.xts(mp_light_2, order.by=as.Date(mp_light_2$month,format=""%Y/%m/%d""))



# Dygraphs ----------------------------------------------------------------


library(dygraphs)


dygraph(mp_light_3$amount, main = ""#TidyTuesday"", xlab= """", ylab = ""Number of windows lit at the McCormick Place, Chicago"") %>% dyOptions(fillGraph = TRUE, fillAlpha = 0.4, colors = RColorBrewer::brewer.pal(4, ""Paired""), axisLineWidth = 1.5, drawGrid = FALSE)%>%dyRangeSelector(height = 20)

","2019-17"
"609",309,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 30-4-2019.R","# Upload data -------------------------------------------------------------

mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

View(mp_light)


# Group by month ---------------------------------------------------------


library(dplyr)
library(lubridate)

mp_light_2<-mp_light %>% group_by(month=floor_date(date, ""month"")) %>%
  summarize(amount=sum(light_score)) 

mp_light_3_plotly <- mp_light_2%>% mutate(month=format(mp_light_2$month,""%Y-%m""))




# Plotly ------------------------------------------------------------------


View(mp_light_3)

library(plotly)

p <- plot_ly(mp_light_3_plotly, x = ~month, y = ~amount, 
             type = 'scatter', mode = 'lines',
             line = list(color = 'rgb(205, 12, 24)', width = 2),
             text =  ~paste('</br> Light score: ', amount,
                            '</br> Month: ', month), 
             marker = list(color = 'rgb(166,206,227)',
                           line = list(color = 'rgb(8,48,107)',
                                       width = 1))) %>%
  layout(xaxis = list(title = ""month""),
         yaxis = list(title = ""amount""),
         title = 'Number of windows lit at the McCormick Place, Chicago',
         annotations = 
           list(text = ""#TidyTuesday @Juanma_MN"", 
                showarrow = F, xref='paper', yref='paper', 
                xref = 'paper', x = 1,
                yref = 'paper', y = 0,
                font=list(size=10, color=""black""))
  ) 

p
","2019-18"
"610",310,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 30-7-2019.R","
# Upload the data ---------------------------------------------------------

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

View(video_games)
str(video_games)
colnames(video_games)
# unique(video_games$owners)


# Upload the necessary packages -------------------------------------------

library(lubridate)
library(tidyverse)
library(hrbrthemes)
library(ggridges)


# Prepare the data --------------------------------------------------------

video_games$release_date<-mdy(video_games$release_date)

test2<-video_games%>%
  mutate(Year=year(release_date))%>%
  group_by(owners, Year) %>% filter(str_detect(owners, ""000,000"")) %>%
  filter(!str_detect(owners, ""200,000,000""))%>%
  summarize (mean=round(mean(average_playtime,na.rm=TRUE),2))

View(test2)



# ggridges ----------------------------------------------------------------


ggplot(test2, aes(x=Year,y = reorder(owners,desc(owners)), fill = owners, group = owners)) +
  geom_density_ridges2(scale =1) + 
  theme_ft_rc(grid=""X"")+
  labs(
    title = ""Video Games Dataset 2004-2018"",
    subtitle = ""TidyTuesday 30.7.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette = ""Spectral"") + theme(legend.position = """",
                                                  legend.box = """") +
  scale_x_continuous(
    breaks = c(2004:2018), limits = c(2000, 2025),
    expand = c(0, 0)
  )
","2019-31"
"611",311,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 30-9-2019.R","
# Upload the data ---------------------------------------------------------

pizza_jared <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_jared.csv"")



# Upload the packages -----------------------------------------------------

library(ggplot2)
library(ggridges)
library(hrbrthemes)
library(lubridate)
library(plotly)
library(scales)
library(tidyverse)
library(viridis)

# Prepare the data for the graph ------------------------------------------

pizza_jared2<-pizza_jared%>%  mutate(date = as_datetime(time)) %>% mutate(Year=format(date,""%Y""),
                                                                           Month=format(date,""%B""))
# geom_area ---------------------------------------------------------------

pizza_jaredarea<-pizza_jared2%>%group_by (Year,  answer)%>% 
  summarise(total=sum(votes))

pizza_jaredarea$Year<-as.numeric(pizza_jaredarea$Year)


p2area3 <- pizza_jaredarea%>% 
  ggplot(aes(x=Year, y=total, fill=factor(answer), group=1,
             text =paste(""Answer:"", answer,
                         ""<br>Total Votes:"", total))) +
  geom_area() +
  scale_fill_viridis(discrete = TRUE)  +
  theme_ipsum_rc() +
  theme(legend.position=""bottom"",
        legend.title = element_blank()) +
  scale_y_continuous()+
  scale_x_continuous()+
  labs(
    title = ""NY pizza restaurants - TidyTuesday 30.9.2019"",
    subtitle = """",
    caption = ""Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """") +
  scale_fill_brewer(palette=""Set3"")

ggplotly(p2area3, tooltip=c(""text"",""x""))







# Ridgeline ---------------------------------------------------------------


# Excelent and Good

pizza_jaredREG<-pizza_jared2%>%group_by (Year, Month, answer)%>% filter (answer == ""Excellent"") %>%
  summarise(total=sum(votes))


pizza_jaredREG$Year<-as.numeric(pizza_jaredREG$Year)


head(pizza_jaredREG)
ggplot(pizza_jaredREG, aes(x=Year,y = reorder(Month,desc(Month)), fill = Month, group = interaction(Month, answer)),width=800, height=700) +
  geom_density_ridges2(scale =1) + 
  theme_ipsum_rc()+
  labs( 
    title = ""NY pizza restaurants - Excelent Answer"",
    subtitle = ""TidyTuesday 2.10.2019"",
    caption = ""\n Source: TidyTuesday
      Visualization: JuanmaMN (Twitter @Juanma_MN)"",
    x = """",
    y = """")  +
  theme(legend.position="""",
        legend.title = element_blank())



","2019-39"
"612",312,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday 8-10-2019.R","
# Upload the data ---------------------------------------------------------

ipf_lifts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-08/ipf_lifts.csv"")


# Data manipulation -------------------------------------------------------


ipf_lifts$place[ipf_lifts$place == ""1""] <- ""Gold""

ipf_lifts$place[ipf_lifts$place ==""2""] <- ""Silver""

ipf_lifts$place[ipf_lifts$place ==""3""] <- ""Bronze""

ipf_lifts$place[ipf_lifts$place %in% c(""4"", ""5"",""6"", ""7"", ""8"", ""9"", ""10"")] <- ""4-10""

ipf_lifts$place[ipf_lifts$place %in% c(""11"", ""12"",""13"", ""14"", ""15"", ""16"", ""17"",
                                       ""18"", ""19"", ""20"", ""21"", ""22"", ""23"",
                                       ""24"", ""25"", ""26"", ""27"", ""28"", ""29"", ""30"", ""31"")] <- ""11-31""

ipf_lifts$place[ipf_lifts$place ==""G""] <- ""Guest lifter""
ipf_lifts$place[ipf_lifts$place ==""DQ""] <- ""Disqualified""
ipf_lifts$place[ipf_lifts$place ==""DD""] <- ""Doping Disqualification""
ipf_lifts$place[ipf_lifts$place ==""NS""] <- ""No-Show""

ipf_lifts1<-ipf_lifts%>%select(age_class, place)%>%group_by(age_class, place) %>%
  summarise(n=n())



ipf_lifts2<-ipf_lifts1 %>% spread(place,n)

# Reorder columns ---------------------------------------------------------

ipf_lifts3 <- ipf_lifts2[, c(1, 8,6,5,2,3,4,9,7)] %>% filter(age_class != ""5-12"")

View(ipf_lifts3)
# Prepare the data for heatmap --------------------------------------------

ipf_lifts4<-ipf_lifts3%>% mutate(id = row_number())

ipf_lifts4<-ipf_lifts3[, -(1)]
rownames(ipf_lifts4) <- ipf_lifts3$age_class

View(ipf_lifts4)



# heatmap -----------------------------------------------------------------


library(d3heatmap)
d3heatmap(ipf_lifts4, scale = ""column"", colors = ""Blues"", dendrogram = ""none"",xaxis_font_size = ""7pt"", yaxis_font_size = ""7pt"", show_legend = show.legend,main = ""TidyTuesday"")






","2019-41"
"613",313,"https://github.com/JuanmaMN/TidyTuesday","JuanmaMN","TidyTuesday","TidyTuesday15-4-2019.R","# Upload the necessary packages -------------------------------------------

library(readr)
library(plotly)
library(scales)



# Upload and prepare the data ---------------------------------------------------------


corbyn <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/corbyn.csv"")

corbyn
corbyn_2<-corbyn%>%mutate(percentage=avg_facebook_likes/sum(avg_facebook_likes))


# Plotly graph ------------------------------------------------------------


p <- plot_ly(corbyn_2, labels = ~political_group, values = ~avg_facebook_likes, type = 'pie',
             textposition = 'inside',
             textinfo = 'label+value') %>%
  layout(title = 'Political identity or group - Average number of facebook likes per Facebook post in 2016',
         xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
         annotations = 
           list(text = ""#TidyTuesday.  "", 
                showarrow = F, xref='paper', yref='paper', 
                xref = 'paper', x = 0,
                yref = 'paper', y = 1,
                font=list(size=10, color=""black"")))

p","2019-15"
"614",1024,"https://github.com/edugonzaloalmorox/tidy-tuesdays/blob/master/week_26_02_2019/week_26_02_201.R","edugonzaloalmorox","tidy-tuesdays","week_26_02_2019/week_26_02_201.R","##########################
# Tidytuesday 
# Week: 26/02/2019
# @ EdudinGonzalo
##########################




library(tidyverse)
library(readr)
library(janitor)
library(hrbrthemes)


full_train = read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")


line_departures = full_train %>%
  tabyl(departure_station, year)  %>%
  gather(year, lines, -departure_station) %>%
  arrange(departure_station)

traffic =  full_train %>%
  group_by(departure_station, year) %>%
  summarise(trains = sum(total_num_trips))



traffic$year = as.character(traffic$year)

complete_data = line_departures %>%
  left_join(., traffic, by = c(""departure_station"", ""year""))


sncf_plot = complete_data %>%
   filter(!departure_station %in% c(""PARIS LYON"",""PARIS MONTPARNASSE""), year %in% c(""2015"", ""2018"")) %>%
  ggplot(., aes(lines, str_to_title(departure_station))) +
  geom_line(aes(group = departure_station), color = 'grey50', alpha = 0.5) +
  geom_point(aes(color = year, size = trains), alpha = 0.875) +
  scale_colour_viridis_d(name =""Year"", guide = guide_legend(title.position = ""top"", nrow = 1, title.hjust = 0.5, option = ""cividis"")) +
  scale_x_continuous(limits = c(0, 80), 
                     breaks = seq(0, 80, by = 5)) +
  labs(y= """", x= ""Number of lines"", size=""Traffic (number of trains)"",
       title =  ""How many lines & trains from each destination?"", 
       subtitle = ""Most stations have reduced the number of lines since 2015"",
       caption =  ""Paris Lyon and Paris Montparnasse excluded from the analysis \n Source: SNCF \n @EdudinGonzalo"") +
  theme_ipsum(base_size = 6.5) + 
  theme(panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
       legend.position = ""bottom"",
        legend.background = element_blank(),
        legend.direction=""horizontal"",
        text = element_text(family = ""Helvetica"")) +
 guides(size = guide_legend(title.position=""top"", title.hjust = 0.5))



ggsave(""week_26_02_2019/sncf.png"", sncf_plot)

","2019-9"
"615",1025,"https://github.com/edugonzaloalmorox/tidy-tuesdays/blob/master/week_05_03_2019/week_05_03_2019.R","edugonzaloalmorox","tidy-tuesdays","week_05_03_2019/week_05_03_2019.R","##########################
# Tidytuesday 
# Week: 05/03/2019
# @ EdudinGonzalo
##########################


library(tidyverse)
library(gganimate)
library(gghighlight)
library(ggpubr)


earnings_female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"") 



rank_data <- earnings_female %>%
  group_by(Year) %>%
  mutate(ordering = rank(percent)*1.0) %>%
  ungroup() 


rank_data$Year = as.Date(as.character(rank_data$Year), format = ""%Y"")



p<-ggplot(rank_data,
          aes(ordering, group = group ,color= group,fill= group)) +
  geom_tile(aes(y = percent/2, 
                height = percent,
                width = 0.9), alpha = 0.75) +
  geom_text(aes(y = percent, label = group), hjust = -0.4) +
  geom_text(aes(y = 0, label = group), hjust = 2) +
  coord_flip(clip = ""off"", expand = FALSE) +
  scale_color_viridis_d(option = ""plasma"" )+
  scale_fill_viridis_d(option = ""plasma"")+
  scale_y_continuous(breaks = c(0,25, 50, 75, 100), limits = c(0,105))+
  theme_minimal(14,""Avenir"")+
  guides(color=F,fill=F)+
  labs(title =  ""Earnings female workers per age group, 1979 - 2011"",
       subtitle='Year {frame_time}',
       y = ""Female salary percent of male salary (%)"",
       x = """",
       caption =  ""Source: NBER | @EdudinGonzalo"") +
  theme(plot.title = element_text(hjust = 1, size = 22),
       axis.ticks.y = element_blank(),
      axis.text.y  = element_blank(), 
      panel.background  = element_blank(), 
      panel.grid = element_blank(),
      plot.background = element_blank(),
      legend.position=""bottom"") + 
  transition_time(Year)+
  ease_aes('cubic-in-out') +
  font(""title"", size = 22, color = ""#c66eef"", face = ""bold"") 


animate(p, nframes = 250, fps = 10, end_pause = 20, width = 1000)

anim_save(filename =  ""week_05_03_2019/output/tidytuesday_womenearnings.gif"", animation = p)





","2019-10"
"616",1679,"https://github.com/stevejburr/tidytuesday/tree/master/11092018","stevejburr","tidytuesday","11092018/code.r","library(tidyverse)

#read data
data <- read.csv(""cats_vs_dogs.csv"")

#get map data for US states
map <- map_data(""state"")

data %>% mutate(region=tolower(state),
                `Dogs` = dog_population/n_households,
                `Cats` = cat_population/n_households) %>%
  select(region,`Dogs`,`Cats`) %>%
  gather(key=""key"",value=`Avg per household`,-region) %>%
  ggplot(aes(map_id=region)) +
  facet_grid(key ~ ., switch=""y"") +
  geom_map(map=map,aes(fill=`Avg per household`),colour=""white"") +
  expand_limits(x = map$long, y = map$lat) +
  coord_map(""albers"", lat0 = 39, lat1 = 45) +
  scale_fill_distiller(""Average pets per household"",
                       type=""seq"",palette=""Purples"",direction=1,
                       breaks=c(0.25,0.45,0.65,0.85)) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        text = element_text(color=""grey50""),
        panel.grid = element_blank(),
        strip.text.y= element_text(colour=""grey50"",
                                   angle=180)) +
  labs(title=""Cats are most common in the North of the USA, while Dogs are prefered in South"",
       caption=""#TidyTuesday - Data from data.world/datanerd - Design by @stevejburr"")

ggsave(""plot.png"",dpi=""retina"",width=8,height=6)




","2018-37"
"617",1680,"https://github.com/stevejburr/tidytuesday/blob/master/04092018/code.r","stevejburr","tidytuesday","04092018/code.r","#setwd(""C:/Data/Personal/Tidy Tuesday/04092018"")

library(tidyverse)
library(ggrepel)

data <- read_csv(""fastfood_calories.csv"")

#scatter of sodium / sat fat
#sodium
#calories
#sat_fat

#grab top 7 products by sodium
#grab top 7 products by sat_fat
#label both of these on chart

data %>% arrange(-sodium) %>% top_n(7,sodium) %>% select(item) %>% pull() -> big_sodium
data %>% arrange(-sat_fat) %>% top_n(7,sat_fat) %>% select(item) %>% pull() -> big_sat_fat
data %>% filter(sodium>=2300 & sat_fat>=20) %>% select(item) %>% pull() -> danger_zone

labels <- c(big_sodium,big_sat_fat,danger_zone) %>% unique()

data %>% mutate(label=if_else(item %in% labels,item,"""")) -> data


#line at 20g of sat_fat = the recommended amount
#line at 2300 mg of sodium = the recommended amount

#colours

# Arbys - #d71921
# Burger King - #ec7801
# Chick Fil-A - #5b6770
# Dairy Queen - #009eb7
# Mcdonalds - #fcb827
# Sonic - #fcdd2a
# Subway - #0f9246
# Taco Bell - #682a8a

ourColours <- c(""#d71921"",""#ec7801"",""#5b6770"",""#009eb7"",""#fcb827"",""#fcdd2a"",""#0f9246"",""#682a8a"")

data %>% select(restaurant,label,sodium,calories,sat_fat) %>%
  ggplot(aes(x=sodium,y=sat_fat)) +
  geom_rect(data=data[1,],aes(ymin=20,ymax=55,xmin=0,xmax=2300),alpha=0.5,fill=""grey90"")+
  geom_rect(data=data[1,],aes(ymin=0,ymax=20,xmin=2300,xmax=6500),alpha=0.5,fill=""grey90"")+
  geom_rect(data=data[1,],aes(ymin=20,ymax=55,xmin=2300,xmax=6500),alpha=1,fill=""grey90"")+
  geom_point(aes(size=calories,col=as.factor(restaurant))) +
  geom_text_repel(aes(label=label),size=3,col=""grey50"") +
  geom_hline(yintercept = 20,col=""grey50"",linetype=""dashed"") +
  geom_label(data=data[1,],aes(x=6200,y=21,label=""Daily RDA""),alpha=1,size=3,fill=NA,hjust=1,col=""grey50"",label.size=NA) +
  geom_vline(xintercept= 2300,col=""grey50"",linetype=""dashed"") +
  geom_label(data=data[1,],aes(x=2310,y=1,label=""Daily RDA""),alpha=0.5,size=3,fill=NA,hjust=0,col=""grey50"",label.size=NA) +
  scale_y_continuous(""Saturated Fat (g)"")+
  scale_x_continuous(""Sodium (mg)"")+
  scale_size(""Total Calories"") +
  scale_colour_manual(""Restaurant"",values=ourColours)+
  guides(size = guide_legend(override.aes = list(colour=""grey50"", alpha = 1))) +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        text = element_text(colour=""grey50"")) +
  labs(title=""What are the unhealthiest fast food meals you can buy in the USA?"",
       subtitle=""Based on Saturated Fat and Sodium content"",
       caption=""Design by @stevejburr - Data from fastfoodnutrition.org - #TidyTuesday"")


ggsave(""plot.png"",width=10,height=10,dpi=""retina"")
","2018-36"
"618",1681,"https://github.com/stevejburr/tidytuesday/tree/master/18092018","stevejburr","tidytuesday","18092018/code.r","library(tidyverse)
library(gridExtra)
library(grid)

data1 <- read_csv(""hypoxia.csv"")
data2 <- read_csv(""us-airports.csv"")

#col 5/7/8- show cut off with >90% write commentary based on article

#create an altitude in ft column, duplicate on other side in mts

#drop first row which is just labelling
data <- data1[-1,c(6,7,9,10)]
data$heights <- c(0,10000,20000,30000,40000,50000)

#do % sat O2 with > 90
# and Alv pCO2 >35

dataO2 <- data[,c(1,3,5)]
dataCO2 <- data[,c(2,4,5)]

dataO2 %>% gather(key=""key"",value=""value"",-heights) %>%
  mutate(value=as.numeric(value),
         value=if_else(is.na(value),0,value)) %>%
  ggplot() +
  geom_hline(aes(yintercept=90),colour=""grey50"") +
  scale_x_continuous(""Height / ft"",sec.axis = sec_axis(~.*0.3048, name=""Height / m""),labels=scales::comma) +
  scale_y_continuous(""% of haemoglobin molecules saturated with O2"",breaks=c(25,50,75,90,100)) +
  scale_colour_manual("""",values=c(""#BCB6FF"",""#97F9F9""),labels=c(""Without oxygen"",""With oxygen"")) +
  geom_point(aes(y=value,x=heights,colour=key),size=3) +
  annotate(""text"",x=10000,y=83,label=""If flying without oxygen,\nabove 10,000ft the oxygen content \nof the blood drops dangerously low"",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=40000,y=75,label=""Even with a supply of pure oxygen, \nwithout a pressurised mask it \nbecomes dangerous to fly above 40,000ft"",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=48000,y=91,label=""Critical satuation value"",size=2,colour=""grey50"")+
  theme_minimal()+
  theme(text=element_text(colour=""grey50""),
        panel.grid = element_blank(),) +
  labs(title=""Using oxygen helps, but above about 40,000ft a pressurised mask is required"",
       subtitle=""This graph shows the % of haemoglobin molecules in the blood which are fully saturated with oxygen at different heights"") -> O2Plot




dataCO2 %>% gather(key=""key"",value=""value"",-heights) %>%
  mutate(value=as.numeric(value),
         value=if_else(is.na(value),0,value)) %>%
  ggplot() +
  geom_hline(aes(yintercept=35),colour=""grey50"") +
  scale_x_continuous(""Height / ft"",sec.axis = sec_axis(~.*0.3048, name=""Height / m""),labels=scales::comma) +
  scale_y_continuous(""Partial pressure of CO2 in the alveoli / mm Hg"",breaks=c(25,50,75,90,100)) +
  scale_colour_manual("""",values=c(""#BCB6FF"",""#97F9F9""),labels=c(""Without oxygen"",""With oxygen"")) +
  geom_point(aes(y=value,x=heights,colour=key),size=3) +
  annotate(""text"",x=10000,y=30,label=""If flying without oxygen,\nabove 10,000ft the CO2 pressure\nbecomes a problem"",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=40000,y=25,label=""Even with a supply of pure oxygen, \nwithout a pressurised mask it \nbecomes dangerous to fly above 40,000ft.\nWithout oxygen, the pressure of CO2\ndramatically falls further at this altitude."",
           colour=""grey50"",size=3.5) +
  annotate(""text"",x=48000,y=36,label=""Critical CO2 pressure"",size=2,colour=""grey50"")+
  theme_minimal()+
  theme(text=element_text(colour=""grey50""),
        panel.grid = element_blank(),) +
  labs(title=""The partial pressure of CO2 is also important, and this also falls with height."",
  subtitle=""If it is too low, then the blood vessels in the brain start to constrict, which negatively impacts cognition, while also hindering the release of\noxygen by your red blood cells. When it falls bellow 20mm Hg you start to feel mentally clouded (>35 is ideal), but this is not to do with lack of oxygen."") -> CO2plot

png(""plot.png"",height=1100,width=800,type=""cairo-png"")
grid.arrange(O2Plot,CO2plot,
           top = textGrob(
               ""The levels of both CO2 and O2 become important when flying above 10,000ft"",
               gp = gpar(fontface=2,fontsize=14,col=""grey50""),
               hjust=0.5
             ),
           bottom = textGrob(
             ""#TidyTuesday Design by - @stevejburr Data Source - Soaring Society of America/Nathan Cook"",
             gp = gpar(fontface = 3, fontsize = 9,col=""grey50""),
             hjust = 1,
             x = 1
           ),nrow=2,ncol=1,padding=unit(2,""lines""))
dev.off()
","2018-38"
"619",1111,"https://github.com/rebekahjacob/tt_play","rebekahjacob","tt_play","TT 5.28.19_WineTimes.r","#libraries
library(dplyr)
library(ggplot2)

#load data
wine<- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

#grab year from title function
yearExtract <- function(string) {
  t <- regmatches(string, regexec(""[0-9]{4}"", string))
  sapply(t, function(x) {
    if(length(x) > 0){
      return(as.numeric(x))
    } else {
      return(NA)    
    }
  })
}

#prices under 1000 and extract year
wine<- wine %>%
  filter(price<1000) %>%
  mutate(balance=ifelse(grepl('balanced', description), 'balanced', 'unbalanced')) %>%
  mutate(year=yearExtract(wine$title)) %>%
  filter(between(year, 1800, 2019))

#checking range of years
range(wine$year, na.rm=TRUE)

#plot points by year among balanced vs unbalanced wine
ggplot(wine, aes(y=points, x=year, col=balance)) + geom_smooth(se=F) + ggtitle(""Points awarded by vintage and 'balance' mentioned in description"")

#plot price by year among balanced vs unbalanced wine
ggplot(wine, aes(y=price, x=year, col=balance)) + geom_smooth(se=F) + ggtitle(""Price awarded by vintage and 'balance' mentioned in description"")

#points by price among balanced vs unbalanced wine
ggplot(wine, aes(y=price, x=points, col=balance)) + geom_smooth(se=F) + ggtitle(""Price by Points and 'balance' mentioned in description"")","2019-22"
"620",1112,"https://github.com/rebekahjacob/tt_play","rebekahjacob","tt_play","TT 6.11.19 Meteorites.rmd","---
title: ""Meteorites""
output: github_document
---

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(RColorBrewer)
library(extrafont)
font_import()
loadfonts(device = ""win"")

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

#only last 50 years and create quantile categories
meteorites<- meteorites %>%
  filter(year %in% 1969:2019 & !is.na(year) & !is.na(mass)) %>%
  mutate(size= factor(ntile(mass, 5)))


#bar plot
p<- ggplot(meteorites, aes(x=year, fill=size)) + geom_bar(position=""fill"") + scale_fill_brewer(palette=""Spectral"") + ggtitle(""Quantiles of Meteorite Size (mass in grams) over the Last 50 years"") + xlab(""Year"") + ylab(""Percent"") + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + theme(text=element_text(size=12,  family=""Comic Sans MS""))
p

```

","2019-24"
"621",1113,"https://github.com/rebekahjacob/tt_play","rebekahjacob","tt_play","TT 6.4.19_Ramen.rmd","---
title: ""Tidy Tuesday: Ramen""
author: ""Rebekah R. Jacob, MSW, MPH""
date: ""June 4, 2019""
output: html_document
---

#Load Data and libraries
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(RColorBrewer)

ramen <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

ramen
```

#Look for brands with most reviews (most popular)
```{r message=FALSE, warning=FALSE}
ramen %>%
  group_by(brand) %>%
  summarise(n=length(brand)) %>%
  arrange(desc(n))
```

#Create curated df for plotting
```{r message=FALSE, warning=FALSE}
brand.df<- ramen %>%
  filter(brand==c(""Nissin"", ""Nongshim"", ""Maruchan"") & !is.na(stars))
brand.df
```

#Create boxplot: Star ratings by brand and style
```{r message=FALSE, warning=FALSE}
p<- ggplot(brand.df, aes(x=factor(brand), y=stars, fill=factor(style))) + geom_boxplot()
p + ggtitle(""Ratings of the most popular ramen by style"") + xlab(""Brand"") + ylab(""Stars"") + scale_fill_brewer(palette=""Dark2"") + scale_fill_discrete(name=""Style"")

```
","2019-23"
"622",1114,"https://github.com/rebekahjacob/tt_play","rebekahjacob","tt_play","TT_5.14.19_NobelWinners.r","#libraries
library(tidyverse)
library(igraph)
library(ggplot2)

#load data
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

#physics
df1<- nobel_winner_all_pubs %>%
  filter(category==""physics"") %>%
  select(paper_id, laureate_id)

#make into matrix
pubs1<- as.data.frame.matrix(table(df1))

#graph incidence
pubs_inc1<- graph.incidence(pubs1)

#make bipartite graph
pubs_pr1<- bipartite.projection(pubs_inc1)

#and save just collaborations (authors)
collab_phy<- pubs_pr1$proj2


#chemistry
df2<- nobel_winner_all_pubs %>%
  filter(category==""chemistry"") %>%
  select(paper_id, laureate_id)

#make into matrix
pubs2<- as.data.frame.matrix(table(df2))

#graph incidence
pubs_inc2<- graph.incidence(pubs2)

#make bipartite graph
pubs_pr2<- bipartite.projection(pubs_inc2)

#and save just collaborations (authors)
collab_chem<- pubs_pr2$proj2


#medicine
df3<- nobel_winner_all_pubs %>%
  filter(category==""medicine"") %>%
  select(paper_id, laureate_id)

#make into matrix
pubs3<- as.data.frame.matrix(table(df3))

#graph incidence
pubs_inc3<- graph.incidence(pubs3)

#make bipartite graph
pubs_pr3<- bipartite.projection(pubs_inc3)

#and save just collaborations (authors)
collab_med<- pubs_pr3$proj2


#plot all three and include density for each
op<- par(mfrow=c(1,3))
plot(collab_phy, vertex.label=NA, vertex.size=degree(collab_phy)/1.5, vertex.color=""darkred"", main=""Physics"", sub=paste0(""Density= "", round(graph.density(collab_phy), 4)))
plot(collab_chem, vertex.label=NA, vertex.size=degree(collab_chem)/1.5, vertex.color=""lightblue"",main=""Chemistry"", sub=paste0(""Density= "", round(graph.density(collab_chem), 4)))
plot(collab_med, vertex.label=NA, vertex.size=degree(collab_med)/1.5, vertex.color=""salmon"", main=""Medicine"", sub=paste0(""Density= "", round(graph.density(collab_med), 4)))
par(op)

#plot separately for clearer images

plot(collab_phy, vertex.label=NA, vertex.size=degree(collab_phy)/1.5, vertex.color=""darkred"", main=""Physics"", sub=paste0(""Density= "", round(graph.density(collab_phy), 4)))

plot(collab_chem, vertex.label=NA, vertex.size=degree(collab_chem)/1.5, vertex.color=""lightblue"",main=""Chemistry"", sub=paste0(""Density= "", round(graph.density(collab_chem), 4)))

plot(collab_med, vertex.label=NA, vertex.size=degree(collab_med)/1.5, vertex.color=""salmon"", main=""Medicine"", sub=paste0(""Density= "", round(graph.density(collab_med), 4)))


#create df of the 3 network attributes
att.df <- data.frame(
  category=c(""Physics"", ""Chemistry"", ""Medicine""),
  density=round(c(graph.density(collab_phy), graph.density(collab_chem), graph.density(collab_med)), 4),
  net_size=c(length(V(collab_phy)$name), length(V(collab_chem)$name), length(V(collab_med)$name)),
  ties=c(length(E(collab_phy)$weight), length(E(collab_chem)$weight), length(E(collab_med)$weight)),
  avg_deg=round(c(mean(degree(collab_phy)), mean(degree(collab_chem)), mean(degree(collab_med))), 2),
  deg_cent=round(c(centralization.degree(collab_phy)$centralization, centralization.degree(collab_chem)$centralization, centralization.degree(collab_med)$centralization), 4)
)
att.df

#Since networks are very similar- this is boring, but oh well
#bar graph of network degree centralization
g<-ggplot(data = att.df, aes(x = category, y = deg_cent, fill=category)) +
  geom_bar(stat=""identity"") + theme_minimal()
g+labs(title=""Centralization (degree) by Nobel Prize Publication Collaboration Network"", 
       x=""Category of Publication Network"", y = ""Degree Centralization"")
ggsave(""boring.png"")","2019-20"
"623",1115,"https://github.com/rebekahjacob/tt_play","rebekahjacob","tt_play","TT_6.18.19_Canada Birds.Rmd","---
title: ""Canada Bird Counts""
output: github_document
---

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(RColorBrewer)
library(wesanderson)

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

summary(bird_counts)

birds<- bird_counts %>%
  mutate(type=ifelse(grepl('Owl', species), 'Owl', ifelse(grepl('Duck', species), ""Duck"", 'Other Species')),
         count_k=how_many_counted/1000)

table(birds$type)       
         
#split
ggplot(birds, aes(y=total_hours, x=year, col=type)) +
geom_point()+
geom_smooth(method=""lm"", se=FALSE)+
facet_grid(~type)+ scale_color_brewer(palette=""RdYlBu"") + theme_dark()


```","2019-25"
"624",1116,"https://github.com/rebekahjacob/tt_play","rebekahjacob","tt_play","TT_6.25.19_UFOs.Rmd","---
title: ""UFO sightings""
output: github_document
---

#data and libraries
```{r message=FALSE, warning=FALSE}
ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

library(tidyverse)
library(RColorBrewer)
```

#cleaning
```{r message=FALSE, warning=FALSE}
head(ufo_sightings$state) #how state abbrevs?
head(ufo_sightings$date_time) #how dates stored?

time.df<- ufo_sightings %>%
  filter(ufo_shape==c(""light"", ""triangle"", ""fireball"", ""disk"")) %>%
  mutate(year=yearExtract(date_time),
         time=sub("".* "", """", date_time),
         hour=as.numeric(substring(time, 1,2)))

```

#plots
```{r message=FALSE, warning=FALSE}
p <- ggplot(time.df, aes(x = hour, fill = ufo_shape))
p + geom_area(stat = ""count"") + scale_fill_brewer(palette=""RdBu"") + theme_minimal() + ggtitle(""Popular UFO sighting hours"") + scale_x_continuous(breaks=c(0:25)) + xlab(""Hour the UFO was sighted"")
```
","2019-26"
"625",1483,"https://github.com/RyanMAllen/TidyTuesday","RyanMAllen","TidyTuesday","April_23/April23.R","library(tidyverse)
library(data.table)
library(corrplot)

# Reading in the data
 tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")
tidy_anime

# Selecting the columns I will use
anime <- select(tidy_anime, name, type, genre, episodes, duration, score, rank, popularity) %>% 
    filter(complete.cases(tidy_anime))
# Shortcuts for me to remember
# ctrl shift m %>% %>% %>% 
# <- alt - gives you <- <- <- 

# Finding the top 10 genre's by inclusion
anime_genre <- anime %>% group_by(genre) %>% tally() %>% arrange(desc(n))
anime_genre <- slice(anime_genre, 1:10)
anime_genre

# Filtering based on the top 10 genres.
anime_genre <- filter(anime, genre == c(""Action"", ""Comedy"", ""School"", ""Romance"", ""Fantasy"", 
                                        ""Supernatural"", ""Drama"", ""Sci-Fi"", ""Adventure"", ""Shounen""))
# Top 10 characters accoring to average score
top_10 <- anime_genre %>% 
    
    group_by(name) %>% 
    
    summarise(Score = mean(score)) %>% 
    
    arrange(desc(Score))
top_10

# Summary by boxplot of the top 10 genres' scores
g <- ggplot(anime_genre, aes(x=genre, y= score)) +
    geom_boxplot()+ theme(panel.grid.major = element_blank(), axis.ticks = element_blank(), panel.grid.minor = element_blank(),panel.background = element_blank()) + 
    ggtitle(""Summaries of the Top 10 Genres by count"")

g

# Selecting all the numeric columns, then realizing that duration was a character
numeric <- anime %>% 
    select(episodes,duration, score, rank, popularity)
numeric$duration <- as.numeric(gsub("" min per ep"", """", numeric$duration))
# Correlation of each variable
corrplot(cor(numeric))

# A tibble with count, average score, average popularity, all grouped by genre
genre_average <- anime %>%
    group_by(genre) %>%
    summarise(Count = n(), Average_Score = mean(score), Average_Popularity = mean(popularity))
genre_average

# Finding the r.squared value of the regression line
r_squared <- summary(lm(genre_average$Average_Popularity~genre_average$Average_Score))

# Plot of the average score vs average popularity by genre in color with an included line of best fit
# attempted good graphics etiquette by including white background, no gridlines or legend, with a
# left justified title and subtitle with a semi-conclusion?
chart <- ggplot(data = genre_average, aes(x = Average_Popularity, y = Average_Score, col = genre))
chart + geom_point() +
    geom_text(aes(label = genre), vjust=-0.5) + 
    geom_smooth(method = 'lm', col = ""black"") +
    theme(panel.grid.major = element_blank(), axis.ticks = element_blank(), panel.grid.minor = element_blank(),
          panel.background = element_blank()) +
    theme(legend.position = ""none"") +
    annotate(""text"", x= 1700, y= 7.5, label =""r.squared = .1709"") + 
    ggtitle(""Average Popularity vs Average Score by Genre"", subtitle = ""There is a negative trend line, as popularity increases
average score decreases. It would appear that genres like Spake, Music, Josei, Sports perhaps
are the most popular and highly ranked. Samurai scores well, but is not very popular."")
","2019-17"
"626",1485,"https://github.com/RyanMAllen/TidyTuesday","RyanMAllen","TidyTuesday","April_30/RA_TidyTuesday_April30.R","library(tidyverse)
library(data.table)
set.seed(12)
library(ggplot2)
library(lubridate)
library(here)

bird_collisions <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")

sbird <- bird_collisions[bird_collisions$locality == 'MP']

dt <- na.omit(dplyr::left_join(mp_light, sbird, by = 'date'))

dt <- as.data.table(dt)
head(dt)
str(dt)

dt$date <- as.Date(dt$date, ""%Y-%m-%d"")
str(dt)

library(dplyr)
library(ggplot2)
dt %>% filter(date > ""2001-01-01"" & date <""2001-12-31"") %>% group_by(genus) %>% 
  count(light_score, genus) %>% 
  ggplot(aes(x=light_score, y=n, col=genus)) + geom_point(aes(col=genus))+ geom_line(aes(col=genus))

dt %>% add_count(light_score) %>% 
  group_by(date) %>% 
  ggplot(aes(x=date, y=n)) + geom_point()+ geom_line() %>% 
  facet_wrap(facet = 'light_score', ncol = 3)

deadliest_days <- dt %>% 
  add_count(date) %>% 
  group_by(genus, date) %>% 
  select(date, light_score,genus, n) %>%
  arrange(desc(n)) %>% 
  slice(1:10)

ggplot(deadliest_days, aes(x=date, y= n, col = genus))+ geom_bar(stat = ""identity"")


# plot_data <- bird_collisions %>%
#   filter(locality == ""CHI"") %>% 
#   mutate(month = month(date),
#          year = year(date)) %>% 
#   unite(""binomial_name"", genus, species, sep = "" "") %>% 
#   count(year, month, binomial_name) %>% 
#   complete(nesting(year, binomial_name), month = 1:12, fill = list(n = 0)) %>% 
#   group_by(year, binomial_name) %>% 
#   mutate(percent = n/sum(n)) %>% 
#   mutate(percent = ifelse(is.nan(percent), 0, percent))
# 
# flower <- ggplot(plot_data, aes(x = month, y = percent, fill = binomial_name)) +
#   geom_area(size = 0, position = position_dodge(), alpha = 0.2) +
#   scale_x_continuous(labels = month.abb, breaks = 1:12) +
#   scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
#   scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
#   scale_color_viridis_d(option = ""plasma"", direction = 1) +
#   guides(fill = guide_colorbar()) +
#   coord_polar() +
#   labs(x = NULL,
#        y = NULL,
#        title = ""Overall"") +
#   #theme_jk(dark = FALSE, grid = ""X"", strip_text_size = 10, plot_title_size = 14) +
#   theme(axis.text = element_blank(),
#         legend.position = ""none"")
# 
# petals <- flower +
#   aes(group = year) +
#   geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
#   labs(title = ""By Species"") +
#   facet_wrap(~binomial_name, labeller = label_wrap_gen(10), nrow = 7) 
# 
# legend <- plot_data %>% 
#   filter(binomial_name == ""Setophaga fusca"") %>% 
#   ggplot(aes(x = month, y = percent, fill = binomial_name, group = year)) +
#   geom_area(size = 0, position = position_dodge(), alpha = 0.1) +
#   geom_path(aes(color = binomial_name), size = 0.2, show.legend = FALSE) +
#   annotate(""text"", x = 11.2, y = 0.8, label = ""One year of\ncollisions in October"", family = ""Scope One"", size = 3, hjust = 0) +
#   annotate(""segment"", x = 10.8, y = 0.8, xend = 10, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
#   annotate(""text"", x = 3.5, y = 0.8, label = ""Multiple years of\ncollisions in May"", family = ""Scope One"", size = 3) +
#   annotate(""segment"", x = 3.8, y = 0.8, xend = 5, yend = 0.8, arrow = arrow(length = unit(0.2, ""cm""))) +
#   scale_x_continuous(labels = month.abb, breaks = 1:12) +
#   scale_y_continuous(limits = c(0,1), breaks = c(0.5, 0.1)) +
#   scale_fill_viridis_d(""Year"", option = ""plasma"", direction = 1) +
#   scale_color_viridis_d(option = ""plasma"", direction = 1) +
#   labs(x = NULL,
#        y = NULL,
#        title = ""How to Interpret This Chart"",
#        subtitle = str_wrap(""A flower represents the recorded total collisions of each bird species with the individual petals representing the normalized events during each year (from 0-1).  The position of the petals indicates the month or months collisions occur, with overlaps indicating repeated year-over-year collisions."", 70)) +
#   guides(fill = guide_colorbar()) +
#   coord_polar(theta = ""x"", start = 0) +
#   #theme_jk(dark = FALSE, grid = ""XY"", plot_title_size = 14) +
#   theme(axis.text.y = element_blank(),
#         legend.position = ""none"")
# 
# out <- wrap_plots(flower / legend, petals, ncol = 2, widths = c(1, 2)) +
#   plot_annotation(title = ""Seasonality of Bird Collisions in Chicago"",
#                   subtitle = str_wrap(""Presented below is a petal chart of of bird collisions, with instructions on how to interpret this chart in the lower left.  The upper left flower represents collisions recorded across all years and species, with individual species presented as small multiple flowers on the right."", 220),
#                   caption = ""Data: Winger et al. (2019) Nocturnal flight-calling behaviour predicts vulnerability to artificial light in migratory birds. Proceedings of the Royal Society B 286(1900): 20190364. https://doi.org/10.1098/rspb.2019.0364 | Graphic: @jakekaupp"")
","2019-18"
"627",1486,"https://github.com/RyanMAllen/TidyTuesday","RyanMAllen","TidyTuesday","April_8/tidy_tuesday_4-8.R","library(dplyr)

library(ggplot2)

library(data.table)



player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")



grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")



grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")





g <- grand_slams %>% 
    
    select(name,gender,rolling_win_count) %>%
    
    group_by(name, gender) %>% 
    
    summarise(rolling_win_count = sum(rolling_win_count))



males <- as.data.table(filter(g, gender == ""Male"") %>% arrange(desc(rolling_win_count)) %>% top_n(n=9))

top_10m <- slice(males, 1:10)





females <- as.data.table(filter(g, gender == ""Female"") %>% arrange(desc(rolling_win_count)))

top_10f <- slice(females, 1:10)





top_10m$name <- factor(top_10m$name, levels = top_10m$name[order(-top_10m$rolling_win_count)])



chart <- ggplot(top_10m, aes(x=name, y= rolling_win_count))

chart + geom_bar(stat='identity') + theme(panel.grid.major = element_blank(), axis.ticks = element_blank(), panel.grid.minor = element_blank(),
                                          
                                          panel.background = element_blank(), axis.line = element_line(colour = ""black"")) +
    
    geom_text(aes(label=rolling_win_count), vjust=-0.5) + ggtitle(""Top 10 Male Tennis Players"")



top_10f$name <- factor(top_10f$name, levels = top_10f$name[order(-top_10f$rolling_win_count)])



chart1 <- ggplot(top_10f, aes(x=name, y= rolling_win_count))

chart1 + geom_bar(stat='identity') + theme(panel.grid.major = element_blank(), axis.ticks = element_blank(), panel.grid.minor = element_blank(),
                                           
                                           panel.background = element_blank(), axis.line = element_line(colour = ""black"")) +
    
    geom_text(aes(label=rolling_win_count), vjust=-0.5) + ggtitle(""Top 10 Female Tennis Players"")







https://stackoverflow.com/questions/21349329/drawing-a-barchart-to-compare-two-sets-of-data-using-ggplot2-package
","2019-14"
"628",1487,"https://github.com/RyanMAllen/TidyTuesday","RyanMAllen","TidyTuesday","Oct_29/Squirrels.R","library(tidyverse)
nyc_squirrels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")
","2019-44"
"629",1750,"https://github.com/Songeo/tidytuesday","Songeo","tidytuesday","src/180402_ustuition.R","

library(tidyverse)
library(lubridate)
library(ggrepel)


theme_set(theme_minimal())


# read data
df_tuition <- readxl::read_xlsx(""data/us_avg_tuition.xlsx"")

# tidy version of data 
df_tuition_tidy <- df_tuition %>% 
  # dates should be rows
  gather(date, avg_tuition, -State) %>% 
  # one observation per year and number of observation separate
  separate(date, c('year', 'obs_num'), sep = ""-"") %>% 
  # from characters to numbers
  mutate_at(.vars = c('year', 'obs_num'),
            .funs = parse_number)

# how many states
df_tuition_tidy$State %>% n_distinct()

# number of observation per state
df_tuition_tidy %>% 
  group_by(State) %>% 
  tally() %>% 
  print(n = Inf)


# boxplot of tuituon in time 
df_tuition_tidy %>% 
  ggplot(aes(x = factor(year), y = avg_tuition)) + 
  geom_boxplot() + 
  ylab(""Tuition (avg)"") + 
  xlab(""Year"") + 
  ggtitle(""Average tuition in time"", 
          ""Prices always go up"")
ggsave(""graphs/170402_ustuition_01boxplot.png"", width = 7, height = 5)


# difference of tuition per annual average
tab_gg <- df_tuition_tidy %>% 
  group_by(year) %>% 
  mutate(year_mean = mean(avg_tuition), 
         cent = avg_tuition-year_mean) %>% 
  arrange(State) %>% 
  group_by(State) %>% 
  mutate(diff_cent = cent - lag(cent), 
         change_avg = mean(diff_cent, na.rm = T),
         change_max = max(diff_cent, na.rm = T), 
         ind = max( abs(diff_cent) > 3000| 
                      change_max > 700 | 
                      abs(cent) > 3000 | 
                      abs(change_avg) > 250, na.rm = T)  == 1) %>% 
  ungroup

# some summaries
tab_gg %>% 
  filter(State == ""Wyoming"")
tab_gg$change_avg %>% summary()
tab_gg$change_max %>% summary()
tab_gg$year %>% summary()

tab_gg %>% 
  select(State, change_max) %>% 
  unique() %>% 
  arrange(desc(change_max))
filter(State == ""Washington"")


# change over national avg per state and year
tab_gg %>% 
  ggplot(aes(x = year, y = State, fill = diff_cent)) +
  geom_tile() +
  scale_fill_continuous(low = ""#0000FF"", high = ""#FFFF00"") + 
  guides(fill = guide_legend(""Difference"")) +
  ggtitle(""State Tuition (avg) - National Tuition (avg)"",
          ""Some years have big changes"")
ggsave(""graphs/170402_ustuition_02heatmap.png"", width = 7, height = 8)

# plot of special states
tab_gg %>% 
  # filter(State %in% c(""Washington"", ""New Hampshire"", ""Wyoming"")) %>%
  ggplot(aes(x = year,
             y = cent, 
             group = State,
             color = State)) + 
  geom_line(aes(alpha = ind, 
                size = ind)) +
  scale_alpha_discrete(range = c(.5, 1)) +
  scale_size_discrete(range = c(.5, 1)) +
  xlim(c(2004, 2016)) +
  geom_text_repel(data = filter(tab_gg,
                                ind,
                                 year == 2015),
                   aes(label = State),
                   size = 3,
                   nudge_x = 2,
                   segment.color = NA) + 
  theme(legend.position = ""none"") + 
  ggtitle(""Tuition per State"", 
          ""Interesting changes in some states"") +
  ylab( ""State Tuition (avg) - National Tuition (avg)"")
ggsave(""graphs/170402_ustuition_03trends.png"", width = 8, height = 6)
","2018-14"
"630",1751,"https://github.com/Songeo/tidytuesday","Songeo","tidytuesday","src/180409_nfl.R","
# libraries
library(tidyverse)
library(forcats)
library(ggrepel)

# ggplot theme set
theme_set(theme_bw())


# 1. read data and tidy form ----
df_salaries <- readxl::read_excel(""data/tidy_tuesday_week2.xlsx"")
df_salaries 

df_salaries_tidy <- df_salaries %>% 
  gather(position, salary, -c(year)) %>% 
  mutate(pos_code = fct_recode(position, 
                               CB_defense = 'Cornerback',
                               DL_defense = ""Defensive Lineman"",
                               LB_defense = ""Linebacker"",
                               OL_offense = ""Offensive Lineman"",
                               QB_offense = ""Quarterback"",
                               RB_offense = ""Running Back"",
                               SY_defense = ""Safety"",
                               ST_defense = ""Special Teamer"",
                               TE_offense = ""Tight End"",
                               WR_offense = ""Wide Receiver"")) %>% 
  separate(pos_code, c(""pos_short"", ""def_off""), sep = ""_"")
df_salaries_tidy


df_salaries_tidy %>% 
  ggplot(aes(x = position, y = salary, 
             color = factor(year))) +
  geom_boxplot() + 
  scale_y_continuous(labels = function(x)x/1e3)


tab_gg <- df_salaries_tidy %>% 
  na.omit() %>% 
  group_by(year) %>% 
  mutate(total = sum(salary), 
         prop = salary/total) %>% 
  gather(variable, value, c(salary, prop)) 

tab_gg %>% 
  ggplot(aes(x = factor(year), 
             y = value,
             group = position)) +
  geom_smooth(se = F, aes(color = position, linetype = position))  + 
  facet_wrap(~variable, scales = 'free_y', ncol = 1) 


","2018-15"
"631",1752,"https://github.com/Songeo/tidytuesday","Songeo","tidytuesday","src/180418.R","
library(tidyverse)
library(imputeTS)
library(forecast)
library(ggfortify)
library(ggrepel)


source(""src/180418_lib.R"")

# data 
df_global <- readxl::read_xlsx(""data/global_mortality.xlsx"")
df_global

df_global %>% 
  filter(is.na(country_code)) %>% 
  summarise(n_distinct(country))

df_global %>% 
  filter(is.na(country_code)) %>% 
  .$country %>% 
  unique()


df_global_tidy <- df_global %>% 
  gather(type_death, value, -c(country, country_code, year)) %>% 
  filter(!is.na(country_code)) %>% 
  mutate_if(is.character, factor) %>% 
  group_by(country, type_death) %>% 
  mutate(nas = sum(is.na(value)),
         ceros = sum(value == 0),
         len = length(value), 
         value = ifelse(nas >= len & is.na(value), 0, value),
         value_imp = na.ma(value),
         value_init = lag(value_imp, 26),
         cambio = (value_imp - lag(value_imp, 26))/lag(value_imp, 26) ) %>% 
  ungroup %>% 
  dplyr::select(-len)
df_global_tidy %>% print(n = 30)

df_global_tidy %>% summary()

filter(df_global_tidy, is.na(value)) %>% 
  .$type_death %>% 
  unique()
filter(df_global_tidy, is.na(country_code))
filter(df_global_tidy, type_death == ""Conflict (%)"")


is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 3 * IQR(x))
}
df_global_tidy %>% 
  filter(!is.na(cambio)) %>% 
  filter(cambio != Inf) %>%
  group_by(type_death) %>% 
  mutate(outlier = ifelse(is_outlier(cambio), 
                          as.character(country), 
                          NA) ) %>% 
  ungroup %>% 
  ggplot(aes(x = fct_reorder(type_death, cambio, median), 
             y = cambio, 
             color = type_death)) + 
  geom_boxplot()  + 
  ylim(c(0, 40)) +
  theme(legend.position = ""none"") + 
  coord_flip()


df_global_tidy %>% 
  filter(!is.na(cambio)) %>%
  filter(cambio != Inf) %>% 
  filter(type_death == ""HIV/AIDS (%)"") %>% 
  arrange(desc(cambio))

df_global_tidy %>% 
  filter(!is.na(cambio)) %>%
  filter(cambio != Inf) %>% 
  filter(type_death == ""Terrorism (%)"") %>% 
  arrange(desc(cambio))


df_global_tidy %>% 
  filter(country_code == 'AGO',
         type_death == ""Diarrheal diseases (%)"") %>% 
  ggplot(aes(x = year, 
             y = value_imp)) + 
  geom_point(alpha = .1) +
  facet_wrap(~type_death, scales = ""free_y"")


measures_fun <- function(sub_series){
  print(sub_series[1,])
  ts_serie <- ts(sub_series$value_imp, start = 1990, frequency = 1)
  measures(ts_serie)
}
df_global_tidy %>% 
  filter(nas < 27, 
         ceros < 15) %>% 
  group_by(country, country_code, type_death) %>% 
  do(measures_fun(.))


","2018-16"
"632",1753,"https://github.com/Songeo/tidytuesday","Songeo","tidytuesday","src/180418_lib.R","


findfrequency <- function(x)
{
  n <- length(x)
  x <- as.ts(x)
  # Remove trend from data
  x <- residuals(tslm(x ~ trend))
  # Compute spectrum by fitting ar model to largest section of x
  n.freq <- 500
  spec <- spec.ar(c(na.contiguous(x)), plot=FALSE, n.freq=n.freq)
  if(max(spec[[""spec""]])>10) # Arbitrary threshold chosen by trial and error.
  {
    period <- floor(1/spec[[""freq""]][which.max(spec[[""spec""]])] + 0.5)
    if(period==Inf) # Find next local maximum
    {
      j <- which(diff(spec[[""spec""]])>0)
      if(length(j)>0)
      {
        nextmax <- j[1] + which.max(spec[[""spec""]][(j[1]+1):n.freq])
        if(nextmax < length(spec[[""freq""]]))
          period <- floor(1/spec[[""freq""]][nextmax] + 0.5)
        else
          period <- 1L
      }
      else
        period <- 1L
    }
  }
  else
    period <- 1L
  
  return(as.integer(period))
}


decomp <- function(x,transform=TRUE)
{
  require(forecast)
  # Transform series
  if(transform & min(x,na.rm=TRUE) >= 0)
  {
    lambda <- BoxCox.lambda(na.contiguous(x))
    x <- BoxCox(x,lambda)
  }
  else
  {
    lambda <- NULL
    transform <- FALSE
  }
  # Seasonal data
  if(frequency(x)>1)
  {
    x.stl <- stl(x,s.window=""periodic"",na.action=na.contiguous)
    trend <- x.stl[[""time.series""]][,2]
    season <- x.stl[[""time.series""]][,1]
    remainder <- x - trend - season
  }
  else #Nonseasonal data
  {
    require(mgcv)
    tt <- 1:length(x)
    trend <- rep(NA,length(x))
    trend[!is.na(x)] <- fitted(gam(x ~ s(tt)))
    season <- NULL
    remainder <- x - trend
  }
  return(list(x=x,trend=trend,season=season,remainder=remainder,
              transform=transform,lambda=lambda))
}

# f1 maps [0,infinity) to [0,1]
f1 <- function(x,a,b)
{
  eax <- exp(a*x)
  if (eax == Inf)
    f1eax <- 1
  else
    f1eax <- (eax-1)/(eax+b)
  return(f1eax)
}

# f2 maps [0,1] onto [0,1]
f2 <- function(x,a,b)
{
  eax <- exp(a*x)
  ea <- exp(a)
  return((eax-1)/(eax+b)*(ea+b)/(ea-1))
}

measures <- function(x)
{
  require(forecast)
  
  N <- length(x)
  freq <- findfrequency(x)
  fx <- c(frequency=(exp((freq-1)/50)-1)/(1+exp((freq-1)/50)))
  x <- ts(x,f=freq)
  
  # Decomposition
  decomp.x <- decomp(x)
  
  # Adjust data
  if(freq > 1)
    fits <- decomp.x[[""trend""]] + decomp.x[[""season""]]
  else # Nonseasonal data
    fits <- decomp.x[[""trend""]]
  adj.x <- decomp.x[[""x""]] - fits + mean(decomp.x[[""trend""]], na.rm=TRUE)
  
  # Backtransformation of adjusted data
  if(decomp.x[[""transform""]])
    tadj.x <- InvBoxCox(adj.x,decomp.x[[""lambda""]])
  else
    tadj.x <- adj.x
  
  # Trend and seasonal measures
  v.adj <- var(adj.x, na.rm=TRUE)
  if(freq > 1)
  {
    detrend <- decomp.x[[""x""]] - decomp.x[[""trend""]]
    deseason <- decomp.x[[""x""]] - decomp.x[[""season""]]
    trend <- ifelse(var(deseason,na.rm=TRUE) < 1e-10, 0, 
                    max(0,min(1,1-v.adj/var(deseason,na.rm=TRUE))))
    season <- ifelse(var(detrend,na.rm=TRUE) < 1e-10, 0,
                     max(0,min(1,1-v.adj/var(detrend,na.rm=TRUE))))
  }
  else #Nonseasonal data
  {
    trend <- ifelse(var(decomp.x[[""x""]],na.rm=TRUE) < 1e-10, 0,
                    max(0,min(1,1-v.adj/var(decomp.x[[""x""]],na.rm=TRUE))))
    season <- 0
  }
  
  m <- c(fx,trend,season)
  
  # Measures on original data
  xbar <- mean(x,na.rm=TRUE)
  s <- sd(x,na.rm=TRUE)
  
  # Serial correlation
  Q <- Box.test(x,lag=10)[[""statistic""]]/(N*10)
  fQ <- f2(Q,7.53,0.103)
  
  # Nonlinearity
  p <- tseries::terasvirta.test(na.contiguous(x))[[""statistic""]]
  fp <- f1(p,0.069,2.304)
  
  # Skewness
  sk <- abs(mean((x-xbar)^3,na.rm=TRUE)/s^3)
  fs <- f1(sk,1.510,5.993)
  
  # Kurtosis
  k <- mean((x-xbar)^4,na.rm=TRUE)/s^4
  fk <- f1(k,2.273,11567)
  
  # Hurst=d+0.5 where d is fractional difference.
  H <- fracdiff::fracdiff(na.contiguous(x),0,0)[[""d""]] + 0.5
  
  # Lyapunov Exponent
  if(freq > N-10)
    stop(""Insufficient data"")
  Ly <- numeric(N-freq)
  for(i in 1:(N-freq))
  {
    idx <- order(abs(x[i] - x))
    idx <- idx[idx < (N-freq)]
    j <- idx[2]
    Ly[i] <- log(abs((x[i+freq] - x[j+freq])/(x[i]-x[j])))/freq
    if(is.na(Ly[i]) | Ly[i]==Inf | Ly[i]==-Inf)
      Ly[i] <- NA
  }
  Lyap <- mean(Ly,na.rm=TRUE)
  fLyap <- exp(Lyap)/(1+exp(Lyap))
  
  m <- c(m,fQ,fp,fs,fk,H,fLyap)
  
  # Measures on adjusted data
  xbar <- mean(tadj.x, na.rm=TRUE)
  s <- sd(tadj.x, na.rm=TRUE)
  
  # Serial
  Q <- Box.test(adj.x,lag=10)[[""statistic""]]/(N*10)
  fQ <- f2(Q,7.53,0.103)
  
  # Nonlinearity
  p <- tseries::terasvirta.test(na.contiguous(adj.x))[[""statistic""]]
  fp <- f1(p,0.069,2.304)
  
  # Skewness
  sk <- abs(mean((tadj.x-xbar)^3,na.rm=TRUE)/s^3)
  fs <- f1(sk,1.510,5.993)
  
  # Kurtosis
  k <- mean((tadj.x-xbar)^4,na.rm=TRUE)/s^4
  fk <- f1(k,2.273,11567)
  
  m <- c(m,fQ,fp,fs,fk)
  names(m) <- c(""frequency"", ""trend"",""seasonal"",
                ""autocorrelation"",""non-linear"",""skewness"",""kurtosis"",
                ""Hurst"",""Lyapunov"",
                ""dc autocorrelation"",""dc non-linear"",""dc skewness"",""dc kurtosis"")
  
  return(m)
}


","2018-16"
"633",1754,"https://github.com/Songeo/tidytuesday","Songeo","tidytuesday","src/180507_coffee.R","

library(tidyverse)
library(maps)
library(tmap)
library(sp)
theme_set(theme_bw())

# Datos ----
df_coffee_raw <- readxl::read_xlsx(""data/week6_coffee_chains.xlsx"")
df_coffee_raw %>% 
  data.frame %>% head
df_coffee_raw %>%  summary()
filter(df_coffee_raw, is.na(Longitude))

df_coffee_raw %>% 
  group_by(Brand) %>% 
  summarise(n_ctry = n_distinct(Country),
            n_obs = n())
df_coffee_raw$`Ownership Type` %>% table


# World map ----
map_wd <- map_data(""world"") 
map_wd %>% head
gg <- ggplot() + 
  geom_polygon(data = map_wd, 
               aes(x=long, y = lat, group = group), 
               fill = ""mistyrose"") + 
  geom_point(data = df_coffee_raw, 
             aes(x = Longitude, y = Latitude, 
                 color = Brand), 
             alpha = .3) + 
  coord_fixed(1.3) + 
  facet_wrap(~Brand)
ggsave(plot = gg, filename = ""graphs/180507_worldmap.png"", 
       width = 12, height = 8)

# Mexico ----
# Just mapping Mexico (my home)
map_mex <- map_wd %>% 
  filter(region == ""Mexico"")

df_coffee_raw_mx <- df_coffee_raw %>% 
  filter(Country %in% c(""MX""))

df_coffee_raw_mx$`City` %>% unique()
df_coffee_raw_mx$`State/Province` %>% unique()

# mapping with ggplot
gg <- ggplot() + 
  geom_polygon(data = map_mex, 
               aes(x=long, y = lat, group = group), 
               fill = ""gray80"") + 
  geom_point(data = df_coffee_raw_mx, 
             aes(x = Longitude, y = Latitude, 
                 color = `State/Province` ), 
             alpha = .3) + 
  theme(legend.position = ""none"") + 
  coord_fixed(1.3) + 
  facet_wrap(~Brand)
ggsave(gg, filename = ""graphs/180507_ggplot_mex.png"", 
       width = 10, height = 7)

df_coffee_raw_mx %>% 
  group_by(`State/Province`) %>% 
  tally() 


# Shape files Mexico por estado ----
# Mapping with tmap, very similar to ggplot

# Shape files from mexico by state
dir(""src/mex_edos_shapes"")
shp_edo_rgdal <-  rgdal::readOGR(""src/mex_edos_shapes/Mex_Edos.shp"") %>% 
  sp::merge(read_csv(""src/180507_mex_states.csv""), 
            by = ""NOM_ENT"") %>% 
  sp::merge(df_coffee_raw_mx %>% 
              group_by(`State/Province`) %>% 
              summarise(`num tiendas` = n()) )

# DF Polygone
class(shp_edo_rgdal)
shp_edo_rgdal@data %>% head()
shp_edo_rgdal@data %>% summary()

# Map polygons and bubles
tm_shape(shp_edo_rgdal) + 
  tm_fill(col = ""num tiendas"", 
          palette = ""RdYlBu"", 
          title = ""Number stores in MEX"",
          style=""fixed"",
          breaks=c(-Inf, 0, 1, 10, 
                   50, 100, 250, Inf),
          contrast=.7) + 
  tm_bubbles(size = ""num tiendas"",
             col = ""red"",
             title.size=""Number of stores"", 
             alpha = .3,
             contrast = 1) + 
  tm_borders() + 
  tm_text(""State/Province"", col = ""gray40"") +
  tm_style_gray() + 
  tm_format_World()
save_tmap(filename = ""graphs/180507_tmap_mex.png"", 
          width = 10, height = 7)




# Script adicional
{
# # function to obtain US county shape
# # https://github.com/mtennekes/tmap/blob/master/demo/USChoropleth/US_choropleth.R
# get_US_county_2010_shape <- function() {
#   dir <- tempdir()
#   download.file(""http://www2.census.gov/geo/tiger/GENZ2010/gz_2010_us_050_00_20m.zip"", 
#                 destfile = file.path(dir, ""gz_2010_us_050_00_20m.zip""))
#   unzip(file.path(dir, ""gz_2010_us_050_00_20m.zip""), exdir = dir)
#   US <- read_shape(file.path(dir, ""gz_2010_us_050_00_20m.shp""))
#   levels(US@data$NAME) <- iconv(levels(US@data$NAME), from = ""latin1"", to = ""utf8"")
#   US
# }
# # obtain US county shape
# US <- get_US_county_2010_shape()
# US@data %>% head
# data(""World"")
# World
# World@data %>% head
}
","2018-19"
"634",138,"https://github.com/gkaramanis/tidytuesday/tree/master/week-20","gkaramanis","tidytuesday","week-20/nobel.R","library(tidyverse)

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

nobel_winners %>%
  # remove NA death countries
  filter(!is.na(death_country)) %>%
  # keep only entries with different birth and death country
  filter(birth_country != death_country) %>%
  mutate(
    colour = case_when(
      death_country == ""United States of America"" ~ ""#FF2B4F"",
      death_country == ""West Germany (Germany)"" ~ ""#003399"",
      death_country == ""United Kingdom"" ~ ""#3686d3"",
      death_country == ""Germany"" ~ ""#fcab27"",
      death_country == ""France"" ~ ""#88398a"",
      death_country == ""Switzerland"" ~ ""#20d4bc"",
      T ~ ""gray60""
    )
  ) %>%
  ggplot(aes(
    x = 0,
    y = fct_rev(factor(birth_country)),
    xend = death_country,
    yend = 1,
    colour = colour,
    alpha = (colour != ""gray60"")
  )) +
  geom_curve(curvature = -0.5,
             arrow = arrow(length = unit(0.01, ""npc""))) +
  scale_x_discrete() +
  scale_y_discrete() +
  scale_color_identity() +
  scale_size_identity() +
  scale_alpha_manual(values = c(0.1, 0.2), guide = F) +
  scale_size_manual(values = c(0.1, 0.4), guide = F) +
  labs(title = ""Birth and death countries of Nobel laureates that were born and died in different countries"",
       subtitle = ""USA, W. Germany, UK, Germany, France and Switzerland have the most"",
       x = ""Death country"", y = ""Birth country"",
       caption = ""\nSource: Kaggle | Graphic: Georgios Karamanis / @geokaramanis"") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    plot.background = element_rect(fill = ""#F0EFF1"", colour = ""#F0EFF1""),
    legend.position = ""none"",
    axis.text.x = element_text(angle = 40, hjust = 1, margin = margin(t = -3, r = 0, b = 0, l = 0)),
    text = element_text(family = ""IBM Plex Sans"", size = 5),
    plot.title = element_text(face = ""bold""),
    plot.subtitle = element_text(vjust = 2)
  ) +
  ggsave(""./week-20/nobel.png"", width = 5.5, height = 6)


# Top Death countries of the Nobel Laureates that have
# a different birth country
#
# nobel_winners %>% 
#   filter(!is.na(death_country)) %>% 
#   mutate(diffCountry = ifelse(birth_country == death_country, 0, 1)) %>% 
#   group_by(death_country) %>% 
#   tally(diffCountry) %>% 
#   arrange(desc(n))
","Other-20"
"635",139,"https://github.com/gkaramanis/tidytuesday/tree/master/week-20","gkaramanis","tidytuesday","week-20/nobelClean.R","library(tidyverse)

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

nobel_winners %>%
  # remove NA death countries
  filter(!is.na(death_country)) %>%
  # keep only entries with different birth and death country
  filter(birth_country != death_country) %>%
  # Clean birth countries
  mutate(birth_con = str_extract(birth_country, ""\\(([^()]*)\\)"")) %>%
  mutate(birth_country = 
           if_else(
             is.na (birth_con),
             birth_country,
             gsub(""[()]"", """", birth_con)
           )) %>% 
           mutate(death_con = str_extract(death_country, ""\\(([^()]*)\\)"")) %>%
           mutate(death_country = 
                    if_else(
                      is.na (death_con),
                      death_country,
                      gsub(""[()]"", """", death_con)
                    )
         
         ) %>% 
  mutate(
    colour = case_when(
      death_country == ""United States of America"" ~ ""#FF2B4F"",
      death_country == ""Germany"" ~ ""#fcab27"",
      death_country == ""United Kingdom"" ~ ""#3686d3"",
      death_country == ""France"" ~ ""#88398a"",
      death_country == ""Switzerland"" ~ ""#20d4bc"",
      T ~ ""gray60""
    )
  ) %>%
  ggplot(aes(
    x = 0,
    y = fct_rev(factor(birth_country)),
    xend = death_country,
    yend = 1,
    colour = colour,
    alpha = (colour != ""gray60"")
  )) +
  geom_curve(curvature = -0.5,
             arrow = arrow(length = unit(0.01, ""npc""))) +
  scale_x_discrete() +
  scale_y_discrete() +
  scale_color_identity() +
  scale_alpha_manual(values = c(0.1, 0.2), guide = F) +
  scale_size_manual(values = c(0.1, 0.4), guide = F) +
  labs(title = ""Birth and death countries of Nobel laureates that were born and died in different countries"",
       subtitle = ""USA, Germany, UK, France and Switzerland have the most"",
       x = ""Death country"", y = ""Birth country"",
       caption = ""\nSource: Kaggle | Graphic: Georgios Karamanis / @geokaramanis"") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    plot.background = element_rect(fill = ""#F0EFF1"", colour = ""#F0EFF1""),
    legend.position = ""none"",
    axis.text.x = element_text(angle = 40, hjust = 1, margin = margin(t = -3, r = 0, b = 0, l = 0)),
    text = element_text(family = ""IBM Plex Sans"", size = 5),
    plot.title = element_text(face = ""bold""),
    plot.subtitle = element_text(vjust = 2)
  ) +
  ggsave(""./week-20/nobelClean.png"", width = 5.5, height = 6)


# Top Death countries of the Nobel Laureates that have
# a different birth country
#
# nobel_winners %>%
#   filter(!is.na(death_country)) %>%
#   mutate(diffCountry = ifelse(birth_country == death_country, 0, 1)) %>%
#   group_by(death_country) %>%
#   tally(diffCountry) %>%
#   arrange(desc(n))
","Other-20"
"636",140,"https://github.com/gkaramanis/tidytuesday/tree/master/week-20","gkaramanis","tidytuesday","week-20/nobelMap.R","library(tidyverse)
library(ggmap)

# Load data
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
countriesCoord <- readr::read_csv(""http://worldmap.harvard.edu/download/wfs/34645/csv?outputFormat=csv&service=WFS&request=GetFeature&format_options=charset%3AUTF-8&typename=geonode%3Acountry_centroids_az8&version=1.0.0"")

nobelCountries <- nobel_winners %>%
  select(c(""birth_country"", ""death_country"")) %>% 
  # remove NA death countries
  filter(!is.na(death_country)) %>%
  # Clean birth and death countries (to get current countries in map) 
  mutate(birth_con = str_extract(birth_country, ""\\(([^()]*)\\)"")) %>%
  mutate(birth_country = 
           if_else(
             is.na (birth_con),
             birth_country,
             gsub(""[()]"", """", birth_con)
           )) %>% 
  mutate(death_con = str_extract(death_country, ""\\(([^()]*)\\)"")) %>%
  mutate(death_country = 
           if_else(
             is.na (death_con),
             death_country,
             gsub(""[()]"", """", death_con)
           )
         
  ) %>% 
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""Czechoslovakia""), ""Czech Republic"")) %>%
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""Northern Ireland""), ""United Kingdom"")) %>%
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""Scotland""), ""United Kingdom"")) %>%
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""East Germany""), ""Germany"")) %>%
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""Republic of Macedonia""), ""Macedonia"")) %>%
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""Serbia""), ""Republic of Serbia"")) %>%
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""Guadeloupe Island""), ""France"")) %>%
  mutate_at(vars(birth_country, death_country),
            ~ replace(., which(.== ""Union of Soviet Socialist Republics""), ""Russia"")) %>%
  mutate(
    colour = case_when(
      death_country == ""United States of America"" ~ ""#FF2B4F"",
      death_country == ""Germany"" ~ ""#fcab27"",
      death_country == ""United Kingdom"" ~ ""#3686d3"",
      death_country == ""France"" ~ ""#88398a"",
      death_country == ""Switzerland"" ~ ""#20d4bc"",
      T ~ ""gray60""
    )
  ) %>% 
  select (-c(birth_con, death_con)) %>% 
# keep only entries with different birth and death country
filter(birth_country != death_country)

countriesLL <- countriesCoord %>% select(c(""admin"", ""Longitude"", ""Latitude""))

nobelLL <- merge(nobelCountries, countriesLL, by.x = ""birth_country"", by.y = ""admin"", all.x = TRUE)
nobelLL <- nobelLL %>% rename(fromLong = Longitude, fromLat = Latitude) 
nobelLL <- merge(nobelLL, countriesLL, by.x = ""death_country"", by.y = ""admin"", all.x = TRUE)
nobelLL <- nobelLL %>% rename(toLong = Longitude, toLat = Latitude) 

worldmap <- borders(""world"", colour = ""gray60"", fill = ""gray80"", size = 0.05)

ggplot(nobelLL, aes(
  x = fromLong, y = fromLat,
  xend = toLong, yend = toLat,
  colour = colour,
  alpha = (colour != ""gray60""))) +
  scale_color_identity() +
  scale_alpha_manual(values = c(0.3, 0.5), guide = FALSE) +
  scale_size_manual(values = c(0.05, 0.1), guide = FALSE) +
  labs(title = ""   USA, W. Germany, UK, Germany, France and Switzerland are the most common death countries"",
       subtitle = ""    of Nobel laureates that were born in a different country (arrow heads point to the death country)"", 
       caption = ""\nSource: Kaggle | Graphic: Georgios Karamanis / @geokaramanis    "") +
  worldmap +
  coord_cartesian(ylim = c(-50, 105)) +
  geom_curve(aes(x = fromLong, y = fromLat,
                 xend = toLong, yend = toLat,
                 size = colour != ""gray60""),
             arrow = arrow(length = unit(0.009, ""npc""))) +
  theme_void() +
  theme(
    plot.background = element_rect(fill = ""#F0EFF1"", colour = ""#F0EFF1""),
    text = element_text(family = ""IBM Plex Sans"", size = 5),
    plot.title = element_text(face = ""bold""),
    plot.subtitle = element_text(vjust = 2),
  ) +
  ggsave(""./week-20/nobelMap.png"", width = 6, height = 3.5)

nobelLL %>% filter()","Other-20"
"637",141,"https://github.com/gkaramanis/tidytuesday/tree/master/week-20","gkaramanis","tidytuesday","week-20/nobelShared.R","library(tidyverse)

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

decadesLabels <- function(string) {
  return(as.numeric(string)+1900)
}

filterCategory = ""Medicine""

nobel_winners %>%
  filter(category == filterCategory) %>%
  # Uncomment to add ""missing"" years when filterCategory = Economics:
  # add_row(prize_year = 1901:1968, category = ""Economics"", prize_share=0/1) %>%
  mutate(nume = as.numeric(str_sub(prize_share, 1, 1)),
         deno = as.numeric(str_sub(prize_share, -1)),
         share = nume/deno,
         year = prize_year %% 10,
         decade = prize_year - 1900 - year) %>%
  group_by(prize_year) %>% 
  distinct(full_name, .keep_all = TRUE) %>% 
  mutate(n = row_number()) %>%
  # Big parts of plot code from https://github.com/spren9er/tidytuesday/blob/master/tidytuesday_201916_new_economist.r
  ggplot() + 
  geom_bar(aes(x = """", y = share, fill = as.factor(n)),
    stat = ""identity"", show.legend = FALSE
  ) +
  scale_fill_brewer(palette = ""Purples"") +
  coord_polar(""y"") +
  facet_grid(decade ~ year, switch = ""both"",
             labeller = labeller(decade = decadesLabels)) +
  labs(title = paste(""Shared Nobel Prizes in "", filterCategory, sep = """"),
       subtitle = ""by decade and year, 1901-2016"",
       caption = ""\nSource: Kaggle | Graphic: Georgios Karamanis / @geokaramanis"") +
  theme_void() +
  theme(
    plot.background = element_rect(fill = ""lightgoldenrod3"", colour = ""lightgoldenrod3""),
    plot.margin = unit(c(1.6, 0.6, 0.8, 0.8), ""cm""),
    text = element_text(family = ""IBM Plex Sans"", size = 8),
    plot.title = element_text(face = ""bold"", vjust = 8),
    plot.subtitle = element_text(vjust = 9),
    plot.caption = element_text(size = 4, vjust = -3),
    strip.text.x = element_text(size = 7, 
                                margin = margin(t = 5)),
    strip.text.y = element_text(size = 7, 
      angle = 180, hjust = 1, margin = margin(r = 10))
    ) 

img <- paste(""./week-20/nobelShared-"", filterCategory, "".png"", sep = """")
ggsave(img, height = 5, width = 3.64)
","Other-20"
"638",142,"https://github.com/gkaramanis/tidytuesday/tree/master/week-20","gkaramanis","tidytuesday","week-20/nobelTime.R","library(tidyverse)

nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

# first try, but there are multiple papers for some authors ----
nobel_winner_all_pubs %>%
  filter(is_prize_winning_paper == ""YES"") %>% 
  mutate(yearsToPrize = prize_year - pub_year) %>% 
  arrange(desc(pub_year)) %>% 
  mutate(id = row_number()) %>% 
  ggplot() +
  # geom_point(aes(x = pub_year, y = id)) +
  # geom_point(aes(x = prize_year, y = id)) +
  geom_rect(aes(xmin = pub_year, xmax = prize_year,
                ymin = id, ymax = id + 1))

# find unique combinations, but losing papers ----
winP <- nobel_winner_all_pubs %>%
  filter(is_prize_winning_paper == ""YES"") %>% 
  mutate(yearsToPrize = prize_year - pub_year) %>% 
  arrange(desc(pub_year)) %>%
  distinct(laureate_id, prize_year, .keep_all = TRUE) %>% 
  mutate(id = row_number())
","Other-20"
"639",143,"https://github.com/gkaramanis/tidytuesday/tree/master/week-27","gkaramanis","tidytuesday","week-27/deprecated/media_franchises_tornadotyp.R","library(tidyverse)
library(ggimage)
library(here)

media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

top_games <- media_franchises %>%
  filter(original_media == ""Video game"" &
           revenue_category == ""Video Games/Games"") %>%
  distinct() %>% 
  mutate(
    franchise = str_replace_all(franchise, c("""" = ""e"", ""&"" = ""AND"")),
    coins = map2(5, revenue + 5, seq, by = 1),
    ) %>%
  arrange(year_created) %>% 
  mutate(
    revenue = ifelse((row_number() %% 2) == 1, revenue, -revenue),
    coins = ifelse((revenue > 0), coins, map(coins, function(x) x*-1))
         ) %>% 
  unnest(coins) 

coin_jpg <- here(""week-27"", ""img"", ""coin.jpg"")

top_games %>% 
  group_by(franchise) %>% 
  ggplot(aes(coins,
             factor(fct_reorder(franchise, year_created, .desc = TRUE)))) +
  geom_point() +
  geom_image(aes(image = coin_jpg), size = 0.015, asp = 1.8) +
  geom_text(aes(x = 0,
                label = paste(franchise, year_created, sep = ""\n"")),
            family = ""Karmatic Arcade"",
            size = 3,
            color = ""purple"", fill = ""purple"",
            stat = ""identity"",
            position = ""identity"",
            check_overlap = TRUE) +
  theme_minimal() +
  theme(
    panel.background = element_rect(fill = ""green""),
    text = element_text(family = ""Karmatic Arcade""),
    axis.text.y = element_blank(),
    axis.title.y = element_blank()
  ) +
  
  ggsave(here(""week-27"", ""media_franchises.png""),
          dpi = 300)

","Other-27"
"640",144,"https://github.com/gkaramanis/tidytuesday/tree/master/week-27","gkaramanis","tidytuesday","week-27/media_franchises.R","library(tidyverse)
library(ggimage)
library(here)
library(ggrepel)
library(cowplot)

media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")
coin_img <- here(""week-27"", ""img"", ""coin.png"")

top_games <- media_franchises %>%
  filter(original_media == ""Video game"" &
           revenue_category == ""Video Games/Games"") %>%
  distinct() %>% 
  filter(revenue >= 10) %>% 
  mutate(
    franchise = str_replace_all(franchise, "" (?=\\w)"", ""\n""),
    coins = map2(0, revenue, seq, by = 1)
    ) %>%
  arrange(year_created) %>%
  unnest(coins) 

rev_plot <- ggplot(top_games, aes(coins,
              factor(fct_reorder(franchise, revenue)))) +
  geom_image(aes(image = coin_img), size = 0.035, asp = 1.2) +
  scale_x_continuous(labels = c(""0"", ""10"", ""20"", ""30""),
                     limits =  c(0, 32)) +
  labs(
    x = ""Revenue in billion dollars""
  ) +
  theme_minimal() +
  theme(
    plot.background = element_rect(fill = ""darkblue"", color = ""darkblue""),
    text = element_text(size = 8, family = ""Press Start 2P""),
    axis.text.x = element_text(color = ""magenta1""),
    axis.title.x = element_text(color = ""blue"",
                                margin = margin(20, 0, 0, 0)),
    axis.title.y = element_blank(),
    axis.text.y = element_text(color = ""white"", size = 7),
    panel.grid.minor.y = element_blank(),
    panel.grid.minor.x = element_line(color = ""blue"",
                                      size = 0.1),
    panel.grid.major.x = element_line(color = ""blue"",
                                      size = 0.2),
    panel.grid.major.y = element_blank(),
  )

year_plot <- top_games %>% 
  distinct(franchise, year_created) %>% 
  mutate(franchise = str_replace_all(franchise, ""\\n"", "" "")) %>% 
  ggplot(aes(1, year_created)) +
  geom_text_repel(aes(x = 1,
                      label = franchise),
                  hjust = 1, direction = ""y"", nudge_x = -1,
                  segment.alpha	= 0, color = ""white"",
                  size = 2.5, family = ""Press Start 2P"") +
  geom_text(aes(x = 2.5, label = year_created), check_overlap = TRUE,
            family = ""Press Start 2P"", size = 2.5, color = ""magenta1"") +
  geom_path(size = 0.2, color = ""blue"") +
  geom_point(color = ""yellow"") +
  xlim(-8, 5) +
  scale_y_reverse() +
  labs(
    x = ""Year of inception""
  ) +
  theme_minimal() +
  theme(
    plot.background = element_rect(fill = ""darkblue"", color = ""darkblue""),
    axis.title.x = element_text(size = 8, color = ""blue"",
                                family = ""Press Start 2P"",
                                margin = margin(20, 0, 0, 0)),
    axis.text = element_blank(),
    panel.grid = element_blank(),
    axis.title.y = element_blank()
    )
  
p <- plot_grid(rev_plot, year_plot, rel_widths = c(1.5, 1)) +
  theme(
  plot.margin = margin(10, 30, 10, 30),
  plot.background = element_rect(fill = ""darkblue"", color = ""darkblue"")
  )


title <- ggdraw() +
  draw_label(""Video game franchises with a revenue of $10 billion\nor more from sales of the actual video games "",
             size = 11, fontfamily = ""Press Start 2P"", colour = ""white"") +
  theme(
    plot.background = element_rect(fill=""darkblue"", color = ""darkblue"")
  )

caption <- ggdraw() +
  draw_label(""Source: Wikipedia | Graphic: Georgios Karamanis"",
             size = 6.5, fontfamily = ""Press Start 2P"", colour = ""white"") +
  theme(
    plot.background = element_rect(fill=""darkblue"", color = ""darkblue"")
  )

plot_grid(title, p, caption, ncol = 1, rel_heights = c(0.2, 1, 0.15)) +
ggsave(here(""week-27"", ""media_franchises.png""),
          dpi = 300, height = 7, width = 10)
","Other-27"
"641",145,"https://github.com/gkaramanis/tidytuesday/tree/master/week-27","gkaramanis","tidytuesday","week-27/media_franchises_circles.R","library(tidyverse)
library(here)
library(cowplot)
library(RColorBrewer)

media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

sorted_rev <- media_franchises %>%
  group_by(franchise) %>%
  mutate(revenue_perc = round(revenue/sum(revenue)*100, 1)) %>% 
  select(franchise, revenue_category, revenue, revenue_perc) %>% 
  arrange(franchise, -revenue_perc) %>%
  mutate(order = row_number())

# saved me:
# https://drsimonj.svbtle.com/ordering-categories-within-ggplot2-facets

# main plot
p <- sorted_rev %>%
  ungroup() %>% 
  mutate(franchise = str_replace(franchise, "" / "", ""\n"")) %>% 
ggplot() +
  geom_col(aes(x = order,
               y = revenue_perc,
               fill = revenue_category),
           # width affects only the biggest revenue, gives warnings
           width = 3
           ) +
  facet_wrap(~franchise, ncol = 10) +
  scale_x_reverse() +
  scale_fill_brewer(palette = ""Dark2"") +
  coord_polar(theta = ""y"") +
  labs(
    title = ""Media Franchise Powerhouses"",
    subtitle = ""Different revenue streams as percentage of the total revenue.\nThe outer ring shows the largest revenue stream (full circle is 100%)"",
    caption = ""Source: Wikipedia | Graphic: Georgios Karamanis""
  ) +
  theme_void() +
  theme(
    legend.position = ""none"",
    plot.background = element_rect(fill = ""#fff5ba"", color = ""#fff5ba""),
    plot.margin = margin(0, 50, 0, 50),
    strip.text.x = element_text(size = 1),
    plot.title = element_text(family = ""Space Mono Bold"",
                              size = 11, hjust = 0.5,
                              margin = margin(30, 0, 5, 0)),
    plot.subtitle = element_text(family = ""Space Mono"",
                              size = 7, hjust = 0.5,
                              margin = margin(0, 0, 30, 0)),
    plot.caption = element_text(family = ""Space Mono"", 
                                size = 6, hjust = 0.5,
                                margin = margin(30, 0, 30, 0)),                      
    text = element_text(family = ""Space Mono"")
  )

# custom ""legend"" plot
l <- tribble(
  ~category, ~x, ~y,
  ""Video Games/Games"", 1.5,  2,
  ""Box Office"", 2.15,  2,
  ""Home Video/Entertainment"", 3.65, 2,
  ""Music"", 4, 2,
  ""TV"", 0.5, 1,
  ""Book Sales"", 1.15, 1,              
  ""Merchandise, Licensing & Retail"", 3.1, 1,
  ""Comic or Manga"", 4, 1
  ) %>% 
  ggplot(aes(label = category, x = x, y = y,
             color = category)) +
  # geom_text(family = ""Space Mono Bold"",
  #           hjust = 1, size = 1.5) +
  geom_label(aes(fill = category),
             label.r = unit(0, ""lines""),
             label.padding = unit(0.05, ""lines""),
             color = ""#fff5ba"",
             family = ""Space Mono Bold"",
             hjust = 1, size = 1.5) +
  scale_fill_brewer(palette = ""Dark2"") +
  coord_fixed(ratio = 0.2, xlim = c(0, 4), ylim = c(0, 2.5)) +
  theme_void() +
  theme(
    legend.position = ""none"",
    plot.background = element_rect(fill = ""#fff5ba"", color = ""#fff5ba"")
  )

# plot and save
ggdraw() +
  draw_plot(p) +
  draw_plot(l, x = 0.35, y = 0.11, width = 0.52, height = 0.1) +
  ggsave(here(""week-27"", ""media_franchises_circles.png""),
    height = 6.35, width = 5, dpi = 900)

","Other-27"
"642",146,"https://github.com/gkaramanis/tidytuesday/tree/master/week-24","gkaramanis","tidytuesday","week-24/meteorites.R","library(tidyverse)
library(ggrepel)

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

top10 <- meteorites %>%
  top_n(10, mass) %>%
  arrange(-mass) %>%
  mutate(x = (row_number()- 1) %% 5,
         y = ((row_number() - 1) %/% 5)
         )
# stars
stars <- data.frame(s = runif(100, min = 0.1, max = 0.7))

# world without Antarctica
world <- map_data(""world"") %>%
  filter(group < 32 | group > 132)

ggplot(top10, aes(x = x, y = y - 0.1)) +
  # stars
  geom_jitter(data = stars,
              aes(2, -1.2), width = 2.5, height = 1,
              size = stars$s, color = ""white"", alpha = stars$s) +
  
  # meteorites          
  geom_point(aes(size = mass), color = ""darkorange"") +
  
  # meteorite name
  geom_text(aes(y = y + 0.22,
                label = toupper(name)), size = 2.5, color = ""white"",
            family = ""IBM Plex Sans Bold"") +
  # meteorite mass
  geom_text(aes(y = y + 0.31,
                label = paste(mass/1000000, ""tons"", sep = "" "")), size = 2.5, color = ""orange"",
            family = ""IBM Plex Sans Bold"") +
  # year
  geom_text(aes(y = y + 0.39,
                label = year), size = 2.5, color = ""white"",
            family = ""IBM Plex Sans Italic"") +
            
  # title         
  geom_text(
    aes(x = 2, y = -1.5,
        label = ""THE TEN\nBIGGEST\n\nON EARTH""),
    size = 10, hjust = 0.5, lineheight = 0.8,
    color = ""white"", family = ""IBM Plex Sans Bold""
  ) +
  geom_text(
    aes(x = 2, y = -1.358,
        label = ""METEORITES""),
    size = 10, hjust = 0.5, lineheight = 0.8,
    color = ""orange"", family = ""IBM Plex Sans Bold""
  ) +
  geom_text(
    aes(x = 2, y = -0.7,
        label = ""Name, mass and year found or observed\nRanked by mass""),
    size = 3, hjust = 0.5, lineheight = 0.9,
    color = ""white"", family = ""IBM Plex Sans Light""
  ) +
  
  # map
  geom_polygon(data = world, aes(1.9 + long/80,
                                 2.8 - lat/96,
                                 group = group),
               fill = ""grey50"", color = ""grey30"", size = 0.05) +
  geom_point(aes(1.9 + long/80, 2.8 - lat/96),
    alpha = 1, color = ""darkorange"") +
  geom_text_repel(aes(1.9 + long/80,
                2.8 - lat/96,
                label = name), color = ""white"",
                family = ""IBM Plex Sans Italic"",
            size = 2) +
  # caption
  geom_text(aes(x = 2, y = 3.5,
                label = ""Source: NASA | Graphic: Georgios Karamanis""),
            color = ""grey50"", family = ""IBM Plex Sans Light"", size = 1.8) +
  
  scale_y_reverse() +
  coord_cartesian(xlim = c(-0.5, 4.5),
                  ylim = c(3.5,-2)) +
  scale_size(range = c(7, 20)) +

  theme_void() +
  theme(plot.background = element_rect(color = ""midnightblue"",
                                        fill = ""midnightblue""),
        legend.position = ""none""
        ) +
  
  ggsave(""./week-24/meteorites.png"",
         height = 8,
         width = 5)","Other-24"
"643",147,"https://github.com/gkaramanis/tidytuesday/tree/master/week-24","gkaramanis","tidytuesday","week-24/meteorites2.R","library(tidyverse)
#library(sp)
library(rworldmap)

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

# https://stackoverflow.com/questions/21708488/get-country-and-continent-from-longitude-and-latitude-point-in-r
coords2continent = function(points)
  {  
  countriesSP <- getMap(resolution='low')
  pointsSP = SpatialPoints(points, proj4string = CRS(proj4string(countriesSP)))  
  indices = over(pointsSP, countriesSP)
  # indices$REGION # returns continent
  indices$ADMIN  #returns country name
  }


fellMeteo <- meteorites %>%
  drop_na() %>%
  filter(fall == ""Fell"") %>% 
  select(long, lat) %>% 
  mutate(country = coords2continent(.)) %>%
  mutate(country = str_replace_all(country, ""United States of America"", ""U.S.A."")) %>% 
  drop_na() %>% 
  left_join(., meteorites) %>% 
  group_by(country) %>% 
  mutate(medianMass = median(mass)/1000,
         sumFell = sum(n()),
         countryLat = mean(lat),
         countryLong = mean(long)) %>% 
  filter(sumFell > 21) %>% 
  mutate(countryNr = group_indices())

countriesList <- fellMeteo %>%
  distinct(country, countryNr, countryLat)

fellMeteo %>% 
  ggplot(aes(countryNr + lat/50, 3)) +
  geom_rect(aes(xmin = 0, ymin = 0, xmax = 29, ymax = 3)) +
  geom_segment(aes(xend = countryNr + lat/50,
                   yend = 3 + (2020 - year)/100),
                   size = 0.25, alpha = 0.5, color = ""orange"") +
  geom_point(aes(size = mass),
             color = ""orangered"", fill = ""red"",
             alpha = 0.2, shape = 21) +
  geom_text(data = countriesList, aes(countryNr + countryLat/50, 2.8, label = country),
             color = ""white"", hjust = 1, size = 1) +    
  scale_size(range = c(0, 10)) +                 
  theme_minimal() +
  xlim(0, 29) +
  ylim(0, 15) +
  coord_polar(start = -pi/2.4) +
  theme_void() +
  theme(
    legend.position = ""top"",
    panel.background = element_rect(fill = ""midnightblue""),
    plot.margin = margin(0, 0, -27, 0, ""cm"")
  ) +

ggsave(""./week-24/meteorites.png"", dpi = 600)




","Other-24"
"644",148,"https://github.com/gkaramanis/tidytuesday/tree/master/week-19","gkaramanis","tidytuesday","week-19/students.R","library(tidyverse)
library(wesanderson)

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

# keep just the countries
student_ratio %>% filter(nchar(country_code) < 4) %>% 
ggplot(aes(student_ratio, edulit_ind)) +
  geom_jitter(height = 0.05, alpha = 0.4,
              shape = 4, color = ""midnightblue"") +
  scale_x_continuous(limits = c(0, 180),
                     expand = c(0, 0)) +
  scale_y_discrete(labels = c(""Pre-Primary"", ""Primary"",
                              ""Lower\nSecondary"", ""Secondary"",
                              ""Upper\nSecondary"", ""Post-Secondary\nNon-Tertiary"",
                              ""Tertiary"")) +
  labs(title = ""Student to Teacher Ratios"",
       subtitle = ""in 200 countries, by level of education"",
       caption = ""\nSource: UNESCO | Graphic: @geokaramanis"",
       x = ""Student to teacher ratio""
       ) +
  theme_minimal() +
  theme(
  legend.position = ""none"",
  plot.background = element_rect(fill = ""cornsilk"", colour = ""cornsilk""),
  plot.margin = unit(c(0.2, 0.8, 0.2, 0.6), ""cm""),
  panel.grid = element_blank(),
  panel.grid.minor.x = element_blank(),
  panel.grid.minor.y = element_blank(),
  panel.grid.major.x = element_blank(),
  panel.grid.major.y = element_line(color = ""gray85"", size = 0.3),
  axis.text.y = element_text(size = 9),
  axis.title.y = element_blank(),
  axis.ticks = element_blank(),
  axis.ticks.x = element_line(color = ""#212121"", size = 0.3),
  axis.ticks.length = unit(0.2, ""cm""),
  axis.line.x = element_line(size = 0.3, color = ""#212121""),
  text = element_text(family = ""IBM Plex Sans"", size = 9),
  plot.title = element_text(face = ""bold""),
  plot.subtitle = element_text(vjust = 2)
) +
  ggsave(""./week-19/students.png"", width = 6, height = 4)
","Other-19"
"645",149,"https://github.com/gkaramanis/tidytuesday/tree/master/week-33","gkaramanis","tidytuesday","week-33/deprecated/emperor_curves.R","library(tidyverse)
library(here)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# BCE dates
age_emperors <- emperors %>% 
  mutate(
    birth = case_when(
      index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
      TRUE ~ birth
    ),
    reign_start = case_when(
      index == 1 ~ update(reign_start, year = -year(reign_start)),
      TRUE ~ reign_start
    ),
    age_death = interval(birth, death) / years(1),
    age_reignstart = interval(birth, reign_start) / years(1),
    age_reignend = interval(birth, reign_end) / years(1) 
  ) %>% 
  filter(!is.na(age_death)) %>% 
  mutate(index = row_number())

ggplot(age_emperors) +
  geom_curve(aes(x = reign_start, y = 1,
                 xend = reign_end, yend = 1, color = name),
             curvature = -1) +
  geom_curve(aes(x = birth, y = -1,
                 xend = death, yend = -1, color = name),
             curvature = +1) +
  ylim(-15, 15) +
theme_void() +
  theme(
    legend.position = ""none"",
    plot.background = element_rect(fill = ""#9a1d15"", color = ""#9a1d15"")
  ) +
  
  ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         width = 18, height = 6, dpi = 320)


","Other-33"
"646",150,"https://github.com/gkaramanis/tidytuesday/tree/master/week-33","gkaramanis","tidytuesday","week-33/deprecated/emperor_turtle.R","library(TurtleGraphics)


l = 0.1
p = 10

turtle_init(width = 2, height = 2)
turtle_lwd(3)
turtle_hide()

# left wreath
turtle_setpos(1, 0.6)
turtle_left(90)

for (i in 1:p) {
  turtle_forward(l * 1.5)
  # leaf left
  turtle_left(90)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_right(135)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_left(120)
  # leaf right
  turtle_right(90)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_left(135)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_right(120)
  # 
  turtle_right(15)
  }

# right wreath
turtle_setpos(1, 0.6)
turtle_right(30)
for (i in 1:p) {
  turtle_forward(l * 1.5)
  # leaf left
  turtle_left(90)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_right(135)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_left(120)
  # leaf right
  turtle_right(90)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_left(135)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_right(120)
  # 
  turtle_right(15)
}","Other-33"
"647",151,"https://github.com/gkaramanis/tidytuesday/tree/master/week-33","gkaramanis","tidytuesday","week-33/deprecated/emperor_year.R","library(tidyverse)
library(here)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# BCE dates
age_emperors <- emperors %>% 
  mutate(
    birth = case_when(
      index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
      TRUE ~ birth
    ),
    reign_start = case_when(
      index == 1 ~ update(reign_start, year = -year(reign_start)),
      TRUE ~ reign_start
    ),
    birth = year(birth),
    death = year(death),
    reign_start = year(reign_start),
    reign_end = year(reign_end),
    reign_duration = reign_end - reign_start
  )

ggplot(age_emperors) +
  geom_tile(aes(x = 0, y = index,
                width = reign_duration, height = 0.8))
  
  ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         width = 12, height = 12, dpi = 320)



#9a1d15 60.9 %Sangria (Red)
#b89836 17.8 % Sundance (Brown)
#d3b03c 8.2 % Metallic Gold (Yellow)
#8d2516 5.1 % Falu Red (Red)
#925523 4.5 % Mai Tai (Brown)
#a67831 3.4 % Hot Toddy (Brown)



","Other-33"
"648",152,"https://github.com/gkaramanis/tidytuesday/tree/master/week-33","gkaramanis","tidytuesday","week-33/deprecated/emperors.R","library(tidyverse)
library(here)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# BCE dates
age_emperors <- emperors %>% 
  mutate(
    birth = case_when(
			index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
			TRUE ~ birth
			),
			reign_start = case_when(
			index == 1 ~ update(reign_start, year = -year(reign_start)),
			TRUE ~ reign_start
			),
    age_death = interval(birth, death) / years(1),
    age_reignstart = interval(birth, reign_start) / years(1),
    age_reignend = interval(birth, reign_end) / years(1) 
			) %>% 
  filter(!is.na(age_death)) %>% 
  mutate(index = row_number())

ggplot(age_emperors) +
  geom_rect(aes(ymin = 0, xmin = index - 0.1, ymax = age_death, xmax = index + 0.1), fill = ""#a67831"") +
  geom_rect(aes(ymin = age_reignstart, xmin = index - 0.25, ymax = age_reignend, xmax = index + 0.25), fill = ""#d3b03c"") +
  # cause of death as icon/label
	# background bands = dynasties
  scale_y_reverse(breaks = c(0, 10, 20, 30, 40, 50, 60, 70)) +
		theme_void() +
		theme(
			plot.background = element_rect(fill = ""#9a1d15"", color = ""#9a1d15""),
			axis.text.y = element_text(color = ""white"")
		) +

ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
        width = 12, height = 12, dpi = 320)
        
        
        
#9a1d15 60.9 %Sangria (Red)
#b89836 17.8 % Sundance (Brown)
#d3b03c 8.2 % Metallic Gold (Yellow)
#8d2516 5.1 % Falu Red (Red)
#925523 4.5 % Mai Tai (Brown)
#a67831 3.4 % Hot Toddy (Brown)



","Other-33"
"649",153,"https://github.com/gkaramanis/tidytuesday/tree/master/week-33","gkaramanis","tidytuesday","week-33/deprecated/laurel.R","library(tidyverse)
library(ggforce)

laurel <- data.frame(
  start = c(0.7, -0.7),
  end = c(pi - 0.1, -pi + 0.1),
  r = c(0.7, 0.7)
  )

leaf <- data.frame(
  x = c(0.6, 0.5, 0.8, 0.5, 0.6, 0.3),
  y = c(1, 1, 0.5, 0, 0, 0.5)
  )

ggplot() +
  geom_arc(data = laurel, aes(x0 = 0, y0 = 0, r = r, start = start, end = end)) +
  geom_bspline_closed(data = leaf, aes(x, y), alpha = 0.5) +
  coord_fixed() +
  
  ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         dpi = 320)
","Other-33"
"650",154,"https://github.com/gkaramanis/tidytuesday/tree/master/week-33","gkaramanis","tidytuesday","week-33/emperors_table.R","library(tidyverse)
library(here)
library(lubridate)
library(glue)
library(ggtext)
library(rcartocolor)
library(cowplot)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

age_emperors <- emperors %>% 
  # BCE dates to negative
  mutate(
    birth = case_when(
      index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
      TRUE ~ birth
    ),
    reign_start = case_when(
      index == 1 ~ update(reign_start, year = -year(reign_start)),
      TRUE ~ reign_start
    ),
    # calculate ages, durations
    age_death = round(interval(birth, death) / years(1)),
    age_reignstart = interval(birth, reign_start) / years(1),
    age_reignend = interval(birth, reign_end) / years(1),
    reign_duration = round(interval(reign_start, reign_end) / years(1), 1),
    # abbreviation of names
    nam = substring(name, 1, 3),
    # fix typo in dataset
    name = case_when(
    	name == ""Consantius II"" ~ ""Constantius II"",
    	TRUE ~ name
    	)
  )

# big table
p1 <- ggplot(age_emperors) +
  # box for dynasty
  geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1, fill = dynasty), color = ""white"") +
  # bar for era
  geom_rect(aes(xmin = -1, ymin = 0.8, xmax = 1, ymax = 1, fill = era), color = ""white"") +
  # full name
  geom_text(aes(label = name, x = -0.65, y = 0.45), hjust = 0,
            size = 2, family = (""Cinzel""), color = ""white"") +
  # abbreviation        
  geom_text(aes(label = nam, x = -0.7, y = 0.05), hjust = 0,
            size = 8, family = (""Cinzel""), fontface = ""bold"", color = ""white"") +
  # age at death and reign duration      
  geom_text(aes(label = paste0(age_death, "" | "", reign_duration),
                x = -0.7, y = -0.5), hjust = 0,
            size = 6, family = (""Cinzel""), color = ""grey90"") +
  # not sure if helps for keeping everything square       
  coord_fixed(xlim = c(-1, 1), ylim = c(-1, 1)) + 
  # fills with custom order
  scale_fill_carto_d(palette = ""Antique"", name = ""Eras and Dynasties"",
    limits = c(""Principate"", ""Dominate"", ""Julio-Claudian"", ""Flavian"", ""Nerva-Antonine"", ""Severan"", ""Gordian"", ""Constantinian"", ""Valentinian"", ""Theodosian"")) +
  # facets
  facet_wrap(~ index, ncol = 10) +
  # title and caption
  labs(
  	title = ""The Unperiodic Table\nof the Roman Emperors,\n27 BCE  395 CE"",
  	caption = ""Source: Zonination via Wikipedia | Graphic: Georgios Karamanis""
  ) + 
  # theme
  theme_void(base_family = ""Cinzel"") +
  theme(
    legend.position = ""bottom"",
    # legend.spacing.x = unit(0.8, 'cm'),
    legend.text = element_text(margin = margin(0, 20, 0, 0)),
    legend.title = element_text(margin = margin(0, 20, 0, 0)),
    legend.text.align = 0,
    strip.text = element_blank(),
    panel.spacing = unit(2, ""points""),
    plot.margin = margin(20, 20, 20, 20),
    plot.title = element_text(family = ""Cinzel"", face = ""bold"", size = 48,
                              margin = margin(0, 0, 60, 0), hjust = 0),
    plot.caption = element_text(family = ""Cinzel"", hjust = 0.5, size = 20,
                                margin = margin(40, 0, 0, 50))
  ) 

# legend 
p2 <- ggplot(subset(age_emperors, index == 1)) +
  # dynasty and era
  geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1), fill = ""#AF6458"", color = ""white"") +
  geom_rect(aes(xmin = -1, ymin = 0.8, xmax = 1, ymax = 1), fill = ""#855C75"", color = ""white"") +
  # text
  geom_text(aes(label = name, x = -0.65, y = 0.45), hjust = 0,
            size = 3, family = (""Cinzel""), color = ""white"") +
  geom_text(aes(label = nam, x = -0.7, y = 0.05), hjust = 0,
            size = 12, family = (""Cinzel""), fontface = ""bold"", color = ""white"") +
  geom_text(aes(label = paste0(age_death, "" | "", reign_duration),
                x = -0.7, y = -0.5), hjust = 0,
            size = 8, family = (""Cinzel""), color = ""grey90"") +
  # legend of legend
  geom_label(aes(x = -1.1, y = 0.9, hjust = 1,
                     label = ""Era""), size = 4,  family = (""Cinzel""), fontface = ""bold"", fill = ""#855C75"", color = ""white"", label.r = unit(0, ""lines"")) +
  geom_label(aes(x = -1.1, y = 0.68, hjust = 1,
                     label = ""Dynasty""), size = 4,  family = (""Cinzel""), fontface = ""bold"", fill = ""#AF6458"", color = ""white"", label.r = unit(0, ""lines"")) +
  geom_text(aes(x = -1.1, y = 0.45, hjust = 1,
                     label = ""Full Name""), size = 4,  family = (""Cinzel""), color = ""black"") +
  geom_text(aes(x = -1.1, y = 0.05, hjust = 1,
                     label = ""Abbreviation""), size = 6,  family = (""Cinzel""), fontface = ""bold"", color = ""black"") +
  geom_text(aes(x = -1.1, y = -0.5, hjust = 1,
                     label = ""Age at Death | Reign Duration\n(in years)""), size = 4,  family = (""Cinzel""), color = ""black"") +
  
  coord_fixed(xlim = c(-4, 1), ylim = c(-1, 1)) +
  theme_void() +
  theme(
    legend.position = ""none""
  ) 

ggdraw(p1) + draw_plot(p2, 0.49, 0.81, 0.6, 0.15) +
  
ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         # width = 15, height = 15, dpi = 320)
       width = 15, height = 15)







","Other-33"
"651",155,"https://github.com/gkaramanis/tidytuesday/tree/master/week-30","gkaramanis","tidytuesday","week-30/meta/wilidlife_times.R","library(ggplot2)

wildlife_times <- read.csv(""week-30/wildlife_times.csv"") 

ggplot(wildlife_times) +
  geom_point(aes(date, time)) +
  scale_y_time()
","Other-30"
"652",156,"https://github.com/gkaramanis/tidytuesday/tree/master/week-30","gkaramanis","tidytuesday","week-30/wildlife.R","library(tidyverse)
library(here)
library(ggimage)
library(ggrepel)

airplane_png <- here(""week-30"", ""747.png"")
components <-  read.csv(here(""week-30"", ""components.csv""))

air_size = 10
  
comp_coord <-  tribble(
  ~aircraft_component, ~x, ~y,
  ""Radome"", 0, 0.9*air_size,
  ""Nose"", 0, 0.82*air_size,
  ""Windshield"", 0, 0.77*air_size,
  ""Fuselage"", 0, 0.4*air_size,
  ""Propeller"", 0.36*air_size, 0.25*air_size,
  ""Engines"", 0.6*air_size, 0.05*air_size,
  ""Wing/rotor"", 0.7*air_size, -0.2*air_size,
  ""Landing gear"", 0, -0.05*air_size,
  ""Tail"", 0, -0.7*air_size
  )

components <- right_join(components, comp_coord)
y_list <- seq(from = 0.82*air_size, to = -0.7*air_size, length.out = 9) 
 
ggplot(components, aes(x, y)) +
  # airplane
  geom_image(aes(image = airplane_png, -4, 0), size = 0.55, asp = 1.3) +
  
  # rectangle
  geom_tile(aes(x = 12.8, y = 0.6,
                width = 9.6, height = 16.8), 
            fill = ""#4089bb"") +
  
  # labels
  geom_segment(aes(x = x-4, y = y,
    xend = 8, yend = y_list),
    color = ""#43464B"") +
  geom_text(aes(label = toupper(aircraft_component), 
                x = 8.5, y = y_list), family = ""IBM Plex Sans Condensed Medium"",
            color = ""white"", hjust = 0) +
  
  # birds circles
  geom_point(aes(14, y_list, size = birds_percentage_of_total_struck, 
                 stroke = birds_percentage_of_total_damaged/3),
             shape = 21, color = ""#E6C4A1"", fill = ""#69108a"") +
  
  # terrestrial mammals circles
  geom_point(aes(16.2, y_list, size = terrestrialmammals_percentage_of_total_struck,
                 stroke = terrestrialmammals_percentage_of_total_damaged/3), 
             shape = 21, color = ""#FFFC31"", fill = ""#3A533D"") +
  
  # legend birds
  geom_point(aes(21.5, 4.5, size = 35, 
                 stroke = 6),
             shape = 21, color = ""#E6C4A1"", fill = ""#69108a"") +
  geom_segment(aes(x = 21.5, y = 4.5, xend = 21.5, yend = 6),
               color = ""#69108a"", size = 1) +
  geom_segment(aes(x = 21.5, y = 4, xend = 21.5, yend = 3),
               color = ""#E6C4A1"", size = 1) +
  geom_text(aes(label = ""Birds"", 21, 7.6),
            family = ""IBM Plex Sans Condensed Medium"", 
            hjust = 0, color = ""white"") +
  geom_text(aes(label = ""percent of\ntotal struck"", 21, 6.8),
            family = ""IBM Plex Sans Condensed"",
            lineheight = 0.8, hjust = 0, color = ""#43464B"") +
  geom_text(aes(label = ""percent of\ntotal damaged"", 21, 2.2),
            family = ""IBM Plex Sans Condensed"",
            lineheight = 0.8, hjust = 0, color =""#43464B"") +
  # legend terrestrial mammals
  geom_point(aes(21.5, -2.7, size = 35, 
                 stroke = 6),
             shape = 21, color = ""#FFFC31"", fill = ""#3A533D"") +
  geom_segment(aes(x = 21.5, y = -2.7, xend = 21.5, yend = -1.2),
               color = ""#3A533D"", size = 1) +
  geom_segment(aes(x = 21.5, y = -3.2, xend = 21.5, yend = -4.2),
               color = ""#FFFC31"", size = 1) +
  geom_text(aes(label = ""percent of\ntotal struck"", 21, -0.4),
            family = ""IBM Plex Sans Condensed"",
            lineheight = 0.8, hjust = 0, color = ""#43464B"") +
  geom_text(aes(label = ""percent of\ntotal damaged"", 21, -5),
            lineheight = 0.8, family = ""IBM Plex Sans Condensed"",
            hjust = 0, color = ""#43464B"") +
  geom_text(aes(label = ""Terrestrial\nMammals"", 21, -6.2),
            family = ""IBM Plex Sans Condensed Medium"",
            lineheight = 0.8, hjust = 0, color = ""white"") +
  
  labs(
    title = ""Aircraft components most commonly reported as struck and damaged by birds and terrestrial mammals"",
    subtitle = ""The aircraft components most commonly reported as struck by birds from 1990  2017 were the nose/radome, windshield,\nwing/rotor, engine, and fuselage. Aircraft engines were the component most frequently reported as being damaged by bird\nstrikes (27 percent of all damaged components). Aircraft components most commonly reported as struck by terrestrial\nmammals were the landing gear, 'other', propeller, and wing/rotor. Aircraft components most commonly reported as\ndamaged were the landing gear, wing/rotor, propeller, and 'other' (Wildlife Strikes to Civil Aircraft in the United States,\n19902017)."",
    caption = ""Source: FAA National Wildlife Strike Database | Graphic: Georgios Karamanis""
  ) +

  scale_size_area(max_size = 8) +
  coord_fixed(xlim = c(-5, 25), ylim =  c(-10, 10)) +
  theme_void() +
  theme(
    legend.position = ""none"",
    plot.margin = margin(20, 20, 20, 20),
    plot.title  = element_text(family = ""IBM Plex Sans Bold"", color = ""white""),
    plot.subtitle = element_text(family = ""IBM Plex Serif"", color = ""white""),
    plot.caption  = element_text(family = ""IBM Plex Sans""),
    plot.background = element_rect(color = ""skyblue3"", fill = ""skyblue3"")
  ) +
  ggsave(here(""week-30"", ""img"", paste0(""wildlife"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         width = 10, height = 8.32)
","Other-30"
"653",157,"https://github.com/gkaramanis/tidytuesday/tree/master/week-22","gkaramanis","tidytuesday","week-22/wine.R","library(tidyverse)
library(ggimage)

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

food <- tribble(
   ~type, ~example,
  ""meat &\ncured meat"",    ""salami"",
  ""pasta &\npizza"",     ""pasta"",
  ""pasta &\npizza"",     ""spaghetti"",
  ""pasta &\npizza"",     ""lasagna"",
  ""pasta &\npizza"",     ""ravioli"",
  ""vegetables &\nmushrooms"",  ""mushroom"",
  ""meat &\ncured meat"",      ""meat"",
  ""meat &\ncured meat"",      ""sausage"",
  ""meat &\ncured meat"",      ""beef"",
  ""meat &\ncured meat"",      ""hamburger"",
  ""meat &\ncured meat"",      ""pork"",
  ""meat &\ncured meat"",      ""veal"",
  ""meat &\ncured meat"",      ""lamb"",
  ""meat &\ncured meat"",      ""ribs"",
  ""dessert"",  ""dessert"",
  ""seafood"",   ""seafood"",
  ""seafood"",   ""scallops"",
  ""seafood"",   ""tuna"",
  ""seafood"",   ""tilapia"",
  ""seafood"",      ""fish"",
  ""seafood"",      ""salmon"",
  ""seafood"",    ""shrimp"",
  ""seafood"",     ""clams"",
  ""seafood"",    ""oyster"",
  ""seafood"",   ""lobster"",
  ""cheese"",    ""cheese"",
  ""cheese"",    ""mozzarella"",
  ""cheese"",    ""pecorino"",
  ""poultry"",   ""poultry"",
  ""poultry"",   ""chicken"",
  ""poultry"",   ""duck"",
  ""vegetables &\nmushrooms"", ""vegetable"",
  ""vegetables &\nmushrooms"", ""tomato"",
  ""vegetables &\nmushrooms"", ""eggplant"",
  ""vegetables &\nmushrooms"",     ""salad"",
  ""pasta &\npizza"", ""pizza"" 
  )

pairings <- wine_ratings %>%
  # remove X1 and keep unique entries
  select(-c(""X1"")) %>% 
  distinct() %>% 
  # keep the two variables
  select(""variety"", ""description"") %>% 
  # rename Corvina, Rondinella, Molinara to Valpolicella
  mutate(variety = str_replace_all(variety, ""Corvina, Rondinella, Molinara"", ""Valpolicella"")) %>% 
  # keep reviews that contain ""pair* with"" 
  filter(str_detect(description, ""pair\\w*\\b with"")) %>%
  # keep the varieties with more than X reviews
  group_by(variety) %>% 
  mutate(n = n()) %>%
  filter(n > 48) %>%
  # extract text after ""pair* with"" and to the end of the sentence
  mutate(pairWith = str_extract(description,
                                ""pair\\w*\\b with(?:(?=[\\s.?!])[^.?!]*(?:[.?!].*)?)\\."")) %>% 
  # find matches from the food table
  mutate(found = str_extract_all(pairWith,
                                 paste(food$example,collapse=""|""))) %>% 
  # match food
  unnest() %>% 
  left_join(., food, by = c(""found"" = ""example"")) %>%
  # number variety groups
  group_by(variety) %>% 
  mutate(varietyNr = group_indices()*2-0.5) %>% 
  ungroup() %>% 
  # number type groups
  group_by(type) %>% 
  mutate(typeNr = group_indices()*1.5-0.5) %>% 
  ungroup() %>% 
  # count pairings per variety and type
  group_by(varietyNr, typeNr) %>% 
  mutate(ntype = n()) %>% 
  ungroup() %>% 
  # needed for images
  rowwise() %>%
  # images and colors
  mutate(foodImg = paste(""./week-22/img/"", substr(type, 1, 4), "".png"", sep = """"),
         bottleColor = ifelse(variety == ""Chardonnay"" | variety == ""White Blend"", ""#D4C52D"", ""#5e1224""),
         nudge = runif(1)/5 - 0.1)

# plot pairings
ggplot() +
  # down
  geom_segment(data = pairings,
             aes(x = varietyNr + nudge, y = 10,
                 xend = typeNr + nudge, yend = 1,
                 colour = bottleColor),
             size = pairings$ntype/30,
             lineend = ""butt"",
             alpha = 0.2) +
  # bottle icons
  geom_image(aes(image = ""./week-22/img/bottle.png"",
  # color = ""#D4C52D"",
                 x = c(1.5, 9.5),
                 y = 11.3)) +
  geom_image(aes(image = ""./week-22/img/bottle.png"",
  # color = ""#5e1224"",
                 x = c(3.5, 5.5, 7.5),
                 y = 11.3)) +                
  # food icons
  geom_image(aes(image = unique(pairings$foodImg),
                 x = unique(pairings$typeNr),
                 y = 0.3), size = 0.05) +
  # variety and food names
  geom_text(aes(label = unique(pairings$variety),
                x = unique(pairings$varietyNr),
                y = 12.8),
            size = 1.8,
            family = ""IBM Plex Serif"") +
  geom_text(aes(label = unique(pairings$type),
                x = unique(pairings$typeNr),
                y = -0.4),
            size = 1.4,
            vjust = 1,
            family = ""IBM Plex Serif"") +

  expand_limits(y = c(1, 13)) +
  scale_color_identity() +

  labs(title = ""Wine and food pairings for the top 5 varieties"",
       subtitle = ""as recommended by WineEnthusiast reviewers"",
       caption = ""Source: kaggle.com | Graphic: Georgios Karamanis"") +
  
  theme_void() +
  theme(
    legend.position =  """",
    plot.background = element_rect(fill = ""#F0EFF1"", colour = ""#F0EFF1""),
    plot.margin = unit(c(1, 1, 1, 1), ""cm""),
    text = element_text(family = ""IBM Plex Serif"", size = 8),
    plot.title = element_text(face = ""bold"", vjust = 8),
    plot.subtitle = element_text(vjust = 9),
    plot.caption = element_text(size = 4, vjust = -3)
  )

ggsave(""./week-22/wine.png"", height = 5, width = 4, dpi = 600)

# write.csv(pairings$pairWith, file = ""winePairings.csv"")
","Other-22"
"654",158,"https://github.com/gkaramanis/tidytuesday/tree/master/week-22","gkaramanis","tidytuesday","week-22/wine2.R","library(tidyverse)
library(tidytext)
library(ggrepel)

wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

wineWords <- wine_ratings %>% 
  select(-c(""X1"")) %>% 
  distinct() %>% 
  # group_by(taster_name) %>% 
  # filter(!is.na(taster_name)) %>% 
  select(taster_name, description) %>%
  unnest_tokens(word, description) %>%    
  anti_join(stop_words)

wineWords %>%
  filter(!is.na(taster_name)) %>% 
  group_by(taster_name, word) %>%
  summarise(n = n()) %>% 
  mutate(freq = n / sum(n)) %>% 
  arrange(desc(freq)) %>%
  group_by(taster_name) %>%
  slice(seq_len(3)) %>% 
  ggplot() +
  geom_text_repel(aes(label = word, color = word,
                 x = freq, y = taster_name)) +
  theme_minimal() +
  theme(
    text = element_text(family = ""IBM Plex Sans"", size = 8)
  )

ggsave(""./week-22/wine2.png"")  


","Other-22"
"655",159,"https://github.com/gkaramanis/tidytuesday/tree/master/week-26","gkaramanis","tidytuesday","week-26/ufo.R","library(here)
library(tidyverse)
library(ggimage)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

city_count <- ufo_sightings %>%
  mutate(every_year = str_sub(date_time, -10, -7)) %>% 
  group_by(city_area) %>% 
  summarise(total = n(), first_encounter = min(every_year)) %>% 
  top_n(n = 10, total) %>% 
  mutate(year = as.numeric(first_encounter),
         city_area = str_to_title(city_area),
         city_area = fct_reorder(city_area, year))
  

ggplot(city_count) +
  geom_segment(aes(x = city_area, y = year, 
                   xend = city_area, yend = 1970,
                   size = total),
               color = ""orange1"") +
  # icon by https://www.iconfinder.com/korawan_m
  geom_image(aes(image = here(""week-26"", ""img"", ""saucer.png""),
                 x = city_area, y = year - 0.8),
             asp = 1.4, size = 0.05, color = ""purple3"") +
  geom_text(aes(label = year,
                x = city_area, y = year - 3),
            color = ""grey40"", family = ""IBM Plex Mono Bold"",
            size = 5, alpha = 0.6) +
  geom_text(aes(label = total,
                x = city_area, y = 1967.5),
            nudge_x = 0.37, size = 8, alpha = 0.7,
            color = ""orange1"", family = ""IBM Plex Mono Bold"") +
  # ""legend""
  geom_text(aes(label = ""year of first reported\nencounter at the city"",
                x = 3, y = 1941),
            color = ""grey60"", family = ""IBM Plex Mono Bold"",
            size = 5, alpha = 0.9, hjust = 0) +
  geom_segment(aes(x = 2.8, y = 1941,
                   xend = 1.4, yend = 1941),
               color = ""grey60"", alpha = 0.5) +
  geom_text(aes(label = ""total number of encounters\nduring all years"",
                x = 8, y = 1950),
            color = ""orange1"", family = ""IBM Plex Mono Bold"",
            size = 5, alpha = 0.2, hjust = 0) +
  geom_segment(aes(x = 7.8, y = 1950,
                   xend = 6.4, yend = 1955),
               color = ""orange1"", alpha = 0.2) +
  scale_y_reverse(position = ""right"") +
  coord_cartesian(ylim = c(1940, 1967)) +
  geom_text(aes(label = ""Top 10 cities in the world with\nthe most reported UFO encounters"",
                x = 11, y = 1941),
            family = ""IBM Plex Sans Bold"",
            size = 8, hjust = 1) +
  labs(
    # title = ""Top 10 cities\nin the world with\nthe most reported\nUFO encounters"",
    caption = ""Source: NUFORC | Graphics: Georgios Karamanis"") +
  theme_minimal() +
  theme(
    plot.background = element_rect(fill = ""#e0e7f3"",
                                   colour = ""#e0e7f3""),
    panel.grid = element_blank(),
    legend.position = """",
    text = element_text(family = ""IBM Plex Sans Bold"",
                              size = 14),
    axis.title = element_blank(),
    axis.text.y = element_blank(),
    axis.text.x = element_text(family = ""IBM Plex Sans Bold"", 
                               size = 14, hjust = 0.2, color = ""purple3""),
    plot.margin = unit(c(1, 1, 1, 1), ""cm""),
    # plot.title = element_text(hjust = 1, size = 30,
    #                           margin = margin(0, 0, 0, -100)),
    plot.subtitle = element_text(family = ""IBM Plex Sans""),
    plot.caption = element_text(margin = margin(40, 0, 0, 0),
                                color = ""grey60"")
  ) +

  ggsave(here(""week-26"", ""ufo.png""), width = 13, height = 8)
","Other-26"
"656",160,"https://github.com/gkaramanis/tidytuesday/tree/master/week-26","gkaramanis","tidytuesday","week-26/ufo2.R","library(here)
library(tidyverse)
library(ggimage)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

city_count <- ufo_sightings %>%
  select(city_area, date_time) %>%
  mutate(year = as.numeric(str_sub(date_time, -10, -7)),
         city_area = str_to_title(city_area)) %>%
  add_count(city_area) %>% 
  filter(n>230)

ggplot() +
  geom_tile(data = city_count, aes(x = year, y = city_area,
                height = 0.5, width = 0.3),
            alpha = 0.2, fill = ""orange1"") +
  scale_x_continuous(breaks = seq(1940, 2010, by = 10)) +
  labs(
    title = ""Top 10 cities in the world with\nthe most reported UFO encounters"",
    caption = ""Source: NUFORC | Graphics: Georgios Karamanis""
    ) +
  theme_minimal() +
  theme(
    plot.background = element_rect(fill = ""#e0e7f3"",
                                   colour = ""#e0e7f3""),
    panel.grid = element_blank(),
    legend.position = """",
    axis.title = element_blank(),
    axis.text = element_text(family = ""IBM Plex Mono"", size = 14),
    plot.margin = unit(c(1, 1, 1, 1), ""cm""),
    plot.title = element_text(family = ""IBM Plex Sans"", size = 20),
    plot.subtitle = element_text(family = ""IBM Plex Sans"", size = 14),
    plot.caption = element_text(family = ""IBM Plex Sans"",
                                margin = margin(40, 0, 0, 0),
                                color = ""grey60"", size = 14)
  ) +
  
  ggsave(here(""week-26"", ""ufo2.png""), width = 13, height = 8)

","Other-26"
"657",161,"https://github.com/gkaramanis/tidytuesday/tree/master/week-26","gkaramanis","tidytuesday","week-26/ufo_curve.R","library(here)
library(tidyverse)
# library(tidytext)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

hoax <- ufo_sightings %>%
  # mutate(hoax = ifelse(grepl(""hoax"", tolower(description)), 1, 0),
  #      n = 1:n()) %>% 
  mutate(date_documented = as.Date(date_documented, ""%m/%d/%Y""),
         date_time = as.Date(date_time, ""%m/%d/%Y"")) %>% 
  select(date_time, date_documented) %>%
  mutate(
    ym1 = format(date_time, ""%Y%m""),
    ym2 = format(date_documented, ""%Y%m"")
    ) %>%
    group_by(ym1, ym2) %>%
    summarize(n = n()) %>%
    ungroup() %>%
    mutate(
      ym1 = as.Date(paste(ym1, ""01"", sep = """"), ""%Y%m%d""),
      ym2 = as.Date(paste(ym2, ""01"", sep = """"), ""%Y%m%d"")
    )

ggplot(hoax) +
  geom_curve(aes(x = as.Date(""1990-01-01""), y = ym1, 
                  xend = ym2, yend = as.Date(""1900-01-01""),
                  size = n),
                  curvature = -0.4, color = ""white"",
            alpha = 0.1) +
  scale_size_continuous(range = c(0.1, 0.6)) +        
  scale_x_date(breaks = as.Date(c(""1998-01-01"", ""2002-01-01"",
                                  ""2006-01-01"", ""2010-01-01"",
                                  ""2014-01-01"")),
               date_labels = ""%Y"", expand = c(0,0)) +
  scale_y_date(breaks = as.Date(c(""1920-01-01"", ""1940-01-01"",
                                  ""1960-01-01"", ""1980-01-01"",
                                  ""2000-01-01"", ""2014-01-01"")),
               date_labels = ""%Y"", expand = c(0,0)) +
  labs(
    title = ""UFO sightings reported to NUFORC"",
    subtitle = ""Date the event took place vs date it was documented"",
    caption = ""Source: NUFORC | Graphics: Georgios Karamanis"",
    x = ""Date documented"",
    y = ""Date occurred""
  ) +
  theme_minimal() + 
  theme(
    legend.position = ""None"",
    panel.grid = element_blank(),
    plot.margin = unit(c(1, 1, 0.6, 0.8),""cm""),
    plot.background = element_rect(fill = ""#454c92"", color = ""#454c92""),
    plot.title = element_text(color = ""#9fee98"",
                              family = ""IBM Plex Sans""), 
    plot.subtitle = element_text(color = ""grey90"", 
                                 margin = margin(0, 0, 30, 0)),
    plot.caption = element_text(family = ""IBM Plex Sans ExtraLight"",
                                color = ""grey90"",
                                margin = margin(30, 0, 0, 0)),
    axis.text = element_text(color = ""#9fee98"",
                             family = ""IBM Plex Mono Light""),
    axis.title.x  = element_text(margin = margin(20, 0, 0, 0)),
    axis.title.y  = element_text(margin = margin(0, 20, 0, 0)),
    text = element_text(family = ""IBM Plex Sans"",
                        color = ""white"",
                        size = 12)
  ) +
   
  ggsave(here(""week-26"", ""ufo_curve.png""), height = 9, width = 7)

","Other-26"
"658",162,"https://github.com/gkaramanis/tidytuesday/tree/master/week-26","gkaramanis","tidytuesday","week-26/ufo_curve2.R","library(here)
library(tidyverse)
# library(tidytext)

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

hoax <- ufo_sightings %>%
  # mutate(hoax = ifelse(grepl(""hoax"", tolower(description)), 1, 0),
  #      n = 1:n()) %>% 
  mutate(date_documented = as.Date(date_documented, ""%m/%d/%Y""),
         date_time = as.Date(date_time, ""%m/%d/%Y"")) %>% 
  select(date_time, date_documented) %>%
  mutate(
    ym1 = format(date_time, ""%Y%m""),
    ym2 = format(date_documented, ""%Y%m"")
    ) %>%
    group_by(ym1, ym2) %>%
    summarize(n = n()) %>%
    ungroup() %>%
    mutate(
      ym1 = as.Date(paste(ym1, ""01"", sep = """"), ""%Y%m%d""),
      ym2 = as.Date(paste(ym2, ""01"", sep = """"), ""%Y%m%d"")
    )

ggplot(hoax) +
  geom_curve(aes(x = ym1, y = 5, 
                  xend = ym2, yend = 0,
                  size = n),
                  curvature = 0.1, color = ""white"",
            alpha = 0.1) +
  scale_size_continuous(range = c(0.1, 0.6)) +        
  scale_x_date(breaks = as.Date(c(""1920-01-01"", ""1940-01-01"", ""1960-01-01"",
                                  ""1980-01-01"", ""2000-01-01"", ""2020-01-01"")),
               date_labels = ""%Y"", expand = c(0,0),
               sec.axis = sec_axis(~ .)) +
  labs(
    title = ""UFO sightings reported to NUFORC"",
    subtitle = ""Date the event took place vs date it was documented"",
    caption = ""Source: NUFORC | Graphics: Georgios Karamanis"",
    x = ""Date documented"",
    y = ""Date occurred""
  ) +
  theme_minimal() + 
  theme(
    legend.position = ""None"",
    panel.grid = element_blank(),
    plot.margin = unit(c(1, 1, 0.6, 0.8),""cm""),
    plot.background = element_rect(fill = ""#454c92"", color = ""#454c92""),
    plot.title = element_text(color = ""#9fee98"",
                              family = ""IBM Plex Sans""), 
    plot.subtitle = element_text(color = ""grey90"", 
                                 margin = margin(0, 0, 30, 0)),
    plot.caption = element_text(family = ""IBM Plex Sans ExtraLight"",
                                color = ""grey90"",
                                margin = margin(30, 0, 0, 0)),
    axis.text = element_text(color = ""#9fee98"",
                             family = ""IBM Plex Mono Light""),
    axis.title.x  = element_text(margin = margin(20, 0, 0, 0)),
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    text = element_text(family = ""IBM Plex Sans"",
                        color = ""white"",
                        size = 12)
  ) +
   
  ggsave(here(""week-26"", ""ufo_curve2.png""), height = 9, width = 5)

","Other-26"
"659",163,"https://github.com/gkaramanis/tidytuesday/tree/master/week-25","gkaramanis","tidytuesday","week-25/xBirdCounts.R","library(here)
library(tidyverse)
library(gridExtra)

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

# https://www.massaudubon.org/learn/nature-wildlife/birds/commonly-confused-birds
# Hairy Woodpecker & Downy Woodpecker
# Purple Finch & House Finch
# Chipping Sparrow, American Tree Sparrow, & House Sparrow
# Sharp-Shinned Hawk & Cooper's Hawk

confused <- bird_counts %>%
  mutate(
    pair = case_when(
      species == ""Hairy Woodpecker"" | 
        species == ""Downy Woodpecker"" ~ ""A"",
      species == ""American Tree Sparrow"" | 
        species == ""House Sparrow"" ~ ""B"",
      species == ""Sharp-shinned Hawk"" | 
        species == ""Cooper's Hawk"" ~ ""C"",
                     TRUE ~ """")
    ) %>%
  filter(pair != 0)

confusedSplit <- split(confused, f = confused$pair)

p1 <- ggplot(confusedSplit$A, aes(year, how_many_counted, group = species)) +
  geom_area(aes(fill = species), alpha = 0.9) +
  labs(title = ""What did I just see?"",
       subtitle = ""Observations of three pairs of commonly confused bird species\nat the Christmas Bird Counts in Hamilton, Ontario, between 1921 and 2017"") +
  scale_y_continuous(position = ""right"", breaks = c(0, 400)) +
  scale_fill_manual(values = c(""#0072cf"", ""#ffe71a"")) +
  theme(
    plot.background = element_rect(fill = ""grey90"", color = ""grey90""),
    panel.background = element_rect(fill = ""grey90""),
    plot.title = element_text(family = ""IBM Plex Sans Bold""),
    plot.subtitle = element_text(margin = margin(b = 1, unit = ""cm"")),
    legend.background = element_rect(fill = ""grey90""),
    legend.position = ""top"",
    legend.direction = ""vertical"",
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.5, ""line""),
    legend.key = element_rect(fill = ""grey90"", color = ""grey90""),
    legend.title = element_blank(), 
    panel.grid = element_blank(),
    axis.line.x = element_line(size = rel(0.4)),
    axis.title = element_blank(),
    axis.text  = element_text(color = ""grey50""),
    axis.text.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.ticks = element_line(),
    axis.ticks.length = unit(5, ""points""),
    text = element_text(family = ""IBM Plex Sans""),
    panel.spacing = unit(3, ""lines""),
    plot.margin = margin(1, 1, 1, 1, unit = ""cm"")
  )
  
p2 <- ggplot(confusedSplit$B, aes(year, how_many_counted, group = species)) +
  geom_area(aes(fill = species), alpha = 0.9) +
  scale_y_continuous(position = ""right"", breaks = c(0, 4000)) +
  scale_fill_manual(values = c(""#7a2531"", ""#fdd475"")) +
  theme(
    plot.background = element_rect(fill = ""grey90"", color = ""grey90""),
    panel.background = element_rect(fill = ""grey90""),
    legend.background = element_rect(fill = ""grey90""),
    legend.position = ""top"",
    legend.direction = ""vertical"",
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.5, ""line""),
    legend.key = element_rect(fill = ""grey90"", color = ""grey90""),
    legend.title = element_blank(), 
    panel.grid = element_blank(),
    axis.line.x = element_line(size = rel(0.4)),
    axis.title = element_blank(),
    axis.text  = element_text(color = ""grey50""),
    axis.text.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.ticks = element_line(),
    axis.ticks.length = unit(5, ""points""),
    text = element_text(family = ""IBM Plex Sans""),
    panel.spacing = unit(3, ""lines""),
    plot.margin = margin(1, 1, 1, 1, unit = ""cm"")
  )

p3 <- ggplot(confusedSplit$C, aes(year, how_many_counted, group = species)) +
  geom_area(aes(fill = species), alpha = 0.9) +
  labs(caption = ""Source: Bird Studies Canada | Graphic: Georgios Karamanis"") +
  scale_y_continuous(position = ""right"", breaks = c(0, 30)) +
  scale_fill_manual(values = c(""#485dc5"", ""#e99fdb"")) +
  theme(
    plot.background = element_rect(fill = ""grey90"", color = ""grey90""),
    panel.background = element_rect(fill = ""grey90""),
    plot.caption = element_text(margin = margin(t = 1, unit = ""cm"")),
    legend.background = element_rect(fill = ""grey90""),
    legend.position = ""top"",
    legend.direction = ""vertical"",
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.5, ""line""),
    legend.key = element_rect(fill = ""grey90"", color = ""grey90""),
    legend.title = element_blank(), 
    panel.grid = element_blank(),
    axis.line.x = element_line(size = rel(0.4)),
    axis.title = element_blank(),
    axis.text  = element_text(color = ""grey50""),
    axis.ticks.y = element_blank(),
    axis.ticks = element_line(),
    axis.ticks.length = unit(5, ""points""),
    text = element_text(family = ""IBM Plex Sans""),
    plot.margin = margin(1, 1, 1, 1, unit = ""cm"")
  )

# grid.arrange(p1, p2, p3, heights = c(3, 2, 3))

g <- arrangeGrob(p1, p2, p3, heights = c(4.5, 3, 3.5))

ggsave(here(""week-25"", ""xBirdCounts.png""), g, height = 11, width = 7, dpi = 300)

","Other-25"
"660",164,"https://github.com/gkaramanis/tidytuesday/tree/master/week-31","gkaramanis","tidytuesday","week-31/videogames.R","library(tidyverse)
library(here)
library(ggrepel)
library(ggforce)

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

overpriced_games <- video_games %>%
  # filter titles over $150 
  filter(price > 150) %>%
  # mark games
  mutate(
    type = case_when(
      grepl(""^ADR"", game) ~ ""game"",
      grepl(""^Welcome"", game) ~ ""game"",
      grepl(""^Tactics"", game) ~ ""game"",
      grepl(""^CrisisAction"", game) ~ ""game"",
      grepl(""^Bible"", game) ~ ""game"",
      grepl(""^Silhouette"", game) ~ ""game"",
      grepl(""^????"", game) ~ ""game"",
      T ~ ""not_game""
      ),
    # rename games
    game = case_when(
      grepl(""????"", game) ~ ""Safe Education"",
      T ~ game
    ),
    # labels
    game_label = case_when(
      grepl(""^ADR"", game) ~ ""The most expensive game on Steam"",
      grepl(""^Welcome"", game) ~ ""Deluxe Edition is $7.99"",
      grepl(""^Tactics 2"", game) ~ ""Current price is $7.99"",
      grepl(""^Tactics: Bludgeons"", game) ~ ""Currently discounted to $16.99"",
      # grepl(""^CrisisAction"", game) ~ ""No information found"",
      grepl(""^Bible"", game) ~ ""Frequently discounted to $19.99"",
      grepl(""^Silhouette"", game) ~ ""Intentionally raised price to halt sales"",
      # grepl(""^Safe Education"", game) ~ ""Translated from chinese"",
      T ~ """"
    ),
    # not used in the plot:
    game_description = case_when(
      grepl(""^ADR"", game) ~ ""\""Game is designed to give additional\nsupport and an interactive training platform\nfor people studying for their\nADR license.\"""",
      grepl(""^Welcome"", game) ~ ""Welcome to Boon Hill Deluxe Edition is\n$7.99"",
      grepl(""^Tactics 2"", game) ~ ""\""For russians, the entrance to this page\nis $ 1,000,000,000,000 for 1 second.\"""",
      grepl(""^Tactics: Bludgeons"", game) ~ ""By the developer of Tactics 2. \""This\ngame was updated to Tactics 2: War\"""",
      grepl(""^CrisisAction"", game) ~ ""It seems that the game has had\nthe same price"",
      grepl(""^Bible"", game) ~ ""\""Bible Test is a test for a real\nconnoisseur of this invaluable book.\"""",
      grepl(""^Silhouette"", game) ~ ""The reason the game is so expensive\nright now is because I'm trying to put a\nhalt to sales."",
      grepl(""^Safe Education"", game) ~ ""description"",
      T ~ """"
    )
    ) %>%
  arrange(., desc(price))

# reorder games, descending price
overpriced_games$game <- reorder(overpriced_games$game, overpriced_games$price)

# function to wrap subtitle
wrapper <- function(x, ...) 
{
  paste(strwrap(x, ...), collapse = ""\n"")
}

# plot
ggplot(overpriced_games) +
  # bars
  geom_col(aes(game, price, fill = type), width = 0.25) +
  # game title
  geom_text(aes(label = game, x = game, y = 0),
            nudge_x = 0.4, hjust = 0,
            family = ""IBM Plex Sans Condensed"",
            size = 2, color = ""#cecccf"") +
  # price
  geom_text(aes(label = price, x = game, y = price),
            nudge_x = 0.4, hjust = 1,
            family = ""IBM Plex Sans Condensed"",
            size = 2, color = ""#cecccf"") +
  # annotations
   geom_label_repel(data = subset(overpriced_games, overpriced_games$game_label != """"),  
                     aes(game, price, label = game_label),
                   hjust = 0, force = 10, max.iter = 4000,
                   label.r = 0, ylim = c(320, 600), xlim = c(0, 17),
                   fill = ""#627536"", color = ""#A4CF04"", segment.color = ""#cecccf"", segment.size = 0.1,
                   size = 2.5, family = ""IBM Plex Sans Condensed"") +
  
  # Didn't use it, looks really nice but too much overlapping :(              
  # geom_mark_circle(aes(game, price, filter = type == ""game"",
  #                      label = game_label, description = game_description),
  #                  size = 0, expand = 0, label.buffer = unit(100, 'mm'),
  #                  label.fontsize = 8, label.family = ""IBM Plex Sans Condensed"") +
  
  labs(
    title = ""The most expensive games on Steam"",
    subtitle = wrapper(""There are many games among the most expensive titles, such as design and developer tools, on Steam. Most of the games are of questionable quality and use temporarily increased prices as a way to appear offering generous \""discounts\"" when their price gets lowered. The prices in the plot are as captured by Lisa Wood via Steam Spy at the end of July, some comments show current ones."", width = 160),
    caption = ""Source: Liza Wood via Steam Spy | Graphic: Georgios Karamanis""
       ) +
  coord_flip(ylim = c(0, 600)) +
  scale_color_manual(values= c(""#8aa349"", ""#2666D3"")) +
  scale_fill_manual(values= c(""#8aa349"", ""#2666D3"")) +
  theme_void() +
  theme(
    legend.position = ""none"",
    plot.background = element_rect(fill = ""#474b52"", color = ""#474b52""),
    plot.margin = margin(20, 20, 20, 20),
    plot.title = element_text(family = ""IBM Plex Sans Condensed Bold"", color = ""#cecccf""),
    plot.subtitle = element_text(family = ""IBM Plex Sans Condensed"", color = ""#cecccf"", size = 8, margin = margin(10, 0, 20, 0)),
    plot.caption = element_text(family = ""IBM Plex Sans"", color = ""#cecccf"", size = 6)
  ) +
  
  ggsave(here(""week-31"", ""img"", paste0(""videogames"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")), width = 8, height = 6, dpi = 320)
  

# https://medium.com/nightingale/the-process-of-familiarity-an-interview-with-nicholas-rougeux-c30f1a1b2f8?source=rss----356ca48206e6---4




","Other-31"
"661",165,"https://github.com/gkaramanis/tidytuesday/tree/master/week-21","gkaramanis","tidytuesday","week-21/waste.R","library(tidyverse)
library(ggimage)
library(janitor)

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
mismanaged_vs_gdp <- clean_names(mismanaged_vs_gdp)

mismanaged_vs_gdp %>%
  rename(percapita_mismanaged_kg_pp_pd = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day) %>% 
  filter(entity != ""World"" & year == 2010) %>% 
  top_n(30, percapita_mismanaged_kg_pp_pd) %>% 
  mutate(bar = map2(0.01, percapita_mismanaged_kg_pp_pd, seq, by = 0.008)) %>% 
  unnest(bar) %>% 
  # Icons made by Freepik from www.flaticon.com 
  mutate(plastic = sample(c(""https://cdn1.iconfinder.com/data/icons/fitness-icon-collection/100/plastic-128.png"",
                            ""https://image.flaticon.com/icons/png/128/81/81940.png"",
                            ""https://image.flaticon.com/icons/png/128/1758/1758890.png"",
                            ""https://image.flaticon.com/icons/png/128/85/85051.png"",
                            ""https://image.flaticon.com/icons/png/128/1718/1718442.png"",
                            ""https://image.flaticon.com/icons/png/128/960/960773.png""),
                          size =  nrow(.), replace = TRUE),
                          angle = runif(nrow(.), 0, 360)) %>% 
  ggplot(aes(fct_rev(factor(entity)), bar*1000, angle = angle)) +
  geom_image(aes(image = plastic), color = ""royalblue1"", size = 0.04) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 330), expand = c(0, 0)) +
  labs(title = ""Top 30 countries with most mismanaged plastic waste"",
       subtitle = ""grams per person per day (2010)"",
       caption = ""Source: Our World In Data | Graphic: Georgios Karamanis"") +
  theme_minimal() +
  theme(
    panel.grid = element_blank(),
    plot.background = element_rect(fill = ""#fcfbfc"", colour = ""#fcfbfc""),
    panel.grid.major.x = element_line(color = ""gray85"", size = 0.3),
    axis.title = element_blank(),
    plot.margin = unit(c(1, 1, 1, 0.6), ""cm""),
    axis.ticks.x = element_line(color = ""#212121"", size = 0.3),
    axis.text.y = element_text(hjust = 1),
    axis.line.x = element_line(size = 0.3, color = ""#212121""),
    text = element_text(family = ""IBM Plex Sans"", size = 8),
    plot.title = element_text(face = ""bold"", vjust = 8),
    plot.subtitle = element_text(vjust = 9),
    plot.caption = element_text(size = 5, vjust = -3)
  )

ggsave(""./week-21/waste.png"", height = 7, width = 5)
","Other-21"
"662",166,"https://github.com/gkaramanis/tidytuesday/tree/master/week-21","gkaramanis","tidytuesday","week-21/waste2.R","library(tidyverse)
library(ggimage)
library(janitor)

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")
mismanaged_vs_gdp <- clean_names(mismanaged_vs_gdp)

mismanaged_vs_gdp %>%
  rename(percapita_mismanaged_kg_pp_pd = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day) %>% 
  filter(entity != ""World"" & year == 2010) %>% 
  top_n(30, percapita_mismanaged_kg_pp_pd) %>% 
  mutate(g_pp_pd = percapita_mismanaged_kg_pp_pd * 1000) %>% 
  mutate(plastic = sample(c(""https://image.flaticon.com/icons/png/128/81/81940.png"",
                            ""https://image.flaticon.com/icons/png/128/1758/1758890.png"",
                            ""https://image.flaticon.com/icons/png/128/960/960773.png""),
                          size =  nrow(.), replace = TRUE)) %>% 
  ggplot(aes(x = gdp_per_capita_ppp_constant_2011_international_rate,
             y = total_population_gapminder,
             size = g_pp_pd)) +
  geom_point() +
  geom_image(aes(image = plastic), color = ""royalblue1"") +
  scale_y_log10()

ggsave(""./week-21/waste2.png"")
","Other-21"
"663",167,"https://github.com/gkaramanis/tidytuesday/blob/master/week-28","gkaramanis","tidytuesday","week-28/deprecated/emperor_curves.R","library(tidyverse)
library(here)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# BCE dates
age_emperors <- emperors %>% 
  mutate(
    birth = case_when(
      index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
      TRUE ~ birth
    ),
    reign_start = case_when(
      index == 1 ~ update(reign_start, year = -year(reign_start)),
      TRUE ~ reign_start
    ),
    age_death = interval(birth, death) / years(1),
    age_reignstart = interval(birth, reign_start) / years(1),
    age_reignend = interval(birth, reign_end) / years(1) 
  ) %>% 
  filter(!is.na(age_death)) %>% 
  mutate(index = row_number())

ggplot(age_emperors) +
  geom_curve(aes(x = reign_start, y = 1,
                 xend = reign_end, yend = 1, color = name),
             curvature = -1) +
  geom_curve(aes(x = birth, y = -1,
                 xend = death, yend = -1, color = name),
             curvature = +1) +
  ylim(-15, 15) +
theme_void() +
  theme(
    legend.position = ""none"",
    plot.background = element_rect(fill = ""#9a1d15"", color = ""#9a1d15"")
  ) +
  
  ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         width = 18, height = 6, dpi = 320)


","Other-28"
"664",168,"https://github.com/gkaramanis/tidytuesday/blob/master/week-28","gkaramanis","tidytuesday","week-28/deprecated/emperor_turtle.R","library(TurtleGraphics)


l = 0.1
p = 10

turtle_init(width = 2, height = 2)
turtle_lwd(3)
turtle_hide()

# left wreath
turtle_setpos(1, 0.6)
turtle_left(90)

for (i in 1:p) {
  turtle_forward(l * 1.5)
  # leaf left
  turtle_left(90)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_right(135)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_left(120)
  # leaf right
  turtle_right(90)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_left(135)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_right(120)
  # 
  turtle_right(15)
  }

# right wreath
turtle_setpos(1, 0.6)
turtle_right(30)
for (i in 1:p) {
  turtle_forward(l * 1.5)
  # leaf left
  turtle_left(90)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_right(135)
  turtle_forward(l)
  turtle_right(45)
  turtle_forward(l)
  turtle_left(120)
  # leaf right
  turtle_right(90)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_left(135)
  turtle_forward(l)
  turtle_left(45)
  turtle_forward(l)
  turtle_right(120)
  # 
  turtle_right(15)
}","Other-28"
"665",169,"https://github.com/gkaramanis/tidytuesday/blob/master/week-28","gkaramanis","tidytuesday","week-28/deprecated/emperor_year.R","library(tidyverse)
library(here)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# BCE dates
age_emperors <- emperors %>% 
  mutate(
    birth = case_when(
      index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
      TRUE ~ birth
    ),
    reign_start = case_when(
      index == 1 ~ update(reign_start, year = -year(reign_start)),
      TRUE ~ reign_start
    ),
    birth = year(birth),
    death = year(death),
    reign_start = year(reign_start),
    reign_end = year(reign_end),
    reign_duration = reign_end - reign_start
  )

ggplot(age_emperors) +
  geom_tile(aes(x = 0, y = index,
                width = reign_duration, height = 0.8))
  
  ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         width = 12, height = 12, dpi = 320)



#9a1d15 60.9 %Sangria (Red)
#b89836 17.8 % Sundance (Brown)
#d3b03c 8.2 % Metallic Gold (Yellow)
#8d2516 5.1 % Falu Red (Red)
#925523 4.5 % Mai Tai (Brown)
#a67831 3.4 % Hot Toddy (Brown)



","Other-28"
"666",170,"https://github.com/gkaramanis/tidytuesday/blob/master/week-28","gkaramanis","tidytuesday","week-28/deprecated/emperors.R","library(tidyverse)
library(here)
library(lubridate)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# BCE dates
age_emperors <- emperors %>% 
  mutate(
    birth = case_when(
			index %in% c(1, 2, 4, 6) ~ update(birth, year = -year(birth)),
			TRUE ~ birth
			),
			reign_start = case_when(
			index == 1 ~ update(reign_start, year = -year(reign_start)),
			TRUE ~ reign_start
			),
    age_death = interval(birth, death) / years(1),
    age_reignstart = interval(birth, reign_start) / years(1),
    age_reignend = interval(birth, reign_end) / years(1) 
			) %>% 
  filter(!is.na(age_death)) %>% 
  mutate(index = row_number())

ggplot(age_emperors) +
  geom_rect(aes(ymin = 0, xmin = index - 0.1, ymax = age_death, xmax = index + 0.1), fill = ""#a67831"") +
  geom_rect(aes(ymin = age_reignstart, xmin = index - 0.25, ymax = age_reignend, xmax = index + 0.25), fill = ""#d3b03c"") +
  # cause of death as icon/label
	# background bands = dynasties
  scale_y_reverse(breaks = c(0, 10, 20, 30, 40, 50, 60, 70)) +
		theme_void() +
		theme(
			plot.background = element_rect(fill = ""#9a1d15"", color = ""#9a1d15""),
			axis.text.y = element_text(color = ""white"")
		) +

ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
        width = 12, height = 12, dpi = 320)
        
        
        
#9a1d15 60.9 %Sangria (Red)
#b89836 17.8 % Sundance (Brown)
#d3b03c 8.2 % Metallic Gold (Yellow)
#8d2516 5.1 % Falu Red (Red)
#925523 4.5 % Mai Tai (Brown)
#a67831 3.4 % Hot Toddy (Brown)



","Other-28"
"667",171,"https://github.com/gkaramanis/tidytuesday/blob/master/week-28","gkaramanis","tidytuesday","week-28/deprecated/emperors.Rmd","---
title: ""Roman Emperors""
author: ""Georgios Karamanis""
date: ""8/13/2019""
output:
  html_document:
    theme: paper
highlight: textmate
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.width = 16, fig.height = 10)
```

```{r libraries, message = FALSE, warning = FALSE}
library(tidyverse)
library(here)
library(lubridate)
```

```{r data}
emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")
```

```{r data-prep}
# BCE dates
emperors %>% 
  mutate(
    birth = case_when(
			index <= 3 ~ update(birth, year = -year(birth)),
			TRUE ~ birth
			)
			)
```



```{r plot}
ggplot(emperors) +
  geom_rect(aes(xmin = birth, ymin = index - 0.25, xmax = death, ymax = index + 0.25), fill = ""grey50"") +
  geom_rect(aes(xmin = reign_start, ymin = index - 0.25, xmax = reign_end, ymax = index + 0.25), fill = ""green"") +
		# cause of death as icon/label
		# background bands = dynasties
		scale_y_reverse() +
		theme_minimal()
```

```{r}
ggsave(here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         dpi = 320)
```

","Other-28"
"668",172,"https://github.com/gkaramanis/tidytuesday/blob/master/week-28","gkaramanis","tidytuesday","week-28/deprecated/laurel.R","library(tidyverse)
library(ggforce)

laurel <- data.frame(
  start = c(0.7, -0.7),
  end = c(pi - 0.1, -pi + 0.1),
  r = c(0.7, 0.7)
  )

leaf <- data.frame(
  x = c(0.6, 0.5, 0.8, 0.5, 0.6, 0.3),
  y = c(1, 1, 0.5, 0, 0, 0.5)
  )

ggplot() +
  geom_arc(data = laurel, aes(x0 = 0, y0 = 0, r = r, start = start, end = end)) +
  geom_bspline_closed(data = leaf, aes(x, y), alpha = 0.5) +
  coord_fixed() +
  
  ggsave(here::here(""week-33"", ""img_plot"", paste0(""emperors"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         dpi = 320)
","Other-28"
"669",173,"https://github.com/gkaramanis/tidytuesday/blob/master/week-28","gkaramanis","tidytuesday","week-28/wwc.R","library(tidyverse)
library(ggimage)
library(here)

wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")

winloss <- wwc_outcomes %>%
  group_by(team) %>%
  mutate(
    game_n = row_number(),
    win_i = -2 + as.integer(factor(win_status))
   )

ggplot(winloss) +
  # grey background bars
  geom_tile(aes(x = 25.5, y = 0), height = 3, 
            width = 50, fill = ""grey97"") +
  geom_tile(aes(x = 25.5, y = 0), height = 1,
            width = 50, fill = ""grey93"") +
  # win/draw/loss boxes
  geom_tile(aes(x = game_n, y = win_i, alpha = win_i,
                fill = as.factor(win_i)), color = ""white"") +
  # country codes and flags
  geom_text(aes(label = team, x = -1, y = 0),
    hjust = 1, size = 3, check_overlap = TRUE,
    family = ""IBM Plex Mono Bold"") +
  geom_image(x = -10, y = 0, asp = 20, size = 0.04,
             aes(image = here(""week-28"", ""flags"", paste0(team, "".png"")))) +
  # Scales
  scale_fill_manual(values = c(""#8c5358"", ""#465675"", ""#27b376""),
    labels = c(""loss"", ""draw"", ""win"")) +
  coord_fixed(xlim = c(-10, 50)) +
  scale_x_continuous(breaks = c(10, 30, 50)) +
  scale_alpha_continuous(range = c(1, 1), guide = F) +
  # Title, subtitle and caption
  labs(
    title = ""Wins, draws and losses for the teams that have taken part in\nthe Women's World Cup from 1991 to 2019"",
    subtitle = ""USA have the most total wins (42), followed by Germany (31) and Norway (23). USA have the\ntwo longest winning streaks (12 and 11) and Norway the third longest (10). Germany hold the\nlongest undefeated streak (15), USA the second and third one (14 and 11)."",
    caption = ""Source: data.world | Graphic: Georgios Karamanis"",
    x = ""Number of matches played in WWC""
  ) +
  facet_wrap(~ team, ncol = 2) +
  theme_minimal() +
  theme(
    plot.background = element_rect(fill = ""grey97"", color = ""white""),
    legend.position = ""top"",
    legend.key.size = unit(0.35, ""line""),
    legend.text = element_text(color = ""grey60"", size = 6,
                               family = ""IBM Plex Mono""),
    legend.title = element_blank(),
    plot.margin = margin(20, 60, 20, 60),
    panel.grid = element_blank(),
    axis.text.x = element_text(color = ""grey70"", size = 7,
                               family = ""IBM Plex Mono""),
    axis.text.y = element_blank(),
    axis.title.x = element_text(color = ""grey60"", size = 7,
                               family = ""IBM Plex Mono""),
    axis.title.y = element_blank(),
    plot.title = element_text(size = 11, family = ""IBM Plex Serif Medium""),
    plot.subtitle = element_text(size = 8, family = ""IBM Plex Sans"",
                                 margin = margin(0, 0, 25, 0)),
    plot.caption = element_text(size = 7, color = ""grey60"",
                                family = ""IBM Plex Mono"",
                                margin = margin(25, 0, 0, 0)),
    strip.text = element_blank()
  ) +
  # http://www.storytellingwithdata.com/blog/2019/6/27/power-pairing-color-words
  ggsave(here(""week-28"", ""wwc.png""),
         width = 6, height = 6, dpi = 300)
","Other-28"
"670",174,"https://github.com/gkaramanis/tidytuesday/tree/master/week-23","gkaramanis","tidytuesday","week-23/ramen.R","library(tidyverse)

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")
# dupes <- ramen_ratings %>% group_by(brand, variety, style, country, stars) %>% filter(n() > 1)

shio <- ramen_ratings %>%
  filter(country == ""Japan"", str_detect(variety, ""Shio"")) %>% 
  arrange(., stars) %>%
  mutate(n = 1:n())

ggplot() +
  # chopstics
  geom_polygon(aes(x = c(-30, 32, 32, -30), y = c(0.02, 0.02, 0.1, 0.3)),
               fill = ""firebrick4"") +
  geom_polygon(aes(x = c(-30, 32, 32, -30), y = c(0.35, 0.12, 0.2, 0.63)),
               fill = ""firebrick4"") +

  # stars
  geom_text(aes(x = -20,  y = c(1.1, 2.1, 3.1, 4.1, 5.1),
                label = c(""1 star"", ""2 stars"", ""3 stars"", ""4 stars"", ""5 stars"")),
            color = ""gray85"", size = 2, hjust = 0,
            family = ""IBM Plex Mono"") +
  geom_segment(aes(x = -20, y = c(0.99, 1.99, 2.99, 3.99, 4.99),
                   xend = c(0.6, 1.6, 3.6, 9.6, 23.6), yend = c(0.99, 1.99, 2.99, 3.99, 4.99)),
               color = ""gray85"", size = 0.3, alpha = 0.5) +
  # 5 starred
  geom_text(data = shio, aes(x = n, y = -0.2,
                label = paste(brand, variety, sep = "" - "")),
            size = 1.8, family = ""IBM Plex Sans"",
            hjust = 0, angle = 90, color = ""gray85"") +
    
  # ramen               
  geom_col(data = shio, aes(n, stars), width = 0.5, fill = ""khaki"") +
  
  scale_y_reverse(limits = c(8, -5), breaks = c(1, 2, 3, 4, 5),
  position = ""right"") +
  
  # title, subtitle and caption
  geom_text(aes(x = 32, y = 7.4, label = ""Ratings of Japanese Instant Shio Ramen""),
            family = ""IBM Plex Serif SemiBold"", hjust = 1,
            color = ""white"", size = 4.5) +
  geom_text(aes(x = 32, y = 7.8, label = ""Source: TheRamenRater.com | Graphic: Georgios Karamanis""),
            family = ""IBM Plex Sans"", hjust = 1,
            color = ""white"", size = 3) +
  
  theme_void() +
  theme(
    panel.background = element_rect(fill = ""#0881A3"", color = ""#0881A3""),
  )

ggsave(""./week-23/ramen.png"", height = 7, width = 5, dpi = 300)


","Other-23"
"671",175,"https://github.com/gkaramanis/tidytuesday/tree/master/week-32","gkaramanis","tidytuesday","week-32/bob_ross.R","library(tidyverse)
library(here)
library(ggimage)
library(cowplot)

bob_ross <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")

# elements to draw
draw_elements <- c(""cloud"", ""mountain"", ""tree"", ""sun"", ""cabin"",
                   ""bushes"", ""lake"", ""river"", ""grass"", ""fence"",
                   ""waterfall"", 
                   ""cactus"", ""palm_trees"", ""lighthouse"", ""sea"", ""beach"",
                   ""moon"", ""boat"", ""rocks"",
                   ""night"")

bob <- bob_ross %>% 
  janitor::clean_names() %>% 
  mutate(n = row_number()) %>% 
  separate(episode, into = c(""season"", ""episode""), sep = ""E"", remove = F) %>% 
  mutate(season = str_extract(season, ""[:digit:]+"")) %>% 
  mutate_at(vars(season, episode), as.integer) %>%
  # remove frame elements and names (columns)
  select(-contains(""FRAME""), -contains(""STEVE""), -contains(""DIANE"")) %>%
  # remove episodes with guests (rows)
  filter(guest != 1) %>%
  # titlecase for episode titles
  mutate(title = str_to_title(title)) %>%
  # gather drawing elements
  gather(""element"", ""exists"", aurora_borealis:winter, na.rm = T) %>%
  filter(exists != 0) %>% 
  select(-exists) %>%
  # sort
  arrange(season, episode) %>%
  # rename elements
  mutate(
    element = case_when(
      element == ""barn"" ~ ""cabin"",
      element == ""building"" ~ ""cabin"",
      element == ""farm"" ~ ""cabin"",
      element == ""clouds"" ~ ""cloud"",
      element == ""mountains"" ~ ""mountain"",
      element == ""hills"" ~ ""mountain"",
      element == ""trees"" ~ ""tree"",
      element == ""conifer"" ~ ""tree"",
      element == ""deciduous"" ~ ""tree"",
      element == ""cumulus"" ~ ""cloud"",
      element == ""cirrus"" ~ ""cloud"",
      element == ""snowy_mountain"" ~ ""mountain"",
      element == ""waves"" ~ ""sea"",
      element == ""ocean"" ~ ""sea"",
      T ~ element
    )
  ) %>% 
  # remove duplicates after renaming
  distinct(season, episode, title, element, n) %>% 
	# images
	mutate(img_element = paste0(element, "".png"")) %>%
  # keep elements that can be drawn
  filter(element %in% draw_elements)

# legend
label1 <- ""cloud (cirrus, cumulus), moon, night, palm tree, sun, mountain (hills), cactus, lighthouse, rocks, tree (deciduous, conifer), beach, boat, cabin (barn, building, farm), sea (ocean, waves), bushes, fence, grass, waterfall, lake, river""
#label2 <- ""moon, cactus, palm tree, lighthouse, rocks, beach, boat, sea (ocean, waves)""
# wrapper
wrapper <- function(x, ...){paste(strwrap(x, ...), collapse = ""\n"")}
# plot legend
p1 <- ggplot() +
  geom_image(aes(image = here(""week-32"", ""elements"", ""legendx4.png""), 0, 0), size = 1) +
  geom_text(aes(label = wrapper(label1, width = 50), -9.5, -6),
            hjust = 0, vjust = 1,
            family = ""Silkscreen"", size = 4.5) +
  #geom_text(aes(label = wrapper(label2, width = 25), 0.5, -6),
  #          hjust = 0, vjust = 1,
  #          family = ""Silkscreen"", size = 4) +
  coord_fixed(xlim = c(-10, 10), ylim =  c(-10, 10)) +
  labs(
    # title = ""Bob Ross:\npainting by the elements"",
    subtitle = wrapper(""Graphic representations of Bob Ross' paintings with elements identified in them by Walt Hickey (FiveThirtyEight). Each element represents one or more occurrences in the painting. Only the elements in the legend below are drawn. To the right there are 25 random paintings that Bob painted in 'The Joy of Painting', with the season and episode number."", width = 45),
    caption = ""source: FiveThirtyEight | plot: Georgios Karamanis"") +
  theme_void(base_family = ""Silkscreen"") +
	theme(
		plot.title = element_text(size = 20, family = ""Silkscreen Bold""),
		plot.subtitle = element_text(size = 16),
		plot.caption = element_text(margin = margin(20, 0, 0, 0)),
		plot.margin = margin(0, 20, 20, 20)
	)
	
# paintings
p2 <- bob %>% 
  group_by(n) %>% nest() %>% sample_n(25) %>% unnest() %>%  ungroup() %>% 
  ggplot() +
  geom_image(aes(image = here(""week-32"", ""elements"", img_element), 0, 0), size = 1) +
  geom_text(aes(label = paste(season, episode, sep = ""-""),
                x = -32, y = 32),
            family = ""Silkscreen"", size = 3, hjust = 0) +
  coord_fixed(xlim = c(-32, 32), ylim =  c(-32, 32)) +
  facet_wrap( ~ n, ncol = 5) +
  theme_void() +
  theme(
    strip.text = element_blank(),
    panel.border = element_rect(color = ""grey90"", fill = NA),
    plot.margin = margin(20, 20, 20, 20)
  ) 

# title
title <- ggdraw() + draw_label(""Bob Ross - painting by the elements"",
                               size = 20, fontfamily = ""Silkscreen Bold"")
# p1+p2
p <- plot_grid(p1, p2, rel_widths = c(2, 3))
# title + (p1 + p2)
plot_grid(title, p, ncol=1, rel_heights=c(0.1, 1)) +
  ggsave(here(""week-32"", ""img_plot"", paste0(""bob_ross"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         width = 16, height = 10, dpi = 320)

# all the paintings
bob %>% 
  ggplot() +
  geom_image(aes(image = here(""week-32"", ""elements"", img_element), 0, 0), size = 1) +
  geom_text(aes(label = paste(season, episode, sep = ""-""),
                x = -32, y = 32),
            family = ""Silkscreen"", size = 3, hjust = 0) +
  coord_fixed(xlim = c(-32, 32), ylim =  c(-32, 32)) +
  facet_wrap( ~ n, ncol = 13) +
  theme_void() +
  theme(
    strip.text = element_blank(),
    panel.border = element_rect(color = ""grey90"", fill = NA),
    plot.margin = margin(20, 20, 20, 20)
  ) +
  ggsave(here(""week-32"", ""img_plot"", paste0(""massive"", format(Sys.time(), ""%Y%m%d_%H%M%S""), "".png"")),
         width = 16, height = 10, dpi = 320)","Other-32"
"672",176,"https://github.com/gkaramanis/tidytuesday/tree/master/week-32","gkaramanis","tidytuesday","week-32/bob_ross/app.R","library(shiny)
library(tidyverse)
library(ggimage)

bob_ross <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"")

# elements to draw
draw_elements <- c(""cloud"", ""mountain"", ""tree"", ""sun"", ""cabin"",
                   ""bushes"", ""lake"", ""river"", ""grass"", ""fence"",
                   ""waterfall"", 
                   ""cactus"", ""palm_trees"", ""lighthouse"", ""sea"", ""beach"",
                   ""moon"", ""boat"", ""rocks"",
                   ""night"")

bob <- bob_ross %>% 
    janitor::clean_names() %>%
    rename(SE = episode) %>% 
    mutate(n = row_number()) %>% 
    separate(SE, into = c(""season"", ""episode""), sep = ""E"", remove = FALSE) %>% 
    mutate(season = str_extract(SE, ""[:digit:]+"")) %>% 
    mutate_at(vars(season, episode), as.integer) %>%
    # remove frame elements and names (columns)
    select(-contains(""FRAME""), -contains(""STEVE""), -contains(""DIANE"")) %>%
    # remove episodes with guests (rows)
    filter(guest != 1) %>%
    # titlecase for episode titles
    mutate(title = str_to_title(title)) %>%
    # gather drawing elements
    gather(""element"", ""exists"", aurora_borealis:winter, na.rm = T) %>%
    filter(exists != 0) %>% 
    select(-exists) %>%
    # sort
    arrange(SE) %>%
    mutate(SE = paste0(SE, "" - "", title)) %>% 
    # rename elements
    mutate(
        element = case_when(
            element == ""barn"" ~ ""cabin"",
            element == ""building"" ~ ""cabin"",
            element == ""farm"" ~ ""cabin"",
            element == ""clouds"" ~ ""cloud"",
            element == ""mountains"" ~ ""mountain"",
            element == ""hills"" ~ ""mountain"",
            element == ""trees"" ~ ""tree"",
            element == ""conifer"" ~ ""tree"",
            element == ""deciduous"" ~ ""tree"",
            element == ""cumulus"" ~ ""cloud"",
            element == ""cirrus"" ~ ""cloud"",
            element == ""snowy_mountain"" ~ ""mountain"",
            element == ""waves"" ~ ""sea"",
            element == ""ocean"" ~ ""sea"",
            T ~ element
        )
    ) %>% 
    # remove duplicates after renaming
    distinct(SE, season, episode, title, element, n) %>% 
    # images
    mutate(img_element = paste0(element, "".png"")) %>%
    # keep elements that can be drawn
    filter(element %in% draw_elements)

ui <- fluidPage(
    includeCSS(""styles.css""),
    verticalLayout(
        h3(""Bob Ross - Painting by the elements""),
        plotOutput(""paintingPlot"", height = ""300px""),
        selectInput(""episodeInput"", ""Select episode:"",
                    choices = bob$SE,
                    selected = T,
                    width = ""100%""),
        tableOutput(""elementsTable"")
        )
    )

server <- function(input, output) {
    output$paintingPlot <- renderPlot({
        bob %>% 
            filter(SE == input$episodeInput) %>% 
            ggplot() +
            geom_image(aes(image = (paste0(""www/elements/"", img_element)), 0, 0), size = 1) +
            coord_fixed(xlim = c(-32, 32), ylim =  c(-32, 32)) +
            theme_void()
    }, bg=""transparent"")
    
    output$elementsTable <- renderTable(
        bob %>% 
            filter(SE == input$episodeInput) %>% 
            select(""Elements drawn"" = ""element""),
        
        colnames = T, width = ""100%""
    )
}

shinyApp(ui = ui, server = server)","Other-32"
"673",177,"https://github.com/gkaramanis/tidytuesday/blob/master/week-29","gkaramanis","tidytuesday","week-29/r4ds.R","library(tidyverse)
library(here)

r4ds_members <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")

rfds <- r4ds_members %>%
  mutate(
    yearmonth = format(as.Date(date), ""%Y-%m""),
    day = format(as.Date(date), ""%d""),
    month = format(as.Date(date), ""%m""),
    year = format(as.Date(date), ""%Y""),
    ) %>%
  select(date, yearmonth, day, month, year,
         messages_in_public_channels)

# Top day with most messages
annot <- rfds %>%
  group_by(yearmonth) %>%
  top_n(n = 1)

# Office hours
office_hours <- read_tsv(here(""week-29"", ""office_hours.tsv""))
office_hours <- office_hours %>%
  mutate(
    yearmonth = format(as.Date(date), ""%Y-%m""),
    day = format(as.Date(date), ""%d""),
    month = format(as.Date(date), ""%m""),
    year = format(as.Date(date), ""%Y""),
    ) %>%
    left_join(., rfds)

# Facet labels
m_labels <- c(""01"" = ""January"", ""02"" = ""February"",
              ""03"" = ""March"", ""04"" = ""April"",
              ""05"" = ""May"", ""06"" = ""June"",
              ""07"" = ""July"", ""08"" = ""August"",
              ""09"" = ""September"", ""10"" = ""October"", 
              ""11"" = ""November"", ""12"" = ""December"",
              ""2017"" = ""2017"", ""2018"" = ""2018"", ""2019"" = ""2019"") 

ggplot(rfds) +

  # Office hours
  geom_segment(data = office_hours,
               aes(x = day, xend = day, y = 200, yend = messages_in_public_channels),
               size = 0.3, color = ""#36C5F0"", alpha = 0.25) +
  # geom_point(data = office_hours, aes(day, messages_in_public_channels),
  #           alpha = 0.7, color = ""#36C5F0"", size = 1.2) +
  
  # Messages
  geom_line(aes(day, messages_in_public_channels,
                group = fct_rev(yearmonth)),
            color = ""white"", size = 0.3) +
            
  # Top days
  geom_point(data = annot, aes(day, messages_in_public_channels),
   color = ""#ECB22E"", size = 0.7) +
  # geom_segment(data = annot, aes(x = day, y = messages_in_public_channels, xend = day, yend = 0),
  #  color = ""#ECB22E"", size = 0.7) +
  labs(
    title = ""R for Data Science Online Learning Community: Messages in public channels on Slack"",
    subtitle = ""The yellow points indicate the day of the month with the most messages and the blue lines the office hours"",
    caption = ""source: R4DS Slack | graphic: Georgios Karamanis""
  ) +
  facet_grid(month ~ year, labeller = as_labeller(m_labels)) +
  theme_void() +
  theme(
    plot.background = element_rect(fill = ""#4A154B"",
                                   color = ""#4A154B""),
    plot.margin = margin(20, 30, 20, 30),
    strip.text = element_text(family = ""IBM Plex Sans Light"",
                              color = ""grey90""),
    plot.title = element_text(family = ""IBM Plex Sans Light"",
                              color = ""white"", hjust = 1),
    plot.subtitle = element_text(family = ""IBM Plex Sans Light"",
                                 color = ""white"", hjust = 1,
                                 margin = margin(5, 0, 20, 0)),
    plot.caption = element_text(family = ""IBM Plex Sans Thin"",
                                color = ""grey90"",
                                hjust = 0, margin = margin(25, 0, 0, 0))                      
  ) +
  ggsave(here(""week-29"", ""r4ds.png""),
         width = 9, height = 9, dpi = 300)
  
# Slack palette
# ECB22E yellow
# 36C5F0 blue
# 2EB67D green
# E01E5A red
# 4A154B aubergine
","Other-29"
"674",270,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_11_june_12/worldcup_viewer_data.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 12, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(grid)

worldcup_raw <- 
  read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week11_fifa_audience.csv"") %>% 
  select(-X1) 

worldcup_confed_sum <- worldcup_raw %>% 
  add_count(country) %>% 
  group_by(confederation) %>% 
  summarize_if(is.numeric, sum) %>% 
  ungroup() %>% 
  mutate(total_members = sum(n),
         perc_members = (n / total_members) * 100,
         perc_members = perc_members %>% round(1)) %>% 
  select(-n, -total_members) %>% 
  gather(key = share_var, value = value, -confederation)

# re-order variables as factors for the plot
worldcup_confed_sum <- worldcup_confed_sum %>% 
  mutate(share_var = share_var %>% as_factor(),
         share_var = share_var %>% fct_relevel(""perc_members"", ""population_share"",
                                               ""tv_audience_share"", ""gdp_weighted_share""))
# re-order confederations
worldcup_confed_sum <- worldcup_confed_sum %>% 
  mutate(confederation = confederation %>% as_factor(),
         confederation = confederation %>% fct_relevel(""OFC"", ""CAF"", ""CONMEBOL"", 
                                                       ""CONCACAF"", ""AFC"", ""UEFA""))
# have % label ONLY for UEFA
worldcup_confed_sum <- worldcup_confed_sum %>% 
  mutate(val2 = if_else(confederation == ""UEFA"", paste0(value, ""%""), paste0(value)))

perc_labs <- c(""FIFA MEMBERS"", ""GLOBAL \nPOPULATION"",
               ""WORLD CUP TV \nAUDIENCE"", ""GDP-WEIGHTED \nTV AUDIENCE"")

confed_labs <- c(""OFC (Oceania)"", ""CAF (Africa)"", ""CONMEBOL (S. America)"",
                 ""CONCACAF (N. America)"", ""AFC (Asia)"", ""UEFA (Europe)"")

```

FiveThirtyEight Heatmap:

```{r fig.height=6, fig.width=10}

# Different greens: #00CD00 #008B00 #e5f5e0 #31a354)
p <- 
  ggplot(worldcup_confed_sum,
         aes(share_var, confederation, 
             fill = value)) +
  geom_tile(color = ""lightgrey"") +
  scale_fill_gradient(low = ""#e5f5e0"", high = ""#008B00"") + #  mid = ""#a1d99b""
  geom_text(aes(label = val2, fontface = ""bold""), size = 5) +
  theme_fivethirtyeight() +                   # erases axis.title, text font not the actual one?
  theme(legend.position = ""none"",
        text = element_text(face = ""bold"", color = ""black""),
        axis.title = element_text(),          # to add axis.title back into plot...
        axis.title.x.top = element_text(margin = margin(b = 10)),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(hjust = 0, size = 12),
        plot.margin = rep(grid::unit(0.75, ""cm""), 4)
        ) +
  scale_x_discrete(position = ""top"", expand = c(0, 0),
                   labels = perc_labs) +
  labs(x = ""IN 2010, SHARE OF ..."", y = """") + 
  scale_y_discrete(expand = c(0, 0),
                   labels = confed_labs) +
  annotation_custom(grob = textGrob(
    label = expression(bold(""CONFEDERATION"")), # use bold() inside expression() to get BOLD text
    gp = gpar(cex = 1.0, fontface = ""bold"", hjust = 0)), # also need to specify in fontface as well
                    ymin = 6.66, ymax = 6.66,
                    xmin = -0.23, xmax = -0.23) +     
  annotation_custom(grob = linesGrob(), 
                    xmin = 0.5, xmax = 4.5, ymin = 7, ymax = 7) + # top bar
  annotation_custom(grob = linesGrob(gp = gpar(lwd = 3)),  
                    xmin = -0.64, xmax = 4.5, ymin = 6.5, ymax = 6.5) # x-axis bar

pt <- ggplot_gtable(ggplot_build(p))
pt$layout$clip[pt$layout$name == ""panel""] <- ""off""  # so stuff outside the plot can be shown.

grid.newpage()
grid.draw(pt) # doesn't show anything...?

plot(pt) # use plot instead i guess...

#g <- plot(pt) 

# took a gabillion times to get the positioning of the grobs just right but ... worth it? eh.

#ggsave(file = ""recreated_538_heatmap.png"", plot(pt))

#g_g <- save(pt, file = ""grobby.png"")

```




```{r}

glimpse(worldcup_raw)

glimpse(worldcup_confed_sum)


worldcup_raw %>% arrange(desc(tv_audience_share))


library(rvest)
library(janitor)

url <- ""https://en.wikipedia.org/wiki/2010_FIFA_World_Cup""

wc_2010_raw <- url %>% 
  read_html() %>% 
  html_nodes("".mw-parser-output > div:nth-child(29) > table:nth-child(1)"") %>% 
  html_text()

# .mw-parser-output > div:nth-child(29) > table:nth-child(1)

wc_2010_raw %>% 
  str_remove_all(""\n"") %>% 
  str_remove_all(""\\([^()]+\\)"") %>% # get rid of () and those with contents therein
  str_remove_all(""[A-Z]{3,}"") %>%    # get rid of confed names (All Caps longer than 3)
  str_replace(""North Korea"", ""North_Korea"") %>% 
  str_replace(""South Korea"", ""South_Korea"") %>% 
  str_replace(""United States"", ""United_States"") %>% 
  str_replace(""Ivory Coast"", ""Ivory_Coast"") %>% 
  str_replace(""New Zealand"", ""New_Zealand"") %>% 
  str_replace(""South Africa"", ""South_Africa"") %>% 
  str_trim()
  str_replace(""\\s+"", "" "") %>% 
  str_split("" "")

wc_2010_tab <- ""https://en.wikipedia.org/wiki/2010_FIFA_World_Cup_qualification"" %>% 
  read_html() %>% 
  html_nodes(""table.wikitable:nth-child(13)"") %>% 
  html_table()

wc_2010_tab <- wc_2010_tab %>% flatten_df()

class(wc_2010_tab)
glimpse(wc_2010_tab)


```



```{r}
library(ggrepel)

wc_2010_teams <- wc_2010_tab %>% pull(Team)

worldcup_raw %>% 
  mutate(wc_2010 = if_else(country %in% wc_2010_teams, T, F)) %>% 
  ggplot(aes(x = population_share/100, 
           y = tv_audience_share/100)) +
  geom_point(aes(size = gdp_weighted_share/100, 
                 color = confederation)) +
  scale_x_sqrt(labels = scales::percent) +
  scale_y_sqrt(labels = scales::percent) 



```




```{r}
# from FIFA Big Count (2006):
# % of population that are involved in football (m/f players, referees, officials).
players_perc <- c(2.22, 5.16, 8.53, 7.47, 4.68, 7.59)




worldcup_raw %>% 
  add_count(country) %>% 
  group_by(confederation) %>% 
  summarize_if(is.numeric, sum) %>% 
  ungroup() %>% 
  mutate(total_members = sum(n),
         perc_members = (n / total_members) * 100,
         perc_members = perc_members %>% round(1)) %>% 
  select(-n, -total_members) %>% 
  mutate(players_share = players_perc) %>% 
  ggplot(aes(x = players_perc / 100, 
             y = tv_audience_share / 100)) +
  geom_point(aes(size = population_share)) +
  geom_label(aes(label = confederation), nudge_x = 0.02, nudge_y = 0.02) +
  scale_y_sqrt(labels = scales::percent,
               expand = c(0, 0),
               limits = c(0, 0.5),
               breaks = c(0.1, 0.2, 0.3, 0.4, 0.5)) +
  scale_x_sqrt(labels = scales::percent, 
               expand = c(0, 0),
               limits = c(0, 0.12),
               breaks = c(0.02, 0.04, 0.06, 0.08, 0.1)) +
  annotate(""text"", x = 0.01, y = 0.05, 
           label = ""AFC is clear outlier,\nmost likely due to India & China"") +
  theme_solarized() +
  labs(caption = ""Player data from 2007..."")


```





```{r}
worldcup_raw %>% 
  add_count(country) %>% 
  group_by(confederation) %>% 
  summarize_if(is.numeric, sum) %>% 
  ungroup() %>% 
  mutate(total_members = sum(n),
         perc_members = (n / total_members) * 100,
         perc_members = perc_members %>% round(1)) %>% 
  select(-n, -total_members) %>% 
  mutate(players_share = players_perc) %>% 
  ggplot(aes(x = players_perc / 100, 
             y = (tv_audience_share / 100) / (population_share / 100))) +
  geom_point(aes(size = population_share)) +
  geom_label(aes(label = confederation), nudge_x = 0.01, nudge_y = 0.01)


```



```{r}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(grid)

# Calculate football player share (Registered/Unregistered)

# registered + unregistered, IN 1000s
total_players <- (38287 + 226265) * 1000

afc <- 4040 + 81136

caf <- 3101 + 43199

concacaf <- 6121 + 36988

conmebol <- 3759 + 24018

ofc <- 241 + 301

uefa <- 21025 + 40622

players <- c(afc, caf, concacaf, conmebol, ofc, uefa) * 1000

# 2007 pop

pop_2007 <- c(3870439, 909575, 518613, 374235, 12252, 844677) * 1000


worldcup_confed <- worldcup_raw %>% 
  add_count(country) %>% 
  group_by(confederation) %>% 
  summarize_if(is.numeric, sum) %>% 
  ungroup() %>% 
  mutate(total_members = sum(n),
         perc_members = (n / total_members) * 100,
         perc_members = perc_members %>% round(1)) %>% 
  select(-n, -total_members)

worldcup_confed <- worldcup_confed %>% 
  mutate(players = players,
         total_pop = pop_2007,
         total_players = total_players,
         players_per_pop_1000 = (players / total_pop) * 1000, # player per capita (1000 people)
         players_share = players_per_pop_1000 / sum(players_per_pop_1000) * 100)  %>% 
  mutate(image = ""https://d30y9cdsu7xlg0.cloudfront.net/png/2034-200.png"")

# plot

worldcup_confed %>% 
  ggplot(aes(x = players_share / 100, 
             y = tv_audience_share / 100)) +
  geom_point(aes(size = players_per_pop_1000)) +
  geom_label_repel(aes(label = confederation), nudge_x = 0.02, nudge_y = 0.05) +
  scale_y_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks()
               
               ) +
  scale_x_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks()
               ) +
  theme_solarized() +
  theme(legend.position = ""none"") +
  labs(x = ""Share of Players per Capita \n (1 Player per 1000 people)"",
       y = ""Share of TV Audience"",
       caption = ""Source: FiveThirtyEight.com"")

# players per pop

```

```{r}
worldcup_confed %>% 
  ggplot(aes(x = players_share / 100, 
             y = tv_audience_share / 100)) +
  geom_point(aes(size = players_per_pop_1000)) +
  geom_label(aes(label = confederation), nudge_x = 0.02, nudge_y = 0.05) +
  scale_y_continuous(labels = scales::percent,
               breaks = scales::pretty_breaks()
               
               ) +
  scale_x_continuous(labels = scales::percent,
               breaks = scales::pretty_breaks(),
               expand = c(0, 0)
               ) +
  theme_solarized() +
  theme(legend.position = ""none"") +
  labs(x = ""Share of Players per Capita (1000 people)"",
       y = ""Share of TV Audience"",
       caption = ""Source: FiveThirtyEight.com"")



library(ggimage)
library(extrafont)
library(hrbrthemes)
loadfonts()

# there is a better way to do this with case_when() but whatever it's 3AM.
confed_labs <- c(""AFC (Asia)"", ""CAF (Africa)"", ""CONCACAF (N. America)"",
                 NA, NA , NA)

confed_labs2 <- c(NA, NA , NA,
                  ""CONMEBOL (S. America)"", ""OFC (Oceania)"", ""UEFA (Europe)"")

worldcup_confed %>% 
  ggplot(aes(x = players_share / 100, 
             y = tv_audience_share / 100)) +
  geom_image(aes(image = image), size = 0.05) +
  geom_label_repel(aes(label = confed_labs), 
                   family = ""Roboto Condensed"",
                   nudge_x = 0.02, nudge_y = -0.05,
                   force = 20) +
  geom_label_repel(aes(label = confed_labs2), 
                   family = ""Roboto Condensed"",
                   nudge_x = 0.02, nudge_y = 0.045,
                   force = 20) +
  scale_y_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks(5)
               
               ) +
  scale_x_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks(5),
               limits = c(NA, 0.27)) +
  theme_ipsum() +
  theme(
    panel.grid.minor = element_blank()
  ) +
  labs(
    title = """",
    subtitle = ""Players = Unregistered & Registered, Male & Female"",
    x = ""Share of Players per Capita \n (1 Player per 1000 people)"",
    y = ""Share of TV Audience"",
    caption = ""Source: FiveThirtyEight.com"") +
  annotate(""text"", x = 0.085, y = 0.1, 
           label = ""AFC is the clear outlier,\nmost likely due to India & China"",
           family = ""Roboto Condensed"")

```


```{r fig.height=6, fig.width=8}

worldcup_confed2 <- worldcup_confed %>% 
  mutate(image = ""https://d30y9cdsu7xlg0.cloudfront.net/png/43563-200.png"")

# 1 ""http://extras.mnginteractive.com/live/media/site27/2017/0928/20170928_093500_Soccer%20ball.png""
# 2 ""https://d30y9cdsu7xlg0.cloudfront.net/png/43563-200.png""

worldcup_confed2 %>% 
  ggplot(aes(x = players_share / 100, 
             y = tv_audience_share / 100)) +
  geom_image(aes(image = image), size = 0.06) +
  geom_label_repel(aes(label = confed_labs), 
                   family = ""Trebuchet MS"",
                   nudge_x = 0.02, nudge_y = -0.06,
                   force = 20) +
  geom_label_repel(aes(label = confed_labs2), 
                   family = ""Trebuchet MS"",
                   nudge_x = 0.03, nudge_y = 0.07,
                   force = 20) +
  scale_y_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks(5),
               limits = c(NA, 0.5)
               ) +
  scale_x_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks(5),
               limits = c(NA, 0.27)) +
  theme_minimal() +
  theme(
    text = element_text(family = ""Trebuchet MS"", color = ""black""),
    panel.grid.minor = element_blank(),
    plot.subtitle = element_text(size = 8, family = ""Arial Narrow""),
    axis.text = element_text(size = 12)
  ) +
  labs(
    title = ""Share of Players per Capita & TV Audience (2010 World Cup)\nby Football Confederations"",
    subtitle = ""Players: Total of Unregistered & Registered, Male & Female"",
    x = ""Share of Players per Capita \n (1 Player per 1000 people)"",
    y = ""Share of TV Audience"",
    caption = ""Source: FiveThirtyEight.com & FIFA Big Count (2006)"") +
  annotate(""text"", x = 0.088, y = 0.15, 
           label = ""AFC (Asia) is the clear outlier,\nmost likely due to India & China"",
           family = ""Trebuchet MS"", fontface = ""bold"")

```








```{r fig.height=6, fig.width=8}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(ggimage)
library(extrafont)
# loadfonts()

worldcup_raw <- 
  read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week11_fifa_audience.csv"") %>% 
  select(-X1) 

# Calculate football player share (Registered/Unregistered, Male/Female)
# data from FIFA Big Count (2006)

# registered + unregistered, male + female IN 1000s
total_players <- (38287 + 226265) * 1000

afc <- 4040 + 81136

caf <- 3101 + 43199

concacaf <- 6121 + 36988

conmebol <- 3759 + 24018

ofc <- 241 + 301

uefa <- 21025 + 40622

# as one vector in ordnung
players <- c(afc, caf, concacaf, conmebol, ofc, uefa) * 1000

# 2006 pop, also in 1000s
pop_2006 <- c(3870439, 909575, 518613, 374235, 12252, 844677) * 1000

# new dataframe
worldcup_confed <- worldcup_raw %>% 
  add_count(country) %>% 
  group_by(confederation) %>% 
  summarize_if(is.numeric, sum) %>% 
  ungroup() %>% 
  mutate(players = players,
         total_pop = pop_2006,
         total_players = total_players,
         players_per_pop_1000 = (players / total_pop) * 1000, # player per capita (1000 people)
         players_share = players_per_pop_1000 / sum(players_per_pop_1000) * 100) 

# add soccer ball image
worldcup_confed <- worldcup_confed %>% 
  mutate(image = ""https://d30y9cdsu7xlg0.cloudfront.net/png/43563-200.png"")

# there is a better way to do this with case_when() but whatever it's 3AM.
confed_labs <- c(""AFC (Asia)"", ""CAF (Africa)"", ""CONCACAF (N. America)"",
                 NA, NA , NA)

confed_labs2 <- c(NA, NA , NA,
                  ""CONMEBOL (S. America)"", ""OFC (Oceania)"", ""UEFA (Europe)"")

# PLOT
p <- worldcup_confed %>% 
  ggplot(aes(x = players_share / 100, 
             y = tv_audience_share / 100)) +
  geom_image(aes(image = image), size = 0.06) +
  geom_label_repel(aes(label = confed_labs), 
                   family = ""Trebuchet MS"",
                   nudge_x = 0.02, nudge_y = -0.06,
                   force = 20) +
  geom_label_repel(aes(label = confed_labs2), 
                   family = ""Trebuchet MS"",
                   nudge_x = 0.03, nudge_y = 0.07,
                   force = 20) +
  scale_y_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks(5),
               limits = c(NA, 0.5)
               ) +
  scale_x_sqrt(labels = scales::percent,
               breaks = scales::pretty_breaks(5),
               limits = c(NA, 0.27)) +
  theme_minimal() +
  theme(
    text = element_text(family = ""Trebuchet MS"", color = ""black""),
    panel.grid.minor = element_blank(),
    plot.subtitle = element_text(size = 8, family = ""Arial Narrow""),
    axis.text = element_text(size = 12)
  ) +
  labs(
    title = ""Share of Players per Capita & TV Audience (2010 World Cup)\nby Football Confederations"",
    subtitle = ""Players: Total of Unregistered & Registered, Male & Female"",
    x = ""Share of Players per Capita \n (1 Player per 1000 people)"",
    y = ""Share of TV Audience"",
    caption = ""Source: FiveThirtyEight.com & FIFA Big Count (2006)"") +
  annotate(""text"", x = 0.088, y = 0.15, 
           label = ""AFC (Asia) is the clear outlier,\nmost likely due to India & China"",
           family = ""Trebuchet MS"", fontface = ""bold"")

ggsave(p, filename = ""worldcup_tv_player.png"")

```









","Other-11"
"675",271,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_12_june_19/media_coverage.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""June 19, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Media coverage 


```{r}
library(tidyverse)
library(ggthemes)
library(ggrepel)
library(ggimage)
library(extrafont)
# loadfonts()


# mediacloud_trump.csv (Updated through 10/10/2017): number of headlines that mention Puerto Rico, Texas, and Florida, + headlines that mention those locations along with 'President' or 'Trump'.

headline_trump_raw <- 
  read_csv(
    ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_mediacloud_trump.csv"")

headline_trump_clean <- headline_trump_raw %>% 
  janitor::clean_names() %>% 
  rename_at(vars(contains(""title"")), 
            funs(str_replace_all(., pattern = ""title_"", replacement = """")))

headline_share <- headline_trump_clean %>% 
  mutate(share_pr_trump = puerto_rico_and_trump_or_president / puerto_rico,
         share_fl_trump = florida_and_trump_or_president / florida,
         share_tx_trmp = texas_and_trump_or_president / texas) %>% 
  select(date, contains(""share"")) %>% 
  gather(""location"", ""share_pct"", -date) %>% 
  replace_na(list(share_pct = 0))

headline_share %>% 
  ggplot(aes(x = date, y = share_pct * 100, fill = location)) +
  geom_area(position = ""identity"") +   # position = ""identity"" so NOT STACK!!
  ylim(c(0, 100))





```



























","Other-12"
"676",272,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_18_july_30/dallas_animals.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""July 31, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(readxl)
library(dplyr)
library(tidyr)
library(stringr)
library(forcats)
library(ggplot2)
library(purrr)
```


```{r}
dallas_anim_raw <- read_xlsx(""week18_dallas_animals.xlsx"")

glimpse(dallas_anim_raw)

```






```{r}
dallas_anim_raw %>% 
  ggplot(aes(x = council_district, y = )) +
  geom_col()
```



","Other-18"
"677",273,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_19_august_6/airline_safety.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""August 7, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(readr)

airline_safety_raw <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week19_airline_safety.csv"")


```

","Other-19"
"678",274,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_1_april_3/tidy_tues_april_3.r","library(xlsx)
library(dplyr)
library(stringr)
library(tidyr)
library(ggplot2)
library(scales)


usa_avg_tuition <- read.xlsx(file = ""us_avg_tuition.xlsx"", sheetName = ""Table 5"")

glimpse(usa_avg_tuition)

colnames(usa_avg_tuition)


# regex ugh

colnames(usa_avg_tuition) <- colnames(usa_avg_tuition) %>% 
  str_replace_all(""X"", """") %>% 
  str_replace(""\\."", ""-20"")

# manually change 2007-2008 ...

usa_avg_tuition <- usa_avg_tuition %>% rename(`2007-2008` = `-20.2007.08.`)

# spread/gather to correct format

usa_avg_tuition <- usa_avg_tuition %>% gather(key = ""year"", value = ""tuition"", -State)

usa_avg_tuition <- usa_avg_tuition %>% 
  arrange(year, desc(tuition)) %>% 
  group_by(year) %>% 
  mutate(rank = dense_rank(desc(tuition)))


usa_avg_tuition <- usa_avg_tuition %>% 
  mutate(state = as.character(State))

#usa_avg_tuition %>% 
#  group_by(year) %>% 
#  mutate(top_10 = if_else(State %in% rank[1:10], T, F))

top_states <- usa_avg_tuition %>% 
  filter(year %in% c(""2004-2005"", ""2015-2016"") & rank %in% c(1:10)) %>% 
  pull(state) %>% 
  unique()

top_states

usa_avg_tuition <- usa_avg_tuition %>% 
  mutate(top_tuition = state %in% top_states,
         tuition = round(tuition, digits = 2))

colors = c(
  Vermont = ""#EE2C2C"",          # red
  Pennsylvania = ""lightgreen"",        # dark blue
  Ohio = ""#00441b"",          # green
  `New Hampshire` = ""#4a1486"",        # purple
  `New Jersey` = ""#636363"",        # dark grey
  Massachusetts = ""#fd8d3c"",    # orange
  Maryland = ""#000000"",          # black
  Delaware = ""blue"",
  `South Carolina` = ""brown"",
  Illinois = ""pink"",
  Michigan = ""yellow"",
  Virginia = ""violet""
)



# bump chart theme
library(extrafont)
theme_tuition <-  
  theme(text = element_text(family = ""Arial Narrow"", color = ""#444444"", face = ""bold""),
        plot.title = element_text(size = 24, hjust = 0.5),
        plot.subtitle = element_text(size = 12, hjust = 0.5),
        axis.title = element_text(size = 14),
        axis.title.y = element_text(angle = 0, vjust = 0.5, margin = margin(r = 15)),
        axis.text = element_text(size = 12),
        axis.text.x = element_text(angle = 35,
                                   margin = margin(t = 15, r = 0, b = 0, l = 0)),
        axis.title.x = element_text(margin = margin(t = 20)),
        legend.title = element_blank(),
        legend.position = ""none"")

# bump chart

usa_avg_tuition %>% 
  filter(top_tuition == TRUE) %>% 
  ggplot(aes(year, rank, group = state)) +
  geom_line(aes(color = state), size = 1.6, alpha = 0.75) +
  geom_point(aes(color = state), size = 3, alpha = 1) +
  scale_y_reverse(breaks = 1:10) +         # show only top 10!
  geom_text(data = usa_avg_tuition %>% filter(year == ""2004-2005""),
            aes(label = state, x = 0.5), nudge_x = -0.5, 
            fontface = ""bold"", color = ""black"", size = 4) +
  geom_label(data = usa_avg_tuition %>% filter(year == ""2004-2005""),
            aes(label = paste(""$"", tuition)), nudge_x = -0.7, nudge_y = -0.4, 
            fontface = ""bold"", color = ""black"", size = 2.5) +
  geom_text(data = usa_avg_tuition %>% filter(year == ""2015-2016""),
            aes(label = state, x = 13.5), nudge_x = 0.25, 
            fontface = ""bold"", color = ""black"", size = 4) +
  geom_label(data = usa_avg_tuition %>% filter(year == ""2015-2016""),
             aes(label = paste(""$"", tuition)), nudge_x = 0.9, nudge_y = -0.4, 
             fontface = ""bold"", color = ""black"", size = 2.5) +
  coord_cartesian(ylim = c(1, 10.3), xlim = c(-0.5, 14)) +
  theme_tuition +
  scale_color_manual(values = colors) +
  labs(x = ""Year"", 
       y = ""Rank\n&\nTuition ($)"",
       title = ""College Tuition Rankings in the United States"",
       subtitle = ""2004-2005 to 2015-2016"")



","Other-1"
"679",275,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_1_april_3/tidy_tues_april_3.rmd","---
title: ""tidy_tues_april_3""
author: ""RN7""
date: ""April 3, 2018""
output: 
  md_document: 
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(xlsx)
library(dplyr)
library(stringr)
library(tidyr)
library(ggplot2)
library(scales)

```

# load data, check data

```{r}

usa_avg_tuition <- read.xlsx(file = ""us_avg_tuition.xlsx"", sheetName = ""Table 5"")

glimpse(usa_avg_tuition)

colnames(usa_avg_tuition)

```

# deal with annoying column names ==> regex time!

```{r}

colnames(usa_avg_tuition) <- colnames(usa_avg_tuition) %>% 
  str_replace_all(""X"", """") %>% 
  str_replace(""\\."", ""-20"")

# manually change 2007-2008 ...

usa_avg_tuition <- usa_avg_tuition %>% rename(`2007-2008` = `-20.2007.08.`)

```

# gather to correct format + create ""rank"" column

```{r}

usa_avg_tuition <- usa_avg_tuition %>% gather(key = ""year"", value = ""tuition"", -State)

usa_avg_tuition <- usa_avg_tuition %>% 
  arrange(year, desc(tuition)) %>% 
  group_by(year) %>% 
  mutate(rank = dense_rank(desc(tuition)))


usa_avg_tuition <- usa_avg_tuition %>% 
  mutate(state = as.character(State))

```

`pull()` out the top 10 states for start year and end year ==> assign color to them.

```{r}

top_states <- usa_avg_tuition %>% 
  filter(year %in% c(""2004-2005"", ""2015-2016"") & rank %in% c(1:10)) %>% 
  pull(state) %>% 
  unique()

top_states

usa_avg_tuition <- usa_avg_tuition %>% 
  mutate(top_tuition = state %in% top_states,
         tuition = round(tuition, digits = 2))

colors = c(
  Vermont = ""#EE2C2C"",          # red
  Pennsylvania = ""lightgreen"",        # dark blue
  Ohio = ""#00441b"",          # green
  `New Hampshire` = ""#4a1486"",        # purple
  `New Jersey` = ""#636363"",        # dark grey
  Massachusetts = ""#fd8d3c"",    # orange
  Maryland = ""#000000"",          # black
  Delaware = ""blue"",
  `South Carolina` = ""brown"",
  Illinois = ""pink"",
  Michigan = ""yellow"",
  Virginia = ""violet""
)

```

# bump chart theme

```{r}
library(extrafont)

theme_tuition <-  
  theme(text = element_text(family = ""Arial Narrow"", color = ""#444444"", face = ""bold""),
        plot.title = element_text(size = 24, hjust = 0.5),
        plot.subtitle = element_text(size = 12, hjust = 0.5),
        axis.title = element_text(size = 14),
        axis.title.y = element_text(angle = 0, vjust = 0.5, margin = margin(r = 15)),
        axis.text = element_text(size = 12),
        axis.text.x = element_text(angle = 35, vjust = 1.3, hjust = 1.1,
                                   margin = margin(t = 15, r = 0, b = 0, l = 0)),
        axis.title.x = element_text(margin = margin(t = 8)),
        panel.grid.minor.y = element_blank(),
        legend.title = element_blank(),
        legend.position = ""none"")

```

# the final bump chart

```{r fig.height=7, fig.width=9, fig.align='center'}

usa_avg_tuition %>% 
  filter(top_tuition == TRUE) %>% 
  ggplot(aes(year, rank, group = state)) +
  geom_line(aes(color = state), size = 1.6, alpha = 0.75) +
  geom_point(aes(color = state), size = 3, alpha = 1) +
  scale_y_reverse(breaks = 1:10) +         # show only top 10!
  geom_text(data = usa_avg_tuition %>% filter(year == ""2004-2005""),
            aes(label = state, x = -0.3), 
            fontface = ""bold"", color = ""black"", size = 3.5) +
  geom_label(data = usa_avg_tuition %>% filter(year == ""2004-2005""),
            aes(label = paste(""$"", tuition)), nudge_x = -1.3, nudge_y = -0.4, 
            fontface = ""bold"", color = ""black"", size = 2.5) +
  geom_text(data = usa_avg_tuition %>% filter(year == ""2015-2016""),
            aes(label = state, x = 13.25), 
            fontface = ""bold"", color = ""black"", size = 3.5) +
  geom_label(data = usa_avg_tuition %>% filter(year == ""2015-2016""),
             aes(label = paste(""$"", tuition)), nudge_x = 1.3, nudge_y = -0.4, 
             fontface = ""bold"", color = ""black"", size = 2.5) +
  coord_cartesian(ylim = c(1, 10.3), xlim = c(-0.9, 14)) +
  theme_tuition +
  scale_color_manual(values = colors) +
  labs(x = ""Year"", 
       y = ""Rank\n&\nTuition"",
       title = ""Average College Tuition Rankings in the United States"",
       subtitle = ""By State, 2004-2005 to 2015-2016"",
       caption = ""By: Ryo Nakagawara (@R_by_Ryo) \n Source: https://onlinembapage.com/average-tuition-and-educational-attainment-in-the-united-states/\n#TidyTuesday"")

```



```{r fig.height=12, fig.width=9, fig.align='center'}
# ALL states
library(viridis)

usa_avg_tuition %>% 
  ggplot(aes(year, rank, group = state)) +
  geom_line(aes(color = state), size = 1.6, alpha = 0.75) +
  geom_point(aes(color = state), size = 3, alpha = 1) +
  #scale_color_viridis(option = ""A"") +
  scale_y_reverse(breaks = 1:50) +         # show only top 10!
  geom_text(data = usa_avg_tuition %>% filter(year == ""2004-2005""),
            aes(label = state, x = -0.3), 
            fontface = ""bold"", color = ""black"", size = 2.7) +
  geom_label(data = usa_avg_tuition %>% filter(year == ""2004-2005""),
            aes(label = paste(""$"", tuition)), nudge_x = -1.3, nudge_y = -0.4, 
            fontface = ""bold"", color = ""black"", size = 1.5) +
  geom_text(data = usa_avg_tuition %>% filter(year == ""2015-2016""),
            aes(label = state, x = 13.25), 
            fontface = ""bold"", color = ""black"", size = 2.7) +
  geom_label(data = usa_avg_tuition %>% filter(year == ""2015-2016""),
             aes(label = paste(""$"", tuition)), nudge_x = 1.3, nudge_y = -0.4, 
             fontface = ""bold"", color = ""black"", size = 1.5) +
  coord_cartesian(ylim = c(1, 51), xlim = c(-0.9, 14)) +
  theme_tuition +
  labs(x = ""Year"", 
       y = ""Rank\n&\nTuition"",
       title = ""Average College Tuition Rankings in the United States"",
       subtitle = ""By State, 2004-2005 to 2015-2016"",
       caption = ""By: Ryo Nakagawara (@R_by_Ryo) \n Source: https://onlinembapage.com/average-tuition-and-educational-attainment-in-the-united-states/\n#TidyTuesday"") +
  theme(axis.text.y = element_text(size = 6.5))


```

","Other-1"
"680",276,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_21_august_20/california_fires.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""August 22, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r warning=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggridges)
library(stringr)
library(lubridate)
library(forcats)
library(gganimate)
```




```{r}
calfire_damage_raw <- read_csv(""https://raw.githubusercontent.com/BuzzFeedNews/2018-07-wildfire-trends/master/data/calfire_damage.csv"")

calfire_frap_raw <- read_csv(""https://raw.githubusercontent.com/BuzzFeedNews/2018-07-wildfire-trends/master/data/calfire_frap.csv"")

us_fires_1_raw <- read_csv(""https://raw.githubusercontent.com/BuzzFeedNews/2018-07-wildfire-trends/master/data/us_fires/us_fires_1.csv"")

```






```{r}
calfire_frap_raw %>% 
  rename(year = year_) %>% 
  mutate_at(vars(contains(""date"")), funs(lubridate::dmy)) %>% glimpse()

# base R has a ""month.abb"" vector so you don't have to type out the months yourself
month_names <- month.abb %>% 
  as_data_frame() %>% 
  mutate(num_month = seq(1:12))

calfire_frap_clean <- calfire_frap_raw %>% 
  rename(year = year_) %>% 
  mutate(alarm_month = month(alarm_date)) %>% 
  left_join(month_names, by = c(""alarm_month"" = ""num_month"")) %>% 
  rename(month_abbv = value) %>% 
  glimpse()

calfire_frap_clean <- calfire_frap_clean %>% 
  mutate(month_abbv = as_factor(month_abbv)) %>% 
  mutate(month_abbv = fct_relevel(month_abbv, c(""Jan"", ""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"",
                                                ""Jul"", ""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec""))) 

levels(calfire_frap_clean$month_abbv)

ggplot(calfire_frap_clean) +
  geom_point(aes(y = month_abbv, x = gis_acres)) +
  scale_y_discrete(limits = rev(levels(calfire_frap_clean$month_abbv)))


calfire_frap_clean %>% 
  ggplot(aes(x = gis_acres, y = month_abbv, fill = ..x..)) +
  geom_density_ridges_gradient() +
  scale_fill_gradientn(colors = RColorBrewer::brewer.pal(n = 5, name = ""YlOrRd"")) +
  scale_y_discrete(limits = rev(levels(calfire_frap_clean$month_abbv))) +
  scale_x_continuous(breaks = scales::pretty_breaks(5)) +
  theme_minimal() +
  theme(axis.title = element_blank()) 


calfire_frap_clean %>% 
  ggplot(aes(x = gis_acres, y = month_abbv, fill = gis_acres)) +
  geom_density_ridges_gradient() +
  scale_fill_gradientn(colors = RColorBrewer::brewer.pal(n = 5, name = ""YlOrRd"")) +
  scale_y_discrete(limits = rev(levels(calfire_frap_clean$month_abbv))) +
  scale_x_continuous(breaks = scales::pretty_breaks(5)) +
  theme_minimal() +
  theme(axis.title = element_blank()) 

```


```{r}
calfire_frap_clean %>% 
  filter(month_abbv == ""Feb"") %>% 
  select(month_abbv, gis_acres, year, unit_id) %>% 
  summarize(macres = max(gis_acres))
```




```{r}
calfire_acres_sum <- calfire_frap_clean %>% 
  filter(month_abbv != ""NA"") %>% 
  group_by(month_abbv) %>% 
  mutate(acres = mean(gis_acres, na.rm = TRUE)) %>% 
  select(year, fire_name, cause, gis_acres, acres, alarm_date, alarm_month, month_abbv)

# colorbrewer2.org >>> sequential 9 classes (single hue: reds)
firered <- c('#fff5f0','#fee0d2','#fcbba1','#fc9272','#fb6a4a',
             '#ef3b2c','#cb181d','#a50f15','#67000d')

RColorBrewer::brewer.pal(n = 5, name = ""YlOrRd"") %>% glimpse()

calfire_acres_sum %>% 
  ggplot(aes(x = gis_acres, y = month_abbv, fill = ..x..)) +
  geom_density_ridges_gradient() +
  scale_fill_gradientn(colors = RColorBrewer::brewer.pal(n = 5, name = ""YlOrRd"")) +
  scale_y_discrete(limits = rev(levels(calfire_acres_sum$month_abbv))) +
  scale_x_continuous(breaks = scales::pretty_breaks(5), 
                     labels = scales::comma,
                     limits = c(0, 20000)) +
  theme_minimal() +
  theme(axis.title = element_blank()) 
  

calfire_acres_sum$acres %>% head()

```





```{r}


```

animation: across years? see how months UP or DOWN?






draw a circle of an area of ""shape_area"" around the center long/lat point in us_fires_1_raw for CALIFORNIA?","Other-21"
"681",277,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_24_september_10/catdog.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""September 12, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r warning=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggimage)
```



```{r}
catdog_df <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-09-11/cats_vs_dogs.csv"") %>% select(-X1)
```


```{r}
catdog_df %>% glimpse()
```

- double sided lolipop chart
- cat/dog per capita map >>> cartograms?
","Other-24"
"682",278,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_31_october_30/cran_downloads.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""October 30, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(purrr)
library(ggplot2)
library(ggimage)
```



```{r}
cran_R_df <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-10-30/r_downloads_year.csv"") %>% select(-X1)
```



```{r}
# Set your range of dates
start <- as.Date('2018-10-01')
today <- as.Date('2018-10-07')

all_days <- seq(start, today, by = 'day')

year <- as.POSIXlt(all_days)$year + 1900

# combine dates into a character vector of dates
urls <- paste0('http://cran-logs.rstudio.com/', year, '/', all_days, '.csv.gz')

cran_packages_df <- urls %>%
  map_dfr(read_csv)
```




```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(cranlogs)
library(ggtextures) # devtools::install_github(""clauswilke/ggtextures"")
library(scales)
library(extrafont)
loadfonts()

# top 10 package downloads from 9/29 to 10/28 from 'cranlogs' package
top_10_october <- cran_top_downloads(when = ""last-month"", count = 10)

top_10_october_images <- top_10_october %>% 
  mutate(image = c(
    ""https://raw.githubusercontent.com/tidyverse/tidyverse/master/man/figures/logo.png"",
    ""https://raw.githubusercontent.com/isocpp/logos/master/cpp_logo.png"",
    ""https://raw.githubusercontent.com/r-lib/rlang/master/man/figures/rlang.png"",
    ""https://raw.githubusercontent.com/tidyverse/ggplot2/master/man/figures/logo.png"",
    ""https://upload.wikimedia.org/wikipedia/en/1/1f/Spool_of_string.jpg"",
    ""https://pixfeeds.com/images/16/421149/1200-498885446-digestive-system.jpg"",
    ""https://raw.githubusercontent.com/tidyverse/glue/master/man/figures/logo.png"",
    ""https://raw.githubusercontent.com/tidyverse/dplyr/master/man/figures/logo.png"",
    ""https://i.imgur.com/JYv9NTF.jpg"",
    ""https://raw.githubusercontent.com/tidyverse/stringr/master/man/figures/logo.png"")) %>% 
  mutate(count_lab = comma(count))

# PLOT
ggplot(top_10_october_images, 
       aes(x = reorder(package, -count), y = count, 
           image = image)) +
  geom_textured_col(img_width = unit(0.6, ""null"")) +
  geom_text(aes(label = count_lab, family = ""Roboto Condensed""), 
            size = 3.5,
            nudge_y = 25000) +
  scale_y_continuous(expand = c(0, 0),
                     limits = c(0, 1100000),
                     labels = scales::comma) +
  labs(title = ""Top 10 Most Downloaded R Packages in the Past Month"",
       subtitle = ""from CRAN: Sept. 28, 2018 - Oct. 29, 2018"",
       x = ""Package"", y = ""# of Times Downloaded"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 12),
        panel.grid.major.x = element_blank())
```

```{r}
# isotype plot

ggplot(top_10_october_images, 
       aes(x = reorder(package, -count), y = count, 
           image = image)) +
  geom_isotype_col(img_height = grid::unit(100000, ""native"")) +
  geom_text(aes(label = count_lab, family = ""Roboto Condensed""), 
            size = 3.5,
            nudge_y = 25000) +
  scale_y_continuous(expand = c(0, 0),
                     limits = c(0, 1100000),
                     labels = scales::comma) +
  labs(title = ""Top 10 Most Downloaded R Packages in the Past Month"",
       subtitle = ""from CRAN: Sept. 28, 2018 - Oct. 29, 2018"",
       x = ""Package"", y = ""# of Times Downloaded"") +
  theme_minimal() +
  theme(text = element_text(family = ""Roboto Condensed""),
        axis.text = element_text(size = 10),
        axis.title = element_text(size = 12),
        panel.grid.major.x = element_blank())
```

","Other-31"
"683",279,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_34_november_20/gravy_example.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""November 25, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## https://github.com/tkoomar/tidytuesday/blob/master/work/2018-11-20.Rmd


```{r}
library(tidyverse)
```



```{r}
dat <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-20/thanksgiving_meals.csv"")

dat %>% 
  filter(is.na(dat) %>% rowSums() < 50) %>% 
  select(-id, -pie13, -dessert11, - side15, -contains(""Other"")) %>% 
  mutate(
    ""number of\nkinds of pie"" = select(., contains(""pie"")) %>% {!is.na(.)} %>% rowSums(),
    ""total number\nof sides"" = select(., contains(""side"")) %>% {!is.na(.)} %>% rowSums(), 
    ""number of\n non-pie desserts"" = select(., contains(""dessert"")) %>% {!is.na(.)} %>% rowSums()
  ) %>% 
  mutate(
    family_income = factor(family_income,
                           levels = c(""$0 to $9,999"" , ""$10,000 to $24,999"", ""$25,000 to $49,999"", ""$50,000 to $74,999"", ""$75,000 to $99,999"", ""$100,000 to $124,999"", ""$150,000 to $174,999"", ""$175,000 to $199,999"", ""$200,000 and up"", ""Prefer not to answer"", ""NA""),
                           ordered = T)
  )


```

","Other-34"
"684",280,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_3_april_16/tidy_tuesday_3.r","library(dplyr)
library(tidyr)
library(ggplot2)
library(ggmap)
#library(xlsx)
library(forcats)

#df <- read.xlsx(file = ""../tidy_tuesday/april_16_week_3/global_mortality.xlsx"", 
#                sheetName = ""share-of-deaths-by-cause-2016 ("")

#save(df, file = ""data.Rda"")
#write.csv(df, file = ""../tidy_tuesday/april_16_week_3/df.csv"", row.names = FALSE)

df <- read.csv(file = ""../tidy_tuesday/april_16_week_3/df.csv"")

glimpse(df)

df <- df %>% janitor::clean_names() 

glimpse(df)

# data is in --PERCENTAGES-- for each year.

df %>% 
  group_by(country) %>% 
  arrange(desc(cancers))

df %>% 
  filter(year == 2015, country == ""Kenya"") %>% 
  glimpse()


df_gather <- df %>% 
  gather(key = ""cause_of_death"", value = ""percentages"", -country, -country_code, -year) 

df_gather %>% pull(country_code) %>% unique()
# 194 countries and NA and OWID_WRL (World)

df_gather %>% glimpse()

df_gather %>% 
  mutate(cause_of_death = fct_reorder(cause_of_death, percentages, max)) %>% 
  ggplot(aes(x = cause_of_death, y = percentages, fill = cause_of_death)) +
  geom_col(na.rm = TRUE, position = ""dodge"") +
  ylim(c(0, 100)) + coord_flip()



# year: 1990-2016
df_gather %>% pull(year) %>% unique()


## gganimate
library(gganimate)

anim <- df_gather %>% 
  filter(country == ""Kenya"") %>% 
  ggplot(aes(x = cause_of_death, y = percentages, fill = cause_of_death, frame = year)) +
  geom_point(na.rm = TRUE) +
  ylim(c(0, 80)) + 
  coord_flip() +
  theme(legend.position = ""none"")

gganimate(anim)

## bars

df_gather %>% 
  filter(country == ""Kenya"") %>% 
  group_by(year) %>% 
  arrange(desc(year), desc(percentages))

anim <- df_gather %>% 
  filter(country == ""Kenya"") %>% 
  ggplot(aes(x = reorder(cause_of_death, percentages), y = percentages, fill = cause_of_death, frame = year)) +
  geom_bar(stat = ""identity"") +
  ylim(c(0, 80)) + 
  coord_flip() +
  theme(legend.position = ""none"")

gganimate(anim)




# Separate diseases/disorders ---------------------------------------------

diseases_disorders <- c(""tuberculosis"", ""respiratory_diseases"", ""meningitis"",
                        ""malaria"", ""lower_respiratory_infections"", ""liver_disease"", ""hiv_aids"",
                        ""intestinal_infectious_diseases"", ""kidney_disease"", ""hepatitis"",
                        ""digestive_diseases"", ""diarrheal_diseases"", ""diabetes"", ""cancers"",
                        ""cardiovascular_diseases"")



# combine with UN Regional Names ------------------------------------------
library(wpp2015)
data(""UNlocations"")


## inner_join on country name >>> divide group by region of Africa/Asia/Euro
# region == color 
# median/mean for continent
# size of lolipop point by population rank?
#  boxplots instead?
# by continental region?

UNlocations <- UNlocations %>% select(ends_with(""name""))

df2 <- df_gather %>% 
  inner_join(UNlocations, by = c(""country"" = ""name""))

df2 %>% glimpse()

df_afr <- df2 %>% 
  filter(area_name == ""Africa"") %>% 
  filter(percentages != is.na(percentages)) %>% 
  mutate(avg = mean(percentages)) %>%  
  mutate(over_under = if_else(percentages - avg > 0, TRUE, FALSE))

df_afr %>% glimpse()
  
df_afr_anim <- df_afr %>% 
  filter(reg_name == ""Western Africa"", cause_of_death %in% diseases_disorders) %>% 
  ggplot(aes(x = percentages, y = cause_of_death, fill = country, frame = year)) +
  #geom_segment(aes(x = 0, xend = percentages, 
  #                 y = cause_of_death, yend = cause_of_death)) +
  geom_point(size = 3, shape = 21) +
  xlim(c(0, 70)) +
  scale_fill_brewer(palette = ""Set3"")

gganimate(df_afr_anim)

# facet_wrap regions per continent?!??!




df_jp_anim <- df2 %>% 
  filter(country == ""Japan"",
         cause_of_death %in% diseases_disorders) %>% 
  ggplot(aes(percentages, cause_of_death, fill = cause_of_death, frame = year)) +
  geom_point(size = 3, shape = 21) +
  xlim(c(0, 100)) +
  scale_fill_brewer(palette = ""Set3"") +
  theme_bw() +
  theme(legend.position = ""none"")
  
gganimate(df_jp_anim)


# geom_dumbbell TEST ------------------------------------------------------

library(ggalt)

df2 %>% 
  filter(country == ""Japan"", year %in% c(1990, 2016), cause_of_death %in% diseases_disorders) %>% 
  select(year, cause_of_death, percentages) %>% 
  spread(key = ""year"", value = ""percentages"") %>% 
  ggplot(aes(x = `1990`, xend = `2016`, y = cause_of_death, group = cause_of_death)) +
    geom_dumbbell(aes(x = `1990`, xend = `2016`, y = cause_of_death, group = cause_of_death),
      colour_x = ""green"", colour_xend = ""black"", size = 1.5, dot_guide_colour = TRUE)

health <- read.csv(""https://raw.githubusercontent.com/selva86/datasets/master/health.csv"")

glimpse(health)

df2 %>% 
  filter(reg_name == ""Western Europe"", year %in% c(1990, 2016), cause_of_death %in% diseases_disorders) %>% 
  select(country, year, cause_of_death, percentages) %>% pull(country) %>% unique()
  spread(key = ""year"", value = ""percentages"") %>% 
  ggplot(aes(y = cause_of_death, group = cause_of_death)) +
  geom_segment(aes(x = `1990`, xend = `2016`, yend = cause_of_death)) +
  geom_point(aes(x = `1990`), color = ""green"") +
  geom_point(aes(x = `2016`), color = ""black"") +
  facet_grid(~country)


df2 %>% 
  group_by(reg_name) %>% 
  summarize(n = n_distinct(country)) %>% 
  arrange(desc(n)) %>% print(n = 25)

# western europe, east asia as `country` vars.........


# boxplots gganimate TEST -------------------------------------------------



df_afr_anim <- df2 %>% 
  filter(cause_of_death %in% diseases_disorders,
         reg_name == ""Western Africa"") %>% 
  ggplot(aes(cause_of_death, percentages, frame = year)) +
  geom_boxplot()

library(gganimate)

gganimate(df_afr_anim)


df2 %>% 
  filter(cause_of_death %in% diseases_disorders,
         reg_name == ""Western Africa"",
         year == 1990) %>% 
  ggplot(aes(cause_of_death, percentages)) +
  geom_boxplot()

west_afr <- df2 %>% 
  filter(reg_name == ""Western Africa"")

glimpse(west_afr)

# 15 WestAfr countries
west_afr %>% pull(country) %>% unique() # n_distinct()


nort_am <- df2 %>% 
  filter(reg_name == ""Northern America"")

glimpse(nort_am)

# 16 diseases/disorders  non-mental >>> delete parkinsons

# no accumulation for geom_boxplot....
# do it the old fashioned way with for_loop :O
library(jpeg)


years <- c(1990:1993)

for (i in years) {
  
  #west_afr <- west_afr %>% 
  #  filter(year <= y)
  
  boxplots <- west_afr %>% 
    filter(year == i) %>% 
    ggplot(aes(cause_of_death, percentages)) +
    geom_boxplot()
  
  ggsave(file = paste0(""boxplots/"", i, "".jpg""), plot = boxplots, width = 6, height = 4, units = ""in"", dpi = 300)
  print(paste0(""processings: "", i))
  
}



# nested west africa TEST -------------------------------------------------

west_afr %>% 
  group_by(year) %>% 
  nest() %>% 
  head()

library(purrr)

nested_west_afr <- west_afr %>% 
  group_by(year) %>% 
  nest() %>% 
  mutate(plot = map2(data, year, 
                     ~ggplot(data = .x, 
                             aes(reorder(cause_of_death, percentages), percentages)) + 
                       geom_boxplot() +
                       coord_flip()
                     ))

glimpse(nested_west_afr)

nested_west_afr$plot[20]

map2(paste0(""april_16_week_3/boxplots/"", nested_west_afr$year, "".jpg""), nested_west_afr$plot, ggsave)


# divide by regions -------------------------------------------------------

## divide by cause == smaller groups??
df2 %>% pull(cause_of_death) %>% unique()

df2 %>% 
  filter(year == 1999,
         reg_name == ""Eastern Africa"") %>% 
  mutate(percentages = percentages/100) %>%
  ggplot(aes(reorder(cause_of_death, percentages), percentages)) +
  geom_boxplot(fill = ""white"", color = ""darkred"", outlier.color = ""black"") +
  scale_y_continuous(breaks = scales::pretty_breaks(10), 
                     limits = c(0, 1),
                     labels = scales::percent,
                     expand = c(0.02, 0)) +
  coord_flip() +
  labs(title = ""Median proportion of 'Cause of Death' in the Western Africa region"",
       y = ""Proportion of All Deaths"",
       x = ""Cause of death"") +
  theme_bw() +
  theme(panel.grid.major.y = element_blank())
  

# reorder by highest avg for the region?
# outlier for CONFLICT in 1997, Southern Europe == Albania... from ~0% to 10% of all deaths due to conflict
# outlier for CONFLICT in 1994, Eastern Africa == Rwanda... NA in 1993 to 82.3% of all deaths due to conflict
# outlier for CONFLICT in 1999, Eastern Africa == Eritrea  to 37% of all deaths due to conflict
glimpse(df2)


df2 %>% 
  filter(reg_name == ""Southern Europe"",
         cause_of_death %in% c(""terrorism"", ""conflict""))

df2 %>% 
  filter(reg_name == ""Eastern Africa"",
         cause_of_death %in% c(""terrorism"", ""conflict""),
         country == ""Rwanda"")



# western africa ACTUAL ---------------------------------------------------

library(dplyr)
library(tidyr)
library(ggplot2)
library(xlsx)

## Load file
df <- read.csv(file = ""../tidy_tuesday/april_16_week_3/df.csv"")

## Easily clean names
df <- df %>% janitor::clean_names() 

## Gather cause of deaths under single column 
df_gather <- df %>% 
  gather(key = ""cause_of_death"", value = ""percentages"", -country, -country_code, -year) 

## Use stringr functions to make cleaned names work on plot, leave HIV/AIDS for now...
library(stringr)

df_gather <- df_gather %>% 
  mutate(cause_of_death = stringr::str_replace_all(cause_of_death, ""_"", "" ""),
         cause_of_death = stringr::str_to_title(cause_of_death),
         cause_of_death = case_when(
           cause_of_death == ""Hiv Aids"" ~ ""HIV/AIDS"",
           TRUE ~ cause_of_death
         )) 

## Grab the ""region name"" from UNlocations dataset for easy subsetting! Ex. Eastern Europe, Western Africa, etc.
library(wpp2015)

data(""UNlocations"")

UNlocations <- UNlocations %>% select(ends_with(""name""))

df2 <- df_gather %>% 
  inner_join(UNlocations, by = c(""country"" = ""name""))

## Only look at countries in the ""Western Africa"" region
west_afr <- df2 %>% 
  filter(reg_name == ""Western Africa"")

## Unfortunately geom_boxplot() does not support ""frame"" for gganimate...
## Therefore, create plot for each year with purrr then use ImageMagick or other to compile into gif/video!

library(purrr)

nested_west_afr <- west_afr %>% 
  mutate(percentages = percentages/100) %>%
  group_by(year) %>% 
  nest() %>% 
  mutate(plot = map2(data, year, 
                     ~ggplot(data = .x, aes(reorder(cause_of_death, percentages), percentages)) +
                       geom_boxplot(fill = ""white"", color = ""darkred"", outlier.color = ""black"") +
                       scale_y_continuous(breaks = scales::pretty_breaks(10), 
                                          limits = c(0, 1),
                                          labels = scales::percent,
                                          expand = c(0.02, 0)) +
                       coord_flip() +
                       labs(title = ""Median Proportion of 'Cause of Death' in Countries of the Western Africa Region"",
                            subtitle = ""Years: 1990 - 2016, (1 second = 1 year)"",
                            y = ""Proportion of All Deaths"", x = """",
                            caption = ""By: Ryo Nakagawara (@R_by_Ryo) \n Source: ourworldindata.org\n#TidyTuesday"") +
                       theme_bw() +
                       theme(panel.grid.major.y = element_blank(),
                             text = element_text(family = ""Arial Narrow""),
                             plot.title = element_text(size = 14, hjust = 0.5),
                             plot.subtitle = element_text(size = 10, hjust = 0.5)
                             )
  ))

glimpse(nested_west_afr)

nested_west_afr$plot[1]

## Save each plot (per year) with ggsave!
map2(paste0(""april_16_week_3/boxplots/"", nested_west_afr$year, "".jpg""), nested_west_afr$plot, ggsave)

# Saving 9.49 x 7.98 in image

## Futile attempts at using ImageMagick >>> gave up and just used GifMaker.me   :(

years <- c(1990:2016)

# C:/Users/Ryo Nakagawara/Documents/R_materials/tidy_tuesday/april_16_week_3/boxplots/

for (i in years) {
  
  system(paste0('magick.exe convert C:/Users/""Ryo Nakagawara""/Documents/R_materials/tidy_tuesday/april_16_week_3/boxplots/', i, '.jpg C:/Users/""Ryo Nakagawara""/Documents/R_materials/tidy_tuesday/april_16_week_3/boxplots/', i, '.jpg -geometry +305+72 -composite -pointsize 100 -font Arial -annotate +2000+1120 ', i, 'C:/Users/""Ryo Nakagawara""/Documents/R_materials/tidy_tuesday/april_16_week_3/boxplots_combined/img', i, '.jpg'))
  print(paste0(""processing: "", i))
  
}

## ....
library(magick)

image_convert()




# Eastern Africa ----------------------------------------------------------

## Only look at countries in the ""Eastern Africa"" region
east_afr <- df2 %>% 
  filter(reg_name == ""Eastern Africa"")

## Unfortunately geom_boxplot() does not support ""frame"" for gganimate...
## Therefore, create plot for each year with purrr then use ImageMagick or other to compile into gif/video!

library(purrr)

nested_east_afr <- east_afr %>% 
  mutate(percentages = percentages/100) %>%
  group_by(year) %>% 
  nest() %>% 
  mutate(plot = map2(data, year, 
                     ~ggplot(data = .x, aes(reorder(cause_of_death, percentages), percentages)) +
                       geom_boxplot(fill = ""white"", color = ""darkred"", outlier.color = ""black"") +
                       scale_y_continuous(breaks = scales::pretty_breaks(10), 
                                          limits = c(0, 1),
                                          labels = scales::percent,
                                          expand = c(0.02, 0)) +
                       coord_flip() +
                       labs(title = ""Median Proportion of 'Cause of Death' in Countries of the Eastern Africa Region"",
                            subtitle = paste0(""Year: "", .y), # .y == YEAR!
                            y = ""Proportion of All Deaths"", x = """",
                            caption = ""By: Ryo Nakagawara (@R_by_Ryo) \n Source: ourworldindata.org\n#TidyTuesday"") +
                       theme_bw() +
                       theme(panel.grid.major.y = element_blank(),
                             text = element_text(family = ""Arial Narrow""),
                             plot.title = element_text(size = 14, hjust = 0.5),
                             plot.subtitle = element_text(size = 12, hjust = 0.5)
                       )
  ))

glimpse(nested_east_afr)

nested_east_afr$plot[5]
nested_east_afr$plot[20]
nested_east_afr$plot[13]
nested_east_afr$plot[1]

## Save each plot (per year) with ggsave!
map2(paste0(""april_16_week_3/boxplots/"", nested_east_afr$year, "".jpg""), nested_east_afr$plot, ggsave)

","Other-3"
"685",281,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_5_april_30/tidy_tuesday_april_30.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""May 1, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown



```{r }
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)

acs_survey <- read_csv(""../april_30_week_5/acs2015_county_data.csv"")

glimpse(acs_survey)

# gather on Ethnicity
acs_survey <- acs_survey %>% gather(key = ""ethnicity"", value = ""percentage"", Hispanic:Pacific)



```



```{r}
library(albersusa)

counties_map_data <- counties_composite()

glimpse(counties_map_data@data)


counties_map_data@data <- left_join(counties_map_data@data, acs_survey, by = c(""name"" = ""County""))

anti_counties_map_data <- anti_join(counties_map_data@data, acs_survey, by = c(""name"" = ""County""))
# ~50 counties from Alaska and Virginia dont have matching name == County between 2 data sets.........


# CensusID  == fips >>> fips is chr and has 0 in front of all

glimpse(counties_map_data@data)

plot(counties_map_data, lwd = 0.25)

c_map <- fortify(counties_map_data, region = ""fips"")


```



Aidan Boland's TT Viz :: https://twitter.com/AidoBo/status/991338257391804416


```{r}
library(dplyr)
library(ggplot2)
library(maps)

counties <- map_data(""county"")

acs_survey <- acs_survey %>% mutate(County = tolower(County),
                                    State = tolower(State))

all_county <- counties %>% inner_join(acs_survey, by = c(""subregion"" = ""County"",
                                                         ""region"" = ""State""))


glimpse(all_county)


county_plot <- function(x) {
  
  all_county$x <- all_county[, x]
  
  
  counties %>% 
    ggplot(aes(x = long, y = lat, group = group)) +
    coord_fixed(1.3) +
    geom_polygon(data = all_county, aes(fill = x), color = ""grey30"", size = 0.05) +
    labs(fill = x) +
    scale_fill_distiller(palette = ""Spectral"") +
    theme_void()

}

county_plot(""Unemployment"")
county_plot(""Income"")
county_plot(""Asian"")
county_plot(""Poverty"")


```






","Other-5"
"686",282,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_6_may_7/coffee_chains.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""May 9, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r cars}
library(dplyr)
library(readxl)
# library(ggplot2)
library(sf)
library(extrafont)
loadfonts()

```

## Including Plots

You can also embed plots, for example:

```{r }

starbucks_raw <- read_excel(""../week_6_may_7/week6_coffee_chains.xlsx"", sheet = 1)

glimpse(starbucks_raw)

starbucks_usa <- starbucks_raw %>% 
  janitor::clean_names() %>% 
  select(brand, city, state_province, country, longitude, latitude) %>% 
  filter(country == ""US"") %>% 
  group_by(state_province) %>% 
  summarize(count = n()) %>% 
  ungroup()

class(starbucks_usa)
# spData::us_states %>% pull(NAME) %>% unique() --- Postal abbrv same as ISO
# ggmap::get_map()
# acs::fips.state %>% st_as_sf()
# us_states %>% glimpse()

states_sf <- tigris::states(cb = TRUE) %>% 
  st_as_sf() %>% 
  select(STUSPS, NAME, geometry) %>% 
  filter(!STUSPS %in% c(""VI"", ""MP"", ""GU"", ""PR"", ""AS"")) # filter out territories and Puerto Rico

class(states_sf)

#starbucks_sf <- starbucks_usa %>% left_join(states_sp, by = c(""state_province"" = ""STUSPS"")) %>% glimpse()
# starbucks_usa %>% left_join.sf(states_sp, by = c(""state_province"" = ""STUSPS"")) %>% class()
starbucks_sf <- states_sf %>% left_join(starbucks_usa, by = c(""STUSPS"" = ""state_province""))

class(starbucks_sf) # sf and data.frame

st_crs(starbucks_sf) # 4269, GRS80

plot(starbucks_sf)

# remove Alaska and Hawaii... for now
starbucks_sf2 <- starbucks_sf %>% filter(!NAME %in% c(""Alaska"", ""Hawaii"")) %>% glimpse()
st_crs(starbucks_sf2)

# test
library(ggplot2)
starbucks_sf2 %>% 
  ggplot() +
  geom_sf(aes(fill = count))


```

# normalize by pop.

```{r}
# normalize by population
library(spData)

states_pop <- us_states %>% 
  select(GEOID, NAME, total_pop_15) %>% 
  filter(!NAME == ""District of Columbia"") %>% 
  st_set_geometry(NULL)

states_pop %>% glimpse()
states_pop %>% class()
states_sf %>% class()
st_crs(states_sf)

# merge/join INTO one with sf df or else lose spatial metadata
starbucks_population <- states_sf %>% 
  left_join(states_pop, by = ""NAME"") %>% 
  left_join(starbucks_usa, by = c(""STUSPS"" = ""state_province""))

# NORMALIZE
library(units)

starbucks_sf_norm2 <- starbucks_sf2 %>% 
  mutate(area_km2 = st_area(geometry) %>% 
           set_units(km^2) %>% 
           as.numeric(),
         area_m2 = st_area(geometry) %>% 
           as.numeric(),
         count_norm_m2 = count / area_m2,
         count_norm_km2 = count / area_km2,
         area_sq2 = st_area(geometry) %>% 
           set_units(mi^2) %>% 
           as.numeric(),
         count_norm_sq2 = count / area_sq2) %>% 
  filter(!NAME == ""District of Columbia"")

starbucks_population <- starbucks_sf_norm2 %>% 
  left_join(states_pop, by = ""NAME"") %>% glimpse()


starbucks_population <- starbucks_population %>% 
  mutate(pop_norm = (count / total_pop_15 * 100000) %>% ceiling()) # try per 100,000 people?

library(cartogram)
starb_cartogram <- st_transform(starbucks_population, crs = 2163)

# change to sp
starb_sp <- as(starb_cartogram, ""Spatial"")

starb_cartogram <- cartogram_ncont(starb_sp, weight = ""pop_norm"", k = 1)
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""pop_norm"", k = 10)
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""total_pop_15"", k = 0.5)

# keep as sf
starb_sf <- starb_cartogram
starb_cartogram <- cartogram_ncont(starb_sf, weight = ""pop_norm"", k = 1)
starb_cartogram <- cartogram_ncont(starb_sf, weight = ""pop_norm"", k = 10)
starb_cartogram <- cartogram_ncont(starb_sf, weight = ""total_pop_15"", k = 0.5)

library(tmap)

# Sequential single hue color palette :: http://colorbrewer2.org/#type=sequential&scheme=Greens&n=5
greenpal <- c('#edf8e9','#bae4b3','#74c476','#31a354','#006d2c')

# add ""jenks"" process for better interval categories (California and Texas are still their own categories but best I can do with big outliers)
# legend.reverse for HIGH values on TOP, slight sepia to offset white glare?
# fiddle with margins to fit legend and small title
# plot!
starbucks_cartogram <- tm_shape(starb_cartogram) + 
  tm_borders(""grey10"") +
  tm_fill(title = """", ""pop_norm"", 
          palette = greenpal, 
          #style = ""kmeans"",
          legend.reverse = TRUE) +
  tm_layout(inner.margins = c(.04,.02, .08, .02),
            main.title = ""Number of Starbucks per 100,000 people"",
            title = ""(Source: https://www.kaggle.com/starbucks/store-locations)\nState size by total population"",
            title.position = c(""center"", ""top""), title.size = 0.7,
            fontfamily = ""Garamond"", fontface = ""bold"",
            legend.text.size = 0.85, 
            sepia.intensity = 0.1)

starbucks_cartogram

save_tmap(starbucks_cartogram, ""starbucks_cartogram_pop_sf.png"")

starb_cartogram %>% 
  mutate(pop_norm = pop_norm * 10) %>% 
  ggplot() +
  geom_sf(aes(fill = pop_norm)) +
  theme_minimal() +
  scale_fill_manual(values = greenpal)

```

# normalize by area

```{r }

# normalize by area
library(units)

starbucks_sf2 %>% 
  mutate(area_m2 = as.numeric(set_units(st_area(starbucks_sf2$geometry)), km^2))


as.numeric(set_units(st_area(starbucks_sf2$geometry)), km^2)

x <- st_area(starbucks_sf2$geometry)

glimpse(x)

x

x_km <- set_units(x, km^2)

glimpse(x_km)

x_km

x_km_num <- as.numeric(x_km)

glimpse(x_km_num)

x_km_num

st_area(starbucks_sf2$geometry) %>% set_units(mi^2) %>% as.numeric() %>% glimpse()

starbucks_sf_norm <- starbucks_sf2 %>% 
  mutate(area_km2 = st_area(geometry) %>% 
           set_units(km^2) %>% 
           as.numeric(),
         area_m2 = st_area(geometry) %>% 
           as.numeric(),
         count_norm_m2 = count / area_m2,
         count_norm_km2 = count / area_km2,
         area_sq2 = st_area(geometry) %>% 
           set_units(mi^2) %>% 
           as.numeric(),
         count_norm_sq2 = count / area_sq2) %>% 
  filter(!NAME == ""District of Columbia"")

starbucks_sf_norm2 <- starbucks_sf2 %>% 
  mutate(area_km2 = st_area(geometry) %>% 
           set_units(km^2) %>% 
           as.numeric(),
         area_m2 = st_area(geometry) %>% 
           as.numeric(),
         count_norm_m2 = count / area_m2,
         count_norm_km2 = count / area_km2,
         area_sq2 = st_area(geometry) %>% 
           set_units(mi^2) %>% 
           as.numeric(),
         count_norm_sq2 = count / area_sq2) %>% 
  filter(!NAME == ""District of Columbia"")

library(cartogram)
starb_cartogram <- st_transform(starbucks_sf_norm2, crs = 2163)

starb_sp <- as(starb_cartogram, ""Spatial"")

starb_cartogram <- cartogram_ncont(starb_sp, weight = ""count_norm_m2"", k = 1000)
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""count_norm_km2"", k = 1)
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""count_norm_sq2"", k = 1) # 10000 with DC
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""count_norm_sq2"", k = 5) # 10000 with DC
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""count_norm_sq2"", k = 2) # 10000 with DC

library(tmap)

# Sequential single hue color palette :: http://colorbrewer2.org/#type=sequential&scheme=Greens&n=5
greenpal <- c('#edf8e9','#bae4b3','#74c476','#31a354','#006d2c')

# add ""jenks"" process for better interval categories (California and Texas are still their own categories but best I can do with big outliers)
# legend.reverse for HIGH values on TOP, slight sepia to offset white glare?
# fiddle with margins to fit legend and small title
# plot!
starbucks_cartogram <- tm_shape(starb_cartogram) + 
  tm_borders(""grey10"") +
  tm_fill(title = ""Starbucks / sq.mile"", ""count_norm_sq2"", 
          palette = greenpal, 
          style = ""jenks"",
          legend.reverse = TRUE) +
  tm_layout(inner.margins = c(.04,.02, .08, .02),
            main.title = ""Number of Starbucks per sq. mile across the United States"",
            title = ""(Source: https://www.kaggle.com/starbucks/store-locations)\n(@R_by_Ryo, #TidyTuesday)"",
            title.position = c(""center"", ""top""), title.size = 0.7,
            fontfamily = ""Garamond"", fontface = ""bold"",
            legend.text.size = 0.85, 
            sepia.intensity = 0.1)

starbucks_cartogram

save_tmap(starbucks_cartogram, ""starbucks_cartogram_sq_mile.png"")
```



# cartograms :: `cartogram_ncont()` >>> by number of each coffee chain!

```{r }
# dev=""cairo_pdf"", dev.args=list(family = ""Lucida Console"") crs = 2163
library(cartogram)
starb_cartogram <- st_transform(starbucks_sf2, crs = 2163)

# reshape as sp object for cartogram_ncont()
starb_sp <- as(starb_cartogram, ""Spatial"")

# construct non-contiguous area cartogram
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""count"") # k = 1 is default

library(tmap)

# Sequential single hue color palette :: http://colorbrewer2.org/#type=sequential&scheme=Greens&n=5
greenpal <- c('#edf8e9','#bae4b3','#74c476','#31a354','#006d2c')


# add ""jenks"" process for better interval categories (California and Texas are still their own categories but best I can do with big outliers)
# legend.reverse for HIGH values on TOP, slight sepia to offset white glare?
# fiddle with margins to fit legend and small title
# plot!
starbucks_cartogram <- tm_shape(starb_cartogram) + 
  tm_borders(""grey10"") +
  tm_fill(title = """", ""count"", 
          palette = greenpal, 
          style = ""jenks"",
          legend.reverse = TRUE) +
  tm_layout(inner.margins = c(.04,.02, .08, .02),
            main.title = ""Number of Starbucks across the United States"",
            title = ""(Source: https://www.kaggle.com/starbucks/store-locations)\n(@R_by_Ryo, #TidyTuesday)"",
            title.position = c(""center"", ""top""), title.size = 0.9,
            fontfamily = ""Garamond"", fontface = ""bold"",
            legend.text.size = 0.85, 
            sepia.intensity = 0.1)


```




```{r}
save_tmap(starbucks_cartogram, ""starbucks_cartogram.png"")
```





### all together 


```{r all}
library(dplyr)
library(readxl)
library(sf)

# read-in data
starbucks_raw <- read_excel(""../may_7_week_6/week6_coffee_chains.xlsx"", sheet = 1)

# clean, select cols, filter USA, summarize
starbucks_usa <- starbucks_raw %>% 
  janitor::clean_names() %>% 
  select(brand, city, state_province, country, longitude, latitude) %>% 
  filter(country == ""US"") %>% 
  group_by(state_province) %>% 
  summarize(count = n()) %>% 
  ungroup()

# grab geometries of USA from tigris pkg, turn into sf
states_sf <- tigris::states(cb = TRUE) %>% 
  st_as_sf() %>% 
  select(STUSPS, NAME, geometry) %>% 
  filter(!STUSPS %in% c(""VI"", ""MP"", ""GU"", ""PR"", ""AS"")) # filter out territories and Puerto Rico

# join with starbucks data
starbucks_sf <- states_sf %>% left_join(starbucks_usa, by = c(""STUSPS"" = ""state_province""))

# remove Alaska and Hawaii... try to rescale and put them back in another time
starbucks_sf2 <- starbucks_sf %>% filter(!NAME %in% c(""Alaska"", ""Hawaii""))

# change crs to one cartogram_ncont() expects (sf compatibility for cartogram pkg coming soon i think...)
starb_cartogram <- st_transform(starbucks_sf2, crs = 2163)

# change back into sp object for cartogram_ncont()
starb_sp <- as(starb_cartogram, ""Spatial"")

# construct non-contiguous area cartogram, area weighed by ""count"" var 
library(cartogram)
starb_cartogram <- cartogram_ncont(starb_sp, weight = ""count"") # k = 1 is default

# Sequential single hue color palette :: http://colorbrewer2.org/#type=sequential&scheme=Greens&n=5
greenpal <- c('#edf8e9','#bae4b3','#74c476','#31a354','#006d2c')


# add ""kmeans"" process for better class intervals for the colors
# (California is still in their own category but best I can do with such big outliers)
# Texas has x2 the amount of Starbucks as NY, WA, and FL but size relative only to CA?
# can also use hclust, kmeans, quantile, jenks to varying success
# legend.reverse for HIGH values on TOP, slight sepia to offset white glare?
# fiddle with inner.margins to fit legend and small title
library(tmap)

starbucks_cartogram <- tm_shape(starb_cartogram) + 
  tm_borders(""grey10"") +
  tm_fill(title = """", ""count"", 
          palette = greenpal, 
          style = ""kmeans"",
          legend.reverse = TRUE) +
  tm_layout(inner.margins = c(.04,.02, .08, .02),
            main.title = ""Number of Starbucks across the United States"",
            title = ""(Source: https://www.kaggle.com/starbucks/store-locations)\n(@R_by_Ryo, #TidyTuesday)"",
            title.position = c(""center"", ""top""), title.size = 0.9,
            fontfamily = ""Garamond"", fontface = ""bold"",
            legend.text.size = 0.85, 
            sepia.intensity = 0.2)

starbucks_cartogram

save_tmap(starbucks_cartogram, ""starbucks_cartogram.png"")

```

```{r}
starbucks_cartogram
```

","Other-6"
"687",283,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_7_may_14/star_wars.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""May 14, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Star Wars movies survey

```{r}
library(tidyverse)

star_wars_raw <- read_csv(""../week_7_may_14/StarWars.csv"")


```

```{r}
glimpse(star_wars_raw)

star_wars_raw %>% janitor::clean_names() %>% trimws() %>% glimpse()

star_wars_unite <- star_wars_raw %>% 
  unite(""movies_watched"", 
        c(`Which of the following Star Wars films have you seen? Please select all that apply.`, 
          ""X5"", ""X6"", ""X7"", ""X8"", ""X9""), sep = "", "") %>% 
  unite(""preference_rank"",
        c(`Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film.`,
          ""X11"", ""X12"", ""X13"", ""X14"", ""X15""), sep = "", "") %>% glimpse()

star_wars_unite <- star_wars_unite %>% 
  mutate(movies_watched = movies_watched %>% as.list(),
         preference_rank = preference_rank %>% as.list()) %>% 
  glimpse()

star_wars_unite %>% select(movies_watched)

# ignore favorable - unfavorable Qs >>> filter them out into separate df?

```




```{r}
star_wars_unite2 <- star_wars_unite %>% 
  slice(-1) %>% 
  filter(`Do you consider yourself to be a fan of the Star Wars film franchise?` != ""NA"") %>% 
  filter(`Which character shot first?` != ""I don't understand this question"")

  star_wars_unite$`Do you consider yourself to be a fan of the Star Wars film franchise?` %>% unique()
  #mutate_all(funs(iconv(., from = ""UTF-8"", to = ""ASCII//TRANSLIT"")))
```
  
  
  
  
```{r}
star_wars_unite2 %>% 
  transmute(
    under30 = star_wars_unite2$Age == ""18-29"",
    over60 = star_wars_unite2$Age == ""> 60"",
    male = star_wars_unite2$Gender == ""Male"",
    female = star_wars_unite2$Gender == ""Female"",
    west_coast = star_wars_unite2$`Location (Census Region)` %in% c(""Pacific"", ""Mountain"")
  ) %>% 
  map(function(x) {
    out <- table(shoot = star_wars_unite2$`Do you consider yourself to be a fan of the Star Wars film franchise?`, blah = x) %>% 
      fisher.test(conf.level = 0.6785)
    out <- c(out$estimate, lower = out$conf.int[1], upper = out$conf.int[2])
    return(out)
  }) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  gather(key, value, -rowname) %>% 
  spread(rowname, value) %>% 
  ggplot(aes(y = key, x = `odds ratio`))+ 
  geom_errorbarh(aes(xmin = lower, xmax = upper), size = .45, color = ""#899DA4"", height = 0.75) + 
  geom_point(size = 4, color = ""#DC863B"") +
  geom_vline(xintercept = 1, lty = 2, lwd = 1, color = ""#C93312"") + 
  scale_x_continuous(
    sec.axis = sec_axis(~ ., 
                        breaks = c(0.65, 1.5), 
                        labels = c(""less likely\nto be a fan of Star Wars"", 
                                   ""more likely\nto be a fan of Star Wars""))
    )
```

  
  
  
```{r}
star_wars_unite2 %>% 
  transmute(
    under30 = star_wars_unite2$Age == ""18-29"",
    over60 = star_wars_unite2$Age == ""> 60"",
    male = star_wars_unite2$Gender == ""Male"",
    female = star_wars_unite2$Gender == ""Female"",
    west_coast = star_wars_unite2$`Location (Census Region)` %in% c(""Pacific"", ""Mountain"")
  ) %>% 
  map(function(x) {
    out <- table(shoot = star_wars_unite2$`Which character shot first?`, blah = x) %>% 
      fisher.test(conf.level = 0.95)
    out <- c(out$estimate, lower = out$conf.int[1], upper = out$conf.int[2])
    return(out)
  }) %>% 
  as.data.frame() %>% 
  rownames_to_column() %>% 
  gather(key, value, -rowname) %>% 
  spread(rowname, value) %>% 
  ggplot(aes(y = key, x = `odds ratio`))+ 
  geom_errorbarh(aes(xmin = lower, xmax = upper), size = .45, color = ""#899DA4"", height = 0.75) + 
  geom_point(size = 4, color = ""#DC863B"") +
  geom_vline(xintercept = 1, lty = 2, lwd = 1, color = ""#C93312"") + 
  scale_x_continuous(
    sec.axis = sec_axis(~ ., 
                        breaks = c(0.65, 1.8), 
                        labels = c(""less likely\nto say 'Greedo shot first!'"", 
                                   ""more likely\nto say 'Greedo shot first!'""))
    )

```






```{r, warning=FALSE, message=FALSE}
pacman::p_load(tidyverse, scales, ggforce, extrafont)
loadfonts()
```



```{r}
starwars_char <- dplyr::starwars

glimpse(starwars_char)
```


```{r}
starwars_char %>% 
  #filter(species %in% c(""Human"", ""Ewok"")) %>% 
  #select(name, height, mass, species) %>% 
  ggplot(aes(birth_year, height, color = species)) +
  geom_point() +
  geom_mark_ellipse(aes(filter = species == ""Yoda's species"", 
                        label = ""Do i look so old to young eyes"")) +
  theme_minimal()
```






```{r}
starwars_char %>% 
  filter(species %in% c(""Human"", ""Ewok"")) %>% 
  select(name, height, mass, species) %>% 
  ggplot(aes(mass, height, color = species)) +
  geom_point() +
  geom_mark_ellipse(aes(filter = species == ""Ewok"", label = ""Ewok"")) +
  theme_minimal()
```

","Other-7"
"688",284,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","week_9_may_28/superhero_gender.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""May 30, 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)


superhero <- read.csv(""../may_28_week9/week9_comic_characters.csv"")

glimpse(superhero)

ggplot(superhero, aes(year)) +
  geom_bar(aes(fill = sex))

superhero %>% 
  group_by(year, publisher) %>% 
  mutate(hero_n = n()) %>% 
  ggplot(aes(x = year, y = hero_n, fill = publisher, color = publisher)) +
  geom_col() +
  facet_wrap(~publisher) +
  scale_y_continuous(breaks = scales::pretty_breaks(), expand = c(0, 0)) +
  scale_x_continuous(breaks = scales::pretty_breaks(), expand = c(0.01, 0)) +
  scale_color_brewer(palette = ""Set1"")

  
```



```{r}

female_pct <- superhero %>% 
  group_by(publisher, year) %>% 
  mutate(new_hero = n()) %>% # total new hero appearance in a certain year for certain publisher
  group_by(publisher, year, sex) %>% 
  mutate(gender_n = n(),
         gender_perc = gender_n / new_hero) %>% 
  ungroup() %>% 
  filter(sex == ""Female Characters"")


female_pct %>% 
  ggplot(aes(x = year, y = gender_perc * 100, 
             group = publisher, color = publisher)) +
  geom_line(size = 1.2) +
  scale_x_continuous(limits = c(1980, 2013))



```






```{r}

superhero %>% glimpse()

superhero %>% 
  mutate(align = as.character(align)) %>% 
  mutate(alignment = case_when(
    align == ""Good Characters"" ~ align,
    align == ""Bad Characters"" ~ align,
    TRUE ~ ""Neutral Characters""
  )) %>% 
  group_by(publisher, sex, alignment) %>% 
  summarise(align_count = n())

superhero


```




","Other-9"
"689",285,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","wines.rmd","---
title: ""Untitled""
author: ""RN7""
date: ""5/31/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse, scales, janitor, rvest, polite, glue)
```




```{r}
wine_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")
```

```{r}
glimpse(wine_ratings)
```




```{r}
wine_ratings %>% 
  ggplot(aes(price, points)) +
  geom_point()

cor(wine_ratings %>% 
      select(-X1) %>% 
      select_if(is.numeric), use = ""complete.obs"") -> wine_cor


corrr::as_cordf()

corrplot::corrplot(wine_cor)
```




```{r}
wine_ratings %>% 
  select(-X1, -description, -taster_name, -taster_twitter_handle,
         -designation, -province, -title) %>% 
  map(~unique(.))



```

","Other-1"
"690",288,"https://github.com/Amalan-ConStat/TidyTuesday/tree/master/Week_35","Amalan-ConStat","TidyTuesday","Week_35/bridges_baby.Rmd","---
title: ""Week 35 Bridges of Baltimore""
author: ""M.amalan""
date: ""November 27, 2018""
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.width = 9,fig.height = 7)

library(readr)
library(tidyverse)
library(stringr)
library(ggthemr)
library(gganimate)
library(formattable)

ggthemr(""flat dark"")

bridges <- read_csv(""baltimore_bridges.csv"")
#View(bridges)

names(bridges)<-c(""lat"",""long"",""County"",""Carries"",""Year Built"",""Condition"",""Average Daily Traffic"",""Total Improvement"",""Month"",""Year"",""Owner"",""Responsibility"",""Vehicles"")
attach(bridges)
```

# Bridge Data and Baltimore 

Data on bridges is from week 35 for TidyTuesday. Trying to explain the data using maps is obvious, yet I
will use animated jitter plots. There are 13 variables and 2079 observations. Brave choice of 
limiting my self to less than 10 variables, where latitude, longitude and Vehicles will not be
taken into account.

So with the help of packages tidyverse, ggthemr, gganimate,formattable and readr I will complete this
analysis. Most of the bridges are owned by several agencies, but I will only focus on the 
top three ownership holders.

## Counties which have bridges owned by State Highway Agency 

Close to 1000 bridges are owned by State Highway Agency, where most of them are in Baltimore
County. High amount of bridges are in good condition, further more bridges are in Fair condition and
only around 10 bridges in Poor condition. 

Considering the Average Daily Traffic only one bridge in Poor condition has the amount of 
close to 110,000, while all the other poor condition bridges have Average Daily Traffic less
than 30,000. While counties Anne Arundel and Hartford have no Poor condition bridges at all.

Most of the bridges are from Baltimore County and around 20 bridges have more than 150,000
Average Daily Traffic for both Fair and Good conditions. Hartford and Carroll Counties have 
their Average Daily Traffic which does not exceed 80,000 at any condition of the bridge.

```{r County with Condition and Average Daily Traffic SHA}
ggplot(subset(bridges,Owner==""State Highway Agency"")
       ,aes(color=Condition,y=`Average Daily Traffic`,x=str_wrap(County,7)))+xlab(""County"")+
  ggtitle(""Condition of Bridges owned by State Highway Agency \nand their Average Daily Traffic"")+
  scale_y_continuous(labels =seq(0,230000,10000) ,breaks = seq(0,230000,10000))+
  geom_jitter()+transition_states(Condition,transition_length = 2,state_length = 3)+
  enter_fade()+exit_shrink()+ease_aes(""back-in"")
```

## Counties which have bridges owned by  County Highway Agency 

County Highway Agency owns the second  most amount of bridges in this data-set. 
Therefore using jitter plots we are going to check how the condition of the bridge 
and counties are explained is the simplest manner. 

Less amount of poor condition bridges in all counties except Anne Arundel
County. All bridges owned by County Highway Agency have a limited Average 
Daily Traffic less than 50,000. Clearly we have More fair bridges than good 
ones. In the poor condition category only two points have Average Daily Traffic
more than 20,000, while other two conditions have more than 10 bridges.

Most of these bridges are in Baltimore County even it is in any one of three
conditions. There are few bridges which have more than 40,000 Average Daily
Traffic and they are also in Baltimore County.

There are bridges which have Zero Average Daily Traffic. In all three Conditions
only Hartford County has bridges which has Average Daily Traffic less than 
10,000.

```{r County with Condition and Average Daily Traffic CHA}
ggplot(subset(bridges,Owner==""County Highway Agency"")
       ,aes(color=Condition,y=`Average Daily Traffic`,x=str_wrap(County,7)))+xlab(""County"")+
  ggtitle(""Condition of Bridges owned by County Highway Agency \nand their Average Daily Traffic"")+
  scale_y_continuous(labels =seq(0,40000,5000) ,breaks = seq(0,40000,5000))+
  geom_jitter()+transition_states(Condition,transition_length = 2,state_length = 3)+
  enter_fade()+exit_shrink()+ease_aes(""back-in"")
```

##  Counties which have bridges owned by  State Toll Authority

There is only bridge which is in Poor condition and it is in Baltimore City, while 
Howard county has no Good condition bridges, but Anne Arundel county has  one good condition 
bridge. Further there is only 3 Fair condition bridges in Howard County while there 
have an Average Daily Traffic less than 10,000. 

The highest Average Daily Traffic is close to 170,000 which are only 4 and in Good and Fair conditions.
Further, Hartford county has only six Good condition bridges. Only few 
of the bridges have Average Daily Traffic close to zero. 

```{r County with Condition and Average Daily Traffic STA}
ggplot(subset(bridges,Owner==""State Toll Authority"")
       ,aes(color=Condition,y=`Average Daily Traffic`,x=str_wrap(County,7)))+xlab(""County"")+
  ggtitle(""Condition of Bridges owned by State Toll Authority \nand their Average Daily Traffic"")+
  scale_y_continuous(labels =seq(0,170000,10000) ,breaks = seq(0,170000,10000))+
  geom_jitter()+transition_states(Condition,transition_length = 2,state_length = 3)+
  enter_fade()+exit_shrink()+ease_aes(""back-in"")
```

## Most amount of bridges Built based on Year 

Years 1957, 1970, 1975, 1991, 1963 and 1961 have the top 6 spots for building more than 50 bridges
in those years. If we consider the conditions of Fair and Good only the year 1991 is suitable to mention,
while all other years has at-least one Poor condition bridge. Further There are more Poor condition bridges 
in 1961 than in 1957. While all Poor condition bridges has Average Daily Traffic less than 50,000. 

Finally, there are only a few bridges which have Average Daily Traffic above 100,000 and only 3 are in Good
condition. There are Bridges which can have Average Daily Traffic close to zero in all 6 years. 

```{r Year Built with Condition and Average Daily Traffic}
ggplot(subset(bridges,`Year Built`==""1957"" | `Year Built`==""1970"" | `Year Built`==""1975"" | `Year Built`==""1991"" 
              | `Year Built`==""1963"" | `Year Built`==""1961"")
       ,aes(color=Condition,y=`Average Daily Traffic`,x=factor(`Year Built`)))+
  xlab(""Year Built"")+ylab(""Average Daily Traffic"")+
  ggtitle(""Most amount of Bridges built based on Years \nand their Conditions"")+
  geom_jitter()+legend_bottom()+transition_states(Condition,transition_length = 2,state_length = 3)+
  enter_fade()+exit_shrink()+ease_aes(""back-in"")
```

## Average Traffic Less than or equal to 100,000 for Counties with Bridge Condition

While obtaining summary for county variable there is one issue because there are two observations
which say ""Baltimore city"" than ""Baltimore City"" and I don't want to change them. 

If we focus on Average Daily Traffic less than or equal to 100,000 based on County and Condition. 
It is clear that Poor condition bridges are part of this criteria and mostly Average Daily Traffic 
is less than 5000 for Counties Howard, Hartford and Carroll. While Baltimore City has highest amount 
up-to 75,000, but Baltimore County has highest amount close to 40,000. Finally Anne Arundel County has only
one Poor condition bridge which has Average Daily Traffic Close to zero. 

We can see that there are more Fair Condition bridges than Good ones. In Baltimore County most of the Fair
condition bridges have Average Daily Traffic less than 15000. Similarly Carroll county and Hartford county 
also behave similarly. But for Good condition bridges this is not the case where there is no certain strong
dense region as similar to Fair condition bridges. 

Previously when we looked into Ownership we did not see Baltimore City as a factor until the ownership 
of State Toll Authority, but here that is not the case. 

```{r Average Traffic less than 100000}
ggplot(subset(bridges, `Average Daily Traffic` <= 100000 & County != ""Baltimore city""),aes(x=County,y=`Average Daily Traffic`,color=Condition))+
  xlab(""County"")+ylab(""Averag Daily Traffic"")+ggtitle(""Average Daily Traffic Less than 100,000 \nFor Counties"")+
  scale_y_continuous(labels = seq(0,100000,5000),breaks = seq(0,100000,5000))+coord_flip()+
  theme(axis.text.x = element_text(angle = -90))+
  geom_jitter()+transition_states(Condition,transition_length = 2,state_length = 3)+
  enter_fade()+exit_shrink()+ease_aes(""back-in"")

```

## Average Traffic More than  100,000 for Counties with Bridge Condition

This Jitter plot is completely different than previous one, because there are no clear dense regions 
for any counties and conditions of the bridge. There is only one Poor condition bridge in Baltimore County
where the Average Daily Traffic is close to 115,000. In Fair condition bridges also Baltimore County holds 
the most, while they are slightly dense in the region of 175,000 to 190,000. while for Howard County similar
density occurs between 190,000 to 205,000. Bridges in Good condition have a more points in Baltimore County
than Anne Arundel County because there are no bridges with Average Daily Traffic above 140,000. 

```{r  Average Traffic more than 100000}
ggplot(subset(bridges, `Average Daily Traffic` > 100000 & County != ""Baltimore city""),aes(x=County,y=`Average Daily Traffic`,color=Condition))+
  xlab(""County"")+ylab(""Average Daily Traffic"")+ggtitle(""Average Daily Traffic More than 100,000 \nFor Counties"")+
  scale_y_continuous(labels = seq(100000,230000,5000),breaks = seq(100000,230000,5000))+coord_flip()+
  theme(axis.text.x = element_text(angle = -90))+
  geom_jitter()+transition_states(Condition,transition_length = 2,state_length = 3)+
  enter_fade()+exit_shrink()+ease_aes(""back-in"")

```


## Improvement and Bridge Conditions with Counties 

In the variable of Total Improvement There are 1438 missing values, 42 values are zero and 
the rest are actual values. I am going to look at Total Improvement in two tables. First 
table will include where bridges have Total Improvement is higher than 9,999,000 and less than 
30,000,000. Second table is for bridges which have Total Improvement higher than or equal to 
30,000,000. 

Further to make these tables interesting I will using the package formattable package and 
add colors and tiles for numerical values. In the first table there are 7 bridges while 
only Anne Arundel County holds 3 and Baltimore City holds 4. One bridge is from 1953, and others
are from the period of 1977 to 1983. Conditions of these bridges are mostly Fair and two bridges 
are in Good condition. Lowest Average Daily Traffic is 11760, while highest is 124193, where both bridges 
are in Fair Condition, and the amount spent on them for Total Improvement are respectively 18,163,000
and 16,264,000. The bridge with Highest amount of traffic is built in 1953.


```{r Bridge Condition and County with Improvement Next 7}
Top10<-subset(bridges[,c(-1,-2,-9,-10,-11,-12,-13)], `Total Improvement` > 9999 & `Total Improvement` < 30000)

customRed0 = ""#FF8080""
customRed = ""#7F0000""

customyellow0 = ""#FFFF80""
customyellow = ""#BFBF00""

customblue0 = ""#6060BF""
customblue =  ""#00007F""

formattable(Top10,align=c(""l"",""l"",""c"",""c"",""c"",""c""),
            list(
              County =formatter(""span"",style= ~style(color=""grey"")),
            `Total Improvement`=color_tile(customblue0,customblue),
            `Average Daily Traffic`=color_tile(customyellow0,customyellow),
            `Year Built`=color_tile(customRed0,customRed)
            ))
```

When I did try to plot the top ten bridges with most Total improvement there 
was one issue, which is the distance between first two values and the next 8 values.
Therefore I divided the table into two. 

In this second table We can see there are two bridges which are from Baltimore City
and are built in 1980 and 1971, but the amount spent on Total Improvement is 
300,000,000. But their Average Daily Traffic values are respectively 56280 and 30600.

While we have another bridge from Baltimore City and built in 1907, but Total
Improvement amount is 35,026,000. But the Average Daily Traffic is 3,900.


```{r Bridge Condition and County with Improvement Top 3}
Top3<-subset(bridges[,c(-1,-2,-9,-10,-11,-12,-13)], `Total Improvement` >= 30000)

customRed0 = ""#FF8080""
customRed = ""#7F0000""

customyellow0 = ""#FFFF80""
customyellow = ""#BFBF00""

customblue0 = ""#6060BF""
customblue =  ""#00007F""

formattable(Top3,align=c(""l"",""l"",""c"",""c"",""c"",""c""),
            list(
              County =formatter(""span"",style= ~style(color=""black"")),
            `Total Improvement`=color_tile(customblue0,customblue),
            `Average Daily Traffic`=color_tile(customyellow0,customyellow),
            `Year Built`=color_tile(customRed0,customRed)
            ))
```
","Other-35"
"691",369,"https://github.com/r0mymendez/R/tree/master/TidyTuesday/20140423-BirdCollisions","r0mymendez","R","TidyTuesday/20140423-BirdCollisions/tidytuesday_29190501.R","rm(list=ls())
library(tidyverse)
library(extrafont)
library(gridExtra)
library(grid)
library(ggpubr)

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")
+ scale_color_jama()

#Gauge plots
df1=bird_collisions%>%
  mutate(year=format(as.Date(bird_collisions$date, format=""%Y-%m/%d""),""%Y""))%>%
  filter(year %in% 1996:2016)%>%
        count(family)%>%
        mutate(
              prop=round(n/sum(n),2),
              label=paste0(round(n/sum(n)*100,0),'%')
                      )%>%
        top_n(5,n)%>%
        arrange(n)%>%
        mutate(val=c(1,1,2,3,3),val=as.factor(val))
      
df1$family=
  factor(df1$family,
            levels = c('Regulidae','Certhiidae',
                 'Turdidae','Parulidae','Passerellidae'))

a=df1%>%
ggplot(aes(fill = val, 
           ymax = prop, 
           ymin = 0, 
           xmax = 2, 
           xmin = 1)) +
  geom_rect(aes(ymax=1, ymin=0, xmax=2, xmin=1),
            fill =""#ece8bd"") +
  geom_rect(color='white') + 
  coord_polar(theta = ""y"",start=-pi/2) + xlim(c(0, 2)) + ylim(c(0,2)) +
  geom_text(aes(x = 0, y = 0, label = label, colour=val), size=6.5, family=""Mr Bedfort"",fontface = ""bold"") +
  geom_text(aes(x=1.5, y=1.5, label=family), family=""Mr Bedfort"", size=6.5,colour='white') + 
  facet_wrap(~family, ncol = 5) +
  theme_void() +
  scale_fill_manual(values = c(""1""=""#C9146C"", ""2""=""#DA9112"", ""3""=""#129188"")) +
  scale_colour_manual(values = c(""1""=""#C9146C"", ""2""=""#DA9112"", ""3""=""#129188"")) +
  theme(strip.background = element_blank(),
        strip.text.x = element_blank()) +
  guides(fill=FALSE) +
  guides(colour=FALSE)+
  theme(plot.background = element_rect(fill='#2a2a2a',colour = ""#2a2a2a""),
        panel.background = element_rect(fill = ""#2a2a2a"", colour = ""#2a2a2a""),
        axis.ticks = element_blank(),
        panel.border = element_blank()
  )





df2=bird_collisions%>%
  mutate(year=format(as.Date(bird_collisions$date, format=""%Y-%m/%d""),""%Y""))%>%
  select(family,year,habitat)%>%
  count(family,year,habitat)%>%
  filter(year %in% 1996:2016)


b=ggplot(df2, aes(x=year,y=family,color=family))+
  geom_quasirandom(alpha=.9,aes(size=n*2),
                   groupOnX = FALSE, 
                   show.legend = FALSE)+
  labs(title='Bird Collisions between 1996-2016',
       subtitle='Data: Winger et al. 2019 (doi: 10.1098/rspb.2019.0364)',
       y='',
       caption='')+
      theme(plot.background = element_rect(fill='#2a2a2a',colour = ""#2a2a2a""),
            panel.background = element_rect(fill = ""#2a2a2a"", colour = ""#2a2a2a""),
            axis.text = element_text(color='white',family = ""Lucida Calligraphy""),
            plot.caption = element_text(color='white'),
            plot.title = element_text(color='white',family = ""Mr Bedfort"",size=30,face = 'bold'),
            plot.subtitle = element_text(color = ""white"",size = 8),
            axis.title = element_text(color = ""white"",family = ""Mr Bedfort"",size = 20),
            panel.grid.major.y = element_line(colour = ""#2a2a2a"", size = .2),
            panel.grid.minor.y = element_blank(),
            panel.grid.major.x = element_line(colour = ""#fdfdf3"", size = .2),
            panel.grid.minor = element_blank())

b


title='#Tidytuesday'

df <- data.frame(
    x = c(1, 1, 2, 2, 1.5),
    y = c(1, 2, 1, 2, 1.5),
    text = c("""", """", """", """", title))
  
  
 g= ggplot(df, aes(x, y)) +
    geom_text(aes(label = text),color=""white"",size=10,family = ""Mr Bedfort"")+
    labs(x='',y='',caption='Visualization by @r0mymendez')+
    theme(
      plot.background  = element_rect(color = '#2a2a2a',fill='#2a2a2a'),
      panel.background = element_rect(color = '#2a2a2a',fill='#2a2a2a'),
      panel.grid =  element_line(colour = '#2a2a2a'),
      axis.text= element_blank(),
      axis.line=element_blank(),
      axis.ticks = element_blank(),
      plot.caption = element_text(color='white',hjust = 0)
      )
  
ggarrange(b,
  ggarrange(g,a,widths= c( 0.5, 1.2),
                      ncol = 2, nrow = 1) +
    theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
          panel.background = element_rect(fill='#2a2a2a',color ='#2a2a2a')), 
          heights = c(2, 0.7),
          ncol = 1, nrow = 2)  +
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ))
","Other-1"
"692",383,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20140423-anime/anime_script.R","rm(list = ls())
library(ghibli)
library(tidyverse)
library(ggrepel)
library(patchwork)
library(scales)
library(extrafont)
library(showtext)
pacman::p_load(jpeg, png, ggplot2, grid, neuropsychology)
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

df=tidy_anime%>%select(title_english,studio,type,source,scored_by,score,rating,rank,popularity)
df=unique(df%>%filter(is.na(title_english)==FALSE))

imgage1 <- png::readPNG(""16.png"")

 g0=
  df%>%count(rating)%>%filter(is.na(rating)==F)%>%
  mutate(rating=case_when(
    rating==""R - 17+ (violence & profanity)""~ 'R17 \n (violence & profanity)',
    rating==""PG-13 - Teens 13 or older""     ~ 'PG13 \n (Teens 13 or older)',
    rating==""PG - Children""                 ~ 'PG (Children)', 
    rating==""R+ - Mild Nudity""              ~ 'R+ \n (Mild Nudity)',
    rating==""G - All Ages""                  ~ 'G (All Ages)', 
    rating== ""None""                          ~ 'None')
    )%>%
  mutate(rating=reorder(rating,n))%>%
  ggplot(aes(rating,n,fill=rating))+
  annotation_custom(rasterGrob(imgage1, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  
  geom_col(show.legend = F,color='black')+
  scale_fill_ghibli_d(""MarnieMedium1"")+
  coord_flip()+
  labs(x='',y='',title='Anime: classification and studios',subtitle='')+
  theme_bw()+
  theme(axis.text.y = element_text(color=""#233a77"",
                                 size=rel(0.7),hjust=0.5),
        axis.text.x = element_text(color=""#233a77"",
                                   size=rel(1)),
        axis.title = element_text(color=""#233a77"",
                                    size=rel(0.8)),
        text=element_text(size=16, family=""Bangers""),
        plot.title = element_text(size = 25),
        )
 

imgage <- png::readPNG(""16.png"")


g1=
  df%>%count(studio)%>%filter(is.na(studio)==F)%>%
  top_n(5,n)%>%
  mutate(studio=reorder(studio,n))%>%
  ggplot(aes(studio,n,fill=studio))+
  annotation_custom(rasterGrob(imgage, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_col(show.legend = F,color='black',alpha=0.6)+
  scale_fill_ghibli_d(""MarnieMedium1"")+
  coord_flip()+
  labs(x='',y='')+
  theme_bw()+
  theme(axis.text.y = element_text(color=""#233a77"",
                                   size=rel(0.8),hjust=0.5),
        axis.text.x = element_text(color=""#233a77"",
                                   size=rel(1)),
        axis.title = element_text(color=""#233a77"",
                                  size=rel(0.8)),
        text=element_text(size=16,  family=""Bangers""),
        plot.title = element_text(size = 25)
  )



img_a <- png::readPNG(""6.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 


g2=
  df%>%
    select(studio,popularity,rating,score,rank)%>%
    mutate(rating=case_when(
      rating==""R - 17+ (violence & profanity)""~ 'R 17',
      rating==""PG-13 - Teens 13 or older""     ~ 'PG 13',
      rating==""PG - Children""                 ~ 'PG', 
      rating==""R+ - Mild Nudity""              ~ 'R+',
      rating==""G - All Ages""                  ~ 'G', 
      rating== ""None""                          ~ 'None')
    )%>%
  filter(studio=='Toei Animation')%>%
  ggplot(aes(x=rank,y=popularity,color=rating)) +
  geom_point()+
  scale_color_ghibli_d(""MarnieMedium1"") +
  annotation_custom(a, xmin = 8000, xmax = 16000,
                     ymin = 0, ymax = 6000)  +
  labs(x = ""Ranking"", y = ""Popularity"",
       title = ""Toei Animation Studio"",
       subtitle = """")+
  theme_bw() +
  guides(col  = guide_legend(title = ""classif.""))+
  theme(
    text=element_text(size=16,  family=""Bangers""),
    legend.text=element_text(size=rel(0.9)),
    panel.border=element_rect(color=""#f4e3b5"", fill=NA, size=1),
    panel.background = element_blank(),
    plot.title = element_text(size = 25)
  )


imgagec <- jpeg::readJPEG(""sp4.jpg"")


g4= ggplot() + annotation_custom(rasterGrob(imgagec, 
                                            width = unit(1,""npc""), 
                                            height = unit(1,""npc"")), 
                                 -Inf, Inf, -Inf, Inf) 
  
(g0|g1) / (g2 + g4 + plot_layout(ncol=2,widths=c(2,1)))

  
","Other-2"
"693",391,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TiduTuesday_Birdsspotting.R","#TidyTuesday
#===============================================================================
#TidyTuesday
# Birdsspotting @Christmas.
#ChordDiagram
#@sil_aarts
#===============================================================================

#Load libraries
library(tidyverse)
library(circlize)
library(dplyr)
library(chorddiag)  
library(LaCroixColoR)
library(extrafont)

#Read file
birds <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

#Check what is in the data! Yep normal names and Latin have the same n.
unique(birds$species)
unique(birds$species_latin)

#Check unique rows
birds2 <- birds %>%
  select(2:6)

#Order count
birds2 <- birds2[order(-birds2$how_many_counted),]

#Sum count
birds3 <- birds2 %>% 
  group_by(species, species_latin) %>% 
  summarise(total = sum(how_many_counted, na.rm=T))

#Order count
birds4 <- birds3[order(-birds3$total),]

#Select top 10
birds5 <- birds4 %>%
  subset(total > 155000)

#Divide by 1000 for ease of use
birds5$total <- birds5$total/1000

#Change colnames
colnames(birds5) <- c(""names"", ""key"", ""value"")

#Make some colours
col <- lacroix_palette(""Pamplemousse"", n = 10, type = ""continuous"")

#Set some parameters: insert gap to see difference between col and rows
circos.par(start.degree = 0, track.margin = c(-0.1, 0.1), points.overflow.warning = FALSE)
par(mar = rep(0, 4), par(bg = ""grey30""), par(family = ""serif""))

#ChordDiagram plot
chordDiagram(
  x = birds5, 
  grid.col = col,
  transparency = 0.2,
  directional = 1,
  direction.type = c(""arrows""), 
  diffHeight  = -0.05,
  annotationTrack = ""grid"", 
  annotationTrackHeight = c(0.05, 0.3),
  link.arr.type = ""big.arrow"", 
  link.sort = TRUE, 
  link.largest.ontop = TRUE,
  link.border=""white"",
  link.lwd=2,
  link.arr.length = 0.1)

#Add axis all around and text using the labels
circos.trackPlotRegion(track.index = 1, 
                       bg.border = NA, 
                       panel.fun = function(x, y) {
                        xlim = get.cell.meta.data(""xlim"")
                        ylim = get.cell.meta.data(""ylim"")
                        sector.index = get.cell.meta.data(""sector.index"")
                        
#Tick white line all the way around to get the axis.ticks in the white 
circos.rect(xleft=xlim[1], ybottom=3, xright=xlim[2], ytop=1, col = ""white"")

#Add names to the sector, make it facing inside, size letters=cex
circos.text(x = mean(xlim), y = 4.5, labels = sector.index, facing = ""inside"", cex = 0.9, col=""white"")

#Add ticks on axis
circos.axis(major.at = c(0, 200, 400, 600, 800, 1000, 1200, 1400, 1600), direction = ""outside"",  col=""black"") }
)

circos.clear()

#Add title
text(0, 0.1,""TidyTuesday"", cex=3, col=""black"")
text(0, 0, ""Birdspotting since 1921"", cex = 2, col=""black"")

#Add read it info
text(-1.1,-0.92,c(""How to read this plot?""), pos=4, cex=1.2, col=""black"")
text(-1.1,-0.96,c(""Arrows represent names of bird species (bottom) ""), pos=4, cex=1, col=""black"")
text(-1.1,-1.00,c(""and their Latin names (top). Arrows are indicative""), pos=4, cex=1, col=""black"")
text(-1.1,-1.04,c(""for the top 5 most spotted birds (x1000) around Christmas""), pos=4, cex=1, col=""black"")

#Add caption
text(1.1,-1.00,c(""Plot by @sil_aarts""), pos=2, cex=1, col=""black"")
text(1.1,-1.04,c(""Source: Bird Studies Canada | Hamilton area of Ontario""), pos=2, cex=1, col=""black"")
","Other-1"
"694",392,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Amusementparks.R","#TidyTuesday
#===============================================================================
#Amusement parks
#@sil_aarts
#===========================================================================

#Load libraries
library(ggplot2)
library(dplyr)
library(harrypotter)
library(tidyverse)
library(showtext)
library(showtextdb)
library(ggtext)

#Load file
injuries <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-10/tx_injuries.csv"")

#Check data
unique(injuries$injury_report_rec)
unique(injuries$name_of_operation)

#Count injuries per operation
injuries$name_of_operation <- as.factor(injuries$name_of_operation)
data1 <- injuries %>%
  group_by(name_of_operation) %>%
  mutate(count_op = n())

#Calculate Females
data2 <- data1 %>%
  filter(gender == ""F"") %>%
  group_by(name_of_operation, gender) %>%
  mutate(count_gender = n())

#Select operations with the most incidents
data3 <- data2 %>%
  filter(name_of_operation== ""Splashtown - Spring, TX"" | 
          name_of_operation==""Wonderland Amusement Park"" |
          name_of_operation== ""Great Wolf Lodge"" |
          name_of_operation== ""Six Flags - Hurricane Harbor"" |
          name_of_operation== ""Six Flags Over Texas"")

#Select some rows
data4 <- data3[c(1,2,8,9,15), ]

#Make some colours
colors <- ""#084D49FF""
colors2 <- ""#830042FF""

#Theme
theme_sil <- theme_minimal() +
  theme(
    text = element_text(family=""serif""),
    line = element_blank(),
    plot.background = element_rect(fill = ""black"", color = NA),
    axis.text = element_text(size = 15, color=""grey70""), 
    panel.grid.major.y = element_line(color=""grey70""),
    panel.grid = element_blank(),
    plot.caption = element_markdown(size = 13, color = ""grey70"", hjust=0)
  )

#GGplot: point
p <- ggplot(data4, aes(x= name_of_operation, y= count_op))+
  geom_point(colour = colors, shape= 11, size=10)+
  scale_y_continuous(breaks=seq(0.0, 100, 20))+
  geom_text(aes(x=name_of_operation, y= count_op, label= ""T""), size=5, color=""white"", fontface=""bold"") +
  #Females 
  geom_point(aes(x=name_of_operation, y= count_gender), shape=11, color=colors2, size=10)+
  #Insert the first letter in geom_point
  geom_text(aes(x=name_of_operation, y= count_gender, label=substr(gender, 1, 1)), size=5, color=""white"", fontface=""bold"")+
  #Title
  annotate(""rect"", xmin = 5.8, xmax = 6, ymin = 0, ymax = 100, alpha = .8, colour= colors, fill=colors)+
  geom_text(aes(x= 5.9, y= 50, label= ""Top 5 amusement parks at which the most injuries happened""), alpha= 0.8, angle=90, fontface=""bold"", size=6, colour=""white"", family= ""serif"")+
  #Line
  annotate(""rect"", xmin = 1, xmax = 2.5, ymin = 110, ymax = 110, alpha = .2, colour= ""white"")+
  annotate(""rect"", xmin = 3.2, xmax = 4.8, ymin = 110, ymax = 110, alpha = .2, colour= ""white"")+
  #Info 1
  annotate(geom=""text"", x= 0.9, y = 118, label = ""92"", size= 25, fontface=""bold"", color=colors2, alpha=0.8)+
  geom_text(aes(x= 1, y = 118), label = ""In total, 92 incidents involving injuries\nhappened at Six Flags Over Texas"",  alpha= 0.2, fontface=""bold"", size=6, family= ""serif"", hjust=0, color=""white"")+
  #Info 2
  annotate(geom=""text"", x= 3.1, y = 118, label = ""50%"", size=25, fontface=""bold"", color=colors2, alpha=0.8)+
  geom_text(aes(x= 3.2, y = 118), label = ""Of all 24 incidents at Splashtown - Spring, TX\n50% involved females"", alpha= 0.2, fontface=""bold"", size=6, family= ""serif"", hjust=0, color=""white"")+
  #Extra info: T
  annotate(geom=""text"", x= ""Splashtown - Spring, TX"", y = 85, label = ""Total number of incidents"", size= 6, family= ""serif"", alpha= 0.2, fontface=""bold"", color=""white"")+
  annotate(""segment"", x= ""Splashtown - Spring, TX"", xend = ""Six Flags Over Texas"", y = 92, yend = 92, size= 0.5, linetype=""dashed"", color=colors)+
  geom_point(aes(x=""Splashtown - Spring, TX"", y= 92), shape=21, size=5, color=colors, fill=""black"", stroke = 5)+
  #Extra info: F
  annotate(geom=""text"", x= ""Splashtown - Spring, TX"", y = 55, label = ""Total number of incidents including females"", alpha= 0.2, size= 6, family= ""serif"", fontface=""bold"", color=""white"")+
  annotate(""segment"", x= ""Splashtown - Spring, TX"", xend = ""Six Flags Over Texas"", y = 47, yend = 47, size= 0.5, linetype=""dashed"", color=colors2)+
  geom_point(aes(x=""Splashtown - Spring, TX"", y= 47), shape=21, size=5, color=colors2, fill=""black"", stroke = 5)+
  #labs 
  labs(caption = ""Source: Saferparks | Plot by: <span style='color:white'>**@sil_aarts**</span>"" )+
  theme_sil

#Run it!
p 
","Other-2"
"695",393,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_AnimeGGanimate.R","#TidyTuesday
#Anime-animated

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)

#Load data
anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

#Delete some columns to make some space and delete all NA
anime$synopsis <- NULL
anime$background <- NULL
anime2 <- na.omit(anime)

#Filter only unique names
anime3 <- unique(anime2[c(""name"", ""score"",""rank"",""start_date"", ""members"",""studio"")])

#Make start_date, year only
anime3$year <- format(anime3$start_date, ""%Y"")
anime3$year <- as.numeric(anime3$year)

#Change members variabele
anime3$members <- anime3$members/1000

#GGplot: scatter
p <- ggplot(anime3, 
  aes(x = members, y=score, size = rank, colour =studio)
) +
  geom_point(show.legend = F, alpha = 0.7) +
  scale_color_viridis_d() +
  scale_size(range = c(2, 10)) +
  labs(x = ""# of members (x1000)"", y = ""Score"", caption = ""Source: MyAnimeList | Plot by @sil_aarts"",
       title = ""TidyTuesday: Anime scatterplot \n Relation between # of members and score (by rank and studio) in {round(frame_time)}"")+
  shadow_mark(colour=""black"", size = 1)+ 
  theme_bw()+
  theme(text=element_text(family=""Times New Roman"", face=""bold"", size=12))+
  transition_time(year) 
  
#Run animation
p2 <- animate(p, nframes = 150, fps=3)

#Save it!
anim_save(""Desktop/R/TidyTuesday/Anime.gif"", p2)
","Other-3"
"696",394,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Biking.R","#TidyTuesday
#Biking

#Install new packages for specific themes GGplot
install.packages(""ggthemes"")

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(ggmap)
library(ggthemes)
library(extrafont)

#Read file
bike <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

#Select one crossing: of course > Broadway!
bike2 <- bike %>%
  filter(bike$crossing == ""Broadway Cycle Track North Of E Union St"")

#Make column 1 only days, not times, substr char <10
bike2$date <- str_sub(bike2$date,1,10)

#Sum bike counts per day
bike3 <- aggregate(bike2$bike_count ~ date + crossing + direction, data=bike2, sum)

#Change colname
colnames(bike3) [c(4)] <- c(""bike_count"")

#Filter 2019: first change character tot date
bike3$date <- as.Date(bike3$date, ""%m/%d/%Y"")
bike4 <- bike3 %>%
  filter(date > ""2019-01-01"" & date < ""2019-12-31"") 

#Make a date for 2019-01-14
x <- as.Date(""2019-01-14"")

#GGplot: North
p <-bike4 %>%
  filter (direction== ""North"") %>%
    ggplot(aes(x=date)) + 
    geom_line(aes(y=bike_count), color=""gold4"", size=1.5) + 
    labs(title= ""TidyTuesday: Biking in Seattle | Broadway Cycle Track North Of E Union St."", 
        subtitle= ""TOTAL DAILY BIKE TRAFFIC | Direction North | January 2019"",
        caption=""Source: Seattle Gov. | Plot by: @sil_aarts"")+
  annotate(geom=""label"", x=x, y = 205, label = ""250 bikes on 14th, January 2019"", family= ""Courier"", vjust=0.1, size=5, fontface=""bold"")+
  theme_wsj()+
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.line.x = element_line(color=""darkgrey""),
    axis.line.y = element_blank(),
    axis.text.x = element_text(color=""darkgrey"", size=15),
    axis.text.y = element_text(color=""darkgrey"", size=14),
    panel.grid.major.y = element_line(colour=""darkgrey""),
    plot.title=element_text(size=16, face=""bold"", hjust=0, color=""black""),
    plot.subtitle=element_text(size=15, hjust=0, color=""black""),
    plot.caption=element_text(size=12, color=""darkgrey""))
    
#Run it!
p

#Make a date for 2019-01-14
x2 <- as.Date(""2019-01-29"")

#GGplot: South
p2 <-bike4 %>%
filter (direction== ""South"") %>%
  ggplot(aes(x=date)) + 
  geom_line(aes(y=bike_count), color=""gold4"", size=1.5) + 
  labs(title= ""TidyTuesday: Biking in Seattle | Broadway Cycle Track North Of E Union St."", 
       subtitle= ""TOTAL DAILY BIKE TRAFFIC | Direction South | January 2019"",
       caption=""Source: Seattle Gov. | Plot by: @sil_aarts"")+
  annotate(geom=""label"", x=x2, y = 241, label = ""241 bikes on 14th, January 2019"", family=""Courier"", hjust=0.8, vjust=0.1, size=5, fontface=""bold"")+
  theme_wsj()+
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.line.x = element_line(color=""darkgrey""),
    axis.line.y = element_blank(),
    axis.text.x = element_text(color=""darkgrey"", size=15),
    axis.text.y = element_text(color=""darkgrey"", size=14),
    panel.grid.major.y = element_line(colour=""darkgrey""),
    plot.title=element_text(size=16, face=""bold"", hjust=0, color=""black""),
    plot.subtitle=element_text(size=15, hjust=0, color=""black""),
    plot.caption=element_text(size=12, color=""darkgrey""))    

#Run it!
p2
","Other-4"
"697",395,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Birds.R","#TidyTuesday
#===============================================================================
#TidyTuesday
# Birds of feather...collide together?!
#ChordDiagram
#@sil_aarts
#===============================================================================

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

#Load libraries
library(tidyverse)
library(viridis)
library(patchwork)
library(hrbrthemes)
library(circlize)
library(dplyr)
library(RColorBrewer)
library(chorddiag)  
library(wesanderson)

#Read file
birds <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

#Check what is in the data!
unique(birds$family)
unique(birds$species)
unique(birds$genus)

#Which birds ten to hurt themselves the most?
birds2 <- birds %>% group_by(species, family) %>% mutate(count = n())

#Just check if aggregation worked
birds_check <- birds %>%
  count(species)

#Select unique rows (first delete date)
birds2$date <- NULL
birds3 <- unique(birds2)
#Only select MP
birds4 <- birds3 %>%
  filter(locality==""MP"")

#Select ony those colums we need for our ChordDiagram
birds5 <- birds4 %>%
   select(2,4,8)

#Select birds who hurt themselves the most: top 10
birds6 <- birds5[order(-birds5$count),] 
birds7 <- birds6 %>%
 filter(count > 2300)

#Divide by 1000 for ease of use
birds7$count <- birds7$count/1000

#Change colnames
colnames(birds7) <- c(""names"", ""key"", ""value"")

#Make some colours (n=14 for # of sectors )
pal <- wes_palette(""IsleofDogs1"", 14, type = ""continuous"")

#Set some parameters
circos.clear()
circos.par(start.degree = 90, gap.degree = 5, track.margin = c(-0.1, 0.1), points.overflow.warning = FALSE)
par(mar = rep(0, 5))

#ChordDiargram plot
chordDiagram(
  x = birds7, 
  grid.col = pal,
  transparency = 0.25,
  directional = 1,
  direction.type = c(""arrows"", ""diffHeight""), 
  diffHeight  = -0.03,
  annotationTrack = ""grid"", 
  annotationTrackHeight = c(0.05, 0.8),
  link.arr.type = ""big.arrow"", 
  link.sort = TRUE, 
  link.largest.ontop = TRUE)

#Add axis all around and text using the labels
circos.trackPlotRegion(track.index = 1, bg.border = NA, 
#Set sector.index
panel.fun = function(x, y) {
    xlim = get.cell.meta.data(""xlim"")
    sector.index = get.cell.meta.data(""sector.index"")
    
#Add names to the sector, make it facing inside, size letters=cex
circos.text(x = mean(xlim), y = 3, labels = sector.index, facing = ""inside"", cex = 0.8)
    
#Add ticks on axis
circos.axis(h = ""top"", minor.ticks = 1, major.tick.percentage=1, labels.niceFacing = FALSE) }
)


","Other-5"
"698",396,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_BoardGames.R","#TidyTuesday
#Board Games: love it! Especially, Monopoly and 'Colonisten van Catan'!

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(wordcloud)
library(RColorBrewer)
library(tidyr)
library(tidytext)
library(stopwords)
library(tm)

#Read file
games<- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")

#Select only one variabele
games_des <- select(games, select=""description"")

#Column name
colnames (games_des) <- c(""games"")

#Every word one vector
games_des2 <- games_des %>% 
  unnest_tokens(word, games) 

#Delete stopwords
games_des3 <- games_des2 %>% 
anti_join(get_stopwords(language=""en"", source=""snowball""))
  
#Do some cleaning!
games_des3$word <- removeNumbers(games_des3$word, ucp = FALSE)
games_des3$word <- str_replace(games_des3$word, "";"", """")
games_des4 <- games_des3[games_des3$word!="""",]

#Frequency words
games_des5 <- games_des4 %>% count(word, sort=T)
sort(games_des5$n)

#Wordcloud
set.seed(1234)
wordcloud(words = games_des5$word, freq = games_des5$n, min.freq = 1,scale=c(2,0.5),
          max.words=50, random.order=FALSE, use.r.layout=FALSE, rot.per=0.35, colors=brewer.pal(8, ""Dark2""))

#Make some colors (12 instead of 8 from Dark2)
nb.cols <- 12
mycolors <- colorRampPalette(brewer.pal(8, ""Dark2""))(nb.cols)

#Filter
p <- games_des5 %>% 
  filter (n > 5000) %>%
#Make GGplot
  ggplot(aes(x = word, y = n)) +
  geom_bar(stat = ""identity"", fill=mycolors)+
  geom_text(aes(label=word), hjust=""left"", nudge_y = 0.5, size = 4, family=""Comic Sans MS"")+
  ggtitle(label = ""TidyTuesday"", subtitle=""Wanna play a (board) game?"")+
  xlab("""")+ ylab(""# of occurences"")+labs(caption=""Source: Board Game Geeks, Plot by @sil_aarts"")+
  theme_minimal(10) +
  theme(legend.position = ""none"",
        text=element_text(family=""Comic Sans MS""),
        plot.title=element_text(size=14, hjust=0, face='bold'),
        plot.subtitle=element_text(size=13, hjust=0, face='italic'),
        plot.caption=element_text(size=8, hjust=1),
        axis.text.x = element_text(size=10),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())+
  coord_flip()

#Run it!
p

","Other-6"
"699",397,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Brexit.R","#TidyTuesday
#Brexit
#The Economist
#@sil_aarts

#Load libraries
library(tidyverse)
library(RColorBrewer)
library(gganimate)
library(dplyr)
library(cowplot)
library(ggplot2)

#Load data
brexit <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/brexit.csv"")

#Change colnames for ease of use
colnames(brexit) <- c(""date"",""perc_right"",""perc_wrong"")

#Merge columns
brexit2 <- data.frame(brexit$date, percent = c(brexit$perc_right,brexit$perc_wrong))

#Add ID and then >85 = wrong
brexit2$ID <- seq.int(nrow(brexit2))

#New column right/wrong
brexit2$Choice <- NA
for (i in 1:nrow(brexit2))
{
  if (brexit2$ID[i] > 85) { brexit2$Choice[i] <- ""wrong""} else {brexit2$Choice=""right""}
}
brexit2$ID <- NULL

#Change date format
brexit2$date <- as.Date(brexit2$brexit.date, format=""%d/%m/%y"")

#GGplot: right
p <- brexit2 %>%
  filter(Choice==""right"") %>%
  ggplot(aes(x = date, y = percent)) + 
  geom_line(aes(color = Choice), size = 1) +
  scale_color_manual(values = c(""navy"")) +
  scale_x_date(date_labels=""%m-%y"")+
  theme_cowplot()+
  theme(
  axis.text.x = element_text(angle = 90, hjust = 1),
  axis.title.x=element_blank())+
  labs(caption=""Source: The Economist | Plot by: @sil_aarts"",
       y=""%"")
    
#Including line (mean)
p1 <- p + stat_smooth(
  color = ""tomato"", fill = ""red"",
  method = ""loess"")

p1

#GGplot: wrong
p2 <- brexit2 %>%
  filter(Choice==""wrong"") %>%
  ggplot(aes(x = date, y = percent)) + 
  geom_line(aes(color = Choice), size = 1) +
  scale_color_manual(values = c(""skyblue"")) +
  scale_x_date(date_labels=""%m-%y"")+
  theme_cowplot()+
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1),
    axis.title.x=element_blank())+
  labs(y=""%"")

#Including line (mean)
p3 <- p2 + stat_smooth(
  color = ""tomato"", fill = ""red"",
  method = ""loess"")

p1
#Put both plots into one plot
p4 <- ggdraw() +
    draw_plot(p1+theme(legend.position=""none""), 0, 0, 1, 1) +
    draw_plot(p3+theme(legend.position=""none""), 0.5, 0.6, 0.45, 0.4) +
    draw_plot_label(c(""A.Right"", ""B.Wrong""), c(0.07, 0.56), c(1, 1), size = 10)

#Run finale plot!
p4
","Other-7"
"700",398,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_FIFA.R","#TidyTuesday
#FIFA!
#Why? Because I love soccer

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(ggmap)
library(zipcode)
library(ggthemes)
library(extrafont)
library(emoGG)

#Read file
fifa <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018/2018-06-12/week11_fifa_audience.csv"")

#Delete first column
fifa$X1 <- NULL

#Select multiple countries which the Dutch still have matches against in 2019
selection <- c(""Netherlands"", ""United Kingdom"", ""Germany"", ""Estonia"", ""Belarus"")
fifa2 <- filter(fifa, country %in% selection)

#Estonia is all NULL so delete that row!
fifa3 <- fifa3[-c(5),]

#GGplot
p <- ggplot(fifa3, aes (country, tv_audience_share)) + geom_emoji(emoji=""26bd"")+
  ggtitle(label = ""TidyTuesday (2018): World Cup 2010 TV audience"", subtitle=""The Dutch team and some countries we still have to play against in 2019"")+
  xlab("""")+ ylab(""Tv viewership (% of population)"")+labs(caption=""Source: fivethirtyteight.com | Plot by: @sil_aarts"")+
  coord_flip()+
  theme_tufte()+
  theme(panel.background = element_rect(fill = ""darkgreen""),
        text=element_text(family=""Comic Sans MS""),
        plot.title = element_text(color=""black"", face=""bold"", size=16, hjust=0),
        plot.subtitle=element_text(size=14, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=12, hjust=1, color=""black""),
        legend.title = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x= element_text(size=10, vjust = 0.5, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=14,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.5, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))
  
#Run it!
p
","Other-8"
"701",399,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_FRDspendingNIH.R","#TidyTuesday 
#Week 7: FRD Spendings on NIH

#Load libraries
library(ggplot2)
library(devtools)
library(gganimate)

#Read data from github
Spendings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-12/fed_r_d_spending.csv"")

#Let's check National Institutes of Health where I worked for 4 months (NIA, Bethesda)
Spendings <- subset(Spendings, department==""NIH"")

#Divide all by 1 miljoen
Spendings$FRD <- Spendings$total_outlays/100000000
Spendings$GDP <- Spendings$gdp/100000000

#GGplot - geom_line 
p <- ggplot(Spendings, aes(x = year, y = GDP))+
  geom_line(aes(x=year, y=FRD), size=1.2, alpha = 0.6, col=""darkslateblue"")+
  geom_label(data=Spendings[23,], aes(x=year, y=FRD, label=""Total FRD Budget""), size =3, alpha=0, vjust=0.03, hjust= 1, col=""darkblue"")+
  geom_line(aes(x=year, y=GDP), size=1.2, alpha = 0.6, col=""darkcyan"")+
  geom_label(data=Spendings[23,], aes(x=year, y=GDP, label=""Total US Gross Domestic Product""), size =3, alpha=0, vjust=1, hjust= 1.2, col=""darkcyan"")+
  ggtitle(label = ""Federal R&D Budget and Total Gross Domestic Product"", subtitle=""Fiscal Years: from 1976 until 2017 (in millions of dollars)"")+
  xlab(""Year"")+ 
  ylab(""Spendings"")+
  labs(caption=""Source: Federal Research and Development Spending. Plot by sil_aarts"")+
  transition_reveal(year)
    
#Run animation
p

#Save gif, using 80 frame (100=default)
anim_save(""Desktop/R/TidyTuesday/TidyTuesday_week7.gif"")
","Other-9"
"702",400,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Female earnings II.R","#TidyTuyesday
#Female earnings II

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(readr)

#Read file
female <- read.csv(""Desktop/employed_gender.csv"")

#Subset
female2<- subset(female, year %in% c(1970, 1980, 1990, 2000, 2010))

#Create new data.frame
female3 <- data.frame(part_time = c(female2$part_time_female, female2$part_time_male))
female3$sex <- ifelse(female3$part_time < 20,  c(""male""), c(""female"")) 
female3$year <- c(1970, 1980, 1990, 2000, 2010, 1970, 1980, 1990, 2000, 2010)

#Create colours
fill <- c(""darkmagenta"", ""darkkhaki"")

#GGplot- bar
p <- ggplot(female3, aes(x=year, y=part_time, fill=sex)) + 
  geom_col(position=""dodge"")+
  scale_fill_manual(values=fill)+
  ggtitle(label = ""TidyTuesday: women in the workplace"", subtitle=""Are you working part-time?"")+
  xlab("""")+ ylab(""% of employed"")+labs(caption=""Source: Bureau of Labor,  Plot by @sil_aarts"")+
  theme(panel.background = element_rect(fill = ""white""),axis.line = element_line(size=1, colour = ""black""),
        plot.title = element_text(color=""black"", face=""bold"", size=14, hjust=0),
        plot.subtitle=element_text(size=13, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=10, hjust=1, color=""azure4""),
        legend.title = element_blank(),
        axis.text.x= element_text(size=10,angle = 90, vjust = 0.5, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.5, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold"")
  )

#Check it
p

#Animate it
p+ transition_states(year,wrap=F) +
  shadow_mark()
  
#Save it!
animate(p, height = 600, width =600)
anim_save(""Desktop/R/TidyTuesday/Female_earningsII.gif"")
","Other-10"
"703",401,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Female earnings.R","#TidyTuyesday
#Female earnings
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(gapminder)
library(RColorBrewer)
library(extrafont)
library(readr)

#Read file
female <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"")

#Year to unique
year2 <- unique(female$Year)

#GGplot - geom_area
p <- ggplot(female, aes(x = Year, y = percent, group=group, color=group))+
  geom_line(aes(x=Year, y=percent))+
  scale_color_manual(values = c(""grey"", ""grey"", ""pink"", rep(""gray"", 4), ""black""))+
  geom_point(aes(colour=group), size=2)+   
  ggtitle(label = ""TidyTuesday: Women in workplace"", subtitle=""Female salary percent of male salary"")+
  xlab(""Year"")+ ylab(""Percentage"")+labs(caption=""Source: Bureau of Labor,  Plot by @sil_aarts"")+
  theme(panel.background = element_rect(fill = ""white""),axis.line = element_line(size=1, colour = ""black""),
        plot.title = element_text(color=""black"", face=""bold"", size=16, hjust=0),
        legend.title = element_blank(),
        plot.subtitle=element_text(size=12, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=8, hjust=1, color=""azure4""),
        axis.text.x= element_text(size=10,angle = 90, vjust = 0.5, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.5, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""),
  )

#Check it
p 

#GGplot save
ggsave(""Desktop/R/TidyTuesday/Female_earnings.png"")
","Other-10"
"704",402,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_French delays.R","#TidyTuesday
#French train delays
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(gapminder)
library(RColorBrewer)
library(extrafont)

#Read file
trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")
summary(trains)

#Select only a few variabeles
trains2 <- select(trains, 1:4,7,8, 10,24, 26,27)

#Filter only national services
trains3 <- filter(trains2, trains2$service == ""National"")

#Summarise some variables
trains4 <- trains3 %>% 
  group_by(departure_station, year) %>% 
  summarise(total_num_trips = sum(total_num_trips, na.rm=T),
            num_of_canceled_trains=sum(num_of_canceled_trains, na.rm=T),
            num_late_at_departure=sum(num_late_at_departure, na.rm=T),
            num_greater_15_min_late = sum(num_greater_15_min_late, na.rm=T),
            num_greater_30_min_late = sum(num_greater_30_min_late, na.rm=T),
            num_greater_60_min_late = sum(num_greater_60_min_late, na.rm=T)) %>% 
  ungroup(trains4)

#Make a new variable regarding percentage of total trips
trains4$percentage_late <- (trains4$num_late_at_departure/trains4$total_num_trips)*100

#Order data file by percentage_late to see top of stations
trains5 <-  trains4[order(-trains4$percentage_late),] 

#Select those trainstations of which one year is >25 percentage delays
trains6 <- trains5 %>%
  group_by(departure_station) %>%
  filter(any(percentage_late > 20))%>%
  ungroup(trains6)

#Change one rowname
trains6$departure_station[trains6$departure_station==""CHAMBERY CHALLES LES EAUX""] <- ""CHAMBERY CHALLES""

#Make sure every bar has a distinct colour: we need 59 bars!
nb.cols <- 12
mycolors <- colorRampPalette(brewer.pal(12, ""Blues""))(nb.cols)

#GGplot with animation
p <- ggplot(data=trains6, aes(x=departure_station, y=percentage_late)) + 
  geom_col(aes(fill=departure_station), width = 0.8)+
  coord_polar()+
  scale_fill_manual(values = mycolors)+
  transition_time(year)+
  labs(title=""Stations with >20% 'late at departure' in at least one year"", 
       subtitle=""% late at departure (of total number of trips) in {round(frame_time)}"",
       x="""", 
       y="""",
       caption=""Source: SNCF OPEN DATA, Plot by @sil_aarts"")+
  theme_minimal(10) +
  theme(legend.position = ""none"",
        text=element_text(family=""Courier""),
        plot.title=element_text(size=12, hjust=0.2, face='bold'),
        plot.subtitle=element_text(size=11, hjust=0.2),
        plot.caption=element_text(size=9, hjust=0.2),
        axis.text.x = element_text(size=9, hjust=0.1, face='bold'),
        axis.title.x = element_blank(),
        axis.ticks.y = element_blank())

#Run it!
p

#GGplot save
animate(p, height = 700, width =700)
anim_save(""Desktop/R/TidyTuesday/French_delaysII.gif"")

","Other-11"
"705",403,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_GrandSlams.R","#TidyTuesday
#Tennis
#Grand Slams!

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(extrafont)
library(emoGG)

#Load File
tennis <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

#Delete NA
tennis2 <- tennis[!is.na(tennis$grand_slam), ]

#Add ID, check data and then >48 is male
tennis2$ID <- seq.int(nrow(tennis2))

#Create new column
tennis2$sex <- NA
#Loop for male and female
for (i in 1:nrow(tennis2))
{
  if (tennis2$ID[i] > 48) { tennis2$sex[i] <- ""Male""} else {tennis2$sex=""Female""}
}

#Age in years
tennis2$age_years <- (tennis2$age/365)

#Make z-scores
tennis2$age_zscore <- ave(tennis2$age_years, tennis2$sex, FUN=scale)
#Make a 0/1 variabele
tennis2$age_groups <- ifelse(tennis2$age_zscore < 0, ""below"", ""above"")

#Check mean age for Females and Male
tennis2 %>%
  group_by(sex) %>%
  summarise(mean_age= mean(age_years))

#Dicimals check 
tennis3 <- tennis2 %>% 
  mutate_if(is.numeric, round, digits = 1)

#Oeps, we see that some 0.0 are below and some above. 
#If mean age_zscore is around 0.0 (0.05 more or less) > age_groups=mean=22.8
for (i in 1:nrow(tennis3))
{
  if (tennis3$age_zscore[i] > -0.05 && tennis3$age_zscore[i] < 0.05) { tennis3$age_groups[i] <- ""mean""} 
}

#GGplot: divergrent lollipop plot
p <- tennis3 %>%
  filter(sex==""Female"") %>%
  ggplot(aes(x=name, y=age_zscore, label=age_zscore)) + 
  geom_segment(aes(y = 0, 
                   x =name, 
                   yend =age_zscore, 
                   xend = name)) +
  geom_point(stat=""identity"", aes(colour=age_groups), size=6)+ 
  scale_colour_manual(name=""Average age: 22.8"", 
                    labels = c(""Above Average"",""Below Average"", ""Mean""), 
                    values = c(""darkgreen"",""limegreen"", ""springgreen""))+
  add_emoji(emoji=""1f3be"")+
  geom_text(color=""black"", size=3, family=""Helvetica"") +
  labs(title=""TidyTuesday: Female Tennis Grand Slams"", 
       subtitle=""Age at first Grand Slam title (z-scores)"",
       caption=""Source: Wikipedia | Plot by: @sil_aarts"",
        y=""age in years (z-scores)"")+
  theme_light()+
  theme(
    axis.title.x = element_text(size=12, face=""bold"", family=""Times""),
    axis.title.y = element_blank(),
    axis.text.y = element_text(size=10, face=""bold"", family=""Times""),
    plot.title=element_text(size=20, face=""bold"", family=""Times""),
    plot.subtitle=element_text(size=18, family=""Times""),
    plot.caption=element_text(size=10, family=""Times""))+
  ylim(-3,3)+
  coord_flip()

#Run it
p
","Other-12"
"706",404,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Horror.R","#TidyTuesday
#===============================================================================
#THE HORROR!
#@sil_aarts
#===========================================================================
#Load libraries
library(tidyverse)
library(showtext)
library(showtextdb)
library(ggmap)
library(ggthemes)
library(grid)
library(gridExtra)
library(magick)

#Load files
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

#Select only rows with non-missing filming_locations
data1 <- data %>%
  drop_na(filming_locations)

#String split on filming_locations
data2 <- data1 %>%
  separate(filming_locations, c(""place"", ""city"", ""state""), "","")

#Change value of a column to another column on conditon
data3 <- mutate(data2, city = ifelse(city== ""USA"", city, place))
data3$city[data3$city == ""Wellington""] <- ""Florida""

#Select 20 most horrible movies!
data4 <- data3 %>%
  top_n(-20, review_rating)

#Merge long & lat
data5 <- data4 %>%
  drop_na(city)
register_google(key = ""Your key here"") 
geo <- geocode(data5$city) 
data6 <- merge(data5, geo, by.x = 0, by.y = 0)

#Add an image
image <- image_read(""https://cdn.pixabay.com/photo/2015/06/22/23/21/filmklappe-818198_960_720.jpg"")
image2 <- image_read(""https://www.nicepng.com/png/full/439-4394330_free-blood-drip-png-real-blood-effect-png.png"")
movie <- grid::rasterGrob(image, interpolate = T) 
blood <- grid::rasterGrob(image2, interpolate = T)

#Pixels!
#Low resolution is lot of dots. High is 'dotless'.
resolution <- 1.5
lat <- tibble(lat = seq(-90, 90, by = resolution))
long <- tibble(long = seq(-180, 180, by = resolution))
#Lakes are optional
pixels <- merge(lat, long, all = TRUE) %>%
  mutate(country = maps::map.where(""world"", long, lat),
         lakes = maps::map.where(""lakes"", long, lat)) %>% 
  filter(!is.na(country) & is.na(lakes)) %>%
  select(-lakes)

#Choose font
font_add_google(""Barrio"", ""C"")
showtext_auto()

#Theme
theme <-  theme_map() +
  theme(
    text = element_text(family=""C""),
    plot.background = element_rect(fill = ""white"", color = NA),
    panel.background = element_rect(fill = ""white"", color = NA), 
    plot.title= element_text(size = 50, color=""red"", hjust=0.5),
    plot.subtitle= element_text(size = 14, color=""black"", hjust=0.5),
    plot.caption = element_text(size = 10, color=""red""),
    panel.grid = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank())
    

#GGplot: ggmap
pixelsmap <- ggplot() + 
    geom_point(data = pixels, aes(x = long, y = lat), color = ""grey30"", size = 1)

#Run quartz for showtext
quartz()

#GGplot: ggmap
p <- pixelsmap + 
  geom_point(data =data6, aes(x = lon, y = lat), color = ""red"", size = 2) +
  geom_point(data =data6, aes(x = lon, y = lat), color = ""red"", size = 4, alpha=0.4)+
  #Peru
  annotation_custom(movie, xmin= -110, xmax= -150, ymin= -40, ymax= -10)+
  geom_text(aes(x = -130, y = -30), label=""Lima, Peru (2017)\nUna Comedia\nMarcabia\nRating 1.0"", color=""white"", size=2.5, family=""C"")+
  annotation_custom(blood, xmin= -110, xmax= -150, ymin= -50, ymax= -40)+
  #Russia
  annotation_custom(movie, xmin= 130, xmax=170, ymin=10, ymax=40)+
  geom_text(aes(x = 150, y = 20), label=""Pereslavl-Zalessky\nRussia (2017)\nInterstelar 2:\nOperation Terra 2040\nRating 1.6"", color=""white"", size=2.1, family=""C"")+
  annotation_custom(blood, xmin= 130, xmax= 170, ymin= 0, ymax= 10)+
  labs(title= ""THE HORROR"", 
       subtitle=""Where were the most 'horrible' movies shot? Locations where movies with ratings <2.0 were filmed*."", 
       caption=""*Scale 1 (low) - 10 (high) rating | Source: IMDB | Plot by: @sil_aarts"")+
  coord_sf(clip = ""on"",
           ylim = c(-75, 85),
           xlim = c(-160, 170))+
  theme

#Run it!
p
","Other-13"
"707",405,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Meteorites.R","#TidyTuesday
#===============================================================================
#Rainclouds of meteorites.
#@sil_aarts
#===============================================================================
install.packages(""magick"")
install.packages(""grid"")
install.packages(""gridExtra"")

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(tidyr)
library(extrafont)
library(magick)
library(grid)
library(gridExtra)

#Load file
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

#Check levels
data$class <- as.factor(data$class)
levels(data$class)

#Check unique
data$id <- NULL
data2 <- unique(data)

#Only non-missing data
data2$class <- as.character(data2$class)
data3 <- na.omit(data2)

#Select data from 2000 onwards
data4 <- data3 %>% 
  filter(year > 1999)

#Count number of meteorites per class
data5 <- data4 %>%
  group_by(class) %>%
  mutate(count = n())

#Order data on count peer class
data5$count <- as.numeric(data5$count)
data6 <- data5[order(-data5$count),] 

#Select 2 columns to see top 5 class: L6, L5, H5, H6, LL6
data7 <- data6 %>%
  select(3,10)
data8 <- unique(data7)

#Select original dataset with only those 5 top classes that fall on Earth
data_final <- data6 %>%
  filter(class==""L6"" | class==""L5"" | class==""H5""| class==""H6""| class==""LL6"")

#Make some colours
col <- c(""darkred"",""#FC3D21"", ""cornflowerblue"" ,""dodgerblue4"",""#0B3D91"")

#Add Images
#Add image NASA
image2 <- image_read(""Desktop/Nasa.jpg"")
NASA <- grid::rasterGrob(image2, interpolate = T) 
#Add background image: meteorites
image3 <- image_read(""Desktop/meteo.jpg"")
meteo <- grid::rasterGrob(image3, interpolate = T) 

#Calculate year of most meteorites:
data_year <- data_final %>%
  group_by(year) %>%
  mutate(count_year = n())
data_year <- data_year[order(-data_year$count_year),] 

#Start using my own theme
theme_sil <- theme_void() + 
  theme(
    legend.position = ""none"",
    text = element_text(size = 10, family=""Courier New""),
    plot.background = element_rect(fill=""black""),
    panel.background = element_rect(fill= ""transparent""),
    plot.title=element_text(size=20, hjust=0, face='bold', colour=""white"", lineheight = 1),
    plot.subtitle=element_text(size=16, hjust=0, colour=""white""),
    plot.caption=element_text(size=10, hjust=1, colour=""white""),
    axis.text = element_text(size = 12, colour=""white"", face=""bold""))

#GGplot
p <- ggplot(data = data_final, aes(x = class, y = year, fill = class)) +
  annotation_custom(rasterGrob(image3, width = unit(1,""npc""), height = unit(1,""npc"")),-Inf, Inf, -Inf, Inf)+
  annotation_custom(NASA, xmin=0, xmax=1, ymin=1998.5, ymax=1999.5)+
  geom_point(aes(y = year, color = class), position = position_jitter(width = .15), size = 1.5, alpha = 0.8) +
  geom_boxplot(width = .3, alpha = 0.8, colour = ""white"", outlier.shape = 1) +
  geom_flat_violin(position = position_nudge(x=0.25, y=0), alpha = .7) +
  labs(title = ""TidyTuesday: Meteorites"" ,
       subtitle = ""The 5 classes of meteorites that have fallen to Earth the most since 2000"" ,
       caption=""Source: NASA | Plot by @sil_aarts"")+
  scale_fill_manual(values=col)+
  scale_color_manual(values=col)+
  scale_y_continuous(breaks=seq(2000, 2013, 2))+
  coord_flip(clip=""off"")+
  theme_bw() +
  theme_sil

#Run it
p
","Other-14"
"708",406,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Mismanagedwaste.R","#TidyTuesday
#===============================================================================
#Mismanaged waste around the world; waste no more...
#@sil_aarts
#===============================================================================

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(extrafont)

#Load data
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

#Take only with per capita plastic waste: omit the rest, so leaving only data for 2010
data1 <- na.omit(data)

#Change colnames for ease of use: per capita plastic waste, kg per person per day | gpd in $
colnames(data1)[4] <- c(""capita_mis"")
colnames(data1)[5] <- c(""gdp_capita"")

#Order the data
data2 <- data1[order(-data1$capita_mis),] 

#Make a variabele regarding percentage of Sri Lanka
data2$perc <- NA
data2$perc <- (data2$capita_mis/0.299)*100

#Select countries with highest waste < selecting by percentage of Sri Lanka
data3 <- data2 %>%
  top_n(36)

#Change some country names for ease of use
data3$Entity[5] <- ""Trinidad & Tobago""
data3$Entity[33] <- ""Sao Tome""

#Order countries based on percentage
data3$Entity <- factor(data3$Entity, levels=data3$Entity[order(-data3$perc)])

#GGplot: multiple piecharts
p <- data3 %>%
  ggplot(aes(x="""", y=perc, fill=perc)) +
  geom_bar(width = 1, stat = ""identity"", fill = ""darkgoldenrod3"", colour = ""black"") +
  coord_polar(""y"", start=0) + facet_wrap(~ Entity) +
  labs(title = ""TidyTuesday: Mismanaged plastic waste"",
       subtitle=""Countries based on kg per person per day as % of Sri Lanka.\nSri Lanka is, with 0.299kg per person per day, the country on 'top'."",
       caption = ""Source: Our World in Data | Plot by @sil_aarts"")+
  theme_minimal()+
  theme(
    plot.background = element_rect(fill = ""grey54""),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid=element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank(),
    plot.title=element_text(size=18, face=""bold"", family=""sans""),
    plot.subtitle=element_text(size=15, family=""sans"", face=""bold"", colour=""white""),
    plot.caption=element_text(size=10, face=""bold"", family=""sans""))


#Run it! 'See those pacmans!'.
p
","Other-15"
"709",407,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_MovieRevenues.R","#TidyTuesday
#===============================================================================
#
#@sil_aarts
#===============================================================================

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(plotly)
library(LaCroixColoR)

#Read data
media <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

#Select some of the best movies!
media2 <- media %>%
  filter(franchise==""Shrek"" | franchise==""Frozen"" | franchise==""Cars"") 

#Change colnames for ease of use and clearity plotly
colnames(media2) [1:3] <- c(""Title"",""Category"",""Revenue"")

#Colours
col2 <- lacroix_palette(""PassionFruit"", n = 4, type = ""continuous"")

#Start using my own theme
theme_sil <- theme_void() + 
  theme(
    text = element_text(size = 10, family=""Courier"", colour=""white""),
    panel.background = element_rect(fill = ""transparent""),
    plot.background = element_rect(fill = ""black""),
    plot.title=element_text(size=18, hjust=0, face='bold', colour=""white"", lineheight = 1),
    plot.subtitle=element_text(size=18, hjust=0, colour=""white""),
    plot.caption=element_text(size=8, hjust=1, colour=""white""),
    axis.text = element_text(size = 12, colour=""white"", face=""bold""))


#Plotly
p <- ggplot(media2, aes(x=Title, y=Revenue, fill=Category)) +
  geom_col(alpha=0.8) +
  labs(title= ""TidyTuesday: revenues of three great movies (in Billion $)"")+
  scale_fill_manual(values=col2)+
  coord_flip()+
  theme_sil


#Run it!
p1 <- ggplotly(p) %>% 
  layout(annotations = 
           list(x = 1, y = -0.05, text = ""Source: Wikipedia, Media Frenchise Revenues | Plot by @sil_aarts."", 
                showarrow = F, xref='paper', yref='paper', 
                xanchor='right', yanchor='auto', xshift=0, yshift=0,
                font=list(size=12, color=""white""))
  )
p1
","Other-16"
"710",408,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Nobelprizes.R","#TidyTuesday
#Nobel prices

#Load libraries
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(ggplot2)
library(extrafont)

#Load data
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

#Filter only females
data1 <- data %>%
  filter(gender==""Female"")

#Add a column
data1[""count""] <- 1

#Aggregate: sum winners per category
data2 <- data1 %>%
  group_by(gender,category) %>% 
  mutate(count=n())

#Make soms colours
mycolors <- c(""#330244"",""#0050B6"",""#250462"",""#003E38"", ""#007067"",""#56416F"")

#GGplot: barchart
p <- ggplot(data=data2, aes(x=category)) + 
  geom_bar(aes(fill=category), width = 0.8)+
  scale_fill_manual(values = mycolors)+
  coord_polar()+
  labs(title=""TidyTuesday: Female Nobel Prize Winners"", 
       subtitle=""Number of Female Winners since first winner in 1903"",
       x="""", 
       y="""",
       caption=""Source: Kaggle | Plot by @sil_aarts"")+
  theme_minimal(10) +
  theme(legend.position = ""none"",
        panel.background = element_rect(fill = 'grey25'),
        plot.title=element_text(size=14, hjust=0.2, family=""Courier New"",face='bold'),
        plot.subtitle=element_text(size=12, hjust=0.2, family=""Courier New""),
        plot.caption=element_text(size=10, hjust=0.2,family=""Courier New""),
        axis.text.x = element_text(size=10, family=""Courier"", face=""bold"", colour=""white""),
        axis.text.y = element_text(size=9, family=""Courier"", face=""bold"", colour=""black""),
        axis.title.x = element_blank(),
        axis.title.y=element_blank(),
        axis.ticks.y= element_blank(),
        axis.ticks.x= element_blank())


#Run it!
p
","Other-17"
"711",409,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Nuclearexplosions.R","#TidyTuesday
#===============================================================================
#Nuclear Explotions
#@sil_aarts
#===========================================================================

#Load libraries
library(ggplot2)
library(dplyr)
library(zoo)
library(tidyverse)
library(ggtext)
library(extrafont)
library(ggforce)
library(showtext)
library(showtextdb)

#Load file
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")
summary(data)
data1 <- data_frame(unique(data$id_no))

#Sort 
data1 <- data[order(-data$magnitude_body),]
#How many explotions with mb=0?
data2 <- data1 %>%
filter(magnitude_body == 0)

#Choose font
font_add_google(""Anton"", ""Anton"")
showtext_auto()

#Make theme
theme_sil <- theme_void() +
  theme(
    plot.background = element_rect(fill = ""grey80""),
    text= element_text(family=""Anton"", face=""bold""),
    legend.text = element_text(margin = margin(0, 20, 0, 0)),
    legend.title = element_text(margin = margin(0, 20, 0, 0)),
    legend.text.align = 0,
    strip.text = element_blank(),
    panel.spacing = unit(2, ""points""),
    plot.margin = margin(20, 20, 20, 20),
    plot.title = element_text(size = 40, hjust = 0, colour=""darkred""),
    plot.subtitle = element_text(size = 25, hjust = 0),
    plot.caption = element_text(hjust = 1, size = 6)) 

#Run quartz for showtext
quartz()

#Make drawing
p <- ggplot()+
  #Circle 1: 7.4
  geom_hline(yintercept = 9, colour=""black"", size=0.5)+
  geom_circle(aes(x0 = -10, y0 = -1, r = 5), fill=""black"")+
  geom_rect(aes(xmin = -12.5, ymin = 1, xmax = -8.5, ymax = 2), fill= ""orange"",color = ""darkred"")+
  geom_text(aes(x = -11, y = 1.5), label=""MB: 7.4"", color=""white"", size=6, family=""Anton"")+
  geom_label(aes(x = -11, y = -0.5), label=""Year: 1987\nCountry: USSR\n Type: SHAFT"", color=""black"", size=3, family=""Anton"")+
  #Circle 2: 7.3
  geom_circle(aes(x0 = -5, y0 = -1, r = 4), colour=""black"", fill=""grey15"")+
  geom_rect(aes(xmin = -7, ymin = 0, xmax = -3, ymax = 1), fill= ""orange"", color = ""darkred"")+
  geom_text(aes(x = -5, y = 0.5), label=""MB: 7.3"", color=""white"", size=6, family=""Anton"")+
  geom_label(aes(x = -5, y = -1.5), label=""Year: 1987\nCountry: USSR\nType: SHAFT"", color=""black"", size=3, family=""Anton"")+
  #Circle 3: 7.2
  geom_circle(aes(x0 = 0, y0 = -1, r = 3), colour=""black"", fill=""grey25"")+
  geom_rect(aes(xmin = -2, ymin = -1, xmax = 2, ymax = 0), fill= ""orange"", color = ""darkred"")+
  geom_text(aes(x = 0, y = -0.5), label=""MB: 7.2** "", color=""white"", size=6, family=""Anton"")+
  geom_label(aes(x = 0, y = -2.5), label=""Year: 1985\nCountry: USSR\nType: SHAFT"", color=""black"", size=3, family=""Anton"")+
  #Circle 4: 0
  geom_circle(aes(x0 = 5, y0 = -1, r = 0.5), colour=""black"", fill=""grey45"")+
  annotate(""segment"", x= 5, xend = 5, y = 3, yend = -1, size=0.5)+
  annotate(geom=""label"", x= 5, y = 3, label = ""1.217 explosions\nhave an 'MB' of zero."", vjust=0.1, size=4, family=""Anton"", fontface=""bold"")+
  #Extra text
  annotate(geom=""label"", x= 10, y = -9, label = 
  ""* 'Biggest' is expressed in 'Body wave magnitude of explosion' (MB).\nBody-waves consist of P-waves or S-waves, or reflections of either. Body-waves travel through rock directly. Source: Wikipedia.
  ** Two explotions have an MB of 7.2. Based on magnitude surface, this explosion was chosen as the 3th biggest."", size=2.5, vjust=0.1, hjust=1, family=""Anton"")+ 
  labs(title=""NUCLEAR EXPLOTIONS"", 
       subtitle=""The three biggest explosions and the smallest ones.*"",
       caption=""Source: Stockholm International Peace Research Institute, SIPRI | Plot by: @sil_aarts"",
       y=""Age of death (z-scores)"")+
  coord_fixed()+
  theme_sil


#Run it!
p
","Other-18"
"712",410,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Petnames II.R","TidyTuesday
#Pet names II

require(devtools)
devtools::install_github(""dkahle/ggmap"", ref = ""tidyup"")

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(ggmap)
library(zipcode)

#Read file
seattle_pets <- read.csv2(""Desktop/R/TidyTuesday/26 maart Petnames/Seattle_Pet.csv"", stringsAsFactors=F, header=T)

#Change colname zipcode
colnames(seattle_pets) [c(3,7)] <- c(""name"", ""zip"")

#Data zipcode
Data(zipcode)

#Merge files
zipcode2 <- zipcode %>%
  filter(city==""Seattle"")
seattle_pets2 <- merge(seattle_pets, zipcode2, by.x='zip', by.y='zip')

#Filter: where is Wall-E?
seattle_pets3 <- seattle_pets2 %>%
  filter(name== ""Wall-E"")
  
  
#API key google
register_google(key = ""YOUR KEY HERE"")

#GGmap > Seattle
p <- ggmap(get_googlemap(center = c(lon = -122.335167, lat = 47.608013),
                         zoom = 11, scale = 2,
                         maptype ='terrain',
                        color=""color""))+
geom_point(aes(x = longitude, y = latitude, colour=name), data=seattle_pets3, size=3)+
scale_color_manual(values=""yellow"")+
    theme(legend.position=""none"",
    axis.text.x=element_blank(),
    axis.text.y=element_blank(),
    axis.title.x=element_blank(),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y=element_blank())

#Run it
p



","Other-19"
"713",411,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Petnames.R","#TidyTuesday
#Pet names!

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(readr)

#Read file
seattle_pets <- read.csv2(""Desktop/Seattle_Pet.csv"", stringsAsFactors=F, header=T)

#Keep only one col> name
pets <- seattle_pets[c(3)]

#Change colname
colnames(pets) <- c(""name"")

#Insert count
pets2 <- pets %>% count(name, sort=T)

#If vector is empty: insert ""Nameless pet""
for (i in 1:nrow(pets2))
{
  if (pets2$name[i]== """") { pets2$name[i] <- ""Nameless pet :-(""}
}

#Filter top 10 names in Seattle
pets3 <- pets2 %>%
  filter(n>227)

#Get percentages
pets4 <- pets3 %>%
  group_by(name) %>%
  summarise(n) %>%
  mutate(percentages = n/sum(n)*100)

#Percentage based on one decimal (round)
pets5 <- pets4 %>% 
  mutate_if(is.numeric, round, digits = 1)

#GGplot: pie chart 
p <- ggplot(pets5, aes(x = """", y=n , fill = factor(name))) + 
    geom_col(aes(fill = name), width = 1) +
    geom_text(aes(label = percentages), position = position_stack(vjust = 0.5)) +
    scale_fill_brewer(palette=""Set3"")+
    coord_polar(""y"")+
    labs(fill=""Pet name"", 
       x=NULL, 
       y=NULL, 
       title=""TidyTuesday: 'Sleepless (pets) in Seattle'"", 
       subtitle=""The 10 most used pet names in %"",
       caption=""Source: Seattle.gov | Plot by: @sil_aarts"")+
    theme_minimal()+
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      axis.text.x=element_blank(),
      panel.border = element_blank(),
      panel.grid=element_blank(),
      axis.ticks = element_blank(),
      plot.title=element_text(size=20, face=""bold""),
      plot.subtitle=element_text(size=18, face='italic')
  )

#Run it!
p

","Other-19"
"714",412,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_PhD_sex.R","#TidyTueasday
#How long does in take to get your Phd? Median PhD Years
#Does it differ per sex?
install.packages(""datapasta"")

#Load library
library(ggplot2)
library(dplyr)
library(datapasta)

#Datapaste, so less cleaning is necessary
data <- data.frame(
          V1 = c(58, 59),
          V2 = c(26.305, 22.397),
          V3 = c(57, 58),
          V4 = c(5.168, 6.335),
          V5 = c(57, 56),
          V6 = c(3.723, 1.831),
          V7 = c(57, 58),
          V8 = c(2.614, 836),
          V9 = c(60, 60),
         V10 = c(3.245, 4.614),
         V11 = c(53, 53),
         V12 = c(6.681, 2.086),
         V13 = c(63, 65),
         V14 = c(1.352, 2.878),
         V15 = c(70, 73),
         V16 = c(2.301, 2.4),
         V17 = c(54, 60),
         V18 = c(1.221, 1.417)
) 

#Delete columns 
data2 <- data[, c(1,3,9)]

#Add colnames
colnames(data2) <- c(""All fields"", ""Life Sciences"", ""Psychology and Social Sciences"")

#Add one variabele gender
sex <- c(""Male"", ""Female"")
data3 <- cbind(sex, data2) 

#All fields into one column
data4 <- data3 %>% gather(Field, Count, 2:4 )

#Divide by 10 to get median years
data4$Count <- data4$Count/10
  
#Labels
labels <- unique(data4$Field)

#GGplot
p <- ggplot(data4, aes(x=Field, y=Count, fill=sex))+
  geom_bar(stat=""identity"", position=position_dodge())+
  ggtitle(label = ""Getting your PhD in the U.S."", subtitle=""Median years to doctorate"")+
  labs(caption=""Source: National Science Foundation,  Plot by @sil_aarts"")+
  scale_x_discrete(limits=labels)+
  scale_fill_manual(values = c(""Male"" = ""powderblue"", ""Female""=""rosybrown1""))+
  geom_text(aes(label=Count), position=position_dodge(width=0.9), vjust=-0.25)+
  coord_flip()+ 
  theme_minimal(14) +
  theme(legend.position = ""bottom"",
        plot.title = element_text(size=18, hjust=0, color=""black"", face=""bold""),
        plot.subtitle=element_text(size=16, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=8, hjust=1, color=""black""),
        axis.text.x= element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank())
p

#Save plot
ggsave(""Desktop/R/TidyTuesday/TidyTuesday_PhDtime.png"", width = 20, height = 20)
","Other-20"
"715",413,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_PhDs.R","#TidyTuesday 18 februari 2019 - Doctorates U.S.
#Load library
library(ggplot2)
library(tidyr)
library(dplyr)

#Read file (original excel file: saved as csv)
data2 <- read.csv(""Desktop/R/Data_doc.csv"", header=T, sep = "";"")

#Transpose all but the first column and keep them numeric
data3 <- as.data.frame(t(data2[,-1]))
colnames(data3) <- data2[, 1]
data3 <- data.frame(lapply(data3, function(x) as.numeric(as.character(x))))

#Create a new column with years
Year <- c(1997, 2002, 2007, 2012, 2017)
data4 <- cbind(Year, data3)

#Select Psychology and Social Sciences
data5 <- data4 %>% 
  select(""Year"", ""Psychology.and.social.sciences."", ""Hispanic.or.Latino.4"",""American.Indian.or.Alaska.Native.4""
  ,""Asiana.4"", ""Black.or.African.American.4"", ""White.4"", ""More.than.one.race.4"",""Other.race.or.race.not.reportedb.4"")

#Change colnames for ease of use
colnames(data5) <- c(""Year"", ""Total"", ""Hispanic/Latino"", ""American Indian/Alaska Native"",
                     ""Asian"", ""African American"", ""Caucasian"", ""Multiple"", ""Other"")

#For two variables x1000 (to make sure they're thousands,'cause of the . as decimal)
data5 <- data5 %>% mutate(Total=Total*1000, Caucasian=Caucasian*1000)

#All ethnicities into one column
data6 <- data5 %>% gather(Ethnicity, count, 3:9)

#Alter the x-as for years using unique years; 1997, 2002, 2007, 2012, 2017
labels <- unique(data6$Year)

#GGplot bar
p <- ggplot(data6, aes(x=Year, y=count, fill=Ethnicity))+
  geom_bar(stat=""identity"", position=position_dodge())+
ggtitle(label = ""Getting your PhD in the U.S."", subtitle=""PhD awarded in Psychology & Social Sciences"")+
  xlab(""Year"")+ ylab(""Number of PhD awarded"")+labs(caption=""Source: NSF,  Plot by @sil_aarts"")+
  scale_x_discrete(limits=labels)+
  theme(panel.background = element_rect(fill = ""white""),axis.line = element_line(size=1, colour = ""black""),
  plot.title = element_text(color=""black"", face=""bold"", size=16, hjust=0),
  plot.subtitle=element_text(size=12, hjust=0, face=""italic"", color=""black""),
  plot.caption= element_text(size=8, hjust=1, color=""azure4""),
  axis.text.x= element_text(size=10,angle = 90, vjust = 0.5, hjust=1, colour='black'),
  axis.text.y= element_text(size=10, colour='black'),
  axis.title.x = element_text(color = ""black"", size = 18, angle = 0, hjust = 0.5, vjust = 1),
  axis.title.y = element_text(color = ""black"", size = 18, angle = 90, hjust = 0.5, vjust = 1)
)

#Run GGplot
p
","Other-21"
"716",414,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Plasticpolution.R","#TidyTuesday
#===============================================================================
#Plastic waste; waste no more...
#@sil_aarts
#===============================================================================

#Load libraries
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(extrafont)

#Load data
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

#Take only rows with per capita plastic waste: omit the others, leaving only 2010
data1 <- na.omit(data)

#Change colnames for ease of use: per capita plastic waste, kg per person per day | gpd in $
colnames(data1)[4] <- c(""capita_waste"")
colnames(data1)[5] <- c(""gdp_capita"")

#Order the data
data2 <- data1[order(-data1$capita_waste),] 

#Check the mean of all countries=0.198
data2 %>%
  summarise((mean_capita=mean(capita_waste)))

#Select 20 countries with most waste per capita > 0.296
data3 <- data2 %>%
  filter(capita_waste > 0.296)

#Check the mean of top 20 countries capita_waste=0.605
data3 %>%
  summarise((mean_capita=mean(capita_waste)))

#Check the median of top 20 countries capita_waste=0.411
data3 %>%
  summarise((median_capita=median(capita_waste)))

#GGplot: Barchart using annotations and curves
p <- data3 %>%
  ggplot(aes(x = Entity, y = capita_waste))+
  geom_hline(yintercept = 0.605, colour=""red"", size=0.8, linetype=""dashed"")+
  geom_hline(yintercept = 0.411, colour=""red"", size=0.8)+
  geom_bar(stat = ""identity"", color=""darkslategray3"")+
  coord_flip()+
  labs(title=""TidyTuesday: Plastic polution in 2010"", 
       subtitle=""Global plastic waste: 20 countries with the most waste in kg per person per day"",
       x="""", 
       y=""Plastic waste in kg per person per day"",
       caption=""Source: Our World in Data | Plot by @sil_aarts"")+
  annotate(geom=""label"", x=""Saint Lucia"", y = 3.3, label = ""Tinidad and Tobago:\n 3.6kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Seychelles"", xend = ""Trinidad and Tobago"", y = 3.6, yend = 3.6 ,size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  annotate(geom=""label"", x=""Netherlands"", y = 1.5, label = ""Netherlands:\n 0.424kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Netherlands"", xend = ""Netherlands"", y = 1, yend = 0.424, size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  annotate(geom=""label"", x=""Ireland"", y = 1.5, label = ""Mean of top 20 countries:\n 0.605kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Ireland"", xend = ""Ireland"", y = 1, yend = 0.605, size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  annotate(geom=""label"", x=""Grenada"", y = 1.55, label = ""Median of top 20 countries:\n 0.411kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Grenada"", xend = ""Grenada"", y = 1, yend = 0.411, size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  theme_classic()+
  theme(panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""grey30""),
        plot.title=element_text(size=18, hjust=0, family=""Courier New"",face='bold', colour=""white""),
        plot.subtitle=element_text(size=14, hjust=0, family=""Courier New"", colour=""white""),
        plot.caption=element_text(size=10, hjust=1,family=""Courier New"", colour=""white""),
        axis.text.x= element_text(size=10, family=""Courier"", face=""bold"", colour=""white""),
        axis.text.y= element_text(size=10, family=""Courier"", face=""bold"", colour=""white""),
        axis.title.x = element_text(size=10, family=""Courier"", face=""bold"", colour=""white""))

#Run it
p
","Other-22"
"717",415,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Policing.R","#TidyTuesday
#Stanford Open Policing project

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(RColorBrewer)
library(readr)

#Read file
combined_data <- readr::read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")
sort(combined_data$stops_per_year, decreasing=T)

#Alter stops per year for esthetics plot
combined_data$stops_per_year <- combined_data$stops_per_year/100

#GGplot: scatterplot: search rate by arrest rate
#Make colors for the states
nb.cols <- 17
mycolors <- colorRampPalette(brewer.pal(12, ""Paired""))(nb.cols)

#Make the plot (in my tweet about this plot I used geom_count, however, geom_point gives you all the states)
p4 <- ggplot(combined_data, aes(x=search_rate, y=arrest_rate)) + 
  geom_point(aes(col=state, size=stops_per_year)) + 
  xlim(c(0, 0.18)) + 
  labs(subtitle=""Stanford Open Policing Project: relating search rate(%) to arrest rate(%)"", 
       y=""Arrest rate %"", 
       x=""Search rate %"", 
       title=""TidyTuesday"", 
       size=""Stops per year*100"", 
       col=""State"",
       caption = ""Source: Stanford Open Policing Project | Plot by @sil_aarts"")+
  scale_color_manual(values = mycolors)+
  scale_size_continuous(breaks = 1:4, labels = c(""<1"",""1000"",""2000"",""3000""), limits = NULL, trans = ""identity"")+
  guides(size = guide_legend(override.aes = list(size = c(2:5))))+  
  theme(legend.background = element_rect(fill=""lightgrey"", size=0.5, linetype=""solid"", colour=""black""),
        panel.background = element_rect(fill = ""lightgrey""),
        panel.border = element_rect(colour = ""black"", fill=NA, size=0.5),
        panel.grid.major.x =element_blank(),
        panel.grid.major.y =element_blank(),
        panel.grid.minor.x =element_blank(),
        panel.grid.minor.y =element_blank(),
        plot.title = element_text(color=""black"", face=""bold"", size=14, hjust=0),
        plot.subtitle=element_text(size=13, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=10, hjust=1, color=""azure4""),
        legend.title = element_text(size=10, hjust=1, color=""black"", face=""bold""),
        axis.text.x= element_text(size=10, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.6, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))

#Run it
p4

#Make the plot: ZOOM IN!
p5 <- ggplot(combined_data, aes(x=search_rate, y=arrest_rate)) + 
  geom_point(aes(col=state, size=stops_per_year)) + 
  xlim(c(0, 0.05)) + 
  labs(subtitle=""Stanford Open Policing Project: relating search rate(%) to arrest rate(%): ZOOM IN"", 
       y=""Arrest rate %"", 
       x=""Search rate %"", 
       title=""TidyTuesday"", 
       size=""Stops per year*100"", 
       col=""State"",
       caption = ""Source: Stanford Open Policing Project | Plot by @sil_aarts"")+
  scale_color_manual(values = mycolors)+
  scale_size_continuous(breaks = 1:4, labels = c(""<1"",""1000"",""2000"",""3000""), limits = NULL, trans = ""identity"")+
  guides(size = guide_legend(override.aes = list(size = c(2:5))))+  
  theme(legend.background = element_rect(fill=""lightgrey"", size=0.5, linetype=""solid"", colour=""black""),
        panel.background = element_rect(fill = ""lightgrey""),
        panel.border = element_rect(colour = ""black"", fill=NA, size=0.5),
        panel.grid.major.x =element_blank(),
        panel.grid.major.y =element_blank(),
        panel.grid.minor.x =element_blank(),
        panel.grid.minor.y =element_blank(),
        plot.title = element_text(color=""black"", face=""bold"", size=14, hjust=0),
        plot.subtitle=element_text(size=13, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=10, hjust=1, color=""azure4""),
        legend.title = element_text(size=10, hjust=1, color=""black"", face=""bold""),
        axis.text.x= element_text(size=10, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.6, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))

#Run it
p5
","Other-23"
"718",416,"https://github.com/silaarts/Shiny_TidyTuesday","silaarts","Shiny_TidyTuesday","Female_earnings_app.R","#TidyTuesday
#Female earnings
#Shiny, first try

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(readr)
library(shiny)
library(rsconnect)

#Read file
female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"")

#Subset of file
female2 <- subset(female, year %in% c(1970, 1980, 1990, 2000, 2010))

#Make data.matrix
names(female2)[1] <- """"
female2 <-data.matrix(female2)

#Make variabele year -> rownames
female3 <- female2[,-1]
rownames(female3) <- female2[,1]

#Ui
ui <- fluidPage(
    titlePanel('TidyTuesday:
               Employment through the years for females and males'),
    sidebarLayout(
      sidebarPanel(
      selectInput(""region"", ""Type of employment by gender"",
                  choices=colnames(female3)),
      hr(),
      helpText(""Employment from 1970 to 2010, 
               Source: Bureau of Labor"")),
  mainPanel(
    plotOutput(""EmployeePlot"")
  )
)
)

#Server
server <- function(input, output) {
  
#Fill in the spot we created for the barplot
output$EmployeePlot <- renderPlot ({
    
#Barplot
barplot(female3[,input$region], 
            main="""",
            col = ""darkmagenta"", border = ""black"",
            ylab=""% employed"",
            xlab=""year"")
  })
}

#Run it
shinyApp(ui, server)








","Other-1"
"719",417,"https://github.com/silaarts/Shiny_TidyTuesday","silaarts","Shiny_TidyTuesday","Policing_app.R","#TidyTuesday
#Policing

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(readr)
library(shiny)
library(rsconnect)
library(RColorBrewer)
library(DT)

#Read file
combined_data <- readr::read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")

#Delete columns
data <- select(combined_data, -c(7, 9:11))

#ui
ui <- 
  fluidPage(
    plotOutput(""plot"", click = ""plot_click""),
    hr(),
    helpText(""Source: Stanford Policing Project | Plot by @sil_aarts""),
    fluidRow(
      column(5, 
        selectInput('driver_race',""Driver's race"", choices=unique(data$driver_race)),
        selectInput('state', ""State"", choices =unique(data$state)),
      column(8,
             h4(""Click the points for info!""),
             dataTableOutput(""click_info""))
      )
)
)

#server
server <- function(input, output) {
  
#Make scatterplot
 output$plot <- renderPlot({
        data <- data[data$driver_race == input$driver_race, ]
        data <- data[data$state == input$state, ]
        ggplot(data) +
          geom_point(aes(x = search_rate, y = arrest_rate, color=input$state, shape=input$driver_race)) +
          labs(x = ""search rate %"", 
               y = ""arrest rate %"", 
               title = ""TidyTueday: Search rate & arrest rate"")+
          theme(legend.background = element_rect(fill=""white"", size=0.5, linetype=""solid"", colour=""black""),
                panel.background = element_rect(fill = ""white""),
                legend.position = ""none"",
                panel.border = element_rect(colour = ""black"", fill=NA, size=0.5),
                panel.grid.major.x =element_blank(),
                panel.grid.major.y =element_blank(),
                panel.grid.minor.x =element_blank(),
                panel.grid.minor.y =element_blank(),
                axis.text.x= element_text(size=10, hjust=1, face='bold', colour='black'),
                axis.text.y= element_text(size=10,face='bold', colour='black'),
                axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.6, vjust = 1, face = ""bold""),
                axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))
    })

#Make Table
output$click_info <- 
  DT::renderDataTable(DT::datatable({
    nearPoints(data, input$plot_click)},

#Change lay-out table
options = list(pageLength = 5,dom = 'ftl', searching=FALSE), rownames = FALSE, escape = FALSE) %>%   
  formatStyle('state', color = 'white',backgroundColor = 'grey', fontWeight = 'bold'))
}


shinyApp(ui=ui, server=server)


","Other-2"
"720",499,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","01/tt_01.R","library(tidyverse)

##

nobel_winners <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")

##

glimpse(nobel_winners)
glimpse(nobel_winner_all_pubs)

##

library(scico)

##

nobel_winners %>%
  filter(!is.na(organization_city)) %>%
  group_by(organization_city) %>%
  summarise(n = n()) %>%
  top_n(10, n) %>%
  arrange(desc(n)) %>%
  ggplot(aes(x = reorder(organization_city, n), y = n)) +
  geom_bar(aes(fill = n), stat = 'identity', show.legend = FALSE) +
  scale_fill_gradientn(colours = scico(palette = 'oslo', 11, direction = -1)[2:11]) + ## 2:11 because oslo starts off white
  labs(title = ""learned places"", subtitle = ""cities with most nobel laureates"", 
       x = ""city"", y = ""number"") +
  coord_flip() +
  theme_rot() +
  ggsave(filename = ""bars.png"", height = 6, width = 6, dpi = 300)

##

nobel_winners %>%
  filter(!is.na(organization_city)) %>%
  group_by(prize_year, organization_city) %>%
  summarise(n = n()) %>%
  right_join(tibble(prize_year = 1901:2018)) %>%
  ggplot(aes(x = prize_year, y = n)) +
  geom_line(aes(colour = n), stat = 'identity', show.legend = FALSE) +
  scale_colour_gradientn(colours = scico(palette = 'oslo', 11, direction = -1)[2:11]) + ## 2:11 because oslo starts off white
  labs(title = ""learned places"", subtitle = ""cities with most nobel laureates"", 
       x = ""year"", y = ""city"") +
  theme_hor()

##

top <- 
  nobel_winners %>% 
  filter(!is.na(organization_city)) %>%
  group_by(organization_city) %>%
  summarise(n = n()) %>%
  top_n(9, n) %>%
  pull(organization_city)

##

nobel_winners %>%
  filter(!is.na(organization_city)) %>%
  group_by(organization_city, category) %>%
  summarise(n = n()) %>%
  filter(organization_city %in% top) %>%
  arrange(desc(n)) %>%
  ggplot(aes(x = category, y = n)) +
  geom_bar(aes(fill = n), stat = 'identity', show.legend = FALSE) +
  scale_fill_gradientn(colours = scico(palette = 'oslo', 11, direction = -1)[2:11]) + ## 2:11 because oslo starts off white
  labs(title = ""learned places"", subtitle = ""cities with most nobel laureates"", 
       x = ""category"", y = ""number"") +
  coord_flip() +
  facet_wrap(~ organization_city) +
  theme_rot() +
  ggsave(filename = ""facets.png"", height = 8, width = 8, dpi = 300)

##

nobel_winners %>%
  filter(!is.na(organization_city)) %>%
  group_by(organization_city, category) %>%
  summarise(n = n()) %>%
  ggplot(aes(x = n)) +
  geom_density(aes(fill = n), show.legend = FALSE) +
  scale_fill_gradientn(colours = scico(palette = 'oslo', 11, direction = -1)[2:11]) + ## 2:11 because oslo starts off white
  labs(title = ""distribution of cities"", subtitle = ""which prize requires the right milieux"", 
       x = ""number"", y = ""density"") +
  facet_wrap(~ category, nrow = 1) +
  theme_hor() +
  ggsave(filename = ""densities.png"", height = 6, width = 8, dpi = 300)

##

library(glue)

##

cities <- 
  bind_rows(nobel_winners %>%
              select(full_name, birth_city, birth_country) %>%
              rename(city = birth_city, country = birth_country) %>%
              mutate(type = ""birth""),
            nobel_winners %>%
              select(full_name, death_city, death_country) %>%
              rename(city = death_city, country = death_country) %>%
              mutate(type = ""death""),
            nobel_winners %>%
              select(full_name, organization_city, organization_country) %>%
              rename(city = organization_city, country = organization_country) %>%
              mutate(type = ""institution"")) %>%
  mutate(location = glue(""{city}, {country}"")) %>%
  drop_na()

##

glimpse(cities)

library(googleway)
library(glue)

geocoderesults <- tibble()

for (i in 476:length(unique(cities$location))){
  
  index <- i
  
  city <- as.character(unique(cities$location)[index])
  
  location <- google_geocode(city, key = ""YOURKEY"")
  
  located  <- tibble(city = city, 
                     name = c(location$results$formatted_address),
                     lat = c(location$results$geometry$location[1]),
                     lon = c(location$results$geometry$location[2]))
  
  geocoderesults <- bind_rows(geocoderesults, located)
  
  Sys.sleep(1)
  
}

rank_joinLocation <- left_join(allyears, geocoderesults)

cities_located <- 
  cities %>%
  left_join(rename(geocoderesults, 
                   location = city,
                   address = name)) %>%
  drop_na()

cities_located$lat

latlon <- tibble()

for (i in 1:length(pull(cities_located, lat))) {
  
  index <- i 
  
  Y <- cities_located$lat[[index]][1]
  X <- cities_located$lon[[index]][1]
  
  iteration <- tibble(lat = Y,
                      lon = X)
  
  latlon <- bind_rows(latlon, iteration)
  
}

cities_located <- 
  cities_located %>%
  select(-lat, -lon) %>%
  bind_cols(latlon)

##

library(rnaturalearth)
library(sf)

##

countries  <- 
  ne_countries() %>% 
  st_as_sf() %>%
  select(name) %>%
  st_transform(54030)

##

scico(palette = 'grayC', 10)

##

cities_shaped <- 
  cities_located %>%
  st_as_sf(coords = c(""lon"", ""lat"")) %>%
  st_set_crs(4326) %>%
  st_transform(st_crs(countries)) %>%
  st_coordinates() %>%
  as_tibble() %>%
  bind_cols(cities_located)

##

w <- ne_countries(scale = ""medium"", returnclass = ""sf"")

w_Poly <- bind_cols(w %>%
                      st_cast(""POLYGON"") %>%
                      st_cast(""MULTIPOINT"") %>%
                      st_cast(""POINT""), 
                    w %>%
                      st_cast(""POLYGON"") %>%
                      st_cast(""MULTIPOINT"") %>%
                      st_coordinates() %>%
                      as_tibble())

##

ggplot() +
  geom_sf(data = countries, 
          aes(), fill = '#696969', colour = '#FFFFFF', size = 0.1) +
  geom_point(data = cities_shaped %>%
               filter(type == ""institution""), 
             aes(x = X, y = Y, group = full_name, colour = full_name), show.legend = FALSE) +
  geom_line(data = cities_shaped %>%
              filter(type == ""institution""), 
            aes(x = X, y = Y, group = full_name, colour = full_name), show.legend = FALSE) +
  theme_map()

##

ggplot() +
  geom_polygon(data = w_Poly, 
               aes(x = X, y = Y, group = L1),
               fill = '#696969', colour = '#FFFFFF', size = 0.1) +
  geom_point(data = cities_shaped %>%
               filter(type == ""institution"") %>%
               group_by(location, lat, lon) %>%
               summarise(n = n()), 
             aes(x = lon, y = lat, colour = n), show.legend = FALSE) +
  scale_colour_gradientn(colours = scico(palette = 'oslo', 11, direction = -1)[2:11]) +
  scale_size_continuous(range = c(0, 20)) +
  coord_map(""ortho"", orientation = c(42.952287, -40.989156, 0)) +
  labs(title = ""learned places"", subtitle = ""cities with most nobel laureates"", 
       x = ""city"", y = ""number"") +
  theme_map() +
  ggsave(filename = ""locations.png"", height = 10, width = 10, dpi = 300)
","Other-01"
"721",500,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","02/match.R","library(tidyverse)
library(ggplot2)

################################ LIGHT ################################ 
################################ 
## Horizontal Emphasis
## White

theme_hor <- function () {
  theme_minimal() +
    theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_line(size=0.1, color='grey50'),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_line(size=0.5, color='black'),
          axis.line.y = element_blank(),
          axis.ticks.x = element_line(size=0.5, color='black'),
          axis.ticks.y = element_line(size=0.1, color='grey50'),
          axis.text.x = element_text(face = 'bold'),
          axis.text.y = element_text(face = 'bold'),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.margin = margin(20, 20, 20, 20),
          legend.position = 'none'
          )
}

## Black

theme_hor <- function () {
  theme_minimal() +
    theme(plot.background = element_rect(fill = 'white', colour = 'white'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_line(size=0.1, color='grey50'),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_line(size=0.5, color='black'),
          axis.line.y = element_blank(),
          axis.ticks.x = element_line(size=0.5, color='black'),
          axis.ticks.y = element_line(size=0.1, color='grey50'),
          axis.text.x = element_text(face = 'bold'),
          axis.text.y = element_text(face = 'bold'),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.margin = margin(20, 20, 20, 20),
          legend.position = 'none'
          )
}

## Flipped Horizontal

theme_rot <- function () {
  theme_minimal() +
    theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
          panel.grid.major.x = element_line(size=0.1, color='grey50'),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.y = element_line(size = 0.5, color='black'),
          axis.line.x = element_blank(),
          axis.ticks.y = element_line(size = 0.5, color='black'),
          axis.ticks.x = element_line(size = 0.1, color='grey50'),
          axis.text.x = element_text(face = 'bold'),
          axis.text.y = element_text(face = 'bold'),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black'),
          plot.margin = margin(20, 20, 20, 20), 
          legend.position = c(0.6, 0.2)
          )
}

################################
## Vertical Emphasis
## White

theme_ver <- function () {
  theme_minimal() +
    theme(plot.background = element_rect(fill = 'white', colour = 'white'),
          panel.grid.major.x = element_line(size=0.1, color='grey50'),
          panel.grid.major.y = element_line(size=0.1, color='grey50'),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.y = element_line(size = 0.5, color='black'),
          axis.line.x = element_blank(),
          axis.ticks.y = element_line(size = 0.5, color='black'),
          axis.ticks.x = element_line(size = 0.1, color='grey50'),
          axis.text.x = element_text(face = 'bold'),
          axis.text.y = element_text(face = 'bold'),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black'),
          plot.margin = margin(20, 20, 20, 20), 
          legend.position = c(.8, .4)
          )
}

## Black

theme_ver_black <- function () {
  theme_minimal() +
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_line(size=0.1, color='white'),
          panel.grid.major.y = element_line(size=0.1, color='white'),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.y = element_line(size = 0.5, color='black'),
          axis.line.x = element_blank(),
          axis.ticks.y = element_line(size = 0.5, color='black'),
          axis.ticks.x = element_line(size = 0.1, color='white'),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          axis.title.x = element_text(face = 'bold', color = 'white'),
          axis.title.y = element_text(face = 'bold', color = 'white'),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white'),
          plot.margin = margin(20, 20, 20, 20), 
          legend.position = 'none'
          )
}

################################
## Map Theme
## White

theme_map <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.caption = element_text(face = 'bold', colour = 'black'),
          plot.margin = margin(5, 5, 5, 5),
          strip.text = element_text(face = 'bold', colour = 'black'),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.position = 'none'
          )
  
}

## Legend

theme_map_legend <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'white', colour = 'white'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.margin = margin(20, 20, 20, 20),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.position = 'bottom'
          )
  
}

################################ DARK ################################ 
################################ 
## Horizontal

theme_bh <- function () {
  theme_minimal() +
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_line(size = 0.1, color='grey50'),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_line(size = 0.5, color = 'white'),
          axis.line.y = element_blank(),
          axis.ticks.x = element_line(size = 0.5, color = 'white'),
          axis.ticks.y = element_line(size = 0.1, color = 'grey50'),
          axis.text.x = element_text(face = 'bold'),
          axis.text.y = element_text(face = 'bold'),
          axis.title.x = element_text(colour = 'white'),
          axis.title.y = element_text(colour = 'white'),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white', size = 15),
          plot.margin = margin(20, 20, 20, 20),
          legend.position = 'none'
    )
}

## Rotated

## Verticle

## Map (No Legend)

theme_bm <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white', size = 15),
          plot.margin = margin(20, 20, 20, 20),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.position = 'none'
    )
  
}

## Map (Legend)

theme_bm_legend <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          legend.title = element_text(colour = 'grey50', angle = 270),
          legend.text = element_text(colour = 'white', angle = 270),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white', size = 15),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.position = c(0.8, 0.3),
          plot.margin = margin(20, 20, 20, 20)
    )
  
}

## Graph

theme_graph <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          legend.text = element_text(colour = 'white'),
          legend.title = element_text(colour = 'white'),
          plot.title = element_text(face = 'bold', colour = '#A4A4A4'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white', size = 15),
          plot.caption = element_text(colour = '#A4A4A4', size = 8),
          plot.margin = margin(20, 20, 20, 20),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.position = 'none'
          )
  
}

################################ Legends ################################
################################ 
## Continuous

guide_continuous <- 
  guide_colorbar(direction = ""vertical"",
                 barheight = unit(50, units = ""mm""),
                 barwidth = unit(2, units = ""mm""),
                 draw.ulim = FALSE,
                 title.position = 'right',
                 label.position = 'left',
                 title.hjust = 0.5,
                 label.hjust = 0.5)

## Discrete

guide_discrete <-
  guide_legend(direction = ""vertical"",
               keywidth = unit(1, units = ""mm""),
               keyheight = unit(100 / length(lab), units = ""mm""),
               title.position = 'right',
               label.position = 'left',
               title.hjust = 0.5,
               label.hjust = 1,
               ncol = 1,
               bycol = TRUE)

################################ Colours ################################
## Space Syntax

pal <- c('#00007f', '#0000fe', '#0160ff', '#01d0ff', '#49ffad', 
         '#a4ff53', '#fbec00', '#ff8500', '#ff1e00', '#7f0000')


colorRampPalette(colors = 
                   c('#00007f', '#0000fe', '#0160ff', '#01d0ff', '#49ffad', 
                     '#a4ff53', '#fbec00', '#ff8500', '#ff1e00', '#7f0000'))

## With White

colorRampPalette(colors = c('#F05154', '#FAFBFB', '#62ACC9'))

colfunc <- colorRampPalette(c('#F05154', '#FAFBFB', '#62ACC9'))
colfunc(10)

## With Purple

colfunc <- colorRampPalette(c('#F05154', '#62ACC9', '#7B6576'))
colfunc(5)

## Palettte

pal <- c(""Clinton"" = ""#62ACC9"", ""Trump"" = ""#F05154"", ""Stein"" = ""#67B1B8"", ""Johnson"" = ""#7B6576"", ""Other"" = ""#555655"")

","Other-02"
"722",501,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","02/tt_02.R","library(tidyverse)
library(janitor)

coast_vs_waste <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>%
  clean_names()

mismanaged_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"") %>%
  clean_names()

waste_vs_gdp <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>%
  clean_names()

glimpse(coast_vs_waste)
glimpse(mismanaged_vs_gdp)
glimpse(waste_vs_gdp)

##

data <- 
  coast_vs_waste %>%
  left_join(waste_vs_gdp) %>%
  left_join(mismanaged_vs_gdp)

##

library(rnaturalearth)
library(sf)

##

countries  <- 
  ne_countries() %>% 
  st_as_sf() %>%
  rename(code = adm0_a3,
         name = admin,
         region = subregion) %>%
  select(code, name, region, continent) %>%
  st_transform(54030)

##

spatial_data <-
  data %>%
  filter(year == 2010) %>%
  left_join(countries) %>%
  st_as_sf()

##

coastline <- 
  ne_coastline(scale = 110) %>%
  st_as_sf() %>%
  st_transform(54030) %>%
  st_snap(countries, tolerance = 1000) %>%
  st_intersection(countries) %>%
  mutate(coastline = st_length(geometry)) %>%
  filter(region != ""Antarctica"") %>%
  group_by(name) %>%
  summarise(coastline = sum(coastline))

##

map_data <- 
  spatial_data %>%
  left_join(st_drop_geometry(coastline)) %>%
  mutate(bylength = mismanaged_plastic_waste_tonnes / (as.numeric(coastline) / 1000),
         bypopulation = mismanaged_plastic_waste_tonnes / coastal_population) %>%
  mutate(bylengthtile = ntile(bylength, 100),
         bypopulationtile = ntile(bypopulation, 100)) %>%
  replace_na(list(bylengthtile = 1,
                  bypopulationtile = 1,
                  mismanaged_plastic_waste_tonnes = 0)) %>%
  select(entity, name, region, continent, mismanaged_plastic_waste_tonnes, 
         bylengthtile, bypopulationtile, geometry) %>%
  drop_na() %>%
  st_as_sf()

##

pal <- c(""#007f00"",
         ""#00501f"",
         ""#00223d"",
         ""#000c5d"",
         ""#003a7c"",
         ""#00699a"",
         ""#2f97ba"",
         ""#8cc6d8"",
         ""#ffffff"")

##

guide_continuous <- 
  guide_colorbar(direction = ""horizontal"",
                 barwidth = unit(50, units = ""mm""),
                 barheight = unit(1, units = ""mm""),
                 draw.ulim = FALSE,
                 title.position = 'top',
                 label.position = 'bottom',
                 title.hjust = 0.5,
                 label.hjust = 0.5)


##

library(stringr)

##

ggplot(data %>%
         filter(year == 2010) %>%
         mutate(ratio = coastal_population / total_population_gapminder) %>%
         mutate(name = case_when(nchar(entity) > 15 ~ word(entity, 1, 2, sep="" ""),
                                 TRUE ~ entity)) %>%
         top_n(64, ratio), 
       aes(x = """", y = ratio)) +
  geom_bar(aes(fill = ntile(ratio, 10)), width = 1, stat = ""identity"", show.legend = FALSE) +
  coord_polar(""y"", start = 0) +
  scale_fill_gradientn(colours = rev(pal[1:8])) +
  facet_wrap(~ reorder(name, -ratio), nrow = 8) +
  labs(title = ""settlement patterns"", subtitle = ""PERCENT COASTAL"") +
  theme_map() +
  ggsave(""test.png"", height = 10, width = 10, dpi = 300)

##

library(scales)

##

spatial_data %>%
  left_join(st_drop_geometry(coastline)) %>%
  group_by(entity) %>%
  summarise(coastline = sum(as.numeric(coastline), na.rm = TRUE),
            population = sum(coastal_population, na.rm = TRUE)) %>%
  top_n(10, coastline) %>%
  ggplot(aes(x = reorder(entity, coastline), y = coastline / 1000)) +
  geom_bar(aes(fill = population / 1000), position = 'stack', stat = 'identity',
           colour = 'grey50', size = 0.1, linetype = 2) +
  scale_fill_gradientn(colours = rev(pal),
                       guide = guide_continuous,
                       name = ""coastal population"",
                       limits = c(0, 200000),
                       breaks = c(50000, 100000, 150000),
                       labels = c(""50m"", ""100m"", ""150m""), 
                       oob = squish) +
  labs(title = ""a tale of ten countries"", subtitle = ""COASTS AND COASTAL POPULATION"",
       x = ""entity"", y = ""coastline (km)"") +
  coord_flip() +
  theme_rot() +
  ggsave(""test2.png"", height = 8, width = 8, dpi = 300)

##

spatial_data %>%
  left_join(st_drop_geometry(coastline)) %>%
  mutate(bylength = mismanaged_plastic_waste_tonnes / (as.numeric(coastline) / 1000),
         bypopulation = mismanaged_plastic_waste_tonnes / coastal_population) %>%
  select(entity, name, region, continent, mismanaged_plastic_waste_tonnes, 
         bylength, bypopulation, geometry) %>%
  drop_na() %>% 
  mutate(length = rank(rescale(bylength, to = c(100, 0))),
         population = rank(rescale(bypopulation, to = c(100, 0)))) %>%
  mutate(selector = population) %>%
  filter(selector < 50) %>%
  gather(variable, rank, length:population) %>%
  ggplot(aes(x = rank, y = reorder(entity, -selector))) +
  geom_line(aes(group = entity), colour = 'grey50', size = 1) +
  geom_point(aes(colour = variable), shape = '|', size = 5) +
  scale_colour_manual(values = c(pal[1], pal[8]),
                      name = ""mass of stray plastic by\n(denominator)"",
                      labels = c(""/ coastline"", ""/ population"")) +
  labs(title = ""weighted and ranked wastefulness"", subtitle = ""THEORIES OF RELATIVITY"",
       x = ""rank"", y = ""entity"") +
  theme_ver() +
  ggsave(""test3.png"", height = 10, width = 10, dpi = 300)

##

rank <-
  spatial_data %>%
  filter(year == 2010) %>%
  filter(entity != ""World"" & !is.na(continent)) %>% 
  group_by(continent) %>%
  summarise(population = sum(mismanaged_plastic_waste_tonnes, na.rm = TRUE)) %>%
  mutate(rank = rank(population)) %>%
  select(-population)

spatial_data %>%
  st_drop_geometry() %>%
  filter(year == 2010) %>%
  filter(entity != ""World"" & !is.na(continent)) %>% 
  group_by(continent, entity) %>%
  summarise(total = sum(mismanaged_plastic_waste_tonnes, na.rm = TRUE),
            population = sum(coastal_population, na.rm = TRUE)) %>%
  left_join(rank) %>%
  ggplot(aes(x = reorder(continent, rank), y = total / 1000)) +
  geom_bar(aes(fill = population / 1000, group = continent), position = 'stack', stat = 'identity',
           colour = 'grey50', size = 0.05, linetype = 2) +
  scale_fill_gradientn(colours = rev(pal),
                       guide = guide_continuous,
                       name = ""coastal population"",
                       limits = c(0, 200000),
                       breaks = c(50000, 100000, 150000),
                       labels = c(""50m"", ""100m"", ""150m""), 
                       oob = squish) +
  labs(title = ""a tale of six continents"", subtitle = ""LITTER BY CONTINENT"",
       x = ""plastic waste (kilotonnes)"", y = ""continent"") +
  coord_flip() +
  theme_rot() +
  ggsave(""test4.png"", height = 8, width = 8, dpi = 300)

spatial_data %>%
  filter(year == 2010) %>%
  filter(entity != ""World"") %>%
  filter(str_detect(region, ""Asia"")) %>%
  group_by(region) %>%
  top_n(5, mismanaged_plastic_waste_tonnes) %>%
  ggplot(aes(x = reorder(entity, mismanaged_plastic_waste_tonnes), y = mismanaged_plastic_waste_tonnes / 1000)) +
  geom_bar(aes(fill = coastal_population / 1000), stat = 'identity',
           colour = 'grey50', size = 0.05, linetype = 2) +
  scale_fill_gradientn(colours = rev(pal),
                       guide = guide_continuous,
                       name = ""coastal population"",
                       limits = c(0, 200000),
                       breaks = c(50000, 100000, 150000),
                       labels = c(""50m"", ""100m"", ""150m""), 
                       oob = squish) +
  facet_wrap(~ region, scales = 'free_y') +
  labs(title = ""a tale of four subcontinents"", subtitle = ""LITTER BY REGION"", 
       x = ""plastic waste (kilotonnes)"", y = ""country"") +
  coord_flip() +
  theme_rot() +
  theme(legend.position = c(0.3, 0.2)) +
  ggsave(""test5.png"", height = 8, width = 8, dpi = 300)

##

library(cartogram)

##

gram_length <- cartogram_cont(map_data, ""bylengthtile"", itermax = 500, prepare = 'adjust')
gram_population <- cartogram_cont(map_data, ""bypopulationtile"", itermax = 500, prepare = 'adjust')

##

gram_start <- st_normalize(sf::st_combine(gram_length))
gram_start <- sf::st_sf(geometry = sf::st_sfc(gram_start))

gram_end <- st_normalize(sf::st_combine(gram_population))
gram_end <-  sf::st_sf(geometry = sf::st_sfc(gram_end))

##

library(transformr)
library(tweenr)
library(ggplot2)

##

morph <- tween_sf(gram_start, gram_end,
                  ease = 'cubic-in-out',
                  nframes = 50)

##

morph <-
  morph %>%
  st_as_sf() %>%
  st_cast(""POLYGON"") %>%
  mutate(area = st_area(geometry)) %>%
  group_by(.frame) %>%
  mutate(ntile = ntile(area, 100)) %>%
  st_cast(""MULTIPOLYGON"")

##

library(gganimate)

##

animate <-
  ggplot(morph) + 
  geom_sf(aes(geometry = geometry, fill = ntile), colour = 'white', size = .1, show.legend = FALSE) + 
  coord_sf(datum = 54030) + 
  scale_fill_gradientn(colours = rev(pal)) +
  labs(title = ""coast against coastal population"", subtitle = ""THEORIES OF RELATIVITY"",
       caption = ""FRAME 1: waste / coastline     FRAME 2: waste / population\ncartogram distorting each country according to how much plastic waste it produces by the length of its coasts or the number of people living on said coasts"") +
  transition_manual(.frame) +
  ease_aes('cubic-in-out') + 
  theme_map()

anim_save(""cartogram.gif"", animation = animate, 
          height = 600, width = 800, nframes = 100, fps = 5,
          start_pause = 2, end_pause = 2)

","Other-02"
"723",502,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","03/tt_03.R","install.packages(""tidyverse"")

library(tidyverse)

##

wine_ratings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")

##

glimpse(wine_ratings)

##

wine_ratings %>%
  group_by(variety) %>%
  summarise(n = n()) %>%
  mutate(position = rank(-n, ties.method = ""random"")) %>%
  arrange(desc(n))

wine_ratings %>%
  group_by(variety) %>%
  summarise(n = n()) %>%
  mutate(position = rank(-n, ties.method = ""random"")) %>%
  ggplot(aes(reorder(position, n), n)) +
  geom_bar(aes(fill = n, colour = n), stat = 'identity', show.legend = FALSE) +
  geom_curve(aes(x = 500, y = 10000, xend = 700, yend = 13000), 
             colour = ""#555555"", 
             size = 0.5, 
             curvature = 0.5,
             arrow = arrow(length = unit(0.01, ""npc""))) +
  geom_text(aes(500, 9000, label = ""pinot noir"")) +
  geom_curve(aes(x = 500, y = 10000, xend = 700, yend = 13000), 
             colour = ""#555555"", 
             size = 0.5, 
             curvature = 0.5,
             arrow = arrow(length = unit(0.01, ""npc""))) +
  geom_text(aes(500, 9000, label = ""pinot noir"")) +
  geom_curve(aes(x = 230, y = 5000, xend = 100, yend = 3), 
             colour = ""#555555"", 
             size = 0.5, 
             curvature = -0.3,
             arrow = arrow(length = unit(0.01, ""npc""))) +
  geom_text(aes(250, 5000, label = ""never heard of this thing called ojaleshi"")) +
  scale_fill_gradientn(colours = pal) +
  scale_colour_gradientn(colours = pal) +
  labs(title = ""power laws"", subtitle = ""WINES BY VARIETAL"", 
       x = """", y = ""n"") + 
  coord_flip() +
  theme_minimal() +
  theme(plot.background = element_rect(fill = '#bcbcbc', colour = '#bcbcbc'),
        panel.grid.major.x = element_line(size = 0.1, colour = 'grey50'),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.line.y = element_line(size = 0.5, colour = 'black'),
        axis.line.x = element_blank(),
        axis.ticks.y = element_line(size = 0.5, colour = 'black'),
        axis.ticks.x = element_line(size = 0.1, colour = 'grey50'),
        axis.text.x = element_text(face = 'bold'),
        axis.text.y = element_blank(),
        plot.title = element_text(face = 'bold', colour = 'grey50'),
        plot.subtitle =  element_text(face = 'plain', colour = 'black'),
        strip.text = element_text(face = 'bold', colour = 'black'),
        plot.margin = margin(20, 20, 20, 20)) +
  ggsave(""test.png"", height = 8, width = 8, dpi = 300)

##

wine_ratings %>%
  group_by(variety) %>%
  summarise(n = n()) %>%
  mutate(position = rank(-n, ties.method = ""random"")) %>%
  ggplot(aes(reorder(position, n), n)) +
  geom_bar(aes(fill = n), size = NA, colour = NA, stat = 'identity', show.legend = FALSE) +
  scale_fill_gradientn(colours = pal) +
  labs(title = ""power laws"", subtitle = ""WINES BY VARIETAL"", 
       x = """", y = ""n"") + 
  coord_flip() +
  theme_rot() +
  ggsave(""test.png"", height = 7, width = 7, dpi = 300)

##

library(googleway)

##

wine_ratings %>%
  mutate(year = str_extract(title, ""(\\d)+"")) %>%
  group_by(year) %>%
  summarise(price = mean(price)) %>%
  pull(year)

##

library(rnaturalearth)
library(sf)

provinces <- 
  ne_states() %>% 
  st_as_sf() %>%
  rename(code = adm0_a3,
         country = admin) %>%
  select(code, country)

countries  <- 
  ne_countries() %>% 
  st_as_sf() %>%
  rename(code = adm0_a3,
         country = admin,
         region = subregion) %>%
  select(code, name, region, continent) %>%
  st_drop_geometry()

provinces_clipped <- 
  provinces %>%
  left_join(countries) %>%
  st_as_sf() %>%
  filter(continent == ""Europe"")

ratings_clipped <- 
  wine_ratings %>%
  group_by(country) %>%
  summarise(price = mean(price),
            points = mean(points),
            n = n()) %>%
  filter(country %in% provinces_clipped$country)

library(geofacet)

eu_grid1

ratings_gridded <-
  ratings_clipped %>%
  mutate(name = country) %>%
  left_join(world_countries_grid1) %>%
  select(row, col, name, country, everything())

ratings_gridded$row <- if_else(ratings_gridded$name == ""Moldova"", 7, if_else(ratings_gridded$name == ""Bosnia and Herzegovina"", 7, as.double(ratings_gridded$row)))
ratings_gridded$col <- if_else(ratings_gridded$name == ""Moldova"", 18, if_else(ratings_gridded$name == ""Bosnia and Herzegovina"", 15, as.double(ratings_gridded$col)))

ratings_gridded$row <- if_else(ratings_gridded$name == ""Macedonia"", 7, if_else(ratings_gridded$name == ""Greece"", 8, as.double(ratings_gridded$row)))
ratings_gridded$col <- if_else(ratings_gridded$name == ""Macedonia"", 16, if_else(ratings_gridded$name == ""Greece"", 16, as.double(ratings_gridded$col)))


grid <- 
  world_countries_grid1 %>%
  filter(name == ""Belgium"") %>%
  select(col, row, name) %>%
  bind_rows(ratings_gridded)

grid %>%
  filter(name != ""Malta"") %>%
  mutate(name = if_else(name == ""Bosnia and Herzegovina"", ""Bosnia\n+\nHerzegovina"", if_else(name == ""Czech Republic"", ""Czech\nRepublic"", name))) %>%
  ggplot(aes(x = col, y = row)) +
  geom_tile(aes(fill = points), colour = '#ffffff', size = 0.5) +
  geom_text(aes(label = name), size = 3, colour = '#000000', alpha = 0.5, fontface = 'bold', show.legend = FALSE) +
  scale_fill_gradientn(colours = pal, na.value = '#bcbcbc', 
                       breaks = c(86, 88),
#                       limits = c(82, 92),
                       guide = guide_continuous) +
  scale_y_reverse(breaks = NULL) +
  scale_x_continuous(breaks = NULL) +
  labs(title = ""viticultures"", subtitle = ""SCORES BY COUNTRY"", 
       x = """", y = ""n"") + 
  theme_void() + 
  theme(plot.background = element_rect(fill = '#bcbcbc', colour = '#bcbcbc'),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major = element_line(size = NA), 
        panel.grid.minor = element_line(size = NA),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.title = element_text(face = 'bold', colour = 'grey50'),
        plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
        plot.caption = element_text(face = 'bold', colour = 'black'),
        strip.text = element_text(face = 'bold', colour = 'black'),
        plot.margin = margin(20, 20, 20, 20),
        legend.text = element_text(angle = 270),
        legend.title = element_text(angle = 270),
        legend.position = c(0.95, 0.7)) +
  ggsave(""test2.png"", height = 8, width = 8, dpi = 300)
  

unique(wine_ratings$variety)

fun <- colorRampPalette(pal)

wine_ratings %>%
  filter(country == ""Spain"" | country == ""Portugal"" | country == ""France"" | country == ""Italy"") %>%
  mutate(variety = str_replace(variety, pattern = ""-"", replacement = "" "")) %>%
  mutate(varietal = case_when(str_detect(variety, ""Chardonnay"") ~ ""Chardonnay"",
                              str_detect(variety, ""Pinot Noir"") ~ ""Pinot Noir"",
                              str_detect(variety, ""Cabernet"") ~ ""Cabernet"",
                              str_detect(variety, ""Pinot Gris"") ~ ""Pinot Gris"",
                              str_detect(variety, ""Pinot Grigio"") ~ ""Pinot Grigio"",
                              str_detect(variety, ""Syrah"") ~ ""Syrah"",
                              str_detect(variety, ""Merlot"") ~ ""Merlot"",
                              str_detect(variety, ""Malbec"") ~ ""Malbec"",
                              str_detect(variety, ""Carignan"") ~ ""Carignan"",
                              str_detect(variety, ""Grenache"") ~ ""Grenache"",
                              str_detect(variety, ""Sangiovese"") ~ ""Sangiovese"",
                              str_detect(variety, ""Riesling"") ~ ""Riesling"",
                              str_detect(variety, ""Sauvignon Blanc"") ~ ""Sauvignon Blanc"",
                              str_detect(variety, ""Shiraz"") ~ ""Shiraz"",
                              str_detect(variety, ""Gewrztraminer"") ~ ""Gewrztraminer"",
                              str_detect(variety, ""Carmnre"") ~ ""Carmnre"",
                              str_detect(variety, ""Tempranillo"") ~ ""Tempranillo"",
                              str_detect(variety, ""Zinfandel"") ~ ""Zinfandel"",
                              str_detect(variety, ""Muscat"") ~ ""Muscat"",
                              str_detect(variety, ""Champagne"") ~ ""Champagne"",
                              str_detect(variety, ""Chenin Blanc"") ~ ""Chenin Blanc"",
                              TRUE ~ ""what?"")) %>%
  mutate(varietal = fct_relevel(varietal, ""what"")) %>%
  group_by(country, varietal) %>%
  summarise(price = mean(price, na.rm = TRUE),
            points = mean(points,  na.rm = TRUE),
            n = n()) %>%
  ggplot(aes(log(price), points)) +
  geom_point(aes(colour = varietal, size = n)) +
  scale_colour_manual(values = fun(20)) +
  scale_size_continuous(range = c(2, 8)) +
  facet_wrap(~ country) +
  labs(title = ""comparative advantage"", subtitle = ""NATIONS POINTS + PRICES"", 
       x = ""log price"", y = ""mean points"") + 
  theme_minimal() +
  theme(plot.background = element_rect(fill = '#bcbcbc', colour = '#bcbcbc'),
        panel.grid.major.x = element_line(size = 0.1, colour = 'grey50'),
        panel.grid.major.y = element_line(size = 0.1, colour = 'grey50'),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.line.y = element_line(size = 0.5, colour = 'black'),
        axis.line.x = element_blank(),
        axis.ticks.y = element_line(size = 0.5, colour = 'black'),
        axis.ticks.x = element_line(size = 0.1, colour = 'grey50'),
        axis.text.x = element_text(face = 'bold'),
        axis.text.y = element_text(face = 'bold'),
        plot.title = element_text(face = 'bold', colour = 'grey50'),
        plot.subtitle =  element_text(face = 'plain', colour = 'black'),
        strip.text = element_text(face = 'bold', colour = 'black'),
        plot.margin = margin(20, 20, 20, 20)) + 
  ggsave(""test3.png"", height = 8, width = 8, dpi = 300)

","Other-03"
"724",503,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","04/tt_04.R","library(tidyverse)

##

ramen_ratings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")

##

library(scico)

##

guide <- 
  guide_legend(direction = ""horizontal"",
               keywidth = unit(10, units = ""mm""),
               keyheight = unit(2, units = ""mm""),
               title.position = 'top',
               label.position = 'right',
               title.hjust = 0.5,
               label.hjust = 1,
               nrow = 1,
               byrow = TRUE)

##

pal <- sample(scico(palette = 'tokyo', 8))

##

ramen_ratings %>% 
  mutate(country = if_else(country == ""USA"", ""United States"", country)) %>%
  group_by(country) %>%
  add_tally() %>%
  ungroup() %>%
  group_by(country, n, style) %>%
  summarise(count = n()) %>%
  mutate(ratio = count / n) %>%
  filter(n > 8) %>%
  ggplot(aes(x = """", y = ratio)) +
  geom_bar(aes(fill = style), width = 1, position = 'fill', stat = ""identity"") +
  coord_polar(""y"", start = 0) +
  scale_fill_manual(values = pal,
                    na.translate = FALSE,
                    guide = guide) +
  facet_wrap(~ reorder(country, -n)) +
  labs(title = ""cupped, packed, boxed or bowled?"", subtitle = ""RATIO OF RAMEN STYLES BY COUNTRY"",
       caption = ""(ordered by the number of varieties)"") +
  theme_map() +
  theme(legend.position = 'bottom',
        legend.title = element_text(colour = 'grey50', face = 'bold'),
        legend.text = element_text(colour = 'black')) +
  ggsave(""test.png"", height = 10, width = 10, dpi = 300) 

##

library(rnaturalearth)
library(sf)

##

countries  <- 
  ne_countries() %>% 
  st_as_sf() %>%
  rename(code = adm0_a3,
         name = admin,
         region = subregion) %>%
  select(code, name, region, continent) %>%
  st_transform(54030)

##

ramen_map <-
  ramen_ratings %>% 
  mutate(country = case_when(country == ""United States"" ~ ""United States of America"",
                             country == ""USA"" ~ ""United States of America"",
                             country == ""UK"" ~ ""United Kingdom"",
                             country == ""Hong Kong"" ~ ""China"",
                             TRUE ~ country)) %>%
  group_by(country) %>%
  add_tally() %>%
  ungroup() %>%
  group_by(country, n, style) %>%
  summarise(count = n()) %>%
  mutate(ratio = count / n) %>%
  mutate(name = country) %>%
  right_join(countries) %>%
  st_as_sf() %>%
  select(name, country, everything()) %>%
  replace_na(list(n = 0.5))

##

library(cartogram)
library(ggrepel)

##

gram <- 
  ramen_map %>%
  filter(count == max(count)) %>%
  slice(1) %>%
  cartogram_dorling(""n"", itermax = 100)

ggplot(gram) +
  geom_sf(data = countries, 
          aes(), fill = NA, colour = 'black', linetype = 3) +
  geom_sf(aes(fill = style, colour = style)) +
  geom_text_repel(data = gram %>%
                    filter(n > 0.5) %>%
                    st_centroid() %>%
                    st_coordinates() %>%
                    as_tibble() %>%
                    bind_cols(gram),
                  aes(X, Y, label = name),
                  fontface = 'bold', colour = 'grey50') +
  scale_fill_manual(values = c(""#9AC495"", ""#562456"",""#CAF3B4""),
                    na.translate = FALSE,
                    guide = guide) +
  scale_colour_manual(values = c(""#9AC495"", ""#562456"",""#CAF3B4""),
                      na.translate = FALSE,
                      guide = guide) +
  labs(title = ""most like it packed"", subtitle = ""MOST POPULAR RAMEN TYPE"",
       caption = ""(sized to the number of reviews in that country)"") +
  theme_void() + 
  theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major = element_line(size = NA), 
        panel.grid.minor = element_line(size = NA),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.title = element_text(face = 'bold', colour = 'grey50'),
        plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
        plot.caption = element_text(face = 'bold', colour = 'black'),
        strip.text = element_text(face = 'bold', colour = 'black'),
        plot.margin = margin(20, 20, 20, 20),
        legend.position = c(0.5, 0.2),
        legend.title = element_text(colour = 'grey50', face = 'bold'),
        legend.text = element_text(colour = 'black')) +
  ggsave(""test2.png"", height = 8, width = 12, dpi = 300) 
  
multigram <- 
  ramen_map %>%
  replace_na(list(count = 0.5)) %>%
  cartogram_dorling(""count"", k = 0.75, itermax = 100)

ggplot(multigram) +
  geom_sf(data = countries, 
          aes(), fill = NA, colour = 'grey50', linetype = 3) +
  geom_sf(aes(fill = country), show.legend = FALSE) +
  geom_text(data = multigram %>%
                    filter(n > 0.5) %>%
                    st_centroid() %>%
                    st_coordinates() %>%
                    as_tibble() %>%
                    bind_cols(filter(multigram, n > 0.5)),
                  aes(X, Y, label = style)) +
  theme_map()


ramens <- 
  ramen_ratings %>% 
  mutate(country = case_when(country == ""United States"" ~ ""United States of America"",
                             country == ""USA"" ~ ""United States of America"",
                             country == ""UK"" ~ ""United Kingdom"",
                             country == ""Hong Kong"" ~ ""China"",
                             TRUE ~ country)) %>%
  group_by(country, style, variety) %>%
  summarise(count = n(), 
            rating = mean(stars)) %>%
  ungroup() %>%
  group_by(country) %>%
  add_tally() %>%
  mutate(name = country) %>%
  right_join(countries) %>%
  st_as_sf() %>%
  select(name, country, everything()) %>%
  replace_na(list(n = 0, rating = 0)) %>%
  filter(n > 0) %>%
  ungroup()

ramen_nations <- 
  ramens %>%
  select(name, n) %>%
  group_by(name) %>%
  slice(1) %>%
  ungroup()

dots <- 
  ramen_nations %>%
  select(n) %>%
  st_drop_geometry()
  
sample <- 
  st_sample(ramen_nations, size = dots$n, type = ""random"", exact = TRUE) %>%
  st_sf() %>%
  bind_cols(st_drop_geometry(ramens)) %>%
  select(everything(), geometry) %>%
  st_as_sf()

ggplot() +
  geom_point(data = sample %>%
               st_coordinates() %>%
               as_tibble() %>%
               bind_cols(sample),
             aes(X, Y, size = ntile(rating, 100), colour = style), 
             alpha = 0.25) +
  geom_sf(data = countries, 
          aes(), fill = NA, colour = 'black', linetype = 3) +
  scale_colour_manual(values = pal,
                    na.translate = FALSE,
                    guide = guide) +
  scale_size_continuous(range = c(1, 6), 
                        guide = 'none') +
  labs(title = ""dotting the nation"", subtitle = ""RAMENS AS POINTS"",
       caption = ""(sized to the number of stars for that variety)"") +
  theme_void() + 
  theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major = element_line(size = NA), 
        panel.grid.minor = element_line(size = NA),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.title = element_text(face = 'bold', colour = 'grey50'),
        plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
        plot.caption = element_text(face = 'bold', colour = 'black'),
        strip.text = element_text(face = 'bold', colour = 'black'),
        plot.margin = margin(20, 20, 20, 20),
        legend.position = c(0.5, 0.2),
        legend.title = element_text(colour = 'grey50', face = 'bold'),
        legend.text = element_text(colour = 'black')) +
  ggsave(""test3.png"", height = 8, width = 12, dpi = 300) 

multigram <- 
  sample %>%
  mutate(rating = ntile(rating, 100)) %>%
  cartogram_dorling(""rating"", itermax = 10)

##

ramen_ratings %>% 
  mutate(country = if_else(country == ""USA"", ""United States"", country)) %>%
  filter(str_detect(country, ""China|Japan|Taiwan|Hong Kong|Thailand|Vietnam|South Korea|Malaysia|United States"")) %>%
  ggplot() +
  geom_density(aes(stars, fill = style, colour = style), position = 'stack') +
  scale_fill_manual(values = pal[c(2, 3, 5, 6, 7, 8)],
                    na.translate = FALSE,
                    guide = guide) +
  scale_colour_manual(values = pal[c(2, 3, 5, 6, 7, 8)],
                      na.translate = FALSE,
                      guide = guide) +
  facet_wrap(~ country) +
  labs(title = ""pacific theater"", subtitle = ""RAMEN RATINGS BY STYLE AND COUNTRY"",
       caption = ""(top 9 countries by selection)"") +
  theme_hor() +
  theme(legend.position = 'bottom',
        legend.title = element_text(colour = 'grey50', face = 'bold'),
        legend.text = element_text(colour = 'black')) +
  ggsave(""test4.png"", height = 10, width = 10, dpi = 300) 
 


","Other-04"
"725",504,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","05/tt_05.R","library(tidyverse)

##

meteorites <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

##

library(rnaturalearth)
library(sf)

##

w <- ne_countries(scale = 'medium', returnclass = 'sf')
p <- ne_download(scale = 'medium', type = 'populated_places', category = 'cultural', returnclass = 'sf')

##

w_Poly <- 
  bind_cols(w %>%
              st_cast(""POLYGON"") %>%
              st_cast(""MULTIPOINT"") %>%
              st_cast(""POINT""), 
            w %>%
              st_cast(""POLYGON"") %>%
              st_cast(""MULTIPOINT"") %>%
              st_coordinates() %>%
              as_tibble())

p_Coord <-
  p %>%
  st_coordinates() %>%
  as_tibble() %>%
  bind_cols(p)

##

places <-
  p %>%
  st_transform(54030) %>%
  st_coordinates() %>%
  as.matrix()

sites <- 
  meteorites %>%
  drop_na(long, lat) %>%
  mutate(X = long, Y = lat) %>%
  st_as_sf(coords = c(""X"", ""Y"")) %>%
  st_set_crs(4269) %>%
  st_transform(54030) %>%
  st_coordinates() %>%
  as.matrix()

##

ggplot() +
  geom_point(data = sites %>%
               as_tibble(),
             aes(X, Y)) +
  geom_point(data = places %>%
               as_tibble(),
             aes(X, Y), colour = 'blue')

##

library(FNN)

##

nn <- get.knnx(places, sites, k = 1)

##

distances <-
  as.data.frame(nn$nn.dist) %>%
  rownames_to_column(var = ""places"") %>%
  gather(site, dist_place, V1) %>%
  arrange(as.numeric(places)) %>%
  group_by(places) %>%
  summarize(d_place = mean(dist_place)) %>%
  arrange(as.numeric(places)) %>% 
  select(-places) %>%
  bind_cols(drop_na(meteorites, long, lat))

##

fun <- colorRampPalette(pal)
fun(10)

##

lab <- glue(""{as.character(round(quantile((distances$d_place / 1000),
                                   c(.1, .2, .4, .6, .8), na.rm = TRUE)), 
                    0)} +"")
                          
##

library(ggrepel)

##

ggplot() +
  geom_polygon(data = w_Poly, 
               aes(x = X, y = Y, group = L1),
               fill = '#696969', colour = '#ffffff', size = 0.1) +
  geom_point(data = p_Coord,
             aes(x = X, y = Y), size = 0.05, alpha = 0.5, colour = '#bababa') +
  geom_point(data = distances, 
             aes(x = long, y = lat, size = mass, colour = factor(ntile(d_place, 5))), alpha = 0.5) +
  geom_label_repel(data = distances %>%
                     group_by(d_place) %>%
                     slice(1) %>%
                     ungroup() %>%
                     mutate(site = str_remove(name, "" [0-9]+"")) %>%
                     group_by(site) %>%
                     slice(1) %>%
                     ungroup() %>%
                     top_n(50, d_place) %>%
                     sample_n(10) %>%
                     mutate(site = glue(""{site}\n{round(d_place / 1000, 0)}km"")),
                   aes(x = long, y = lat, label = site),
                   arrow = arrow(length = unit(0.01, ""npc""), type = ""open"", ends = ""last""),
                   force = 10) +
  scale_colour_manual(values = rev(fun(6)[1:5]),
                      labels = lab,
                      name = ""isolation\n(km)"",
                      guide = guide_legend(direction = ""horizontal"",
                                           keyheight = unit(2, units = ""mm""),
                                           keywidth = unit(10, units = ""mm""),
                                           title.position = 'top',
                                           label.position = 'bottom',
                                           title.hjust = 0.5,
                                           label.hjust = 0.5,
                                           nrow = 1,
                                           byrow = TRUE)) +
  scale_size_continuous(range = c(1, 10), guide = 'none') +
  coord_map(projection = ""mollweide"", orientation = c(140, 0, 45)) +
  labs(title = ""observation biases"", subtitle = ""DISTANCE TO NEAREST POPULATED PLACE"") +
  theme_map() +
  theme(legend.position = c(0.7, 0.9),
        legend.title = element_text(face = 'bold')) +
  ggsave(filename = ""meteorites.png"", path = ""/Users/andrewrenninger/Desktop/R/tuesdays"", height = 8, width = 12, dpi = 300)
","Other-05"
"726",505,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","07/tt_07.R","devtools::install_github(""tylermorganwall/rayshader"")

##

library(""tidyverse"")

##

ufo_sightings <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

##

glimpse(ufo_sightings)

##

grid <- 
  counties %>%
  st_make_grid(cellsize = 50000) %>%
  st_sf() %>%
  rownames_to_column() %>%
  st_join(counties) %>%
  drop_na() %>%
  group_by(rowname) %>%
  summarise() %>%
  st_as_sf()

plot(grid)

##

ufo_sf <-
  ufo_sightings %>%
  mutate(x = longitude, y = latitude) %>%
  drop_na() %>%
  st_as_sf(coords = c(""x"", ""y"")) %>%
  st_set_crs(4269) %>%
  st_transform(102003) %>%
  st_join(grid) %>%
  st_drop_geometry() %>%
  group_by(rowname) %>%
  summarise(sightings = n()) %>%
  right_join(grid) %>%
  replace_na(list(sightings = 0)) %>%
  st_as_sf()

ufo_sf %>%
  filter(country == ""us"") %>%
  select(date_time) %>%
  st_coordinates() %>%
  as_tibble() %>%
  ggplot(aes(X, Y)) +
  stat_density_2d(aes(fill = stat(nlevel)), geom = 'polygon', n = 100, bins = 10)

ggplot(ufo_sightings %>%
         filter(country == ""us""), aes(longitude, latitude)) +
  geom_point()

##

library(viridis)

##

theme_map <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'white', colour = 'white'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.margin = margin(20, 20, 20, 20),
          strip.text = element_text(face = 'bold', colour = 'white'),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.title = element_text(angle = 270, face = 'bold', colour = 'grey50'),
          legend.text = element_text(angle = 270)
    )
  
}

##

plot_sightings <-
  ggplot(ufo_sf) +
  geom_sf(aes(fill = sightings), colour = NA, size = 0) +
  scale_fill_viridis(guide =   guide_colorbar(direction = ""vertical"",
                                              barheight = unit(50, units = ""mm""),
                                              barwidth = unit(2, units = ""mm""),
                                              draw.ulim = FALSE,
                                              title.position = 'right',
                                              label.position = 'left',
                                              title.hjust = 0.5,
                                              label.hjust = 0.5),
                     name = ""ufo sitings"") +
  ggtitle(""O'ER THE LAND OF THE FREE"") +
  theme_bw() +
  theme(legend.title = element_text(angle = 270, face = 'bold', colour = 'grey50'),
        legend.text = element_text(angle = 270))

plot_sightings

##

library(rayshader)

##

plot_gg(plot_sightings, multicore = TRUE, width = 10, height = 8, scale = 250,
        soliddept = -10)

render_depth(focallength = 100, focus = 0.72)

##

?plot_gg
?render_movie

##

render_movie(filename = ""test3"", type = 'orbit', frames = 360, fps = 30,
             phi = 30, theta = 0, zoom = 0.5)
","Other-07"
"727",506,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","08/tt_08.R","##

library(tidyverse)

##

wildlife_impacts <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")

##

glimpse(wildlife_impacts)

##

crosswalk <- 
  wildlife_impacts %>%
  filter(state != ""N/A"") %>%
  filter(airport_id != ""ZZZZ"") %>%
  select(airport_id, state) %>%
  distinct() %>%
  mutate(city = glue(""{airport_id} Airport, {state}""))

##

library(googleway)
library(glue)

##

geocoderesults <- tibble()

##

for (i in 275:nrow(crosswalk)){
  
  index <- i
  
  city <- 
    crosswalk %>%
    slice(index) %>%
    pull(city) 
  
  location <- google_geocode(city, key = ""YOURKEY"")
  
  located  <- tibble(city = city, 
                     address = c(location$results$formatted_address),
                     lat = c(location$results$geometry$location[[1]]),
                     lon = c(location$results$geometry$location[[2]])) %>%
    slice(1)
  
  geocoderesults <- bind_rows(geocoderesults, located)
  
  Sys.sleep(1)
  
}

crosswalk %>% slice(274)

glimpse(geocoderesults)
glimpse(crosswalk)

##

library(sf)

##

impacts_spatial <-
  wildlife_impacts %>%
  left_join(crosswalk) %>%
  left_join(geocoderesults) %>%
  drop_na(address) %>%
  filter(!str_detect(species, ""Unknown"")) %>%
  filter(lon < 0 & lon > -150 & lat < 50 & lat > 20) %>%
  mutate(x = lon, y = lat) %>%
  st_as_sf(coords = c(""x"", ""y""), 
           crs = 4326) %>%
  st_transform(102003)

coords <- 
  st_coordinates(impacts_spatial)

##

library(rnaturalearth)

##

states <- 
  ne_states(returnclass = 'sf') %>% 
  filter(adm0_a3 == ""USA"") %>%
  filter(!str_detect(name, ""Alaska|Hawaii"")) %>%
  select(name)

states <- st_transform(states, 102003)

##

library(janitor)

##

cities <-
  ne_download(scale = 'medium', type = 'populated_places', category = 'cultural', returnclass = 'sf') %>%
  clean_names() %>%
  filter(adm0_a3 == ""USA"" & name != ""Honolulu"" & pop2010 > 250) %>%
  select(name, pop2010)

cities <- st_transform(states, 102003)

##

states_buffered <-
  states %>%
  mutate(dissolve = 1) %>%
  summarise() %>%
  st_buffer(100000)

##

cells <-
  states_buffered %>%
  st_make_grid(cellsize = 20000)

##

library(kknn)

##

species_train <-
  impacts_spatial %>%
  mutate(lon = coords[, 1],
         lat = coords[, 2]) %>%
  st_drop_geometry() %>%
  select(species, lon, lat) %>%
  group_by(species) %>% 
  nest() %>% 
  mutate(num = map_int(data, nrow)) %>% 
  arrange(desc(num)) %>% 
  slice(1:8) %>% 
  unnest() %>% 
  select(-num) %>%
  mutate(species = factor(species))

##

ggplot(species_train, aes(x = lon, y = lat, colour = species)) +
  geom_point()

##

k <- 1000

species_result <- tibble(species = factor(NA), 
                         lon = st_coordinates(cells)[, 1], 
                         lat = st_coordinates(cells)[, 2])

##

species_kknn <- kknn::kknn(species ~ ., 
                           train = species_train, 
                           test = species_result, 
                           kernel = ""gaussian"", 
                           k = 1000)

##

species_result <-
  species_result %>%
  mutate(species = fitted(species_kknn), 
         prob = apply(species_kknn$prob, 
                      1, 
                      function(x) max(x)))

##

states_grid <-
  cells %>%
  st_sf() %>%
  rownames_to_column() %>%
  st_join(states) %>%
  drop_na() %>%
  group_by(rowname) %>%
  summarise() %>%
  st_as_sf()

##

species_grid <- 
  species_result %>%
  mutate(x = lon, y = lat) %>%
  st_as_sf(coords = c(""x"", ""y""),
           crs = 102003) %>%
  st_join(states_grid) %>%
  st_drop_geometry() %>%
  drop_na() %>%
  left_join(states_grid) %>%
  st_as_sf()

##

theme_map <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.caption = element_text(face = 'bold', colour = 'black'),
          strip.text = element_text(face = 'bold', colour = 'black'),
          plot.margin = margin(20, 20, 20, 20),
          legend.title = element_text(face = 'bold', angle = 270)
    )
  
}

##

guide_discrete <-
  guide_legend(direction = ""vertical"",
               keyheight = unit(10, units = ""mm""),
               keywidth = unit(2, units = ""mm""),
               title.position = 'right',
               label.position = 'left',
               title.hjust = 0.5,
               label.hjust = 1,
               ncol = 1,
               bycol = TRUE)

##

species_raster <-
  species_result %>%
  st_as_sf(coords = c(""lon"", ""lat""),
           crs = 102003, 
           remove = FALSE) %>%
  st_intersection(states)

plot(species_raster[, 1])

##

install.packages(""rcartocolor"")
library(rcartocolor)

##

map <- 
  ggplot() +
  geom_raster(data = species_raster,
              aes(x = lon, y = lat, fill = species, alpha = prob)) +
  geom_sf(data = states, 
          aes(), fill = NA, size =  0.1, colour = 'black', alpha = 0.5) +
  scale_fill_carto_d(palette = ""Safe"",
                     na.translate = FALSE,
                     guide = guide_discrete) +
  scale_alpha(guide = 'none') +
  coord_sf(crs = 102003) +
  labs(title = ""whodunnit?"", subtitle = ""INTERPOLATED LIKELIHOOD"",
       caption = ""bird most likely to bring down your plane using categorical interpolation"") +
  theme_map()

##

guide_discrete <-
  guide_legend(direction = ""vertical"",
               keyheight = unit(10, units = ""mm""),
               keywidth = unit(2, units = ""mm""),
               title.position = 'right',
               label.position = 'left',
               title.hjust = 0.5,
               label.hjust = 1,
               ncol = 1,
               bycol = TRUE,
               override.aes = list(size = 3))

##

map <- 
  ggplot() +
  geom_point(data = species_train %>%
               filter(species != ""American kestrel""),
             aes(x = lon, y = lat, colour = species),
             size = 1, alpha = 0.5) +
  geom_sf(data = states, 
          aes(), fill = NA, size =  0.1, colour = 'black', alpha = 0.5) +
  scale_colour_carto_d(palette = ""Safe"",
                      na.translate = FALSE,
                      guide = guide_discrete) +
  scale_alpha(guide = 'none') +
  coord_sf(crs = 102003) +
  labs(title = ""whodunnit?"", subtitle = ""TRAINING DATA"",
       caption = ""incidences of birds striking planes by airport"") +
  theme_map()

##

ggsave(map, path = ""~/Desktop"", filename = ""test.png"", height = 6, width = 7, dpi = 300)  

##
","Other-08"
"728",507,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","09/tt_09.R","
library(tidyverse)

##

rome_peeps <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

##

library(sf)

##

rome_shape <- st_read(""09/pplaces_out.shp"")

## loose

rome_shape %>%
  filter(str_detect(TITLE, paste(rome_peeps$birth_cty, collapse = ""|""))) %>%
  ggplot(aes(REPRLONG, REPRLAT)) +
  geom_point(data = rome_shape,
             aes(REPRLONG, REPRLAT), alpha = 0.25) +
  geom_point(aes(colour = GEOCONTEXT), show.legend = FALSE)

## tight

rome_shape %>%
  filter(TITLE %in% rome_peeps$birth_cty | GEOCONTEXT %in% rome_peeps$birth_cty) %>%
  drop_na(GEOCONTEXT) %>%
  ggplot(aes(REPRLONG, REPRLAT)) +
  geom_point(data = rome_shape,
             aes(REPRLONG, REPRLAT), alpha = 0.25) +
  geom_point(aes(colour = GEOCONTEXT), show.legend = FALSE)

## remaining

remainder <- 
  rome_peeps %>%
  filter(!birth_cty %in% rome_shape$GEOCONTEXT & !birth_cty %in% rome_shape$TITLE) %>%
  distinct(birth_cty)

## blend

library(stringdist)

##

narrow <- 
  rome_shape %>%
  mutate(match_wide = str_extract(GEOCONTEXT, paste(rome_peeps$birth_cty, collapse = ""|"")),
         match_narrow = str_extract(TITLE, paste(rome_peeps$birth_cty, collapse = ""|""))) %>%
  filter(match_wide != ""<NA>"" | match_narrow != ""<NA>"") %>%
  mutate(similarity_wide = stringdist(GEOCONTEXT,  match_wide),
         similarity_narrow = stringdist(TITLE,  match_narrow)) %>% 
  mutate(match = case_when(is.na(match_wide) ~ match_narrow,
                           TRUE ~ match_wide),
         similarity = case_when(is.na(match_wide) ~ similarity_narrow,
                                TRUE ~ similarity_wide)) %>%
  group_by(match) %>%
  filter(similarity == min(similarity)) %>%
  select(GEOCONTEXT, TITLE, REPRLAT, REPRLONG, match, similarity)

## how many

sum(str_detect(unique(rome_shape$GEOCONTEXT), paste(remainder$birth_cty, collapse = ""|"")), na.rm = TRUE)

## which ones

remainder <-
  rome_peeps %>%
  filter(!birth_cty %in% narrow$match) %>%
  distinct(birth_cty) %>%
  pull()

## grasping at straws

wide <- 
  rome_shape %>%
  filter(str_detect(GEOCONTEXT, ""Gamzigrad"") | str_detect(TITLE, ""Arca"") | str_detect(TITLE, ""Lepti Minus"")) %>%
  filter(str_detect(GEOCONTEXT, ""Gamzigrad"") | str_detect(TITLE, ""Caesarea"") | str_detect(TITLE, ""Lepti Minus"")) %>%
  mutate(match = ""manual"",
         similarity = 0) %>%
  select(GEOCONTEXT, TITLE, REPRLAT, REPRLONG,  match, similarity) %>%
  mutate(match = str_extract(TITLE, ""Romuliana|Arca|Lepti Minus"")) %>%
  mutate(match = str_replace_all(match, ""Romuliana"", ""Felix Romuliana"")) %>%
  mutate(match = str_replace_all(match, ""Arca"", ""Arca Caesarea"")) %>%
  mutate(match = str_replace_all(match, ""Lepti Minus"", ""Leptis Magna"")) %>%
  rename(lat = REPRLAT,
         lon = REPRLONG) %>%
  select(match, lon, lat)

## combined

combined <- 
  narrow %>%
  filter(TITLE != ""Alba"") %>%
  filter(GEOCONTEXT != ""Salona"") %>%
  group_by(match) %>%
  summarise(lat = mean(REPRLAT),
            lon = mean(REPRLONG)) %>%
  rbind(wide)

joined <-
  combined %>%
  mutate(birth_cty = match) %>%
  right_join(rome_peeps) %>%
  group_by(birth_cty) %>%
  summarise(lat = median(lat),
            lon = median(lon),
            n = n())

## plotting

theme_map <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.caption = element_text(face = 'bold', colour = 'black'),
          strip.text = element_text(face = 'bold', colour = 'black'),
          plot.margin = margin(5, 5, 5, 5),
          legend.position = c(0.8, 0.8)
    )
  
}

##

library(ggrepel)

##

coast <- st_read(""09/coastline.shp"")
empire <- st_read(""09/roman_empire_ad_200_extent.shp"")

##

ggplot() +
  geom_sf(data = empire,
          aes(), fill = 'red4', colour = NA) +
  geom_sf(data = coast,
          aes(), colour = 'navyblue', size = 0.1) +
  geom_point(data = rome_shape,
             aes(REPRLONG, REPRLAT), colour = 'grey70', alpha = 0.25, size = 0.1) +
  geom_text_repel(data = joined,
                  aes(lon, lat, label = birth_cty),
                  fontface = 'bold', colour = 'black',
                  segment.alpha = 0.5,
                  force = 1) + 
  geom_point(data = joined,
             aes(lon, lat, colour = n, size = n)) +
  scale_color_gradientn(colors = c('gold', 'gold4')) +
  guides(color = guide_legend(), size = guide_legend()) +
  coord_sf(xlim = c(-12.50000,  93.33042),
           ylim = c(-7.50000, 62.50000)) +
  labs(title = ""places of birth for roman emporers"",
       subtitle = ""WHICH ROADS LEAD TO ROME?"",
       caption = ""each point represents a site from antiquity"") +
  theme_map() +
  ggsave(""hometowns.png"", height = 8, width = 10, dpi = 300)

","Other-09"
"729",508,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","10/tt_10.R","library(tidyverse)
library(sf)

##

library(rnaturalearth)

##

w <- ne_countries(scale = ""medium"", returnclass = ""sf"")

w_Poly <- bind_cols(w %>%
                      st_cast(""POLYGON"") %>%
                      st_cast(""MULTIPOINT"") %>%
                      st_cast(""POINT""), 
                    w %>%
                      st_cast(""POLYGON"") %>%
                      st_cast(""MULTIPOINT"") %>%
                      st_coordinates() %>%
                      as_tibble())

##

nuclear_explosions <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")

##

theme_map <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
          panel.grid.major.x = element_line(size = 0.1, colour = 'grey50'),
          panel.grid.major.y = element_line(size = 0.1, colour = 'grey50'),
          panel.grid.minor.x = element_line(size = 0.1, colour = 'grey50'),
          panel.grid.minor.y = element_line(size = 0.1, colour = 'grey50'),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'black'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.caption = element_text(face = 'bold', colour = 'black'),
          strip.text = element_text(face = 'bold', colour = 'black'),
          plot.margin = margin(20, 20, 20, 20)
    )
  
}

##

ggplot() +
  geom_polygon(data = w_Poly, 
               aes(x = X, y = Y, group = L1),
               fill = '#696969', colour = '#FFFFFF', size = 0.1) +
  geom_point(data = nuclear_explosions, 
             aes(x = longitude, y = latitude, colour = yield_upper, size = yield_upper), show.legend = FALSE) +
  scale_colour_gradientn(colours = pal[2:11]) +
  scale_size_continuous(range = c(0, 10)) +
  coord_map(""ortho"", orientation = c(42.952287, -40.989156, 0)) +
  labs(title = ""doom around the globe"", subtitle = ""NUCLEAR DETONATIONS"") +
  theme_map() +
  ggsave(filename = ""test.png"", height = 10, width = 10, dpi = 300)

##

explosions_filled <-
  nuclear_explosions %>%
  mutate(rounded = round(longitude, -1)) %>%
  right_join(tibble(rounded = seq(from = -180, to = 180, by = 10)))
        
##

library(magick)

##

img <- image_graph(1000, 1000, res = 300)

datalist <- split(explosions_filled, explosions_filled$rounded)

##

out <- lapply(datalist, function(data){
  
  p <- 
    ggplot() +
    geom_polygon(data = w_Poly, 
                 aes(x = X, y = Y, group = L1),
                 fill = '#696969', colour = '#FFFFFF', size = 0.1) +
    geom_point(data = nuclear_explosions, 
               aes(x = longitude, y = latitude, colour = yield_upper, size = yield_upper), show.legend = FALSE) +
    scale_colour_gradientn(colours = pal[2:11]) +
    scale_size_continuous(range = c(0, 10)) +
    coord_map(""ortho"", orientation = c(42.952287, unique(data$rounded), 0)) +
    ggtitle(""atomic booms"") +
    theme_map()
  
  print(p)
  
})

dev.off()

##

animation <- image_animate(img, fps = 2)
image_write(animation, ""booms.gif"")

##

","Other-10"
"730",509,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","11/11.R","library(tigris)
library(sf)

##

options(tigris_use_cache = TRUE)

##

roads <- roads(""NY"", ""New York"", class = 'sf')
tracts <- tracts(""NY"", ""New York"", class = 'sf')

water <- 
  area_water(""NY"", ""New York"", class = 'sf') %>%
  st_union() %>%
  st_combine()

##

options(scipen = 999)

library(tidyverse)
library(scales)
library(magrittr)
library(classInt)
library(janitor)

##

background <-
  tracts %>%
  mutate(dissolve = 1) %>%
  group_by(dissolve) %>%
  summarise() %>%
  st_difference(water)

##

roads_local <- 
  roads %>% 
  filter(str_detect(MTFCC, ""S1200|S1400"")) %>%
  filter(str_detect(RTTYP, ""M|C""))

##

library(stplanr)

##
##

network <- 
  roads_local %>%
  as('Spatial') %>%
  SpatialLinesNetwork()

graph <- network@g

##

library(igraph)

##

is.simple(graph)
simplied <- simplify(graph)
is.simple(simplied)

##

coords <- 
  simplified %>%
  set_vertex_attr('x', value = use_series(simplified, x)) %>%
  set_vertex_attr('y', value = use_series(simplified, y))

coords <- 
  graph %>%
  set_vertex_attr('x', value = use_series(simplified, x)) %>%
  set_vertex_attr('y', value = use_series(simplified, y))

##

attributes <- 
  coords %>%
  set_edge_attr('head_x', value = head_of(., E(.))$x) %>%
  set_edge_attr('tail_x', value = tail_of(., E(.))$x) %>%
  set_edge_attr('head_y', value = head_of(., E(.))$y) %>%
  set_edge_attr('tail_y', value = tail_of(., E(.))$y)

##

attributes <- 
  attributes %>%
  set_edge_attr('slope', value = map_dbl(E(.), function(e){
    slope = (e$tail_y - e$head_y)/(e$tail_x - e$head_x)
    if(is.infinite(slope)) return(Inf)
    return(slope)
  })) %>%
  set_edge_attr('color', value = map_chr(E(.)$slope, function(e){
    if(e < 0) return('red')
    return('blue')
  }))

##

plot(attributes, vertex.label = '', vertex.size = .1)

##

roads_labelled <-
  roads_local %>%
  mutate(slope = E(attributes)$slope) %>%
  mutate(rounded = round(slope, 1)) %>% 
  mutate(street = case_when(rounded == -0.4 ~ ""sidestreet"",
                            rounded > 1.2 & rounded < 1.7 ~ ""avenue"",
                            TRUE ~ ""breaks"")) 

##

mapview(roads_labelled, zcol = ""street"") 

##

guide_discrete <-
  guide_legend(direction = ""vertical"",
               keywidth = unit(1, units = ""mm""),
               keyheight = unit(50 / 3, units = ""mm""),
               title.position = 'left',
               label.position = 'right',
               title.vjust = 0.5,
               label.vjust = 1,
               ncol = 1,
               bcol= TRUE)

theme_bm_legend <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          legend.title = element_text(colour = 'grey50', angle = 90),
          legend.text = element_text(colour = 'white', angle = 90),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white', size = 15),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.position = c(0.8, 0.2),
          #  legend.background = element_rect(fill = ""grey10"", colour = ""grey10"", 
          #                                   size = 5, linetype=""solid""),
          plot.margin = margin(20, 20, 20, 20)
    )
  
}

##

pal <- read_csv(""https://github.com/asrenninger/palettes/raw/master/turbo.txt"", col_names = FALSE) %>% pull(X1) 
fun <- colorRampPalette(pal)

##

ggplot() +
  geom_sf(data = background,
          aes(), fill = '#353535', colour = NA, size = 0) +
  geom_sf(data = roads_labelled %>%
            mutate(street = fct_relevel(street, ""sidestreet"", ""avenue"", ""breaks"")),
          aes(colour = street, fill = street), size = 0.25) +
  scale_fill_manual(values = fun(9)[c(2, 5, 8)],
                    na.translate = FALSE,
                    guide = guide_discrete) +
  scale_color_manual(values = fun(9)[c(2, 5, 8)],
                     na.translate = FALSE,
                     guide = guide_discrete) +
  labs(title = ""manhattan streets"", subtitle = ""TYPOLOGIES"") +
  theme_bm_legend() +
  ggsave(""streets.png"", height = 6.5, width = 3.5, dpi = 300)

##

pizza_datafiniti <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_datafiniti.csv"")

##

pizza_barstool <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-01/pizza_barstool.csv"")

##

barstool_trimmed <- 
  pizza_barstool %>%
  drop_na(latitude, longitude) %>%
  st_as_sf(coords = c(""longitude"", ""latitude""), remove = FALSE, crs = 4326) %>%
  st_intersection(st_transform(background, 4326)) %>%
  st_drop_geometry()

datafiniti_trimmed <- 
  pizza_datafiniti %>%
  drop_na(latitude, longitude) %>%
  st_as_sf(coords = c(""longitude"", ""latitude""), remove = FALSE, crs = 4326) %>%
  st_intersection(st_transform(background, 4326)) %>%
  st_drop_geometry()

glimpse(barstool_trimmed)
glimpse(datafiniti_trimmed)

##

theme_bm_legend_2 <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          legend.title = element_text(colour = 'grey50'),
          legend.text = element_text(colour = 'white'),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white', size = 15),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          legend.position = c(0.8, 0.2),
          #  legend.background = element_rect(fill = ""grey10"", colour = ""grey10"", 
          #                                   size = 5, linetype=""solid""),
          plot.margin = margin(20, 20, 20, 20)
    )
  
}

##

ggplot() +
  geom_sf(data = background,
          aes(), fill = '#353535', colour = NA, size = 0) +
  geom_sf(data = roads_labelled,
          aes(), colour = '#a1a1a1', size = 0.25) +
  geom_point(data = barstool_trimmed,
             aes(x = longitude, y = latitude, colour = factor(ntile(review_stats_all_average_score, 5))), 
             size = 1) +
  scale_color_manual(values = fun(5),
                     labels = str_sub(as.character(quantile(barstool_trimmed$review_stats_all_average_score,
                                                            c(.1,.2,.4,.6,.8),
                                                            na.rm = TRUE)), 1, 4),
                     na.translate = FALSE,
                        name = ""rating"") +
  labs(title = ""manhattan pizzerias"", subtitle = ""AVERAGE RATING"") +
  theme_bm_legend_2() +
  ggsave(""pizzerias.png"", height = 6, width = 3.5, dpi = 300)

##

library(RANN)

##

coords <- roads_labelled %>%
  st_cast('POINT') %>%
  st_coordinates() %>%
  as_tibble()

points <- 
  roads_labelled %>%
  st_cast('POINT') %>%
  st_drop_geometry() %>%
  bind_cols(coords) %>%
  rownames_to_column() %>%
  mutate(nearest = as.numeric(rowname)) %>%
  as_tibble()

##

closest <-
  nn2(data = tibble(X = points$X, Y = points$Y), 
      query = tibble(X = barstool_trimmed$longitude, Y = barstool_trimmed$latitude),
      k = 1, 
      searchtype = ""radius"", 
      radius = 500)

as_tibble(closest$nn.idx)

barstool_linked <-
  barstool_trimmed %>%
  bind_cols(as_tibble(closest$nn.idx)) %>%
  rename(nearest = V1) %>%
  left_join(points)

barstool_linked %>%
  ggplot(aes(x = review_stats_all_average_score)) +
  geom_density() +
  facet_wrap(~ street)

##

theme_rot <- function () {
  theme_minimal() +
    theme(plot.background = element_rect(fill = 'black', colour = 'black'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          axis.line.y = element_blank(),
          axis.line.x = element_line(size = 0.5, colour = 'white'),
          axis.ticks.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.text.x = element_text(face = 'bold', colour = 'white'),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'white'),
          strip.text = element_text(face = 'bold', colour = 'white'),
          plot.margin = margin(20, 20, 20, 20)
    )
}

##

barstool_trimmed <-
  barstool_linked %>%
  mutate(range = ntile(review_stats_all_average_score, 100)) %>%
  filter(range != 100 & range != 1 & !is.na(review_stats_all_average_score))

city_average <-
  barstool_trimmed %>%
  summarise(city_avg = mean(review_stats_all_average_score, na.rm = TRUE))

street_averages <-
  barstool_trimmed %>%
  group_by(street) %>%
  summarise(street_avg = mean(review_stats_all_average_score, na.rm = TRUE))

comparisons <-
  barstool_trimmed %>%
  left_join(street_averages) %>%
  mutate(city_avg = pull(city_average, city_avg))
  
##

ggplot(comparisons, 
       aes(review_stats_all_average_score)) +
  geom_density(aes(fill = street, colour = street), show.legend = FALSE, alpha = 0.5) +
  geom_vline(aes(xintercept = street_avg), color = ""gray70"", size = 0.75, linetype = 2) +
  facet_wrap(~ street, ncol = 1) +
  scale_fill_manual(values = fun(9)[c(2, 5, 8)],
                    na.translate = FALSE,
                    guide = 'none') +
  scale_color_manual(values = fun(9)[c(2, 5, 8)],
                     na.translate = FALSE,
                     guide = 'none') +
  theme_rot() +
  ggsave(""ratings.png"", height = 6, width = 8, dpi = 300)

##

library(nngeo)

##

joined <- 
  pizza_barstool %>%
  drop_na(latitude, longitude) %>%
  st_as_sf(coords = c(""longitude"", ""latitude""), remove = FALSE, crs = 4326) %>%
  st_transform(4269) %>%
  st_intersection(background) %>%
  st_nn(roads_labelled)

index <- 
  roads_labelled %>%
  rownames_to_column() %>%
  rename(index = rowname) %>%
  mutate(index = as.numeric(index))

barstool_trimmed %>%
  mutate(index = unlist(joined)) %>%
  left_join(index) %>%
  st_as_sf(coords = c(""longitude"", ""latitude""), remove = FALSE, crs = 4326) %>%
  mapview(zcol = ""street"")
  


","Other-11"
"731",510,"https://github.com/asrenninger/tidytuesdays","asrenninger","tidytuesdays","12/tt_12.R","library(tidyverse)

##

horror_movies <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

##

glimpse(horror_movies)

## 

locations <-
  horror_movies %>%
  select(filming_locations) %>%
  drop_na() %>%
  distinct()

##

library(googleway)
library(glue)

##

geocoderesults <- tibble()

for (i in 1:length(locations$filming_locations)){
  
  index <- i
  
  city <- as.character(locations$filming_locations[index])
  
  location <- google_geocode(city, key = ""YOURKEY"")
  
  located  <- tibble(city = city, 
                     name = c(location$results$formatted_address),
                     lat = c(location$results$geometry$location[1]),
                     lon = c(location$results$geometry$location[2]))
  
  geocoderesults <- bind_rows(geocoderesults, located)
  
  Sys.sleep(1)
  
}

##

results <-
  geocoderesults %>%
  group_by(name) %>%
  slice(1)

##

latlon <- tibble()

for (i in 1:nrow(results)) {
  
  index <- i 
  
  Y <- results$lat[[index]][1]
  X <- results$lon[[index]][1]
  
  iteration <- tibble(lat = Y,
                      lon = X)
  
  latlon <- bind_rows(latlon, iteration)
  
}

##

shoots <-
  results %>%
  select(-lon, -lat) %>%
  bind_cols(latlon) %>%
  rename(filming_locations = city) %>%
  right_join(horror_movies) %>%
  drop_na(lon, lat)

##

glimpse(shoots)

ggplot(shoots, aes(lon, lat, colour = review_rating)) +
  geom_point()

##

library(rnaturalearth)
library(sf)

##

world <- ne_countries(scale = ""medium"", returnclass = ""sf"")

##

st_crs(world)

counts <- 
  shoots %>%
  st_as_sf(coords = c(""lon"", ""lat""), remove = FALSE, crs = 4326) %>%
  st_join(world) %>%
  st_drop_geometry() %>%
  group_by(continent) %>%
  summarise(n = n())

##

poly <- 
  bind_cols(world %>%
              st_cast(""POLYGON"") %>%
              st_cast(""MULTIPOINT"") %>%
              st_cast(""POINT""), 
            world %>%
              st_cast(""POLYGON"") %>%
              st_cast(""MULTIPOINT"") %>%
              st_coordinates() %>%
              as_tibble())

##

centroids <- 
  world %>%
  group_by(continent) %>%
  summarise() %>%
  filter(!str_detect(continent, ""Antarctica|Seven"")) %>%
  st_centroid() %>%
  left_join(counts) %>%
  st_as_sf()

coords <-
  centroids %>%
  st_coordinates() %>%
  as_tibble() %>%
  bind_cols(centroids)

## 

plots <- list()

##

library(glue)

## 

theme_map <- function () {
  theme_void() + 
    theme(plot.background = element_rect(fill = 'transparent', colour = 'transparent'),
          panel.grid.major.x = element_blank(),
          panel.grid.major.y = element_blank(),
          panel.grid.minor.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          panel.grid.major = element_line(size = NA), 
          panel.grid.minor = element_line(size = NA),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.ticks.x = element_blank(),
          axis.ticks.y = element_blank(),
          axis.text.x = element_blank(),
          axis.text.y = element_blank(),
          plot.title = element_text(face = 'bold', colour = 'grey50'),
          plot.subtitle =  element_text(face = 'plain', colour = 'black', size = 15),
          plot.caption = element_text(face = 'bold', colour = 'black'),
          strip.text = element_text(face = 'bold', colour = 'black'),
          plot.margin = margin(5, 5, 5, 5)
    )
  
}

##

pal <- read_csv(""https://github.com/asrenninger/palettes/raw/master/orred.txt"", col_names = FALSE) %>% pull(X1)

##

for (i in 1:nrow(centroids)) {
  
  plot <-
    ggplot() +
    geom_polygon(data = poly, 
                 aes(x = X, y = Y, group = L1),
                 fill = '#696969', colour = '#FFFFFF', size = 0.1) +
    geom_point(data = shoots, 
               aes(x = lon, y = lat, size = review_rating, colour = review_rating), 
               alpha = 0.5,
               show.legend = FALSE) +
    scale_size_continuous(range = c(0.1, 3)) +
    scale_colour_gradientn(colours = pal) +
    coord_map(""ortho"", orientation = c(coords$Y[i], coords$X[i], 0)) +
    labs(title = glue(""{centroids$n[i]} film shoots""), subtitle = glue(""{centroids$continent[i]}""), 
         x = ""city"", y = ""number"") +
    theme_map()
  
  plots[[glue(""plot{i}"")]] <- plot
  
}

## 

library(gridExtra)
library(grid)

## 

blank <- grid.rect(gp = gpar(col = 'transparent', fill = 'transparent'))

lay <- rbind(c(1, 1, 1, 2, 2, 2),
             c(1, 1, 1, 2, 2, 2),
             c(1, 1, 1, 2, 2, 2),
             c(3, 3, 3, 4, 4, 4),
             c(3, 3, 3, 4, 4, 4),
             c(3, 3, 3, 4, 4, 4),
             c(5, 5, 5, 6, 6, 6),
             c(5, 5, 5, 6, 6, 6),
             c(5, 5, 5, 6, 6, 6)) 

agg <- grobTree(rectGrob(gp = gpar(fill = 'transparent', lwd = 0)), 
                grid.arrange(grobs = plots, layout_matrix = lay))

ggsave(agg, filename = ""aggregate.png"", height = 12, width = 12, dpi = 300)

##
","Other-12"
"732",534,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/correlations.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext)
csv_files <- grep(""\\.csv"",list.files(), value = TRUE)

set.seed(4)
x <- bind_rows(lapply(csv_files, function(i) read_csv(i)))

set.seed(5)
right_sample <- x %>% filter(account_type == ""left"" & language == ""English"") %>%
  sample_n(20000) %>% mutate(content = rtweet::plain_tweets(content))

##Convert into Tidy Text
replace_reg <- ""https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https""
unnest_reg <- ""([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))""

tidy_tweets <- right_sample %>% mutate(text = content) %>%
  select(author, text) %>% mutate(text = str_replace_all(text, replace_reg, """")) %>%
  unnest_tokens(word, text, token = ""regex"",pattern = unnest_reg) %>% filter(!word %in% stop_words$word,
                                                                             str_detect(word,""[a-z]""))
##Get Correlations
library(tidyr)
library(gtools)
library(stringr)
library(igraph)
library(ggraph)
library(widyr)

word_cors <- tidy_tweets%>% group_by(word) %>% filter(n() >= 30) %>% pairwise_cor(word, author, sort = TRUE)
word_cors <- word_cors %>% mutate(to_filter = as.numeric(row.names(word_cors)) %%2) %>% filter(to_filter == 0) %>% mutate(to_filter = NULL)


set.seed(5)
word_cors %>%
  filter(correlation> .75) %>%
  graph_from_data_frame() %>%
  ggraph(layout = ""fr"") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = ""firebrick"", size = 4) +
  geom_node_label(aes(label = name), repel = TRUE, size = 3) +
  theme_minimal() + labs(title =""Word correlations within tweets published by left wing bots"", y = """", x= """",
                         subtitle = ""Correlations over 0.75"")

##Need to fix the graph
word_cors %>% filter(item1 %in% c(""#nowplaying"",""#blacklivesmatter"", ""white"",""trump"")) %>%
  group_by(item1) %>% filter(item2!=""trump's"") %>% top_n(10) %>% ungroup() %>%
  filter(item2!=""video"") %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation, fill = item1)) + geom_bar(stat = ""identity"", show.legend = FALSE) + facet_wrap(~item1, scales = ""free"") + coord_flip() + 
  labs(y = ""Correlation"", x = ""Word"", title = ""Top correlations for selected words"",
       subtitle = ""Data for left wing bots"") + theme_bw()


##Get related words
hip_hop_words <- word_cors %>% filter(item1 %in% c(""#nowplaying"")) %>%
  group_by(item1) %>% top_n(15) %>%
  pull(item2) %>% append(""#nowplaying"")

blm_words <- word_cors %>% filter(item1 %in% c(""#blacklivesmatter"")) %>%
  group_by(item1) %>% top_n(15) %>%
  pull(item2) %>% append(""#blacklivesmatter"")

trump_words <- word_cors %>% filter(item1 %in% c(""trump"")) %>%
  filter(item2!=""trump's"") %>%
  group_by(item1) %>% top_n(15) %>%
  pull(item2) %>% append(""trump"")


##search for term function
search_term <- function(word, data_frame){
  x <- data_frame
  k <- x[grep(word, x$content),] %>%
    dplyr::select(content, publish_date)
  print(paste0(""Retrieved "",word))
  return(k)
}

##Not searching for 'playing' because it is too broad of a term
library(lubridate)
list_1 <- lapply(2:length(hip_hop_words), function(i)search_term(hip_hop_words[i], x %>% filter(account_type == ""left"")))
hh_df <- bind_rows(list_1) %>% unique()

hh_by_month <- hh_df %>% mutate(publish_date = mdy_hm(publish_date)) %>%
  mutate(month_year = floor_date(publish_date,unit = ""month"")) %>%
  group_by(month_year) %>% summarise(total = n()) %>%
  arrange(month_year) %>% mutate(group = ""Music Words"")


##Searching for BLM
list_2 <- lapply(1:length(blm_words), function(i)search_term(blm_words[i], x %>% filter(account_type == ""left"")))
blm_df <- bind_rows(list_2) %>% unique()


blm_by_month <- blm_df %>% mutate(publish_date = mdy_hm(publish_date)) %>%
  mutate(month_year = floor_date(publish_date,unit = ""month"")) %>%
  group_by(month_year) %>% summarise(total = n()) %>%
  arrange(month_year) %>% mutate(group = ""BLM Words"")

##Searching for DJT words
list_3 <- lapply(1:length(trump_words), function(i)search_term(trump_words[i], x %>% filter(account_type == ""left"")))
djt_df <- bind_rows(list_3) %>% unique()


djt_by_month <- djt_df %>% mutate(publish_date = mdy_hm(publish_date)) %>%
  mutate(month_year = floor_date(publish_date,unit = ""month"")) %>%
  group_by(month_year) %>% summarise(total = n()) %>%
  arrange(month_year) %>% mutate(group = ""Trump Words"")


##
djt_dates <- tibble(get_date = as.POSIXct(c(""2016-11-08 UTC"",""2017-01-01 UTC"",""2015-06-01 UTC"")),
                    value = c(2633, 2156,1765),
                    my_label = c(""Election"", ""Inauguration"", ""Announcement""),
                    group = ""Trump Words"")

blm_dates <- tibble(get_date = as.POSIXct(c(""2016-02-01 UTC"",""2017-04-01 UTC"",""2015-08-01 UTC"")),
                    value = c(2114, 1367,697),
                    my_label = c(""HRC Interrupted"", ""Jordan Edwards"", ""Sanders Interrupted""),
                    group = ""BLM Words"")

##
bind_rows(blm_by_month, hh_by_month, djt_by_month) %>%
  filter(month_year > ymd(""2014-01-01"")) %>%
  ggplot(aes(month_year, y = total, color = group)) + geom_line(size = 0.5, show.legend = FALSE) + theme_bw() +
  geom_point(aes(x = get_date, y = value),color = ""black"", data = djt_dates) + 
  geom_label(aes(x = get_date, y = value, label = my_label),color = ""black"",data = djt_dates, size = 3, alpha = 0.5) + 
  geom_label(aes(x = get_date, y = value, label = my_label),color = ""black"",data = blm_dates, size = 3, alpha = 0.5) + 
  facet_wrap(~group) + 
  labs(x = ""Time"", y = ""Total"",
       title = ""Total tweets containing groups of selected keywords"",
       subtitle = ""Data for left wing bots - Data aggregated monthly"")

##
","Other-20"
"733",535,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/left_right_comparison.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext)


csv_files <- grep(""\\.csv"",list.files(), value = TRUE)
x <- bind_rows(lapply(csv_files, function(i) read_csv(i))) 

english <- x %>% filter(language == ""English"")
##
#hashtags <- tibble(hashtag = unlist(stringr::str_extract_all(rtweet::plain_tweets(english$content),""#\\S+"")))
#saveRDS(hashtags, ""all_hashtags.RDS"")

##political hashtags
politics <- x %>% filter(language == ""English"") %>%
  filter(account_category %in% c(""RightTroll"",""LeftTroll""))

#pol_hashtags <- tibble(hashtag = unlist(stringr::str_extract_all(rtweet::plain_tweets(politics$content),""#\\S+"")))
#saveRDS(pol_hashtags, ""political_hashtags.RDS"")
pol_hashtags <- readRDS(""political_hashtags.RDS"")

total_pols <- pol_hashtags %>% mutate(hashtag = str_to_lower(hashtag)) %>%
  count(hashtag, sort = TRUE) %>% filter(n > 100)

##politics, no rtweets or replies
politics <- politics %>% filter(is.na(post_type)) %>%
  mutate(content = rtweet::plain_tweets(content))

politics <- politics %>% mutate(content = gsub(""'$|^'"","""",content)) %>%
  mutate(content = gsub('""$|^""',"""",content)) %>%
  mutate(publish_date = lubridate::mdy(gsub(""\\s.*"","""",publish_date)))


##
my_words <- readxl::read_excel(""most_common_words_english_for_twitter.xlsx"")
replace_reg <- ""https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https""
unnest_reg <- ""([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))""

tidy_politics <- politics %>% select(content, publish_date, account_type) %>%
  mutate(content = tm::removeNumbers(str_replace_all(content, replace_reg, """"))) %>%
  mutate(content = gsub(""[^[:alnum:][:space:]]"","""",content)) %>%
  unnest_tokens(word, content, token = ""regex"", pattern = unnest_reg) %>%
  anti_join(stop_words) %>% anti_join(my_words)

##
for_graph <- tidy_politics %>% mutate(account_type = ifelse(account_type == ""right"", ""Right"", account_type)) %>%
  group_by(account_type, word) %>% tally() %>%
  filter(n > 100) %>%
  left_join(tidy_politics %>%
              mutate(account_type = ifelse(account_type == ""right"", ""Right"", account_type)) %>%
              count(account_type, sort = TRUE) %>% rename(total = n)) %>%
  mutate(proportion = n/total)

library(scales)
for_graph %>% ungroup() %>%
  select(-n, -total) %>%
  spread(account_type, proportion) %>%
  ggplot(aes(left, Right)) + 
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  geom_abline(color = ""red"")

","Other-20"
"734",536,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/modelling_accounts.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext)


##Bring and sample data
x <- read_csv(""sampled_tweets.csv"") %>%
  filter(account_type %in% c(""left"", ""Right"") & language == ""English"")
x <- x %>% mutate(account_type = str_to_title(account_type))

set.seed(1)
x_2 <- x %>% sample_n(10000) %>% dplyr::rename(text = content) %>%
  mutate(text = rtweet::plain_tweets(text)) %>%
  mutate(document = 1:10000)

###
tidy_tweets <- x_2 %>% select(document, account_type,text) %>%
  unnest_tokens(word, text, token = ""tweets"") %>%
  group_by(word) %>% filter(n() > 10) %>%
  ungroup()

##Create a sparse matrix
sparse_tweets <- tidy_tweets %>% dplyr::count(document, word, sort = TRUE) %>%
  cast_sparse(document, word, n)

tweets_joined  <- data_frame(document = (as.integer(rownames(sparse_tweets)))) %>%
  left_join(x_2) %>% select(document,account_type)


##Fit the model
library(glmnet)
response_model <- tweets_joined$account_type == ""Right""

lasso_model <- cv.glmnet(sparse_tweets,
                         y = response_model,
                         family = ""binomial"",
                         alpha = 0,
                         nfolds = 10)

##Tidying the model
library(broom)

coefficients <- lasso_model$glmnet.fit %>% tidy() %>%
  filter(lambda == lasso_model$lambda.min)

##Predict probabilities
classifications <- tidy_tweets %>% inner_join(coefficients, by = c(""word"" = ""term"")) %>%
  group_by(document) %>%
  summarize(Score = sum(estimate)) %>%
  mutate(probability = arm::invlogit(0.366 + Score)) %>%
  mutate(predictions = ifelse(probability > 0.55, ""Right"", ""Left""))%>% ##Increasing threshold
  inner_join(x_2 %>% select(document, account_type))

##Create confusion matrix: wrong because this is training data
classifications %>% group_by(predictions, account_type) %>% tally() %>%
  spread(account_type, n)

##
coefficients %>% filter(term!=""(Intercept)"") %>%
  top_n(n = 12, estimate) %>% arrange(desc(estimate)) %>%
  bind_rows(coefficients %>% filter(term!=""(Intercept)"") %>%
              top_n(n = -12, estimate) %>% arrange(estimate)) %>% 
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = estimate >0)) + geom_col(show.legend = FALSE) + coord_flip() + 
  theme_minimal() + 
  labs(x = ""Term"", y = ""Coefficient"", title = ""Largest and smallest coefficients: Lasso fit"") + 
  theme(
    text = element_text(family = ""Roboto"")
  )


##Total zero coefficients
lasso_model$nzero

##Get ROC curve: Test set
account_classes <- classifications %>% mutate(Correct = (predictions == account_type))
original_classifications <- as.numeric(factor(account_classes$account_type)) - 1
predictions <- as.numeric(factor(account_classes$predictions)) - 1
pROC::roc(original_classifications, predictions)

##Predicted right, but actually left
mistakes <- classifications %>% filter(account_type == ""Left"" & probability > 0.7)


##Do a word cloud of the mistakes 
x_2 %>% filter(document %in% mistakes$document) %>% 
  select(text) %>% unnest_tokens(word, text, token = ""tweets"") %>%
  anti_join(stop_words) %>% group_by(word) %>% tally() %>% arrange(desc(n)) %>%
  slice(1:200) %>%
  wordcloud2::wordcloud2(color = ""firebrick"", fontFamily = ""Roboto"")

#Pretty good job of identifying right wing accounts
classifications %>%
  ggplot(aes(x = probability*100, y = ..density.., fill = account_type)) + 
  geom_density(adjust = 3, show.legend = TRUE,alpha = 0.5) + 
  theme_minimal() + 
  theme(legend.position = ""bottom"",
        legend.title = element_text(face = ""bold"")) + 
  labs(x = ""Predicted probability of being a right-wing account"", y= ""Density"") + 
  scale_fill_manual(values = c(""navyblue"", ""firebrick3"")) + 
  guides(fill = guide_legend(title = ""Account type"", title.position = ""top"", 
                             title.hjust = 0.5, barwidth = 20,
                             barheight = 0.5,keywidth = 5,keyheight = 0.5,nrow = 1,label.position = ""bottom""))


classifications %>% filter(account_type == ""Left"") %>%
  pull(probability) %>% quantile(probs = seq(0,1,by = 0.1)) %>% round(3)*100

","Other-20"
"735",537,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/modelling_accounts_with_test_set.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext)


##Bring and sample data
x <- read_csv(""sampled_tweets.csv"") %>%
  filter(account_type %in% c(""left"", ""Right"") & language == ""English"")
x <- x %>% mutate(account_type = str_to_title(account_type))

set.seed(1)
x_2 <- x %>% sample_n(20000) %>% dplyr::rename(text = content) %>%
  mutate(text = rtweet::plain_tweets(text)) %>%
  mutate(document = 1:20000)

###
tidy_tweets <- x_2 %>% select(document, account_type,text) %>%
  unnest_tokens(word, text, token = ""tweets"") %>%
  group_by(word) %>% filter(n() > 10) %>%
  ungroup()

##Create a sparse matrix
sparse_tweets <- tidy_tweets %>% dplyr::count(document, word, sort = TRUE) %>%
  cast_sparse(document, word, n)

tweets_joined  <- data_frame(document = (as.integer(rownames(sparse_tweets)))) %>%
  left_join(x_2) %>% select(document,account_type)

##Fit the model and split the sample
set.seed(1)
train_rows <- sample(1:19660, 15000)

library(glmnet)
response_model <- tweets_joined$account_type == ""Right""


lasso_model <- cv.glmnet(sparse_tweets[train_rows,],
                         y = response_model[train_rows],
                         family = ""binomial"",
                         alpha = 1,
                         nfolds = 10)


##Check coefficients
##Tidying the model
library(broom)

coefficients <- lasso_model$glmnet.fit %>% tidy() %>%
  filter(lambda == lasso_model$lambda.min)


##Training data predictions
test_classification <- tidy_tweets%>% filter(!document %in% train_rows) %>%
  inner_join(coefficients, by = c(""word"" = ""term"")) %>%
  dplyr::group_by(document) %>%
  dplyr::summarize(Score = sum(estimate)) %>%
  mutate(probability = arm::invlogit(0.2777646 + Score)) %>%
  mutate(predictions = ifelse(probability > 0.55, ""Right"", ""Left""))%>% ##We can do slightly better by increasing threshold
  inner_join(x_2 %>% select(document, account_type))


##Create confusion matrix
test_classification %>% group_by(predictions, account_type) %>% tally() %>%
  spread(account_type, n)

##Top coefficients
coefficients %>% filter(term!=""(Intercept)"") %>%
  top_n(n = 15, estimate) %>% arrange(desc(estimate)) %>%
  bind_rows(coefficients %>% filter(term!=""(Intercept)"") %>%
              top_n(n = -15, estimate) %>% arrange(estimate)) %>% 
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = estimate >0)) + geom_col(show.legend = FALSE) + coord_flip() + 
  theme_minimal() + 
  labs(x = ""Term"", y = ""Coefficient"", title = ""Largest and smallest coefficients: Lasso fit"") + 
  theme(
    text = element_text(family = ""Roboto"")
  )


##Get ROC curve: Test set
account_classes <- test_classification %>% mutate(Correct = (predictions == account_type))
original_classifications <- as.numeric(factor(account_classes$account_type)) - 1
predictions <- as.numeric(factor(account_classes$predictions)) - 1
pROC::roc(original_classifications, predictions)


##Predicted right, but actually left
mistakes <- test_classification %>% filter(account_type == ""Left"" & probability > 0.7)

##Do a word cloud of the mistakes 
x_2 %>% filter(document %in% mistakes$document) %>% 
  select(text) %>% unnest_tokens(word, text, token = ""tweets"") %>%
  anti_join(stop_words) %>% group_by(word) %>% tally() %>% arrange(desc(n)) %>%
  slice(1:200) %>%
  wordcloud2::wordcloud2(color = ""firebrick"", fontFamily = ""Roboto"")

test_classification %>%
  ggplot(aes(x = probability*100, y = ..density.., fill = account_type)) + 
  geom_density(adjust = 4, show.legend = TRUE,alpha = 0.5) + 
  theme_minimal() + 
  theme(legend.position = ""bottom"",
        legend.title = element_text(face = ""bold""),
        plot.title = element_text(size = 14, face = ""bold"")) + 
  labs(x = ""Pr(Y = right-wing | X)"", y= ""Density"",
       title = ""Model generated probability of being a right-wing account"",
       subtitle = ""Probabilities generated by a Lasso model"") + 
  scale_fill_manual(values = c(""navyblue"", ""firebrick3"")) + 
  guides(fill = guide_legend(title = ""Account type"", title.position = ""top"", 
                             title.hjust = 0.5, barwidth = 20,
                             barheight = 0.5,keywidth = 5,keyheight = 0.5,nrow = 1,label.position = ""bottom""))


##Building a TF-IDF
","Other-20"
"736",538,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/read_and_sample.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext)
csv_files <- grep(""\\.csv"",list.files(), value = TRUE)

set.seed(4)
x <- bind_rows(lapply(csv_files, function(i) read_csv(i) %>% sample_n(30000)))
write_csv(x, ""sampled_tweets.csv"")","Other-20"
"737",539,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/right_wing_correlations.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext)
csv_files <- grep(""\\.csv"",list.files(), value = TRUE)

set.seed(4)
x <- bind_rows(lapply(csv_files, function(i) read_csv(i)))

set.seed(5)
right_sample <- x %>% filter(account_type %in% c(""right"",""Right"") & language == ""English"") %>%
  sample_n(20000) %>% mutate(content = rtweet::plain_tweets(content))

##Convert into Tidy Text
replace_reg <- ""https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https""
unnest_reg <- ""([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))""

tidy_tweets <- right_sample %>% mutate(text = content) %>%
  select(author, text) %>% mutate(text = str_replace_all(text, replace_reg, """")) %>%
  unnest_tokens(word, text, token = ""regex"",pattern = unnest_reg) %>% filter(!word %in% stop_words$word,
                                                                             str_detect(word,""[a-z]""))
##Get Correlations
library(tidyr)
library(gtools)
library(stringr)
library(igraph)
library(ggraph)
library(widyr)

word_cors <- tidy_tweets%>% group_by(word) %>% filter(n() >= 30) %>% pairwise_cor(word, author, sort = TRUE)
word_cors <- word_cors %>% mutate(to_filter = as.numeric(row.names(word_cors)) %%2) %>% filter(to_filter == 0) %>% mutate(to_filter = NULL)


set.seed(5)
word_cors %>% ungroup() %>%
  filter(item1 !=""debalwaystrump"") %>%
  filter(item2 !=""debalwaystrump"") %>%
  filter(correlation> .85) %>%
  graph_from_data_frame() %>%
  ggraph(layout = ""fr"") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = ""steelblue"", size = 4) +
  geom_node_label(aes(label = name), repel = TRUE, size = 3) +
  theme_minimal() + labs(title =""Word correlations within tweets published by right wing bots"", y = """", x= """",
                         subtitle = ""Correlations over 0.85"")

##
word_cors %>% filter(item1 %in% c(""trump"",""army"", ""cnn"",""congress"")) %>%
  group_by(item1) %>% filter(item2!=""trump's"") %>% 
  filter(item2 !=""debalwaystrump"") %>%
  top_n(10) %>% ungroup() %>%
  filter(item2!=""video"") %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation, fill = item1)) + geom_bar(stat = ""identity"", show.legend = FALSE) + facet_wrap(~item1, scales = ""free"") + coord_flip() + 
  labs(y = ""Correlation"", x = ""Word"", title = ""Top correlations for selected words"",
       subtitle = ""Data for right wing bots"") + theme_bw()

##Get related words
army_words <- word_cors %>% filter(item1 %in% c(""army"")) %>%
  filter(item2!=""return"") %>%
  group_by(item1) %>% top_n(10) %>%
  pull(item2) %>% append(""army"")

congress_words <- word_cors %>% filter(item1 %in% c(""congress"")) %>%
  filter(item2 !=""debalwaystrump"") %>%
  group_by(item1) %>% top_n(10) %>%
  pull(item2) %>% append(""congress"")

trump_words <- word_cors %>% filter(item1 %in% c(""trump"")) %>%
  filter(item2!=""trump's"") %>%
  group_by(item1) %>% top_n(10) %>%
  pull(item2) %>% append(""trump"")

#
##search for term function
search_term <- function(word, data_frame){
  x <- data_frame
  k <- x[grep(word, x$content),] %>%
    dplyr::select(content, publish_date)
  print(paste0(""Retrieved "",word))
  return(k)
}

##
library(lubridate)
list_1 <- lapply(1:length(army_words), function(i)search_term(army_words[i], x %>% filter(account_type %in% c(""right"", ""Right""))))
army_df <- bind_rows(list_1) %>% unique()

army_by_month <- army_df %>% mutate(publish_date = mdy_hm(publish_date)) %>%
  mutate(month_year = floor_date(publish_date,unit = ""month"")) %>%
  group_by(month_year) %>% summarise(total = n()) %>%
  arrange(month_year) %>% mutate(group = ""Army Words"")

##Searching for Congress
list_2 <- lapply(1:length(congress_words), function(i)search_term(congress_words[i], x %>% filter(account_type %in% c(""right"", ""Right""))))
congress_df <- bind_rows(list_2) %>% unique()


congress_by_month <- congress_df %>% mutate(publish_date = mdy_hm(publish_date)) %>%
  mutate(month_year = floor_date(publish_date,unit = ""month"")) %>%
  group_by(month_year) %>% summarise(total = n()) %>%
  arrange(month_year) %>% mutate(group = ""Congress Words"")

##Searching for DJT words
list_3 <- lapply(1:length(trump_words), function(i)search_term(trump_words[i], x %>% filter(account_type %in% c(""right"", ""Right""))))
djt_df <- bind_rows(list_3) %>% unique()


djt_by_month <- djt_df %>% mutate(publish_date = mdy_hm(publish_date)) %>%
  mutate(month_year = floor_date(publish_date,unit = ""month"")) %>%
  group_by(month_year) %>% summarise(total = n()) %>%
  arrange(month_year) %>% mutate(group = ""Trump Words"")


##
bind_rows(army_by_month, congress_by_month, djt_by_month) %>%
  filter(month_year > ymd(""2014-01-01"")) %>%
  ggplot(aes(month_year, y = total, color = group)) + geom_line(size = 0.5, show.legend = FALSE) + theme_bw() +
  #geom_point(aes(x = get_date, y = value),color = ""black"", data = djt_dates) + 
  #geom_label(aes(x = get_date, y = value, label = my_label),color = ""black"",data = djt_dates, size = 3, alpha = 0.5) + 
  #geom_label(aes(x = get_date, y = value, label = my_label),color = ""black"",data = blm_dates, size = 3, alpha = 0.5) + 
  facet_wrap(~group) + 
  labs(x = ""Time"", y = ""Total"",
       title = ""Total tweets containing groups of selected keywords"",
       subtitle = ""Data for right wing bots - Data aggregated monthly"")
","Other-20"
"738",540,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/sentiment_analysis.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext);library(tm);library(lubridate)
csv_files <- grep(""\\.csv"",list.files(), value = TRUE)


x <- bind_rows(lapply(csv_files, function(i) read_csv(i)))
my_words <- readxl::read_excel(""most_common_words_english_for_twitter.xlsx"")

set.seed(4)
sample_1 <- x %>% filter(language == ""English"" & is.na(post_type)) %>%
  sample_n(60000) %>% mutate(content = rtweet::plain_tweets(content))


##Define clean variable function
clean_text_variable <- function(the_vector){
  library(tm)
  the_vector <- stringi::stri_trans_general(the_vector, ""latin-ascii"")
  #change to lower case, only alpha-numeric
  the_vector <- stringr::str_trim(gsub(""[^[:alnum:] ]"", "" "" , tolower(the_vector)))
  #kills websites
  the_vector <- stringr::str_trim(gsub('http.* *', '', the_vector))
  #removes punctuation
  the_vector <- removePunctuation(the_vector)
  #removes numbers
  the_vector <- removeNumbers(the_vector)
  #remove whitespace
  the_vector <- stripWhitespace(the_vector)
  ##
  #remove whitespace
  the_vector <- stringr::str_trim(stripWhitespace(the_vector))
}

sample_2 <- sample_1 %>% mutate(content = clean_text_variable(content)) %>%
  mutate(publish_date = floor_date(mdy_hm(publish_date),unit = ""day"")) %>%
  mutate(month = floor_date(publish_date, ""month"")) %>%
  mutate(day = floor_date(publish_date, ""day"")) %>%
  mutate(account_type = ifelse(account_type == ""right"", ""Right"", account_type))

##
with_sentiment <- sample_2 %>% dplyr::select(account_type, content, day) %>%
  unnest_tokens(word, content) %>%
  anti_join(stop_words) %>%
  anti_join(my_words) %>% inner_join(get_sentiments(lexicon = ""afinn"")) %>%
  filter(word != ""trump"")

##
aggregate_sentiment <- with_sentiment %>% filter(day > ymd(""2015-01-01"")) %>%
  mutate(account_type = str_to_title(account_type)) %>%
  group_by(account_type, day) %>% dplyr::summarise(daily_score = sum(score)) %>%
  filter(account_type %in% c(""Right"", ""Left""))

##first  
aggregate_sentiment %>% 
  filter(day > ymd(""2016-01-01"")) %>%
  mutate(month = floor_date(day, unit = ""month"")) %>%
  group_by(month, account_type) %>%
  summarise(monthly_median = median(daily_score)) %>%
  ggplot(aes(x = month, y = monthly_median, fill = monthly_median >0)) +
  geom_col(show.legend = FALSE, color = ""black"") + facet_wrap(~account_type) + theme_bw() + 
  scale_fill_manual(values = c(""firebrick"",""blue"")) + 
  labs(y = ""Daily Score"", x = ""Day"", title = ""Median Daily Sentiment by Month"",
       subtitle = ""Data for Political Bots"")


##Find Worst scoring months
aggregate_sentiment %>% 
    filter(day > ymd(""2016-01-01"")) %>%
    mutate(month = floor_date(day, unit = ""month"")) %>%
    group_by(month, account_type) %>%
    summarise(monthly_median = median(daily_score)) %>%
    arrange(monthly_median, account_type) ##Worst months for the right are
                                           ##August, September, October 2017

##Doing a TF-IDF of those months,
###     comparing to three before, and three after

target_period <- c(ymd(""2017-08-01""),ymd(""2017-09-01""),ymd(""2017-10-01""))
previous <- c(ymd(""2017-05-01""),ymd(""2017-06-01""),ymd(""2017-07-01""))
after <- c(ymd(""2017-11-01""),ymd(""2017-12-01""),ymd(""2018-01-01""))

for_tfidf <- sample_2 %>% filter(day > ymd(""2017-05-01"") & day < ymd(""2017-11-01"")) %>%
    filter(account_type == ""Right"") %>%
    mutate(period = paste0(month(month),""-"",year(month)))


##Start TF-IDF
replace_reg <- ""https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https""
unnest_reg <- ""([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))""

##Get Right Wing First
tidy_right <- for_tfidf %>% dplyr::rename(text = content) %>%
    filter(account_type == ""Right"") %>%
    dplyr::select(period,text) %>% mutate(text = str_replace_all(text, replace_reg, """")) %>%
    unnest_tokens(word, text) 

total_words <- tidy_right %>% 
    dplyr::group_by(period) %>% 
    dplyr::summarize(total = n())

list_tf_right <- tidy_right %>% group_by(period, word) %>% summarise(total_period = n()) %>%
    left_join(total_words) %>%
    bind_tf_idf(word, period, total_period) %>% anti_join(stop_words)


list_tf_right %>%
    dplyr::select(-total) %>%
    arrange(desc(tf_idf))


list_tf_right %>% arrange(desc(tf_idf)) %>%
    mutate(nchar = nchar(word)) %>% filter(nchar >3) %>%
    dplyr::select(-nchar) %>%
    group_by(period) %>% arrange(period, desc(tf_idf)) %>% 
    slice(1:20) %>%
    ungroup() %>% group_by(word) %>%
    top_n(1,tf_idf) %>%
    ggplot(aes(reorder(word,tf_idf), tf_idf, fill = period)) +
    geom_col(show.legend = FALSE) +
    labs(x = NULL, y = ""tf-idf"") +
    facet_wrap(~period,scales = ""free"") +
    coord_flip() + theme_bw()","Other-20"
"739",541,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/tf_idf_left_right.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(tidytext)

x <-read_csv(""sampled_tweets.csv"") %>%
  filter(language == ""English"")


x <- x %>% mutate(content = rtweet::plain_tweets(content))

##Begin data processing
right_left <- x %>% filter(account_category %in% c(""RightTroll"", ""LeftTroll"")) %>%
  mutate(publish_date = lubridate::mdy(gsub(""\\s.*"","""",publish_date))) %>%
  mutate(harvested_date = lubridate::mdy(gsub(""\\s.*"","""",harvested_date))) %>%
  mutate(year = lubridate::year(publish_date))


##Right wing accounts
right <- right_left %>% filter(account_category == ""RightTroll"" & year >=2015)
left <- right_left %>% filter(account_category == ""LeftTroll"" & year >=2015)

##
replace_reg <- ""https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https""
unnest_reg <- ""([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))""


##Get Right Wing First
tidy_right <- right %>% dplyr::rename(text = content) %>%
  select(year,text) %>% mutate(text = str_replace_all(text, replace_reg, """")) %>%
  unnest_tokens(word, text, token = ""regex"",pattern = unnest_reg) 

total_words <- tidy_right %>% 
  dplyr::group_by(year) %>% 
  dplyr::summarize(total = n())

list_tf_right <- tidy_right %>% group_by(year, word) %>% summarise(total_year = n()) %>%
  left_join(total_words) %>%
  bind_tf_idf(word, year, total_year) %>% anti_join(stop_words)


list_tf_right %>%
  select(-total) %>%
  arrange(desc(tf_idf))

list_tf_right %>% arrange(desc(tf_idf)) %>%
  mutate(nchar = nchar(word)) %>% filter(nchar >3) %>%
  dplyr::select(-nchar) %>%
  group_by(year) %>% arrange(year, desc(tf_idf)) %>% 
  slice(1:20) %>%
  ungroup() %>%
  mutate(word = ifelse(year == 2015, paste0(word,"" ""),
                       ifelse(year == 2016, paste0("" "",word),
                              ifelse(year == 2017, paste0(""  "",word),word)))) %>%
  ggplot(aes(reorder(word,tf_idf), tf_idf, fill = as.character(year))) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = ""tf-idf"") +
  facet_wrap(~year,scales = ""free"") +
  coord_flip() + theme_bw() +
  labs(x = ""Word"", y = ""TF-IDF"", title = ""TF-IDF of Right Wing Trolls: Data for Selected Years"", 
       subtitle = ""Based on 68,263 Tweets from a random sample of 300,000 tweets"",
       caption = ""Tidy Tuesday week 20, Russian Bot Data\nOnly tweets in English"")


##Repeat for Left Wing
tidy_left <- left %>% dplyr::rename(text = content) %>%
  select(year,text) %>% mutate(text = str_replace_all(text, replace_reg, """")) %>%
  unnest_tokens(word, text, token = ""regex"",pattern = unnest_reg) 

total_words <- tidy_left %>% 
  dplyr::group_by(year) %>% 
  dplyr::summarize(total = n())

list_tf_left <- tidy_left %>% group_by(year, word) %>% summarise(total_year = n()) %>%
  left_join(total_words) %>%
  bind_tf_idf(word, year, total_year) %>% anti_join(stop_words)


list_tf_left %>%
  select(-total) %>%
  arrange(desc(tf_idf))

list_tf_left %>% arrange(desc(tf_idf)) %>%
  mutate(nchar = nchar(word)) %>% filter(nchar >3) %>%
  dplyr::select(-nchar) %>%
  group_by(year) %>% arrange(year, desc(tf_idf)) %>% 
  slice(1:20) %>%
  ungroup() %>%
  mutate(word = ifelse(year == 2015, paste0(word,"" ""),
                       ifelse(year == 2016, paste0("" "",word),
                              ifelse(year == 2017, paste0(""  "",word),word)))) %>%
  ggplot(aes(reorder(word,tf_idf), tf_idf, fill = as.character(year))) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = ""tf-idf"") +
  facet_wrap(~year,scales = ""free"") +
  coord_flip() + theme_bw() +
  labs(x = ""Word"", y = ""TF-IDF"", title = ""TF-IDF of Left Wing Trolls: Data for Selected Years"", 
       subtitle = ""Based on 44,858 Tweets from a random sample of 300,000 tweets"",
       caption = ""Tidy Tuesday week 20, Russian Bot Data\nOnly tweets in English"")
","Other-20"
"740",542,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_20","Cyranka","rviz","tidy_tuesday_week_20/time_of_the_day.R","remove(list = ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_20/"")
library(tidyverse);library(lubridate)

x <- read_csv(""sampled_tweets.csv"")

##
k <- x %>% mutate(row = 1:nrow(x)) %>%
  select(publish_date, row) %>%
  separate(publish_date, into = c(""date"", ""time""), sep = "" "") %>%
  mutate(day_of_the_week = factor(wday(mdy(date),label = TRUE,week_start = 1)),
         hour = str_extract(time, ""^[0-9]{1,2}""))

k2 <- k %>% group_by(day_of_the_week, hour) %>% tally() %>%
  mutate(hour = as.numeric(hour)) %>%
  arrange(day_of_the_week, hour) %>%
  mutate(day_order = as.numeric(day_of_the_week)) %>% ungroup() %>%
  mutate(my_group = as.numeric(cut_width(n,1000,boundary = 0)))


k2 %>% arrange(hour, day_of_the_week) %>%
  ggplot(aes(y = reorder(day_order,-day_order), x = hour, fill = n)) + geom_tile(color = ""black"") + 
  theme_minimal() + 
  theme(
     text = element_text(size = 15)
  ) + 
  scale_fill_continuous(high = ""firebrick"", low = ""white"") + 
  scale_y_discrete(labels = c(""1"" = ""Mon"", ""2"" = ""Tue"",""3"" = ""Wed"",""4"" = ""Thu"", ""5"" = ""Fri"", ""6"" = ""Sat"", ""7"" = ""Sun"")) + 
  scale_x_continuous(breaks = c(0:23)) + labs(y = ""Day of the week"", x = ""Hour"", fill = ""Total tweets"",
                                              title = ""Russian bots: total tweets by hour and day of the week"")


##
library(RColorBrewer)
colors <- brewer.pal(5,""OrRd"")
k2 %>% arrange(hour, day_of_the_week) %>%
  ggplot(aes(y = reorder(day_order,-day_order), x = hour, fill =as.character(my_group))) + geom_tile(color = ""gray0"") + theme_minimal() + 
  scale_y_discrete(labels = c(""1"" = ""Mon"", ""2"" = ""Tue"",""3"" = ""Wed"",""4"" = ""Thu"", ""5"" = ""Fri"", ""6"" = ""Sat"", ""7"" = ""Sun"")) + 
  scale_x_continuous(breaks = c(0:23)) + labs(y = ""Day of the week"", x = ""Hour"", fill = ""Total tweets"",
                                              title = ""Russian bots: total tweets by hour and day of the week"") + 
  theme(legend.position=""bottom"") + scale_fill_manual(values = colors,labels = c(""0-1,000"",""1,001-2,000"",
                                                                                 ""2,001-3,000"", ""3,001-4,000"", ""Over 4,000""))

","Other-20"
"741",543,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_21","Cyranka","rviz","tidy_tuesday_week_21/human_fires_code.R","remove(list =ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_21/"")
library(tidyverse);library(readxl);library(lubridate)

x <- read_csv(""california_fires_1.csv"") %>% dplyr::rename(year = year_)
y <- read_excel(""cal_fire_units.xlsx"") 
z <- x %>% left_join(y, by = c(""unit_id"" = ""unit_name""))

##
causes_by_year <- z %>% group_by(year,fire_cause) %>%
  summarise(totals = n()) %>%
  group_by(year) %>%
  mutate(percent = totals/sum(totals))

causes_by_year %>%
  ggplot(aes(x = year, y = percent*100)) + geom_line(size = 1.1, alpha = 0.5) + 
  geom_smooth(se = FALSE, size = 1.1) + theme_bw() + 
  labs(x = ""Year"", y =""% of total fires"",
       title = ""% of total fires by year"",
       subtitle = ""Marked increase in the proportion of human-related fires since the 1950s"",
       caption = ""Tidy Tuesday Week 21: California Fires"") + facet_wrap(~fire_cause, nrow = 3) + 
  theme_minimal()


##Size by Decades
dec_labels <- c(""1950-1960"",""1961-1970"",""1971-1980"", ""1981-1990"", ""1991-2000"", ""2001-2010"",""2010-2017"")
decades <- z %>% mutate(decade = cut_width(year,10,boundary = 1950)) %>%
  arrange(year) %>% mutate(decade = factor(decade,labels = dec_labels))
  
decades %>%
  group_by(year, decade, fire_cause) %>%
  summarise(mean_log_gis_acres = mean(log(gis_acres,base = 2),na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = mean_log_gis_acres, color = decade)) +
  geom_line(size = 1.4) + theme_bw() + geom_smooth(size = 0.3,color = ""black"", se = FALSE) + 
  labs(x = ""Year"", color = ""Decade"", y = ""Mean log acres of fire"",
       title = ""Mean log acres of fire-related incidents by year"",
       subtitle = ""There has been a visible decrease in the acreage of fires \nSmooth line in black"",
       caption = ""Tidy Tuesday Week 21: California Fires\nY-axis is Base 2 Log"") + facet_wrap(~fire_cause, nrow = 3)


x %>% mutate(month = month(ymd(alarm_date),label = TRUE)) %>% count(month, sort = TRUE)","Other-21"
"742",544,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_21","Cyranka","rviz","tidy_tuesday_week_21/simulating_outcomes.R","remove(list =ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

#setwd(""/Users/francisco06121988/Desktop/rviz/tidy_tuesday_week_21/"")
library(tidyverse);library(readxl);library(lubridate);library(COUNT);library(arm)

x <- read_csv(""california_fires_1.csv"") %>% dplyr::rename(year = year_) %>%
    mutate(month = month(ymd(alarm_date)))
y <- read_excel(""avg_temperature.xlsx"") %>%
    rename(mean_temperature = Value)
z <- x %>% left_join(y, by = c(""year"" = ""Date"", ""month"" = ""Month"")) 

k <- z %>% group_by(year, month) %>%
    summarise(total = n(),
              avg_temperature = mean(mean_temperature,na.rm = TRUE))  %>%
    filter(!is.na(month))

k %>%
    ggplot(aes(x = avg_temperature, y = total)) + geom_point() + theme_bw()


##Use Only Natural
n_1 <- z %>% group_by(year, month) %>%
    summarise(total = n(),
              avg_temperature = mean(mean_temperature,na.rm = TRUE))  %>%
    filter(!is.na(month))

n_1 %>%
    ggplot(aes(x = avg_temperature, y = total)) + geom_point() + theme_bw()

##No Outliers and fit model
n_2 <- filter(n_1, total <180)

n_2 %>%
    ggplot(aes(x = avg_temperature, y = total)) + geom_point() + theme_bw()

fit_1 <- glm(total~avg_temperature, data = n_2, family = ""poisson"")

arm::display(fit_1)

###Goodness of Fit Test: Deviance should be distributed chi2
dev <- deviance(fit_1) ##Get Deviance Statistic
residual_df <- df.residual(fit_1) ##Residual Degrees of Freedom

1 - pchisq(dev, residual_df) ##We reject H0 that the model fits well the data

tibble(statistic = c(""Deviance GOF"",""D"",""df"",""p-value""),
       value = c("""",as.character(round(dev,2)),""281"",""0""))

##Calculating Dispersion
round(P__disp(fit_1),2) ##Very dispersed model

###What if we try a model that corrects for overdispersion?
##Standard errors have been scaled to account for overdispersion
fit_2 <- glm(total~avg_temperature, data = n_2, family = ""quasipoisson"")
display(fit_2, digits = 3) ##Notice how standard errors are now rescaled by the square root of the dispersion parameter


##Let's simulate the model and plot estimates
set.seed(4)
simulations <- sim(fit_2, 1000)

##Create list of predictions
temperature_seq <- seq(75,to = 85, by = 1)

# pred_1 <- exp(simulations@coef %*% c(1,80)) ##if avg temperature is 80 degrees.
# pred_2 <- exp(simulations@coef %*% c(1,85)) ##if avg temperature is 90 degrees. Old code adapted from Gelman
# pred_3 <- exp(simulations@coef %*% c(1,90)) 

linear_estimate <- lapply(1:10, function(i)exp(simulations@coef %*% c(1,temperature_seq[i])))


##Draw from a poisson distribution with mean lambda = prediction
#simulations_1 <- sapply(1:1000, function(i)rpois(n = 1,lambda = pred_1[i])) ##Old code adapted from Gelman
#simulations_2 <- sapply(1:1000, function(i)rpois(n = 1,lambda = pred_2[i]))
#simulations_3 <- sapply(1:1000, function(i)rpois(n = 1,lambda = pred_3[i]))


##Drawing 1,000 a poisson distribution with lambda = prediction
simulations_2 <- lapply(1:10, function(i)sapply(1:1000, function(k)rpois(n = 1,lambda = linear_estimate[[i]][[k]])) %>%
                        as_tibble() %>% mutate(temperature = temperature_seq[i]))

# sims <- tibble(sim_1 = simulations_1, sim_2 = simulations_2,sim_3 = simulations_3) %>%
#     gather(simulation, estimate) #%>% filter(estimate <25)


sim_df <- bind_rows(simulations_2)



##
library(ggridges);library(viridis)
sim_df %>% ggplot(aes(x = value, y = temperature,group = temperature, fill = ..x..)) + 
  geom_density_ridges_gradient(color = ""black"", show.legend = FALSE, alpha = 0.5) + 
  labs(x = ""Distribution of predicted number of wildfires"", y = ""Temperature"",
       title = ""Model based prediction of the number of wildfires in California"",
       subtitle = ""Estimates obtained using a quasi poission regression model"",
       caption = ""Source: Cal Fire\nTidy Tuesday Week 21"") + 
  scale_y_reverse(breaks = c(75:84)) + 
  scale_fill_viridis(alpha = 0.3, option = ""C"") +
  theme_minimal() + 
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_line(colour = ""black"", size = 0.3),
        plot.background = element_rect(fill = ""gainsboro""),
        text = element_text(color = ""black""),
        axis.text = element_text(colour = ""black""),
        strip.text = element_text(colour = ""black"",size = 12),
        plot.title = element_text(size = 15, face = ""bold""),
        plot.subtitle = element_text(size = 13))

##Now add regression uncertainty to the basic plot

##Subset simulations
set.seed(5)
subset_sim <- simulations@coef[sample(1:1000,100),1:2]

##Build Matrices
vavg_temp <- z$mean_temperature[!is.na(z$mean_temperature)]
intercepts <- rep(1, length(vavg_temp))
X_matrix <- matrix(c(intercepts, vavg_temp), ncol = 2)

list_of_fitted_values <- lapply(1:100, function(i)exp(X_matrix %*% subset_sim[i,]) %>% as_tibble() %>% mutate(sim_number = paste0(""simulation_"",i),
                                                                                                              temperature = X_matrix[,2]))
df_fitted_values <- bind_rows(list_of_fitted_values)
original_model <- tibble(temperature = fit_2$model$avg_temperature, fitted_values = fit_2$fitted.values)


###
graph_2 <- n_2 %>%
  ggplot(aes(x = avg_temperature, y = total)) + geom_point() + theme_bw() + 
  geom_line(data = df_fitted_values, aes(x = temperature, y = V1, group = sim_number), color = ""grey"", size = 2,alpha = 0.5) + 
  geom_line(data = original_model, aes(x = temperature, y = fitted_values), color = ""red"", size = 1) + 
  labs(x = ""Average monthly temperature"", y = ""Total wildfires"",
       caption = ""Source: Cal Fire\nTidy Tuesday Week 21"",
       title = ""Fitted quasi poisson regression of total wildfires on average monthly temperature"",
       subtitle = ""Red line represents estimated model\nGrey area shows variance of the estimated model"")


graph_2 + 
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_line(colour = ""black"", size = 0.1),
        #plot.background = element_rect(fill = ""gainsboro""),
        text = element_text(color = ""black""),
        axis.text = element_text(colour = ""black"", size = 12),
        strip.text = element_text(colour = ""black"",size = 12),
        axis.title.x = element_text(colour = ""black"", size = 12),
        plot.title = element_text(size = 13, face = ""bold""),
        plot.subtitle = element_text(size = 11))


","Other-21"
"743",545,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_21","Cyranka","rviz","tidy_tuesday_week_21/temperature_total_files.R","remove(list =ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_21/"")
library(tidyverse);library(readxl);library(lubridate)

x <- read_csv(""california_fires_1.csv"") %>% dplyr::rename(year = year_) %>%
  mutate(month = month(ymd(alarm_date)))
y <- read_excel(""avg_temperature.xlsx"") %>%
  rename(mean_temperature = Value)
z <- x %>% left_join(y, by = c(""year"" = ""Date"", ""month"" = ""Month"")) 

k <- z %>% group_by(year, month) %>%
  summarise(total = n(),
            avg_temperature = mean(mean_temperature,na.rm = TRUE))  %>%
  filter(!is.na(month))

k %>%
  ggplot(aes(x = avg_temperature, y = total)) + geom_point() + theme_bw()


##Use Only Natural
n_1 <- z %>% group_by(year, month) %>%
  filter(fire_cause %in% c(""Natural"")) %>%
  summarise(total = n(),
            avg_temperature = mean(mean_temperature,na.rm = TRUE))  %>%
  filter(!is.na(month))

n_1 %>%
  ggplot(aes(x = avg_temperature, y = total)) + geom_point() + theme_bw()

##No Outliers and fit model
n_2 <- filter(n_1, total <180)

n_2 %>%
  ggplot(aes(x = avg_temperature, y = total)) + geom_point() + theme_bw()

fit_1 <- glm(total~avg_temperature, data = n_2, family = ""poisson"")

arm::display(fit_1)
summary(fit_1)","Other-21"
"744",546,"https://github.com/Cyranka/rviz/tree/master/tidy_tuesday_week_21","Cyranka","rviz","tidy_tuesday_week_21/total_fires_county_map.R","remove(list =ls())
options(stringsAsFactors = FALSE)
options(scipen = 999)

setwd(""/Users/harrocyranka/Desktop/rviz/tidy_tuesday_week_21/"")
library(tidyverse);library(urbnmapr)


read_and_filter_ca <- function(files){
  k <- read_csv(files) %>% filter(state %in% c(""CA"", ""California""))
  return(k)
}

get_files <- grep(""buzzfee"",list.files(),value = TRUE)

##
j <- lapply(get_files, read_and_filter_ca)
ca_buzzfeed <- bind_rows(lapply(1:7, function(i) j[[i]] %>% mutate_all(as.character)))


##Data Frames to Use
with_county <- ca_buzzfeed %>% select(state,fips_name,fips_code,fire_year, discovery_date, fire_size,latitude,longitude) %>%
  filter(!is.na(fips_name)) %>% dplyr::rename(county = fips_name)

##Lat/Long
with_latlong <- ca_buzzfeed %>% select(state,fips_name,fips_code, fire_year, discovery_date, fire_size,latitude,longitude) %>%
   dplyr::rename(county = fips_name)


##County California Map
fires_by_county <- with_county %>% group_by(county) %>% 
  summarise(total_fires = n()) %>%
  mutate(county = paste0(county, "" County"")) %>%
  mutate(fire_group = cut_number(total_fires,5, boundary = 0, labels = FALSE))


##Labels for Map
get_labels <- fires_by_county %>% 
  group_by(fire_group) %>% 
  summarise(min = min(total_fires), max = max(total_fires)) %>%
  mutate(my_labels = paste0(min, ""-"",max))

#library(RColorBrewer)
colors <- brewer.pal(5,""YlOrRd"")

##groups to remove: c(""06037.3"",""06083.1"",""06111.3"")

groups_to_filter <- c(""06037.3"",""06083.5"",""06083.2"",""06083.3"",""06083.4"",""06111.3"")

fires_by_county %>% inner_join(urbnmapr::counties, by = c(""county"" = ""county_name"")) %>%
  filter(state_abbv == ""CA"" & !group %in% groups_to_filter) %>%
  ggplot(aes(long, lat, group = county, fill = as.character(fire_group))) + 
  geom_polygon(color = ""black"", size = .25)+ theme_minimal() + 
  scale_fill_manual(values = colors,labels = get_labels$my_labels) + 
  labs(x = """", y = """", fill = ""Total fires"",
       title = ""Total wildfires in California"",
       subtitle = ""County level map"",
       caption = ""Source: CalFire/Buzzfeed\nEach color represents groups of roughly equal size"") + 
  theme(panel.grid.major = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        plot.background = element_rect(fill = ""gray20""),
        legend.text = element_text(color = ""white"", size = 12),
        legend.title = element_text(color = ""white"", size = 12,face = ""bold""),
        plot.title = element_text(color = ""white"", size = 20,face = ""bold""),
        plot.subtitle = element_text(color = ""white"", size = 15,face = ""bold""),
        plot.caption =  element_text(color = ""white"", size = 9,face = ""bold""),
        panel.grid.minor = element_blank())


##Break down between human and natural
fires_by_county <- with_county %>% group_by(county) %>% 
  summarise(total_fires = n()) %>%
  mutate(county = paste0(county, "" County"")) 

causes_tibble <- tribble(
  ~stat_cause_descr, ~cause,
  ""Miscellaneous"", ""Other"",
  ""Equipment Use"", ""Human"",
  ""Lightning"", ""Nature"",
  ""Arson"", ""Human"",
  ""Debris Burning"",""Human"",
  ""Missing/Undefined"", ""Other"",
  ""Campfire"", ""Human"",
  ""Children"", ""Human"",
  ""Smoking"", ""Human"",
  ""Powerline"", ""Human"",
  ""Railroad"", ""Human"",
  ""Fireworks"", ""Human"",
  ""Structure"", ""Human""
)

added_causes <- ca_buzzfeed %>% inner_join(causes_tibble) %>%
  select(state,fips_name,fips_code,cause,fire_year, discovery_date, fire_size,latitude,longitude) %>%
  dplyr::rename(county = fips_name) %>%
  filter(!is.na(county))

county_cause_group <- added_causes %>%
  group_by(county, cause) %>% 
  summarise(total_fires = n()) %>% ungroup() %>%
  mutate(county = paste0(county, "" County"")) %>%
  spread(cause, total_fires, fill = 0) %>%
  gather(cause, total_fires, -county) %>%
  group_by(cause) %>%
  arrange(cause, total_fires) %>%
  mutate(row = row_number()) %>%
  mutate(color_group = cut_width(row,width = 10,boundary = 0))

##Do Humans first
library(RColorBrewer)
new_colors <- brewer.pal(6,""YlOrBr"")

county_cause_group %>% 
  mutate(color_group = factor(color_group, labels = c(""1-10"",
                                                      ""11-20"",
                                                      ""21-30"",
                                                      ""31-40"",
                                                      ""41-50"",
                                                      ""50-59""))) %>%
  inner_join(urbnmapr::counties, by = c(""county"" = ""county_name"")) %>%
  filter(state_abbv == ""CA"" & !group %in% groups_to_filter & cause!=""Other"") %>% 
  ggplot(aes(long, lat, group = county, fill = color_group)) + 
  geom_polygon(color = ""black"", size = .25) + theme_minimal() + 
  scale_fill_manual(values = c(""blue4"",""blue1"",
                               ""lightblue3"",""honeydew3"",
                               ""indianred3"", ""firebrick3"")) + 
  facet_wrap(~cause, scales = ""free"") + 
  labs(x = """", y ="""",
       title = ""County comparison between human and nature related wildfires"",
       subtitle = ""Counties ranked from least number of incidents to greatest number of incidents"",
       fill = ""County rank"",
       caption = ""Source CalFire/Buzzfeed\nCounty ranked #1 is the one with the lowest number of wildfires"") + 
  theme(#panel.grid.major = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        legend.text = element_text(color = ""black"", size = 12),
        legend.title = element_text(color = ""black"", size = 12,face = ""bold""),
        plot.title = element_text(color = ""black"", size = 20,face = ""bold""),
        plot.subtitle = element_text(color = ""black"", size = 13,face = ""bold""),
        plot.caption =  element_text(color = ""black"", size = 9,face = ""bold""),
        #panel.grid.minor = element_blank(),
        strip.background = element_rect(fill = ""azure4""),
        strip.text = element_text(color = ""white"", face = ""bold"")
        )
","Other-21"
"745",570,"https://github.com/othomantegazza/code-tidytuesday/blob/master/34-thanksgiving.R","othomantegazza","code-tidytuesday","34-thanksgiving.R","library(tidyverse)
library(glue)

# Get Data ----------------------------------------------------------------


dat_path <- ""data/34-thanksgiving.Rdata""


if(!file.exists(dat_path)) {
  dat <- 
    read_csv(paste0(""https://raw.githubusercontent.com/"",
                    ""rfordatascience/tidytuesday/master/data/"",
                    ""2018-11-20/thanksgiving_meals.csv""))
  
  save(dat, file = dat_path)
  
} else {
  load(dat_path)
}


# Alluvial plot -------------------------------------------------------------

dat_smp <- 
  dat %>% 
  filter(celebrate == ""Yes"") %>%
  select(
    age,
    # gender,
    # prayer,
    friendsgiving,
    # black_friday,
    # community_type,
    # us_region,
    cranberry
    ) %>%
  filter(complete.cases(.)) %>%
  filter(!cranberry %>% str_detect(""Other"")) %>%
  group_by_all() %>% 
  count()
  

library(ggalluvial)
p_all <- 
  dat_smp %>% 
  ggplot(aes(
    axis1 = cranberry,
    axis2 = friendsgiving,
    axis3 = age,
    y = n)) +
  theme_minimal() +
  geom_alluvium(aes(fill = cranberry)) +
  geom_stratum(fill = ""grey98"") +
  geom_text(stat = ""stratum"",
            label.strata = TRUE) +
  scale_x_continuous(breaks = 1:3,
                     labels = c(""Cranberry Sauce"",
                                ""Friendsgiving"",
                                ""Age"")) +
  scale_fill_viridis_d() +
  labs(title = ""Cranberry Sauce Types at Thanksgiving"",
       subtitle = ""Data Polled on Nov. 17, 2015"",
       fill = ""Cranberry\nSauce"",
       caption = ""Data source: fivethirtyeight.com | Plot by @othomn"")


png(filename = ""plots/34-thanksgiving_all.png"",
    height = 1400, width = 2300,
    res = 300)
p_all %>% print()
dev.off() 


  
# bar plot ----------------------------------------------------------------

dat_ratio <- 
  dat %>% 
  select(cranberry,
         us_region) %>%
  filter(complete.cases(.)) %>%
  filter(!cranberry %>% str_detect(""Other"")) %>% 
  group_by_all() %>% 
  count() %>% 
  group_by(us_region) %>%
  mutate(all = n %>% sum()) %>% 
  ungroup() %>% 
  mutate(ratio = n/all) 
  
lvl <- dat_ratio %>%
  filter(cranberry == ""Homemade"") %>%
  arrange(ratio) %>%
  pull(us_region)
  
p_bar <- 
  dat_ratio %>% 
  mutate(us_region = factor(us_region,
                            levels = lvl),
         cranberry = factor(cranberry,
                            levels = (c(
                              ""None"", ""Canned"", ""Homemade""
                              )))) %>% 
  ggplot(aes(x = us_region,
             y = ratio,
             fill = cranberry)) +
  geom_bar(stat = ""identity"",
           colour = ""grey80"") +
  geom_text(data = . %>%
              group_by(us_region) %>%
              summarise(n = sum(n)),
            aes(label = glue(""n = {n}""),
                fill = NULL),
            y = 0.02, 
            colour = ""#208C88"", 
            hjust = 0) +
  scale_fill_viridis_d(option = ""D"") +
  coord_flip(expand = FALSE) +
  theme_minimal() + 
  theme(panel.grid = element_blank(),
        legend.text = element_text(colour = ""grey40""), 
        title = element_text(colour = ""grey20"")) +
  labs(x = """",
       title = ""Where is Homemade Cranberry Sauce Most Common?"",
       subtitle = ""For Thanksgiving, Data Polled on Nov. 17, 2015"",
       fill = ""Cranberry\nSauce"",
       caption = ""Data source: fivethirtyeight.com | Plot by @othomn"")

png(filename = ""plots/34-thanksgiving.png"",
    height = 1400, width = 2300,
    res = 300)
p_bar %>% print()
dev.off() 

","2018-34"
"746",571,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-20-nobel-prize.R","othomantegazza","code-tidytuesday","2-20-nobel-prize.R","library(tidyverse)
library(lubridate)


# Get data ----------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                   ""master/data/2019/2019-05-14/nobel_winners.csv"")

data_path <- ""data/2-20-nobel-prize.Rdata""

if(!file.exists(data_path)) {
  nobel <- read_csv(data_url)
  
  save(nobel, file = data_path)
} else {
  load(data_path)
}


# plot -----------------------------------------------------------------

p <- 
  nobel %>% 
  mutate(age =  prize_year - year(birth_date)) %>% 
  ggplot(aes(x = category,
             y = age,
             colour = gender,
             alpha = gender)) +
  ggbeeswarm::geom_beeswarm() +
  coord_flip() +
  scale_color_manual(values = c(""#BB1288"", ""#5867A6"")) +
  scale_alpha_manual(values = c(1, .4)) +
  theme_minimal() +
  labs(title = ""Way Beyond Gender Imbalance"",
       subtitle = ""Nobel prize laureates until 2016"",
       colour = ""Gender"",
       alpha = ""Gender"",
       x = ""Category"",
       y = ""Age"",
       caption = ""Source: Kaggle | Plot by @othomn"")

# I was wondering if with a beeswarm plot you can show also every nobel price as a point. The picture 

# some checks
nobel %>% filter(gender == ""Female"") %>% select(category, full_name) #%>% View()
nobel %>%
  mutate(age =  prize_year - year(birth_date)) %>% 
  filter(age < 25) %>% select(category, full_name) #%>% View()


# save --------------------------------------------------------------------

png(filename = ""plots/2-20-nobel-prize.png"",
    res = 300,
    height = 1800,
    width = 2400)
p %>% print()
dev.off()

nobel %>% 
  mutate(age =  prize_year - year(birth_date)) %>% 
  ggplot(aes(x = category,
             y = age,
             fill = gender)) +
  geom_boxplot()
  
","2019-20"
"747",576,"https://github.com/othomantegazza/code-tidytuesday/blob/master/36-medium-metadata.R","othomantegazza","code-tidytuesday","36-medium-metadata.R","library(tidyverse)


# get data ----------------------------------------------------------------

dat_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/"",
                  ""data/2018-12-04/medium_datasci.csv?raw=true"")

dat_path <- ""data/36-medium-metadata.Rdata""


if(!file.exists(dat_path)) {
  dat <- 
    read_csv(dat_url) %>% 
    select(-x1)
  
  save(dat, file = dat_path)
  
} else {
  load(dat_path)
}


# explore -----------------------------------------------------------------

dat$title %>% unique() %>% length()

dat %>% 
  ggplot(aes(x = reading_time,
             y = claps)) +
  geom_point(alpha = .1) +
  scale_x_log10() +
  scale_y_log10()

dat %>% filter(claps > 10000) %>% View()
dat %>% filter(claps > 10000) %>% 
  select(contains(""tag"")) %>% 
  mutate(sums = pmap_dbl(.,sum)) %>% 
  # pull(sums) %>% 
  # range()
  filter(sums > 1) %>% View

dat %>% top_n(50, wt = claps) %>% pull(author) %>% table()

dat %>% 
  mutate_at(vars(matches(""tag"")),
            .funs = funs(.*claps)) %>% 
  summarise_at(.vars = vars(matches(""tag"")), sum)


# plot --------------------------------------------------------------------

clap <- dat %>% 
  mutate_at(vars(matches(""tag"")),
            .funs = funs(.*claps)) %>% 
  summarise_at(.vars = vars(matches(""tag"")),
               sum) %>% 
  mutate(measure = ""claps"", 
         tot = pmap_dbl(., sum)) %>% 
  mutate_at(vars(matches(""tag"")),
            .funs = funs(./tot))


posts <- dat %>% 
  summarise_at(.vars = vars(matches(""tag"")), 
               sum) %>% 
  mutate(measure = ""posts"",
         tot = pmap_dbl(., sum)) %>% 
  mutate_at(vars(matches(""tag"")),
            .funs = funs(./tot))

to_plot <- 
  bind_rows(clap, posts) %>% 
  select(-tot) %>% 
  gather(tag_ai:tag_machine_learning,
         key = ""tag"",
         value = ""percent"")

p <- 
  to_plot %>% 
  arrange(percent) %>% 
  mutate(tag = tag %>% 
           str_remove(""tag_"") %>% 
           str_replace(""_"", ""\n"") %>% 
           as_factor()) %>% 
  ggplot(aes(x = measure,
              y = percent,
              fill = tag)) +
  geom_bar(stat = ""identity"",
           colour = ""white"", size = .8) +
  coord_flip(expand = F) +
  theme_minimal() +
  labs(title = ""Deep and Machine Learning Posts Get Clapped More"",
       subtitle = ""Share of posts and claps for a set of 78k posts on Medium with data related tags"",
       x = """",
       caption = ""Source: medium.com, kaggle.com, M. Hendirckson, K. Misra | Plot by @othomn"") +
  scale_fill_viridis_d(
    option = ""B"",
    guide = guide_legend(title.vjust = .2,
                         label.position = ""top"",
                         keyheight = unit(4, units = ""mm""),
                         keywidth=unit(14, units = ""mm""), 
                         nrow = 1,
                         reverse = TRUE)) +
  theme(text = element_text(colour = ""grey20"",
                            family = ""sans""),
        legend.position = ""top"",
        plot.margin = margin(t = 10, l = 3.4,
                             b = 6, r = 5, unit = ""mm""))

png(filename = ""plots/36-medium-metadata.png"",
    height = 1100, width = 2200,
    res = 300)
p %>% print()
dev.off()   

","2018-36"
"748",577,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-29-r4ds-slack.R","othomantegazza","code-tidytuesday","2-29-r4ds-slack.R","library(tidyverse)
library(tibbletime)
library(grid)
library(lubridate)

# months in english
Sys.setlocale(""LC_TIME"", ""en_US.UTF8"")

# colors
purple <- ""#AA2255""
purple2 <- ""#BB2255""
bg_col <- ""#EAEA9F""
blue <- ""#263A89""

# load data ---------------------------------------------------------------


data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                   ""tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")

data_path <- ""data/2-29-r4ds-slack.Rdata""


if(!file.exists(data_path)) {
  r4ds <- 
    data_url %>% 
    read_csv() %>% 
    select(-name)
  
  save(r4ds, file = data_path)
} else {
  load(data_path)
}


# explore -----------------------------------------------------------------

# no na
r4ds %>% map(~is.na(.) %>% sum())

# correlations
prs <- r4ds %>% GGally::ggpairs()

png(filename = ""plots/2-29-r4ds-slack.png"",
    width = 3000,
    height = 3000,
    res = 400)
prs
dev.off()

# what is name?
# r4ds %>% pull(name) %>% range()
# edited name, can be removed


# all timelines
r4ds %>% 
  gather(total_membership:messages_posted,
         key = ""key"", value = ""value"") %>% 
  ggplot(aes(x = date,
             y = value)) +
  geom_line() +
  facet_grid(key ~ ., scales = ""free_y"") +
  theme(strip.text.y = element_text(angle = 0))


# Active members ----------------------------------------------------------

# new years resolution?

roll_weekmean <- rollify(mean, window = 7)

roll_monthmean <- rollify(mean, window = 30)

text_height <- 240

p <- 
  r4ds %>% 
  mutate(weekmean = roll_weekmean(daily_active_members) %>% 
           # recenter rolled mean
           .[c(4:n(), 1:3)]) %>%
  ggplot(aes(x = date,
             y = daily_active_members)) +
  geom_density(stat = ""identity"", colour = NA,
               fill = ""white"") +
  geom_line(colour = ""#E4E484"") + #""#99D0E3"") + # ""#27A6D3"") +
  geom_line(aes(y = weekmean), colour = purple) +
  annotate(geom = ""text"",
           label = ""New Year's Resolutions? ;)"",
           y = text_height,
           x = as.Date(""2018-07-15""), 
           family = ""courier"",
           colour = blue) +
  annotate(geom = ""curve"",
           x = as.Date(""2018-04-01""),
           y = text_height,
           xend = as.Date(""2018-01-15""),
           yend = 160,
           curvature = .25,
           arrow = arrow(length = unit(1.2, ""mm""), type = ""closed""),
           size = .1,
           colour = blue) +
  annotate(geom = ""curve"",
           x = as.Date(""2018-10-27""),
           y = text_height,
           xend = as.Date(""2019-01-20""),
           yend = 155,
           curvature = -.26,
           arrow = arrow(length = unit(1.2, ""mm""), type = ""closed""),
           size = .1,
           colour = blue) +
  annotate(geom = ""text"",
           label = str_wrap(""Mean of 7 days window."", width = 10),
           y = 130,
           x = as.Date(""2019-07-22""), 
           family = ""courier"",
           colour = purple,
           size = 3,
           hjust = 0,
           lineheight = 1) +
  annotate(geom = ""curve"",
           x = as.Date(""2019-08-10""),
           y = 104,
           xend = as.Date(""2019-07-10""),
           yend = 70,
           curvature = -.45,
           arrow = arrow(length = unit(1.2, ""mm""), type = ""closed""),
           size = .1,
           colour = purple) +
  labs(x = """",
       y = ""Daily active members"",
       title = ""Activity of the R4DS Learning Community on Slack"",
       caption = ""Source: R4DS UseR Presentation | Plot by @othomn"") +
  theme_minimal(base_family = ""courier"") +
  scale_x_date(limits = as.Date(c(""2017-08-20"", ""2019-09-05"")),
               expand = c(0,0)) +
  theme(panel.grid = element_blank(),
        plot.margin = margin(10, 20, 5, 30),
        axis.title = element_text(colour = ""grey30""),
        plot.title = element_text(colour = blue,
                                  face = ""bold"",
                                  margin = margin(t = 10, b = 10)),
        plot.caption = element_text(colour = purple))


# save plot ---------------------------------------------------------------

png(filename = ""plots/2-29-r4ds-slack.png"",
    height = 1000,
    width = 3200,
    res = 300)
grid.newpage()
grid.rect(gp = gpar(fill = bg_col))
print(p, vp = viewport())
dev.off()



# save to json for d3 -----------------------------------------------------
library(jsonlite)

a <- 
r4ds %>% 
  select(date, daily_active_members) %>%
  toJSON() %>%
  {paste(""var r4ds = "", .)} %>% 
  cat(file = ""d3/json_data/2-29-r4ds-slack.js"")
  
# easier: monthly visitors
r4ds %>% 
  mutate(month_year = paste(month(date, label = T), year(date)),
         month_year = as_factor(month_year)) %>% 
  group_by(month_year) %>% 
  summarise(active_members = sum(daily_active_members)) %>%
  toJSON() %>% 
  {cat(""var r4ds = "", ., file = ""d3/json_data/2-29-r4ds-slack-months.js"")}





","2019-29"
"749",578,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-21-plastic-waste.R","othomantegazza","code-tidytuesday","2-21-plastic-waste.R","library(tidyverse)
library(lubridate)
library(countrycode)
library(ggforce)
library(ggrepel)

# Get data ----------------------------------------------------------------

managed_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                   ""master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

mismanaged_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                         ""master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")


data_path <- ""data/2-21-plastic-waste.Rdata""

if(!file.exists(data_path)) {
  waste_ok <- read_csv(managed_url) %>% 
    janitor::clean_names() %>% 
    filter(year == 2010)
  
  waste_lost <- read_csv(mismanaged_url) %>% 
    janitor::clean_names() %>% 
    filter(year == 2010)
  
  save(waste_ok, waste_lost, file = data_path)
} else {
  load(data_path)
}


waste <-
  full_join(waste_ok %>%
              select(entity,
                     code, 
                     gdp_per_capita = gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
                     plastic = per_capita_plastic_waste_kilograms_per_person_per_day),
            waste_lost %>% 
              select(entity,
                     code,
                     lost = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day)) %>% 
  # select(entity, code, year,
  #        ok = per_capita_plastic_waste_kilograms_per_person_per_day,
  #        lost = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day) %>% 
  drop_na() 

# Explore -----------------------------------------------------------------

waste %>% 
  ggplot(aes(x = plastic,
             y = lost)) +
  geom_point() 
  # scale_x_log10() +
  # scale_y_log10()
  # ggrepel::geom_text_repel(aes(label = code))

waste <- 
  waste %>% 
  mutate(ratio_lost = lost/plastic)

# two groups?
waste %>% 
  ggplot(aes(x = ratio_lost)) +
  geom_histogram()

waste %>%
  filter(ratio_lost > .75) %>% 
  pull(entity)

waste %>%
  filter(ratio_lost <.1 ) %>% 
  pull(entity)


# with continent ----------------------------------------------------------

waste_cont <- 
  waste %>% mutate(continent = countrycode(sourcevar = entity,
                                         origin = ""country.name"",
                                         destination = ""continent""),
                 continent = case_when(entity == ""Micronesia (country)"" ~ ""Oceania"",
                                    TRUE ~ continent)) %>% 
  drop_na(continent)

p <- 
  waste_cont %>% 
  ggplot(aes(x = ratio_lost,
             fill = continent,
             colour = continent)) +
  geom_histogram(bins = 25, alpha = .5) +
  # geom_mark_rect(data = tibble(x = .07,
  #                              y = 40,
  #                              label = ""Ciao"",
  #                              description = ""Ciao ciao ciao""),
  #                aes(x = x,
  #                    y = y,
  #                    label = label,
  #                    description = description),
  #                colour = ""white"", position = ""right"",
  #                inherit.aes = F) +
  annotate(geom = ""text"", x = .12, y = 41, 
                label = str_wrap(""High income countries can invest in
                                 plastic waste manegement?"",
                                 width = 20),
           hjust = 0, vjust = 0,
           size = 3, lineheight = 1,
           color = ""grey10"") +
  annotate(geom = ""segment"", x = .12,
           y = 40, yend = 37, xend = .09,
           color = ""grey10"") +
  annotate(geom = ""text"", x = .76, y = 18, 
           label = str_wrap(""Low income countries?"",
                            width = 20),
           hjust = 1, vjust = 0,
           size = 3, lineheight = 1,
           color = ""grey10"") +
  annotate(geom = ""segment"", x = .76,
           y = 17.5, yend = 16, xend = .78,
           color = ""grey10"") +
  geom_hline(yintercept = 0, colour = ""grey50"") +
  theme_minimal() +
  theme(text = element_text(family = ""sans"",
                            colour = ""grey20""),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  labs(x = ""[Mismanaged/Total] waste in Kg per capita"",
       y = ""Number of Countries"",
       fill = ""Continent"", colour = ""Continent"",
       title = ""Does Plastic Waste Management Mirrors Inequality?"",
       subtitle = ""Ratio of mismanaged plastic waste per country in 2010."",
       caption = ""Source: Our World in Data | Plot by @othomn"")

png(""plots/2-21-plastic-waste.png"",
    res = 300,
    height = 1400,
    width = 2200)
p %>% print()
dev.off()

# My Wednesday #TidyTuesday #rstats

# Is inequality mirrored also in waste plastic management?

# I checked the distribution of the percentage of mismanaged plastic waste, and it's kind of bimodal.

# https://ourworldindata.org/plastic-pollution
# https://github.com/othomantegazza/code-tidytuesday/blob/master/2-21-plastic-waste.R


# scatterplot -------------------------------------------------------------

annos_df <- 
  tibble(x = c(),
         y = c)

# p_s <- 
  waste_cont %>% 
  ggplot(aes(x = plastic,
             y = lost,
             size = gdp_per_capita,
             colour = continent)) +
  geom_point(alpha  = .7) +
  geom_text_repel(data = tibble(x = .05,
                                y = .005,
                                label= str_wrap(""High income countries can invest in
                                plastic waste manegement?"",
                                                width = 20)),
                  aes(x = x, y = y, label = label),
                  inherit.aes = F,
                  hjust = 1, vjust = 0,
                  size = 3, lineheight = 1,
                  color = ""grey10"") +
  # annotate(geom = ""text"", x = 1.3, y = 0.014, 
  #          label = str_wrap(""High income countries can invest in
  #                                plastic waste manegement?"",
  #                           width = 20),
           # hjust = 0, vjust = .5,
           # size = 3, lineheight = 1,
           # color = ""grey10"") +
  # annotate(geom = ""segment"",
  #          arrow = arrow(length = unit(1, ""mm""), type = ""closed""), 
  #          x = 1.3, y = .014,
  #          xend = 1, yend = .014) +
  scale_x_log10(limits = c(.001, 10)) +
  scale_y_log10(limits = c(.0005, .3)) +
  theme_minimal() 


png(""plots/2-21-plastic-waste-scatterplot.png"",
    res = 300,
    height = 1400,
    width = 2200)
p_s %>% print()
dev.off()


# cluster -----------------------------------------------------------------

set.seed(49)

waste_clust <- 
  waste_cont %>% 
  transmute(plastic = log(plastic),
            lost = log(lost),
            gdp_per_capita = log(gdp_per_capita)) %>% 
  kmeans(centers = 3) %>% 
  {bind_cols(waste_cont, tibble(cluster = .$cluster))}


cl_1 <- ""Medium GDP, high plastic loss""
cl_2 <- ""High GDP, low plastic loss""
cl_3 <- ""Low GDP, medium plastic loss""


p_clust <- 
waste_clust %>% 
  mutate(label = case_when(cluster == 1 ~ cl_1,
                                 cluster == 2 ~ cl_2,
                                 cluster == 3 ~ cl_3)) %>%
  # mutate(plastic = log(plastic),
  #           lost = log(lost)) %>% 
  ggplot(aes(x = plastic,
             y = lost,
             colour = cluster)) +
  geom_point(aes(size = gdp_per_capita)) +
  geom_mark_ellipse(aes(group = cluster,
                        label = cluster,
                        description = label),
                    # label.margin = .2,
                    size = 1.1, con.size = 1.3,
                    label.fontsize = 10, label.fill = ""grey90"",
                    label.minwidth = 30) +
  scale_x_log10(
    limits = c(.01, 5)
    ) +
  scale_y_log10(
    limits = c(.0008, .8)
    ) +
  theme_minimal() +
  scale_colour_continuous(guide = FALSE) +
  labs(x = ""Per capita plastic waste (kg per person per day)"",
       y = ""Per capita mismanaged plastic waste (kg per person per day)"",
       size = ""GDP per capita"",
       caption = ""Source: Our World in Data | Plot by @othomn"") +
  theme(axis.title = element_text(size = 12))


png(""plots/2-21-plastic-waste-cluster.png"",
    res = 300,
    height = 2300,
    width = 3000)
p_clust %>% print()
dev.off()

waste_clust %>% 
  mutate(label = case_when(cluster == 1 ~ cl_1,
                           cluster == 2 ~ cl_2,
                           cluster == 3 ~ cl_3)) %>%
  # mutate(plastic = log(plastic),
  #           lost = log(lost)) %>% 
  ggplot(aes(x = gdp_per_capita,
             y = lost,
             colour = cluster)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10()

waste_clust %>% 
  mutate(label = case_when(cluster == 1 ~ cl_1,
                           cluster == 2 ~ cl_2,
                           cluster == 3 ~ cl_3)) %>%
  # mutate(plastic = log(plastic),
  #           lost = log(lost)) %>% 
  ggplot(aes(x = gdp_per_capita,
             y = plastic,
             colour = cluster)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10()

","2019-21"
"750",636,"https://github.com/othomantegazza/code-tidytuesday/blob/master/26-invasive.R","othomantegazza","code-tidytuesday","26-invasive.R","library(tidyverse)
library(countrycode)
library(scales)
library(ggrepel)

# want to plot cost/GDP for countries split by continents


# can I find the continents in the package countrycode?
# str(countrycode::codelist)
# str(countrycode::cldr_examples)
# str(countrycode::codelist_panel)
# yes


# get the data for cost/GDP -----------------------------------------------

gdp_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                  ""tidytuesday/master/data/2018-09-25/table_3.csv"")

gdp_file <- ""data/26-invasive-gdp-ratio.Rdata""

if(!file.exists(gdp_file)) {
  dat_gdp <- read_csv(gdp_url)
  save(dat_gdp, file = gdp_file)
} else {
  load(gdp_file)
}


# get data for risk -------------------------------------------------------

risk_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                   ""tidytuesday/master/data/2018-09-25/table_1.csv"")

risk_file <- ""data/26-risk.Rdata""

if(!file.exists(risk_file)) {
  dat_risk <- read_csv(risk_url)
  save(dat_risk, file = risk_file)
} else{
  load(risk_file)
}



# fix country names of gdp dataset ----------------------------------------

# this is error prone

dat_gdp <- dat_gdp %>%
  filter(! country %in% c(""Guinea"", ""Niger"")) %>%
  mutate(country = pmap(., ~grep(paste0(""^"", ..1),
                x = dat_risk$country,
                value = TRUE)) %>%
           unlist())

# Full data ---------------------------------------------------------------

dat <- dat_risk %>%
  select(-rank) %>%
  full_join(dat_gdp) %>%
  drop_na(invasion_cost) %>%
  left_join(codelist_panel %>%
              rename(country = country.name.en) %>%
              select(country, continent, region) %>%
              distinct()) %>%
  # fix missing continents
  mutate(continent = replace(continent, country == ""Czech Republic"", ""Europe""),
         continent = replace(continent, country == ""Bosnia and Herzegovina"", ""Europe""),
         continent = replace(continent, country == ""USA"", ""Americas""),
         continent = replace(continent, country == ""Korea Republic of"", ""Asia""),
         continent = replace(continent, country == ""Georgia (Republic)"", ""Europe""),
         continent = replace(continent, country == ""Congo (Republic of)"", ""Africa""),
         continent = replace(continent, country == ""Trinidad and Tobago"", ""Americas""),
         continent = replace(continent, country == ""Russian Federation"", ""Asia"")
  )

# dat %>% filter(is.na(continent)) %>% View

# plot --------------------------------------------------------------------

png(filename = ""plots/26-invasives.png"",
    height = 4700, width = 1500,
    res = 300)
dat %>%
  ggplot(aes(x = reorder(country,
                         gdp_proportion),
             y = gdp_proportion,
             size = invasion_threat,
             colour = log(invasion_cost))) +
  geom_point(alpha = .8) +
  facet_grid(continent ~ .,
             scales = 'free',
             space = ""free"") +
  # facet_wrap(facets = ""continent"", ncol = 1, scales = ""free_y"") +
  coord_flip() +
  scale_size_continuous(range = c(.1,3)) +
  scale_color_viridis_c() +
  # scale_y_log10() +
  scale_y_continuous(labels = scales::percent) +
  theme_minimal() +
  theme(legend.position = ""bottom"",
        legend.box = ""vertical"") +
  labs(title = ""Agriculture is Affected by\nInvasive Species"",
       x = """",
       y = ""Cost in Proportion to GDP"",
       caption = ""data: griis.org; Paini et al., PNAS July 5, 2016 \n plot by @othomn"",
       size = ""Invasion Threat"",
       colour = ""Invasion Costs [log USD]"")
dev.off()  

# Scatterplot logit -------------------------------------------------------

png(filename = ""plots/26-invasives-xy-logit.png"",
    height = 1700, width = 2200,
    res = 300)
dat %>%
  ggplot(aes(colour = continent,
             x = invasion_cost,
             y = gdp_proportion)) +
  geom_point(aes(size = invasion_threat),
             alpha = .7) +
  geom_text(data = dat %>%
              top_n(2, wt = gdp_proportion),
            aes(label = country),
            size = 2.5,
            nudge_y = -.3,
            show.legend = FALSE) +
  geom_text(data = dat %>%
              top_n(-4, wt = gdp_proportion),
            aes(label = country),
            size = 2.5,
            nudge_y = -.3,
            show.legend = FALSE) +
  scale_x_log10() +
  scale_y_continuous(trans = ""logit"",
                     breaks = boot::inv.logit(c(-10, -8, -6,-4, -2, 0, 2, 4)),
                     labels = scales::percent_format(.001)) +
  scale_size_continuous(range = c(.1,4)) +
  theme_minimal() +
  theme(plot.caption = element_text(hjust = 0)) +
  labs(title = ""Agriculture is Affected by Invasive Species"",
       x = ""Cost of Invasive Species on Agriculture [log USD]"",
       y = ""Cost in Proportion to GDP [logit spaced]"",
       caption = ""data: griis.org; Paini et al., PNAS July 5, 2016 | plot by @othomn"",
       size = ""Invasion Threat"",
       colour = ""Continent"")
dev.off()

# Scatterplot -------------------------------------------------------------

png(filename = ""plots/26-invasives-xy.png"",
    height = 1700, width = 2200,
    res = 300)
dat %>%
  ggplot(aes(colour = continent,
             x = invasion_cost,
             y = gdp_proportion)) +
  geom_point(aes(size = invasion_threat),
             alpha = .7) +
  geom_text_repel(data = dat %>%
                    top_n(9,
                          gdp_proportion),
                  aes(label = country),
                  size = 4,
                  show.legend = FALSE) +
  geom_text_repel(data = dat %>%
                    top_n(4,
                          invasion_cost),
                  aes(label = country),
                  size = 4,
                  show.legend = FALSE) +
  scale_x_log10() +
  scale_y_continuous(labels = scales::percent) +
  scale_size_continuous(range = c(.1,4)) +
  theme_minimal() +
  theme(plot.caption = element_text(hjust = 0)) +
  labs(title = ""Agriculture is Affected by Invasive Species"",
       x = ""Cost of Invasive Species on Agriculture [log USD]"",
       y = ""Cost in Proportion to GDP"",
       caption = ""data: griis.org; Paini et al., PNAS July 5, 2016 | plot by @othomn"",
       size = ""Invasion Threat"",
       colour = ""Continent"")
dev.off()

","2018-26"
"751",637,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-33-rome-circle.R","othomantegazza","code-tidytuesday","2-33-rome-circle.R","library(tidyverse)
library(lubridate)
library(grid)
library(tibbletime)

# get data ----------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                   ""tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

data_path <- ""data/2-33-rome.Rdata""


# Check if data have already been downloaded,
# If not, read data from github and saves them locally
if(!file.exists(data_path)) {
  emps <- 
    data_url %>% 
    read_csv() %>% 
    janitor::clean_names()
  
  save(emps, file = data_path)
} else {
  load(data_path)
}

# simplify dataset --------------------------------------------------------

# and fix BC date (only 1: Augustus start)

diffday <- (emps$reign_start[1] - as_date(""0001-01-01"")) %>% as.numeric()

emps2 <- 
  emps %>% 
  mutate(reign_start = case_when(name == ""Augustus"" ~ (reign_start - 2*diffday),
                                 TRUE ~ reign_start)) %>%
  select(reign_start, reign_end, name)



# grid parameters ---------------------------------------------------------

width  <- 18; height <- 40

margin_top <- .06; margin_low <- .04

bg_col <- ""#3752C3""

x_labels <- .51

x_circle <- .77

x_title <- .12

y_sign <- margin_low + 1

# Turn all dates to numeric? ----------------------------------------------

# to map them into the x space


range_reign <- c(min(emps2$reign_start), max(emps2$reign_end))

rescale_reing <- function(y)
  {
  scales::rescale(y,
                  to = c(1 - margin_top, margin_low),
                  from = range_reign)
  }

emps3 <- 
  emps2 %>% 
  mutate(start_y = reign_start %>% rescale_reing(),
         end_y = reign_end %>% rescale_reing(),
         r = (start_y - end_y)/2 ,
         y = start_y - r,
         r = r * (height/width) * .75,
         x = x_circle)


to_circles <-
  emps3 %>% 
  select(x, r, y) %>% 
  mutate(gp = list(gpar(fill = ""#ffffff66"", col = ""#ffffff00"")))


# labels ------------------------------------------------------------------

emps4 <-
  emps3 %>%
  arrange(desc(y)) %>%
  mutate(n = 1:n(),
         ylab = scales::rescale(n, from = range(n), to = c(1 - margin_top, margin_low)),
         gp = list(gpar(fontsize = 12, col = ""white"")),
         xlab = x_labels,
         rot = 0,
         hjust = 1) %>% 
  mutate(ylab = (y + ylab)/2) %>% 
  mutate(reign_span = case_when(year(reign_start) == year(reign_end) ~ year(reign_start) %>% as.character(),
                                year(reign_start) < 0 ~ paste(paste(-year(reign_start), ""BC""),
                                                            year(reign_end), sep = "" - ""),
                                TRUE ~ paste(year(reign_start), year(reign_end), sep = "" - "")),
         label = paste(name, reign_span, sep = "" | ""))

to_label <- 
  emps4 %>%
  select(label,
         y = ylab,
         x = xlab,
         gp, rot, hjust)



# bezier curves -----------------------------------------------------------

max_r <- emps4$r %>% max()

xbez_stop <-  x_circle - max_r * 1.4



make_bez_x <- function(xlab) {c(xlab, mean(xbez_stop, x_labels)*0.87, mean(xbez_stop, xlab)*0.8, xbez_stop)}
make_bez_y <- function(ylab, y) {c(ylab, ylab, y, y)}
make_gpar <- function(lty) {gpar(col = ""white"", lwd = .5, lty = lty)}

bezier_y_in <- emps4 %>% select(ylab, y) %>% pmap(make_bez_y)
bezier_gpar <- rep(1:3, length.out = nrow(emps4)) %>% map(make_gpar)


emps5 <- 
  emps4 %>% 
  mutate(bezier_x = xlab %>% map(make_bez_x),
         bezier_y = bezier_y_in,
         gp = bezier_gpar)

to_bezier <- 
  emps5 %>% 
  select(x = bezier_x,
         y = bezier_y,
         gp) 


# segments ----------------------------------------------------------------

# connect beziers to circles

to_segments <- 
  emps5 %>% 
  transmute(x0 = xbez_stop,
            x1 = x - .02 - scales::rescale(r, from = range(r), to = c(median(r), max(r)*1.1)),
            y0 = y,
            y1 = y,
            gp = gp)


# signature ---------------------------------------------------------------

sig_x <- .15
sig_y <- .07
sig_r <- .013
sig_col <- ""#CB7BA5""

make_circle_text <- function(label, x, y, r, angle) 
{
  angle_pi <- scales::rescale(angle, from = c(0, 360), to = c(0, 2*pi))
  list(label = label,
       x = x + sin(angle_pi)*r,
       y = y + cos(angle_pi)*r*(width/height),
       rot = -angle)
}

signature <- ""plot by @othomn"" %>% strsplit(split = """") %>% .[[1]]

to_signature <- 
  tibble(label = signature) %>% 
  mutate(n = 1:n(),
         angle = scales::rescale(n, from = range(n), to = c(-80, 80)),
         x = sig_x,
         y = sig_y,
         r = sig_r + .016) %>% 
  select(-n) %>% 
  pmap_df(make_circle_text) %>% 
  mutate(vjust = 0,
         hjust = 0.5,
         rot = rot - 1,
         gp = list(gpar(fontsize = 16,
                        col = sig_col,
                        fontfamily = ""mono"",
                        fontface = ""bold"")))

# plot --------------------------------------------------------------------

svglite::svglite(""plots/2-33-rome-circle.svg"",
                 width = width,
                 height = height)

# new page, is it necessary?
grid.newpage()

# background blue rectangle
grid.rect(gp = gpar(fill = bg_col, col = bg_col))

# draw circles
to_circles %>%
  pmap(grid.circle)

# draw labels
to_label %>%
  pmap(grid.text)

# draw_beziers
to_bezier %>% 
  pmap(grid.bezier)

# connect them to circles with segments
to_segments %>% 
  pmap(grid.segments)


# add title
grid.text(label = str_wrap(""Timeline of Roman Emperors"", width = 6),
          x = x_title,
          y = (to_label %>% arrange(desc(y)) %>% pull(y) %>% .[1]) + .008,
          hjust = 0,
          vjust = 1,
          gp = gpar(fontsize = 40,
                    # fontface = ""bold"",
                    col = ""#D8DDF3"", #  ""#98F0D8"",  #  ""#44D4DC"", # ""#F6F6DF"", #
                    lineheight = 1))

# add signature
grid.circle(x = sig_x,
            y = sig_y,
            r = sig_r,
            gp = gpar(fill = sig_col,
                      col = sig_col,
                      alpha = .9))

to_signature %>% 
  pmap(grid.text)

# add source
grid.text(""Data from Wikipedia."",
          x = x_title,
          y = margin_low + .005,
          hjust = 0,
          vjust = 0,
          gp = gpar(fontsize = 12,
                    fonttype = ""mono"",
                    col = ""#D8DDF3""))


dev.off()




","2019-33"
"752",638,"https://github.com/othomantegazza/code-tidytuesday/blob/master/28-voters.R","othomantegazza","code-tidytuesday","28-voters.R","library(tidyverse)
library(magrittr)
library(rvest)

# Main opponents each year ----------------------------------------------

opponents_url <- paste0(""https://en.wikipedia.org/wiki/"", 
                        ""List_of_United_States_presidential_candidates"")

pull_lastname <- function(i) {
  i %>%
    str_split(pattern = ""\\("", 
              n = 2,
              simplify = TRUE) %>%
    .[, 1] %>%
    str_split(pattern = "" "",
              simplify = TRUE) %>%
    as.character() %>%
    tail(2) %>%
    .[1]
}

opponents <- 
  opponents_url %>%
  read_html() %>%
  html_nodes(""table"") %>%
  .[[3]] %>%
  html_table() %>%
  select(-Other) %>% 
  mutate(Democratic = Democratic %>% map_chr(pull_lastname),
         Republican = Republican %>% map_chr(pull_lastname)) %>%
  transmute(year = Year,
            opponents = paste(Democratic, Republican, sep = "" vs.""))

save(opponents, file = ""data/28-opponents.Rdata"")

# Try read US census from pdf online ----------------------------------------

library(tabulizer)


census_url <- ""https://www.census.gov/prod/2011pubs/12statab/election.pdf""

census_path <- ""data/28-voter-census.Rdata""

if(!file.exists(census_path)) {
  census_table <- 
    census_url %>%
    extract_tables(pages = 2)
  
  save(census_table, file = census_path)
  
} else {
  load(census_path)
}


# Tidy census  ------------------------------------------------------------

census_tidy <- 
  # Its a matrix within a list
  census_table[[1]] %>%
  as_tibble() %>%
  # colnames are spread over first columns
  slice(8:n()) %>%
  # data from 1972 to 2010 
  select(V7, V8, V9, V10, V12) %>%
  # The year is in V7 and has some dots
  # at the end
  rename(year = ""V7"") %>%
  mutate(year = str_sub(year,
                        start = 1,
                        end = 4) %>% as.numeric()) %>%
  # The population in voting age is in V8
  # in the last lines the first 2 or 3 is actually a note
  rename(voting_pop = ""V8"") %>% 
  mutate(voting_pop = str_replace(voting_pop, ""2 "", """") %>% 
           str_replace(""3 "", """") %>%
           str_replace("","", """") %>%
           as.numeric()*1000) %>% 
  # The ones that voted for the President is in V9
  rename(presidential = ""V9"") %>%
  mutate(presidential = str_replace(presidential, "","", """") %>%
           na_if(""(X)"")%>%
           as.numeric()*1000) %>%  
  # V10 contains both 
  # the percentage that voted for the President
  # and the ones that voted for the representative
  mutate(president_perc= str_split_fixed(V10, "" "", n = 2)[,1] %>%
           na_if(""(X)"") %>%
           as.numeric(),
         representative = str_split_fixed(V10, "" "", n = 2)[,2] %>%
           str_replace("","", """") %>%
           as.numeric()*1000) %>%
  select(-V10) %>%
  # percentage that voted at representative is in V12
  rename(representative_perc = ""V12"") %>%
  mutate(representative_perc = as.numeric(representative_perc)) %>%
  # better order for columns
  select(year, 
         voting_pop,
         presidential,
         president_perc,
         representative,
         representative_perc)

# what is a reasonable way to gather this dataset?
census_to_plot <- 
  census_tidy %>% 
  select(-contains(""perc"")) %>%
  gather(key = ""measure"", value = ""voters"",
         presidential, representative, voting_pop) %>% 
  arrange(year)  %>% 
  filter(complete.cases(.)) 

tot_pop <- 
  census_to_plot %>% 
  filter(measure == ""voting_pop"") %>%
  select(year, 
         voting_pop = voters) %>%
  distinct()


census_to_plot <- 
  census_to_plot %>%
  left_join(tot_pop) %>%
  mutate(perc = voters/voting_pop) %>%
  select(-voting_pop) %>%
  left_join(opponents) 

# Plot --------------------------------------------------------------------

p <- census_to_plot %>%
  ggplot(aes(x = year %>% as.character() %>% as_factor() %>% fct_rev(),
             y = voters)) +
  geom_line(aes(group = year),
            lwd = 0.2) +
  geom_linerange(data = . %>%
                   filter(measure == ""representative""),
                 aes(ymax = voters),
                 ymin = 0,
                 colour = ""grey40"",
                 lty = 2) +
  geom_point(aes(colour = measure),
             size = 2.5) +
  geom_text(data = . %>%
              filter(measure == ""representative"") %>%
              mutate(label = paste0(perc %>% round(3)*100, ""%"")),
            aes(label = label),
            size = 2.5,
            colour = ""grey40"",
            nudge_y = -1.2e+07,
            nudge_x = .35) +
  geom_text(data = . %>%
              filter(measure == ""presidential"") %>%
              mutate(label = paste0(perc %>% round(3)*100, ""%"")),
            aes(label = label),
            size = 2.5,
            colour = ""grey40"",
            nudge_y = +1.2e+07,
            nudge_x = .35) +
  geom_text(data = . %>%
              filter(measure == ""voting_pop""),
            aes(label = opponents),
            size = 2.5,
            colour = ""grey40"",
            nudge_y = 5e+06,
            hjust = 0, 
            vjust = 0) +
  ylim(0, 3e+08) +
  coord_flip() +
  scale_color_manual(values = scico::scico(10, palette = ""lajolla"")[c(6, 8, 3)],
                     breaks = c(""presidential"",
                                ""representative"",
                                ""voting_pop""),
                     labels = c(""Voters,\nPresidential"",
                                ""Voters,\nRepresentative"",
                                ""Population\nof Voting Age"")) +
  theme_minimal() +
  theme(legend.position = ""top"", legend.justification = 0) +
  guides(colour = guide_legend(title = NULL,
                               label.position = ""right"",
                               nrow=1)) +
  labs(title = ""In US, How Many People of Age Do Vote?"",
       subtitle = ""From 1972 to 2010, split in Presidential and Representative elections"",
       x = """",
       y = ""voters [n]"",
       caption = ""Data: US Census - www.census.gov | Plot: @othomn"")

png(filename = ""plots/28-voters.png"",
    height = 2000, width = 1700,
    res = 300)
p %>% print()
dev.off()
","2018-28"
"753",639,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-32-painting-voronoi.R","othomantegazza","code-tidytuesday","2-32-painting-voronoi.R","# Most steps are taken form:
# https://chichacha.netlify.com/2018/11/12/utilizing-k-means-to-extract-colours-from-your-favourite-images/


# set up ------------------------------------------------------------------


library(tidyverse)
library(imager)
library(ggvoronoi)
library(grid)

# background color
bg_color <- ""#E8EDEF""

# Get image ---------------------------------------------------------------

image_path <- ""data/2-32-bob-ross-sunset.Rdata""


if(!file.exists(image_path)) {
  img <- load.image(""https://assets.atlasobscura.com/article_images/66876/image.jpg"")
  
  save(img, file = image_path)
} else {
  load(image_path)
}


# analyze -----------------------------------------------------------------

# number of pixel?
dim(img)[1]*dim(img)[2]

# colours: hex value for every pixel
hex_pix <- 
  img  %>% 
  as.data.frame(wide = ""c"") %>% 
  mutate(hexval = rgb(c.1,c.2,c.3))

# luminosity for every pixes
grey_pix <- 
  img %>% 
  grayscale() %>% 
  as.data.frame()

# merge
hex_pix <- 
  hex_pix %>%
  inner_join(grey_pix)


# sample pixels ------------------------------------------------------------

set.seed(63); hex_pix_mini <- 
  hex_pix %>% 
  sample_n(2500, weight = value) # more likely if luminosity is higher 
  
# colors named vectors
# for plotting
pix_colors <- 
  hex_pix_mini %>% 
  pull(hexval) %>% 
  {purrr::set_names(x = .,
                   nm = .)}

# range of axis
range_x <- c(0, dim(img)[1])
range_y <-  c(dim(img)[2], 0)

p <- 
  hex_pix_mini %>% 
  ggplot(aes(x = x,
             y = y)) +
  # geom_point(aes(colour = hexvalue)) +
  ggvoronoi::geom_voronoi(aes(fill = hexval),
                          colour = bg_color,
                          size = .2) +
  scale_y_reverse(limits = range_y,
                  expand = expand_scale(mult = .01)) +
  scale_x_continuous(limits = range_x,
                     expand = expand_scale(mult = .01)) +
  scale_fill_manual(values = pix_colors, guide = FALSE) +
  coord_fixed() +
  theme_void() +
  theme(plot.background = element_rect(fill = bg_color),
        plot.margin = margin(0,0,0,0))

# svglite::svglite(file = ""plots/2-32-painting-voronoi.svg"")
# p %>% print()
# dev.off()


# decorate plot with grid and save ----------------------------------------

# png parameters
img_height <- 2800
img_width <- 2300

# position of bottom left corner
img_x <- .2
img_y <- .18

# and plot size
plot_width <- 1 - img_x - .05
plot_height <- 1 - img_y - .05

# save
png(file = ""plots/2-32-painting-voronoi.png"",
    height = img_height,
    width = img_width,
    res = 300)
grid.newpage()
# background
grid.rect(gp = gpar(fill = ""#838798""))
# plot
p %>% print(vp = viewport(x = img_x, y = img_y, 
                          just = c(0, 0),
                          height = plot_height,
                          width = plot_width))
# side caption
grid.text(label = str_wrap(""Voronoi tesselation of one of Bob Ross paintigs. Inspired by @chisatini's blog."",
                           width = 14),
          x = img_x - .003, y = .945,
          hjust = 1, vjust = 1, gp = gpar(size = 14, lineheight = 1,
                                          col = bg_color))
# signature
grid.text(label = ""Painting by Bob Ross | Plot by @othomn"",
          x = .92, y = .1,
          hjust = 1, vjust = 1, gp = gpar(fontsize = 10, lineheight = 1,
                                          col = bg_color))
dev.off()


# save json for d3 --------------------------------------------------------

library(jsonlite)

hex_pix_mini %>% 
  toJSON() %>%
  {paste(""var hexpix = "", .)} %>% 
  cat(file = ""d3/json_data/2-32-painting-voronoi.js"")
","2019-32"
"754",640,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-26-UFO.R","othomantegazza","code-tidytuesday","2-26-UFO.R","library(tidyverse)
library(jsonlite)
library(lubridate)
library(grid)
library(ggrepel)
library(ggforce)
library(showtext)


# colors
purple <- ""#AA2255""
purple2 <- ""#BB2255""
blue <-  ""#4C63C3""
mid <- ""#D5A080""
mid2 <- ""#E2CD92""
grey <- ""grey30""
bg_col <- ""#F0F0CB"" # ""#EAEA9F""

cpal <- colorRamp(colors = c(bg_col, purple), bias =  10e20)
cpal_rgb <- function(n) {rgb(cpal(n), maxColorValue = 255)}

# fonts
font_families()
font_add_google(""B612 Mono"", family = ""courier"")

# read data ---------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                   ""tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

data_path <- ""data/2-26-ufo.Rdata""

if(!file.exists(data_path)) {
  ufo <- 
    data_url %>% 
    read_csv(col_types = cols(date_documented = col_datetime(format = ""%m/%d/%Y"")))
  
  save(ufo, file = data_path)
} else {
  load(data_path)
}

# us towns

us_towns <- fromJSON(""https://gist.githubusercontent.com/Miserlou/c5cd8364bf9b2420bb29/raw/2bf258763cdddd704f8ffd3ea9a3e81d25e2c6f6/cities.json"")

save(us_towns, file = ""data/2-26-ufo-us-towns.Rdata"")

# explore -----------------------------------------------------------------

ufo %>% 
  ggplot(aes(x = date_documented)) +
  geom_histogram()


ufo %>% 
  ggplot(aes(x = date_documented %>% month() %>% as.character())) +
  geom_bar()


ufo %>% 
  ggplot(aes(x = encounter_length)) +
  geom_histogram() +
  scale_x_log10()

ufo %>% 
  ggplot(aes(x = date_documented,
             y = encounter_length)) +
  # geom_point() +
  geom_hex(colour = ""grey"", size = .5) +
  scale_y_log10() +
  theme_bw()


# plot --------------------------------------------------------------------

towns_in <- 
  tibble(city = c(""New York"", ""Los Angeles"", ""Seattle"", ""Phoenix"", ""Chicago""),
         nudge_x = c(3, -3, -3, -2, 1.5),
         nudge_y = c(-2, -2, -2, -2, 1.7),
         vjust = case_when(nudge_y > 0 ~ 0, TRUE ~ 1),
         hjust = case_when(nudge_x > 0 ~ 0, TRUE ~ 1)) %>% 
  left_join(us_towns, by = ""city"")

p <- 
  ufo %>%
  ggplot(aes(x = longitude,
             y = latitude)) +
  geom_hex(colour = bg_col, size = .4, bins = c(100, 150)) +
  geom_link(data = towns_in,
               aes(xend = longitude + nudge_x,
                   yend = latitude + nudge_y,
                   colour = case_when(..index.. > .16 & ..index.. < .93 ~ ""grey"",
                                      # ~ ""grey"",
                                      TRUE ~ ""none"")),
            size = .4) +
  geom_text(data = towns_in,
            aes(label = city,
                x = longitude + nudge_x,
                y = latitude + nudge_y,
                hjust = hjust,
                vjust = vjust),
            colour = grey,
            size = 2.6,
            family = ""courier"",
            fontface = ""bold"") +
  lims(x = c(-128, -50),
       y = c(25, 49)) +
  # scale_fill_gradient(low = rgb(cp(.05), maxColorValue = 255),
  #                     # trans = ""log"",
  #                     high = rgb(cp(1), maxColorValue = 255)) +
  scale_fill_gradientn(limits = c(0, NA),
                       colours = map_chr(seq(.08, 1, length.out = 256), cpal_rgb),
                       breaks = c(0, 400, 800, 1200),
                       guide = guide_legend(nrow = 1,
                                            label.position = ""bottom"", title.position = ""top"",
                                            keywidth = unit(6, units = ""mm""),
                                            keyheight = unit(1.2, units = ""mm""))) +
  scale_colour_manual(values = c(grey = grey, none = ""#FFFFFF00"")) +
  guides(colour = FALSE) +
  labs(fill = ""Counts"") +
  theme_void(base_size = 9, base_family = ""courier"") +
  theme(aspect.ratio = .4,
        legend.position = c(.95, .7),
        plot.margin = margin(3, 14, 6, 0, unit = ""mm"")) 
 
# grid.rect(gp = gpar(fill = bg_col))
# print(p, vp = viewport())

png(filename = ""plots/2-26-ufo.png"",
    height = 1200, 
    width = 3000,
    res = 400)
grid.rect(gp = gpar(fill = bg_col))
print(p, vp = viewport())
grid.text(label = ""UFO \u2764 NY"",
          x = .8, y = .3, 
          gp = gpar(fontfamily = ""courier"",
                    col = purple,
                    fontface = ""bold"",
                    fontsize = 30))
grid.text(label = ""(and Los Angeles, Seattle, Chicago and Phoenix)"",
          x = .8, y = .2, 
          gp = gpar(fontfamily = ""courier"",
                    col = grey,
                    fontface = ""bold"",
                    fontsize = 6))
grid.text(label = ""Data by NUFORC and Sigmond Axel (and Miserlou) | Plot by @othomn"",
          x = .99, y = .03, 
          hjust = 1,
          gp = gpar(fontfamily = ""courier"",
                    col = purple,
                    # fontface = ""bold"",
                    fontsize = 6))

dev.off()

","2019-26"
"755",641,"https://github.com/othomantegazza/code-tidytuesday/blob/master/011-fifa-view.R","othomantegazza","code-tidytuesday","011-fifa-view.R","library(tidyverse)
library(maptools)
library(maps)
library(broom)
library(shadowtext)

# Get data ----------------------------------------------------------------

dat_path <- ""data/fifa.Rdata""
if(!file.exists(dat_path)) {
  dat <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week11_fifa_audience.csv"",
                  col_types = cols_only(country = col_character(),
                                        confederation = col_character(),
                                        population_share = col_double(),
                                        tv_audience_share = col_double(),
                                        gdp_weighted_share = col_double()))
  save(dat, file = dat_path)
} else {
  load(dat_path)
}


# Share density in europe? -----------------------------------------

dat <- dat %>%
  filter(confederation == ""UEFA"") %>%
  arrange(desc(tv_audience_share))


# Europe Map --------------------------------------------------------------

data(""wrld_simpl"")
dat$country[!dat$country %in% wrld_simpl$NAME]

country_codes <- wrld_simpl@data %>%
  rename(country = ""NAME"",
         id = ""ISO3"") %>%
  select(country, id)

dat <- dat %>%
  left_join(country_codes)

uefa <- wrld_simpl[wrld_simpl$NAME %in% dat$country, ]


# Get Capitals ------------------------------------------------------------

capitals <- world.cities %>% 
  filter(capital == 1) %>%
  rename(country = ""country.etc"") %>%
  mutate(country = if_else(country == ""UK"",
                           true = ""United Kingdom"",
                           false = country)) %>%
  right_join(dat) %>%
  filter(complete.cases(.))
 

# Tidy --------------------------------------------------------------------

uefa <- tidy(uefa) %>%
  left_join(dat) %>%
  group_by(id) %>%
  mutate(med_long = mean(range(long)),
         med_lat = mean(range(lat))) %>%
  ungroup()


# Plot --------------------------------------------------------------------

# credits:
# https://www.r-graph-gallery.com/a-smooth-transition-between-chloropleth-and-cartogram/

jpeg(filename = ""plots/uefa.jpg"",
    width = 9, 
    height = 9,
    units = ""in"",
    res = 200)
ggplot() +
  geom_polygon(data = uefa,
               aes(fill = tv_audience_share,
                   x = long,
                   y = lat,
                   group = group),
               size=1) +
  geom_shadowtext(data = capitals,
                  aes(x = long,
                      y = lat,
                      label = tv_audience_share,
                      size = tv_audience_share)) +
  xlim(-10, 50) +
  ylim(32, 77) +
  annotate(""text"", x = -10, y = 74,
          label =  ""TV audience share of FIFA World Cup, 2010"", size = 6) +
  annotate(""text"", x = -10, y = 72,
           label =  ""UEFA Countries"", size = 5,
           hjust = 1.2) +
  coord_map(projection = ""conic"", lat0 = 50) +
  theme_void() +
  scale_fill_gradient(name=""TV Audience Share"",
                     breaks=c(0, 1, 2, 3),
                     guide = guide_legend(keyheight = unit(3, units = ""mm""),
                                          keywidth=unit(12, units = ""mm""), 
                                          label.position = ""bottom"",
                                          title.position = 'top',
                                          nrow=1),
                     high = ""#001a33"", low = ""#cce6ff"") +
  scale_size(guide = FALSE,
             range = c(0, 10)) +
  theme(text = element_text(size = 14),
        legend.position = c(.5, .05))
dev.off()
","2018-11"
"756",642,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-05-milk.R","othomantegazza","code-tidytuesday","2-05-milk.R","library(tidyverse)
library(scico)
library(tibbletime)

# Get data Milk products ---------------------------------------------------

dat_path <- ""data/2-05-milk-product-facts.Rdata""
dat_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""2019/2019-01-29/milk_products_facts.csv"")

if(!file.exists(dat_path)) {
  dat_milkprods <- 
    read_csv(dat_url)
  
  save(dat_milkprods, file = dat_path)
  
} else {
  load(dat_path)
}


# Percent ---------------------------------------------------------

# roll over tibbles
roll_percent <- rollify(.f = function(n) (n[2] - n[1])*100/n[1], 2)

dat <- 
  dat_milkprods %>%
  select(year, butter) %>% 
  mutate(percent = roll_percent(butter)) %>% 
  filter(complete.cases(.))


# plot --------------------------------------------------------------------

# needed to center divergent palette
lim <- 
  dat$percent %>% 
  range() %>% 
  abs() %>% 
  max()


p <- 
  dat %>% 
  mutate(yend = butter + (percent/10)) %>% 
  ggplot(aes(x = year,
             y = butter)) +
  annotate(geom = ""rect"",
           xmin = 2008, xmax = 2010,
           ymin = -Inf, ymax = Inf,
           fill = ""grey80"", alpha = .5) +
  annotate(geom = ""text"",
           x = 2009, y = 4,
           label = ""2008\nEconomic Crisis?"",
           family = ""Arial Narrow"",
           colour = ""grey40"",
           size = 3, fontface = ""bold"") +
  # geom_line(color = ""grey80"") +
  geom_segment(aes(yend = yend,
                   xend = ..x..,
                   colour = percent),
               size = 2,
               arrow = arrow(length = unit(1.2, ""mm""),
                             type = ""closed"")) +
  geom_point(colour = ""grey40"", size = 2) +
  geom_text(aes(y = case_when(percent > 0 ~ yend + .12,
                              TRUE ~ yend - .12),
                label = percent %>% 
                  round() %>% paste0(""%""),
                colour = percent),
            size = 2.7) +
  scale_colour_scico(palette = ""roma"",
                   direction = 1,
                   limits = c(-lim, lim),
                   guide = FALSE) +
  guides(colour = element_blank()) +
  labs(title = ""Fluctuations in Butter Consumptions"",
       subtitle = str_wrap(""In the US between 1975 - 2017,
                           with weight of sold butter in lbs 
                           and its percent change compared to
                           the previous year.""),
       y = ""Sold Butter in lbs"",
       x = ""Year"",
       caption = ""Data: USDA | Plot by @othomn"") +
  theme_minimal() +
  theme(text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40"",
                            size = 11),
        axis.title = element_text(size = 14),
        plot.title = element_text(colour = ""grey20"",
                                  face = ""bold"",
                                  size = 18),
        plot.subtitle = element_text(face = ""bold"",
                                     size = 12),
        aspect.ratio = .6,   
        plot.margin = margin(t = 10, r = 15, b = 0, l = 10,
                             unit = ""mm""))

p
# Save --------------------------------------------------------------------

png(filename = ""plots/2-05-milk.png"",
    height = 1600, width = 2100,
    res = 300)
p %>% print()
dev.off() 

","2019-5"
"757",643,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-17-anime.R","othomantegazza","code-tidytuesday","2-17-anime.R","library(tidyverse)
library(igraph)
library(grid)

# get data ----------------------------------------------------------------

anime_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                ""tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")
anime_file <- ""data/2-17-anime.Rdata""


if(!file.exists(anime_file)) {
  anime <- readr::read_csv(anime_url)
  
  save(anime, file = anime_file)
  
} else {
  load(anime_file)
}


# Explore -----------------------------------------------------------------

anime$producers %>% table() %>% sort(decreasing = T) %>% head()
anime$genre %>% table() %>% sort(decreasing = T) #%>% head()

to_plot <- 
  with(anime, table(genre, producers)) %>%
  as_tibble() %>%
  arrange(desc(n))



# graph ? -----------------------------------------------------------------

dat_graph <- 
  anime %>% 
  select(animeID, genre) %>% 
  filter(complete.cases(.)) %>% 
  distinct() %>% 
  split(.$animeID) %>% 
  map(~expand.grid(x = .$genre, y = .$genre) %>% 
        as_tibble() %>% 
        mutate_all(as.character)) %>% 
  reduce(bind_rows) %>% 
  mutate(count = 1) %>% 
  group_by(x, y) %>% 
  summarise(count = sum(count))

dat_graph %>% filter(x == y)


# with igraph -------------------------------------------------------------

library(""igraph"")

vs <- 
  dat_graph %>%
  filter(x == y) %>% 
  select(genre = x,
         count) %>% 
  filter(count >= 500)

edges <- 
  dat_graph %>% 
  mutate(n_x = case_when(x == y ~ count)) %>% 
  arrange(x, n_x) %>% 
  fill(n_x) %>% 
  mutate(perc = count/n_x) %>% 
  filter(perc > .2,
         x %in% vs$genre,
         y %in% vs$genre) %>% 
  filter(x != y)

g <- graph_from_data_frame(d = edges, vertices = vs)


# plot with ggraph --------------------------------------------------------

library(ggraph)

text_color <- ""grey20""

g %>% as_long_data_frame()

set.seed(7)
# set.seed(12)
# set.seed(16)
p <- 
  g %>% 
  ggraph(layout = ""graphopt"") +
  # ggraph(layout = ""lgl"") +
  geom_edge_link(aes(alpha = count),
                 colour = ""#4C63C3"") +
  geom_node_point(aes(size = count),
                  colour = ""#B63A82"") +
  geom_node_text(aes(label = name),
                 nudge_x = 1,
                 nudge_y = 1,
                 vjust = 0,
                 hjust = 0,
                 colour = text_color) +
  # geom_text(aes(label = count)) +
  expand_limits(x = c(0, 70),
                y = c(60, 80)) +
  theme_void()

p #%>% ggplotGrob()

p2 <- 
  p +
  scale_edge_alpha(guide = guide_legend(nrow = 1)) +
  guides(alpha = guide_edge_colorbar(nrow = 1),
         size = guide_legend(nrow = 1, title = NULL)) +
  theme(legend.position = c(.4, .07))

# Save --------------------------------------------------------------------

png(filename = ""plots/2-17-anime.png"", 
    height = 10,
    width = 8,
    units = ""in"",
    res = 300)
grid.newpage()
print(p2, vp = viewport())
# title 
grid.text(""Anime Genres"",
          x = .65,
          y = .9,
          gp = gpar(col = text_color,
                    fontsize = 20),
          hjust = 0,
          vjust = 0)
grid.text(""Source: myanimelist.net\nPlot by @othomn"",
          x = .65,
          y = .81,
          gp = gpar(col = text_color,
                    fontsize = 10),
          hjust = 0,
          vjust = 0)
dev.off()

 # others ------------------------------------------------------------------

g %>% 
  ggraph(layout = ""linear"", circular = TRUE) +
  geom_edge_arc(aes(alpha = count),
                 colour = ""#4C63C3"") +
  geom_node_point(aes(size = count), colour = ""#B63A82"") +
  geom_node_text(aes(label = name),
                 angle = 90) +
  # geom_text(aes(label = count)) +
  theme_void()

g %>% 
  ggraph(layout = ""linear"") +
  geom_edge_arc(aes(alpha = count)) +
  theme_void()

g %>% 
  ggraph(layout = ""linear"", circular = TRUE) +
  geom_edge_arc2(aes(alpha = count)) +
  theme_void()

# c('star', 'circle', 'gem', 'dh', 'graphopt', 'grid', 'mds', 
#   'randomly', 'fr', 'kk', 'drl', 'lgl')","2019-17"
"758",644,"https://github.com/othomantegazza/code-tidytuesday/blob/master/32-wind-turbines.R","othomantegazza","code-tidytuesday","32-wind-turbines.R","library(tidyverse)
library(maps)

# Get data ----------------------------------------------------------------

dat_path <- paste0(""https://raw.githubusercontent.com/"",
                   ""rfordatascience/tidytuesday/"",
                   ""master/data/2018-11-06/us_wind.csv"")

dat_file <- ""data/32-wind-turbine.Rdata""

if(!file.exists(dat_file)) {
  dat <- read_csv(dat_path)
  
  save(dat, file = dat_file)
} else {
  load(dat_file)
}

# Remove NA ---------------------------------------------------------------

dat <- 
  dat %>% 
  select(p_year, p_cap, t_cap,
         xlong, ylat) %>%
  mutate(p_year = p_year %>%
           na_if(-9999),
         p_cap = p_cap %>%
           na_if(-9999),
         t_cap = t_cap %>% 
           na_if(-9999))
         
dat_tidy <-
  dat %>% 
  filter(complete.cases(.)) %>% 
  mutate(year_span = case_when(p_year >= 1981 & p_year <= 1993 ~ ""1981 - 1993"",
                               p_year >= 1994 & p_year <= 2006 ~ ""1994 - 2006"",
                               p_year >= 2007 & p_year <= 2018 ~ ""2007 - 2018""))


# Plot on map -------------------------------------------------------------

usa_map <- map_data(""state"")

map_plot <- 
  dat_tidy %>%
  ggplot(aes(x = xlong,
             y = ylat)) +
  geom_map(data=usa_map,
           map=usa_map,
           aes(x=long, y=lat,
               map_id=region),
           colour = ""grey60"", fill = ""grey96"",
           size = .4) +
  geom_bin2d(
    bins = c(80, 50)
    ) +
  facet_wrap(facets = ""year_span"",
             ncol = 1) +
  coord_map(projection = ""conic"",
            lat = 41) +
  lims(x = c(-124.5, -67.5),
       y = c(25, 50)) +
  scale_fill_viridis_c(guide = guide_colourbar(breaks = c(1000, 1500),
                                               title.vjust = 1,
                                               barwidth = 10.5,
                                               barheight = .4)) +
  theme_void() +
  theme(strip.text = element_text(size = 12,
                                  colour = ""grey40""), 
        title = element_text(colour = ""grey20"",
                             face = ""bold""), 
        legend.position = ""bottom"", 
        plot.margin = margin(18, 10, 10, 10,
                             unit = ""pt"")) + 
  labs(title = ""New Wind Turbines in US Mainland"",
       caption = ""Source: usgs.gov | plot by @othomn"", 
       fill = ""Count"")

# Save plot ---------------------------------------------------------------

png(filename = ""plots/32-wind-turbines.png"",
    height = 3000, width = 1700,
    res = 400)
map_plot %>% print()
dev.off()
","2018-32"
"759",645,"https://github.com/othomantegazza/code-tidytuesday/blob/master/02-24-meteorites.R","othomantegazza","code-tidytuesday","02-24-meteorites.R","library(tidyverse)
library(grid)
library(maptools)
library(sf)

purple <- ""#AA2255""
purple2 <- ""#BB2255""
bg_col <- ""#EAEA9F"" #""#F6F6DF""

data(wrld_simpl)

# Get data ----------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                   ""master/data/2019/2019-06-11/meteorites.csv"")

data_path <- ""data/2-24-meteorites.Rdata""

if(!file.exists(data_path)) {
  meteors <- 
    data_url %>% 
    read_csv()
  
  save(meteors, file = data_path)
} else {
  load(data_path)
}


# how many by years? ------------------------------------------------------

meteors %>% 
  count(year) %>% 
  arrange(desc(year)) # %>% View()

# there are peak years 2003, 1998, 1988, 1979
# ten years cycle?


meteors %>% 
  filter(fall == ""Fell"") %>% # View()
  count(year) %>% 
  filter(year > 1950,
         year < 2014) %>% 
  ggplot(aes(x = year, 
             y = n)) +
  geom_line()


# where do they fall? -----------------------------------------------------

meteors %>% 
  mutate(long = case_when(long > 200 ~ long - 360,
                          TRUE ~ long)) %>% 
  ggplot(aes(x = long,
             y = lat)) +
  geom_point(alpha = .4) +
  coord_map(projection = ""gall"", lat0 = 0)

meteors %>% 
  filter(long > 200) # %>% View()

# size by year -----------------------------------------------------------

meteors %>% 
  filter(year > 1950,
         year < 2014) %>% 
  ggplot(aes(x = year %>% as.character(),
             y = mass)) +
  # geom_boxplot(fill = ""#CD0A62"") +
  geom_boxplot(aes(fill = fall), position = ""dodge"") +
  scale_y_log10() +
  # facet_wrap(facets = ""fall"", ncol = 1) +
  theme_bw()


# size of fell meteorites by location -------------------------------------

p <- 
  meteors %>% 
  filter(long < 200,
         fall == ""Fell"",
         mass >= 250000) %>% # View()
  ggplot(aes(x = long,
             y = lat)) +
  # geom_path(data = map_data(""world""),
  #           aes(x = long, y = lat,
  #               group = group),
  #           colour = ""grey70"") +
  borders(fill = ""white"", colour = bg_col) +
  # geom_sf(data = wrld_simpl %>%
  #           sf::st_as_sf()) +
  ggrepel::geom_text_repel(aes(label = paste(name,
                                             scales::scientific(mass, digits = 0),
                                             sep = ""\n"")),
                           force = 8,
                           lineheight = .8, 
                           colour = purple,
                           size = 3,
                           fontface = ""bold"") +
  geom_point(aes(size = mass),
             colour = ""#4C63C3"",
             alpha = .7) +
  guides(size = FALSE,
         colour = FALSE) +
  scale_colour_viridis_c(option = ""A"") +
  theme_void() +
  theme(panel.background =  element_rect(fill = bg_col, colour = bg_col),
        title = element_text(hjust = .5)) +
  coord_map(projection = ""mollweide"", orientation = c(90, 0, 0))#, lat0 = 0) 

grid.newpage()
grid.rect(gp = gpar(fill = bg_col))
print(p, vp = viewport())


png(""plots/2-24-meteorites.png"",
    width = 2500,
    height = 1800,
    res = 300)
set.seed(46)
grid.newpage()
grid.rect(gp = gpar(fill = bg_col))
print(p, vp = viewport(y = .45))
grid.text(label = str_wrap(""Biggest meteorites that have been observed hitting Earth until 2012."",
                           width = 50),
          vjust = .5,
          hjust = .5,
          x = .5,
          y = .9, 
          gp = gpar(fontfamily = ""courier"",
                    fontface = ""bold"",
                    fontsize = 14,
                    col = ""#7A82A6"",
                    lineheight = 1))
grid.text(label = str_wrap(""With name and mass in grams."",
                           width = 50),
          vjust = .5,
          hjust = .5,
          x = .5,
          y = .84, 
          gp = gpar(fontfamily = ""courier"",
                    fontface = ""bold"",
                    fontsize = 7,
                    col = purple))
grid.text(label = str_wrap(""Data from NASA | plot by @othomn"",
                           width = 50),
          vjust = .5,
          hjust = .5,
          x = .78,
          y = .06, 
          gp = gpar(fontfamily = ""courier"",
                    fontface = ""bold"",
                    fontsize = 8,
                    col = ""#7A82A6""))
dev.off()


meteors %>% 
  filter(long < 200,
         fall == ""Fell"",
         mass >= 250000) %>% 
  st_as_sf(coords = c(""long"", ""lat""),
           crs = ""+proj=longlat +datum=WGS84 +no_defs"") %>% 
ggplot() +
  # geom_path(data = map_data(""world""),
  #           aes(x = long, y = lat,
  #               group = group),
  #           colour = ""grey70"") +
  geom_sf(data = wrld_simpl %>%
            sf::st_as_sf(crs = ""+proj=longlat +datum=WGS84 +no_defs"")) +
  geom_sf(aes(size = mass),
          colour = purple) +
  geom_sf_text(aes(label = name)) +
  theme_void() +
  coord_sf(crs = ""+proj=moll +datum=WGS84 +no_defs"")

""+proj=moll +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs""

meteors %>% 
  filter(long < 200,
         fall == ""Fell"",
         mass >= 250000) %>% 
  ggplot() +
  # geom_path(data = map_data(""world""),
  #           aes(x = long, y = lat,
  #               group = group),
  #           colour = ""grey70"") +
  geom_sf(data = wrld_simpl %>%
            sf::st_as_sf()) +
  geom_point(aes(x = long,
                 y = lat,
                 size = mass),
             colour = purple) +
  theme_void() +
  coord_map(projection = ""mollweide"")#, lat0 = 0) 

wrld_simpl %>% sf::st_as_sf() %>% 
  ggplot() +
  geom_sf()
","2019-24"
"760",646,"https://github.com/othomantegazza/code-tidytuesday/blob/master/25-flights.R","othomantegazza","code-tidytuesday","25-flights.R","library(MASS)
library(tidyverse)
library(broom)
library(ggrepel)

# Read Data ---------------------------------------------------------------

dat_path <- ""data/25-flights.Rdata""


if(!file.exists(dat_path)) {
  dat <- read_csv(paste0(""https://raw.githubusercontent.com/"",
                         ""rfordatascience/tidytuesday/master/data/"",
                         ""2018-09-18/us-airports.csv"")) %>%
    select(-X1)
  save(dat, file = dat_path)
} else {
  load(dat_path)
}


# Analyze data ------------------------------------------------------------

# Many missing data from 2014 onward ?

dat %>%
  split(.$year) %>%
  # map(~sum(is.na(.$passengers)))
  map(dim)

# Subset - only hubs ------------------------------------------------------

hubs <- dat %>%
  dplyr::select(loc_id, hub_type,
         year, passengers, state) %>%
  spread(key = year, value = passengers) %>%
  filter(complete.cases(.),
         hub_type != ""Nonhub"") %>%
  mutate(x = `2012`,
         y = `2017`/`2012`)

# model -------------------------------------------------------------------

fit <- MASS::rlm(y ~ poly(x, 2), data = hubs)

tidy(fit)

hubs <- predict(fit,
        newdata = hubs,
        interval = ""predict"") %>%
  as_tibble() %>% 
  bind_cols(hubs)

# plot --------------------------------------------------------------------

png(filename = ""plots/25-airports.png"",
    height = 1500, width = 2500,
    res = 300)
hubs %>%
  ggplot(aes(x = `2012`,# + `2017`/ 2,
             y =`2017`/`2012`, 
             ymin = lwr,
             ymax = upr)) +
  geom_point(colour = ""grey30"") +
  # geom_point(data = hubs %>% filter(state == ""OH""),
  #            colour = ""blue"") +
  geom_point(data = hubs %>%
               filter(y > upr | y < lwr),
             aes(colour = state)) +
  geom_text_repel(data = hubs %>%
                    filter(y > upr),
                  aes(label = loc_id), nudge_y = .1) +
  geom_text_repel(data = hubs %>%
                    filter(y < lwr),
                  aes(label = loc_id), nudge_y = -.1) +
  # stat_smooth(method = ""rlm"",
  #             formula = y ~ poly(x, 2),
  #             se = F) +
  geom_line(aes(y = fit), lwd = 1.5,
            alpha = .5) +
  geom_ribbon(alpha = .3,
              fill = ""cyan3"") +
  scale_x_log10() +
  scale_y_continuous(breaks = c(.75, 1, 1.25, 1.5, 1.75, 2.0, 2.25),
                     labels = paste(c(""Decrease - "", ""Same - "", """", """", """", """", ""Increase - ""),
                     c(.75, 1, 1.25, 1.5, 1.75, 2.0, 2.25))) +
  # scale_y_log10() +
  # facet_wrap(facet = ""state"") +
  theme_bw() +
  labs(title = ""Passenger Increase in US Hubs (Airports)"",
       subtitle = ""Between 2012 and 2017"",
       x = ""Yearly Passengers in 2012 [log scale]"",
       y = ""Passengers Increase in 2017 [2017 / 2012]"",
       caption = ""Source: faa.gov, plot by @othomn"")
dev.off() 



","2018-25"
"761",647,"https://github.com/othomantegazza/code-tidytuesday/blob/master/24-cats-and-dogs.R","othomantegazza","code-tidytuesday","24-cats-and-dogs.R","library(tidyverse)
library(statebins)
library(socviz)

# Get data ----------------------------------------------------------------

dat_path <- ""data/24-cats-and-dogs.Rdata""


if(!file.exists(dat_path)) {
  dat <- read_csv(paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""2018-09-11/cats_vs_dogs.csv"")) %>%
    select(-X1)
  save(dat, file = dat_path)
} else {
  load(dat_path)
}


# plot --------------------------------------------------------------------

# code tries to replicate:
# https://socviz.co/maps.html#map-u.s.-state-level-data

# get the census column from socviz
# to facet regions

tst <- dat %>%
  left_join(socviz::election %>%
              select(state, census)) %>%
  mutate(ratio_owner = n_dog_households/n_cat_households,
         main_household = case_when(ratio_owner > 1 ~ ""Dog"",
                                    ratio_owner < 1 ~ ""Cat"",
                                    TRUE ~ ""Both""),
         main_household = factor(main_household,
                                 levels = c(""Cat"", ""Both"", ""Dog"")))


png(filename = ""plots/24-cats-and-dogs.png"",
    height = 2500, width = 1700,
    res = 300)
tst %>%
  ggplot(aes(x = reorder(state, ratio_owner),
             y = ratio_owner,
             colour = main_household)) +
  geom_hline(yintercept = 1) +
  geom_point(size = 2) +
  facet_grid(census ~ .,
             scales = ""free_y"",
             space = ""free"") +
  scale_color_viridis_d(begin = .1, end = .9) +
  coord_flip() +
  scale_y_log10(limits = c(.6, 1.7),
                breaks = c(.625, .8, 1, 1.25, 1.6),
                labels = c(""x1.6\n (Cat)"", ""x1.25"", ""1"", ""x1.25"", ""x1.6\n(Dog)"")) +
  theme_minimal() +
  theme(axis.text.x = element_text(size = 12)) +
  labs(title = ""Households with Cats and/or Dogs"",
       subtitle = ""In the US, split by region"",
       x = """",
       y = ""Household Ratio"", 
       colour = ""Preferred Pet"",
       caption = ""Source: data.world, plot by @othomn"")
dev.off()


# A slightly different take -----------------------------------------------


png(filename = ""plots/24-cats-and-dogs-2nd-take.png"",
    height = 2500, width = 1600,
    res = 300)
tst %>%
  select(state, census,
         percent_dog_owners, percent_cat_owners) %>%
  gather(percent_dog_owners:percent_cat_owners,
         key = pet,
         value = percent) %>%
  mutate(pet = case_when(pet == ""percent_dog_owners"" ~ ""Dog"",
                         pet == ""percent_cat_owners"" ~ ""Cat"")) %>% 
  ggplot(aes(x = reorder(state, percent),
             y = percent,
             fill = pet,
             pch = pet)) +
  geom_line(aes(group = state), colour = ""grey"") +
  # geom_hline(yintercept = 1) +
  geom_point(size = 2,
             alpha = 1) +
  facet_grid(census ~ .,
             scales = ""free_y"",
             space = ""free"") +
  scale_fill_viridis_d(begin = .1, end = .9,
                       guide = guide_legend(title = ""Pet owned"")) +
  scale_shape_manual(values = c(21, 23),
                     guide = guide_legend(title = ""Pet owned"")) +
  coord_flip() +
  scale_y_continuous(breaks = 1:5*10,
                     labels = c(paste0(1:5*10, ""%""))) +
  theme_minimal() +
  # guides(shape = guide_legend())
  labs(title = ""Households with Cats and/or Dogs"",
       subtitle = ""In the US, split by region"",
       x = """",
       y = ""Pet Owners [% of Households]"", 
       fill = ""Preferred Pet"",
       caption = ""Source: data.world, plot by @othomn"")
dev.off()
  



","2018-24"
"762",648,"https://github.com/othomantegazza/code-tidytuesday/blob/master/012-hurricane-cover.R","othomantegazza","code-tidytuesday","012-hurricane-cover.R","Sys.setlocale(""LC_TIME"", ""en_US.UTF8"")
library(tidyverse)
library(lubridate)

# Read files --------------------------------------------------------------

local_data <- ""data/hurrican-cover.Rdata""


if(!file.exists(local_data)) {
  paths <- c(google_trends = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_google_trends.csv"",
             written_media = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_mediacloud_hurricanes.csv"",
             states = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_mediacloud_states.csv"",
             top_online_news = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_mediacloud_top_online_news.csv"",
             trump = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_mediacloud_trump.csv"",
             tv_media = ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_tv_hurricanes.csv"")
  
  dat <- paths %>%
    map(read_csv)
  
  # the first file complains
  # 
  # Parsed with column specification:
  #   cols(
  #     `Category: All categories` = col_character()
  #   )
  # Warning: 38 parsing failures.
  #
  # read manually
  
  dat$google_trends <- read_csv(paths[""google_trends""], skip = 2)
  
  save(dat, file = ""data/hurrican-cover.Rdata"")
} else {
  load(local_data)
}


# Small tidyings to specific files------------------------------------------------

dat$written_media <- dat$written_media %>% mutate(Date = mdy(Date))

dat$states <- dat$states %>% mutate(Date = mdy(Date))

dat$tv_media <- dat$tv_media %>% 
  mutate(Date = mdy(Date)) %>%
  rename_at(.vars = vars(Harvey:Jose), .funs = ~paste0(., ""_tv""))

dat$top_online_news <- NULL

dat$google_trends <- dat$google_trends %>% 
  rename(Date = ""Day"") 



# Tidy and merge into one dataset -----------------------------------------

# one observation per line
dat <- dat %>%
  map(~gather(data = .,
              key = ""hurricane_state"",
              value = ""value"",
              -Date))

# include data source in the dataset
# and merge
dat <- names(dat) %>%
  map(~mutate(dat[[.]], source = .)) %>%
  reduce(bind_rows)


# Plot reaction -----------------------------------------------------------

# last wrangling
dat <- dat %>%
  # Simple names for hurricanes
  mutate(hurricane = case_when(grepl(""Harvey"", hurricane_state) ~""Harvey"",
                               grepl(""Irma"", hurricane_state) ~ ""Irma"",
                               grepl(""Jose"", hurricane_state) ~ ""Jose"",
                               grepl(""Maria"", hurricane_state) ~ ""Maria"",
                               TRUE ~ NA_character_)) %>%
  # descriptive name for data sources
  mutate(source = case_when(source == ""google_trends"" ~ ""Google Search Trend"",
                            source == ""tv_media"" ~ ""Percent of Sentences in TV News"",
                            source == ""written_media"" ~ ""N. of Sentences in Online News"")) %>%
  filter(complete.cases(.),
         value > 0)

# and plot
jpeg(filename = ""plots/hurricane_media.jpg"",
     width = 8, 
     height = 5,
     units = ""in"",
     res = 200)
ggplot(dat,
       aes(x = Date, y = value)) +
  geom_col(fill = ""#007399"",
           alpha = .5) + #0099cc"") +
  facet_grid(source ~ hurricane,
             scales = ""free"",
             space = ""free_x"",
             labeller = label_wrap_gen(width = 10,
                                       multi_line = T)) +
  ggtitle(""Hurricane Mentions in Media"") +
  ylab(""Recurrence in Media"") +
  theme_bw() +
  theme(text = element_text(size = 12),
        axis.text.x = element_text(angle = 90, vjust = 1),
        strip.text.y = element_text(angle = 0))

dev.off()","2018-12"
"763",649,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-23-ramen.R","othomantegazza","code-tidytuesday","2-23-ramen.R","library(tidyverse)
library(ggwordcloud)
library(grid)
library(ggforce)

purple <- ""#AA2255""
purple2 <- ""#BB2255""

# Get data ----------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/"",
                   ""data/2019/2019-06-04/ramen_ratings.csv"")

data_path <- ""data/2-23-ramen.Rdata""

if(!file.exists(data_path)) {
  ramen <- 
    data_url %>% 
    read_csv()
  
  save(ramen, file = data_path)
} else {
  load(data_path)
}


# explore -----------------------------------------------------------------

# ramen %>% View()

ramen %>%  
  count(brand) %>% 
  arrange(desc(n))

ramen %>% 
  count(style) %>% 
  arrange(desc(n))

ramen %>% 
  count(country) %>% 
  arrange(desc(n))

ramen %>% 
  count(variety) %>% 
  arrange(desc(n))


ramen %>% 
  ggplot(aes(x = style,
             y = stars)) +
  geom_count()

# stars by style
ramen %>% 
  filter(!style %in% c(""Bar"", ""Can"", ""Restaurant"")) %>% 
  ggplot(aes(x = style,
             y = stars)) +
  geom_boxplot() +
  geom_count()


# stars by country
top_c <-
  ramen %>% 
  count(country) %>%
  arrange(desc(n)) %>% 
  top_n(n = 10) %>% 
  pull(country)

third_q <- function(x) quantile(x, probs = 3/4)
first_q <- function(x) quantile(x, probs = 1/4)


purple <- ""#CD0A30""

p <- 
  ramen %>% 
  filter(country %in% top_c) %>% 
  select(country, stars) %>% 
  drop_na() %>% 
  mutate(country = reorder(country, stars, FUN = ""median"")) %>% 
  ggplot(aes(x = country,
             y = stars)) +
  geom_count(aes(alpha = ..n..), colour = purple) +
  stat_summary(aes(x = as.numeric(country) + .3),
               fun.y = median,
               fun.ymax = third_q,
               fun.ymin = first_q) +
  coord_flip() +
  theme_minimal() +
  scale_alpha_continuous(range = c(.5, 1)) +
  # scale_radius() +
  guides(size = guide_legend(nrow = 1),
         alpha = FALSE) +
  labs(x = ""Country"",
       y = ""Star Rating"",
       size = ""Count"",
       caption = ""Data from theramenrater.com | Plot by @othomn"") +
  theme(text = element_text(family = ""courier""),
        title = element_text(face = ""bold""),
        axis.title = element_text(hjust = 1, size = 10,
                                  colour = ""grey10""),
        plot.caption = element_text(colour = purple, 
                                    # colour = ""grey10"",
                                    size = 8),
        plot.title = element_text(lineheight = .2),
        plot.subtitle = element_text(colour = purple,
                                     lineheight = .3),
        plot.margin = margin(5,4,4,2, unit = ""mm""),
        legend.position = ""left"",
        legend.justification = ""center"", 
        legend.margin = margin(0, 10, 0, 40, unit = ""mm""))


dat_p_legend <- 
  tibble(y = c(.25, .5, .75),
         label = c(""1st quartile"", ""median"", ""3rd quartile""),
         xend = .85,
         curvature = c(.2, 0, -.2)) %>% 
  mutate(yend = y + c(-.05, 0, .05),
         y2 = y + c(-.02, 0, .02)) 

geom_curve_2 <- function(x, xend, y, y2, yend, label, curvature) {
  dat <- tibble(xend = xend, y2 = y2, yend = yend, curvature = curvature)
  geom_curve(data = dat,
             aes(x = .96, 
                 xend = xend, 
                 y = y2, 
                 yend = yend),
             curvature = curvature,
             colour = purple,
             arrow = arrow(length = unit(3, ""mm""),
                           ends = ""last"",
                           type = ""open"")) 
}

p_legend <- 
  dat_p_legend %>% 
  ggplot() +
  geom_text(aes(x = .8, y = y,
                label = label,
                hjust = 1- y),
            family = ""courier"") +
  geom_pointrange(x = 1, y = .5,
                 ymin = .25, ymax = .75) +
  pmap(.l = dat_p_legend, .f = geom_curve_2) +
  lims(x = c(0, 2),
       y = c(0, 1)) +
  coord_flip() +
  theme_void()
  

png(filename = ""plots/2-23-ramen.png"",
    width = 3500,
    height = 1600,
    res = 300)
p %>% print()
grid.lines(x = unit(c(.355, .355), ""npc""),
           y = unit(c(.18, .95), ""npc""))
grid.text(label = str_wrap(""Ramen Ratings by Country""),
          vjust = 1,
          hjust = 1,
          x = .32,
          y = .95, 
          gp = gpar(fontfamily = ""courier"",
                    fontface = ""bold"",
                    fontsize = 14,
                    col = purple))
grid.text(label = str_wrap('All ramens have been rated by ""The Ramen Rater"":
                           a one man initiative and top authority in the field.
                           Respect! ;)',
                           width = 30),
          vjust = 1,
          hjust = 1,
          x = .32,
          y = .85, 
          gp = gpar(fontfamily = ""courier"",
                    fontsize = 10,
                    lineheight = .84))
print(p_legend, vp = viewport(x = .2, y = .33, width = .3))
dev.off()
","2019-23"
"764",650,"https://github.com/othomantegazza/code-tidytuesday/blob/master/38-cetaceans.R","othomantegazza","code-tidytuesday","38-cetaceans.R","library(tidyverse)
library(lubridate)
library(rlang)
library(gtable)
library(gridExtra)
library(grid)
library(scico)

# Get Data ----------------------------------------------------------------


dat_path <- ""data/38-cetaceans.Rdata""
dat_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""2018-12-18/allCetaceanData.csv"")


if(!file.exists(dat_path)) {
  dat <- 
    read_csv(dat_url)
  
  save(dat, file = dat_path)
  
} else {
  load(dat_path)
}

# Plot -----------------------------------------------------------------

# prepare data for plots
dat_acq <- 
  dat %>% 
  filter(acquisition %in% c(""Born"", ""Capture"", ""Rescue"")) %>% 
  mutate(acquisition = factor(
    acquisition, levels = c(""Rescue"", ""Born"", ""Capture"")
  )) 


# set colors
sc_pal <- scico::scico(10, palette = ""devon"")[c(1, 4, 6)]


# Put a density plot on top
p_dens <- 
  dat_acq %>% 
  ggplot(aes(x = originDate,
             y = stat(count),
             fill = acquisition)) +
  geom_density(alpha = .5) +
  scale_fill_manual(
    values = sc_pal,
    guide = guide_legend(title.vjust = .2,
                         label.position = ""top"",
                         keyheight = unit(4, units = ""mm""),
                         keywidth=unit(14, units = ""mm""), 
                         nrow = 1,
                         reverse = TRUE)) +
  theme_bw() +
  labs(x = NULL, 
       y = ""Density"",
       title = ""New Cetaceans in Captivity in the US"",
       subtitle = ""Since the '90s, no new cetacean has been captured"",
       fill = ""Mean of Acquisition"") +
  theme(text = element_text(family = ""Arial Narrow"",
                             colour = ""grey40""),
        plot.title = element_text(colour = ""grey20"",
                                  face = ""bold"",
                                  size = 18, family = ""Arial Narrow""),
        plot.subtitle = element_text(colour = ""grey40"",
                                     face = ""bold"",
                                     size = 12),
        aspect.ratio = .35,
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.margin = margin(t = 10, r = 10, b = 0, l = 3, unit = ""mm""),
        legend.position = ""top"")


# and a rug at the bottom

half_width <- .33

p_point <- 
 dat_acq %>% 
  ggplot(aes(x = originDate,
             y = acquisition %>% as.numeric(),
             colour = acquisition)) +
  geom_linerange(aes(ymin = as.numeric(acquisition) - half_width,
                     ymax = as.numeric(acquisition) + half_width),
                 lwd = .2) +
  scale_y_continuous(breaks = 1:3,
                     labels = levels(dat_acq$acquisition)) +
  scale_color_manual(values = sc_pal) +
  guides(colour = FALSE) +
  theme_bw() +
  theme(aspect.ratio = .12,
        plot.margin = margin(t = 0, r = 10, b = 10, l = 3, unit = ""mm""),
        text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40"")) +
  labs(x = ""Day of Acquisiton"",
       y = """",
       caption = ""Sources: FOIA, Ceta-Base; collected by Amber Thomas | Plot by @othomn"")



# Put them together -------------------------------------------------------

png(filename = ""plots/38-cetaceans.png"",
    height = 1600, width = 2200,
    res = 300)
grid.newpage()
gtable_rbind(p_dens %>% ggplotGrob(),
             p_point %>% ggplotGrob(),
             size = ""max"") %>% 
  grid.draw()
dev.off() 


# Try logistic regression -------------------------------------------------

# For acquisition: use two levels:
# - Capture: the original and less respectful method
# - Others: Born +  Rescue = more modern and respectful methods

dat_acq2 <- 
  dat_acq %>%
  arrange(originDate) %>% 
  # filter(acquisition %in% c(""Born"", ""Capture"")) %>% 
  # mutate(acquisition = forcats::fct_relevel(acquisition)) %>% pull(acquisition)
  mutate(acquisition = acquisition %>% 
           fct_collapse(Others = c(""Born"", ""Rescue"")) %>% 
           fct_inorder(f = .))#levels = c(""Capture"", ""Others""))) #pull(acquisition)

# reset colour palette with two levels
# set colors
sc_pal2 <- sc_pal[c(2,3,1)]

# Put a density plot on top, again
p_dens <- 
  dat_acq2 %>% 
  ggplot(aes(x = originDate,
             y = stat(count),
             fill = acquisition)) +
  geom_density(alpha = .5) +
  scale_fill_manual(
    labels = c(""Capture"", ""Others\n[Born or Rescue]""),
    values = sc_pal2,
    guide = guide_legend(title.vjust = .2, 
                         label.position = ""top"",
                         keyheight = unit(4, units = ""mm""),
                         keywidth=unit(14, units = ""mm""), 
                         nrow = 1)) +
  theme_bw() +
  labs(x = NULL, 
       y = ""Density\nNew Captives per Day"",
       title = ""New Cetaceans in Captivity in the US"",
       subtitle = str_wrap(""With a classifier that estimates the probability that
                           a new cetacean was acquired by friendly means [Not Captured]
                           as a function of the Day of Acquisition""),
       fill = ""Mean of Acquisition"") +
  theme(text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40""),
        plot.title = element_text(colour = ""grey20"",
                                  face = ""bold"",
                                  size = 18, family = ""Arial Narrow""),
        plot.subtitle = element_text(colour = ""grey40"",
                                     face = ""bold"",
                                     size = 12),
        aspect.ratio = .35,
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        plot.margin = margin(t = 10, r = 10, b = 0, l = 3, unit = ""mm""),
        legend.position = ""top"")

p_dens

# fit logistic regression

fit <- 
  dat_acq2 %>% 
  {glm(acquisition ~ originDate, data = ., family = ""binomial"")}

# plot it

p_logit <- 
  dat_acq2 %>%
  mutate(acquisition = as.numeric(acquisition) %>% `-`(1)) %>% #pull(acquisition)
  ggplot(aes(x = originDate,
             y = acquisition, #%>% as.numeric() %>% `-`(1),
             colour = acquisition)) +# %>% as.character() %>% as_factor())) +
  # geom_point() +
  geom_linerange(aes(ymin = as.numeric(acquisition) - half_width*.2,
                     ymax = as.numeric(acquisition) + half_width*.2),
                 lwd = .2) +
  geom_smooth(method = ""glm"",
              method.args = list(family = ""binomial""),
              se = FALSE,
              colour = sc_pal2[3]) +
  ggplot2::annotate(x = as_date(as_date(""2004-01-01"")),
                    y = .5,
                    geom = ""label"",
                    label = ""estimated probability\n(logistic regression)"",
                    fill = sc_pal2[3],
                    colour = ""white"") +
  scale_color_continuous(low = sc_pal2[1],
                         high = sc_pal2[2]) +
  guides(colour = FALSE) +
  theme_bw() +
  theme(aspect.ratio = .28,
        plot.margin = margin(t = 0, r = 10, b = 10, l = 3, unit = ""mm""),
        text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40"")) +
  labs(x = ""Day of Acquisiton"",
       y = ""PROBABILITY\nthat new Cetacean\nwas NOT Captured"",
       caption = ""Sources: FOIA, Ceta-Base; collected by Amber Thomas | Plot by @othomn"")

p_logit
 
# save new plot with logistic regression
png(filename = ""plots/38-cetaceans-logit.png"",
    height = 2000, width = 2200,
    res = 300)
grid.newpage()
gtable_rbind(p_dens %>% ggplotGrob(),
             p_logit %>% ggplotGrob(),
             size = ""max"") %>% 
  grid.draw()
dev.off() 
","2019-38"
"765",652,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-22-wine.R","othomantegazza","code-tidytuesday","2-22-wine.R","library(tidyverse)
library(broom)

wine_purple <- ""#AA2255""

# Get data ----------------------------------------------------------------

data_url <- paste0(""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-05-28/winemag-data-130k-v2.csv?raw=true"")

data_path <- ""data/2-22-wine.Rdata""

if(!file.exists(data_path)) {
 wine <- 
   data_url %>% 
   read_csv()
  
  save(wine, file = data_path)
} else {
  load(data_path)
}


# explore -----------------------------------------------------------------

wine %>% 
  filter(country == ""Italy"") %>% 
  ggplot(aes(x = reorder(province, price, order = T),
             y = price)) +
  ggbeeswarm::geom_quasirandom(alpha = .2) +
  coord_flip() +
  scale_y_log10()

wine %>% pull(region_1) %>% unique()

wine %>% 
  ggplot(aes(x = points,
             y = price)) +
  geom_hex(bins = 20, colour = ""white"") +
  scale_y_log10()

wine %>% 
  filter(province == ""Lombardy"") %>% # distinct(variety)
  ggplot(aes(x = points %>% as.character(),
             y = price,
             fill = variety)) +
  geom_boxplot()+
  facet_wrap(facets = ""variety"")



#  test some model --------------------------------------------------------

set.seed(46)

wine_ita <- 
  wine %>% 
  filter(country == ""Italy"") %>% 
  mutate(test = sample(c(""train"", ""test""),
                       size = nrow(.),
                       replace = T)) %>% 
  drop_na(points, price)

train_test <- function(n, dat) {
  dat_train <- 
    dat %>% 
    filter(test == ""train"") 
  
  dat_test <- 
    dat %>% 
    filter(test == ""test"")
  
  fit_train <- 
    dat_train %>% 
    {lm(price ~ poly(points, n), data = dat)}
  
  MSE_train <- 
    dat_train %>% 
    {broom::augment(fit_train, newdata = .)} %>% 
    mutate(SE = (.fitted - price)^2) %>% 
    pull(SE) %>% mean()
  

  MSE_test <- 
    dat_test %>% 
    {broom::augment(fit_train, newdata = .)} %>% 
    mutate(SE = (.fitted - price)^2) %>% 
    pull(SE) %>% mean()
  
  tibble(mse_train = MSE_train,
         mse_test = MSE_test)
}

ploy_res_ita <- 
  1:20%>% 
  map_df(~train_test(., dat = wine_ita),
         .id = ""poly_degree"")



wine %>% 
  filter(country == ""Italy"") %>%
  {lm(price ~ poly(points, 16), data = .)} %>% 
  summary()


# plot italian wines ---------------------------------------------------------------

# 
# add_count(variety) %>%
#   filter(n > 300) %>% 
#   filter(!str_detect(variety, ""Blend"")) %>% 

wine %>% 
  filter(country == ""Italy"") %>%
  # add_count(variety) %>%
  # filter(n > 300) %>% 
  # filter(!str_detect(variety, ""Blend"")) %>% 
  ggplot(aes(x = points, 
             y = price)) +
  geom_hex(bins = 20, colour = ""white"", size = 1) +
  geom_smooth(formula = y ~ poly(x, 5),
              method = lm,
              size = 2) +
  # facet_wrap(facets = ""variety"") +
  # scale_y_log10() +
  scale_fill_viridis_c(option = ""C"") +
  theme_bw()

annos_tb <- 
  tibble(points = c(79.9, 96, 97),
         price = c(40, 10, 38),
         xend = c(80.5, 95, 96.2),
         yend = c(27, 23, 27),
         colourz = c(""black"", ""red"", ""red""))


best_95 <- 
  wine_ita %>% 
  filter(points == 95, 
         price == 25) %>% 
  pull(title)

best_96 <- 
  wine_ita %>% 
  filter(points == 96, 
         price == 27) %>% 
  pull(title)



p <- 
  wine_ita %>% 
  ggplot(aes(x = points, 
             y = price,
             group = points)) +
  ggbeeswarm::geom_quasirandom(alpha = .5,
                               colour = wine_purple,
                               size = .8) +
  geom_hline(yintercept = 25) +
  geom_curve(data = annos_tb,
             aes(xend = xend,
                 yend = yend),
             curvature = -.3,
             arrow = arrow(length = unit(3, ""mm""),
                           ends = ""last"",
                           type = ""open"")) +
  # annotate 25 line
  annotate(geom = ""text"",
           x = 79.8, y = 40,
           label = ""25$"",
           vjust = .5, hjust = 1,
           family = ""Courier"") +
  # annotate best choice at 95 points
  annotate(geom = ""text"",
           x = 96.2, y = 10,
           label = best_95 %>% str_wrap(15),
           vjust = .5, hjust = 0,
           family = ""Courier"",
           fontface = ""bold"",
           size = 3,
           lineheight = 1,
           colour = wine_purple) +
  annotate(geom = ""text"",
           x = 96.5, y = 40,
           label = best_96 %>% str_wrap(15),
           vjust = 0, hjust = 0,
           family = ""Courier"",
           fontface = ""bold"",
           size = 3,
           lineheight = 1,
           colour = wine_purple) +
  ylim(0, 100) +
  labs(x = ""Review scores by Vivino [range 80 - 100]"",
       y = ""Price [USD]"",
       caption = ""Data at Kaggle | Plot by @othomn"",
       title = ""Price of Italian Wine by Score\n"",
       subtitle = ""According to Wine-Enthusiast. Only Italian wines priced less than 100 $ are shown.\n"") +
  theme_minimal() +
  theme(text = element_text(family = ""Courier""),
        title = element_text(face = ""bold""),
        axis.title = element_text(hjust = 1, size = 10,
                                  colour = ""grey10""),
        plot.caption = element_text(colour = wine_purple, 
                                    # colour = ""grey10"",
                                    size = 8),
        plot.title = element_text(lineheight = .2),
        plot.subtitle = element_text(colour = wine_purple,
                                     lineheight = .3),
        plot.margin = margin(5,4,4,2, unit = ""mm""))


png(filename = ""plots/2-22-wine.png"",
    res = 300,
    height = 1600,
    width = 2600)
p %>% print()
dev.off()
","2019-22"
"766",655,"https://github.com/othomantegazza/code-tidytuesday/blob/master/21-wildfire.R","othomantegazza","code-tidytuesday","21-wildfire.R","library(tidyverse)
library(lubridate)

# load USA wide data ------------------------------------------------------

paths <- list.files(""data/us_fires"",
                    full.names = T)

us_fires <- paths %>%
  map(~read_csv(file = .,
                col_types = cols(
                  .default = col_character(),
                  stat_cause_code = col_double(),
                  cont_date = col_datetime(format = """"),
                  discovery_date = col_datetime(format = """"),
                  cont_doy = col_integer(),
                  cont_time = col_integer(),
                  fire_size = col_double(),
                  latitude = col_double(),
                  longitude = col_double()
                ))) %>%
  reduce(bind_rows)



# Bin data ----------------------------------------------------------------

jpeg(filename = ""plots/21-wildfire-map.jpg"",
     width = 10, 
     height = 7,
     units = ""in"",
     res = 200)
us_fires %>%
  mutate(latitude = round(latitude, digits = 0),
         longitude = round(longitude, digits = 0)) %>%
  group_by(fire_year, latitude, longitude) %>%
  summarise(fire_size = sum(fire_size)) %>%
  # filter(fire_year == 2007) %>%
  ggplot(aes(x = longitude,
             y = latitude,
             fill = sqrt(fire_size))) +
  geom_raster() +
  facet_wrap(facets = ""fire_year"") +
  # coord_map(projection = ""azequalarea"") +
  ylim(20, 50) +
  xlim(-130, -70) +
  scale_fill_viridis_c(option = ""C"") +
  theme_bw() 
dev.off()


# is total intensity increasing ---------------------------------------------

jpeg(filename = ""plots/21-wildfire-high-class.jpg"",
     width = 10, 
     height = 8,
     units = ""in"",
     res = 300)
us_fires %>%
  filter(fire_size_class %in% c(""F"", ""G"")) %>%
  ggplot(aes(x = discovery_date,
              y = fire_size)) +
  # geom_point(alpha = .1) +
  geom_hex(bins = 70) +
  scale_y_log10() +
  scale_fill_viridis_c(option = ""C"") +
  theme_minimal(base_size = 20) +
  ggtitle(""Big Fires in the USA from 1992 to 2015"",
          sub = ""Data from US fire service, only biggest fires (categories F and G)"") +
  xlab(""Date of Alert"") +
  ylab(""Fire Size [Hectares???] (log scale)"")
dev.off()

jpeg(filename = ""plots/21-wildfire-high-class-facet.jpg"",
     width = 12, 
     height = 10,
     units = ""in"",
     res = 300)
us_fires %>%
  filter(fire_size_class %in% c(""F"", ""G"")) %>%
  ggplot(aes(x = discovery_date,
             y = fire_size)) +
  # geom_point(alpha = .1) +
  geom_hex(bins = 12) +
  scale_y_log10() +
  scale_fill_viridis_c(option = ""C"") +
  scale_x_datetime(date_breaks = ""3 months"",
                   date_labels = ""%b"") +
  facet_wrap(facets = ""fire_year"",
             scales = ""free_x"",
             ncol = 6) +
  theme_bw(base_size = 14) +
  ggtitle(""Big Fires in the USA from 1992 to 2015"",
        sub = ""Data from US fire service, only biggest fires (categories F and G)"") +
  xlab(""Date of Alert"") +
  ylab(""Fire Size [Hectares???] (log scale)"")
dev.off()


","2018-21"
"767",656,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-25-birds.R","othomantegazza","code-tidytuesday","2-25-birds.R","library(tidyverse)
library(ggforce)
library(showtext)
library(grid)

font_families()
font_add(family = 'FontAwesome', regular = 'data/Font Awesome 5 Free-Solid-900.otf')
font_add_google(""B612 Mono"", family = ""courier"")

purple <- ""#AA2255""
purple2 <- ""#BB2255""
blue <-  ""#4C63C3""
bg_col <- ""#EAEA9F""

# get data ----------------------------------------------------------------


data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                   ""master/data/2019/2019-06-18/bird_counts.csv"")

data_path <- ""data/2-25-birds.Rdata""

if(!file.exists(data_path)) {
  birds <- 
    data_url %>% 
    read_csv()
  
  save(birds, file = data_path)
} else {
  load(data_path)
}

# explore -----------------------------------------------------------------

birds %>% 
  count(year) %>% View()

birds %>% 
  count(species) %>% View()

birds %>% summary

birds %>% 
  ggplot(aes(x = total_hours)) +
  geom_histogram()


# prepare data for plot ---------------------------------------------------


med_20 <- 
  birds %>% 
  filter(year > 1997,
         year <= 2007) %>% 
  drop_na() %>% # no need
  group_by(species) %>% 
  summarise(count_20 = median(how_many_counted_by_hour))


med_10 <- 
  birds %>% 
  filter(year > 2007,
         year <= 2017) %>% 
  drop_na() %>% # no need
  group_by(species) %>% 
  summarise(count_10 = median(how_many_counted_by_hour))

to_plot <- 
  full_join(med_20, med_10) %>% 
  filter(!{count_20 < .007 & count_10 < .007})

# Plot --------------------------------------------------------------------


showtext_auto()
font_families()

p <- 
  to_plot %>% 
  ggplot(aes(x = reorder(species, count_20), 
             y = count_10)) +
  geom_link(aes(xend = reorder(species, count_10),
                y = count_20,
                yend = count_10,
                size = ..index..,
                alpha = ..index..),
            colour = blue) +
  geom_text(label = ""\uf4ba"", family = ""FontAwesome"",
            colour = purple,
            size = 6) +
  coord_flip() +
  scale_y_log10() +
  scale_size_continuous(range = c(.1, .6)) +
  scale_alpha_continuous(range = c(.6, 1)) +
  guides(size = FALSE,
         alpha = FALSE) +
  theme_minimal() +
  labs(y = ""Counts per hour"",
       x = """",
       caption = ""Data by Bird Studies Canada and Sharleen W. | Plot by @othomn"") +
  theme(text = element_text(family = ""courier""),
        title = element_text(face = ""bold""),
        axis.title = element_text(hjust = 1, size = 9,
                                  colour = ""grey10""),
        axis.text = element_text(hjust = 1, size = 10,
                                 colour = ""grey10"",
                                 family = ""courier""),
        plot.caption = element_text(colour = purple, 
                                    # colour = ""grey10"",
                                    size = 8),
        plot.title = element_text(lineheight = .2),
        plot.subtitle = element_text(colour = purple,
                                     lineheight = .3),
        plot.margin = margin(14,2,2,2, unit = ""mm""),
        panel.background =  element_rect(fill = bg_col, colour = bg_col),
        panel.grid = element_line(colour = ""white"", size = .15))


# legend ------------------------------------------------------------------

dat_p_legend <- 
  tibble(y = c(.25, .75),
         label = c(""Median\n1998 - 2007"", ""Median\n2008 - 2017""),
         xend = .85,
         curvature = c(.2, -.2)) %>% 
  mutate(yend = y + c(-.05, .05),
         y2 = y + c(-.02, .02)) 

geom_curve_2 <- function(x, xend, y, y2, yend, label, curvature) {
  dat <- tibble(xend = xend, y2 = y2, yend = yend, curvature = curvature)
  geom_curve(data = dat,
             aes(x = .96, 
                 xend = xend, 
                 y = y2, 
                 yend = yend),
             curvature = curvature,
             colour = ""grey50"",
             arrow = arrow(length = unit(.3, ""mm""),
                           ends = ""last"",
                           type = ""open""),
             size = .18) 
}

p_legend <- 
  dat_p_legend %>% 
  ggplot() +
  geom_text(aes(x = .78, y = yend,
                label = label,
                hjust = .5),
            family = ""courier"",
            size = 4,
            lineheight = .18) +
  geom_link(aes(x = 1, y = .25,
            xend = 1, yend = .75,
            alpha = ..index..,
            size = ..index..),
            colour = blue) +
  pmap(.l = dat_p_legend, .f = geom_curve_2) +
  geom_text(aes(x = 1.015, y = .75),
            label = ""\uf4ba"", family = ""FontAwesome"",
            colour = purple,
            size = 10) +
  scale_size_continuous(range = c(.2, 1)) +
  lims(x = c(.6, 1.2),
       y = c(0, 1)) +
  guides(size = FALSE,
         alpha = FALSE) +
  coord_flip() +
  theme_void()


p_legend

# save plot ---------------------------------------------------------------

png(filename = ""plots/2-25-birds.png"",
    res = 500,
    height = 1946,
    width = 800)
grid.newpage()
grid.rect(gp = gpar(fill = bg_col))
p %>% print(vp = viewport())
p_legend %>% print(vp = viewport(x = .6, y = .9,
                                 width = .5, height = .1))

grid.text(label = str_wrap(""Christmas Bird Counts in the Hamilton Area of Ontario"",
                           width = 40),
          vjust = .5,
          hjust = .5,
          x = .5,
          y = .97, 
          gp = gpar(fontfamily = ""courier"",
                    fontface = ""bold"",
                    fontsize = 18,
                    col = ""#7A82A6"",
                    lineheight = .2))
dev.off()


# else --------------------------------------------------------------------

birds %>% 
  filter(species %>% str_detect(""winged Scoter"")) %>% View()

birds %>% 
  filter(species %>% str_detect(""Northern Pintail"")) %>% View()
","2019-25"
"768",657,"https://github.com/othomantegazza/code-tidytuesday/blob/master/02-10-jobs-gender.Rmd","othomantegazza","code-tidytuesday","02-10-jobs-gender.Rmd","---
title: ""Jobs Gender""
author: ""Otho""
date: ""March 5, 2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
```

Download data:

```{r}
dat_path <- ""data/2-10-jobs-gender.Rdata""
dat_url <- paste0(""https://raw.githubusercontent.com/"",
                 ""rfordatascience/tidytuesday/master/data/"",
                 ""2019/2019-03-05/jobs_gender.csv"")

if(!file.exists(dat_path)) {
  jobs_gender <- read.csv(dat_url)
  
  save(jobs_gender, file = dat_path)
} else {
  load(dat_path)
}
```

show only:

- 2016 (last year),
- Computer, Engineering, and Science (my occupation)

```{r}
to_plot <- 
  jobs_gender %>% 
  # selected categories
  filter(year == 2016,
         major_category == ""Computer, Engineering, and Science"")
```

center palette

```{r}
# needed to center divergent palette
lim <- 
  to_plot$percent_female %>% 
  range() %>% 
  abs() %>% 
  max()
```

and plot

```{r}
p <- 
  to_plot %>% 
  ggplot(aes(x = total_earnings_female,
             y = total_earnings_male,
             colour = percent_female, 
             size = total_workers)) +
  geom_point(alpha = .8) +
  geom_abline(slope = 1,
              intercept = 0,
              colour = ""grey60"",
              size = .5) +
  # scale_x_log10() +
  # scale_y_log10() +
  scale_y_continuous(labels = scales::scientific) +
  scico::scale_color_scico(palette = ""imola"",
                           limits = c(100 - lim, lim)) +
  theme_minimal() +
  labs(title = ""Estimated Median Earnings for Fulltime Workers"",
       subtitle = paste0('In the US in 2016,\n',
                         'for ""Computer, Engineering, and Science"" related jobs.'),
       x = ""Females   [USD]"", 
       y = ""Males   [USD]"",
       size = ""Number of Workers"",
       colour = ""Percent of Females"",
       caption = ""Source: Census Bureau & Bureau of Labor\nPlot by @othomn"") +
  theme(text = element_text(family = ""sans"",
                            colour = ""grey40""), 
        plot.title = element_text(colour = ""#3752C3""))

p
```

Save the plot

```{r, eval = FALSE}
png(filename = ""plots/2-10-jobs-gender.png"",
    height = 1500, width = 2000,
    res = 300)
p %>% print()
dev.off()
```

Other, save data as json

```{r}
to_plot %>% 
  select(total_earnings_female,
         total_earnings_male,
         percent_female, 
         total_workers,
         occupation,
         minor_category) %>% 
  jsonlite::write_json(path = ""data/2-10-jobs-gender.json"")
```

","2019-10"
"769",658,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-18-bird-collisions.R","othomantegazza","code-tidytuesday","2-18-bird-collisions.R","library(tidyverse)
library(lubridate)
library(broom)

# get data ----------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                                   ""master/data/2019/2019-04-30/bird_collisions.csv"")
data_url2 <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                    ""master/data/2019/2019-04-30/mp_light.csv"")

data_file <- ""data/2-18-bird-collisions.Rdata""


if(!file.exists(data_file)) {s
  birds <- readr::read_csv(data_url)
  lights <- readr::read_csv(data_url2)
  
  save(birds, lights, file = data_file)
  
} else {
  load(data_file)
}

# with light score? -------------------------------------------------------

dat <- 
  birds %>% 
  filter(locality == ""MP"") %>% 
  left_join(lights, by = ""date"") %>% 
  filter(complete.cases(.)) %>% 
  mutate(species = paste(genus, species))

# exploratory plot --------------------------------------------------------

p <- 
  dat %>% 
  group_by(date, species, flight_call, light_score) %>%
  count() %>% 
  ggplot(aes(x = light_score,
         y = n)) +
  # geom_point() +
  # geom_smooth(method = ""lm"") +
  stat_bin_2d(binwidth = 1) +
  facet_wrap(facets = ""species"", scales = ""free_y"")


png(filename = ""plots/2-18-bird-collisions-exploratory.png"",
    height = 20,
    width = 40,
    res = 300,
    units = ""in"")
p
dev.off()

# not sure....

p2 <- 
  dat %>% 
  group_by(date, light_score) %>%
  count() %>% # pull(light_score) %>% table()
  ggplot(aes(x = light_score,
             y = n,
             group = light_score)) +
  ggbeeswarm::geom_quasirandom(alpha = .1) 

# tricky tricky dataset, is it a multiple poisson?
p2 + scale_y_continuous(trans = ""log"")

p3 <- 
  dat %>% 
  group_by(species, date, light_score, flight_call) %>%
  count() %>% # pull(light_score) %>% table()
  ggplot(aes(x = light_score,
             y = n,
             group = light_score,
             colour = flight_call)) +
  ggbeeswarm::geom_quasirandom()  +
  facet_wrap(facets = ""species"", scales = ""free_y"")


png(filename = ""plots/2-18-bird-collisions-exploratory2.png"",
    height = 20,
    width = 40,
    res = 300,
    units = ""in"")
p3
dev.off()


# poisson model -----------------------------------------------------------

dat$species %>% unique()

dat_imputed <- 
  dat %>% 
  group_by(date, species) %>% 
  count() %>% 
  spread(key = species, value = n) %>% 
  ungroup() %>% 
  mutate_at(.vars = vars(contains("" "")),
            funs(case_when(is.na(.) ~ as.integer(0), TRUE ~ .))) %>% 
  gather(-date, key = species, value = n) %>% 
  left_join(lights)

# poisson model for each species,
# extract log likelihood
get_loglik <- function(dat_spec) {
  # print(dat_spec)
  if(nrow(dat_spec) < 2) return(NA_real_)
  # to_fit <- 
  #   dat_spec %>% 
  #   group_by(date, light_score) %>%
  #   count() %>% 
  #   ungroup() #%>% 
    # mutate(light_score = light_score %>% as.character() %>% as.factor())
  
  to_fit <- dat_spec %>% ungroup()
  
  # fit <- glm(n ~ light_score - 1, data = to_fit, family = ""poisson"") #%>% summary()
  fit <- glm(n ~ light_score, data = to_fit, family = ""poisson"") #%>% summary()
  
  glance(fit) %>% pull(logLik) %>% as.numeric()
  
}


loglik_df <- 
  dat_imputed %>% 
  split(.$species) %>% 
  map(get_loglik) %>% 
  {tibble(species = names(.),
          loglik = flatten_dbl(.))} %>% 
  arrange(loglik)


# plot top 4 --------------------------------------------------------------

top4 <- 
  loglik_df %>% 
  top_n(4, wt = -loglik) %>% 
  pull(species)

p_top4 <- 
  dat %>% 
  filter(species %in% top4) %>% 
  group_by(species, date, light_score, flight_call) %>%
  count() %>% # pull(light_score) %>% table()
  ggplot(aes(x = light_score,
             y = n,
             # fill = ""#3752C3"",
             group = light_score)) +
  ggbeeswarm::geom_quasirandom(groupOnX = T,
                               alpha = .7,
                               size = .3,
                               fill = ""#3752C3"",
                               shape = 21)  +
  facet_wrap(facets = ""species"") +
  # scale_y_continuous(trans = ""log"") +
  # scale_fill_viridis_c() +
  theme_bw() +
  theme(text = element_text(color = ""grey5""),
        strip.text = element_text(face = ""italic"")) +
  labs(x = ""Windows Light Score"",
       y = ""Number of Strikes per Night"",
       title = ""Do window lights attract birds in collisions with buildings?"",
       subtitle = str_wrap(""Top 4 species that might be sensitive to building's window lights,
                    data from Winger et al., (2019)."", width = 110),
       caption = paste(""plot by @othomn"",
                       str_wrap(""Source: Winger BM, Weeks BC, Farnsworth A, Jones AW, Hennen M,
                                Willard DE (2019) Nocturnal flight-calling behaviour predicts
                                vulnerability to artificial light in migratory birds. Proceedings
                                of the Royal Society B 286(1900):
                                20190364. https://doi.org/10.1098/rspb.2019.0364"",
                                width = 120),
                       sep = ""\n""))

png(filename = ""plots/2-18-bird-collisions.png"",
    height = 7.5,
    width = 7,
    res = 300,
    units = ""in"")
p_top4
dev.off()


# lineplot all species ----------------------------------------------------

p_lines <- 
  dat %>% 
  mutate(species = species %>% factor(levels = loglik_df$species)) %>% 
  group_by(species, date, light_score, flight_call) %>%
  count() %>% # pull(light_score) %>% table()
  group_by(species, light_score, flight_call) %>%
  summarise(n_mean = mean(n)) %>% 
  ggplot(aes(x = light_score,
             y = n_mean,
             colour = flight_call)) +
  geom_point(size = 3) +
  geom_line(size = 4)  +
  facet_wrap(facets = ""species"", ncol = 12) +
  # scale_y_continuous(trans = ""log"") +
  # scale_fill_viridis_c() +
  theme_bw() +
  theme(text = element_text(color = ""grey5""),
        strip.text = element_text(face = ""italic"")) +
  labs(x = ""Windows Light Score"",
       y = ""Number of Strikes per Night"",
       title = ""Do window lights attract birds in collisions with buildings?"",
       subtitle = str_wrap(""Migratory bird species ranked from the most likely to strike a building,
                            when the windows of that building are lighted. After the first two rows,
                            observations are really sparse, so it is hard to draw conclusions on the
                            species below. It might be that the flight caller species are more likely
                            to be influenced and vulnerable to window lights, but most of the species
                            observed are flight callers, so it's not that easy to draw conclusions on that.
                    Source and Data from Winger et al., (2019)."", width = 110),
       caption = paste(""plot by @othomn"",
                       str_wrap(""Source: Winger BM, Weeks BC, Farnsworth A, Jones AW, Hennen M,
                                Willard DE (2019) Nocturnal flight-calling behaviour predicts
                                vulnerability to artificial light in migratory birds. Proceedings
                                of the Royal Society B 286(1900):
                                20190364. https://doi.org/10.1098/rspb.2019.0364"",
                                width = 120),
                       sep = ""\n""))


png(filename = ""plots/2-18-bird-collisions-all.png"",
    height = 11.5,
    width = 15,
    res = 300,
    units = ""in"")
p_lines
dev.off()
","2019-18"
"770",659,"https://github.com/othomantegazza/code-tidytuesday/blob/master/010-biketown.R","othomantegazza","code-tidytuesday","010-biketown.R","Sys.setlocale(""LC_TIME"", ""en_US.UTF8"")
library(ggmap)
library(tidyverse)
library(lubridate)


# Get data ----------------------------------------------------------------

dat <- read_csv(""data/week10_biketown.csv"", 
                # read only the columns that you need
                col_types = cols_only(StartHub = col_character(),
                                      StartLatitude = col_double(),
                                      StartLongitude = col_double(),
                                      StartTime = col_time(format = """"),
                                      StartDate = col_character())) %>%
  filter(complete.cases(.)) %>%
  # This is the only way I managed to get the correct date
  mutate(StartDate = mdy(StartDate)) %>%
  # columns useful later
  mutate(start_day = weekdays(StartDate)) %>%
  mutate(start_hour = hour(StartTime)) %>%
  mutate(start_month = month(StartDate, label = TRUE)) %>%
  mutate(start_month = factor(start_month, ordered = F)) %>%
  # in the end I decided to use both month and year for the GIF
  mutate(start_at = as_factor(paste(start_month,
                                    year(StartDate))))
  

# Get Map -----------------------------------------------------------------

# Map inspired by https://twitter.com/WireMonkey/status/1004790383451176962
portland_path <- ""data/portland_map.Rdata"" 
if(!file.exists(portland_path)) {
# portland <- get_map(""Portland, Oregon"",
  portland <- get_map(location = c(-122.710, 45.49,
                                   -122.615, 45.57),
                    zoom = 13,
                    # source = ""stamen"",
                    maptype = ""toner-lite"")
save(portland, file = portland_path)
} else {
  load(portland_path)
}

# Make gif with months ----------------------------------------------------

# a small transformation necessary because I did not manage to
# make gganimate work on geom_count

dat <- dat %>%
  group_by(StartHub) %>%
  mutate(lat = mean(StartLatitude),
         lon = mean(StartLongitude),
         start_at = start_at) %>%
  group_by(start_at, StartHub, lat, lon) %>%
  summarise(n = n())


# inspired by https://d4tagirl.com/2017/05/how-to-plot-animated-maps-with-gganimate
library(gganimate)
p <- ggmap(portland) +
  geom_point(data = dat,
             aes(x = lon,
                 y = lat,
                 size = n,
                 frame = start_at),
             # alpha = .3,
             colour = ""blue"") +
  ggtitle(""Bikesharing ride starts in Portland"") +
  theme(text = element_text(size = 18))
  
gganimate(p,
          filename = ""plots/portland.gif"",
          ani.width=600, ani.height=700)

","2018-10"
"771",660,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-07-heatmap.R","othomantegazza","code-tidytuesday","2-07-heatmap.R","library(tidyverse)

# Get data ---------------------------------------------------

rd_path <- ""data/2-07-funding.Rdata""
rd_url <- paste0(""https://raw.githubusercontent.com/"",
                 ""rfordatascience/tidytuesday/master/data/"",
                 ""2019/2019-02-12/fed_r_d_spending.csv"")

if(!file.exists(rd_path)) {
  rd <- 
    read_csv(rd_url)
  
  save(rd, file = rd_path)
  
} else {
  load(rd_path)
}

# explore -----------------------------------------------------------------

# Try some cluster --------------------------------------------------------

# hierarchical
rd_wide_01 <- 
  rd_wide %>%
  as.data.frame() %>% 
  rownames_to_column() %>% 
  mutate_if(is.numeric, ~scales::rescale(., to = c(0,1))) %>% 
  column_to_rownames() %>% 
  t()

rd_wide_01 %>%  
  dist() %>%
  hclust() %>%
  plot()

# kmeans
k_clust <- 
  rd_wide_01 %>%
  kmeans(centers = 2)

clust_df <- 
  k_clust$cluster %>% 
  {tibble(department = names(.),
          cluster = .)}

# plot
p <- 
  k_clust %>%
  broom::augment(data = rd_wide_01)  %>% 
  rename_all(~str_sub(., 2, -1)) %>% 
  gather(`1976`:`2017`, key = ""year"", value = ""scaled_funding"") %>% 
  mutate(cluster = cluster %>% as.character()) %>% 
  ggplot(aes(x = year,
             y = rownames,
             fill = scaled_funding)) +
  geom_tile() +
  facet_grid(cluster ~ ., scales = ""free"", space = ""free"") +
  scale_fill_viridis_c(option = ""D"",
                       breaks = c(0, .2, .4, .6, .8, 1),
                       guide = guide_legend(label.position = ""top"", 
                                            keyheight = unit(2, units = ""mm""),
                                            keywidth=unit(15, units = ""mm""), 
                                            nrow = 1,
                                            title.vjust = 0, 
                                            title.theme = element_text(family = ""Arial Narrow"",
                                                                       colour = ""grey40"",
                                                                       size = 12.5,
                                                                       face = ""bold""))) +
  labs(title = ""US Federal Research and Development Spending by Agency"",
       subtitle = str_wrap(""Relative patterns of spending split in two clusters [k-means
                           and hierarchical algorithms have similar results].
                           Fundings for group 1 increase sharply in the
                           late '90s and '00s, fundings for group 2 falls sharply in
                           the '80s an then stabilizes."",
                           width = 90),
       y = """",
       fill = ""Scaled Spending*"", 
       x = ""Year"",
       caption = paste0(""*Absolute spending (USD) is adjusted for inflation, "",
                        ""then every row is scaled between 0 and 1 "",
                        ""to highlight relative patterns.\n"",
                        ""Source: AAAS | Plot by @othomn"")) +
  scale_x_discrete(labels = function(lbs) {
    lbs_num <- lbs %>% as.numeric()
    print(lbs)
    lbs_num <- case_when(lbs_num %% 5 == 0 ~ lbs_num,
                   TRUE ~ 0) %>%
      as.character()
    out <- case_when(lbs_num != ""0"" ~ lbs_num,
                     TRUE ~ """")
    # lbs %>% as.numeric()
    }) +
  theme_minimal() +
  theme(aspect.ratio = 1,
        legend.position = ""top"",
        text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40"",
                            size = 11),
        axis.title = element_text(size = 14, face = ""bold""),
        axis.ticks.x = element_line(colour = ""grey70""),
        plot.title = element_text(colour = ""grey20"",
                                  face = ""bold"",
                                  size = 16),
        # strip.text.y = element_text(angle = 0,
        #                             size = 9,
        #                             hjust = 0),
        strip.background = element_rect(fill = ""grey90"",
                                        colour = ""grey90""),
        plot.subtitle = element_text(size = 12), 
        plot.margin = margin(t = 5, r = 10, b = 0, l = 10,
                             unit = ""mm"")) 


# p                


# save --------------------------------------------------------------------

png(filename = ""plots/2-07-funding-heat.png"",
    height = 1600, width = 2100,
    res = 300)
p %>% print()
dev.off() 

","2019-7"
"772",661,"https://github.com/othomantegazza/code-tidytuesday/blob/master/27-births.R","othomantegazza","code-tidytuesday","27-births.R","# to get english weekdays
Sys.setlocale(""LC_TIME"", ""en_US.UTF8"")

library(tidyverse)
library(lubridate)
library(ggridges)

# load data ---------------------------------------------------------------

dat_path <- ""data/27-birth.Rdata""


if(!file.exists(dat_path)) {
  dat <- 
    read_csv(paste0(""https://raw.githubusercontent.com/"",
                    ""rfordatascience/tidytuesday/master/data/"",
                    ""2018-10-02/us_births_2000-2014.csv"")) %>%
    # date is more useful in one single line
    # stored as date
    mutate(date = paste(year, month, date_of_month,
                        sep = ""-""),
           date = date %>% lubridate::ymd())  %>%
    select(date, births)
  
  save(dat, file = dat_path)
  
} else {
  load(dat_path)
}


# plot --------------------------------------------------------------------

png(filename = ""plots/27-births.png"",
    height = 1500, width = 2400,
    res = 300)
dat %>%
  ggplot(aes(x = births,
             y = date %>% wday(label = TRUE) %>% fct_rev(),
             fill = ..x..)) +
  geom_density_ridges_gradient(alpha = .4, 
                               scale = 2.5, 
                               rel_min_height = .01) +
  scale_fill_viridis_c(option = ""D"") +
  theme_ridges() +
  theme(plot.caption = element_text(colour = ""grey50"")) +
  labs(x = ""Births per day"",
       y = """",
       title = ""Births per Weekday"",
       subtitle = ""Measured in the US | 2000-2014"",
       fill = ""Births \n per day"",
       caption = ""Data: ssa.gov | Source: Fivethirtyeight | Plot by @othomn"")
dev.off()  
","2018-27"
"773",662,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-27-franchise-rev.R","othomantegazza","code-tidytuesday","2-27-franchise-rev.R","library(tidyverse)
library(packcircles) ## easily package circles
library(ggforce)
library(grid)

bg_col <- ""#F6F6DF"" # ""#E4F3F9""

# get data ----------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                   ""tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

data_path <- ""data/2-27-franchise-rev.Rdata""


if(!file.exists(data_path)) {
  fr <- 
    data_url %>% 
    read_csv() %>% 
    distinct()
  
  save(fr, file = data_path)
} else {
  load(data_path)
}

# explore -----------------------------------------------------------------

# biggest revenues from merchandise
fr %>% 
  arrange(desc(revenue))

# revenue vs year
fr %>% 
  ggplot(aes(x = year_created,
             y = revenue,
             colour = revenue_category)) +
  geom_point()


# plot packaged circles ---------------------------------------------------

# Inspired by:
# https://chichacha.netlify.com/2018/12/22/bubble-packed-chart-with-r-using-packcircles-package/

# total revenue by franchise
tot_rev <- 
  fr %>%
  group_by(franchise) %>% 
  summarise(tot_revenue = sum(revenue)) %>% 
  arrange(desc(tot_revenue))

# pack circles
set.seed(93) # use motogp riders to select seeds ;)
packs <- 
  tot_rev %>% 
  pull(tot_revenue) %>% 
  # circleProgressiveLayout()
  circleRepelLayout() %>% 
  .$layout


# and check if you can save circles in a tibble
# with extra variables
packs_df <- 
  bind_cols(tot_rev, packs) %>% 
  select(x, y, radius, franchise) %>% 
  # the column id is needed later to join 
  # the dataset from circleLayoutVertices
  mutate(id = 1:n())


# plot with circlelayout
packs_df %>% 
  circleLayoutVertices(npoints = 200) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_polygon(aes(group=id)) +
  coord_equal() +
  theme_void()
 
# plot with ggforce
# easier
packs_df %>% 
  ggplot() +
  geom_circle(aes(x0 = x,
                  y0 = y, 
                  r = radius),
              fill = ""#CD0A39"",
              colour = ""#CD0A39"") +
  coord_equal()

# inner circles -----------------------------------------------------------

# 1. rank categories and estimate revenue ratios --------------------------

fr_ranked <- 
  fr %>% 
  group_by(franchise) %>%
  arrange(franchise, desc(revenue)) %>% 
  mutate(rank = 1:n(),
         rev_tot = sum(revenue),
         rev_ratio = revenue/rev_tot) %>% 
  arrange(franchise, revenue) %>% 
  # cummulative revenue from lowest
  mutate(cumul_ratio = cumsum(rev_ratio))

# 2. set colors -----------------------------------------------------------
colorz <-
  c(""#D9F6FF"", # ""#EAEA9F"", 
    ""#E97E00"",""#E0E0D2"",""#5867A6"", # ""#44D4FF"", ""#E2CD92"",
    ""#27A6D3"", ""#1E2D6C"",""#CD0A62"",""#CB7BA5"") %>%
  set_names(nm = fr %>% pull(revenue_category) %>% unique())

# colorz <- 
#   Redmonder::redmonder.pal(n = 8, name = ""qMSOPu2"")[2:8] %>% 
#   c(""#27A6D3"") %>% 
#   set_names(nm = fr %>% pull(revenue_category) %>% unique())


# colorz <-
#   c(""#D81B60"",""#8E24AA"",""#5E35B1"",""#3949AB"",""#1E88E5"",""#039BE5"",""#00ACC1"",""#00897B"") %>%
#   set_names(nm = fr %>% pull(revenue_category) %>% unique())

# 3. try plot first rank --------------------------------------------
#  with ggforce geom_circle

pack1 <- 
  packs_df %>% 
  left_join(fr_ranked %>% filter(rank == 1), by = ""franchise"")

p <- 
  pack1 %>% 
  ggplot() +
  geom_circle(aes(x0 = x,
                  y0 = y, 
                  r = radius,
                  fill = revenue_category,
                  colour = revenue_category),
              size = .1) +
  scale_fill_manual(values = colorz) +
  scale_colour_manual(values = colorz) +
  coord_equal() +
  theme_void() +
  theme(legend.position = ""right"",
        legend.justification = ""center"") +
  guides(colour = FALSE,
         fill = FALSE) 

p

# 4. make a list of ranks and loop over it -----------------------------------

get_rank_circles <- function(rank_in = 2) {
  packs_n <- 
    packs_df %>% 
    left_join(fr_ranked %>% filter(rank == rank_in), by = ""franchise"") %>% 
    # scale radius on proportion to cumulative revenue
    mutate(radius = radius*cumul_ratio)
}

circles_dfs <- map(2:max(fr_ranked$rank), get_rank_circles)


for(i in circles_dfs) {
  p <-
    p +
    geom_circle(data = i,
                aes(x0 = x,
                    y0 = y, 
                    r = radius,
                    fill = revenue_category,
                    colour = revenue_category),
                size = .1)
} 


# 5. make legend maually --------------------------------------------------

leg <- 
  tibble(y = rep(c(1,2), each = 4),
         x = rep(1:4, times = 2),
         fill = colorz %>% names(),
         r = .1) %>% 
  ggplot() +
  geom_text(aes(x = x, y = y - .26,
                label = str_wrap(fill, 15)),
            lineheight = .9,
            size = 1.2,
            vjust = 1, family = ""courier"", fontface = ""bold"") +
  geom_circle(aes(x0 = x,
                  y0 = y,
                  fill = fill,
                  colour = fill,
                  r = r)) +
  guides(fill = FALSE, colour = FALSE) +
  scale_fill_manual(values = colorz) +
  scale_colour_manual(values = colorz) +
  coord_equal() +
  theme_void() +
  lims(y = c(0.5, 2.3),
       x = c(.5, 4.5))

leg

# 6. save plot ------------------------------------------------------------



png(filename = ""plots/2-27-franchise-rev.png"",
    height = 1600,
    width = 2700,
    res = 400)
grid.newpage()
grid.rect(gp = gpar(fill = bg_col)) # background
p %>% print(vp = viewport(x = .42, y = .5)) # plot
leg %>% print(vp = viewport(x = .83, y = .16, width = .26)) # legend
grid.text(label = ""Media Franchise Revenues"", # title
          x = .98,
          y = .3,
          hjust = 1,
          gp = gpar(fontfamily = ""courier"",
                    col = ""#100089"",
                    fontsize = 10.5,
                    fontface = ""bold""))
grid.text(label = ""Data by Wikipedia | Plot by @othomn"", # caption
          x = .02, y = .03, 
          hjust = 0,
          gp = gpar(fontfamily = ""courier"",
                    col = ""#AA2255"",
                    # fontface = ""bold"",
                    fontsize = 4))
dev.off()
","2019-27"
"774",663,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","02-09-train-delays.Rmd","---
output: html_document
editor_options: 
  chunk_output_type: console
---

# get train data

```{r}
library(tidyverse)

small_path <- ""data/2-09-train-delays-small.Rdata""
small_url <- paste0(""https://raw.githubusercontent.com/"",
                 ""rfordatascience/tidytuesday/master/data/"",
                 ""2019/2019-02-26/small_trains.csv"")

if(!file.exists(small_path)) {
  train_small <- 
    read_csv(small_url)
  
  save(train_small, file = small_path)
  
} else {
  load(small_path)
}
```

# remove negative delays

```{r}

train_small_0 <- 
  train_small %>% 
  mutate(avg_delay_all_arriving = 
           case_when(avg_delay_all_arriving < 0 ~ 0,
                     TRUE ~ avg_delay_all_arriving))

train_small_0 %>% 
  ggplot(aes(x = journey_time_avg,
             y = avg_delay_all_arriving)) +
  geom_point() +
  geom_smooth()
```

# Station coordinates

```{r}
nodes <- 
  train_small_0 %>% 
  select(station = departure_station) %>% 
  distinct()


to_query <- 
  nodes %>%
  mutate(station = station %>%
           str_to_lower() %>%
           str_replace_all("" "", ""-""))

```

## get coordinates from sncf


```{r}
library(sf)
# data from sncf

sncf_link <- ""https://ressources.data.sncf.com/explore/dataset/liste-des-gares/download/?format=shp&timezone=Europe/Berlin""

station_path <- ""data/2-09-stations""

if(!file.exists(station_path)) {
  
  temp <- tempfile()

  sncf_link %>% 
    download.file(destfile = temp)
  
  temp %>% unzip(exdir = station_path)
  rm(temp)
}

stations <- 
  read_sf(station_path) %>% 
  mutate(station = libelle_gar %>% 
           iconv(from=""UTF-8"",to=""ASCII//TRANSLIT"") %>% 
            str_to_lower())
```

check them

```{r}
library(leaflet)

# this is big
# leaflet() %>% 
#   addTiles() %>% 
#   addMarkers(data = stations$geometry)
```


## merge 1st

```{r}
station_coords <- 
  to_query %>% left_join(stations, by = ""station"") %>% 
  filter(!duplicated(libelle_gar))

leaflet() %>% 
  addTiles() %>% 
  addMarkers(data = station_coords$geometry)

to_query$station[!to_query$station %in% stations$libelle_gar]

stations$libelle_gar[stations$libelle_gar %>% str_detect(""creusot"")]

dict <- c('paris-lyon' = ""paris-gare-de-lyon"",
          montpellier = ""montpellier-st-roch"",
          'la rochelle-ville' = ""la rochelle-ville"",
          lille = ""lille-europe"",
          'angers-saint-laud' = ""angers-st-laud"",
          'macon-loche' = ""macon-loche-tgv"",
          nancy = ""nancy-ville"",
          'valence-alixan-tgv' = ""valence-alixan-tgv"",
          ""saint-etienne-chateaucreux"" = ""st-etienne-chateaucreux"",
          metz = ""metz-ville"",
          ""le-mans"" = ""le mans"",
          ""strasbourg"" = ""strasbourg-ville"",
          ""bellegarde-(ain)"" =""bellegarde"", 
          ""le-creusot-montceau-montchanin"" = ""le creusot-montceau-montchanin"")
```


```{r}
train_small %>% 
  pull(departure_station) %>% 
  unique()

train_2017 <- 
  train_small %>% 
  filter(year == 2017)

nodes <- 
  train_2017 %>% 
  select(station = departure_station) %>% 
  distinct()

edges <- 
  train_2017 %>% 
  filter(month == 1) %>% 
  select(from = departure_station,
         to = arrival_station)
         #num_late_at_departure)
```

```{r}
library(tidygraph)
library(ggraph)

g <- tbl_graph(nodes = nodes, edges = edges)

g %>% 
  ggraph() +
  geom_edge_link() +
  geom_node_point()
```

```{r}
to_query <- 
  nodes %>%
  mutate(station = station %>%
           str_to_title() %>%
           str_replace_all("" "", ""-""))

coord_by_name <- function(st_name) {
  opq(c(-5.054, 42.066, 8.438,  51.262)) %>% 
  add_osm_feature(key = ""railway"",
                  value = ""station"") %>%
  # add_osm_feature(key = ""railway"", value = ""stop_name"") %>%
  # add_osm_feature(key = ""official_name"", value = ""CLICHY LEVALLOIS"") %>% 
  add_osm_feature(key = ""SNCF:stop_name"",
                  value = st_name) %>%
  osmdata_sf()
}

coord_by_name(""Paris-Nord"")

to_query$station %>% 
  map(coord_by_name)
```

```{r}
full_data <- 
  read_delim(""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-02-26/regularite-mensuelle-tgv-aqst.csv?raw=true"", delim = "";"")

full_data$`Gare de dpart`


```

","2019-9"
"775",664,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-02-tv-golden-age.R","library(tidyverse)
library(lubridate)
library(rlang)
library(magrittr)
library(broom)


# Set parameters ----------------------------------------------------------

light_orange <- ""orange""
dark_orange <- ""#E97E00""
title_blue <- ""#5F3BBA""
highlight_blue <- ""#46AEF9""

# Set theme and functions -------------------------------------------------

theme_set(theme_gray() +
            theme(legend.position = ""right"",
                  text = element_text(family = ""Arial Narrow"",
                                      colour = ""grey40"",
                                      size = 14),
                  plot.title = element_text(colour = title_blue, # or  ""#582F69""
                                            face = ""bold"",
                                            size = 27,
                                            family = ""Arial Narrow""),
                  plot.subtitle = element_text(colour = ""grey40"",
                                               face = ""bold"",
                                               size = 12),
                  aspect.ratio = .67))


save_plot <- function(p, file) 
{
  on.exit(
    dev.off()
  )
  png(filename = file,
      height = 1500, width = 2200,
      res = 300)
  p %>% print()
}

# Get Data ----------------------------------------------------------------


dat_path <- ""data/2-02-tv.Rdata""
dat_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""2019/2019-01-08/IMDb_Economist_tv_ratings.csv"")


if(!file.exists(dat_path)) {
  dat <- 
    read_csv(dat_url)
  
  save(dat, file = dat_path)
  
} else {
  load(dat_path)
}


# Basic plot, then add layer ----------------------------------------------

dat_drama <- 
  dat %>% 
  filter(genres %>% str_detect(""Drama""))

p <- 
  dat_drama %>% 
  ggplot(aes(x = date, y = av_rating, colour = share)) +
  geom_point(alpha = .8, size = 2) +
  scale_color_viridis_c(trans = ""log10"",
                        breaks = c(.01, .1, 1, 10, 50),
                        # limits = c(NA, 100)
                        guide = guide_colourbar(barheight = 12)) +
  labs(x = ""Original Airing Date"",
       y = ""Average Rating"",
       colour = str_wrap(""Share of yearly votes"", width = 12),
       caption = ""Data: IMDB | Plot by @othomn"")


save_plot(p = p +
            labs(title = ""Series with high rating get more votes""),
          file = ""plots/2-02-1-tv.png"")

# How to describe it?
# 1. Is it normally distributed?
# 2. There is this issue with low share ratings :
#   - https://www.evanmiller.org/how-not-to-sort-by-average-rating.html
#   - https://redditblog.com/2009/10/15/reddits-new-comment-sorting-system/
# 3. For best series share is higher, (they get more attention?)
#   - It requires a slump to get high share and bad rating

#  Most of the high share ratings are above the regression line -----------

fit <- 
  dat_drama %>% 
  {lm(av_rating ~ poly(date, 3), data = .)}

glance(fit)
tidy(fit)
fit %>% predict(newdata = dat_drama)

p_lm <- 
  p +
  geom_smooth(method = ""lm"",
              formula = y ~ poly(x, 3),
              colour = light_orange)

save_plot(p = p_lm +
            annotate(geom = ""label"",
                     x = as_date(""2013-10-01""), y = 8.5,
                     label = ""y ~ poly(x, 3)"",
                     fill = dark_orange,
                     colour = ""white"",
                     size = 4) +
            labs(title = ""Do ratings form trend over time? Not sure""),
          file = ""plots/2-02-2-tv.png"")

# Is Star Trek DS9 the only one below? ------------------------------------

# base plot for highlightings

p_labs <- 
  p_lm +
  ggrepel::geom_label_repel(data = . %>% 
                              mutate(pred_lm = fit %>% predict(newdata = dat_drama),
                                     year = year(date)) %>% 
                              group_by(year) %>% 
                              top_n(n = 1, wt = share) %>% 
                              # filter(av_rating < 8),
                              filter(av_rating < pred_lm),
                           aes(label = paste0(title,
                                              "", season "",
                                             seasonNumber) %>%
                                 str_wrap(width = 20)),
                           fontface = ""bold"",
                           fill = dark_orange,
                           angle = 90,
                           colour = ""white"",
                           segment.colour = dark_orange,
                           box.padding = 0,
                           ylim = c(NA, 6)) + 
  geom_point(data = . %>% 
               mutate(year = year(date)) %>% 
               group_by(year) %>% 
               top_n(n = 1, wt = share),
             shape = 21,
             colour = title_blue,
             fill = light_orange,
             stroke = 1.6,
             size = 3) 

  
# p_labs

save_plot(p = p_labs +
            labs(title = str_wrap(""Two Series have best yearly share of
                 votes but low ratings"")) +
            theme(plot.title = element_text(size = 21)), 
          file = ""plots/2-02-3-tv.png"")


","2019-2"
"776",665,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-03-space-launches.R","library(tidyverse)

# Get Data ----------------------------------------------------------------


dat_path <- ""data/2-03-space-launces.Rdata""
dat_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""2019/2019-01-15/launches.csv"")


if(!file.exists(dat_path)) {
  dat <- 
    read_csv(dat_url)
  
  save(dat, file = dat_path)
  
} else {
  load(dat_path)
}

# also agencies data

agencies_path <- ""data/2-03-agencies.Rdata""
agencies_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""/2019/2019-01-15/agencies.csv"")


if(!file.exists(agencies_path)) {
  dat_agencies <- 
    read_csv(agencies_url)
  
  save(dat_agencies, file = agencies_path)
  
} else {
  load(agencies_path)
}


# Explore -----------------------------------------------------------------

dat %>% View()

dat %>% 
  filter(state_code == ""US"") %>% 
  ggplot(aes(x = launch_year,
             fill = agency_type)) +
  geom_bar()
","2019-3"
"777",666,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-04-prison.Rmd","---
title: ""An analysis of Vera institute's prison dataset""
subtitle: ""Tidytuesday week 4""
author: ""Otho Mantegazza""
date: 2019-01-25
editor_options: 
  chunk_output_type: console
---

# Intro

This is week 4 of the social data project TidyTuesday. In this week, we explore the incarceration trend dataset. This dataset stores US demographic and incarceration data by county and by gender / ethnic profile for the last 30 years.

The incarceration trend dataset is kindly provided by the [Vera Institute](https://www.vera.org/) on their [Github page](https://github.com/vera-institute/incarceration_trends). Analyzing this dataset aims at remembering of the social injustices still present in our world on Martin Luther King Jr. Day.

For this analysis, I want to practice modelling rather than data wrangling and tidying, so I decided to start from the file `prison_population.csv`, from [Tidytuesday's github page](https://github.com/rfordatascience/tidytuesday) which has already been tidied by Thomas Mock.

```{r, message = FALSE, warning = FALSE}
# Setup -------------------------------------------------------------------
library(tidyverse)
theme_set(theme_bw())
```

```{r}
# Get Data ----------------------------------------------------------------

# download data directly from github and store them as Rdata locally.

dat_path <- ""data/2-04-prison.Rdata""
dat_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""/2019/2019-01-22/prison_population.csv"")

if(!file.exists(dat_path)) {
  
  dat <- read_csv(dat_url)
  save(dat, file = dat_path)
  
} else {
  load(dat_path)
}
```

# A strategy for missing values [NA]


Collecting such detailed data is a massive effort, and some missing values are inevitable. For statistical modeling we must select a clear and explicit strategy to deal with measurements that are mixed with missing values.

The dataset `prison_population.csv` has many missing values stored as `NA` in the column `prison_population`. That column counts incarcerated individuals, and it is our main interest together with the `population` columns that stores a full population census.

```{r}
# how many NAs in the variable prison_population?
dat$prison_population %>% is.na() %>% sum()
```

## Ignore the NAs

A very basic strategy, could be just to ignore the NAs. We can try to plot a quick summary of prison population by state, using `sum(na.rm = TRUE)` to ignore NAs. But this strategy, introduce strange fluctuations in the measurements, because randomly occurring NAs increase or decrease the prison population counts with patterns that are not reflected in reality.

```{r, fig.height=6}
# Try sum(na.rm = TRUE) --------------------------------------------------------

# summarize the data by state and year
dat_state <- 
  dat %>% 
  filter(pop_category == ""Total"",
         year > 1982, 
         year != 2016) %>% 
  group_by(year, state) %>% 
  summarise(prison_population = prison_population %>% sum(na.rm = TRUE),
            population = population %>% sum(na.rm = TRUE)) 

# plot them as an heatmap
dat_state %>% 
  ggplot(aes(x = year,
             y = state,
             fill = prison_population)) +
  geom_raster() +
  scale_fill_viridis_c(trans = ""log10"", breaks = 10^(1:5)) +
  # Do not add padding around x limits
  scale_x_continuous(expand = expand_scale(0))
```

We can hypothesize that the sharp changes in the `prison_population` variable are caused by missing data, rather than by real changes in the population of prisons.

## A more solid strategy

As a more solid strategy to deal with missing values, we can keep only measurements from counties in which the variable `prison_population` never has missing values.

For example, if in a county we did not count the prison population for two years, and we thus have missing values, when we sum the data for those county to the others ignoring NAs, we would notice a sharp increase and decrease in prison population, that is not reflected in reality.

It is better to remove measurements from that county altogether. In this way we may lose some measurements. But the time series that we retain reflects better the real trends in prison population.

(If we needed to retain more measurements, we could have tried to impute missing values, but in this case we don't need to. Because we should have already enough measurements to make insightful observations).

We can use `dplyr` to create the new variable `has_na` that is `TRUE` if any measurement from that county contains missing values. And then we can use to filter out those observations.

```{r}
dat_clean <- 
  dat %>% 
  filter(pop_category == ""Total"",
         # to include more counties, I have reduced the time span
         year >= 1990,
         year != 2016) %>% 
  group_by(state, county_name) %>% 
  mutate(has_na = anyNA(prison_population)) %>% 
  filter(!has_na) %>% 
  ungroup()
```

Let's do again the heatmap, but after we have removed counties with missing values.

```{r}
dat_clean %>% 
  # first summarize data by state and year
  group_by(year, state) %>% 
  summarise(prison_population = sum(prison_population),
            population = sum(population)) %>% 
  # then plot the heatmap
  ggplot(aes(x = year,
             y = state,
             fill = prison_population)) +
  geom_raster() +
  scale_fill_viridis_c(
    # trans = ""log10"", breaks = 10^(1:5)
    ) +
  # Do not add padding around x limits
  scale_x_continuous(expand = expand_scale(0))
```

(If you compare this heatmap with the one before, you'll notice that here the colour scale is mapped to a linear scale, rather then a log scale, because in this case the differences are so smooth that they get imperceptible in log scale.)

Now the progression through time is much smoother.

As you notice, I have restricted the time span from 1990 to 2015 to retain more counties. Nevertheless, we have lost information about many states. 

```{r}
# Which State is missing in the clean dataset?
setdiff(dat$state, dat_clean$state)
```

We can anyway go on, apply this system to remove NA to the observations split by gender and ethnic categories, and test on that dataset which category is overrepresented in prison population.

# Which Category is Overrepresented?

First, we can clean from missing values the observations that are split by categories.

```{r}
# Try with more details ---------------------------------------------------
by_cat <- 
  dat %>% 
  filter(
    pop_category != ""Other"",
    year >= 1990,
    year != 2016) %>% 
  group_by(state, county_name, pop_category) %>% 
  mutate(has_na = anyNA(prison_population)) %>% 
  filter(!has_na) %>% 
  ungroup()
```

## Exploratory plot

Then we can produce some plots to explore how the various categories behave. In this case I've found this boxplot most helpful.

```{r fig.height=7}
by_cat %>% 
  mutate(ratio = prison_population/population) %>% 
  ggplot(aes(x = year,
             y = ratio,
             group = year)) +
  geom_boxplot() +
  scale_y_log10() +
  facet_grid(pop_category ~ .,
             scales = ""free"",
             # Wrap the text in the strip labels
             labeller = label_wrap_gen(width = 10))
```

Above, we can observe that:

- The ratio of African american [Black] incarcerated is higher than any other category, with median around 0.02.
- The ratio of males incarcerated is very high, with median going from 0.01 to 0.02.
- The ratio of `Latino` and `Native American` incarcerated are also high.

Just to be sure, we can also reproduce the same heatmap as above on all categories.

```{r, fig.width=8}
by_cat %>% 
  mutate(ratio = prison_population/population) %>% 
  ggplot(aes(x = year,
             y = state,
             fill = prison_population)) +
  geom_raster() +
  facet_grid(. ~ pop_category) +
  scale_fill_viridis_c(trans = ""log10"", breaks = 10^c(1:5)) +
  # because of facetting, the x axis is very tight
  theme(axis.text.x = element_text(angle = 90, vjust = .5))
```

We can see that data are still sparse, but importantly, for each year/category we have sets of paired observation of `prison_population` and `population` without missing values.

## Hypergeometric test

We can model this data with an [hypergeometric distribution](https://stattrek.com/probability-distributions/hypergeometric.aspx), and use it to test if a category of gender or ethnicity is overrepresented. 

First, we can (again) summarize observation by state and year (we don't want to test over-representation for every county).

```{r}
by_cat_sum <- 
  by_cat %>% 
  filter(pop_category != ""Other"") %>% 
  group_by(pop_category, year) %>% 
  summarise(population = sum(population),
            prison_population = sum(prison_population)) %>% 
  ungroup()
```

Then we have to prepare the data for the function `phyper()` that will estimate the p-value of each observation under the hypergeometric distribution.

As state by its help page, the `phyper()` function requires these parameters:

> - q: vector of quantiles representing the number of white balls drawn without replacement from an urn which contains both black and white balls.
- m: the number of white balls in the urn.
- n: the number of black balls in the urn.
- k: the number of balls drawn from the urn.

>> From the help pages of the [stats package](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/00Index.html)

We can reshape the dataset and place each of those values in a separate column. If we call each column as the appropriate parameter of the function `phyper()`, then we loop this function on each row of the dataset with [`pmap()`](https://r4ds.had.co.nz/iteration.html#mapping-over-multiple-arguments) and match all arguments automatically by name.

```{r}
# prepare a table for hyopergeometric test:
# get category total next to each other category

by_cat_tot <- 
  by_cat_sum %>% 
  filter(pop_category == ""Total"") %>% 
  rename_all(funs(paste0(., ""_total"")))

by_cat_hyp <- 
  by_cat_sum %>% 
  left_join(by_cat_tot, by = c(""year"" = ""year_total""))

# apply phyper() using pmap

# Define phyper() wrapper that contains ""...""
# So that it can be used in pmap with extra variables
# Test enrichment
# inspired from
# https://github.com/GuangchuangYu/DOSE/blob/master/R/enricher_internal.R

phyper2 <- function(q, m, n, k, ...) {
  phyper(q, m, n, k, log.p = TRUE, lower.tail = FALSE)
  }

by_cat_hyp <- 
  by_cat_hyp %>% 
  # rename arguments for dhyper
  transmute(year = year,
            pop_category = pop_category,
            q = prison_population, # white balls drawn
            # x = prison_population, # white balls drawn
            m = population, # white balls in the urn
            n = population_total - population, # black balls in the urn
            k = prison_population_total) # balls drawn from the urn
```

This approach was inspired by the field of genomics and transcriptomics, in which the hypergeometric test is often used to test the if structural or functional categories of genes are enriched in a given set. Some code here is inspired by [this bioconductor package](https://github.com/GuangchuangYu/DOSE/blob/master/R/enricher_internal.R)

Then we can use [pmap()](https://r4ds.had.co.nz/iteration.html#mapping-over-multiple-arguments) to run an hypergeometric test on each row.

```{r}
# apply dhyper() to every row
by_cat_hyp <- 
  by_cat_hyp %>% 
  mutate(log_p = pmap(., .f = phyper2) %>% purrr::flatten_dbl())
```

And eventually we can plot the log p-values with inverse sign, to make the plot more intuitive.

```{r}
p <- 
  by_cat_hyp %>% 
  # I could have filtered out this earlier,
  # but it served as practical control
  filter(pop_category != ""Total"") %>% 
  # filter categories not overepresented
  filter(log_p < -100) %>% 
  ggplot(aes(x = year,
             y = -log_p)) +
  geom_bar(stat = ""identity"",
           fill = ""orange"",
           colour = ""black"") +
  facet_grid(pop_category ~ .) 

p %>% print()
```

We can see that the categories ""Black"" and ""Male"" are far from what we would expect by chance, and, thus, members of that categories are overrepresented.

# Adjust plot for publication

We can adjust the plot labels for publication. Adding clearer labels, a title, and making small adjustments to the layout.

```{r}
p2 <- 
  p +
  labs(title = ""Categories that are Overrepresented in US Prisons"",
       subtitle = str_wrap(""A quick exploratory analysis of 
                           the VERA dataset, using a hypergeometric
                           test to estimate which category is more 
                           represented than expected""), width = 27,
       y = ""-log(p-value)"",
       x = ""Year"",
       caption = ""Source: www.vera.org | Plot by @othomn"") +
  theme(text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40"",
                            size = 11),
        axis.title = element_text(size = 14),
        strip.text = element_text(colour = ""grey20"",
                                  size = 14),
        plot.title = element_text(colour = ""grey20"",
                                  face = ""bold"",
                                  size = 18),
        plot.subtitle = element_text(face = ""bold"",
                                     size = 12),
        aspect.ratio = .2,   
        plot.margin = margin(t = 10, r = 10, b = 0, l = 3,
                             unit = ""mm""))

p2 %>% print()
```

```{r, echo = FALSE, eval = FALSE}
# save as png
png(filename = ""plots/2-04-prison.png"",
    height = 1400, width = 2300,
    res = 300)
p2 %>% print()
dev.off() 
```


# Interpretation and closing remarks

This is a quick analysis and my take on [Tidytuesday week 4 dataset](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-22).

My analysis shows an issue that is widely known, that African American are overrepresented in US prisons. But this just a statistical analysis, which could be helpful or misleading if not contextualized. If you have any suggestion on how to improve my analysis, please contact me.

Unfortunately, in here I don't contextualize and I don't discuss this results. If you are interested in this topic, if you feel engaged by these results, and you want to know more. If you want to interpret this data, you'll have to contextualize this results. To do so, you'll have to read about history and societal issues! And if you are interested and you want to form an opinion, please, please, please, do read, explore and contextualize.

Many thanks to Thomas Mock for bringing the work of the Vera institute to our attention on Martin Luther King Jr. Day.","2019-4"
"778",667,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-05-milk-waterfall.R","library(tidyverse)
library(scico)
library(tibbletime)

# Get data Milk products ---------------------------------------------------

dat_path <- ""data/2-05-milk-product-facts.Rdata""
dat_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""2019/2019-01-29/milk_products_facts.csv"")

if(!file.exists(dat_path)) {
  dat_milkprods <- 
    read_csv(dat_url)
  
  save(dat_milkprods, file = dat_path)
  
} else {
  load(dat_path)
}


# Percent ---------------------------------------------------------

# roll over tibbles
roll_percent <- rollify(.f = function(n) (n[2] - n[1])*100/n[1], 2)
roll_prev <- rollify(.f = function(n) n[1], 2)

dat <- 
  dat_milkprods %>%
  select(year, butter) %>% 
  mutate(percent = roll_percent(butter),
         prev_year = roll_prev(butter)) %>% 
  filter(complete.cases(.))


# plot --------------------------------------------------------------------

# needed to center divergent palette
lim <- 
  dat$percent %>% 
  range() %>% 
  abs() %>% 
  max()

half_rect <- .3

p <- 
  dat %>% 
  mutate(yend = butter + (percent/10)) %>%
  ggplot(aes(x = year,
             y = butter)) +
  annotate(geom = ""rect"",
           xmin = 2008, xmax = 2010,
           ymin = -Inf, ymax = Inf,
           fill = ""grey80"", alpha = .5) +
  annotate(geom = ""text"",
           x = 2009, y = 4.2,
           label = ""2008\nEconomic Crisis?"",
           family = ""Arial Narrow"",
           colour = ""grey40"",
           size = 3, fontface = ""bold"") +
  # geom_line(color = ""grey80"") +
  geom_rect(aes(xmin = year - half_rect,
                xmax = year + half_rect,
                ymin = prev_year,
                ymax = butter,
                colour = percent,
                fill = percent), size = 0) +
  geom_segment(aes(x = year - half_rect,
                   xend = ..x.. + 1 + half_rect*2,
                   yend = ..y..),
               colour = ""grey40"", size = 1) +
  geom_text(aes(y = case_when(percent > 0 ~ butter + .05,
                              TRUE ~ butter - .05),
                label = percent %>%
                  round() %>% paste0(""%""),
                colour = percent),
            size = 2.7) +
  scale_colour_scico(palette = ""roma"",
                     direction = 1,
                     limits = c(-lim, lim),
                     guide = FALSE) +
  scale_fill_scico(palette = ""roma"",
                     direction = 1,
                     limits = c(-lim, lim),
                     guide = FALSE) +
  guides(colour = element_blank()) +
  labs(title = ""Fluctuations in Butter Consumptions"",
       subtitle = str_wrap(""In the US between 1975 - 2017,
                           with weight of sold butter in lbs
                           and its percent change compared to
                           the previous year.""),
       y = ""Sold Butter in lbs per person"",
       x = ""Year"",
       caption = ""Data: USDA | Plot by @othomn"") +
  theme_minimal() +
  theme(text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40"",
                            size = 11),
        axis.title = element_text(size = 14),
        plot.title = element_text(colour = ""grey20"",
                                  face = ""bold"",
                                  size = 18),
        plot.subtitle = element_text(face = ""bold"",
                                     size = 12),
        aspect.ratio = .6,   
        plot.margin = margin(t = 10, r = 15, b = 0, l = 10,
                             unit = ""mm""))

p
# Save --------------------------------------------------------------------

png(filename = ""plots/2-05-milk-waterfall.png"",
    height = 1600, width = 2100,
    res = 300)
p %>% print()
dev.off() 

","2019-5"
"779",668,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-07-funding-lines.R","library(tidyverse)
library(tibbletime)

# Get data ---------------------------------------------------

rd_path <- ""data/2-07-funding.Rdata""
rd_url <- paste0(""https://raw.githubusercontent.com/"",
                 ""rfordatascience/tidytuesday/master/data/"",
                 ""2019/2019-02-12/fed_r_d_spending.csv"")

if(!file.exists(rd_path)) {
  rd <- 
    read_csv(rd_url)
  
  save(rd, file = rd_path)
  
} else {
  load(rd_path)
}

# explore -----------------------------------------------------------------

rd_wide <- 
  rd %>% 
  select(department, year, rd_budget) %>% 
  tidyr::spread(key = year,
                value = rd_budget) %>%
  column_to_rownames(""department"") %>%
  t()

# Try some cluster --------------------------------------------------------

# hierarchical
rd_wide_01 <- 
  rd_wide %>%
  as.data.frame() %>% 
  rownames_to_column() %>% 
  mutate_if(is.numeric, ~scales::rescale(., to = c(0,1))) %>%
  # mutate_if(is.numeric, scale)
  column_to_rownames() %>% 
  t()


rd_hclust <- 
  rd_wide_01 %>%  
  dist() %>%
  hclust() 

rd_hclust %>% plot()

# ordered factor

# kmeans
k_clust <- 
  rd_wide_01 %>%
  kmeans(centers = 2)

clust_df <- 
  k_clust$cluster %>% 
  {tibble(department = names(.),
          cluster = .)}

# Tidy clusters
clust_tidy <- 
  k_clust %>%
  broom::augment(data = rd_wide_01)  %>% 
  rename_all(~str_sub(., 2, -1)) %>% 
  gather(`1976`:`2017`,
         key = ""year"",
         value = ""scaled_funding"") %>% 
  rename(agency = ""rownames"") %>% 
  mutate(cluster = cluster %>%
           as.character()) %>% 
  mutate(agency = agency %>% 
           factor(levels = rd_hclust$labels[rd_hclust$order]))
  

# plot --------------------------------------------------------------------

pwidth <- 5
lwidth <- .5
scfill <- 
  scale_fill_viridis_c(
    option = ""D"",
    breaks = c(0, .2, .4, .6, .8, 1),
    guide = guide_legend(
      label.position = ""top"", 
      keyheight = unit(2, units = ""mm""),
      keywidth=unit(15, units = ""mm""), 
      nrow = 1,
      title.vjust = 0, 
      title.theme = element_text(family = ""Arial Narrow"",
                                 colour = ""grey40"",
                                 size = 12.5,
                                 face = ""bold""))
  ) 


p <- 
  clust_tidy %>% 
  ggplot(aes(x = year,
             y = scaled_funding,
             fill = scaled_funding)) +
  geom_bar(stat = ""identity"", width = .3) +
  geom_hline(yintercept = 0, colour = ""grey80"") +
  geom_hline(yintercept = .2, colour = ""white"", size = lwidth) +
  geom_hline(yintercept = .4, colour = ""white"", size = lwidth) +
  geom_hline(yintercept = .6, colour = ""white"", size = lwidth) +
  geom_hline(yintercept = .8, colour = ""white"", size = lwidth) +
  facet_grid(agency ~ .) +
  theme_minimal() + 
  scale_fill_viridis_c(
    option = ""D"",
    breaks = c(0, .2, .4, .6, .8, 1),
    guide = guide_legend(
      label.position = ""top"", 
      keyheight = unit(2, units = ""mm""),
      keywidth=unit(8, units = ""mm""), 
      nrow = 1,
      title.vjust = 0, 
      title.theme = element_text(family = ""Arial Narrow"",
                                 colour = ""grey40"",
                                 size = 12.5,
                                 face = ""bold""))
  ) + 
  theme(axis.text.y = element_blank(),
        panel.grid = element_blank(),
        legend.position = ""top"")

svglite::svglite(file = 'plots/2-07-funding-lines.svg',
                 width = pwidth)
p %>% print
dev.off()


# plot 2 ------------------------------------------------------------------

p2 <- 
  clust_tidy %>% 
  ggplot(aes(x = year,
             y = scaled_funding,
             fill = scaled_funding,
             colour = scaled_funding)) +
  geom_point(size = .5) +
  geom_bar(stat = ""identity"", width = .1) +
  geom_hline(yintercept = 0, colour = ""grey80"") +
  facet_grid(agency ~ .) +
  theme_minimal() + 
  scfill + 
  scale_colour_viridis_c(guide = FALSE) + 
  theme(axis.text.y = element_blank(),
        panel.grid = element_blank(),
        legend.position = ""top"")

svglite::svglite(file = 'plots/2-07-funding-lines2.svg',
                 width = 5)
p2 %>% print()
dev.off()


# p3 line size ------------------------------------------------------------

p3 <- 
  clust_tidy %>% 
  ggplot(aes(x = year,
             y = scaled_funding,
             fill = scaled_funding,
             colour = scaled_funding,
             group = agency)) +
  # geom_point(size = .5) +
  # geom_bar(stat = ""identity"", width = .1) +
  geom_ribbon(aes(size = scaled_funding)) +
  geom_hline(yintercept = 0, colour = ""grey80"") +
  facet_grid(agency ~ .) +
  theme_minimal() + 
  scale_size(guide = FALSE) +
  scfill + 
  scale_colour_viridis_c(guide = FALSE) + 
  theme(axis.text.y = element_blank(),
        panel.grid = element_blank(),
        legend.position = ""top"",
        text = element_text(colour = ""grey40""),
        strip.text = element_text(colour = ""grey40""))

p3

svglite::svglite(file = 'plots/2-07-funding-lines3.svg',
                 width = 5)
p3 %>% print()
dev.off()

png(filename = ""plots/2-07-funding-lines3.png"",
    height = 2000, width = 1400,
    res = 300)
p3 %>% print()
dev.off() 
","2019-7"
"780",669,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-07-funding.R","library(tidyverse)

# Get data ---------------------------------------------------

rd_path <- ""data/2-07-funding.Rdata""
rd_url <- paste0(""https://raw.githubusercontent.com/"",
                  ""rfordatascience/tidytuesday/master/data/"",
                  ""2019/2019-02-12/fed_r_d_spending.csv"")

if(!file.exists(rd_path)) {
  rd <- 
    read_csv(rd_url)
  
  save(rd, file = rd_path)
  
} else {
  load(rd_path)
}


# set theme ---------------------------------------------------------------

theme_set(theme_bw() +
            theme(axis.text.x = element_text(angle = 90, vjust = .5)))

# explore -----------------------------------------------------------------

# rd %>% View()

rd %>% 
  ggplot(aes(x = year %>% as.character %>% as_factor(),
             y = rd_budget)) +
  geom_boxplot()

rd %>% 
  ggplot(aes(x = year,
             y = rd_budget,
             group = department)) +
  geom_line() +
  scale_y_log10()

# correlation
library(ggfortify)
library(GGally)

rd_wide <- 
  rd %>% 
  select(department, year, rd_budget) %>% 
  tidyr::spread(key = year,
                value = rd_budget) %>%
  column_to_rownames(""department"") %>%
  t()
  
# rd_wide %>% View()

cors <- 
  rd_wide %>% 
  cor() 

cors %>% GGally::ggcorr()
cors %>% 
  autoplot() +
  scale_fill_viridis_c(option = ""E"")

# cors %>% GGally::ggpairs()


# Try some cluster --------------------------------------------------------

# hierarchical
rd_wide %>% scale() %>% t() %>% #View()
  dist() %>%  hclust() %>% plot()

# kmeans
k_clust <- 
  rd_wide %>%
  scale() %>%
  t() %>%
  kmeans(centers = 2)

clust_df <- 
  k_clust$cluster %>% 
  {tibble(department = names(.),
          cluster = .)}

# plot
p <- 
  k_clust %>%
  broom::augment(data = rd_wide %>% scale() %>% t()) %>% 
  rename_all(~str_sub(., 2, -1)) %>% 
  gather(`1976`:`2017`, key = ""year"", value = ""scaled_funding"") %>% 
  mutate(cluster = cluster %>% as.character()) %>% 
  ggplot(aes(x = year,
             y = scaled_funding,
             colour = cluster)) +
  geom_line(aes(group = rownames),
            alpha = .5) +
  # geom_smooth() +
  stat_summary(aes(group = cluster),
               geom = ""line"",
               fun.y = median,
               size = 2) +
  facet_grid(cluster ~ .)

# plot reaal values
rd %>% 
  left_join(clust_df, by = ""department"") %>% 
  ggplot(aes(x = year,
             y = rd_budget,
             colour = cluster)) + 
  geom_line() + 
  facet_wrap(""department"", 
             scales = ""free_y"")


# Obama years + Trump begin -----------------------------------------------

rd_last <- 
  rd %>% 
  filter(year >= 2009) 
  
rd_last_wide <- 
  rd_last %>% 
  select(department, year, rd_budget) %>% 
  tidyr::spread(key = year,
                value = rd_budget) %>%
  column_to_rownames(""department"") %>%
  t()

rd_last_wide %>% 
  cor(method = ""spearman"") %>% 
  autoplot() +
  scale_fill_viridis_c()

rd_last_wide %>% scale() %>% t() %>% #View()
  dist() %>%  hclust() %>% plot()

# kmeans
last_k_clust <- 
  rd_last_wide %>%
  scale() %>%
  t() %>%
  kmeans(centers = 2)

last_clust_df <- 
  last_k_clust$cluster %>% 
  {tibble(department = names(.),
          cluster = .)}

# plot
rd_last %>% 
  left_join(last_clust_df, by = ""department"") %>% 
  ggplot(aes(x = year,
             y = rd_budget,
             colour = cluster)) + 
  geom_line() + 
  facet_wrap(""department"", 
             scales = ""free_y"")

# plot scaled values
p_last <- 
  last_k_clust %>%
  broom::augment(data = rd_last_wide %>% scale() %>% t()) %>% 
  rename_all(~str_sub(., 2, -1)) %>% 
  gather(`2009`:`2017`, key = ""year"", value = ""scaled_funding"") %>% 
  mutate(cluster = cluster %>% as.character()) %>% 
  ggplot(aes(x = year,
             y = scaled_funding,
             colour = cluster)) +
  geom_line(aes(group = rownames),
            alpha = .5) +
  # geom_smooth() +
  stat_summary(aes(group = cluster),
               geom = ""line"",
               fun.y = median,
               size = 2) +
  facet_grid(cluster ~ .)


# fix plots ---------------------------------------------------------------


title_blue <- ""#5F3BBA""

depts <- c(
  DOD = ""Deparment of Defense"",
  NASA = ""National Aeronautics and Space Administration"",
  DOE = ""Department of Energy"",
  HHS = ""Department of Health and Human Services"",
  NIH = ""National Institute of Health"",
  NSF = ""National Science Foundation"",
  USDA = ""US Department of Agriculture"",
  Interior = ""Department of Interior"",
  DOT = ""Deparment of Transportation"",
  EPA = ""Environmental Protection Agency"",
  DOC = ""Department of Corrections"",
  DHS = ""Department of Homeland Security"",
  VA = ""Department of Veterands Affairs"",
  Other = ""other R&D spending"")

cl_depts <- 
  clust_df %>% 
  mutate(full_name = depts[department] %>% unname()) %>% 
  {split(.$full_name, .$cluster)} %>% 
  map_chr(~paste(., collapse = ""\n"")) 

  
# plot
p <- 
  k_clust %>%
  broom::augment(data = rd_wide %>% scale() %>% t()) %>% 
  rename_all(~str_sub(., 2, -1)) %>% 
  gather(`1976`:`2017`, key = ""year"", value = ""scaled_funding"") %>% 
  mutate(cluster = cluster %>% as.character()) %>% 
  ggplot(aes(x = year %>% as.numeric(),
             y = scaled_funding,
             colour = cluster)) +
  geom_line(aes(group = rownames),
            alpha = .5) +
  # geom_smooth() +
  stat_summary(aes(group = cluster),
               geom = ""line"",
               fun.y = median,
               size = 2) +
  facet_grid(cluster ~ .,
             labeller = labeller(cluster = cl_depts)) +
  scale_color_viridis_d(begin = .3, end = .8,
                        option = ""B"", guide = FALSE) +
  labs(title = ""US Federal Research and Development Spending by Agency"",
       subtitle = str_wrap(""Spending splits in two clusters [k-means
                           and hierarchical algorithms have similar results].
                           Fundings for group 1 increase sharply in the
                           late '90s and '00s, fundings for group 2 falls sharply in
                           the '80s an then stabilizes.""),
       y = ""Z-score normalized spendings*"",
       x = ""Year"",
       caption = ""*Adjusted for inflation\nSource: AAAS | Plot by @othomn"") +
  theme_bw() +
  theme(text = element_text(family = ""Arial Narrow"",
                            colour = ""grey40"",
                            size = 11),
        axis.title = element_text(size = 14),
        plot.title = element_text(colour = ""grey20"",
                                  face = ""bold"",
                                  size = 16),
        strip.text.y = element_text(angle = 0,
                                    size = 9,
                                    hjust = 0),
        strip.background = element_rect(fill = ""grey90"",
                                        colour = ""grey90""),
        plot.subtitle = element_text(face = ""bold"",
                                     size = 12),
        aspect.ratio = .4,   
        plot.margin = margin(t = 10, r = 15, b = 0, l = 10,
                             unit = ""mm""),
        plot.caption = element_text(hjust = 0)) 

# p


# Save --------------------------------------------------------------------

png(filename = ""plots/2-07-funding.png"",
    height = 1600, width = 2100,
    res = 300)
p %>% print()
dev.off() 


# heatmap -----------------------------------------------------------------


k_clust %>%
  broom::augment(data = rd_wide %>% scale() %>% t()) %>% 
  rename_all(~str_sub(., 2, -1)) %>% 
  gather(`1976`:`2017`, key = ""year"", value = ""scaled_funding"") %>% 
  mutate(cluster = cluster %>% as.character()) %>% 
  ggplot(aes(x = year,
             y = rownames,
             fill = scaled_funding)) +
  geom_tile() +
  facet_grid(cluster ~ ., scales = ""free"", space = ""free"") +
  scale_fill_viridis_c(option = ""D"") +
  theme_minimal() +
  theme(aspect.ratio = 1) 
","2019-7"
"781",670,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-12-open-policing-snake.Rmd","---
title: ""Open Policing - Raleigh""
author: ""Otho""
date:  ""`r Sys.Date()`""
output: html_document
editor_options: 
  chunk_output_type: console
---

Reproduce Nadieh Bremer and Zan Armstrong famouse [Baby Spike visualization](https://www.visualcinnamon.com/portfolio/baby-spike)

```{r}
library(tidyverse)
library(rlang)
library(lubridate)
library(scales)
```


```{r}
dat_path <- ""data/2-12-open-policing.Rdata""

# data for Raleigh, because I have been there
dat_url <- paste0(""https://stacks.stanford.edu/"",
                  ""file/druid:tr137st9964/tr137st9964"",
                  ""_nc_raleigh_2019_02_25.csv.zip"")

if(!file.exists(dat_path)) {
  # one temporary file zipped
  # and one with the csv
  temp <- tempfile()
  temp2 <- tempfile()
  download.file(dat_url, destfile = temp)
  
  temp2 <- unzip(temp)
  
  raleigh <- read_csv(temp2)
  
  save(raleigh, file = dat_path)
} else {
  load(dat_path)
}
```

# explore

I guess that the `time` variable is measured in seconds of the day

```{r}
raleigh$time %>% range(na.rm = TRUE)
# Time differences in secs
# [1]     1 86399
```

# Use loess.

```{r}
day_sec <- 60*60*24


# bin stops per minute
by_minute <- 
  raleigh %>%  
  mutate(mins = as_double(time) %/% 60,
         year = year(date)) %>% 
  group_by(mins, year) %>% 
  count() %>% 
  # na.omit() %>%
  # strange measurements at 0
  # probably tecnical issue
  filter(mins > 0) %>% 
  group_by(mins) %>% 
  summarise(n = mean(n))

# check
span <- 1/30
by_minute %>% 
  ggplot(aes(x = mins, y = n)) +
  stat_smooth(method = ""loess"", span = span) +
  geom_point(shape = ""."") 

# smooth 
smooth_obj <- 
  by_minute %>% 
  {loess(formula = ""n ~ mins"",
         data = .,
         span = span)}


# prediction
preds <- 
  predict(smooth_obj, newdata = by_minute, se = T)
  
min_smooth <- 
  preds %>% 
  # fitted values and interval
  {tibble(mins = names(.$fit) %>% as.numeric(),
          fitted = .$fit,
          se = .$se)} %>% 
  # add back observed values
  full_join(by_minute, by = ""mins"") %>% 
  # interval at 2s
  mutate(lower_bound = fitted - (10*se),
         upper_bound = fitted + (10*se))

# check
min_smooth %>% 
  ggplot(aes(x = mins, y = n)) +
  geom_line(aes(y = fitted)) +
  geom_point(shape = ""."")


# try ribbon
med_y <- mean(min_smooth$n)

min_smooth %>% 
  ggplot(aes(x = mins)) +
  geom_hline(yintercept = med_y,
             colour = ""#B63A82"") +
  geom_ribbon(aes(ymin = lower_bound,
                  ymax = upper_bound),
             fill = ""grey80"",
             colour = ""#27A6D3"") +
  geom_point(aes(y = n),
             shape = ""."") +
  ylim(0, NA) +
  theme_minimal()

# ribbon 
fill_up <- ""#3752C3""
min_smooth %>% 
  ggplot(aes(x = mins)) +
  geom_ribbon(aes(ymax = fitted,
                  ymin = med_y),
              fill = fill_up) +
  geom_point(aes(y = n),
             colour = ""grey70"",
             shape = ""."") +
  theme_minimal()
```



# use coordinates
Only way that I know to plot an arc.

```{r}
# to coordinates
# y_from <- c(0, min_smooth$n %>% max)
# y_to <- c(70, 20)
# x_to <- c(30, -30)
# x_from <- range(min_smooth$mins)
# 
# to_plot <- 
#   min_smooth %>% 
#   mutate(mins = rescale(mins, to = x_to, from = x_from),
#          n = rescale(n, to = y_to, from = y_from),
#          fitted = rescale(fitted, to = y_to, from = y_from),
#          lower_bound = rescale(lower_bound, to = y_to, from = y_from),
#          upper_bound = rescale(upper_bound, to = y_to, from = y_from))
#   

to_plot <- min_smooth
```

# set parameters

```{r}
# save params again
med_y <- to_plot$n %>% mean
fill_down <- ""#E97E00"" # ""#B63A82""
fill_up <- ""#263A89"" # ""#3752C3""
ytop <- to_plot$n %>% max()
ylow <- to_plot$n %>% min()
ridge_width <- to_plot$fitted %>% range() %>% {(.[2] - .[1])/12}
grid_at <- c(20, 40, 60) %>% rescale(to = y_to, from = y_from)
annos_color <- ""grey70""
text_color <- ""#98F0D8""
mins_range <- range(to_plot$mins)
```

# test snake plot

```{r}
to_plot %>% 
  ggplot(aes(x = mins)) +
  geom_hline(yintercept = med_y,
             colour = ""#B63A82"") +
  geom_ribbon(aes(ymin = lower_bound,
                  ymax = upper_bound),
             fill = ""grey80"",
             colour = ""#27A6D3"") +
  geom_point(aes(y = n),
             shape = ""."") +
  # ylim(0, NA) +
  theme_minimal() 
  # coord_map(projection = ""azequidistant"", orientation = c(90, -45, 225))

```

# Try trans_new()

```{r}
# 
# tst <- max(min_smooth$mins)
# 
# radial <- 
#   ggforce::radial_trans(r.range = c(-60, min_smooth$n %>% max()),
#                         a.range = range(tst*1/2, tst*8))
# 
# min_rad <- 
#   min_smooth %>% 
#   {radial$transform(#r = rep(mean(.$n), length(.$n)),
#     r = .$n,
#                       a = .$mins)}
# 
# ggplot(min_smooth, aes(x = mins, y = fitted)) +
#   geom_point()
# 
# ggplot(min_rad, aes(x = x, y = y)) +
#   geom_point() 

```

# Draft plot

```{r}
p <- 
  to_plot %>% 
  ggplot(aes(x = mins)) +
  lims(y = range(to_plot$n) + c(-2, +2),
       x = range(to_plot$mins) + c(-100, +100)) +
  theme_void()

p
```

# Add bars

```{r}
# add bars
add_bar <- function(p, at) {
  p <- 
    p + 
    annotate(geom = ""rect"",
             xmin = mins_range[1],
             xmax = mins_range[2],
             ymin = case_when(at >= 0 ~ Inf,
                              TRUE ~ -Inf),
             ymax = med_y + at,
             fill = case_when(at >= 0 ~ fill_up,
                              TRUE ~ fill_down),
             alpha = .3)
  return(p)  
} 

ridge_at <- c(-0.001, (-6:5)*ridge_width)

p1 <- p
for(i in ridge_at)  p1 <- add_bar(p1, i)

p1
```

# add snake


```{r}
p2 <-
  p1 +
  geom_ribbon(aes(ymin = -Inf,
                  ymax = lower_bound),
              fill = ""white"") +
  geom_ribbon(aes(ymin = upper_bound,
                  ymax = Inf),
              fill = ""white"") #+
  # geom_line(aes(y = upper_bound), colour = text_color) +
  # geom_line(aes(y = lower_bound), colour = text_color)
  
p2
```

# Add x guide / arrow

```{r}
p3 <- 
  p2 +
  geom_ribbon(aes(ymin = -Inf,
                  ymax = case_when(lower_bound >= med_y ~ med_y,
                                   TRUE ~ lower_bound)),
              fill = ""white"",
              colour = ""#DE1288"") +
  geom_ribbon(aes(ymin = +Inf,
                  ymax = case_when(upper_bound < med_y ~ med_y,
                                   TRUE ~ upper_bound)),
              fill = ""white"",
              colour = ""#DE1288"") +
  geom_line(aes(y = upper_bound),
            colour = ""grey50"") +
  geom_line(aes(y = lower_bound),
            colour = ""grey50"",
            size = 1.2)
              
  
p3  
```

# Save SVG

```{r}
svglite::svglite(""plots/2-12-open-policing-snake.svg"")
p3 + theme(aspect.ratio = .4)
dev.off()
```


```{r}
p <- 
to_plot %>% 
  ggplot(aes(x = mins,
             ymax = fitted)) +
  geom_ribbon(data = . %>%
                filter(fitted > med_y),
              ymin = med_y,
              fill = fill_up,
              # colour = colour,
              alpha = .2) +
  geom_ribbon(data = . %>%
                filter(fitted <= med_y),
              ymin = med_y,
              fill = fill_down,
              # colour = colour,
              alpha = .2)  +
  coord_map(projection = ""azequidistant"", orientation = c(90, -45, 225)) +
  # theme_minimal()
  theme_void()


p
```

```{r}

```


# add gradient

```{r}
up_gradient <- function(roll, p = p) {
  p <- p + 
    geom_ribbon(data = . %>%
                  filter(fitted > med_y + ridge_width*roll),
                aes(ymin = med_y + ridge_width*roll),
                fill = fill_up,
                alpha = .3)
  return(p)
}


down_gradient <- function(roll, p = p) {
  p <- p + 
    geom_ribbon(data = . %>%
                  filter(fitted < med_y - ridge_width*roll),
                aes(ymin = med_y - ridge_width*roll),
                fill = fill_down,
                alpha = .3)
  return(p)
}

p2 <- up_gradient(1, p)
p2 <- up_gradient(2, p2)
p2 <- up_gradient(3, p2)
p2 <- up_gradient(4, p2)
p2 <- up_gradient(5, p2)
p2 <- up_gradient(6, p2)
p2 <- down_gradient(1, p2)
p2 <- down_gradient(2, p2)
p2 <- down_gradient(3, p2)
p2 <- down_gradient(4, p2)
p2 <- down_gradient(5, p2)

p2
```

# cover ribbon residues

```{r}
# Cover up ribbon residues
p3 <- 
  p2 +
  geom_ribbon(data = . %>% 
                mutate(upper_bound = case_when(fitted < med_y ~ fitted,
                                               TRUE ~ med_y)),
              aes(ymax = upper_bound,
                  ymin = ylow),
              fill = ""white"",
              colour = NA) +
  geom_ribbon(data = . %>% 
                mutate(lower_bound = case_when(fitted > med_y ~ fitted,
                                               TRUE ~ med_y)),
              aes(ymax = ytop,
                  ymin = lower_bound),
              fill = ""white"",
              colour = NA) 
  
p3

```

# add grid

```{r}

add_lines <- function(at, p) {
  p <- 
    p +
    geom_hline(yintercept = at,
               lty = 2,
               size = .1,
               colour = annos_color)

  return(p)
}

p4 <- p3
for(i in grid_at) p4 <- add_lines(at = i, p = p4)
p4


```


# add points

```{r}
p5 <- 
  p4 +
  geom_point(aes(y = n),
             colour = ""grey70"",
             # shape = ""."",
             size = .2,
             alpha = .5) 
```

# add y guide

```{r}
# add y guide
p6 <- 
  p5 + 
  geom_text(data = tibble(x = max(to_plot$mins) + 3,
                          y = grid_at),
            aes(x = x,
                y = y,
                label = y %>%
                  rescale(to = y_from, from = y_to) %>% 
                  round(1)),
            size = 5,
            nudge_x = 1,
            hjust = 1,
            vjust = .5,
            angle = max(to_plot$mins),
            colour = annos_color,
            inherit.aes = F) 

p6
```

# add arrow

```{r}
p7 <- 
  p6 + 
  geom_line(data = tibble(x = c(x_to[1] + 1.5, x_to[2] - 7),
                          y = med_y),
            aes(x = x, y = y),
            size = 1.2,
            arrow = arrow(ends = ""first"",
                          length = unit(3.4, ""mm""),
                          type = ""closed""),
            colour = text_color,
            inherit.aes = FALSE)

p7
```

# add minutes guide

```{r}
hrs <- seq(0, 24, by = 4) * 60
hrs_guides <- 
  hrs %>% 
  {tibble(x = rescale(., to = x_to, from = x_from),
          label = (./60))}


p8 <- 
  p7 +
  geom_text(data = hrs_guides,
            mapping = aes(x = x,
                          y = med_y,
                          label = paste0(label, ""h""),
                          angle = x),
            size = 3,
            hjust = 0,
            vjust = 1,
            nudge_y = .5,
            colour = ""#44D4DC"", #""#27A6D3"",
            fontface = ""bold"",
            inherit.aes = FALSE)

p8
```

# title and annos

```{r}
p9 <- 
  p8 +
  labs(title = ""Average Police Stops Per Minute of the Day"",
       subtitle = str_wrap(""Recorded in Raleigh, NC., between
                           2002 and 2015. These data are gathered and
                           maintained by the
                           Stanford Open Policing Project."", 30),
       caption = paste0(""Data from Stanford Open Policing Project.\n"",
                        ""Plot inspired to the design invented by "",
                        ""Nadieh Bremer and Zan Armstrong for the "",
                        ""Baby Spike article in Scientific American.\n"",
                        ""Plot done by @othomn in ggplot2."")) +
  theme(plot.title = element_text(family = ""sans"",
                             size = 12,
                             colour = ""grey30"", 
                             hjust = 1),
        plot.subtitle = element_text(family = ""sans"",
                             size = 10,
                             colour = ""grey50"", 
                             hjust = 1),
        plot.caption = element_text(family = ""sans"",
                                    face = ""italic"",
                                    size = 10,
                                    colour = ""grey50"", 
                                    hjust = 0))

p9

p10 <- 
  p9 +
  annotate(geom = ""text"",
           x = (5.5*60) %>% rescale(to = x_to, from = x_from),
           y = max(to_plot$fitted) + 2,
           hjust = 0,
           vjust = 1,
           label = str_wrap(""I can imagine why fewer cars get
                            stopped by the police
                            at these hours of the day..."", 20),
           family = ""sans"",
           size = 3,
           colour = ""grey50"", 
           lineheight = .9) + 
  annotate(geom = ""text"",
           x = (18.5*60) %>% rescale(to = x_to, from = x_from),
           y = max(to_plot$fitted) - 5,
           hjust = 0,
           vjust = 1,
           label = str_wrap(""...but not why also at these hours.
                            Dinner time?"", 20),
           family = ""sans"",
           size = 3,
           colour = ""grey50"", 
           lineheight = .9) 
  
p10

```

# Save SVG

```{r}
svglite::svglite(""plots/2-12-open-policing-arc.svg"")
p10
dev.off()
```

","2019-12"
"782",671,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-12-open-policing.Rmd","---
title: ""Open Policing - Raleigh""
author: ""Otho""
date:  ""`r Sys.Date()`""
output: html_document
editor_options: 
  chunk_output_type: console
---

Reproduce Nadieh Bremer and Zan Armstrong famouse [Baby Spike visualization](https://www.visualcinnamon.com/portfolio/baby-spike)

```{r}
library(tidyverse)
library(rlang)
library(lubridate)
library(scales)
```


```{r}
dat_path <- ""data/2-12-open-policing.Rdata""

# data for Raleigh, because I have been there
dat_url <- paste0(""https://stacks.stanford.edu/"",
                  ""file/druid:tr137st9964/tr137st9964"",
                  ""_nc_raleigh_2019_02_25.csv.zip"")

if(!file.exists(dat_path)) {
  # one temporary file zipped
  # and one with the csv
  temp <- tempfile()
  temp2 <- tempfile()
  download.file(dat_url, destfile = temp)
  
  temp2 <- unzip(temp)
  
  raleigh <- read_csv(temp2)
  
  save(raleigh, file = dat_path)
} else {
  load(dat_path)
}
```

# explore

I guess that the `time` variable is measured in seconds of the day

```{r}
raleigh$time %>% range(na.rm = TRUE)
# Time differences in secs
# [1]     1 86399
```

# Use loess.

```{r}
day_sec <- 60*60*24


# bin stops per minute
by_minute <- 
  raleigh %>%  
  mutate(mins = as_double(time) %/% 60,
         year = year(date)) %>% 
  group_by(mins, year) %>% 
  count() %>% 
  # na.omit() %>%
  # strange measurements at 0
  # probably tecnical issue
  filter(mins > 0) %>% 
  group_by(mins) %>% 
  summarise(n = mean(n))

# check
span <- 1/30
by_minute %>% 
  ggplot(aes(x = mins, y = n)) +
  stat_smooth(method = ""loess"", span = span) +
  geom_point(shape = ""."") 

# smooth 
smooth_obj <- 
  by_minute %>% 
  {loess(formula = ""n ~ mins"",
         data = .,
         span = span)}

min_smooth <- 
  smooth_obj %>% 
  {tibble(mins = 1:length(.$fitted),
          fitted = .$fitted)} %>% 
  full_join(by_minute, by = ""mins"")

# check
min_smooth %>% 
  ggplot(aes(x = mins, y = n)) +
  geom_line(aes(y = fitted)) +
  geom_point(shape = ""."")

# ribbon 
med_y <- mean(min_smooth$n)
fill_up <- ""#3752C3""
min_smooth %>% 
  ggplot(aes(x = mins)) +
  geom_ribbon(aes(ymax = fitted,
                  ymin = med_y),
              fill = fill_up) +
  geom_point(aes(y = n),
             colour = ""grey70"",
             shape = ""."") +
  theme_minimal()
```

# use coordinates
Only way that I know to plot an arc.


```{r}
# to coordinates
y_from <- c(0, min_smooth$n %>% max)
y_to <- c(70, 20)
x_to <- c(60, -60)
x_from <- range(min_smooth$mins)

to_plot <- 
  min_smooth %>% 
  mutate(mins = rescale(mins, to = x_to, from = x_from),
         n = rescale(n, to = y_to, from = y_from),
         fitted = rescale(fitted, to = y_to, from = y_from))
  
# save params again
med_y <- to_plot$n %>% mean
fill_up <- ""#E97E00"" # ""#B63A82""
fill_down <- ""#263A89"" # ""#3752C3""
ytop <- to_plot$n %>% max()
ylow <- to_plot$n %>% min()
ridge_width <- to_plot$fitted %>% range() %>% {(.[2] - .[1])/12}
# grid_at <- c(med_y - ridge_width*3,
#              med_y,
#              med_y + ridge_width*3)
grid_at <- c(20, 40, 60) %>% rescale(to = y_to, from = y_from)
annos_color <- ""grey70""
text_color <- ""#98F0D8""

p <- 
to_plot %>% 
  ggplot(aes(x = mins,
             ymax = fitted)) +
  geom_ribbon(data = . %>%
                filter(fitted > med_y),
              ymin = med_y,
              fill = fill_up,
              # colour = colour,
              alpha = .2) +
  geom_ribbon(data = . %>%
                filter(fitted <= med_y),
              ymin = med_y,
              fill = fill_down,
              # colour = colour,
              alpha = .2)  +
  coord_map(projection = ""azequidistant"", orientation = c(90, -45, 225)) +
  # theme_minimal()
  theme_void()


p
```

# add gradient

```{r}
up_gradient <- function(roll, p = p) {
  p <- p + 
    geom_ribbon(data = . %>%
                  filter(fitted > med_y + ridge_width*roll),
                aes(ymin = med_y + ridge_width*roll),
                fill = fill_up,
                alpha = .3)
  return(p)
}


down_gradient <- function(roll, p = p) {
  p <- p + 
    geom_ribbon(data = . %>%
                  filter(fitted < med_y - ridge_width*roll),
                aes(ymin = med_y - ridge_width*roll),
                fill = fill_down,
                alpha = .3)
  return(p)
}

p2 <- up_gradient(1, p)
p2 <- up_gradient(2, p2)
p2 <- up_gradient(3, p2)
p2 <- up_gradient(4, p2)
p2 <- up_gradient(5, p2)
p2 <- up_gradient(6, p2)
p2 <- down_gradient(1, p2)
p2 <- down_gradient(2, p2)
p2 <- down_gradient(3, p2)
p2 <- down_gradient(4, p2)
p2 <- down_gradient(5, p2)

p2
```

# cover ribbon residues

```{r}
# Cover up ribbon residues
p3 <- 
  p2 +
  geom_ribbon(data = . %>% 
                mutate(upper_bound = case_when(fitted < med_y ~ fitted,
                                               TRUE ~ med_y)),
              aes(ymax = upper_bound,
                  ymin = ylow),
              fill = ""white"",
              colour = NA) +
  geom_ribbon(data = . %>% 
                mutate(lower_bound = case_when(fitted > med_y ~ fitted,
                                               TRUE ~ med_y)),
              aes(ymax = ytop,
                  ymin = lower_bound),
              fill = ""white"",
              colour = NA) 
  
p3

```

# add grid

```{r}

add_lines <- function(at, p) {
  p <- 
    p +
    geom_hline(yintercept = at,
               lty = 2,
               size = .1,
               colour = annos_color)

  return(p)
}

p4 <- p3
for(i in grid_at) p4 <- add_lines(at = i, p = p4)
p4


```


# add points

```{r}
p5 <- 
  p4 +
  geom_point(aes(y = n),
             colour = ""grey70"",
             # shape = ""."",
             size = .2,
             alpha = .5) 
```

# add y guide

```{r}
# add y guide
p6 <- 
  p5 + 
  geom_text(data = tibble(x = max(to_plot$mins) + 3,
                          y = grid_at),
            aes(x = x,
                y = y,
                label = y %>%
                  rescale(to = y_from, from = y_to) %>% 
                  round(1)),
            size = 5,
            nudge_x = 1,
            hjust = 1,
            vjust = .5,
            angle = max(to_plot$mins),
            colour = annos_color,
            inherit.aes = F) 

p6
```

# add arrow

```{r}
p7 <- 
  p6 + 
  geom_line(data = tibble(x = c(x_to[1] + 1.5, x_to[2] - 7),
                          y = med_y),
            aes(x = x, y = y),
            size = 1.2,
            arrow = arrow(ends = ""first"",
                          length = unit(3.4, ""mm""),
                          type = ""closed""),
            colour = text_color,
            inherit.aes = FALSE)

p7
```

# add minutes guide

```{r}
hrs <- seq(0, 24, by = 4) * 60
hrs_guides <- 
  hrs %>% 
  {tibble(x = rescale(., to = x_to, from = x_from),
          label = (./60))}


p8 <- 
  p7 +
  geom_text(data = hrs_guides,
            mapping = aes(x = x,
                          y = med_y,
                          label = paste0(label, ""h""),
                          angle = x),
            size = 3,
            hjust = 0,
            vjust = 1,
            nudge_y = .5,
            colour = ""#44D4DC"", #""#27A6D3"",
            fontface = ""bold"",
            inherit.aes = FALSE)

p8
```

# title and annos

```{r}
p9 <- 
  p8 +
  labs(title = ""Average Police Stops Per Minute of the Day"",
       subtitle = str_wrap(""Recorded in Raleigh, NC., between
                           2002 and 2015. These data are gathered and
                           maintained by the
                           Stanford Open Policing Project."", 30),
       caption = paste0(""Data from Stanford Open Policing Project.\n"",
                        ""Plot inspired to the design invented by "",
                        ""Nadieh Bremer and Zan Armstrong for the "",
                        ""Baby Spike article in Scientific American.\n"",
                        ""Plot done by @othomn in ggplot2."")) +
  theme(plot.title = element_text(family = ""sans"",
                             size = 12,
                             colour = ""grey30"", 
                             hjust = 1),
        plot.subtitle = element_text(family = ""sans"",
                             size = 10,
                             colour = ""grey50"", 
                             hjust = 1),
        plot.caption = element_text(family = ""sans"",
                                    face = ""italic"",
                                    size = 10,
                                    colour = ""grey50"", 
                                    hjust = 0))

p9

p10 <- 
  p9 +
  annotate(geom = ""text"",
           x = (5.5*60) %>% rescale(to = x_to, from = x_from),
           y = max(to_plot$fitted) + 2,
           hjust = 0,
           vjust = 1,
           label = str_wrap(""I can imagine why fewer cars get
                            stopped by the police
                            at these hours of the day..."", 20),
           family = ""sans"",
           size = 3,
           colour = ""grey50"", 
           lineheight = .9) + 
  annotate(geom = ""text"",
           x = (18.5*60) %>% rescale(to = x_to, from = x_from),
           y = max(to_plot$fitted) - 5,
           hjust = 0,
           vjust = 1,
           label = str_wrap(""...but not why also at these hours.
                            Dinner time?"", 20),
           family = ""sans"",
           size = 3,
           colour = ""grey50"", 
           lineheight = .9) 
  
p10

```

# Save SVG

```{r}
svglite::svglite(""plots/2-12-open-policing-arc.svg"")
p10
dev.off()
```

","2019-12"
"783",672,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-13-animal-names.R","library(tidyverse)

pet_names <- read_csv(""https://github.com/rfordatascience/tidytuesday/blob/master/data/2019/2019-03-26/seattle_pets.csv?raw=true"",
                col_types = cols(license_issue_date = col_datetime(format = ""%B %d %Y"")))


dat2 %>% 
  ggplot(aes(x = license_issue_date)) +
  geom_density(fill = ""blue"")
","2019-13"
"784",674,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-14-seattle-bike-draft-grid.R","library(tidyverse)
library(lubridate)
library(grid)


# weekdays in english
Sys.setlocale(""LC_TIME"", ""en_US.UTF8"")

length(p_list)
# 418

length(p_list)%/%(8*4)
# 13
length(p_list)%/%4
# 104

# rows per block
block_rows <- 14
block_cols <- 8
# 112 cells per block

112*4
# 448 for 418 cells
# 30 cells too much
 

# outer margin left and right
m_side <- .14
# outer margin up and down
m_tb <- .16
# inner margin left and right
m_small_side <- .04
# inner margin top and bottom
m_small_tb <- .05

# must fit a group of 8 plots in half table width
p_width <- (.5 - m_side - m_small_side)/8 

# must 13 plots in half table height
p_height <- (.5 - m_tb - m_small_tb)/13


# background color
bg_col <- ""#F1F1F0"" #""#F2F2EF""#""#F6F6EC""

# in a data frame?
p_tibble <- 
  tibble(p = p_list,
         x = seq(from = m_side, to = .5 - m_small_side, length.out = 9)[1:block_cols] %>% 
           rep(block_rows) %>%
           # second block, right top
           c(seq(from = .5 + m_small_side, to = 1 - m_side, length.out = 9)[1:block_cols] %>% 
               rep(block_rows)) %>% 
           # # third and fourth blocks (bottom)
           {c(.,.)} %>% .[1:length(p_list)],
         y = seq(from = 1 - m_tb, to = .5 + m_small_tb, length.out = block_rows) %>% 
           rep(each = block_cols) %>% 
           # second block, right top
           {c(., .)} %>% 
           c(seq(from = .5 - m_small_tb, to = m_tb, length.out = block_rows) %>% 
               rep(each = block_cols) %>% 
               {c(., .)}) %>% 
           .[1:length(p_list)],
         width = p_width,
         height = p_height)

plot_to_vp <- function(p, x, y, width, height) {
  print(p,
        vp = viewport(x = x, y = y, width = width, height = height))
  return(NULL)
}


# Very slow on r graphic devices ------------------------------------------

# grid.newpage()
# 
# p_tibble %>% pmap(plot_to_vp)


# much faster on SVG ------------------------------------------------------

# function to add weeknames
w_names <- 
  tibble(x = seq(from = m_side, to = .5 - m_small_side, length.out = 9)[1:block_cols] %>% 
           c(seq(from = .5 + m_small_side, to = 1 - m_side, length.out = 9)[1:block_cols]),
         label = c("""", ""Sun"", ""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"") %>% 
           rep(2))

add_weeknames <- function(x, label) {
  grid.text(label = label,
            x = x,
            y = 1 - m_tb*.95,
            vjust = 0,
            gp = gpar(col = ""grey20"",
                      fontsize = 18,
                      fontface = ""italic"",
                      fontfamily = ""Times New Roman""))
  return(NULL)
}
  
w_names %>% pmap(add_weeknames)


svglite::svglite(file = ""plots/2-14-seattle-bikes-draft-grid.svg"",
                 height = 33.1,
                 width = 23.4 )
grid.newpage()
# background
grid.rect(gp = gpar(fill = bg_col))
# Title
grid.text(""365 Days Cycling in Seattle"",
          x = m_side,
          y = 1 - m_tb/2,
          gp = gpar(col = ""grey20"",
                    fontsize = 60,
                    fontface = ""italic"",
                    fontfamily = ""Times New Roman""),
          hjust = 0,
          vjust = 0)
# subtitle
grid.text(str_wrap(""Bicycle traffic crossing 7 detection points in Seattle in 2017."") %>% 
            paste(str_wrap("" Also an exercise on making heavily facetted plots with ggplot2 and
                   grid by Otho Mantegazza."",
                   width = 100), sep = ""\n""),
          x = m_side + .02, 
          y = 1 - m_tb*.72,
          gp = gpar(col = ""grey20"",
                    fontsize = 27,
                    fontface = ""italic"",
                    fontfamily = ""Times New Roman"",
                    lineheight = .87),
          hjust = 0,
          vjust = 0)
# mid line
grid.lines(x = unit(c(m_side*1.5, 1 - m_side*1.5), ""npc""),
           y = unit(c(.5, .5), ""npc""))
# week names
w_names %>% pmap(add_weeknames)
# plots
p_tibble %>% pmap(plot_to_vp)
# caption
grid.text(label = ""Data from the Seattle Department of Transportation\nplot by @othomn"",
          x = 1 - m_side, 
          y = m_tb*.5,
          gp = gpar(col = ""grey20"",
                    fontsize = 27,
                    fontface = ""italic"",
                    fontfamily = ""Times New Roman"",
                    lineheight = .87),
          hjust = 1,
          vjust = 0)
dev.off()

png(filename = ""plots/2-14-seattle-bikes-draft-grid.png"", 
    height = 33.1,
    width = 23.4,
    units = ""in"",
    res = 300)
grid.newpage()
# background
grid.rect(gp = gpar(fill = bg_col))
# Title
grid.text(""365 Days Cycling in Seattle"",
          x = m_side,
          y = 1 - m_tb/2,
          gp = gpar(col = ""grey20"",
                    fontsize = 60,
                    fontface = ""italic"",
                    fontfamily = ""Times New Roman""),
          hjust = 0,
          vjust = 0)
# subtitle
grid.text(str_wrap(""Bicycle traffic crossing 7 detection points in Seattle in 2017."") %>% 
            paste(str_wrap("" Also an exercise on making heavily facetted plots with ggplot2 and
                   grid by Otho Mantegazza."",
                           width = 100), sep = ""\n""),
          x = m_side + .02, 
          y = 1 - m_tb*.72,
          gp = gpar(col = ""grey20"",
                    fontsize = 27,
                    fontface = ""italic"",
                    fontfamily = ""Times New Roman"",
                    lineheight = .87),
          hjust = 0,
          vjust = 0)
# mid line
grid.lines(x = unit(c(m_side*1.5, 1 - m_side*1.5), ""npc""),
           y = unit(c(.5, .5), ""npc""))
# week names
w_names %>% pmap(add_weeknames)
# plots
p_tibble %>% pmap(plot_to_vp)
# caption
grid.text(label = ""Data from the Seattle Department of Transportation\nplot by @othomn"",
          x = 1 - m_side, 
          y = m_tb*.5,
          gp = gpar(col = ""grey20"",
                    fontsize = 27,
                    fontface = ""italic"",
                    fontfamily = ""Times New Roman"",
                    lineheight = .87),
          hjust = 1,
          vjust = 0)
dev.off()
","2019-14"
"785",675,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-14-seattle-bike.Rmd","---
title: ""365 Days Cycling in Seattle""
author: ""Otho""
date:  ""`r Sys.Date()`""
output: html_document
editor_options: 
  chunk_output_type: console
---

# Setup

```{r}
library(tidyverse)
library(lubridate)
library(tibbletime)
library(grid)

# weekdays in english
Sys.setlocale(""LC_TIME"", ""en_US.UTF8"")
```

# get data

```{r}
bike_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                   ""tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")
bike_path <- ""data/2-14-seattle-bike.Rdata""

if(!file.exists(bike_path)) {
  bike_traffic <- readr::read_csv()
   
  save(bike_traffic, file = ""data/2-14-seattle-bike.Rdata"")
} else {
  load(""data/2-14-seattle-bike.Rdata"")
}
```  

# wrangle data

Fix time

```{r}
bike_traffic <- 
  bike_traffic %>% 
  mutate(date = mdy_hms(date))
```

Explore

```{r, eval = FALSE}
# explore -----------------------------------------------------------------
bike_traffic %>% 
  pull(crossing) %>% 
  unique()

bike_traffic %>% 
  mutate(year_day = yday(.data$date),
         year = year(.data$date)) %>% 
  group_by(year, year_day, crossing) %>% 
  summarise(bike_count = sum(bike_count, na.rm = TRUE))

bike_traffic %>% 
  ggplot(aes(x = bike_count)) +
  geom_histogram() +
  scale_x_log10() +
  facet_grid(crossing ~ .)


bike_traffic %>% 
  mutate(week_day = wday(.data$date),
         week = week(.data$date), 
         year = year(.data$date)) %>% 
  # group_by(year, year_day, crossing) %>% 
  filter(year > 2013,
         year < 2019) #arrange(desc(bike_count)) %>%  top_n(n = 10)
```

After exploring the data, I decided to go for a poster with 4 heavily faceted panel, for two reasons:

- I thought that it was interesting to show bike counts for each crossing across every day of a year. So one could see the differences between working days and weekends and between the warm and cold season.
- I wanted to practice poster-like layouts and heavily faceted plots, 

I decided to use 2017 because measurements seem most complete during this year.

First, I had to decide what to show on a single plots

Use rolling mean.


```{r}
# smooth mean on a window of three measurements
roll_mean <- rollify(window = 3, .f = mean)

to_plot <- 
  bike_traffic %>% 
  # no need, but I wanted to use something other than ""date""
  # which is generic and it is a function
  rename(time_stamp = ""date"") %>% 
  # each crossing measures bikes in different direction separately
  # sum all the values to get counts by crossing an by hours
  group_by(crossing, time_stamp) %>% 
  summarise(bike_count = sum(bike_count)) %>% 
  ungroup() %>% 
  # Not necessary, but some of this column might be useful later
  mutate(year = year(time_stamp),
         year_day = yday(time_stamp),
         week_day = wday(time_stamp),
         day_hour = hour(time_stamp),
         date_day = round_date(time_stamp, unit = ""day"")) %>% 
  # seems like measurements are most complete in this year
  filter(year == 2017) %>%
  # filter(year_day > 45,year_day < 50) %>% 
  group_by(crossing) %>%
  arrange(year_day, day_hour) %>% 
  mutate(s_mean = roll_mean(bike_count)) %>% 
  ungroup()
```

# Store all plots in a list

I want to control the position of every plot individually
Thus, I plot every day in separately and put everything in a list.


```{r}
# First some parameters
# day 230 has unusually high counts and flattens everything else
ytop <-
  to_plot %>% 
  filter(year_day != 230) %>% 
  pull(s_mean) %>% max(na.rm = TRUE)

plot_bikes <- function(day_in)
{
  p <- to_plot %>%
    filter(yday(time_stamp) == yday(day_in)) %>% 
    ggplot(aes(x = day_hour,
               fill = crossing,
               colour = crossing)) +
    geom_ribbon(aes(ymin = 0,
                    ymax = s_mean),
                alpha = .2) +
    guides(colour = FALSE,
           fill = FALSE) +
    lims(y = c(0, ytop)) +
    theme_void() +
    theme(plot.margin = margin(0, 10, 0, 10))
  
  return(p)
}

# one plot per day
p_list <- 
  to_plot$time_stamp %>%
  round_date(unit = ""day"") %>%
  unique() %>% 
  {subset(., year(.) == 2017)} %>% 
  map(plot_bikes)


save(p_list, file = ""data/2-14-seattle-bike-PLOTS.Rdata"")
```

# Set the grid

To place all plots in the grid programmatically, first you have to set some parameter.

```{r}
length(p_list)
# 365

# how many rows per block (4 blocks in total)
# +1 to fit the remainder
length(p_list)%/%(7*4) + 1
# 14

# how many plots per block (approx)
length(p_list)%/%4
# 91

# rows per block
block_rows <- 14
block_cols <- 7
# 112 cells per block

14*7*4
# 392 cells for 365 plots
# 27 cells too much - no big deal:
# a bit of empty space looks ok at the end
 

# outer margin left and right
m_side <- .14
# outer margin up and down
m_tb <- .16
# inner margin left and right
m_small_side <- .04
# inner margin top and bottom
m_small_tb <- .05

# must fit a group of 8 plots in half table width
# the first space is for the date annotation
# the other 7 are for the plots
p_width <- (.5 - m_side - m_small_side)/8 

# must 13 plots in half table height
p_height <- (.5 - m_tb - m_small_tb)/13


# background color
bg_col <- ""#F1F1F0"" #""#F2F2EF""#""#F6F6EC""
```

## Function that plots in coordinates

Place the coordinates of each plot in a dataframe,
then you will loop on that dataframe with pmap()

```{r}

# x for third and fourth block are a repeat of this:
x_firstblock <-
  seq(from = m_side,
      to = .5 - m_small_side,
      length.out = 9)[2:(block_cols + 1)] %>% 
  rep(block_rows) 

x_secondblock <-
  c(seq(from = .5 + m_small_side,
        to = 1 - m_side,
        length.out = 9)[2:(block_cols + 1)] %>% 
      rep(block_rows))

# y for second and fourth block are a repeat of first and third
y_firstblock <- 
  seq(from = 1 - m_tb,
      to = .5 + m_small_tb,
      length.out = block_rows) %>%
  rep(each = block_cols) %>% 
  {c(., .)}

y_thirdblock <- 
  c(seq(from = .5 - m_small_tb, to = m_tb,
        length.out = block_rows) %>% 
      rep(each = block_cols) %>% 
      {c(., .)})



# all goes in a dataframe
p_tibble <- 
  tibble(p = p_list,
         x = c(x_firstblock, x_secondblock) %>% 
           # # third and fourth blocks (bottom)
           {c(.,.)} %>% 
           # remove extra positions
           .[1:length(p_list)],
         y = c(y_firstblock, y_thirdblock) %>% 
           .[1:length(p_list)],
         width = p_width,
         height = p_height)

# define a function to plot each plot on its position
# in the grid
plot_to_vp <- function(p, x, y, width, height) {
  print(p,
        vp = viewport(x = x, y = y, width = width, height = height))
  return(NULL)
}

```

## Function to plot weekdays

Define a function to plot weekdays on top:

```{r}
# function to add weeknames
w_names <-
  tibble(x = c(x_firstblock[1:7], x_secondblock[1:7]),
         label = c(""Sun"", ""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"") %>%
           rep(2))

add_weeknames <- function(x, label) {
  grid.text(label = label,
            x = x,
            y = 1 - m_tb*.93,
            vjust = 0,
            gp = gpar(col = ""grey20"",
                      fontsize = 18,
                      fontface = ""italic"",
                      fontfamily = ""Times New Roman""))
  return(NULL)
}

```

## Function that plots date

I want to plot the date only for the first Sunday of each month on the side.

```{r}
is_new_month <- rollify(.f = ~month(.) %>% unique() %>% length(),
                        window = 8)


# As always put everything in a dataframe
date_annos <- 
  to_plot %>% pull(time_stamp) %>% 
  unique() %>%
  # Each day
  {tibble(time_stamp = round_date(., unit = ""day""))} %>% 
  distinct() %>% 
  mutate(is_sunday = wday(time_stamp) == 1,
         new_month = is_new_month(time_stamp) == 2,
         new_month = case_when(is.na(new_month) ~ TRUE,
                               TRUE ~ new_month)) %>% 
  filter(is_sunday) %>% 
  select(-is_sunday) %>% 
  # x coordinates
  mutate(x = c(rep(m_side, 14),
               rep(.5 + m_small_side, 14)) %>%
           c(.,.) %>% .[1:53],
         # y coordinates
         y = c(seq(from = 1 - m_tb,
                   to = .5 + m_small_tb,
                   length.out = block_rows) %>% c(.,.),
               seq(from = .5 - m_small_tb, to = m_tb,
                   length.out = block_rows) %>% c(.,.))  %>% .[1:53])


# and set a function to plot them
add_date_annos <- function(time_stamp, new_month, x, y) {
  if(new_month) {
    grid.text(label = paste(month(time_stamp, label = TRUE),
                            mday(time_stamp)),
              x = x,
              y = y,
              vjust = .5,
              hjust = .5,
              gp = gpar(col = ""grey20"",
                        fontsize = 18,
                        fontface = ""italic"",
                        fontfamily = ""Times New Roman""))
    return(NULL) 
  } else {
    return(NULL)
  }
}
```

# Plot in SVG and PNG

```{r}
# Very slow output on the screen, don't know why  ------------------------

# grid.newpage()
# 
# p_tibble %>% pmap(plot_to_vp)


plot_all <- function() {
  grid.newpage()
  # background
  grid.rect(gp = gpar(fill = bg_col))
  # Title
  grid.text(""365 Days Cycling in Seattle"",
            x = m_side,
            y = 1 - m_tb/2,
            gp = gpar(col = ""grey20"",
                      fontsize = 60,
                      fontface = ""italic"",
                      fontfamily = ""Times New Roman""),
            hjust = 0,
            vjust = 0)
  # subtitle
  grid.text(str_wrap(""Bicycle traffic crossing 7 detection points in Seattle in 2017."") %>% 
              paste(str_wrap("" Also an exercise on making heavily facetted plots with ggplot2 and
                   grid by Otho Mantegazza."",
                   width = 100), sep = ""\n""),
            x = m_side + .02, 
            y = 1 - m_tb*.72,
            gp = gpar(col = ""grey20"",
                      fontsize = 27,
                      fontface = ""italic"",
                      fontfamily = ""Times New Roman"",
                      lineheight = .87),
            hjust = 0,
            vjust = 0)
  # mid line
  grid.lines(x = unit(c(m_side*1.5, 1 - m_side*1.5), ""npc""),
             y = unit(c(.5, .5), ""npc""))
  # week names
  w_names %>% pmap(add_weeknames)
  # date annotation
  date_annos %>% pmap(add_date_annos)
  # plots
  p_tibble %>% pmap(plot_to_vp)
  # caption
  grid.text(label = ""Data from the Seattle Department of Transportation\nplot by @othomn"",
            x = 1 - m_side, 
            y = m_tb*.5,
            gp = gpar(col = ""grey20"",
                      fontsize = 27,
                      fontface = ""italic"",
                      fontfamily = ""Times New Roman"",
                      lineheight = .87),
            hjust = 1,
            vjust = 0)
  
}

# it's much faster on SVG ------------------------------------------------------


svglite::svglite(file = ""plots/2-14-seattle-bikes-draft-grid-2.svg"",
                 height = 33.1,
                 width = 23.4 )
plot_all()
dev.off()

png(filename = ""plots/2-14-seattle-bikes-draft-grid-2.png"", 
    height = 33.1,
    width = 23.4,
    units = ""in"",
    res = 300)
plot_all()
dev.off()

```

","2019-14"
"786",676,"https://github.com/othomantegazza/code-tidytuesday","othomantegazza","code-tidytuesday","2-16-economist-post.R","library(tidyverse)
library(rlang)
library(grid)
library(wesanderson)

# Get and clean data ------------------------------------------------------


dat_url <- paste0(""https://raw.githubusercontent.com/"",
              ""rfordatascience/tidytuesday/master/data/"",
              ""2019/2019-04-16/Economist_women-research.csv"")


dat_path <- ""data/2-16-economist-post.Rdata""

if(!file.exists(dat_path)) {
  dat_raw <- readr::read_csv(dat_url)
  
  research_names <- c(""country"",
                      ""Health sciences"",
                      ""Physical sciences"",
                      ""Engineering"",
                      ""Computer science, maths"",
                      ""Women inventores"")
  
  dat <- 
    dat_raw %>% 
    na.omit() %>% 
    set_names(research_names) %>% 
    filter(country != ""Country"") %>% 
    gather(field, percent_women, `Health sciences`:`Women inventores`)
    
  
  save(dat, file = dat_path)
} else {
  load(dat_path)
}


# order country and fields ------------------------------------------------

dat <- 
  dat %>% 
  mutate(percent_women = as.numeric(percent_women),
         # order countries
         country = factor(country, levels = c(""Portugal"", ""Brazil"", ""Australia"",
                                               ""Canada"", ""France"", ""EU28"",
                                               ""Denmark"", ""Mexico"", ""United States"",
                                               ""United Kingdom"", ""Chile"", ""Japan"")),
         # order fields
         field = factor(field, levels = c(""Women inventores"", ""Computer science, maths"",
                                          ""Engineering"", ""Physical sciences"",
                                          ""Health sciences""))) %>%
  arrange(country, field) 

# define grid parameters ----------------------------------------------------

bg <- ""white""
text_color <- ""grey30""

left_margin <- .3
right_margin <- .1
u_margin <- .2

nrow(dat)
# 60

y_ids <- dat %>% pull(country) %>% levels() 
y_n <- y_ids  %>% length()
# 12

x_ids <- dat %>% pull(field) %>% levels()
x_n <- x_ids  %>% length()
# 5

# a grid 12 x 5

width <- (1 - left_margin - right_margin) / x_n
height <- (1 - 2*u_margin) / y_n

p_font <- ""Helvetica""  #""Times New Roman""
p_fontface <- ""plain""
p_fontsize <- 22

pal <- 
  wes_palette(""Darjeeling1"", n = 5) %>%
  as.character() %>% 
  c(""grey90"") %>% 
  set_names(x_ids %>% c(""grey""))

# loop plots --------------------------------------------------------------

plot_circle <- function(percent_women,
                        field,
                        xdown = -1) {
  p <- 
    tibble(gender = c( ""male"", ""female"") %>% factor(levels = c(""male"", ""female"")),
           field = c(""grey"", field %>% as.character) %>% as_factor(),
           value = c(1 - percent_women, percent_women)) %>%  
    ggplot() +
    geom_bar(aes(x = 1,
                 y = value,
                 fill = field),
             stat = ""identity"",
             colour = bg,
             size = 2) + 
    geom_text(data = . %>% 
                filter(gender == ""female""),
              aes(x = xdown, y = 0,
                  label = paste0(""."", value*100)),
              colour = text_color,
              size = 10,
              fontface = ""italic"") +
    coord_polar(theta = ""y"") +
    # scale_fill_viridis_d(begin = .1, end = .9, guide = FALSE) +
    scale_fill_manual(values = pal, guide = FALSE) +
    lims(x = c(xdown, 1.45)) +
    theme_void() +
    theme(plot.margin = margin(0,0,0,0, unit = ""in""))
  
  return(p)
}

# dat_plots <- 
#   dat %>% 
#   mutate(plots = percent_women %>% map(~plot_circle(., xdown = -.9)))
# dat_plots %>% pull(plots) %>% .[[2]]

p_list <- 
  dat %>%
  select(field, percent_women) %>% 
  mutate(xdown = -.9) %>% 
  pmap(plot_circle) 

p_list[[1]]

dat_plots <- 
  dat %>% 
  mutate(plots = p_list)




# Utility functions -------------------------------------------------------

add_fields <- function(x, label) {
  grid.text(label = label %>% str_wrap(width = 10),
            x = x,
            y = 1 - u_margin*.85,
            vjust = 0,
            gp = gpar(col = text_color,
                      fontsize = p_fontsize,
                      fontface = p_fontface,
                      fontfamily = p_font, 
                      lineheight = .9))
  return(NULL)
}

add_countries <- function(y, label) {
  grid.text(label = label,
            x = left_margin - .07,
            y = y,
            vjust = 0,
            hjust = 1,
            gp = gpar(col = text_color,
                      fontsize = p_fontsize,
                      fontface = p_fontface,
                      fontfamily = p_font))
  return(NULL)
}


# plot on grid ------------------------------------------------------------

plot_to_vp <- function(p, x, y, width, height) {
  print(p,
        vp = viewport(x = x, y = y, width = width, height = height))
  return(NULL)
}


plot_all <- function() {
  
  # title 
  grid.text(""Still a man's world"",
            x = .5,
            y = 1 - u_margin/3,
            gp = gpar(col = text_color,
                      fontsize = 60,
                      fontface = p_fontface,
                      fontfamily = p_font),
            hjust = .5,
            vjust = 0)
  
  # subtitle
  grid.text(str_wrap(""Percentage of women author of papers
          (indexed in scopus from 2011 to 2015)"", width = 45),
            x = .5,
            y = 1 - u_margin/2,
            gp = gpar(col = text_color,
                      fontsize = 40,
                      fontface = p_fontface,
                      fontfamily = p_font,
                      lineheight = .9),
            hjust = .5,
            vjust = .5)
  
  # caption
  grid.text(str_wrap('Source: ""Gender in the Global Research Landscape"",
                     by Elsevier; The Economist | Plot by Otho Mantegazza
                     (@othomn) | A take on the blog post by Sarah Leo ""Mistakes,
                     we have drawn a few"".', width = 60),
            x = .5,
            y = u_margin/1.8,
            gp = gpar(col = text_color,
                      fontsize = 30,
                      fontface = p_fontface,
                      fontfamily = p_font,
                      lineheight = .9),
            hjust = .5,
            vjust = .5)
  
  
  
  # field
  tibble(x = seq(left_margin, 1 - right_margin, length.out = x_n + 1)[1:x_n],
         label = x_ids) %>% 
    pmap(add_fields)
  
  # countries
  tibble(y =  seq(1 - u_margin, u_margin, length.out = y_n),
         label = y_ids) %>% 
    pmap(add_countries)
  
  # plots in grid
  dat_plots %>% 
    mutate(x = seq(left_margin, 1 - right_margin, length.out = x_n + 1)[1:x_n] %>% rep(y_n),
           y = seq(1 - u_margin, u_margin, length.out = y_n) %>% rep(each = x_n)) %>% 
    transmute(p = .data$plots,
              x = .data$x,
              y = .data$y,
              width = width,
              height = height) %>% 
    pmap(plot_to_vp)
}

svglite::svglite(file = ""plots/2-16-economist-post.svg"",
                 height = 32,
                 width = 15)
plot_all()
dev.off()

png(filename = ""plots/2-16-economist-post.png"", 
    height = 32,
    width = 15,
    units = ""in"",
    res = 300)
plot_all()
dev.off()
","2019-16"
"787",677,"https://github.com/othomantegazza/code-tidytuesday/blob/master/20-trolls.R","othomantegazza","code-tidytuesday","20-trolls.R","library(tidyverse)
library(ggridges)

# Download data -----------------------------------------------------------
# some rows are lost because external_author_id is parsed badly

if(!file.exists(""data/20-rtrolls.Rdata"")) {
  dat <- set_names(x = paste(""https://github.com/fivethirtyeight/russian-troll-tweets/blob/master/IRAhandle_tweets_"",
                             1:9,
                             "".csv?raw=true"",
                             sep = """"), 
                   nm = as.character(1:9)) %>%
    map(read_csv) %>%
    purrr::reduce(bind_rows)
  save(dat, file = ""data/20-rtrolls.Rdata"")
} else {
  load(""data/20-rtrolls.Rdata"")
}

# dat <- read_csv(file = ""data/IRAhandle_tweets_1.csv"")


# Get top types ------------------------------------------------------------

top_accounts <- dat %>%
  group_by(account_type) %>%
  tally() %>%
  arrange(desc(n)) %>%
  top_n(6) %>%
  pull(account_type)


# plot top accounts -------------------------------------------------------

jpeg(filename = ""plots/rtrolls.jpg"",
     width = 7, 
     height = 5,
     units = ""in"",
     res = 200)
ggplot(dat %>%
         filter(account_type %in% top_accounts,
                post_type != ""RETWEET"") %>%
         # mutate(followers = log10(followers)) %>%
         filter(followers >= 1),
       aes(x = followers,
           y = account_type)) +
       # )) +
  ggridges::geom_density_ridges(alpha = .5, fill = ""lightblue"") +
  # geom_histogram() +
  scale_x_log10() +
  # facet_grid(account_type ~ ., scales = ""free_y"") +
  theme_bw() +
  ggtitle(""Followers of Different IRA Account Types"",
          subtitle = ""Excluding retweets"") +
  xlab(""Number of Followers at Time of the Tweet (log scale)"") +
  ylab(""Specific Account Type (by Linvill and Warren)"")
dev.off()
","2018-20"
"788",678,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week11.R","# week 11 - FIFA
# original article https://fivethirtyeight.com/features/how-to-break-fifa/
# data source https://github.com/rudeboybert/fivethirtyeight
# https://github.com/rfordatascience/tidytuesday/blob/master/data/week11_fifa_audience.csv


library(tidyverse)
library(skimr)
library(ggrepel)


# read data
dat <- read.csv('data/week11_fifa_audience.csv')


# explore data
head(dat)
dim(dat)
skim(dat)
unique(dat$confederation)
unique(dat$country)


# group, pull out top 10 in each confederation by tv audience share, reorder factors for nicer exploratory plots
dat2 <- dat %>%
  group_by(confederation) %>%
  top_n(10, tv_audience_share) %>%
  ungroup() %>%
  mutate(country = fct_reorder(country, tv_audience_share, .desc=TRUE))


# rough exploratory plot
ggplot(dat2, aes(x = country, y = tv_audience_share)) +
  geom_col() +
  facet_wrap(~confederation, ncol = 1, scales = ""free"") +
  ggtitle(""TV Audience Share"", subtitle = ""ordered by tv audience share"") +
  theme_minimal()
ggsave(""output/wk11_exploratoryplot.png"", width = 6, height = 8, units = ""in"")



ggplot(dat2, aes(x = country, y = population_share)) +
  geom_col() +
  facet_wrap(~confederation, ncol = 1, scales = ""free"") +
  ggtitle(""Population Share"", subtitle = ""ordered by tv audience share"") +
  theme_minimal()

ggplot(dat2, aes(x = country, y = gdp_weighted_share)) +
  geom_col() +
  facet_wrap(~confederation, ncol = 1, scales = ""free"") +
  ggtitle(""GDP-weighted Share"", subtitle = ""ordered by tv audience share"") +
  theme_minimal()

ggplot(dat, aes(y = tv_audience_share, x = population_share, color = confederation)) +
  geom_point(size = 3, alpha = 0.5) +
  ggtitle(""Do countries with higher populations watch more soccer?"") +
  theme_minimal()




## do countries with higher populations watch more soccer?
ggplot(dat2, aes(y = tv_audience_share, x = population_share, 
                 color = confederation)) +
    geom_point(size = 2.5, alpha = 0.7) +
    geom_text_repel(data = subset(dat2, population_share >= 1.9), 
                    aes(label = country)) +
    labs(title = ""Do countries with higher populations watch more soccer?"", 
            subtitle = ""top 10 countries from each confederation by tv audience share"",
         x = ""population share"",
         y = ""tv audience share"") +
    theme_minimal()
ggsave(""output/wk11_audshare-v-popshare.png"")




## with log scales
ggplot(dat2, aes(y = tv_audience_share, x = population_share, 
                 color = confederation)) +
    geom_point(size = 2.5, alpha = 0.7) +
    geom_text_repel(data = subset(dat2, population_share > 1), 
                    aes(label = country)) +
    scale_y_log10() +
    scale_x_log10() +
    labs(title = ""Do countries with higher populations watch more soccer?"", 
         subtitle = ""top 10 countries from each confederation by tv audience share \nlabels on countries where population share is > 1"",
         x = ""population share"",
         y = ""tv audience share"") +
    theme_minimal()
ggsave(""output/wk11_audshare-v-popshare_log.png"")



## using RColorBrewer
## and a square root scale
ggplot(dat2, aes(y = tv_audience_share, x = population_share, 
                 color = confederation)) +
    geom_point(size = 2.5, alpha = 0.7) +
    geom_text_repel(data = subset(dat2, population_share > 1.9), 
                    aes(label = country)) +
    scale_y_sqrt() +
    scale_x_sqrt() +
    scale_color_brewer(type = ""qual"", palette = ""Dark2"") +
    labs(title = ""Do countries with higher populations watch more soccer?"", 
         subtitle = ""top 10 countries from each confederation by tv audience share"",
         x = ""population share"",
         y = ""tv audience share"") +
    theme_minimal()


## do that on unfiltered data
ggplot(dat, aes(y = tv_audience_share, x = population_share, 
                 color = confederation)) +
    geom_point(size = 2.5, alpha = 0.7) +
    geom_text_repel(data = subset(dat2, population_share > 1.5), 
                    aes(label = country)) +
    scale_y_sqrt() +
    scale_x_sqrt() +
    scale_color_brewer(type = ""qual"", palette = ""Dark2"") +
    labs(title = ""Do countries with higher populations watch more soccer?"", 
         x = ""population share"",
         y = ""tv audience share"") +
    theme_minimal()
","Other-11"
"789",679,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week13.R","# week 13

library(tidyverse)
library(skimr)

dat <- read.csv(""data/week13_alcohol_global.csv"")

skim(dat)
head(dat)


# reshape so I can group and make faceted plots
# top_n to pull out 40 countries with highest consumption
# make country a factor
# gather() to put it in long format
dat2 <- dat %>%
    rename(beer = beer_servings,
           wine = wine_servings,
           spirits = spirit_servings) %>%
    top_n(40, total_litres_of_pure_alcohol) %>%  
    mutate(country = as.factor(country)) %>%  
    gather(key = ""alc_type"", value = ""value"", 
           -country, -total_litres_of_pure_alcohol) 


# scatterplot matrix
# (everything against everything else)
plot(dat, main = ""Scatterplot Matrix"")


# exploratory bar chart
ggplot(dat2, aes(x = alc_type, y = value, fill = alc_type)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~country, ncol = 5) +
    scale_fill_brewer(type = ""qual"", palette = ""Paired"") +
    theme_bw() +
    labs(title = ""Amount of alcohol consumed by type"", 
         subtitle = ""40 countries with highest total litres of pure alcohol"", 
         x = ""alcohol type"", 
         y = ""# servings"")


# hm, how many countries have beer as top? spirits? wine?
# order within each country, and rank?
# not sure what to plot from this.... 

# thanks, stackoverflow, for dense_rank
# https://stackoverflow.com/questions/26106408/create-a-ranking-variable-with-dplyr

dat3 <- dat %>%
    rename(beer = beer_servings,
           wine = wine_servings,
           spirits = spirit_servings) %>%
    gather(key = ""alc_type"", value = ""value"", 
           -country, -total_litres_of_pure_alcohol) %>%
    group_by(country) %>%
    mutate(alc_rank = dense_rank(desc(value))) %>%
    arrange(country, alc_rank)

rank_summary <- dat3 %>%
    ungroup() %>%
    summarize()
","Other-13"
"790",680,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week13_loopingcolors.Rmd","---
title: ""Week 13 Color Palettes - looping through paletteer""
output: 
    github_document: 
        toc: yes
    html_notebook: 
        toc: yes
---

# Setup and Data import

## libraries

```{r}
# week 13

library(tidyverse)
library(skimr)
library(paletteer)
```


## import and look at

```{r}
dat <- read.csv(""../data/week13_alcohol_global.csv"")

skim(dat)
head(dat)
```


## reshape

Only select top 4 countries for easier-to-see plots
```{r}
# reshape so I can group and make faceted plots
# top_n to pull out 40 countries with highest consumption
# make country a factor
# gather() to put it in long format
dat2 <- dat %>%
    rename(beer = beer_servings,
           wine = wine_servings,
           spirits = spirit_servings) %>%
    top_n(4, total_litres_of_pure_alcohol) %>%  
    mutate(country = as.factor(country)) %>%  
    gather(key = ""alc_type"", value = ""value"", 
           -country, -total_litres_of_pure_alcohol) 
```


## Bar chart with ggplot

```{r}

# exploratory bar chart
p <- ggplot(dat2, aes(x = alc_type, y = value, fill = alc_type)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~country, ncol = 2) +
    theme_bw() +
    labs(x = ""alcohol type"", 
         y = ""# servings"")
```


```{r}
print(p)
```


# Set up the graphing function

## Pull out the data frame with package and palette names  

```{r}
palettes <- palettes_d_names
```

## Make a function for plotting  

```{r}
plot_fun <- function(base_plot, col_pkg, col_pal) {
    Title <- paste(col_pkg, col_pal)
    out <- base_plot +
        scale_fill_paletteer_d(!!ensym(col_pkg), !!ensym(col_pal)) +
        ggtitle(Title)
    return(out)
}
```

## Use purrr::map2 to loop through it  

```{r}
# p is my base plot from up above
map2(palettes$package, palettes$palette, ~ plot_fun(p, .x, .y))
```
","Other-13"
"791",681,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week13_morecolors.Rmd","---
title: ""Tidy Tuesday Week 13""
output: 
    github_document: 
        toc: yes
    html_notebook: 
        toc: yes
---

Mostly playing with color palettes here.

# Setup and Data import

## libraries

```{r}
# week 13

library(tidyverse)
library(skimr)
library(paletteer)
```

## import and look at

```{r}
dat <- read.csv(""../data/week13_alcohol_global.csv"")

skim(dat)
head(dat)
```


## reshape

Only select top 4 countries for easier-to-see plots
```{r}
# reshape so I can group and make faceted plots
# top_n to pull out 40 countries with highest consumption
# make country a factor
# gather() to put it in long format
dat2 <- dat %>%
    rename(beer = beer_servings,
           wine = wine_servings,
           spirits = spirit_servings) %>%
    top_n(4, total_litres_of_pure_alcohol) %>%  
    mutate(country = as.factor(country)) %>%  
    gather(key = ""alc_type"", value = ""value"", 
           -country, -total_litres_of_pure_alcohol) 
```


# Plotting  

## Scatterplot Matrix

```{r}
# scatterplot matrix
# (everything against everything else)
plot(dat, main = ""Scatterplot Matrix"")
```

## Bar chart with ggplot
```{r}

# exploratory bar chart
p <- ggplot(dat2, aes(x = alc_type, y = value, fill = alc_type)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~country, ncol = 2) +
    theme_bw() +
    labs(title = ""Amount of alcohol consumed by type"", 
         subtitle = ""4 countries with highest total litres of pure alcohol"", 
         x = ""alcohol type"", 
         y = ""# servings"")
```

Default color palette
```{r}
p
```


### RColorBrewer

scale_fill_brewer from Paired palette

```{r}
p + scale_fill_brewer(type = ""qual"", palette = ""Paired"")
```


Dark2 palette

```{r}
p + scale_fill_brewer(type = ""qual"", palette = ""Dark2"")
```


### Paletteer package  

#### Discrete, non-dynamic palettes

Nord aurora
```{r}
p + scale_fill_paletteer_d(nord, aurora)
```


Nord polarnight
```{r}
p + scale_fill_paletteer_d(nord, polarnight)
```

Nord snowstorm
```{r}
p + scale_fill_paletteer_d(nord, snowstorm)
```

quickpalette beach
```{r}
p + scale_fill_paletteer_d(quickpalette, beach)
```

quickpalette waterfall
```{r}
p + scale_fill_paletteer_d(quickpalette, waterfall)
```

quickpalette sunset
```{r}
p + scale_fill_paletteer_d(quickpalette, sunset)
```


rcartocolor ag_Sunset
```{r}
p + scale_fill_paletteer_d(rcartocolor, ag_Sunset)
```


rcartocolor TealRose
```{r}
p + scale_fill_paletteer_d(rcartocolor, TealRose)
```


rcartocolor TealGrn
```{r}
p + scale_fill_paletteer_d(rcartocolor, TealGrn)
```

rcartocolor Geyser
```{r}
p + scale_fill_paletteer_d(rcartocolor, Geyser)
```

","Other-13"
"792",682,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week2.R","# tidy tuesday number 2
# (my first one)
# 2018-04-10 kac

library(tidyverse)
library(readxl)
library(skimr)

# read in data
dat <- read_excel(""data/tidy_tuesday_week2.xlsx"")
skim(dat)

# get it into long format
dat_long <- dat %>%
    gather(key = position, value = salary, -year) %>%
    mutate(salary_millions = salary/1000000) %>%
    group_by(position, year)

# violin plot to see all salaries
ggplot(dat_long, aes(x = year, y = salary_millions, col = position)) +
    geom_violin(size = 0.70, draw_quantiles = c(0.25, 0.5, 0.75)) +
    facet_wrap(~position, nrow = 3) +
    theme_bw() +
    theme(legend.position=""none"") +
    ggtitle(""NFL salaries by position over time"") +
    xlab(""Year"") +
    ylab(""Salary, millions of $"")

# subset to just the top 16 players in each position
dat_top <- dat %>%
    gather(key = position, value = salary, -year) %>%
    mutate(salary_millions = salary/1000000) %>%
    group_by(position, year) %>%
    top_n(16, wt = salary_millions) %>%
    ungroup()
    
# plot just the top ones, with a smoothing line
ggplot(dat_top, aes(x = year, y = salary_millions, col = position)) +
    geom_point(size = 2, alpha = 0.3) +
    geom_smooth(method = ""loess"", se = FALSE, size = 1.5) +
    facet_wrap(~position, nrow = 3) +
    theme_bw() +
    theme(legend.position=""none"") +
    ggtitle(""Top 16 NFL salaries by position over time"") +
    xlab(""Year"") +
    ylab(""Salary, millions of $"")
","Other-2"
"793",683,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week3.R","# tidytuesday week 3
# 4-17-2018 kac

library(tidyverse)
library(readxl)
library(skimr)

dat <- read_excel(""data/global_mortality.xlsx"")

# make it long for grouping purposes
dat_long <- dat %>%
    gather(key = cause, value = pct_contribution, -country, -country_code, -year) %>%
    mutate(year = as.numeric(year)) 

dat_long %>%
    filter(country_code == 'USA') %>%
    ggplot(aes(x = year, y = pct_contribution)) +
        geom_point() +
    geom_line() +
    facet_wrap(~cause, scales = ""free_y"")
    

# things I want to do:
# get rid of (%) at the end of the cause names
# lump smaller mortality causes together into an ""other"" category
# select a given country in the plotting command","Other-3"
"794",684,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week4.R","# week 4
# 4-23-2018 kac

library(tidyverse)
library(skimr)

dat <- read.csv(""data/week4_australian_salary.csv"")
skim(dat)

# pull out the top 10 occupations for women
# this will be used to filter all data for these jobs
dat_top_women <- dat %>%
    filter(gender == ""Female"",
           gender_rank <= 10) %>%
    select(occupation)

# pull out those occupations for both genders;
# spread and put in order by women's salaries;
# gather again for easier plotting;
# relevel the gender factor to make it show up the way I want
dat_top_both <- dat %>%
    filter(occupation %in% dat_top_women$occupation) %>%
    select(occupation, gender, average_taxable_income) %>%
    spread(key = gender, value = average_taxable_income) %>%
    mutate(occupation = fct_reorder(occupation, Female, .desc = FALSE)) %>%
    gather(key = gender, value = average_taxable_income, -occupation) %>%
    mutate(gender = fct_relevel(gender, ""Female"", ""Male""))

# plot it
ggplot(dat_top_both) +
    geom_col(aes(x = occupation, y = average_taxable_income/1000, 
                 fill = gender), 
             col = ""gray50"", position = position_dodge(width = -0.3), 
             width = 0.9) +
    ggtitle(""Gender differences in income in Australia"", 
            subtitle = ""10 top-paying professions for women"") +
    xlab(""Occupation"") +
    ylab(""Mean salary \n(thousands of dollars)"") +
    scale_fill_manual(values = c(""cadetblue3"", ""gray80"")) +
    theme_minimal() +
    coord_flip()



# for overlapping bars:
# spread and put in order by women's salaries;
dat_top_overlap <- dat %>%
    filter(occupation %in% dat_top_women$occupation) %>%
    select(occupation, gender, average_taxable_income) %>%
    spread(key = gender, value = average_taxable_income) %>%
    mutate(occupation = fct_reorder(occupation, Female, .desc = FALSE))
    

# plot it
ggplot(dat_top_overlap) +
    geom_col(aes(x = occupation, y = Male/1000, fill = ""Male""),
             col = ""gray50"", width = 0.8) +
    geom_col(aes(x = occupation, y = Female/1000, fill = ""Female""), 
             col = ""gray50"", width = 0.5) +
    ggtitle(""Gender differences in income in Australia"", 
            subtitle = ""10 top-paying professions for women"") +
    xlab(""Occupation"") +
    ylab(""Mean salary \n(thousands of dollars)"") +
    scale_fill_manual(name = ""gender"",
                      values = c(""Female"" = ""cadetblue3"", ""Male"" = ""gray80"")) +
    theme_minimal() +
    coord_flip()
","Other-4"
"795",685,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week5.R","# week 5
# 5/2/18 (wednesday) kac

library(tidyverse)

dat <- read.csv(""data/acs2015_county_data.csv"")
","Other-5"
"796",686,"https://github.com/swmpkim/tidytuesday/tree/master/R","swmpkim","tidytuesday","R/week8.R","## file change for git purposes

# week 8
library(tidyverse)

dat <- read.csv(""data/week8_honeyproduction.csv"")
head(dat)

# which states were the top 10 producers in each year?
topbyyr <- dat %>%
    group_by(year) %>%
    top_n(10, totalprod) %>%
    ungroup()
n_distinct(topbyyr$year)
n_distinct(topbyyr$state)

# which states show up the most?
topstates <- topbyyr %>%
    group_by(state) %>%
    summarize(years = n_distinct(year)) %>%
    arrange(desc(years), state)

# seven states show up in the top 10 in all 15 years, and WI shows up in 14 of them. So I'll look at 8 states:
# CA, FL, MN, MT, ND, SD, TX, WI

statestouse <- topstates %>%
    filter(years >= 14) %>%
    select(state)

dat_top <- dat %>%
    filter(state %in% statestouse$state)

# what is price per lb by year in each of those states?

ggplot(dat_top, aes(x = year, y = priceperlb, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    facet_wrap(~state, ncol = 1) +
    theme_bw()

# or don't facet
ggplot(dat_top, aes(x = year, y = priceperlb, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    theme_bw()
## since the mid-2000s, WI seems to be getting higher price per pound than other states.
## I wonder what happens if I don't filter to top-producing states?

ggplot(dat, aes(x = year, y = priceperlb, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    theme_bw()
## wow, there are some crazy things going on in some states, but it's hard to pick out what's what. Back to faceting!
ggplot(dat, aes(x = year, y = priceperlb, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    facet_wrap(~state, ncol = 4) +
    theme_bw()

# what is total product value by year in each state?
# the ones that aren't high-producers are pretty interesting in terms of price per pound; I wonder if that holds here?

ggplot(dat, aes(x = year, y = prodvalue, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    facet_wrap(~state, ncol = 4) +
    theme_bw()

# the Dakotas and California are pretty interesting


# what about just the top producers, what's the value?
ggplot(dat_top, aes(x = year, y = prodvalue, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    theme_bw()

# still a little hard to tell what's going on, so I'm cutting it to interesting states:
dat_reduced <- dat %>%
    filter(state %in% c(""CA"", ""ND"", ""SD"", ""FL"", ""WI""))
ggplot(dat_reduced, aes(x = year, y = priceperlb, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    theme_bw()
ggplot(dat_reduced, aes(x = year, y = prodvalue, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    theme_bw()

# what about overall average price per pound, and annual total production?
dat_summarized <- dat %>%
    group_by(year) %>%
    summarize(meanprice = mean(priceperlb, na.rm = TRUE),
              totalvalue = sum(prodvalue))

# add those in to the other graphics:
ggplot(dat_reduced, aes(x = year, y = priceperlb, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    geom_line(data = dat_summarized, aes(x = year, y = meanprice), color = ""darkslategray"", size = 2, lty = 2, alpha = 0.7) +
    theme_bw()
ggplot(dat_reduced, aes(x = year, y = prodvalue, color = state)) +
    geom_point() +
    geom_line(size = 1) +
    geom_line(data = dat_summarized, aes(x = year, y = totalvalue/10), color = ""darkslategray"", size = 2, lty = 2, alpha = 0.7) +
    theme_bw()

# this might be a situation for stacked bars
ggplot(dat_reduced, aes(x = year, y = prodvalue/100000, fill = state)) +
    geom_col() +
    theme_bw()
# I kind of want to make a map
# with different color levels for... I don't know.","Other-8"
"797",906,"https://github.com/davidcarayon/TidyTuesdaySubmissions/blob/master/week_31_video_games.R","davidcarayon","TidyTuesdaySubmissions","week_31_video_games.R","library(tidyverse)
library(janitor)
library(ggridges)
library(lubridate)
library(cowplot)

# clean dataset from lizawood's github
url <- ""https://raw.githubusercontent.com/lizawood/apps-and-games/master/PC_Games/PCgames_2004_2018_raw.csv""

# read in raw data
raw_df <- url %>%
  read_csv() %>%
  janitor::clean_names()

# clean up some of the factors and playtime data
clean_df <- raw_df %>%
  mutate(
    price = as.numeric(price),
    score_rank = word(score_rank_userscore_metascore, 1),
    average_playtime = word(playtime_median, 1),
    median_playtime = word(playtime_median, 2),
    median_playtime = str_remove(median_playtime, ""\\(""),
    median_playtime = str_remove(median_playtime, ""\\)""),
    average_playtime = 60 * as.numeric(str_sub(average_playtime, 1, 2)) +
      as.numeric(str_sub(average_playtime, 4, 5)),
    median_playtime = 60 * as.numeric(str_sub(median_playtime, 1, 2)) +
      as.numeric(str_sub(median_playtime, 4, 5)),
    metascore = as.double(str_sub(score_rank_userscore_metascore, start = -4, end = -3))
  ) %>%
  select(-score_rank_userscore_metascore, -score_rank, -playtime_median) %>%
  rename(publisher = publisher_s, developer = developer_s) %>%
  mutate(release_date = mdy(release_date))

library(ggdark)
library(ggforce)


## Custom function to find the max value for each owners category, to create an appropriately ordered factor.

return_max <- function(str) {
  val <- unlist(str_split(str, ""\\..""))[2] %>%
    str_trim() %>%
    str_remove_all("","")
  return(val)
}

## Vector of levels in the right order
levs <- clean_df %>%
  distinct(owners) %>%
  mutate(max_owners = as.numeric(map_chr(owners, return_max))) %>%
  arrange(max_owners) %>%
  pull(owners)

## Modifying the dataframe
clean_df$owners <- factor(clean_df$owners, levels = levs)


# Flipped violin plot -----------------------------------------------------

## Separate date with median values
median_values <- clean_df %>%
  group_by(owners) %>%
  summarise(
    med = median(metascore, na.rm = TRUE),
    mean = median(metascore, na.rm = TRUE)
  )


g1 <- ggplot(clean_df, aes(x = owners, y = metascore)) +
  geom_boxplot(aes(color = owners)) +
  geom_point(data = median_values, aes(x = owners, y = med, fill = owners), shape = 23, size = 4, color = ""black"") +
  dark_mode() +
  guides(fill = FALSE, color = FALSE) +
  coord_flip() +
  labs(y = ""Metascore"", x = ""# of owners"", title = ""Metascore values according to \nthe number of owners"") +
  theme(
    axis.text = element_text(family = ""mono"", size = 11),
    axis.title = element_text(family = ""mono"", face = ""bold"", size = 15),
    plot.title = element_text(family = ""mono"", face = ""bold"", size = 17)
  ) +
  scale_color_viridis_d(option = ""plasma"") +
  scale_fill_viridis_d(option = ""plasma"")


# Geom_tiles  -------------------------------------------------------------

## Credits to @Argaadya1 for inspiration.

g2 <- clean_df %>%
  mutate(
    release_year = year(release_date),
    release_month = month(release_date)
  ) %>%
  group_by(release_year, release_month) %>%
  summarise(
    med_price = median(price, na.rm = TRUE),
    med_playtime = median(average_playtime, na.rm = TRUE),
    mean_metascores = mean(metascore, na.rm = TRUE)
  ) %>%
  ggplot(aes(x = release_month, y = release_year)) +
  geom_tile(aes(fill = mean_metascores), color = ""black"") +
  scale_fill_gradientn(colors = c(""#00AFBB"", ""#E7B800"", ""#FC4E07"")) +
  theme_ridges() +
  scale_x_continuous(breaks = seq(1, 12, 1), labels = month.abb) +
  scale_y_continuous(breaks = seq(2004, 2020, 2)) +
  theme(
    panel.background = element_rect(fill = ""black""),
    plot.background = element_rect(fill = ""black""),
    legend.background = element_rect(fill = ""black""),
    text = element_text(colour = ""white"", family = ""mono""),
    axis.text = element_text(colour = ""white"", family = ""mono""),
    axis.title = element_text(colour = ""white"", family = ""mono"", face = ""bold""),
    panel.grid = element_blank()
  ) +
  labs(x = ""Release month"", y = ""Release year"", fill = ""Metascore"", title = ""Average metascore of games according to month \nand year of release"", caption = ""Data provided by @brightcdns | Plot by @david_carayon"")



# Line plot ---------------------------------------------------------------

g3 <- clean_df %>%
  mutate(release_year = year(release_date)) %>%
  group_by(release_year) %>%
  summarise(
    med_price = median(price, na.rm = TRUE),
    med_playtime = median(average_playtime, na.rm = TRUE),
    mean_metascores = mean(metascore, na.rm = TRUE)
  ) %>%
  ggplot(aes(x = release_year, y = mean_metascores)) +
  geom_line(color = ""green2"") +
  geom_smooth(color = ""gold"", se = FALSE, size = 2) +
  geom_point(color = ""white"", shape = 24, aes(fill = mean_metascores), size = 5) +
  scale_fill_viridis_c(option = ""plasma"") +
  geom_curve(aes(x = 2010, y = 77.3, xend = 2005.2, yend = 78.5), curvature = 0.2, arrow = arrow(length = unit(2, ""mm"")), color = ""white"") +
  annotate(""label"", x = 2010, y = 77.2, label = ""Games released in 2005 have an avg.\n metascore of 78.3/100"", color = ""white"", fill = ""black"", family = ""mono"", size = 4) +
  dark_mode(.theme = theme_classic()) +
  theme(
    axis.text = element_text(size = 13, family = ""mono""),
    axis.title = element_text(size = 15, face = ""bold"", family = ""mono""),
    plot.title = element_text(size = 17, family = ""mono"", face = ""bold""),
    plot.subtitle = element_text(size = 15, family = ""mono"", face = ""bold"")
  ) +
  labs(x = ""Release year"", y = ""Average metascore"", title = ""Average metascore over the years"") +
  guides(fill = FALSE)



# Final plot grid ---------------------------------------------------------
plot_grid(g3, plot_grid(g1, g2), ncol = 1, rel_heights = c(1.45, 1)) +
  ggsave(""README_figs/videogames_tidytuesday.png"", dpi = ""retina"", width = 15.7, height = 9.47)
","Other-31"
"798",907,"https://github.com/davidcarayon/TidyTuesdaySubmissions/blob/master/week_27_media.R","davidcarayon","TidyTuesdaySubmissions","week_27_media.R","# Data and packages loading -----------------------------------------------
library(tidyverse)
library(skimr)
library(data.tree)
library(circlepackeR)
library(ggforce)
library(cowplot)
library(ggthemes)
library(ggrepel)


media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")


# EDA  --------------------------------------------------------------------
media_franchises %>%
  group_by(creators) %>%
  summarise(nd = n_distinct(franchise)) %>%
  filter(nd > 1)

top_15_franchises <- media_franchises %>%
  group_by(franchise) %>%
  summarise(total_revenue = sum(revenue)) %>%
  top_n(15, total_revenue) %>%
  pull(franchise)

media_franchises %>%
  unique() %>%
  filter(franchise %in% top_15_franchises) %>%
  group_by(franchise) %>%
  mutate(total_revenue = sum(revenue)) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(franchise, -total_revenue), y = revenue, group = revenue_category, fill = revenue_category)) +
  geom_bar(stat = ""identity"") +
  theme_bw()

media_franchises %>%
  group_by(owners) %>%
  summarise(sum = sum(revenue)) %>%
  arrange(desc(sum))

# CirclePackR -------------------------------------------------------------
media_franchises -> tab

tab$pathString <- paste(""world"", tab$franchise, tab$revenue_category, sep = ""/"")
population <- as.Node(tab)

circlepackeR(population,
             size = ""revenue"", color_min = ""hsl(152,80%,80%)"",
             color_max = ""hsl(228,30%,40%)""
)

# Final plots -------------------------------------------------------------

## Media

top_5_media <- media_franchises %>%
  group_by(original_media) %>%
  summarise(total_revenue = sum(revenue)) %>%
  top_n(5, total_revenue) %>%
  pull(original_media)

p1 <- media_franchises %>%
  unique() %>%
  mutate(revenue = revenue * 1000000000) %>%
  filter(original_media %in% top_5_media) %>%
  ggplot(aes(x = original_media, y = revenue)) +
  geom_violin(alpha = 0.3, aes(fill = original_media)) +
  geom_sina(aes(fill = original_media), color = ""black"", size = 3, shape = 21) +
  geom_label_repel(
    data = media_franchises %>%
      unique() %>%
      mutate(revenue_category = recode(revenue_category, ""Merchandise, Licensing & Retail"" = ""Merchandise"", ""Video Games/Games"" = ""Games"")) %>%
      filter(original_media %in% top_5_media) %>%
      filter(revenue > 19) %>%
      mutate(categ = paste0(franchise, "" ("", revenue_category, "")"")),
    aes(x = original_media, y = revenue * 1000000000, label = categ), color = ""black"", fill = ""wheat"", family = ""mono"", size = 4
  ) +
  guides(fill = FALSE, color = FALSE) +
  labs(x = ""Original Media"", y = ""Total revenue"") +
  scale_y_continuous(label = scales::dollar) +
  theme_wsj() +
  labs(title = ""Revenue generated for the 5 most successful media"")


## Categories

top_10_categ <- media_franchises %>%
  group_by(revenue_category) %>%
  summarise(total_revenue = sum(revenue)) %>%
  top_n(10, total_revenue) %>%
  pull(revenue_category)


p2 <- media_franchises %>%
  unique() %>%
  mutate(revenue = revenue * 1000000000) %>%
  filter(revenue_category %in% top_10_categ) %>%
  group_by(revenue_category) %>%
  summarise(total_categ = sum(revenue)) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(revenue_category, total_categ), y = total_categ)) +
  geom_bar(stat = ""identity"", aes(fill = revenue_category), color = ""black"") +
  guides(fill = FALSE, color = FALSE) +
  labs(x = ""Original Media"", y = ""Total revenue"") +
  scale_y_continuous(label = scales::dollar, limits = c(0, 10e+11)) +
  theme_wsj() +
  labs(title = ""Total revenue generated for the 10 most successful categories"") +
  coord_flip() +
  geom_label(aes(label = paste0(""$"", round(total_categ / 1000000000), "" Bn"")), fill = ""wheat"", color = ""black"", size = 4, family = ""mono"", nudge_y = 69000000000) +
  theme(
    plot.title = element_text(size = 12, face = ""bold""),
    axis.text.x = element_text(size = 9)
  )

# Timeline
p3 <- distinct(media_franchises, franchise, year_created) %>%
  group_by(year_created) %>%
  summarise(n_franchise = n_distinct(franchise)) %>%
  ungroup() %>%
  unique() %>%
  ggplot(aes(x = year_created, y = n_franchise)) +
  geom_bar(aes(x = year_created, y = n_franchise, fill = n_franchise), stat = ""identity"", color = ""black"") +
  scale_fill_viridis_c(direction = -1) +
  guides(fill = FALSE) +
  theme_wsj() +
  geom_curve(aes(x = 1975, y = 5.2, xend = 1993, yend = 6), curvature = -0.3, arrow = arrow(length = unit(2, ""mm"")), color = ""black"") +
  annotate(""label"", x = 1970, y = 5, label = ""6 franchises were created in 1994"", color = ""black"", fill = ""wheat"", family = ""mono"") +
  labs(title = ""Number of franchises created each year"", subtitle = ""1994 was the most creative year"", caption = ""\n Data from Wikipedia | plot by @david_carayon"") +
  theme(
    plot.title = element_text(size = 14, face = ""bold""),
    plot.subtitle = element_text(size = 12, face = ""bold"")
  )

plot_grid(p1, plot_grid(p2, p3), ncol = 1, rel_heights = c(1.45, 1)) +
  ggsave(""README_figs/media_tidytuesday.png"", dpi = ""retina"", width = 20, height = 11.83)","Other-27"
"799",908,"https://github.com/davidcarayon/TidyTuesdaySubmissions/blob/master/week_32_bob_ross.R","davidcarayon","TidyTuesdaySubmissions","week_32_bob_ross.R","library(tidyverse)
library(janitor)
library(ggstatsplot)
library(ggridges)
library(ggwordcloud)
library(cowplot)

bob_ross <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-06/bob-ross.csv"") %>%
  clean_names() %>%
  separate(episode, into = c(""season"", ""episode""), sep = ""E"") %>%
  mutate(season = str_extract(season, ""[:digit:]+"")) %>%
  mutate_at(vars(season, episode), as.integer) %>%
  mutate(title = str_to_title(title))


long <- bob_ross %>%
  gather(key = element, value = presence, -season, -episode, -title) %>%
  filter(presence > 0) %>%
  mutate(element = str_to_title(str_replace_all(element, ""_"", "" ""))) %>%
  mutate(element = ifelse(str_detect(element, ""Tree""), yes = ""Trees"", no = element)) %>%
  mutate(element = fct_lump_min(element, min = 5)) %>%
  group_by(season, element) %>%
  summarise(freq = sum(presence)) %>%
  ungroup()

# Word cloud --------------------------------------------------------------


g1 <- long %>%
  group_by(element) %>%
  summarise(freq = sum(freq)) %>%
  ggplot(aes(label = element, size = freq, color = freq)) +
  geom_text_wordcloud(eccentricity = 1) +
  theme_minimal() +
  scale_size_area(max_size = 30) +
  scale_color_viridis_c(option = ""plasma"", direction = -1) +
  labs(title = ""Frequency of elements in Bob Ross's paintings"") +
  theme(plot.title = element_text(family = ""Roboto condensed"", face = ""bold"", size = 25, hjust = 0.5))


# Circular barplot --------------------------------------------------------------------
# Inspiration : @jmcastagnetto


br_elements <- bob_ross %>%
  gather(key = element, value = presence, -season, -episode, -title) %>%
  filter(presence > 0) %>%
  mutate(element = str_to_title(str_replace_all(element, ""_"", "" ""))) %>%
  mutate(element = ifelse(str_detect(element, ""Tree""), yes = ""Trees"", no = element)) %>%
  mutate(element = fct_lump_min(element, min = 5)) %>%
  group_by(element) %>%
  count() %>%
  ungroup() %>%
  mutate(
    element = paste0(element, ""\n(N = "", n, "")"") %>%
      forcats::fct_reorder(n)
  )


br_elements$id <- seq(1, nrow(br_elements))
angle <- 90 - (360 * (br_elements$id - 0.5) / nrow(br_elements))
br_elements$hjust <- as.numeric(angle < -90)
br_elements$angle <- angle

g2 <- ggplot(
  br_elements,
  aes(x = element, y = n)
) +
  geom_segment(aes(
    x = element, xend = element,
    y = 0, yend = 375
  ),
  color = ""lightgrey"", size = .25,
  linetype = ""dashed""
  ) +
  geom_col(aes(fill = element), width = 1, color = ""black"") +
  scale_fill_viridis_d(option = ""plasma"", direction = -1) +
  scale_y_log10() + # no reason, except that it looks nicer and colorful
  theme_minimal() +
  theme(
    legend.position = ""none"",
    axis.text.y = element_blank(),
    axis.text.x = element_text(angle = br_elements$angle, size = 11, color = ""black"", family = ""Roboto condensed""),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.caption = element_text(size = 15, family = ""Roboto condensed""),
    plot.title = element_text(family = ""Roboto condensed"", face = ""bold"", size = 17, hjust = 0.5)
  ) +
  coord_polar(start = 0)



g3 <- ggplot(data = long, aes(x = freq, y = element, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_continuous(expand = c(0.01, 0)) +
  theme_ridges() +
  scale_fill_viridis_c(name = ""Frequency"") +
  theme(
    text = element_text(colour = ""black"", family = ""Roboto condensed""),
    axis.text = element_text(colour = ""black"", family = ""Roboto condensed"", size = 13),
    axis.title.x = element_blank(),
    axis.title = element_text(colour = ""black"", family = ""Roboto condensed"", face = ""bold""),
    panel.grid = element_blank()
  ) +
  labs(
    y = ""Element"",
    caption = ""Data provided by 538 | Plot by @david_carayon\nInspiration : @jmcastagnetto""
  )

# Plot --------------------------------------------------------------------

plot_grid(g1, plot_grid(g2, g3), ncol = 1, rel_heights = c(1, 1.45)) +
  ggsave(""README_figs/bob_ross_tidytuesday.png"", dpi = ""retina"", width = 13.1, height = 10.4)
","Other-32"
"800",909,"https://github.com/davidcarayon/TidyTuesdaySubmissions/blob/master/week_24_meteorites.R","davidcarayon","TidyTuesdaySubmissions","week_24_meteorites.R","library(tidyverse)
library(sf)
library(ggforce)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggdark)
library(cowplot)
library(ggsn)

# Data -------------------------------------------------------------------

# Import data and remove outliers
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  filter(long < 180 & year <= 2013)

# World map
world <- ne_countries(scale = ""medium"", returnclass = ""sf"")

world_map <- ggplot() +
  geom_sf(data = world) +
  geom_point(data = meteorites, aes(x = long, y = lat), color = ""darkturquoise"", alpha = .1) +
  guides(size = FALSE) +
  blank() +
  dark_mode() +
  labs(title = ""Location of meteorite crashes"") +
  theme(
    axis.title = element_blank(),
    plot.title = element_text(size = 17, face = ""bold"", family = ""mono""),
    plot.caption = element_text(size = 13, family = ""mono"")
  )


# Mass distribution  ------------------------------------------------------
mass_d <- meteorites %>%
  mutate(class = fct_lump(class, n = 11)) %>%
  filter(class != ""Other"") %>%
  group_by(class) %>%
  mutate(mean_mass = median(mass, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(class = fct_reorder(class, mean_mass)) %>%
  ggplot(aes(x = class, y = mass, color = class)) +
  scale_fill_viridis_c() +
  geom_violin() +
  geom_point(aes(x = class, y = mean_mass, color = class), size = 8, shape = 18) +
  scale_y_log10() +
  coord_flip() +
  dark_theme_classic() +
  theme(
    axis.text = element_text(size = 13, family = ""mono""),
    axis.title = element_text(size = 17, family = ""mono""),
    plot.title = element_text(size = 15, face = ""bold"", family = ""mono""),
    legend.text = element_text(family = ""mono"", size = 12),
    legend.title = element_text(family = ""mono"", size = 13, face = ""bold""),
    plot.caption = element_text(size = 13, family = ""mono"")
  ) +
  labs(y = ""Mass in grams"", x = ""Meteorite class"", title = ""Median mass value and distribution of the 10 most common meteorite classes"", color = ""Meteorite class"")


# Number of meteorites ----------------------------------------------------
meteorites %>%
  distinct(id, year, mass) %>%
  filter(year >= 1900 & year != 2101) %>%
  ggplot(aes(x = year)) +
  geom_histogram(fill = ""pink"", color = ""black"", binwidth = 10) +
  dark_theme_classic() +
  theme(
    axis.text = element_text(size = 13, family = ""mono""),
    axis.title = element_text(size = 17, family = ""mono""),
    plot.title = element_text(size = 17, face = ""bold"", family = ""mono""),
    legend.text = element_text(family = ""mono"", size = 12),
    legend.title = element_text(family = ""mono"", size = 13, face = ""bold""),
    plot.caption = element_text(size = 13, family = ""mono"")
  ) +
  labs(y = ""Count"", title = ""Number of meteorites found from 1900 to 2013"")


# Time series -------------------------------------------------------------

## Mann-Kendal trend test
counts <- meteorites %>%
  distinct(id, year, mass) %>%
  filter(year >= 1975 & year != 2101) %>%
  count(year) %>%
  arrange(year) %>%
  mutate(n = as.numeric(n))

mk_test <- round(trend::mk.test(ts(counts$n))$p.value, 2)

## Time series plot with a second order polynomial trend
ts <- meteorites %>%
  distinct(id, year, mass) %>%
  filter(year >= 1975) %>%
  count(year) %>%
  ggplot(aes(x = year, y = n)) +
  geom_point(color = ""purple"", size = 4, shape = 15) +
  geom_line(color = ""purple"", size = 2) +
  dark_theme_classic() +
  stat_smooth(method = ""lm"", formula = y ~ poly(x, 2), size = 1.5, level = 0.95, se = TRUE, fill = ""green"") +
  theme(
    axis.text = element_text(size = 13, family = ""mono""),
    axis.title = element_text(size = 17, family = ""mono""),
    plot.title = element_text(size = 17, face = ""bold"", family = ""mono""),
    legend.text = element_text(family = ""mono"", size = 12),
    legend.title = element_text(family = ""mono"", size = 13, face = ""bold""),
    plot.caption = element_text(size = 13, family = ""mono""),
    plot.subtitle = element_text(family = ""mono"")
  ) +
  labs(
    y = ""Number of meteorites"",
    x = ""Time"",
    title = ""Number of meteorites observed worldwide between 1975 and 2013"",
    color = ""Meteorite class"",
    caption = ""Data from the Meteoritical Society and shared by NASA \nPlot from @david_carayon"",
    subtitle = paste0(""The Mann-Kendal trend tests indicates a significant increasing trend (P = "", 0.02, "")"")
  ) +
  geom_curve(aes(x = 1984, y = 3000, xend = 1979.4, yend = 3100), curvature = 0.3, arrow = arrow(length = unit(2, ""mm"")), color = ""white"") +
  annotate(""text"", x = 1990, y = 2920, label = paste0(max(counts$n), "" meteorites in 1979""), color = ""white"", family = ""mono"", size = 5)


# Final plot layout -------------------------------------------------------
plot_grid(world_map, plot_grid(mass_d, ts), ncol = 1, rel_heights = c(1.45, 1)) +
  ggsave(""README_figs/meteorites_tidytuesday.png"", dpi = ""retina"", bg = ""black"", width = 21, height = 13)
","Other-24"
"801",910,"https://github.com/davidcarayon/TidyTuesdaySubmissions/blob/master/week_25_birds.R","davidcarayon","TidyTuesdaySubmissions","week_25_birds.R","library(tidyverse)
library(FactoMineR)
library(factoextra)
library(vegan)
library(patchwork)
library(ggthemes)
library(ggrepel)
library(janitor)
library(purrr)

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

# CA analysis -------------------------------------------------------------
bird_matrix <- bird_counts %>%
  filter(total_hours > 8) %>%
  distinct(year, species, how_many_counted_by_hour) %>%
  filter(how_many_counted_by_hour > 0) %>%
  drop_na() %>%
  spread(key = species, value = how_many_counted_by_hour, fill = 0) %>%
  column_to_rownames(""year"") %>%
  as.matrix()

## Hierarchical clustering
bray <- vegdist(bird_matrix, method = ""bray"")
clust <- hclust(bray, method = ""ward.D2"")
cluster <- cutree(clust, k = 3) %>%
  as.data.frame() %>%
  rownames_to_column(""year"") %>%
  rename(""cluster"" = ""."") %>%
  tbl_df()

## Correspondence analysis
res.CA <- CA(bird_matrix, graph = FALSE)

# Scree plot (Keeping 2 dimensions)
fviz_eig(res.CA, addlabels = TRUE)

## Extracting rows coordinates
rows <- res.CA$row$coord %>%
  as.data.frame() %>%
  rownames_to_column(""year"") %>%
  tbl_df() %>%
  clean_names() %>%
  select(year:dim_2) %>%
  inner_join(cluster, by = ""year"") %>%
  mutate(cluster = as.factor(cluster))

## Extracting cols coordinates
cols <- res.CA$col$coord %>%
  as.data.frame() %>%
  rownames_to_column(""species"") %>%
  tbl_df() %>%
  clean_names() %>%
  select(species:dim_2)

extreme_species <- bind_rows(
  cols %>% top_n(5, dim_1),
  cols %>% top_n(-5, dim_1),
  cols %>% top_n(-5, dim_2),
)

## Rows plot with clustering
g1 <- ggplot(data = rows, aes(x = dim_1, y = dim_2)) +
  geom_label(aes(label = year)) +
  stat_ellipse(aes(fill = cluster), geom = ""polygon"", alpha = 0.4, level = 0.95, color = ""black"") +
  labs(
    fill = ""Cluster"", x = paste0(""Dim 1: "", round(res.CA$eig[1, 2], 2), "" %""),
    y = paste0(""Dim 2: "", round(res.CA$eig[2, 2], 2), "" %""), title = ""Correspondence analysis - Rows""
  ) +
  theme_base() +
  theme(axis.text = element_blank(), axis.ticks = element_blank())


## Species plot
g2 <- ggplot(data = cols, aes(x = dim_1, y = dim_2)) +
  geom_point() +
  geom_label_repel(data = extreme_species, aes(label = species)) +
  theme_base() +
  theme(axis.text = element_blank(), axis.ticks = element_blank()) +
  labs(
    x = paste0(""Dim 1: "", round(res.CA$eig[1, 2], 2), "" %""),
    y = paste0(""Dim 2: "", round(res.CA$eig[2, 2], 2), "" %""), title = ""Correspondence analysis - Columns"",
    caption = ""Data from Bird Studies Canada | Plot by @david_carayon""
  )


# Time series analysis ------------------------------------------------------
Metrics <- bird_counts %>%
  filter(total_hours > 8) %>%
  distinct(year, species, how_many_counted_by_hour) %>%
  drop_na() %>%
  spread(key = species, value = how_many_counted_by_hour, fill = 0) %>%
  group_by(year) %>%
  nest() %>%
  mutate(
    SpecRichness = map_dbl(data, specnumber),
    shannon = map_dbl(data, diversity, index = ""shannon"")
  ) %>%
  inner_join(distinct(bird_counts, year, total_hours), by = ""year"") %>%
  select(-data) %>%
  gather(key = index, value = value, -year) %>%
  mutate(index = recode(index, ""shannon"" = ""Shannon's diversity index"", ""SpecRichness"" = ""Species richness"", ""total_hours"" = ""Total hours""))

g3 <- ggplot(Metrics, aes(x = year, y = value)) +
  geom_line(aes(group = index, color = index), key_glyph = ""timeseries"") +
  scale_color_brewer(palette = ""Set1"") +
  geom_point(shape = 21, color = ""black"", fill = ""white"") +
  facet_wrap(~index, scales = ""free"") +
  theme_bw() +
  theme(axis.title.x = element_text(size = 20),
        axis.title.y = element_blank(),
        strip.text.x = element_text(size = 14, face = ""bold""),
        strip.background = element_rect(fill = ""white"", color = ""black""),
        axis.text = element_text(size = 12),
        legend.position = ""top"",
        legend.text = element_text(size = 13),
        legend.title = element_text(size = 15, face = ""bold"")) +
  labs(color = ""Index"", x = ""Year"") 

## Patchwork plotting
g3 / (g1 | g2) + plot_layout(heights = c(0.75, 1)) +
  ggsave(""README_figs/birds_tidytuesday.png"", dpi = ""retina"", width = 13.5, height = 10)
","Other-25"
"802",911,"https://github.com/thewiremonkey/tidy_tuesday/tree/master/week_11","thewiremonkey","tidy_tuesday","week_11/tt11.R","library(tidyverse)
library(fivethirtyeight)
library(maps)
library(forcats)
# devtools::install_github(""rundel/timezone"")
library(timezone)
library(htmltab)

#set raw data frame from fivethirtyeight data
df<-fifa_audience

#get list of city capitals as proxy for countries' time zone.
#Obviously bigger countries have multiple time zones, but the data is
#grouped by country so we have to pick just one

cities<-world.cities %>% filter(capital==1)

#country names don't match up between the data sets.  Find out which ones
#do and which ones don't
df_cities<-cities %>% filter(country.etc %in% df$country)

#list of countries  that don't appear in the df_cities data frame
#many of them are disputed territories.  Rather than get into an unending Twitter
#battle by assigning them to another country, I've left them out.  Most don't reach the .2 audience share anyway
bad_cities<-df %>% filter(!country %in% df_cities$country.etc )

#rename countries so that they'll be available to find the timezone
df<-df %>% mutate(
  country=
    case_when(
    country==""United States"" ~ ""USA"",
    country==""Dominican Republic"" ~ ""Dominica"",
    country==""United Kingdom"" ~ ""UK"",
    country==""South Korea"" ~""Korea South"",
    country==""Serbia"" ~""Serbia and Montenegro"",
    country==""Bosnia-Herzegovina"" ~ ""Bosnia and Herzegovina"",
    country==""Trinidad &Tobago"" ~""Trinidad and Tobago"",
    country==""Kosovo"" ~""Bosnia and Herzogovina"",
    country==""North Korea"" ~ ""Korea North"",
    country==""Montenegro"" ~ ""Serbia and Montenegro"",
    country==""Turks & Caicos"" ~""Turks and Caicos"",
    country==""Congo DR""  ~ ""Congo Democratic Republic"",
    country==""Fiji"" ~""French Polynesia"",
    country==""Curacao"" ~ ""Netherlands Antilles"",
    country==""St. Lucia"" ~""Saint Lucia"",
    country==""Congo, Rep."" ~ ""Congo"",
    country==""Antigua & Barbuda"" ~ ""Antigua and Barbuda"",
    country==""St. Vincent"" ~ ""Saint Vincent and The Grenadines"",
    country==""Timor"" ~ ""East Timor"",
    country== ""St. Kitts"" ~ ""Saint Kitts and Nevis"",
    TRUE ~ country
  )
) %>%
  left_join(cities, by=c(""country""=""country.etc""))

#use purrr's safely to allow the function to run without  throwing an error
safe_tz<-safely(find_tz, otherwise = NA_real_)

#filter out any records that don't have a longitude and latitude
#find the timezone of the remaining countries
tz_df<-df %>% filter(!is.na(long), !is.na(lat), population_share > 0) %>%
  mutate(tzs=find_tz(long, lat))

#tutorial for scraping tables from wikipedia
#https://stackoverflow.com/questions/7407735/importing-wikipedia-tables-in-r?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
# install.packages(""htmltab"")


#get wikipedia table of timezone offsets
#clean the offset to remove the plus sign.  I thought I was going to be able
#to do some math with this, but abandoned that idea
wiki_tz<-htmltab(""https://en.wikipedia.org/wiki/List_of_tz_database_time_zones"",1) %>%
  mutate(coordinates=iconv(`Coordinates*`, from = ""UTF-8"", to=""windows-1252""),
         offset=iconv(`UTC offset`, from=""UTF-8"", to= ""windows-1252"")) %>%
  mutate(offset=ifelse(grepl(""\\+"", offset), gsub(""\\+"", """", offset),offset)  )

#create the table we'll use for the viz
tz_df_plot<-tz_df %>% left_join(wiki_tz, by=c(""tzs""=""TZ*"")) %>%
  filter(!is.na(offset), tv_audience_share > 0) %>%
  mutate(offset=as.factor(offset)) %>%
  mutate(offset=forcats::fct_relevel(offset, ""-06:00"",""-05:00"", ""-04:00"",""-03:00""))
#use forcats to refactor the negatives, which originally came in from -3:00 to -6:00

#create the sum of audience share per timezone
sum_tz_df<-tz_df_plot %>% group_by(offset) %>%
  summarise(share=sum(tv_audience_share))


#Tidy Tuesday Plot
ggplot(sum_tz_df, aes(x=offset, y=share))+
  geom_point(color=""blue"", size=3)+
  geom_jitter(data=tz_df_plot, aes(x=offset, y=tv_audience_share, color=confederation))+
  geom_vline(aes(xintercept=7), linetype=""dashed"", color=""red"")+
  annotate(geom = ""text"", x = 7, y = 10, label = ""Johannesburg"", color = ""red"",
           angle = 90, vjust=0)+
  ggtitle(label = ""Cumulative Audience Share by Timezone"", subtitle=""blue dot = sum of audience share"")+
  labs(x=""UTC Offset"", y=""Audience Share"", caption=""data source: fivethirtyeight.com\nviz: Alyssa Goldberg @WireMonkey 2018\n#TidyTuesday @thomas_mock"")+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90))


","Other-11"
"803",942,"https://github.com/aponsero/Rvisualisations_tidytuesday/blob/master/week27_19/Data_exploration.R","aponsero","Rvisualisations_tidytuesday","week27_19/Data_exploration.R","library(ggplot2)
library(tidyverse)
library(ggthemes)
library(lubridate)
library(maps)

#function to floor the decades
floor_dec= function(myyear){ 
  return(myyear - myyear %% 10) 
}
floor_dec_v <- Vectorize(floor_dec)

## Data exploration
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

#add a decade column
media_franchises <- media_franchises %>% mutate(decade_created=floor_dec_v(year_created))

#stacked barplot of the revenues category
bplot <- media_franchises %>% ggplot(aes(franchise,revenue, fill = revenue_category)) + 
  geom_bar(stat=""identity"")+
  labs(y = ""revenue (in billion)"", x = ""Franchise name"") +
  coord_flip()
bplot

panel <- bplot + facet_grid(decade_created ~ .,scales=""free_y"",space=""free"")
panel

#addition of the type of revenues by decade
franchise_summary <- media_franchises %>% group_by(decade_created, revenue_category) %>% summarise(sum=sum(revenue))
#number of franchise by decades
numb_by_decade <- media_franchises %>% select(decade_created,franchise) %>% distinct()%>% group_by(decade_created) %>% tally()
franchise_summary <- full_join(numb_by_decade, franchise_summary, by=""decade_created"")

bplot2 <- franchise_summary %>% ggplot(aes(x=decade_created)) + 
  geom_bar(aes(y=sum, fill = revenue_category), stat=""identity"")+
  geom_point(aes(y=n*3,size = n))+
  geom_text(aes(y=n*3, label=round(franchise_summary$n,1)), nudge_y = 20) +
  scale_y_continuous(sec.axis = sec_axis(~ . / 3, name = ""number of franchises""))+
  labs(fill=""Categories"", size=""number of franchises"", y = ""revenue (in billion)"", x = ""year of creation"")+
  ggtitle(""revenue and number of media franchises grossing more than 4 billion US$"")+
  theme_classic(base_size = 10)
bplot2

out_file=""week27.png""
ggsave(out_file, width = 10, height = 7, units = ""cm"")","2019-27"
"804",943,"https://github.com/aponsero/Rvisualisations_tidytuesday/tree/master/week29_19","aponsero","Rvisualisations_tidytuesday","week29_19/animation_time.R","library(ggplot2)
library(dplyr)
library(gganimate)
library(tidyverse)
library(lubridate)
library(extrafont)
font_import()
loadfonts()


#Load dataset
r4ds_members <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")
data_plot <- r4ds_members %>% 
  select(date, total_membership,daily_active_members,weekly_active_members) %>% 
  gather(members, count, -date) 



# static plot time-serie
data_plot %>% ggplot(aes(x = date, y = count)) + 
  labs(y=""number of members"", x=""date"",
       title=""Number of members in R4DS\n(2017 to 2019)"")+
  geom_line(aes(color = members), size = 1) +
  scale_color_manual(values = c(""brown1"",""darkolivegreen4"",""burlywood3""),
                     labels=c(""daily active members"", ""total members"",
                              ""weekly active members"")) +
  geom_point(aes(color = members), size = 3) +
  theme_minimal(base_size = 16)+
  theme(text=element_text(family=""Times New Roman""),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = ""black""))

# animation ! exciting times !
my_anim <- data_plot %>% ggplot(aes(x = date, y = count)) + 
  labs(y=""number of members"", x=""date"",
       title=""Number of members in R4DS\n(2017 to 2019)"")+
  geom_line(aes(color = members), size = 1) +
  scale_color_manual(values = c(""brown1"",""darkolivegreen4"",""burlywood3""),
                     labels=c(""daily active members"", ""total members"",
                              ""weekly active members"")) +
  geom_point(aes(color = members), size = 3) +
  theme_minimal(base_size = 16)+
  theme(text=element_text(family=""Times New Roman""),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = ""black""))+
  # Here comes the gganimate stuff
  transition_reveal(date,
                    range = as.Date(c(""2017-08-27"", ""2020-01-01"")))

animate(my_anim, height = 350, width =650)

anim_save(""time_series1.gif"", animation = last_animation(), 
          path = ""/Users/aponsero/Documents/Rvisualisations_tidytuesday/week29_19"")","2019-29"
"805",944,"https://github.com/aponsero/Rvisualisations_tidytuesday/blob/master/week31_19/animation_time.R","aponsero","Rvisualisations_tidytuesday","week31_19/animation_time.R","library(ggplot2)
library(dplyr)
library(gganimate)
library(tidyverse)
library(lubridate)
library(extrafont)
font_import()
loadfonts()


#Load dataset
game_data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

#remove data with playtime=0
data_plot<-game_data %>% filter(!is.na(metascore) & !is.na(price) 
                                & !is.na(owners) & !is.na(release_date))

#change date
data_plot <- data_plot %>% mutate(year=year(mdy(release_date)))

#modify owners categories
data_plot %>% group_by(owners) %>% tally()

cat1 <- data_plot %>% filter(grepl(""20,000$"", owners, fixed = FALSE) | 
                       grepl(""^20,000"", owners, fixed = FALSE) )
cat2 <- data_plot %>% filter(grepl(""100,000$"", owners, fixed = FALSE))
cat3 <- data_plot %>% filter(grepl(""200,000$"", owners, fixed = FALSE) | 
                               grepl(""^200,000"", owners, fixed = FALSE) )
cat4 <- data_plot %>% filter(grepl(""1,000,000$"", owners, fixed = FALSE))
cat5 <- data_plot %>% filter(grepl(""2,000,000$"", owners, fixed = FALSE) | 
                               grepl(""^2,000,000"", owners, fixed = FALSE) )
cat6 <- data_plot %>% filter(grepl(""10,000,000$"", owners, fixed = FALSE))
cat7 <- data_plot %>% filter(grepl(""^10,000,000"", owners, fixed = FALSE))
cat1$category <- '1'
cat2$category <- '2'
cat3$category <- '3'
cat4$category <- '4'
cat5$category <- '5'
cat6$category <- '6'
cat7$category <- '7'

data_plot2 <-bind_rows(list(cat1, cat2, cat3, cat4, cat5, cat6, cat7))

# static plot 
owners_labs <- c(""0 to 50k"",""50k to 100k"",""100k to 500k"",
                 ""550k to 1,000k"",""1,000k to 5,000k"",'5,000k to 10,000k',
                 ""above 10,000k"")
p<-data_plot2 %>% ggplot(aes(x = metascore, y = price)) + 
  labs(y=""price in USD"", x=""metascore"",
       title=""Evolution of video games' prices and metascores"")+
  geom_point(aes(color=category,size = category, group = seq_along(category))) +
  scale_color_discrete(name = ""number of owners"", labels = owners_labs)+
  scale_size_discrete(guide = FALSE) +
  theme_minimal(base_size = 16)+
  theme(text=element_text(family=""Times New Roman""),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = ""black""))

p
# animated plot 
my_anim <- p+transition_states(year,
                    transition_length = 1,
                    state_length = 1)+
  enter_fade() + 
  exit_shrink()+
  labs(subtitle= ""Year of release : {closest_state}"")

#my_anim
animate(my_anim, height = 350, width =650)

anim_save(""price_metascore.gif"", animation = last_animation(), 
          path = ""/Users/aponsero/Documents/other_works/Rvisualisations_tidytuesday/week30_19"")
","2019-31"
"806",1092,"https://github.com/bryce-murphy/tidytuesday","bryce-murphy","tidytuesday","tt_3.R","library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(janitor)
library(RCurl)
library(maps)
library(mapdata)
library(leaflet)
library(ggplot2)
library(plotly)

path <- getURL(""https://raw.githubusercontent.com/bryce-murphy/tidytuesday/master/global_mortality_3.csv"")


# Read in the mortality dataset from github, clean the variable names, and make observations more readable

mort <- read_csv(path) %>%
  clean_names() %>%
  rename_all(
    funs(
      str_replace(., ""_percent"", """"))) %>%
  mutate_if(is.numeric, funs(round(., 4)))

# United States is called USA in the mapdata package

mort$country <-
  mort$country %>%
  str_replace(""United States"", ""USA"")

world <- map_data(""world"") %>%
  rename(country = region)

# Combine the datasets and filter

world_mort <- 
  mort %>%
  inner_join(world, by = ""country"") %>%
  filter(year == 2016) %>%
  gather(key = mortality_type, value = mortality_rate, -c(1:3, 36:40)) %>%
  filter(mortality_type == ""cancers"") %>%
  mutate(z_score = ave(mortality_rate, mortality_type, FUN = scale))


# Save ggplot object to be used in plotly

p <- ggplot(world_mort, aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = mortality_rate), color = ""black"") +
  coord_fixed(1.3) +
  scale_fill_gradient(high = ""red"", low = ""green"") +
  labs(title = ""Cancer Mortality Rates Across the Globe, 2016"")

#
ggplotly(p)



























m = leaflet() %>% addTiles()
df = data.frame(
  lat = rnorm(100),
  lng = rnorm(100),
  size = runif(100, 5, 20),
  color = sample(colors(), 100)
)
m = leaflet(df) %>% addTiles()
m %>% addCircleMarkers(radius = ~size, color = ~color, fill = FALSE)
m %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))

","Other-3"
"807",1093,"https://github.com/bryce-murphy/tidytuesday","bryce-murphy","tidytuesday","tt_4.R","library(readr)
library(RCurl)
library(dplyr)
library(tidyr)
library(ggplot2)

#READ IN DATA FROM THE GITHUB SOURCE
path <- getURL(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week4_australian_salary.csv"")

wages <- 
  read_csv(path) %>%
  rename(income = average_taxable_income) # make variable easier to type

# Find top 10 highest paying female professions
top_female <-
  wages %>% 
  filter(gender == ""Female"") %>%
  arrange(desc(income)) %>%
  head(n = 10)

top_female_jobs <- unique(top_female$occupation)  # Creates vector of names to use for filtering


# Filter males so that they match the highest earning females - join the 2 dfs 
male_counterparts <- 
  wages %>%
  filter(gender == ""Male"", occupation %in% top_female_jobs) %>%
  full_join(top_female)

# Barplot of top 10 female occupations
ggplot(male_counterparts, aes(x = reorder(occupation, income), y = income, fill = gender)) +
  geom_bar(stat = ""identity"", position = ""dodge"") +
  coord_flip() +
  geom_text(aes(label = individuals, y = max(income)), position = position_dodge(1)) +
  labs(x = ""Occupation"",
       y = ""Average Taxable Income (USD)"",
       title = ""Gender Comparison of Taxable Income\n by Top 10 Female Occupations"") +
  scale_fill_discrete(name = ""Gender"")
  
  

","Other-4"
"808",1094,"https://github.com/bryce-murphy/tidytuesday","bryce-murphy","tidytuesday","tt_6.R","library(tidyverse)
library(readxl)
library(leaflet)

# Read in all of the chains and clean some of the column names
path <- ""C:/Users/Bryce/Desktop/Github_Projects/tidytuesday/tt6_coffee.xlsx""

starbucks <- 
  read_excel(path) %>% # Can specify sheet after path to select a different workbook page
  unite(col = ""Geolocation"", c(""City"", ""State/Province"", ""Country""), sep = "" | "")

starbucks %>%
  leaflet() %>%
  addTiles() %>%
  addAwesomeMarkers(clusterOptions = markerClusterOptions(), label = ~as.character(Geolocation))
  













","Other-6"
"809",1125,"https://github.com/toscano84/TidyTuesday/tree/master/Week8","toscano84","TidyTuesday","Week8/tidy_tuesday_week8.R","# tidy tuesday week 8

#libraries needed
library(readr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
library(extrafont)
library(rgeos)
library(geojsonio)
library(broom)

# import and load fonts
font_import()
loadfonts(device = ""win"")

# read file
honey <- read_csv(""honeyproduction.csv"")
View(honey)

# tidy the dataset and create variable that corresponds to percentage change in honez production between 1998 and 2012
honey_totalprod <- honey %>%
  group_by(state) %>%
  select(state, totalprod, year) %>%
  spread(year, totalprod) %>%
  mutate(perc_change_prod = round((`2012` - `1998` ) / `1998` * 100, digits = 2)) %>%
  na.omit

# create new variable - state names to enable the join with the json file
honey_totalprod <- honey_totalprod %>%
  mutate(state_long = case_when(state == ""AL"" ~ ""Alabama"",
                                state == ""AR"" ~ ""Arkansas"",
                                state == ""AZ"" ~ ""Arizona"",
                                state == ""CA"" ~ ""California"",
                                state == ""CO"" ~ ""Colorado"",
                                state == ""FL"" ~ ""Florida"",
                                state == ""GA"" ~ ""Georgia"",
                                state == ""HI"" ~ ""Hawaii"",
                                state == ""IA"" ~ ""Iowa"",
                                state == ""ID"" ~ ""Idaho"",
                                state == ""IL"" ~ ""Illinois"",
                                state == ""IN"" ~ ""Indiana"",
                                state == ""KS"" ~ ""Kansas"",
                                state == ""KY"" ~ ""Kentucky"",
                                state == ""LA"" ~ ""Louisiana"",
                                state == ""MD"" ~ ""Maryland"",
                                state == ""ME"" ~ ""Maine"",
                                state == ""MI"" ~ ""Michigan"",
                                state == ""MN"" ~ ""Minnesota"",
                                state == ""MO"" ~ ""Missouri"",
                                state == ""MS"" ~ ""Mississippi"",
                                state == ""MT"" ~ ""Montana"",
                                state == ""NC"" ~ ""North Carolina"",
                                state == ""ND"" ~ ""North Dakota"",
                                state == ""NE"" ~ ""Nebraska"",
                                state == ""NJ"" ~ ""New Jersey"",
                                state == ""NM"" ~ ""New Mexico"",
                                state == ""NV"" ~ ""Nevada"",
                                state == ""NY"" ~ ""New York"",
                                state == ""OH"" ~ ""Ohio"",
                                state == ""OK"" ~ ""Oklahoma"",
                                state == ""OR"" ~ ""Oregon"",
                                state == ""PA"" ~ ""Pennsylvania"",
                                state == ""SC"" ~ ""South Carolina"",
                                state == ""SD"" ~ ""South Dakota"",
                                state == ""TN"" ~ ""Tennessee"",
                                state == ""TX"" ~ ""Texas"",
                                state == ""UT"" ~ ""Utah"",
                                state == ""VA"" ~ ""Virginia"",
                                state == ""VT"" ~ ""Vermont"",
                                state == ""WA"" ~ ""Washington"",
                                state == ""WI"" ~ ""Wisconsin"",
                                state == ""WV"" ~ ""West Virginia"",
                                state == ""WY"" ~ ""Wyoming""))

# Hexbin available in https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map. Download it and then:
us_hex <- geojson_read(""us_states_hexgrid.geojson"",  what = ""sp"")

# fortify the data 
us_hex@data <- us_hex@data %>% mutate(google_name = gsub("" \\(United States\\)"", """", google_name))
us_fortified <- tidy(us_hex, region = ""google_name"")

# join both datasets
us_fortified <- us_fortified %>% 
  left_join(honey_totalprod, by=c(""id"" = ""state_long"")) 
 

# center the name of the states
centered_states <- cbind.data.frame(data.frame(gCentroid(spdf, byid=TRUE), id=us_hex@data$iso3166_2))


# plot map
p1 <- us_fortified %>%
  na.omit() %>%
  ggplot(aes()) +
  geom_polygon(aes(x = long, y = lat, group = group, fill = perc_change_prod), colour = ""white"", alpha=0.9) +
  geom_text(data = centered_states, aes(x = x, y = y, label=id), fontface = ""bold"", color=""white"", size = 4, alpha = 0.9) +
  scale_fill_gradient(name = ""Change"", low = ""black"", high = ""#FFD700"", breaks = c(-100, -50, 0, 50, 100)) +
  labs(title = ""Change (%) in Honey Production per State"",
       subtitle = ""1998-2012"") +
  theme(text = element_text(color = ""#22211d""),
        plot.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        panel.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        legend.background = element_rect(fill = ""#f5f5f2"", color = NA),
        plot.title = element_text(family = ""Georgia"", size= 22, hjust=0.5, color = ""#4e4d47""),
        plot.subtitle = element_text(family = ""Georgia"", size= 16, hjust=0.5, color = ""#4e4d47""),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank(),
        legend.text = element_text(family = ""Georgia""),
        legend.position = ""right"") +
  coord_map() 


","Other-8/"
"810",1127,"https://github.com/toscano84/TidyTuesday/tree/master/Week3","toscano84","TidyTuesday","Week3/TT_week3.R","# tidytuesday - week 3

# load needed libraries
library(readxl)
library(dplyr)
library(stringr)
library(ggplot2)
library(tidyr)
library(grid)
library(jpeg)
library(scales)
library(magick)
library(extrafont)
library(janitor)
library(maptools)
library(gganimate)

# import and load fonts
font_import()
loadfonts(device = ""win"")

# load data
global_mortality <- read_excel(""global_mortality.xlsx"")

# create EU region
global_mortality<- global_mortality %>%
  mutate(region = case_when(country == ""Portugal"" ~ ""European Union"",
                            country == ""Spain"" ~ ""European Union"",
                            country == ""Greece"" ~ ""European Union"",
                            country == ""Austria"" ~ ""European Union"",
                            country == ""Italy"" ~ ""European Union"",
                            country == ""Malta"" ~ ""European Union"",
                            country == ""Cyprus"" ~ ""European Union"",
                            country == ""Bulgaria"" ~ ""European Union"",
                            country == ""Romania"" ~ ""European Union"",
                            country == ""United Kingdom"" ~ ""European Union"",
                            country == ""Ireland"" ~ ""European Union"",
                            country == ""Germany"" ~ ""European Union"",
                            country == ""Poland"" ~ ""European Union"",
                            country == ""Hungary"" ~ ""European Union"",
                            country == ""Latvia"" ~ ""European Union"",
                            country == ""Estonia"" ~ ""European Union"",
                            country == ""Lithuania"" ~ ""European Union"",
                            country == ""Sweden"" ~ ""European Union"",
                            country == ""Denmark"" ~ ""European Union"",
                            country == ""Finland"" ~ ""European Union"",
                            country == ""Netherlands"" ~ ""European Union"",
                            country == ""Slovenia"" ~ ""European Union"",
                            country == ""Croatia"" ~ ""European Union"",
                            country == ""France"" ~ ""European Union"",
                            country == ""Belgium"" ~ ""European Union"",
                            country == ""Luxembourg"" ~ ""European Union"",
                            country == ""Slovakia"" ~ ""European Union"",
                            country == ""Czech Republic"" ~ ""European Union""))
# tidy the dataframe
global_mortality_tidy <- global_mortality %>%
  select_all(str_to_lower) %>%
  clean_names() %>%
  rename_at(.vars = vars(ends_with(""_percent"")),
            .funs = funs(sub(""(_)percent$"", """", .))) %>%
  gather(cause_of_death, mortality_rate, 4:35) %>%
  filter(cause_of_death == ""cancers"", region == ""European Union"") %>%
  group_by(country, year)

# turn the map of Europe to a dataframe
# create a new empty object called 'temporary' in which to store a zip file
temporary <- tempfile(fileext = "".zip"")
# download the zip file which is on Eurostat website and
download.file(""http://epp.eurostat.ec.europa.eu/cache/GISCO/geodatafiles/NUTS_2010_60M_SH.zip"", 
              temporary)
# unzip
unzip(temporary)

# read administrative boundaries of Europe
europe <- readShapePoly(fn=""NUTS_2010_60M_SH/data/NUTS_RG_60M_2010"")

# convert the shape file to a dataframe
europe <- fortify(europe, region='NUTS_ID')

# prepare the data to join with the global_mortality_tidy dataframe
eu_28 <- europe %>%
  mutate(country = case_when(id == ""PT"" ~ ""Portugal"",
                             id == ""ES"" ~ ""Spain"",
                             id == ""EL"" ~ ""Greece"",
                             id == ""AT"" ~ ""Austria"",
                             id == ""IT"" ~ ""Italy"",
                             id == ""MT"" ~ ""Malta"",
                             id == ""CY"" ~ ""Cyprus"",
                             id == ""BG"" ~ ""Bulgaria"",
                             id == ""RO"" ~ ""Romania"",
                             id == ""UK"" ~ ""United Kingdom"",
                             id == ""IE"" ~ ""Ireland"",
                             id == ""DE"" ~ ""Germany"",
                             id == ""PL"" ~ ""Poland"",
                             id == ""HU"" ~ ""Hungary"",
                             id == ""LV"" ~ ""Latvia"",
                             id == ""EE"" ~ ""Estonia"",
                             id == ""LT"" ~ ""Lithuania"",
                             id == ""SE"" ~ ""Sweden"",
                             id == ""DK"" ~ ""Denmark"",
                             id == ""FI"" ~ ""Finland"",
                             id == ""NL"" ~ ""Netherlands"",
                             id == ""SI"" ~ ""Slovenia"",
                             id == ""HR"" ~ ""Croatia"",
                             id == ""FR"" ~ ""France"",
                             id == ""BE"" ~ ""Belgium"",
                             id == ""LU"" ~ ""Luxembourg"",
                             id == ""SK"" ~ ""Slovakia"",
                             id == ""CZ"" ~ ""Czech Republic""))

# join both databases
eu_28_cancer_mortality <- global_mortality_tidy %>%
  left_join(eu_28, by = ""country"")

# assign path to magick to enable the creation of gifs
magickPath <- shortPathName(""C:/Program Files/ImageMagick-6.9.9-Q16-HDRI/convert.exe"")

# create a dataframe with the limits of Europe
long <- c(60.64878, 24.08464,-31.26192, 56.00000)
lat <- c(80.58823, 34.83469, 39.45479,74.00000)
europe.limits <- data.frame(long, lat)
eu_28_cm <- eu_28_cancer_mortality %>%
  filter(long > min(europe.limits$lon) & long < max(europe.limits$lon) & 
           lat  > min(europe.limits$lat) & lat  < max(europe.limits$lat))
 
  
# create a dataframe to center the labels in the plot
label_data<- eu_28_cm %>%
  group_by(country, year) %>%
  summarise(long = mean(long), lat = mean(lat), 
            mortality_rate = mean(mortality_rate))

# image read
eu_flag<- image_read(""EU.jpg"")

#--------plot the graph---------#
p <- ggplot(data = eu_28_cm, aes(frame = year)) +
  annotation_custom(rasterGrob(eu_flag), 
                    xmin = -28, xmax = -8, ymin = 74, ymax = 54) +
  geom_polygon(data = eu_28_cm, col = ""white"", 
               aes(long, lat, group = group, 
                   fill = mortality_rate)) +
  geom_text(data = label_data, family = ""Georgia"", size = 4, 
            fontface = ""bold"", 
            aes(x = long, y = lat, 
                label=paste(round(mortality_rate, digits=1),""%""))) +
  theme_void() +
  scale_fill_gradient2(breaks = seq(0,40, by = 5),
                       labels=seq(0,40,by=5), low = ""yellow"",
                       high = ""blue"", mid = ""grey70"",
                       midpoint = 25) +
  theme(legend.position = ""bottom"",
        legend.key.width = unit(3,""cm""),
        plot.title = element_text(family = ""Georgia"", face = ""bold"", 
                                  size = 15)) +
  labs(title = ""Cancer Mortality Rate in the European Union in year: "",
       fill = NULL)
gganimate(p, interval = 1)
gganimate(p, interval = 1, ""cancer_mortality_EU.gif"")
","Other-3/"
"811",1128,"https://github.com/toscano84/TidyTuesday/blob/master/Week24/TT_week24_cats_vs_dogs.R","toscano84","TidyTuesday","Week24/TT_week24_cats_vs_dogs.R","# Tidy Tuesday Week 24

# needed libraries
library(tidyverse)
library(viridis)
library(extrafont)
library(statebins)
library(hrbrthemes)

# import and load fonts
font_import()
loadfonts(device = ""win"")

# load file
cats_vs_dogs <- read_delim(""cats_vs_dogs.txt"", delim = "","") 

#---plot statebin map---#
bin_map_dogs <- cats_vs_dogs %>%
  ggplot(aes(state = state, fill = percent_dog_owners)) +
  geom_statebins() +
  coord_equal() +
  scale_fill_viridis(
    name = ""Percentage of Dog Owners"",
    guide = guide_colorbar(
      direction = ""horizontal"",
      barheight = unit(2, units = ""mm""),
      barwidth = unit(50, units = ""mm""),
      draw.ulim = F,
      title.position = 'top',
      title.hjust = 0.5,
      label.hjust = 0.5)) + 
  labs(title=""Percentage of Dog Owners in the USA"", 
       caption = ""\nDataSource: https://data.world/datanerd/cat-vs-dog-popularity-in-u-s"") +
  theme_ft_rc(grid="""") +
  theme(axis.text=element_blank(), 
        plot.title = element_text(family = ""mono"",
                                  hjust = 0.5)) +
  theme(legend.position = ""bottom"")

bin_map_dogs

","Other-24"
"812",1131,"https://github.com/toscano84/TidyTuesday/tree/master/Week1","toscano84","TidyTuesday","Week1/TidyTuesday_week1.R","#tidytuesday - week 1

# load needed libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)
library(maps)
library(fiftystater)
library(stringr)
library(jpeg)
library(grid)
library(magick)
library(scales)

# load data
avg_tuition <- read_excel(""us_avg_tuition.xlsx"")

#==data preparation for graph 1==#
# create new dataframe
avg_tuition_tidy <- avg_tuition %>% 
  gather(""Year"", ""Tuition"", -State) # reshape data from wide to long

# filter data
avg_tuition_tidy_filter <- avg_tuition_tidy %>%
  filter(Year == ""2015-16"")# include only values of the year 2015-16

# create new variable - ranking
avg_tuition_tidy_filter$ranking <- rank(-avg_tuition_tidy_filter$Tuition) # create the variable ranking in relation to the value of tuition

#lower the case of State variable
avg_tuition_tidy_filter$State <- str_to_lower(avg_tuition$State)#to put the states with lower case as the map database

# lower the cases of all column names
avg_tuition_tidy_filter <- avg_tuition_tidy_filter %>%
  select_all(str_to_lower)

# load dataframe for the map of the USA
usa_map <- fifty_states # assign fifty_states to a new dataframe called usa_map

#join the dataframes
usa_map_new <- usa_map %>% 
  left_join(avg_tuition_tidy_filter, by = c(""id"" = ""state""))

#==Create plot 1==#
# first step - create a variable to center the values of the longitude and latitude so that
# the rank is mapped at the center of each state
center_rank_values <- data.frame(region=tolower(state.name), 
                                 long=state.center$x, lat=state.center$y)

# second step - join the dataframes
rank_text <-  usa_map_new %>%
  select(id, ranking) %>%
  left_join(center_rank_values, by = c(""id"" = ""region""))

# set theme for the graph
theme_set(theme_bw())

#given that the centering did not work for alaska and hawaii, I will change these values ""manually""
# compute the means of both states for long and lat
with(usa_map_new, mean(long[id == ""alaska""], na.rm = TRUE))
with(usa_map_new, mean(lat[id == ""alaska""], na.rm = TRUE))
with(usa_map_new, mean(long[id == ""hawaii""], na.rm = TRUE))
with(usa_map_new, mean(lat[id == ""hawaii""], na.rm = TRUE))

# assing the computed mean values to both states.NOTE: The lat value is not exactly correct. 
# With the computed mean (26.30) the rank appeared outside of the state. Therefore, I changed it a bit to fit as I intend it to.
rank_text <- rank_text %>%
  mutate(long = ifelse(id == ""alaska"", -117.12, long),
         long = ifelse(id == ""hawaii"", -107.21, long),
         lat = ifelse(id == ""alaska"", 28.30, lat),
         lat = ifelse(id == ""hawaii"", 26.21, lat))

# Map Tuition graph 1
map_tuition_graph1 <- usa_map_new %>% 
  ggplot() +
  geom_polygon(col = ""white"", aes(long, lat, group = group, fill = tuition)) +
  geom_text(data = rank_text, aes(long, lat, label = ranking), family = ""mono"", size = 4) + coord_map() +
  theme(panel.background = element_blank(), 
        plot.background = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        legend.title = element_text(family = ""mono""),
        legend.text = element_text(family = ""mono""),
        title = element_text(face = ""bold"", family = ""mono"")) + 
  labs(title = ""Ranking of States by Tuition"", subtitle = ""Average Tuition in 2015-16"", fill = ""Tuition"") +
  scale_fill_gradient2(low = ""red"", mid = ""pink"", high = ""blue"", 
                       midpoint = 10000)
map_tuition_graph1


#==data preparation for graph 2==#
# use the avg_tuition_tidy_filter dataframe computed above
avg_tuition_tidy_graph2 <- avg_tuition_tidy_filter %>%
  mutate(tuition_levels = case_when(tuition > mean(tuition, na.rm = TRUE) ~ ""Above Average"",
                          tuition < mean(tuition, na.rm = TRUE) ~ ""Below Average"",
                          TRUE ~ ""USA Average"")) 

# add a new row with the average of the USA       
avg_tuition_tidy_graph2 <- add_row(avg_tuition_tidy_graph2, state = ""USA Average"", 
                                   year = ""2015-16"", tuition = mean(avg_tuition_tidy_graph2$tuition, na.rm = TRUE),
                                   tuition_levels = ""USA Average"")
#variable tuition_levels to factor 
avg_tuition_tidy_graph2$tuition_levels <- factor(avg_tuition_tidy_graph2$tuition_levels, 
                                       levels = c(""Below Average"",""USA Average"",
                                                  ""Above Average""))

#load image from the net
uni <- image_read(""http://moneyuniversitythebook.com/wp-content/uploads/2016/01/shutterstock_589740642.jpg"")
#resize proportionally to width: 600px
uni <- image_scale(uni, ""600"")


# Map Tuition graph 2
map_tuition_graph2 <- avg_tuition_tidy_graph2 %>%
  ggplot(aes(x = reorder(state, tuition), y = tuition, fill = factor(tuition_levels))) +
  annotation_custom(rasterGrob(uni), 
                    xmin = 0, xmax = 50, ymin = 12050, ymax = 18000) + 
  geom_bar(stat = ""identity"", width = 0.8) + 
  scale_fill_manual(values = c(""Below Average"" = ""#BCF5A9"",
                                ""USA Average"" = ""#40FF00"",
                                ""Above Average"" = ""#173B0B"")) +
  geom_text(aes(label = dollar(round(tuition)),
                angle = 90, family = ""mono""),
            hjust = -0.1, 
            color = ""black"",
            size = 4) +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0, face = ""bold"", family = ""mono""),
        axis.text.y = element_text(face = ""bold"", family = ""mono""),
        title = element_text(face = ""bold"", family = ""mono""),
        panel.grid.minor.y = element_blank(), 
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank(),
        legend.text = element_text(size = 10, family = ""mono"")) +
  coord_cartesian(ylim = c(0, max(avg_tuition_tidy_graph2$tuition) * 1.2)) +
  scale_y_continuous(breaks = c(0, 4000, 8000, 12000), 
                     labels = c(""$0k"", ""$4k"", ""$8K"", ""$12K"")) +
  labs(title = ""Average Tuition by State"", 
       subtitle = ""Year 2015-16"", 
       caption = ""\nDataSource: https://trends.collegeboard.org/"", x = ""State"", 
       y = ""Average Tuition"",
       fill = ""Tuition Comparison"")

map_tuition_graph2




","Other-1/"
"813",1133,"https://github.com/toscano84/TidyTuesday/tree/master/Week7","toscano84","TidyTuesday","Week7/tidy_tuesday_week7.R","# tidy tuesday week 7

#libraries
library(readr)
library(ggplot2)
library(janitor) # to clean data
library(dplyr)
library(tidyr)
library(stringr)
library(tibble)
library(mice) # to deal with missing values
library(jpeg)
library(magick) # to read jpeg files
library(grid) # to add images to the plot
library(extrafont)
library(cowplot) # to add images to the axis
library(reshape2)

# import and load fonts
font_import()
loadfonts(device = ""win"")

# read file
star_wars_characters <- read_csv(""StarWars.csv"") %>%
  select(16:29) # select columns with the favorability ratings

# change columns' names  
colnames(star_wars_characters) <- unlist(star_wars_characters[1, ]) # assign the first row to columns
star_wars_characters <- star_wars_characters[-1,] %>% # delete first row
  clean_names() 


# make tidy the data
star_wars_characters_new <- star_wars_characters %>%
  rowid_to_column() %>% # without it, the spread function below will give an error
  gather(sw_character, favorability, -rowid) %>% # from wide to long format
   mutate(level_favorability = case_when(favorability == ""Very favorably"" ~ 2,
                                favorability == ""Somewhat favorably"" ~ 1,
                                favorability == ""Neither favorably nor unfavorably (neutral)"" ~ 0,
                                favorability == ""Somewhat unfavorably"" ~ -1,
                                favorability == ""Very unfavorably"" ~ -2)) %>%
  select(1:2, 4) %>%
  spread(sw_character, level_favorability) %>% # from long to wide format
  select(-1) %>%
  .[-which(rowMeans(is.na(.)) > 0.5), ] # remove rows with more than 50% NA

# convert the variables to integers
star_wars_characters_new [ ] <- lapply(star_wars_characters_new, function(x)
   as.integer(as.numeric(x)))

#-----dealing with the remaining missing cases-----#
# use of library mice #
# imputing the missing data
star_wars_final <- mice(star_wars_characters_new, m = 5, maxit = 50, meth = ""pmm"", seed = 500)

# back to dataframe
star_wars_final <- mice::complete(star_wars_final,1)
View(star_wars_final)
any(is.na(star_wars_final)) # to check if there are still missing cases

#-----plot-----#
# set theme
theme_set(theme_bw())

# image read
sw<- image_read(""star_wars.jpg"")


# divide the correlation graph in two
cor_div <- function(x) {
  L <- R <- cor(x)
  
  R[lower.tri(R, diag = TRUE)] <- NA
  R <- melt(R)
  names(R)[3] <- ""dots""
  
  L[upper.tri(L, diag = TRUE)] <- NA
  L <- melt(L)
  names(L)[3] <- ""labels""
  
  merge(R, L)
}

# Calculate df with cor_list
df <- star_wars_final %>%
  do(cor_div(.)) 

# plot - part1
pcor <- ggplot(df, aes(x = Var1, var, y = Var2)) +
  geom_abline(slope = -1, color = ""black"", linetype = 2, size = 0.5, intercept = nlevels(df$Var1) + 1) +
  annotation_custom(rasterGrob(sw), 
                    xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf) +
  geom_point(aes(col = dots, size = abs(dots)), shape = 16) +
  geom_text(aes(col = labels,  size = abs(labels), label = round(labels, 2)), family = ""Georgia"", fontface = ""bold"", size = 3) +
  scale_size(range = c(0, 6)) +
  scale_color_gradient2(name = ""r"", limits = c(-1, 1), low = ""blue"", mid = ""grey"", high = ""red"") +
  scale_y_discrete("""", labels = c(""Yoda"", ""R2-D2"", ""Princess Leia Organa"", ""Padm Amidala"",""Obi-Wan Kenobi"", ""Luke Skywalker"", 
                                  ""Lando Calrissian"", ""Jar Jar Binks"", ""Han Solo"", 
                                  ""Emperor Palpatine"", ""Darth Vader"", ""C-3PO"", 
                                  ""Boba Fett"", ""Anakin Skywalker""), 
                   limits = rev(levels(df$Var1))) +
  scale_x_discrete("""", labels = c(""Anakin Skywalker"", ""Boba Fett"", ""C-3PO"",
                                  ""Darth Vader"", ""Emperor Palpatine"", ""Han Solo"",
                                  ""Jar Jar Binks"", ""Lando Calrissian"", ""Luke Skywalker"",
                                  ""Obi-Wan Kenobi"", ""Padm Amidala"", ""Princess Leia Organa"", 
                                  ""R2-D2"", ""Yoda"")) +
  guides(size = FALSE) +
  coord_fixed() +
  labs(title = ""Correlation of favorability ratings of Star Wars characters"", hjust = 1) +
  theme(plot.title = element_text(family = ""Berlin Sans FB"", face = ""bold"", 
                                  size = 15, hjust = 0.5),
        axis.ticks = element_blank(),
        axis.text.y = element_text(family = ""Calibri"", size = 11, face = ""bold"", angle = 45, hjust = 1),
        axis.text.x = element_text(family = ""Calibri"", size = 11, face = ""bold"", angle = 45, hjust = 1), 
        panel.grid = element_blank(),
        legend.text = element_text(family = ""Calibri"", size = 11, hjust = 0.5),
        legend.title = element_text(family = ""Calibri"", size = 14),
        strip.background = element_blank())

# load images to put in the xaxis
yoda <- image_read(""yoda.jpg"")
r2_d2 <- image_read(""r2d2.jpg"")
organa <- image_read(""organa.jpg"")
padme <- image_read(""padme.jpg"")
lando <- image_read(""lando.jpg"")
obiwan <- image_read(""obiwan.jpg"")
luke <- image_read(""luke.jpg"")
jarjar <- image_read(""jarjar.jpg"")
emperor <- image_read(""palpatine.jpg"")
hansolo <- image_read(""hansolo.jpg"")
darth <- image_read(""darth.jpg"")
c3po <- image_read(""c3po.jpg"")
boba <- image_read(""boba.jpg"")
anakin <- image_read(""anakin.jpg"")

# create axis with images
pcor_image <- axis_canvas(pcor, axis = 'x') + 
  draw_image(anakin, x = 0.5, scale = 1) +
  draw_image(boba, x = 1.5, scale = 1) +
  draw_image(c3po, x = 2.5, scale = 1) +
  draw_image(darth, x = 3.5, scale = 1) +
  draw_image(emperor, x = 4.5, scale = 1) +
  draw_image(hansolo, x = 5.5, scale = 1) +
  draw_image(jarjar, x = 6.5, scale = 1) +
  draw_image(lando, x = 7.5, scale = 1) +
  draw_image(luke, x = 8.5, scale = 1) +
  draw_image(obiwan, x = 9.5, scale = 1) +
  draw_image(padme, x = 10.5, scale = 1) +
  draw_image(organa, x = 11.5, scale = 1) +
  draw_image(r2_d2, x = 12.5, scale = 1) +
  draw_image(yoda, x = 13.5, scale = 1) 

# add axis with images to the main plot
y <- ggdraw(insert_xaxis_grob(pcor, pcor_image, position = ""bottom""))
y

","Other-7/"
"814",1135,"https://github.com/toscano84/TidyTuesday/blob/master/Week28/tidy_tuesday_week28.R","toscano84","TidyTuesday","Week28/tidy_tuesday_week28.R","# Tidy Tuesday Week 28

# libraries needed
library(tidyverse)
library(data.table)
library(extrafont)
library(ggthemes)
library(mice)
library(extrafont)
library(randomcoloR)

# load file
voters <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-10-09/voter_turnout.csv"")

# import and load fonts
font_import()
loadfonts(device = ""win"")

# create new variables -type of election and region
voters_tidy <- voters %>%
  mutate(election_type = ifelse(year %in% seq(1982, 2014, 4), ""midterm"", ""presidential""), # create variable type of election
         voter_turnout = votes / eligible_voters * 100, # create voter turnout in %
         region = case_when(state %in% c(""Connecticut"", # create region variable
                                         ""Maine"", 
                                         ""Massachusetts"", 
                                         ""New Hampshire"", 
                                         ""Rhode Island"", 
                                         ""Vermont"", 
                                         ""New Jersey"", 
                                         ""New York"", 
                                         ""Pennsylvania"") ~ ""Northeast"",
                            state %in% c(""Illinois"", 
                                         ""Indiana"", 
                                         ""Michigan"", 
                                         ""Ohio"", 
                                         ""Wisconsin"", 
                                         ""Iowa"", 
                                         ""Kansas"", 
                                         ""Minnesota"", 
                                         ""Missouri"", 
                                         ""Nebraska"", 
                                         ""North Dakota"", 
                                         ""South Dakota"") ~ ""Midwest"",
                            state %in% c(""Delaware"", 
                                         ""Florida"", 
                                         ""Georgia"", 
                                         ""Maryland"", 
                                         ""North Carolina"", 
                                         ""South Carolina"", 
                                         ""Virginia"", 
                                         ""District of Columbia"", 
                                         ""West Virginia"",
                                         ""Alabama"", 
                                         ""Kentucky"", 
                                         ""Mississippi"", 
                                         ""Tennessee"",
                                         ""Arkansas"", 
                                         ""Louisiana"", 
                                         ""Oklahoma"", 
                                         ""Texas"") ~ ""South"",
                            state %in% c(""Arizona"", 
                                         ""Colorado"", 
                                         ""Idaho"", 
                                         ""Montana"", 
                                         ""Nevada"", 
                                         ""New Mexico"", 
                                         ""Utah"", 
                                         ""Wyoming"",
                                         ""Alaska"", 
                                         ""California"", 
                                         ""Hawaii"", 
                                         ""Oregon"", 
                                         ""Washington"") ~ ""West"")) %>%
  filter(alphanumeric_state_code != 0) 


# impute missing values
voters_tidy <- mice(voters_tidy, m= 5, maxit = 50, meth = ""cart"", seed = 100)
voters_tidy <- mice::complete(voters_tidy,1)

sum(is.na(voters_tidy)) # check if there are missing values

#----plot ----#
# create random color for the 50 states plus DC
palette <- distinctColorPalette(51)

# create theme
theme_personal <- theme(strip.text.x = element_text(family = ""Cooper Black"", 
                                  size = 12, hjust = 0.5, 
                                  vjust = 2, face = ""bold""),
      panel.grid.minor = element_blank(),
      plot.title = element_text(family = ""Cooper Black"", 
                                size = 14),
      plot.subtitle = element_text(family = ""Cooper Black"", 
                                   size = 11),
      axis.title = element_blank(),
      axis.text = element_text(family = ""Cooper Black"", 
                               size = 10), 
      panel.grid.major.y = element_line(colour = ""#848484""),
      legend.title = element_text(family =""Cooper Black"", size = 12), 
      plot.caption = element_text(family = ""Cooper Black"", 
                                  size = 10))

# plot
plot1 <- voters_tidy %>%
ggplot(aes(year, state, colour = state)) +
  geom_point(aes(size = voter_turnout), alpha = 0.6) +
  guides(color = FALSE) + 
  scale_x_continuous(limits = c(1979, 2015),
                     breaks = seq(1980, 2014, by = 2),
                     labels = c(""'80"", ""'82"", ""'84"", ""'86"", ""'88"", ""'90"", 
                                ""'92"",""'94"", ""'96"", ""'98"",""'00"",""'02"", ""'04"", ""'06"",
                                ""'08"",  ""'10"",""'12"", ""'14"")) +
  scale_color_manual(values = palette) +
  labs(title = ""Voter Turnout in Elections"", subtitle = "" From 1980 to 2014"",
       caption = ""Source: Star Tribune"", size = ""Voter Turnout (%)"") +
  facet_wrap( ~ region, scales = ""free"") +
  theme_fivethirtyeight() + 
  theme_personal
 
plot1
","Other-28"
"815",1136,"https://github.com/toscano84/TidyTuesday/blob/master/Week15/TT_week15.R","toscano84","TidyTuesday","Week15/TT_week15.R","# leaflet week 15
library(leaflet)
library(readxl) # to load excel file
library(tidyverse) # data cleaning, wrangling, visualization
library(htmlwidgets) # to save leaflet as an html file
library(mapview) # to save leaflet as an image
library(htmltools) # label more compatible with html files


# load files
breweries <- read_excel(""week15_beers.xlsx"", sheet = 2)
beers <- read_excel(""week15_beers.xlsx"", sheet = 1)

#join datasets
beers_breweries <- beers %>%
  left_join(breweries, by = c(""brewery_id"" = ""id""))

# rename columns names
beers_breweries <- beers_breweries %>%
  rename(beers_name  = name.x, breweries_name = name.y)
  
# create tile - tile made in mapbox
map_tile <- ""https://api.mapbox.com/styles/v1/toscano84/cjjpgsezebtb72roknl6gatmb/tiles/256/{z}/{x}/{y}?access_token=pk.eyJ1IjoidG9zY2Fubzg0IiwiYSI6ImNqanBncTdsYzBhdXIzcG1hdGFmb3h2ZzUifQ.Jw3BTDv4M4fLluvCsRHI6A""


# check the types of ounces and create palette
beers_breweries %>%
  group_by(ounces) %>%
  count()

pal_ounces <- colorFactor(palette = c(""#FAAC58"", ""#FE9A2E"", ""#FF8000"", ""#DF7401"",
                                      ""#B45F04"", ""#8A4B08"", ""#61380B""),
                   levels = c(""8.4"", ""12"", ""16"", ""16.9"", ""19.2"", ""24"", ""32""))

# plot the map
map_beers <- beers_breweries %>% 
  leaflet() %>% 
  addTiles(urlTemplate = map_tile) %>% 
  addCircleMarkers(radius = 3,
                   color = ~pal_ounces(ounces),
                   label = ~htmlEscape(beers_name),
                   popup = ~paste0(""<b>"", beers_name,""</b>"",
                                   ""<br/>"",""(Ounces: "", ounces,"")""))
map_beers

# save in html format
saveWidget(map_beers, ""beers_USA.html"")



","Other-15"
"816",1137,"https://github.com/toscano84/TidyTuesday/blob/master/Week6/TT_week6.R","toscano84","TidyTuesday","Week6/TT_week6.R","# tidy Tuesday week 6

# libraries needed
library(here) # to create a path to the current directory
library(tidyverse) # to load packages related to data cleaning (e.g. dplyr) and data visualization(ggplot2)
library(readxl) # to load excel files
library(leaflet) # to create interactive maps
library(htmlwidgets) # to save leaflet as an html file
library(htmltools) # labels more compatible with html files
library(leaflet.extras) # to add more tile options
library(skimr) # summary statistics
library(mapview) # to save interactive map as an image


# base tile
leaflet() %>% 
  addProviderTiles(""CartoDB.DarkMatter"") %>%
  setView(lng = -100, lat = 35, zoom = 4)

# load files
# starbucks
starbucks <- read_excel(here(""coffee_chains.xlsx""), sheet = 1)
glimpse(starbucks)

# dunkin' donuts
dunkin_donuts <- read_excel(here(""coffee_chains.xlsx""), 
                            sheet = 3)
glimpse(dunkin_donuts)

# wrangling data
# starbucks
starbucks_tidy <- starbucks %>%
  # select only coffee locations in the USA
  filter(Country == ""US"", 
         Brand == ""Starbucks"") %>%
  # select only columns of interest. Without longitude and latitude we cannot map the locations 
  select(Brand, 
         lng = Longitude, 
         lat = Latitude, 
         Country) %>%
  # tidy the columns' names
  select_all(tolower)
glimpse(starbucks_tidy)

# dunkin' donuts
dunkin_donuts_tidy <- dunkin_donuts %>%
  # various cases where the name is not well spelled. we need to recode them
  mutate(biz_name = recode(biz_name,
                           ""Donuts Dunkin"" = ""Dunkin' Donuts"",
                           ""Dunkin' Donuts-baskln Robbins"" = ""Dunkin' Donuts"",
                           ""Dunkin' Donuts Center"" = ""Dunkin' Donuts"",
                           ""Dunkin' Donuts/Baskin Robbins"" = ""Dunkin' Donuts"")) %>%
  # select only cases where the coffee chain is Dunkin' Donuts
  filter(biz_name == ""Dunkin' Donuts"") %>%
  # select columns of interest and change its names 
  select(brand = biz_name, 
         lng = loc_LONG_poly, 
         lat = loc_LAT_poly, 
         country = e_country) %>%
  mutate(country = 
           case_when(country == ""USA"" ~ ""US""))
glimpse(dunkin_donuts_tidy)


# combine cases
coffee_chains <- bind_rows(starbucks_tidy, dunkin_donuts_tidy)
skim(coffee_chains)

# create colors
pal_color <- colorFactor(palette = c(""#007042"", 
                                     ""#ea4498""),
                         levels = c(""Starbucks"", 
                                    ""Dunkin' Donuts""))

#-----leaflet map-----#
coffee_chains_interactive <- 
  #add coffe_chains to our map
  coffee_chains %>% 
  leaflet(width = ""100%"", 
        options = leafletOptions(preferCanvas = TRUE)) %>% 
  addProviderTiles(""CartoDB.DarkMatter"", 
                   options = providerTileOptions(
                     updateWhenZooming = FALSE,
                     updateWhenIdle = TRUE)) %>% 
  addProviderTiles(""CartoDB.DarkMatter"") %>% 
  addCircleMarkers(data = filter(coffee_chains, brand == ""Starbucks""),# add brand filter
                   radius = 3,
                   label = ~htmlEscape(brand),
                   color = ~pal_color(brand),
                   popup = ~paste0(""<b>"", brand),
                   group = ""Starbucks"") %>%
  addCircleMarkers(data = filter(coffee_chains, brand == ""Dunkin' Donuts""),# add brand filter
                   radius = 3,
                   label = ~htmlEscape(brand),
                   color = ~pal_color(brand),
                   popup = ~paste0(""<b>"", brand),
                   group = ""Dunkin' Donuts"" ) %>%
  # add legend
  addLegend(pal = pal_color, 
            values = c(""Starbucks"", ""Dunkin' Donuts""),
            # opacity of .5, legend title called Brand and its position on the topright corner
            opacity = 0.5, title = ""Brand"", position = ""topright"") %>%
  # add layers to select the brands that are mapped
  addLayersControl(overlayGroups = c(""Starbucks"", ""Dunkin' Donuts"")) 


coffee_chains_interactive

# save as a webmap
saveWidget(coffee_chains_interactive, ""coffee_usa.html"")

# save as an image
mapshot(coffee_chains_interactive, file = ""coffee_usa.jpg"")
","Other-6/"
"817",1141,"https://github.com/toscano84/TidyTuesday/blob/master/Week26/TT_week26.R","toscano84","TidyTuesday","Week26/TT_week26.R","# Tidy Tuesday Week 26

# libraries needed
library(tidyverse)
library(data.table)
library(viridis)
library(extrafont)
library(worldtilegrid)


# import and load fonts
font_import()
loadfonts(device = ""win"")

# load file
invasion_threat <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-09-25/table_1.csv"")

# create tiles file - check Bob Rudis blog https://rud.is/b/2018/08/27/simplifying-world-tile-grid-creation-with-geom_wtg/
country_tiles <- data.frame(
  ctry = worldtilegrid::wtg$alpha.3)

# create new variable country
country_tiles <- country_tiles %>%
  mutate(country = case_when(ctry == ""ALB"" ~ ""Albania"",
                             ctry == ""ARG"" ~ ""Argentina"",
                             ctry == ""ARM"" ~ ""Armenia"",
                             ctry == ""AUS"" ~ ""Australia"",
                             ctry == ""AUT"" ~ ""Austria"",
                             ctry == ""AZE"" ~ ""Azerbaijan"",
                             ctry == ""BDI"" ~ ""Burundi"",
                             ctry == ""BEL"" ~ ""Belgium"",
                             ctry == ""BFA"" ~ ""Burkina Faso"",
                             ctry == ""BGD"" ~ ""Bangladesh"",
                             ctry == ""BGR"" ~ ""Bulgaria"",
                             ctry == ""BIH"" ~ ""Bosnia and Herzegovina"",
                             ctry == ""BLR"" ~ ""Belarus"",
                             ctry == ""BLZ"" ~ ""Belize"",
                             ctry == ""BRA"" ~ ""Brazil"",
                             ctry == ""BRB"" ~ ""Barbados"",
                             ctry == ""CAN"" ~ ""Canada"",
                             ctry == ""CHE"" ~ ""Switzerland"",
                             ctry == ""CHL"" ~ ""Chile"",
                             ctry == ""CHN"" ~ ""China"",
                             ctry == ""CMR"" ~ ""Cameroon"",
                             ctry == ""COD"" ~ ""Congo (Republic of)"",
                             ctry == ""COL"" ~ ""Colombia"",
                             ctry == ""CPV"" ~ ""Cape Verde"",
                             ctry == ""CRI"" ~ ""Costa Rica"",
                             ctry == ""CYP"" ~ ""Cyprus"",
                             ctry == ""CZE"" ~ ""Czech Republic"",
                             ctry == ""DEU"" ~ ""Germany"",
                             ctry == ""DNK"" ~ ""Denmark"",
                             ctry == ""DOM"" ~ ""Dominican Republic"",
                             ctry == ""DZA"" ~ ""Algeria"",
                             ctry == ""ECU"" ~ ""Ecuador"",
                             ctry == ""EGY"" ~ ""Egypt"",
                             ctry == ""ESP"" ~ ""Spain"",
                             ctry == ""EST"" ~ ""Estonia"",
                             ctry == ""ETH"" ~ ""Ethiopia"",
                             ctry == ""FIN"" ~ ""Finland"",
                             ctry == ""FJI"" ~ ""Fiji"",
                             ctry == ""FRA"" ~ ""France"",
                             ctry == ""GBR"" ~ ""United Kingdom"",
                             ctry == ""GEO"" ~ ""Georgia (Republic)"",
                             ctry == ""GHA"" ~ ""Ghana"",
                             ctry == ""GIN"" ~ ""Guinea"",
                             ctry == ""GMB"" ~ ""Gambia"",
                             ctry == ""GNB"" ~ ""Guinea-Bissau"",
                             ctry == ""GNQ"" ~ ""Equatorial Guinea"",
                             ctry == ""GRC"" ~ ""Greece"",
                             ctry == ""HND"" ~ ""Honduras"",
                             ctry == ""HRV"" ~ ""Croatia"",
                             ctry == ""HUN"" ~ ""Hungary"",
                             ctry == ""IDN"" ~ ""Indonesia"",
                             ctry == ""IND"" ~ ""India"",
                             ctry == ""IRL"" ~ ""Ireland"",
                             ctry == ""IRN"" ~ ""Iran"",
                             ctry == ""IRQ"" ~ ""Iraq"",
                             ctry == ""ISL"" ~ ""Iceland"",
                             ctry == ""ISR"" ~ ""Israel"",
                             ctry == ""ITA"" ~ ""Italy"",
                             ctry == ""JAM"" ~ ""Jamaica"",
                             ctry == ""JOR"" ~ ""Jordan"",
                             ctry == ""JPN"" ~ ""Japan"",
                             ctry == ""KAZ"" ~ ""Kazakhstan"",
                             ctry == ""KEN"" ~ ""Kenya"",
                             ctry == ""KGZ"" ~ ""Kyrgyzstan"",
                             ctry == ""KHM"" ~ ""Cambodia"",
                             ctry == ""KOR"" ~ ""Korea Republic of"",
                             ctry == ""LAO"" ~ ""Laos"",
                             ctry == ""LBN"" ~ ""Lebanon"",
                             ctry == ""LKA"" ~ ""Sri Lanka"",
                             ctry == ""LTU"" ~ ""Lithuania"",
                             ctry == ""LUX"" ~ ""Luxembourg"",
                             ctry == ""LVA"" ~ ""Latvia"",
                             ctry == ""MAR"" ~ ""Morocco"",
                             ctry == ""MDA"" ~ ""Moldova"",
                             ctry == ""MDG"" ~ ""Madagascar"",
                             ctry == ""MEX"" ~ ""Mexico"",
                             ctry == ""MKD"" ~ ""Macedonia"",
                             ctry == ""MLI"" ~ ""Mali"",
                             ctry == ""MLT"" ~ ""Malta"",
                             ctry == ""MNG"" ~ ""Mongolia"",
                             ctry == ""MOZ"" ~ ""Mozambique"",
                             ctry == ""MUS"" ~ ""Mauritius"",
                             ctry == ""MWI"" ~ ""Malawi"",
                             ctry == ""MYS"" ~ ""Malaysia"",
                             ctry == ""NER"" ~ ""Niger"",
                             ctry == ""NGA"" ~ ""Nigeria"",
                             ctry == ""NIC"" ~ ""Nicaragua"",
                             ctry == ""NLD"" ~ ""Netherlands"",
                             ctry == ""NOR"" ~ ""Norway"",
                             ctry == ""NPL"" ~ ""Nepal"",
                             ctry == ""NZL"" ~ ""New Zealand"",
                             ctry == ""PAK"" ~ ""Pakistan"",
                             ctry == ""PAN"" ~ ""Panama"",
                             ctry == ""PER"" ~ ""Peru"",
                             ctry == ""PHL"" ~ ""Philippines"",
                             ctry == ""POL"" ~ ""Poland"",
                             ctry == ""PRT"" ~ ""Portugal"",
                             ctry == ""PRY"" ~ ""Paraguay"",
                             ctry == ""QAT"" ~ ""Qatar"",
                             ctry == ""ROU"" ~ ""Romania"",
                             ctry == ""RUS"" ~ ""Russian Federation"",
                             ctry == ""RWA"" ~ ""Rwanda"",
                             ctry == ""SAU"" ~ ""Saudi Arabia"",
                             ctry == ""SDN"" ~ ""Sudan"",
                             ctry == ""SGP"" ~ ""Singapore"",
                             ctry == ""SLV"" ~ ""El Salvador"",
                             ctry == ""SUR"" ~ ""Suriname"",
                             ctry == ""SVK"" ~ ""Slovakia"",
                             ctry == ""SVN"" ~ ""Slovenia"",
                             ctry == ""SWE"" ~ ""Sweden"",
                             ctry == ""TGO"" ~ ""Togo"",
                             ctry == ""THA"" ~ ""Thailand"",
                             ctry == ""TJK"" ~ ""Tajikistan"",
                             ctry == ""TTO"" ~ ""Trinidad and Tobago"",
                             ctry == ""TUN"" ~ ""Tunisia"",
                             ctry == ""TUR"" ~ ""Turkey"",
                             ctry == ""UKR"" ~ ""Ukraine"",
                             ctry == ""URY"" ~ ""Uruguay"",
                             ctry == ""USA"" ~ ""USA"",
                             ctry == ""VEN"" ~ ""Venezuela"",
                             ctry == ""VNM"" ~ ""Vietnam"",
                             ctry == ""VUT"" ~ ""Vanuatu"",
                             ctry == ""YEM"" ~ ""Yemen"",
                             ctry == ""ZAF"" ~ ""South Africa""))

# join both datasets
invasion_threat_tidy <- invasion_threat %>%
  left_join(country_tiles, by = ""country"")

#----plot----#
invasion_threat_tidy %>%
  mutate_at(vars(ctry), as.character) %>% # I had to transform the ctry variable to character - Without it cant make the plot
  mutate(
    invasion_threat = cut(
      x = invasion_threat,
      breaks = c(1, 0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55,
                 0.50, 0.45, 0.40, 0.35, 0.30, 0.25, 0.20,
                 0.15, 0.10, 0.05, 0)) # cut the invasion_threat variable in various intervals
  ) %>%
  ggplot(aes(country = ctry, fill = invasion_threat)) +
  geom_wtg() + 
  geom_text(aes(label = stat(alpha.2)), 
            stat=""wtg"", size=2) + # adding text with the country abbreviations
  coord_equal() +
  scale_fill_viridis_d(option = ""inferno"",
                              na.value=""grey"", 
                              guide = guide_legend(reverse = TRUE)) +
  labs(title = ""Global Threat  to Agriculture from Invasive Species"",
       fill = ""Invasion Threat"", caption = ""Source:http://www.pnas.org/content/113/27/7575"") +
  hrbrthemes::theme_ft_rc() +
  theme_enhance_wtg() +
  theme(legend.position = ""right"", 
        plot.title = element_text(family = ""Bell MT"", 
                                  hjust = 0.5, size = 18),
        legend.title = element_text(family = ""Bell MT""),
        legend.text = element_text(family = ""Bell MT"", size = 12),
        plot.caption = element_text(family = ""Bell MT""))
","Other-26"
"818",1185,"http://github.com/wvictor14/tidytuesday","wvictor14","tidytuesday","week22_wine.Rmd","---
title: ""Week22_Wine""
output: github_document
editor_options: 
  chunk_output_type: console
---

# Setup

```{r, message = F, warning = F}
library(tidyverse)
library(ggrepel)
library(scales)
library(RColorBrewer)
library(ggridges)
library(viridis)
library(egg)

# Read in data
wine_data <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv"")
```

# Clean data

```{r}
wine_data <- wine_data %>%
  
  # filter out country == NA
  filter(!is.na(country)) %>%

  # compute intervals
  mutate(interval = cut(points, breaks = seq(1,100, by = 0.25))) 
  
```

# Calculate density

...over wine ratings grouped by country 

```{r}
# first calculate sum of counts for each coutnry
sum_by_country <- wine_data %>%
  group_by(country) %>%
  summarize(sum_of_counts = n()) 

# calulate count per interval, then divide by total
sum_by_country_by_interval <- wine_data %>%
  group_by(country, interval) %>%
  summarize(counts = n()) %>%
  left_join(sum_by_country) %>%
  mutate(prop_counts = counts/sum_of_counts) 


# need to calculate midpoints for each interval
# taken from  https://www.r-bloggers.com/finding-the-midpoint-when-creating-intervals/
midpoints <- function(x, dp=4){
  lower <- as.numeric(gsub(',.*','',gsub('\\(|\\[|\\)|\\]', '', x)))
  upper <- as.numeric(gsub('.*,','',gsub('\\(|\\[|\\)|\\]','', x)))
  return(round(lower+(upper-lower)/2, dp))
}
  
sum_by_country_by_interval <- sum_by_country_by_interval %>%
  mutate(points = midpoints(interval))
```

# Plotting

Let's organize the rows by their points median 

```{r}
order_of_countries <- wine_data %>%
  group_by(country) %>%
  summarize(ave_points = median(points)) %>%
  arrange(ave_points) %>%
  pull(country)


plot1 <- sum_by_country_by_interval %>%
  ungroup() %>%
  mutate(country = factor(country, levels = order_of_countries)) %>%
  ggplot(aes(x = points, y = country, fill = prop_counts)) +
  geom_tile() +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  scale_fill_viridis(na.value = viridis(100)[1],
                     limits = c(0,1), breaks = c(0.0,0.5,1), 
                     guide = guide_colorbar(title.position = 'top',
                                            barwidth = 10,
                                            barheight = 0.5)) +
  theme(panel.background = element_rect(fill=viridis(100)[1],
                                        colour=viridis(100)[1]),
        panel.grid = element_blank(),
        axis.text.x = element_text(size=13),
        axis.text.y = element_text(size=12),
        axis.title.x = element_text(size=15),
        legend.position = 'top') +
  coord_equal() +
  labs(fill = 'Proportion of ratings', y = '', x = 'Number of points\nrated out of 100')
plot1
```

Some countries have really narrow distributions. Is it because there were only
a few ratings or a few wines for that country? Or is their unanimous agreement.

```{r}
plot2 <- wine_data %>% count(country) %>%
  mutate(country = factor(country, levels = order_of_countries)) %>%
  ggplot(aes(x = country, y = n)) +
  geom_bar(stat = 'identity', fill = viridis(100)[1]) +
  scale_y_log10(expand = c(0,0),
                breaks = c(1,10,100,1000,10000)) +
  theme_classic() +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        panel.grid.major.x= element_line(color = 'grey', 
                                         lineend = 'round',
                                         linetype = 'dashed'),
        axis.title.x = element_text(size = 15)) +
  coord_flip() +
  labs(y = 'Number of ratings', x = '')
plot2
```

put em together

```{r}
plot3 <- egg::ggarrange(plot1, plot2, nrow = 1)
```

Save plot

```{r eval = F}
png('plots/week22_wine.png', units = 'in', height = 14, width = 12, res = 300)
print(plot3)
dev.off()
```","Other-22"
"819",1186,"http://github.com/wvictor14/tidytuesday","wvictor14","tidytuesday","week23_ramen.Rmd","---
title: ""Week23 Ramen Ratings""
author: ""Victor""
date: ""07/06/2019""
output: github_document
editor_options: 
  chunk_output_type: console
---

# Setup

```{r, message = F, warning = F}
library(tidyverse)
library(ggrepel)
library(scales)
library(RColorBrewer)
library(viridis)
library(egg)
library(tidytext)
library(wordcloud)
library(LaCroixColoR)

# Read in data
ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")
```

# Clean data

```{r warning = F}
cleaned_data <- ramen_ratings %>% 
  add_count(country) %>%
  arrange(desc(n)) %>%
  filter(n %in% head(unique(n),6)) %>%
  unnest_tokens(word, variety) %>% # separate variety column by word
  anti_join(get_stopwords()) %>% # remove stopwords
  group_by(country) %>%
  count(word, sort = TRUE)  %>%
  filter(n > 5)
  

cleaned_data_wide <- cleaned_data %>% ungroup() %>% spread(word, n) %>% as.data.frame() # make wide
rownames(cleaned_data_wide) <- cleaned_data_wide$country # add rownames
cleaned_data_wide <- cleaned_data_wide[,2:ncol(cleaned_data_wide)] # remove countries variable
cleaned_data_wide[is.na(cleaned_data_wide)] <- 0 # replace NAs with 0
cleaned_data_wide <- t(cleaned_data_wide) # transpose

comparison.cloud(cleaned_data_wide,
                 colors = lacroix_palette(""PassionFruit"", 6),
                 title.size = 2,
                 scale = c(4, 0.5),
                 rot.per = 0.25,
                 title.bg.colors = c('white')) 
```

# Save plot

```{r, eval = F}
png('plots/week23_ramen.png', units = 'in', height = 5.9, width = 10.1, res = 300)
comparison.cloud(cleaned_data_wide,
                 colors = lacroix_palette(""PassionFruit"", 6),
                 title.size = 1.7,
                 scale = c(4, 0.5),
                 rot.per = 0.3,
                 title.bg.colors = c('white')) 
dev.off()
```","Other-23"
"820",1187,"http://github.com/wvictor14/tidytuesday","wvictor14","tidytuesday","week25_birds.Rmd","---
title: ""Week 25 Bird Counting""
author: ""Victor Yuan""
date: ""07/06/2019""
output: github_document
editor_options: 
  chunk_output_type: console
---

I have previously seen someone make a very nice 'bump' plot (which I did not know
that was the name of the type of plot I saw at the time). I haven't been able to
find that plot in my mind, I think it was probably from someone from [The Pudding](https://pudding.cool/). Anyways, this TidyTuesday I thought it would be
cool to try that type of visualization out.

After some googling I found some blog posts that I helped me get started on the 
plot code:

1. [dog breeds](https://luisdva.github.io/rstats/dog-bump-chart/)
2. [bump chart](https://dominikkoch.github.io/Bump-Chart/)


# Setup

```{r, message = F, warning = F}
library(tidyverse)
library(RColorBrewer)
library(LaCroixColoR)
library(extrafont)
loadfonts(device = ""win"")

# Read in data
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")
```

Initial exploratory work quickly made me realize that I need to focus on a few 
select species, otherwise the plot will be overcrowded:

```{r}
bird_counts %>% glimpse()

bird_counts %>%
  group_by(year) %>%
  mutate(count = sum(how_many_counted)) %>%
  ggplot(aes(x = year, y = count, group = year)) +
  geom_point()
```

I decide to filter to the 9 most abundant species in the most recent year. I 
chose 9 because that's the maximum number of categories for discrete color scales
in th Rcolorbrewer package.

```{r}
# create ranking per year
bird_counts_rank <- bird_counts %>%
  arrange(year, desc(how_many_counted)) %>%
  group_by(year) %>%
  mutate(year_rank = row_number()) %>%
  ungroup()

# get vector of top 9 species in year 2017
top9 <- bird_counts_rank %>%
  filter(year == 2017) %>% filter(year_rank < 10) %>%
  pull(species)
```


After testing a few things out I decided to look at the top 9 species found in
the latest year (2017). This is, again, to avoid overcrowding of the plots.

```{r}
# create color code
others <- setdiff(bird_counts_rank$species %>% unique, top9)
color_code <- setNames(c(brewer.pal(9, ""Set1""), rep('grey', length(others))),
                       c(top9, others))
# font
font <- 'Ubuntu Mono'

# past n-1 years to visualize
nyear <- 21

bird_counts_rank %>% 
  
  # filter to top 9
  filter(species %in% top9,
         year > 2017-nyear) %>%
  
  # relevel on order of top 9 in 2017
  mutate(species = factor(species, levels = top9)) %>% 
  
  {
    ggplot(., aes(x = year, y = year_rank, color = species)) +
      # geom segement for fake gridlines
      geom_segment(data = ., aes(x = year, xend = year,
                                 y = min(.$year_rank), yend = max(.$year_rank)),
                   color = 'grey', alpha = 0.7) +
      
      # basics
      geom_line(size = 1, alpha = 0.5) +
      geom_point(size = 4) +
      geom_text(color = 'white', aes(label = year_rank), size = 1.75) +
      
      # labels for left and right of lines
      geom_text(data =  . %>% filter(year == min(year)),
                aes(label = species, x = min(.$year)-0.5, color = species) , 
                hjust = 'right', nudge_x = 0.1, family = font, size = 3.5) +
      geom_text(data =  . %>% filter(year == max(year)),
                aes(label = species, x = max(.$year)-0.5, color = species) , 
                hjust = 'left', nudge_x = 0.85, family = font, size = 3.5) +

      # x axis
      scale_x_continuous(expand = c(0.2,0.2),
                         breaks = (2017-(nyear-1)):2017,
                         labels = gsub('^[0-9]{2}', ""'"", as.character((2017-(nyear-1)):2017))) +
      
      # other stuff
      #scale_color_brewer(palette = 'Dark2')  +
      scale_color_manual(values = lacroix_palette(""Pamplemousse"", 9)) +
      scale_y_reverse(breaks = 1:max(.$year_rank)) +
      theme_bw() +
      theme(panel.grid.major.y = element_blank(),
            panel.grid.minor.y = element_blank(),
            panel.grid.major.x = element_blank(),
            panel.grid.minor.x = element_blank(),
            panel.border = element_blank(),
            axis.ticks = element_blank(),
            axis.title = element_text(face = 'bold'),
            legend.position = '',
            title = element_text(face = 'bold'),
            text = element_text(family = font)) +
      labs(x = 'Year', y = 'Rank', 
           title = 'Most common xmas bird sightings',
           subtitle = 'in Hamilton, Onatrio. 1997-2017')
    }
```

```{r eval = F}
ggsave('plots/week25_birds.png', dpi = 300)
```

**Lessons learned:**

*1. Bump plots are really hard to read unless you are working with less than 10 groups*

  Although probably if you wanted to highlight less than 10 groups in a largr group,
  that would be pretty cool too.

*2. fonts can be easily customized after some setup with extrafont*

if I had more time, I would want to try to use gganimate to highlight a single 
species per frame, over all years.






","Other-25"
"821",1188,"http://github.com/wvictor14/tidytuesday","wvictor14","tidytuesday","week27_soccer.Rmd","---
title: ""week27_soccer""
output: html_document
output: github_document
editor_options: 
  chunk_output_type: console
---


# Setup

```{r}
library(tidyverse)
library(RColorBrewer)
library(LaCroixColoR)
library(extrafont)

# Read in data
wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
```


# Explortation
```{r}
wwc_outcomes %>% group_by(team, year) %>%  summarize() %>% mutate(count = n()) %>% 
  group_by(team) %>% filter(count == 8) %>% summarize()
```

# Prepare data

I want the most successful teams to show up at the top, and then decrease in success towards bottom
of graph.

I'll define 'success' as number of wins over the entire dataset

```{r}
# arrange by cummulative wins over all seasons
team_order <- wwc_outcomes %>% 
  group_by(team) %>%
  summarize(cum_win = sum(win_status == 'Won')) %>%
  arrange(desc(cum_win))


wwc_outcomes <- wwc_outcomes %>%
  
  # filter to top 10 teams
  filter(team %in% team_order$team[1:10]) %>%
  
  # reorder factors for order of appearance on graph
  mutate(team = factor(team, levels = team_order$team[1:10]),
         win_status = factor(win_status, levels = c('Won', 'Tie', 'Lost')),
         round = factor(round, levels = c('Group', 'Round of 16', 'Quarter Final', 'Semi Final', 
                                          'Third Place Playoff', 'Final'))) %>%
  
  # divide 'round = group' into however many grou pmatches were played that year per team
  arrange(year, team, round)  %>%
  group_by(year, team) %>%
  mutate(round = factor(ifelse(round == 'Group', 
                               paste(round, row_number()), 
                               as.character(round)),
                        levels = c('Group 1', 'Group 2', 'Group 3',  'Round of 16', 
                                   'Quarter Final', 'Semi Final', 'Third Place Playoff', 'Final'))) 

# create a ranking number to plot on the axis
wwc_outcomes %>%
  ungroup() %>%
  arrange(year, team, round) %>%
  group_by(year, team) %>%
  mutate(rank = row_number()) %>%
  
  ggplot(aes(x = win_status, y = rank, color = round)) +
  geom_point(size = 3) +
  geom_vline(xintercept = 2, color = 'grey') +
  facet_grid(rows = vars(team), cols = vars(year), switch = 'y') +
  coord_flip() +
  theme_bw() + 
  theme(panel.spacing = unit(0, ""lines""),
        strip.background = element_blank(),
        strip.text.y = element_text(angle = 180),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank()) +
  labs(x = '', y = '') +
  scale_x_discrete(expand = c(0.76, 0.75)) +
  scale_y_discrete(expand = c(0.05, 0.05))


  
```

","Other-27"
"822",1192,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_#27_Code.R","#### PLOTLY TO MAKE INTERACTIVE VIDEO-------------------------------------------
library(plotly)
library(tidyverse)
library(lubridate)
library(zoo)

#Import Data
df <- read.csv(""TidyTuesday/Data/TT_27/Births.csv"")

#Group data into monthly averages
df1 <- df %>%
  group_by(year, month) %>%
  summarize(births = mean(births))

#Create new row for accumulation function
df1$id <- 1:nrow(df1)

#Acculumate by Function
accumulate_by <- function(dat, var) {
  var <- lazyeval::f_eval(var, dat)
  lvls <- plotly:::getLevels(var)
  dats <- lapply(seq_along(lvls), function(x) {
    cbind(dat[var %in% lvls[seq(1, x)], ], frame = lvls[[x]])
  })
  dplyr::bind_rows(dats)
}

#Remove excess attributes from data processing
df1<- as.data.frame(df1)

#Create new data set with accumulation variable (used for frames in plotly)
df_plotly <- df1 %>%
  accumulate_by(~id)

#Reformat dates into a usable format
df_plotly$Date <- as.yearmon(paste(df_plotly$year, df_plotly$month), ""%Y %m"")
df_plotly$Date <- as.Date.yearmon(df_plotly$Date)

#Create Interactive Plot
p <- plot_ly(data = df_plotly,
             x = ~Date,
             y = ~births) %>%
  add_trace(x = ~Date, y = ~births, frame = ~frame, type = 'scatter', mode = 'lines+markers', line = list(shape = ""spline"")) %>%
  layout(xaxis = list(title = ""Date"",
                      range = c(min(df_plotly$Date),max(df_plotly$Date)),
                      zeroline = F),
         yaxis = list(title = ""Monthly Births"",
                      range = c(min(df_plotly$births)-2000,max(df_plotly$births)+1000),
                      zeroline = F)) %>%
  animation_opts(frame = 100,
                 transition = 0,
                 redraw = FALSE) %>%
  animation_slider(hide = T) %>%
  animation_button(x = 1, xanchor = ""right"", y = 0, yanchor = ""bottom"")

#Set plotly API information
Sys.setenv(""plotly_username""=""YOUR PLOTLY USERNAME"")
Sys.setenv(""plotly_api_key""=""YOUR PLOTLY API KEY"")

#Send plot to https://plot.ly/~YOUR PLOTLY USERNAME/
api_create(p)


#### Faceted Bar Chart ---------------------------------------------------------
library(tidyverse)

#Import Data
df <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_27/Births.csv"")

#Group data into monthly averages
df <- df %>%
  group_by(year, month, day_of_week) %>%
  summarize(births = mean(births))

df$month <- month.abb[df$month]
df$day_of_week <- as.character(df$day_of_week)
df$day_of_week[df$day_of_week == ""1""] <- ""Monday""
df$day_of_week[df$day_of_week == ""2""] <- ""Tuesday""
df$day_of_week[df$day_of_week == ""3""] <- ""Wednesday""
df$day_of_week[df$day_of_week == ""4""] <- ""Thursday""
df$day_of_week[df$day_of_week == ""5""] <- ""Friday""
df$day_of_week[df$day_of_week == ""6""] <- ""Saturday""
df$day_of_week[df$day_of_week == ""7""] <- ""Sunday""

df$day_of_week <- factor(df$day_of_week, levels=c(""Monday"",""Tuesday"",""Wednesday"",""Thursday"",""Friday"", ""Saturday"",""Sunday""))
df$month <- factor(df$month, levels=c(""Jan"",""Feb"",""Mar"",""Apr"",""Jun"", ""Jul"",""Aug"",
                                      ""Sep"", ""Oct"", ""Nov"", ""Dec""))

ggplot(na.omit(df)) + geom_col(aes(x = day_of_week, y = births)) +
  geom_hline(yintercept = c(50000, 100000, 150000, 200000), color =""white"") +
  facet_wrap(~month) + theme_classic() +
  labs(title = ""United States Births 2000-2014"",x = ""Day of\nthe Week"", y = ""Births"") +
  #scale_fill_manual(""Hub Type"",values=c(""#0868ac"", ""#2ca25f"", ""#fd8d3c"",""lightgrey"")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(size = 20, face = ""bold"", hjust = 0.5),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=12))
","Other-27"
"823",1193,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_#28_Code.R","#Load Required Packages
library(tidyverse)
library(geofacet)
library(maps)
library(raster)
library(cartogram)  

#Import Turnout Dataset
df <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_28/voter_turnout.csv"")

#View Data and Structure
View(df)
str(df)

#Create voter turnout percetage
df$Turnout <- (df$votes/df$eligible_voters) *100

ggplot(df) +
  geom_point(aes(year, Turnout), color = ""lightgrey"") +
  geom_smooth(aes(year, Turnout), se = FALSE, color = ""#6495ED"") + 
  facet_geo(~state, grid = us_state_grid2) +
  theme_classic() +
  labs(title = ""Tidy Tuesday #28"",
       subtitle = ""United States Voter Turnout 1980-2014"",
       x = ""Year"",
       y = ""Voter Turnout\n(%)"",
       caption = ""Data from: data.world"") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.text.y = element_text(angle = 0, hjust = 1),
        axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(size = 20, face = ""bold"", hjust = 0.5),
        plot.subtitle = element_text(size = 16, face = ""bold"", hjust = 0.5),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=12))
","Other-28"
"824",1194,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_#29_Code.R","##Tidy Tuesday Week #29
###Example modeled off of the example from:
# https://www.r-bloggers.com/the-grammar-of-graphics-and-radar-charts/

#Load Required Packages
library(tidyverse)
library(scales)
library(reshape2)
library(tibble)
#Import Turnout Dataset
df <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_29/grads.csv"")

#View Data and Structure
View(df)
str(df)

#Group By Major_category and summarize all variables by mean
df_major <- df %>% group_by(Major_category) %>% summarise_all(funs(mean))

#Select subset of a few major variables 
#Major_Categorgy, Men, Women, Employed, Median Income
df_major <- df_major[,c(1,6,7,10,16)]

#Reshape data 
df_major <-  df_major %>%
  mutate_each(funs(rescale), -Major_category) %>% 
  melt(id.vars=c('Major_category'), measure.vars=colnames(df_major)) %>% 
  arrange(Major_category)

# Remove rows that the variable is major category (error)
df_major<-df_major[!(df_major$variable==""Major_category""),]

#Convert Value to numeric
df_major$value <- as.numeric(df_major$value)

#Plot coord_polar chart
df_major %>%
  ggplot(aes(x=variable, y=value, group=Major_category, color=Major_category)) + 
  geom_polygon(fill=NA) +
  theme_bw() +
  coord_polar() + facet_wrap(~ Major_category) 

","Other-29"
"825",1195,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_#32_Code.R","##Tidy Tuesday Week #32
###Example modeled off of the example from:
#https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-11-06

### Introduction----------------------------------------------------------------
#Load Required Packages
library(tidyverse)

#Import Turnout Dataset
df <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_32/us_wind.csv"")

#View Data and Structure
View(df)
str(df)
summary(df)


#Subset Data for Visualization
#Select Subset of variables
#14:16 are turbine characteristics
#Turbine Characteristics Confidence
df1 <- df[,c(14:16, 22)]

#Select 250 random observations
df1 <- df1[sample(1:nrow(df1), 250,
                  replace=FALSE),]

#Remove all observations with ""-9999""
df1[df1 == -9999] <- NA
df1 <- df1[complete.cases(df1), ]


#To create a basic scatterplot matrix just requires using the pairs function
pairs(df1[1:3]) #only quantitative variables

#Modified scatterplot matricies
require(""RColorBrewer"")
display.brewer.pal(4,""Pastel1"") #display colorpalette

#Put Histograms on the diagonal (from ""pairs"" Help)
#Creating new function
panel.hist  <- function(x,...)
{
  usr <- par(""usr""); on.exit(par(usr))
  par(usr = c(usr[1:2], 0,1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, ...)
}

#Re-run pairs using the panel.hist function
pairs(df1[1:3],
      panel = panel.smooth,
      main = ""Scatterplot Maxtris for Turbine Characteristics \n Tidy Tuesday Week #32"",
      diag.panel = panel.hist,
      pch = 16, 
      col = brewer.pal(4,""Pastel1"")[df1$t_img_srce],
      oma=c(4,4,7,20))

legend(locator(), legend = levels(df1$t_img_srce), fill= brewer.pal(4,""Pastel1""))
","Other-32"
"826",1196,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_#37_Code.R","#Tidy Tuesday Week #37
#By Richard Johansen
#Twitter: @DataVizJohansen
#GitHub: RAJohansen

#load tidyverse!
library(tidyverse)

### Import and save data (Script from Tidy Tuesday Week 37) --------------------
#install.packages(""janitor"")
set.seed(20181209)
# You can use this url to download the data directly into R (will take a few seconds)
df <- read_csv(""https://data.cityofnewyork.us/api/views/43nn-pn8j/rows.csv"")

# Cleaning names with janitor, sampling 300,000 records, and dropping some variables
sampled_df <- df %>% 
  janitor::clean_names() %>%
  select(-phone, -grade_date, -record_date, -building, -street) %>% 
  sample_n(size = 300000)

# save the .csv
write_csv(sampled_df, ""C:/R_Packages/TidyTuesday/Data/TT_37/nyc_restaurants.csv"")

### Tidy Tuesday Week #37 ----------------------------------------------------

#Load data set 
df <- read_csv(""C:/R_Packages/TidyTuesday/Data/TT_37/nyc_restaurants.csv"")

#Explore structure and data 
str(df)
summary(df)

#Convert Boro, Cuisine Type, and grade to factor
df$boro <- as.factor(df$boro)
df$cuisine_description <- as.factor(df$cuisine_description)
df$grade <- as.factor(df$grade)
df$violation_code <- as.factor(df$violation_code)
df <- mutate(df,""Code_Num"" = gsub(""[[:alpha:]]"","""",df$violation_code))
df$Code_Num <- as.factor(df$Code_Num)
df$violation_description <- as.factor(df$violation_description)

#Subset data where grades are posted (A,B, or C)
df_grade <- df[df$grade == ""A"" | df$grade == ""B"" | df$grade == ""C"" ,]

df_MH <- df_grade[df_grade$boro == ""MANHATTAN"",]
df_rest <- df_grade[df_grade$boro != ""Missing"",]

df_food <- df_rest[df_rest$cuisine_description == ""American"" | df_rest$cuisine_description == ""Barbecue"" | df_rest$cuisine_description == ""Chinese"" |df_rest$cuisine_description == ""French"" |  df_rest$cuisine_description == ""German"" | df_rest$cuisine_description == ""Greek"" | df_rest$cuisine_description == ""Indian"" | df_rest$cuisine_description == ""Italian"" | df_rest$cuisine_description == ""Middle Eastern"" | df_rest$cuisine_description == ""Scandinavian"" | df_rest$cuisine_description == ""Spanish"" | df_rest$cuisine_description == ""Thai"",]

#Dodged Bar chart of 10 food places and mean scores by boro
ggplot(na.omit(df_food), aes(x =cuisine_description, y = score, fill = grade)) +
  stat_summary(fun.y=""mean"", geom=""col"", position = ""stack"") +
  facet_wrap(~boro) +
  labs(title= ""Mean Inspection Scores for Popular Cuisine Types\n in the Five New York City Boroughs"", x = ""Cuisine Description"", y= ""Inspection Score\n (Mean)"") +
  theme_classic() +
  theme(axis.text.x=element_text(angle=90,hjust=1),
        axis.title.y = element_text(angle=0,vjust = 0.5),
        plot.title = element_text(hjust = 0.5))

","Other-37"
"827",1197,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TT_#38_Code.R","#Tidy Tuesday Week #38
#By Richard Johansen
#Twitter: @DataVizJohansen
#GitHub: RAJohansen

#load tidyverse!
library(tidyverse)


# Load Data
df <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_38/allCetaceanData.csv"")

#Explore structure and data 
str(df)
summary(df)

#Remove all rows where birth year is NA
df1 <- df[!is.na(df$birthYear),]

#Convert birth year from factor to numeric
df1$birthYear <- as.numeric(as.character(df1$birthYear))

#Plot Number of Cetacean Birth Types by species from 1938-2017

jpeg(""C:/R_Packages/TidyTuesday/Jpegs/TT_#39.jpeg"", width = 20, height = 16, units = 'in', res = 300)

ggplot(df1) +
  geom_histogram(aes(birthYear, fill = acquisition), binwidth =5, position = position_dodge2(preserve = ""single"")) +
  facet_wrap(~species) + 
  scale_y_log10() +
  theme_classic() +
  labs(title= ""Cetacean Birth Types by species from 1938-2017"", x = ""Animal's Birth Year"", y= ""Count"") +
  theme(axis.title.y = element_text(angle=0,vjust = 0.5),
        plot.title = element_text(hjust = 0.5))
  
#ggsave(""C:/R_Packages/TidyTuesday/Jpegs/TT_#39.jpeg"", units=""in"", width=20, height=16, dpi=300, compression = 'lzw')
dev.off()
","Other-38"
"828",1199,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TidyTuesday#25.R","#Load Required Packages
library(tidyverse)

#Read CSV Data
ap <- read.csv(""C:/temp/us-airports.csv"")

#Explore data structure and basic summary
str(ap)
summary(ap)

#Group Data by region, state, and year
#Summarize data by mean rank, total passengers, average passengers
ap_group <- ap %>% 
  group_by(region, state, year, hub_type) %>%
  summarize(rank = mean(yearly_rank),
            rank_max = max(yearly_rank),
            rank_min = min(yearly_rank),
                passengers = sum(passengers),
                ave_passengers = mean(passengers))


#Reorder Hub Type Factors
ap_group$hub_type <- factor(ap_group$hub_type, levels = c(""Large"", ""Medium"", ""Small"", ""Nonhub""))

#Plot data using ggplot
ggplot(na.omit(ap_group)) + 
  geom_col(aes(x=reorder(region,-passengers),y = passengers,
               fill = hub_type)) +
  facet_wrap(~year) + theme_classic() +
  labs(title = ""Regional Airline Travel from 2012-2017"",x = ""Geographic Region"", y = ""Airline\nPassengers"") +
  scale_fill_manual(""Hub Type"",values=c(""#0868ac"", ""#2ca25f"", ""#fd8d3c"",""lightgrey"")) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(size = 20, face = ""bold"", hjust = 0.5),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=12))

#Geo_Facet Example
library(geofacet)
ap_geo <- ap %>% 
  group_by(state, year) %>%
  summarize(rank = mean(yearly_rank),
            rank_max = max(yearly_rank),
            rank_min = min(yearly_rank),
            passengers = sum(passengers),
            ave_passengers = mean(passengers))

#Create New column that has full states names from abbreviation
ap$State_Name <- state.name[match(ap$state,state.abb)]
ap$hub_type <- factor(ap$hub_type, levels = c(""Large"", ""Medium"", ""Small"", ""Nonhub""))

#Create geo_faceted map 
ggplot(na.omit(ap)) +
  geom_point(aes(year, passengers, color = hub_type)) +
  facet_geo(~State_Name, grid = us_state_grid2) +
  theme_classic() +
  labs(title = ""Regional Airline Travel from 2012-2017"",x = ""Geographic Region"", y = ""Airline\nPassengers"") +
  scale_fill_manual(""Hub Type"",values=c(""#0868ac"", ""#2ca25f"", ""#fd8d3c"",""lightgrey"")) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        axis.title.y = element_text(angle = 0, vjust = 0.5),
        plot.title = element_text(size = 20, face = ""bold"", hjust = 0.5),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=12))","Other-25"
"829",1200,"https://github.com/RAJohansen/TidyTuesday","RAJohansen","TidyTuesday","Scripts/TidyTuesday#26.R","### Tidy Tuesday Week 26 (September 25 2018)
library(raster)                               
library(tidyverse)
library(tmap)
library(sp)

df_invasion <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_26/table_1.csv"")
df_cost <- read.csv(""C:/R_Packages/TidyTuesday/Data/TT_26/table_2.csv"")
df <- merge(df_cost,df_invasion,by=""country"")
colnames(df) <- c(""name"",""Cost"", ""Rank_Cost"", ""Rank_Threat"", ""Threat"")

World_Pest <- sp::merge(World, df, by =""name"", duplicateGeoms = TRUE)

tm_shape(World_Pest) +
  tm_fill(col = ""Threat"", n = 10, colorNA = ""white"") +
  tm_borders(""grey50"") +  
  tm_compass(type = ""8star"", position = c(""left"", ""top"")) +
  tm_layout(frame = FALSE)

tm_shape(World_Pest) +
  tm_fill(col = ""Cost"", n = 10, colorNA = ""white"") +
  tm_borders(""grey50"") +  
  tm_compass(type = ""8star"", position = c(""left"", ""top"")) +
  tm_layout(frame = FALSE)
","Other-26"
"830",1436,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","16-4-19/16-4-19 banderas.R","library(tidyverse)
library(magrittr)
library(ggthemes)
library(devtools)
#install_github(""rensa/ggflags"")
library(ggflags)

women_research <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-16/women_research.csv"")
women_research$country[grepl(""United Kingdom"",women_research$country)] <- ""UK""
women_research$country[grepl(""United States"",women_research$country)] <- ""US""
women_research$field[grepl(""Women inventores"",women_research$field)] <- ""Inventors""

wr<-women_research
wr$country[grepl(""Australia"", wr$country)]<-""au""
wr$country[grepl(""Chile"", wr$country)]<-""cl""
wr$country[grepl(""France"", wr$country)]<-""fr""
wr$country[grepl(""Portugal"", wr$country)]<-""pt""
wr$country[grepl(""Brazil"", wr$country)]<-""br""
wr$country[grepl(""Denmark"", wr$country)]<-""dk""
wr$country[grepl(""Japan"", wr$country)]<-""jp""
wr$country[grepl(""UK"", wr$country)]<-""gb""
wr$country[grepl(""Canada"", wr$country)]<-""ca""
wr$country[grepl(""EU28"", wr$country)]<-""eu""
wr$country[grepl(""Mexico"", wr$country)]<-""mx""
wr$country[grepl(""US"", wr$country)]<-""us""
wr$field[grepl(""Computer science, maths"", wr$field)]<-""Computer science & Maths""


wr %>% ggplot(aes(x=reorder(field, percent_women), y=percent_women*100, country=country), stringsAsFactors = FALSE)+
  geom_flag(size=8)+
  theme_bw()+
  theme(axis.title.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y = element_blank(),
        legend.position = ""NA"",
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 55, hjust = 1, size = 11),
        panel.background = element_rect(fill = ""#6D9EC1""),
        plot.title = element_text( size=16, face=""bold""),
        panel.grid.major.x = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.border = element_blank())+
  geom_hline(yintercept = 50, linetype=""dashed"", color = ""red"")+
  labs(title = ""Still a Man's World"",
       subtitle = ""Women among researchers\nwith papers published\n2011-15; % of total"",
       caption=""\""Inventors\"": Who filled patent applications\nSources: Gender in the Global Research Landscape by Elsevier;\nThe Economist"")
  
  
","Other-1"
"831",1440,"https://github.com/oranwutang/tidytuesdays_p","oranwutang","tidytuesdays_p","datosdemiercoles/3_5_19 Armas.R","library(tidyverse)
library(magrittr)
library(RColorBrewer)
library(ggpubr)
comercio_hispanoamerica_mundo <- readr::read_csv(""https://raw.githubusercontent.com/cienciadedatos/datos-de-miercoles/master/datos/2019/2019-05-01/comercio_hispanoamerica_mundo_agregado.csv"")

comercio_hispanoamerica_mundo %>% 
  filter(nombre_comunidad_producto==""Armas"") %>% 
  group_by(anio,nombre_pais_origen) %>% 
  summarise(Total=sum(valor_importado_dolares)) %>% 
  ggplot(aes(x=nombre_pais_origen, y=Total/10^6))+
  geom_line(size=2, color=""tomato2"")+
  geom_point(aes(color=as.factor(anio)),size=4)+
  scale_x_discrete(limits = rev(levels(as.factor(comercio_hispanoamerica_mundo$nombre_pais_origen))))+
  coord_flip()+
  scale_color_brewer(palette = ""Greens"")+
  theme(panel.background = element_rect(fill=""black""),
         panel.grid = element_blank(),
        legend.background = element_rect(fill = ""black""),
        legend.key = element_rect(fill = ""black"", color = NA),
        legend.text = element_text(color=""white""),
        legend.title = element_text(color=""white""),
        legend.position = c(0.9,0.15),
        axis.title.y = element_blank(),
        axis.title.x = element_text(color=""yellow""),
        axis.text = element_text(color=""yellow""),
        axis.text.y = element_text(size=12),
        axis.text.x = element_text(size=12),
        title = element_text(color=""yellowgreen"", size=16),
        plot.background = element_rect(fill = ""black""))+
  labs(color=""Ao"", 
        title = ""Gasto armamentstico en Latinoamrica"",
        subtitle = ""Gasto en importaciones de armas por aos"")+
  ylab(label = ""Millones de Dlares"")
","Other-2"
"832",1454,"https://github.com/will-r-chase/tidy_tuesday","will-r-chase","tidy_tuesday","week10_women_in_workplace/gender_part_time.R","extrafont::loadfonts(device=""win"")
library(tidyverse)
library(ggpomological)

#data
jobs_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/gender_earnings.csv"")
earnings_female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"") 
employed_gender <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"") 

#base theme
theme_du_bois <- function() {
  theme_gray(base_family = ""Inconsolata"") %+replace%
    theme(
      plot.background = element_rect(
        fill = ""antiquewhite2"",
        color = ""antiquewhite2""
      ),
      panel.background = element_rect(
        fill = ""antiquewhite2"",
        color = ""antiquewhite2""
      ),
      plot.title = element_text(
        face = ""bold"",
        hjust = 0
      )
    )
}

#get our data ready
part_time <- 
  employed_gender %>%
  select(year, part_time_female, part_time_male, full_time_female, full_time_male) %>%
  gather(key = var, value = percent, -year) %>%
  separate(var, into = c(""type"", ""time"", ""sex"")) %>%
  select(-time) %>%
  mutate(type = ifelse(type == ""full"", ""Full Time"", ""Part Time"")) %>%
  mutate(half_decade = (year %/% 5) * 5) %>% #this'll make it more blocky like the original
  group_by(half_decade, sex, type) %>%
  mutate(average = round(mean(percent), 0))

#x labels
labs <- c(""100"", ""90"", ""80"", ""70"", ""60"", ""50"", ""40"", ""30"", ""20"", ""10"", ""0"", ""10"",  ""20"",  ""30"",  ""40"",  ""50"",  ""60"",  ""70"",  ""80"",  ""90"",  ""100"")

plot <- 
ggplot(part_time, aes(x = rev(year), y = ifelse(sex==""male"", -average, average), fill = type)) +
  geom_bar(stat = ""identity"", width = 1) +
  geom_hline(yintercept = 0, linetype = ""solid"", size = 2) +
  annotate(""text"", x = c(2000, 2000, 2000, 2000), 
           y = c(-50, -6, 13, 50), label = c(""FULL-TIME"", ""PART-TIME"", ""PART-TIME"", ""FULL-TIME""),
           family = ""Inconsolata"", fontface = ""bold"", 
           angle = c(45, 60, -45, -45), size = 6) +
  coord_flip(clip = ""off"") +
  theme_du_bois() +
  scale_fill_manual(
    values = c(""royalblue3"", ""#C1032A""),
    labels = c(""PART-TIME"", ""FULL-TIME"")
  )  +
  scale_x_continuous(
    breaks = c(1969.5, 1974.5, 1979.5, 1984.5, 1989.5, 1994.5, 1999.5, 2004.5, 2009.5, 2014.5),
    labels = rev(c(""1970"", ""1975"", ""1980"", ""1985"", ""1990"", ""1995"", ""2000"", ""2005"", ""2010"", ""2015"")),
    expand = c(0, 0),
    sec.axis = dup_axis()
    ) +# dual age axis
  scale_y_continuous(
    breaks = seq(-100, 100, by = 10),
    labels = paste0(labs, ""%""),
    expand = c(0, 0),
    # lines on original plot are by 2s
    minor_breaks = seq(-100, 100, by = 2)
  ) +
  labs(title = ""Percent of part-time and full-time workers by sex"", 
       subtitle = ""Women have remained nearly constant over the last 48 years, while the proportion of men working part time is slowly increasing"",
       x = ""YEAR"", 
       y = ""PERCENTS"",
       caption = ""Graphic: @W_R_Chase\nData: Census Bureau"") +
  annotate(
    ""text"",
    label = c(""MALES"", ""FEMALES""),
    y = c(-50, 50),
    x = Inf, # is this a thing? will it just put it outside the panel with
    # clip = ""off""?
    vjust = -0.4,
    size = 6,
    family = ""Inconsolata"",
    fontface = ""bold""
  ) +
  theme(
    text = element_text(face = ""bold""),
    panel.background = element_blank(),
    plot.title = element_text(
      family = ""Cormorant Garamond"",
      face = ""plain"",
      size = 24,
      vjust = 8,
      margin = margin(t = 12, b = 5, unit = ""pt"")
    ),
    plot.subtitle = element_text(
      family = ""Cormorant Garamond"",
      face = ""plain"",
      size = 18,
      vjust = 8,
      margin = margin(b = 10, unit = ""pt"")
    ),
    axis.title = element_text(size = 14),
    axis.ticks = element_blank(),
    panel.grid.major = element_line(
      color = ""black"",
      size = 0.1
    ),
    panel.grid.minor.x = element_line(
      color = ""black"",
      size = 0.06
    ),
    panel.grid.minor.y = element_blank(),
    legend.background = element_blank(),
    legend.position = ""none"",
    legend.key = element_blank(),
    # put grid lines on top so not covered by plot
    panel.ontop = TRUE,
    panel.border = element_rect(
      fill = NA,
      color = ""black""
    ),
    axis.text.x = element_text(size = 12),
    # both axes titles for age hortizontal instead of vertical, and put them at
    # the top, just above the values
    axis.title.y = element_text(
      angle = 0,
      vjust = 1
    ),
    axis.title.y.right = element_text(
      angle = 0,
      vjust = 1
    ),
    # age group labels need to be slightly below grid line
    axis.text.y = element_text(
      vjust = 0.5,
      size = 12
    ),
    #something really weird with margins
    #when you change it it changes the weight of the grid lines
    #played with it to try to fix it... but gave up
    plot.margin = margin(t = 25, l = 10, r = 10, unit = ""pt"") 
  )


paint_pomological(plot, outfile = ""second_plot.png"", height = 650, width = 1100, pointsize = 18)

paint_pomological <- function(
  pomo_gg, 
  width = 800, 
  height = 500, 
  pointsize = 16, 
  outfile = NULL,
  pomological_background = ""week10_women_in_workplace/background.jpg"", 
  pomological_overlay = pomological_images(""overlay""),
  ...
) {
  if (!requireNamespace(""magick"", quietly = TRUE)) {
    stop(""The package magick is required for `paint_pomological()`. "",
         ""Please install with `install.packages('magick')`"")
  }
  if (!file.exists(pomological_background)) {
    warning(paste0(""Cannot find file \"""", pomological_background, ""\""""), call. = FALSE)
  }
  
  # Paint figure
  pomo_gg <- pomo_gg + ggplot2::theme(plot.background = ggplot2::element_rect(fill = 'transparent', colour = NA))
  gg_fig <- magick::image_graph(width, height, bg = ""transparent"", pointsize = pointsize, ...)
  print(pomo_gg)
  dev.off()
  
  if (!is.null(pomological_overlay) && file.exists(pomological_overlay)) {
    pomo_over <- magick::image_read(pomological_overlay)
    pomo_over <- magick::image_resize(pomo_over, paste0(width, ""x"", height, ""!""))
    gg_fig <- magick::image_composite(gg_fig, pomo_over, ""blend"", compose_args = ""15"")
  }
  
  # Paint background
  if (file.exists(pomological_background)) {
    pomo_bg <- magick::image_read(pomological_background)
    pomo_bg <- magick::image_resize(pomo_bg, paste0(width, ""x"", height, ""!""))
    pomo_bg <- magick::image_crop(pomo_bg, paste0(width, ""x"", height))
    
    # Paint figure onto background
    pomo_img <- magick::image_composite(pomo_bg, gg_fig)
  } else pomo_img <- gg_fig
  
  if (!is.null(outfile)) {
    # Do you want your picture framed?
    magick::image_write(pomo_img, outfile)
  }
  pomo_img
}

pomological_images <- function(which = c(""background"", ""overlay"")) {
  which <- match.arg(which)
  exts <- c(""background"" = "".png"", ""overlay"" = "".jpg"")
  system.file(""images"", paste0(""pomological_"", which, exts[which]),
              package = ""ggpomological"")
}

test <- paint_pomological(plot, outfile = ""test_plot.png"", height = 650, width = 1200)

part_time$row
rev(part_time$row)
extrafont::font_import()
","Other-10"
"833",1455,"https://github.com/will-r-chase/tidy_tuesday","will-r-chase","tidy_tuesday","week11_board_games/board_games.R","extrafont::loadfonts(device=""win"")
library(tidyverse)
library(ghibli)

board_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-12/board_games.csv"")
glimpse(board_games)

my_theme <- theme(
  panel.background = element_blank(),
  plot.background = element_rect(fill = ""#FCF5E3"", size = 0),
  legend.background = element_blank(),
  legend.key = element_blank(),
  panel.border = element_blank(),
  plot.subtitle = element_text(face = ""italic"", size = 14, vjust = 5), 
  plot.title = element_text(size = 18, vjust = 5),
  plot.caption = element_text(face = ""italic"", size = 8, vjust = 0.5, hjust = 1),
  panel.grid.major = element_line(size = 0.12, color = ""#E1DAC8""),
  panel.grid.minor = element_blank(), 
  axis.ticks = element_line(size = 0.03, color = ""#E1DAC8""),
  axis.title.x = element_text(vjust = -5, margin = margin(15, unit = ""pt"")),
  plot.margin = margin(t = 25, l = 20, r = 20, b=20, unit = ""pt"") 
)

designers <- 
  board_games %>%
  group_by(designer) %>%
  summarize(num = n(), rating = round(mean(average_rating), 2), time = mean(max_playtime)) %>%
  filter(!is.na(designer) & designer != ""(Uncredited)"") %>%
  arrange(desc(num))

artists <- 
  board_games %>%
  group_by(artist) %>%
  summarize(num = n(), rating = round(mean(average_rating), 2), time = mean(max_playtime)) %>%
  filter(!is.na(artist) & artist != ""(Uncredited)"") %>%
  arrange(desc(num))

publishers <- 
  board_games %>%
  group_by(publisher) %>%
  summarize(num = n(), rating = round(mean(average_rating), 2), time = mean(max_playtime)) %>%
  filter(!is.na(publisher) & publisher != ""(Uncredited)"") %>%
  arrange(desc(num))

top_artists <- artists[1:10, ]

art_cat <- 
  board_games %>%
  filter(artist %in% top_artists$artist) %>%
  select(name, category, artist) %>%
  group_by(artist, category) %>%
  summarize(count = n()) %>%
  filter(!is.na(category)) %>%
  arrange(artist, desc(count)) %>%
  ungroup() %>%
  separate(category, into = c(paste0(""V"", 1:10)), sep = "","") %>%
  gather(key = dummy, value = category, -artist, -count) %>%
  select(-dummy) %>%
  filter(!is.na(category)) %>%
  group_by(artist, category) %>%
  summarize(num = sum(count)) %>%
  arrange(artist, desc(num)) 

art_mech <- 
  board_games %>%
  filter(artist %in% top_artists$artist) %>%
  select(name, mechanic, artist) %>%
  group_by(artist, mechanic) %>%
  summarize(count = n()) %>%
  filter(!is.na(mechanic)) %>%
  arrange(artist, desc(count)) %>%
  ungroup() %>%
  separate(mechanic, into = c(paste0(""V"", 1:10)), sep = "","") %>%
  gather(key = dummy, value = mechanic, -artist, -count) %>%
  select(-dummy) %>%
  filter(!is.na(mechanic)) %>%
  group_by(artist, mechanic) %>%
  summarize(num = sum(count)) %>%
  arrange(artist, desc(num)) 

top_designers <- designers[1:10, ]

designers_cat <- 
  board_games %>%
  filter(designer %in% top_designers$designer) %>%
  select(name, category, designer) %>%
  group_by(designer, category) %>%
  summarize(count = n()) %>%
  filter(!is.na(category)) %>%
  arrange(designer, desc(count)) %>%
  ungroup() %>%
  separate(category, into = c(paste0(""V"", 1:10)), sep = "","") %>%
  gather(key = dummy, value = category, -designer, -count) %>%
  select(-dummy) %>%
  filter(!is.na(category)) %>%
  group_by(designer, category) %>%
  summarize(num = sum(count)) %>%
  arrange(designer, desc(num)) 

designers_mech <- 
  board_games %>%
  filter(designer %in% top_designers$designer) %>%
  select(name, mechanic, designer) %>%
  group_by(designer, mechanic) %>%
  summarize(count = n()) %>%
  filter(!is.na(mechanic)) %>%
  arrange(designer, desc(count)) %>%
  ungroup() %>%
  separate(mechanic, into = c(paste0(""V"", 1:10)), sep = "","") %>%
  gather(key = dummy, value = mechanic, -designer, -count) %>%
  select(-dummy) %>%
  filter(!is.na(mechanic)) %>%
  group_by(designer, mechanic) %>%
  summarize(num = sum(count)) %>%
  arrange(designer, desc(num)) 

top_publishers <- publishers[1:10, ]

publishers_cat <- 
  board_games %>%
  filter(publisher %in% top_publishers$publisher) %>%
  select(name, category, publisher) %>%
  group_by(publisher, category) %>%
  summarize(count = n()) %>%
  filter(!is.na(category)) %>%
  arrange(publisher, desc(count)) %>%
  ungroup() %>%
  separate(category, into = c(paste0(""V"", 1:10)), sep = "","") %>%
  gather(key = dummy, value = category, -publisher, -count) %>%
  select(-dummy) %>%
  filter(!is.na(category)) %>%
  group_by(publisher, category) %>%
  summarize(num = sum(count)) %>%
  arrange(publisher, desc(num)) 

publishers_mech <- 
  board_games %>%
  filter(publisher %in% top_publishers$publisher) %>%
  select(name, mechanic, publisher) %>%
  group_by(publisher, mechanic) %>%
  summarize(count = n()) %>%
  filter(!is.na(mechanic)) %>%
  arrange(publisher, desc(count)) %>%
  ungroup() %>%
  separate(mechanic, into = c(paste0(""V"", 1:10)), sep = "","") %>%
  gather(key = dummy, value = mechanic, -publisher, -count) %>%
  select(-dummy) %>%
  filter(!is.na(mechanic)) %>%
  group_by(publisher, mechanic) %>%
  summarize(num = sum(count)) %>%
  arrange(publisher, desc(num)) 

fire <- colorRampPalette(c(""#ffc12e"", ""#b32424""))

ggplot(artists[1:10, ]) +
  geom_segment(aes(x = reorder(artist, num), xend = reorder(artist, num), y = 0, yend = num), color = ""#1E1E1E"") +
  geom_point(aes(x = reorder(artist, num), y = num, size = rating, color = rating)) +
  scale_size_continuous(breaks = c(6, 6.5, 7, 7.5, 8), labels = c(""6"", ""6.5"", ""7"", ""7.5"", ""8""), limits = c(6, 7.5), range = c(8, 12)) +
  scale_color_gradient(breaks = c(6, 6.5, 7, 7.5, 8), labels = c(""6"", ""6.5"", ""7"", ""7.5"", ""8""), limits = c(6, 7.5), low = ""#ffc12e"", high = ""#B51212"") +
  guides(color = guide_legend(), size = guide_legend()) +
  coord_flip() +
  labs(title = ""Most prolific board game artists"", 
       subtitle = ""Point size represents the average rating of the artists games"", 
       caption = ""Graphic: @W_R_Chase\nData: boardgamegeek.com"",
       y = ""Number of games illustrated"",
       x = """") +
  theme_light(base_family = ""Lato"") +
  my_theme +
  theme(panel.grid.major.y = element_blank())

ggsave(""artists.svg"", device = ""svg"", height = 8, width = 10)


ggplot(designers[1:10, ]) +
  geom_segment(aes(x = reorder(designer, num), xend = reorder(designer, num), y = 0, yend = num), color = ""#1E1E1E"") +
  geom_point(aes(x = reorder(designer, num), y = num, size = rating, color = rating)) +
  scale_size_continuous(breaks = c(6, 6.5, 7), labels = c(""6"", ""6.5"", ""7""), limits = c(5.8, 7), range = c(8, 12)) +
  scale_color_gradient(breaks = c(6, 6.5, 7), labels = c(""6"", ""6.5"", ""7""), limits = c(5.8, 7), low = ""#179CE7"", high = ""#882BB9"") +
  guides(color = guide_legend(), size = guide_legend()) +
  coord_flip() +
  labs(title = ""Most prolific board game designers"", 
       subtitle = ""Point size represents the average rating of the designer's games"", 
       caption = ""Graphic: @W_R_Chase\nData: boardgamegeek.com"",
       y = ""Number of games designed"",
       x = """") +
  theme_light(base_family = ""Lato"") +
  my_theme +
  theme(panel.grid.major.y = element_blank())

ggsave(""designers.svg"", device = ""svg"", height = 8, width = 10)
  
  #trying a network thing
  edge_list <- 
    board_games %>%
    select(game_id, name, year_published, category, average_rating, artist, designer, publisher) %>%
    group_by(artist, designer, publisher) %>%
    summarize(weight = n()) %>%
    filter(!is.na(artist) & !is.na(publisher) & !is.na(designer)) %>%
    filter(artist != ""(Uncredited)"" & publisher != ""(Uncredited)"" & designer != ""(Uncredited)"") %>%
    filter(weight > 1)
","Other-11"
"834",1496,"https://github.com/db369/tidytuesday_wk5","db369","tidytuesday_wk5","tidytuesday_wk5.Rmd","---
title: ""Tidy Tuesday - Week 5""
subtitle: ""County-level American Community Survey (5-year estimates) 2015""
output: html_notebook
---

```{r setup}
library(tidyverse)
library(geojsonio)
library(broom)
library(rgeos)
library(wesanderson)
library(ggthemes)
```

```{r}
df <- read.csv(""acs2015_county_data.csv"")
head(df)
str(df)
summary(df)
```

```{r}
df %>%
  ggplot(aes(x=Unemployment)) +
  geom_histogram(binwidth = 1)


```



```{r}
# From the excellent r-graph-gallery: https://www.r-graph-gallery.com/328-hexbin-map-of-the-usa/
spdf <- geojson_read(""us_states_hexgrid.geojson.json"",  what = ""sp"")

spdf@data = spdf@data %>% mutate(google_name = gsub("" \\(United States\\)"", """", google_name))
spdf_fortified <- tidy(spdf, region = ""google_name"")
centers <- cbind.data.frame(data.frame(gCentroid(spdf, byid=TRUE), id=spdf@data$iso3166_2))
 
```


```{r}
acs2015_by_state <- df %>% group_by(State)

spdf_fortified = spdf_fortified %>%
  left_join(. , acs2015_by_state, by=c(""id""=""State"")) 

head(spdf_fortified)
```


```{r}

spdf_fortified$bin = cut(spdf_fortified$Unemployment , breaks=c(seq(0,16,2), Inf), labels=c(paste0("" "",seq(0,14,2),""-"",seq(2,16,2)),""16+""), include.lowest = TRUE)

pal1 <- wes_palette(9, name = ""Moonrise2"", type = ""continuous"")
pal2 <- wes_palette(9, name = ""Darjeeling2"", type = ""continuous"")
pal_alt <- tableau_seq_gradient_pal(""Orange"")(seq(0,1,length=9))

pal <- pal_alt

hex_plot <- ggplot() +
  geom_polygon(data = spdf_fortified, aes(fill = bin, x = long, y = lat, group = group) , size=0.7, alpha=0.9, col=""#f5f5f2"") +
  geom_text(data=centers, aes(x=x, y=y, label=id), color=""white"", size=3, alpha=0.6) +
  theme_void() +
  scale_fill_manual(values=pal, name=""Unemployment rates %"", guide = guide_legend(keyheight = unit(2, units = ""mm""), 
                                                                                  keywidth = unit(8, units = ""mm""), 
                                                                                  title.position = ""top"", label.position = ""bottom"",
                                                                                  title.hjust = 0.5, label.hjust = 0, nrow = 1) ) +
  labs(title = ""Unemployment Rates By State"", 
       subtitle = ""2015 American Community Survey 5-year estimates"",
       caption = ""\nBy @DaveBloom11  |  Source: 2015 American Community Survey "" ) 

hex_plot + 
  theme(
    legend.position = c(0.5, 0.9),
    legend.title = element_text(size = 8),
    legend.text = element_text(size = 7),
    text = element_text(color = ""#22211d""),
    plot.background = element_rect(fill = ""#f5f5f2"", color = NA), 
    panel.background = element_rect(fill = ""#f5f5f2"", color = NA), 
    legend.background = element_rect(fill = ""#f5f5f200"", color = NA),
    plot.title = element_text(size= 22, hjust=0.5, color = ""#4e4d47"", margin = margin(b = -0.1, t = 0.4, l = 2, unit = ""cm"")),
    plot.subtitle = element_text(size= 12, hjust=0.5, color = ""#4e4d47"", margin = margin(b = -0.1, t = 0.4, l = 2, unit = ""cm"")),
    plot.caption = element_text(size = 7),
    plot.margin=unit(c(0,0,0,0),""mm"")
  ) +
  coord_map()

ggsave(""hexplot_alt.jpg"")
```



","Other-5"
"835",1498,"https://github.com/db369/tidytuesday_wk6","db369","tidytuesday_wk6","tidytuesday_wk6.Rmd","---
title: ""TidyTuesday - Week 6""
subtitle: ""Global coffee-chain locations (as of 2017 or 2018)""
author: '@DaveBloom11'
date: ""May 7, 2018""
output: markdown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(wesanderson)
library(extrafont)
#library(emojifont)
```


## Import data
```{r}
sbux <- readxl::read_xlsx(""data/week6_coffee_chains.xlsx"", sheet = 1)
th <- readxl::read_xlsx(""data/week6_coffee_chains.xlsx"", sheet = 2)
dd <- readxl::read_xlsx(""data/week6_coffee_chains.xlsx"", sheet = 3)


```

```{r}

dd_by_zip <- dd %>% 
  group_by(e_postal) %>%
  summarize(dd = n())
dd_by_zip$Postcode <- as.character(dd_by_zip$e_postal)

th_by_zip <- th %>%
  group_by(postal_code) %>%
  summarize(th = n())
th_by_zip$Postcode <- as.character(th_by_zip$postal_code)

df <- sbux %>%
  group_by(Postcode, City, `State/Province`) %>%
  summarize(sbux = n(), city = unique(City), state = unique(`State/Province`),
            city_state = paste0(str_to_title(city),"", "",state,"" "",unique(Postcode))) 

df <- inner_join(df, dd_by_zip, by = ""Postcode"")
df <- inner_join(df, th_by_zip, by = ""Postcode"")

glimpse(df)

# drop incorrectly included / duplicate rows
df <- df[!(df$state %in% c(""48"",""BI"")),]
df <- df[!(df$city %in% c(""Mexico"",""MEXICO"",""Taylor"", ""Gahanna"", ""Ft Wayne"")),]

```


```{r}

sumsq <- function(shares) {
  temp <- 0
  for (sh in shares){
    temp <- temp + sh^2
  }
  return(temp)
}

df <- df %>%
  group_by(Postcode) %>%
  mutate(total = sum(sbux,dd,th),
         sbux_share = 100 * sbux / total,
         dd_share = 100 * dd / total,
         th_share = 100 * th / total,
         hhi = sumsq(c(sbux_share,dd_share,th_share)))

```

```{r fig.height=7}

pal <- wes_palette(n_distinct(df$state), name = ""Darjeeling2"", type = ""continuous"")

plot <- df %>%
  ggplot(aes(x = fct_reorder(city_state,hhi), y = hhi, col = state)) +
  geom_point(size = 3) +
  coord_flip() +
  theme_light() +
  scale_colour_manual(values = pal, name = ""State"") +
  labs(title = ""Concentration of global coffee-chains (as of 2017 or 2018)"",
       subtitle = ""Selected markets (by zip code) containing Starbucks, Tim Hortons, and Dunkin Donuts"",
       x = ""Location"", y = ""Concentration (HHI)"",
       caption = ""By @DaveBloom11\nSources: kaggle.com, timhortons.com, odditysoftware.com"") +
  theme(text = element_text(family = ""Times New Roman"", color = ""#22211d""),
        plot.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        panel.background = element_rect(fill = ""#f5f5f2"", color = NA), 
        legend.background = element_rect(fill = ""#f5f5f2""),
        legend.key = element_rect(fill = ""#f5f5f2""),
        plot.caption = element_text(size = 6))
plot
ggsave(""concentration.jpg"", dpi=300)
```

```{r fig.height=8}
library(ggplot2)
source(""geom_coffee.R"")

df <- df %>% 
  mutate(dominant_share = case_when(
    sbux_share > th_share && sbux_share > dd_share ~ ""Starbucks"",
    th_share > sbux_share && th_share > dd_share ~ ""Tim Hortons"",
    dd_share > sbux_share && dd_share > th_share ~ ""Dunkin Donuts"",
    TRUE ~ ""None""
  ))

df$dominant_share <- factor(df$dominant_share, levels = c(""Starbucks"", ""Tim Hortons"", ""Dunkin Donuts"", ""None""))

dark_plot <- df %>%
  ggplot(aes(col = dominant_share)) +
  #geom_segment(aes(x = fct_reorder(city_state,hhi), xend = fct_reorder(city_state,hhi), y = 0, yend = hhi), size = 1) +
  #geom_point(aes(x = fct_reorder(city_state,hhi), y = hhi), size = 4) +
  #geom_point(aes(x = fct_reorder(city_state,hhi), y = hhi), size = 1.5, color = ""#252525"") +
  geom_coffee(aes(x = fct_reorder(city_state,hhi), y = hhi), size = 8) +
  coord_flip() +
  #theme_void() +
  scale_colour_manual(values = c(""Starbucks"" = ""#006341"", ""Tim Hortons"" = ""#AC1F2D"", ""Dunkin Donuts"" = ""#F5821F"",""None"" = ""#DDDDDD""), name = ""Coffee chain with\nhighest market share"") +
  #guides(colour = guide_legend(override.aes = list(size = 8, shape = '\u2615'))) +
  #scale_color_viridis_d()+
  #rcartocolor::scale_color_carto_d(palette = ""Vivid"", name = ""State"") +
  labs(title = ""Concentration of global coffee-chains (as of 2017 or 2018)"",
       subtitle = ""Selected markets (by zip code) containing Starbucks, Tim Hortons, and Dunkin Donuts"",
       x = ""Location"", y = ""Concentration (HHI)"",
       caption = ""By @DaveBloom11\nSources: kaggle.com, timhortons.com, odditysoftware.com"") +
  theme(text = element_text(family = ""Bitstream"", color = ""#F2F1Fd""),
        panel.grid = element_blank(),
        plot.background = element_rect(fill = ""#050502"", color = NA), 
        panel.background = element_rect(fill = ""#202020"", color = NA), 
        axis.text = element_text(size = 11, family = ""Bitstream"", color = ""#F2F1Fd"", hjust = 1),
        legend.background = element_rect(fill = ""#050502""),
        legend.key = element_rect(color = ""#050502"", fill = ""#050502""),
        plot.title = element_text(size = 16),
        plot.caption = element_text(size = 6))
dark_plot

ggsave(""concentration_dark.jpg"", dpi=300)

```

```{r fig.height=9}

dark_plot2 <- df %>%
  ggplot(aes(x = fct_reorder(city_state,hhi), y = hhi)) +
  geom_text(label = ""?"", aes(col = dominant_share), size=5) +
  coord_flip() +
  scale_colour_manual(values = c(""Starbucks"" = ""#006341"", ""Tim Hortons"" = ""#AC1F2D"", ""Dunkin Donuts"" = ""#F5821F"",""None"" = ""#BBBBBB""), name = ""Coffee chain with\nhighest market share"") +
  labs(title = ""Concentration of global coffee-chains (as of 2017 or 2018)"",
       subtitle = ""Selected markets (by zip code) containing Starbucks, Tim Hortons, and Dunkin Donuts"",
       x = ""Location"", y = ""Concentration (HHI)"",
       caption = ""By @DaveBloom11\nSources: kaggle.com, timhortons.com, odditysoftware.com"") +
  theme(text = element_text(family = ""Bitstream"", color = ""#F2F1Fd""),
        panel.grid = element_blank(),
        plot.background = element_rect(fill = ""#050502"", color = NA), 
        panel.background = element_rect(fill = ""#202020"", color = NA), 
        axis.text = element_text(size = 11, family = ""Bitstream"", color = ""#F2F1Fd"", hjust = 1),
        legend.background = element_rect(fill = ""#050502""),
        legend.key = element_rect(color = ""#050502"", fill = ""#050502""),
        plot.title = element_text(size = 16),
        plot.caption = element_text(size = 6))
dark_plot2

ggsave(""concentration_dark_2.jpg"", dpi=300)



```



```{r}
df
```

","Other-6"
"836",1499,"https://github.com/db369/tidytuesday_wk4","db369","tidytuesday_wk4","wk4.Rmd","---
title: ""Tidy Tuesday - Week 4""
subtitle: Gender differences in Australian Salaries
output:
  html_document:
    df_print: paged
---


```{r}
library(tidyverse)
library(wesanderson)
library(scales)
library(patchwork)
```


```{r}
df <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week4_australian_salary.csv"")

head(df)
```

```{r}
summary(df)

```

```{r}

avg_female_income = mean(df$average_taxable_income[df$gender == ""Female""])
avg_male_income = mean(df$average_taxable_income[df$gender == ""Male""])

df %>%
  mutate(inc_in_thousands = average_taxable_income / 1000) %>%
  ggplot(aes(x=gender,y=average_taxable_income, color=gender)) + 
    geom_jitter(alpha=0.4) +
    scale_color_manual(values=wes_palettes$Moonrise2) +
    theme_light() +
    theme(legend.position = ""none"") +
    scale_y_continuous(labels = comma) +
    labs(x=""Gender"", y=""A$"", title=""Average Taxable Income"") 
    

```


```{r}

df %>%
  ggplot(aes(x=gender,y=average_taxable_income, color=gender)) + 
    geom_boxplot(alpha=0.4) +
    scale_color_manual(values=wes_palettes$Moonrise2) +
    theme_light() +
    theme(legend.position = ""none"") +
    scale_y_continuous(labels = comma) +
    labs(x=""Gender"", y=""A$"", title=""Average Taxable Income"") 
    
```

```{r}
df$occupation <- str_replace(df$occupation, ""\x96"", ""/"")

highest_paying_occupations_for_women <- df %>%
  filter(gender==""Female"") %>%
  top_n(25)

top_25 <- df %>%
  filter(occupation %in% highest_paying_occupations_for_women$occupation) %>%
  select(occupation,gender,average_taxable_income) %>%
  spread(key=gender, value=average_taxable_income) 
  
pal <- wes_palette(25, name = ""Moonrise2"", type = ""continuous"")

top_25 %>%
  mutate(difference = Male - Female) %>%
  ggplot(aes(x=fct_reorder(occupation, Female), y = Female, col = occupation)) +
    geom_segment(aes(x=fct_reorder(occupation, Female), 
                     xend=fct_reorder(occupation, Female), 
                     y=Female, 
                     yend=Male)) + 
    geom_point(aes(x=occupation,y=Female)) +
    geom_point(aes(x=occupation,y=Female), col=""white"", size=1) +
    geom_point(aes(x=occupation,y=Male)) +
    coord_flip() + 
    theme_light() +
    theme(legend.position = ""none"") +
    labs(title=""Top 25 highest paying jobs for females"", y=""A$"", x="""") +
    scale_y_continuous(labels = comma) + 
    scale_color_manual(values = pal) +
    annotate(""text"", x=2:3, y=510000, label = c(""Male"",""Female""), hjust = 0) + 
    annotate(""point"", x=3, y=500000) +
    annotate(""point"", x=3, y=500000, size=1, col=""white"") +
    annotate(""point"", x=2, y=500000)

#ggsave(""top_25.png"",dpi=600)

```

```{r fig.height=8, fig.width=8}

focused_df <- df %>%
  select(occupation,gender,average_taxable_income) %>%
  spread(key=gender, value=average_taxable_income) %>%
  mutate(diff = Male - Female) 

top_15 <- focused_df %>%
  top_n(15)

bottom_15 <-focused_df %>%
  top_n(-15)

t15 <- top_15 %>%
  ggplot(aes(x=fct_reorder(occupation, diff), y = Female, col = occupation)) +
    geom_segment(aes(x=fct_reorder(occupation, diff), 
                     xend=fct_reorder(occupation, diff), 
                     y=Female, 
                     yend=Male)) + 
    geom_point(aes(x=occupation,y=Female)) +
    geom_point(aes(x=occupation,y=Female), col=""white"", size=1) +
    geom_point(aes(x=occupation,y=Male)) +
    coord_flip() + 
    theme_light() +
    theme(legend.position = ""none"") +
    labs(title=""Top 15 by Difference"", y=""A$"", x="""") +
    scale_y_continuous(labels = comma) + 
    scale_color_manual(values = pal) +
    annotate(""text"", x=2:3, y=520000, label = c(""Male"",""Female""), hjust = 0) +  
    annotate(""point"", x=3, y=500000) +
    annotate(""point"", x=3, y=500000, size=1, col=""white"") +
    annotate(""point"", x=2, y=500000) 

b15 <- bottom_15 %>%
  ggplot(aes(x=fct_reorder(occupation, diff), y = Female, col = occupation)) +
    geom_segment(aes(x=fct_reorder(occupation, diff), 
                     xend=fct_reorder(occupation, diff), 
                     y=Female, 
                     yend=Male)) + 
    geom_point(aes(x=occupation,y=Female)) +
    geom_point(aes(x=occupation,y=Female), col=""white"", size=1) +
    geom_point(aes(x=occupation,y=Male)) +
    coord_flip() + 
    theme_light() +
    theme(legend.position = ""none"") +
    labs(title=""Bottom 15 by Difference"", y=""A$"", x="""") +
    scale_y_continuous(labels = comma) + 
    scale_color_manual(values = pal) +
    annotate(""text"", x=1:2, y=260000, label = c(""Male"",""Female""), hjust = 0) +  
    annotate(""point"", x=2, y=250000) +
    annotate(""point"", x=2, y=250000, size=1, col=""white"") +
    annotate(""point"", x=1, y=250000) 

t15 + b15 + plot_layout(ncol = 1, nrow = 2) 
#ggsave(""top_bottom.png"", dpi=600)
```
","Other-4"
"837",1505,"https://github.com/ArthurCheib/TidyTuesday","ArthurCheib","TidyTuesday","Week 34/first_go_tt34.Rmd","---
title: ""TidyTuesday34 - Thanksgiving""
author: Arthur Cheib
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
```

Read and summary file
```{r message=FALSE, warning=FALSE}
url <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-20/thanksgiving_meals.csv""

thanks_dataset <- read_csv(url)
```

Defining the scope of analysis:
* Do you celebrate Thanksgiving?
* Which type of pie is typically served at your Thanksgiving dinner? Please select all that apply.
* Do you typically pray before or after the Thanksgiving meal?
* Age
* How much total combined money did all members of your HOUSEHOLD earn last year?


```{r fig.width= 8, fig.height = 5}
thx_scope <- thanks_dataset %>% 
  select(1,2, pie1:pie13, prayer, age, family_income) %>%
  filter(celebrate == ""Yes"")

thx_table <- thx_scope %>%
  group_by(prayer, family_income) %>% 
  summarize(TOTAL = n()) %>%
  na.omit() %>%
  spread(key = family_income, value = TOTAL) 
  
thx_table[, 2:12] <- round((thx_table[, 2:12]/rowSums(thx_table[, 2:12])), digits = 3)*100

thx_table %>%
  gather(key = family_income, value = TOTAL, -prayer) %>% 
  mutate(TOTAL = case_when(prayer == ""No"" ~ -TOTAL,
                           TRUE ~ TOTAL),
         family_income = factor(family_income, levels = c(""Prefer not to answer"", ""$0 to $9,999"", ""$10,000 to $24,999"",
                                                          ""$25,000 to $49,999"", ""$50,000 to $74,999"", ""$75,000 to $99,999"",
                                                          ""$100,000 to $124,999"", ""$125,000 to $149,999"", ""$150,000 to $174,999"",
                                                          ""$175,000 to $199,999"", ""$200,000 and up""))) %>% 
  ggplot(aes(x = family_income, y = TOTAL, fill = prayer)) +
  geom_col() +
  geom_label(aes(label = str_c(format(abs(TOTAL)), ""%"")), fill = ""white"") +
  coord_flip() +
  scale_y_continuous(limits = c(-20, 20), labels = abs) +
  theme_economist() +
  labs(title = ""PERCENTAGE OF RESPONDENTS THAT \n PRAYS IN THANKSGIVING DINNERS"",
       subtitle = ""Displayed by family combined income"",
       y = """",
       x = """") +
  theme(legend.position = ""bottom"",
        legend.title = element_text(size = 14),
        plot.title = element_text( size = 16))

```

```{r}
thx_scope %>% 
  select(-prayer, - family_income, -celebrate) %>% 
  gather(key = pies, value = types, -age, -id) %>%
  na.omit() %>% 
  group_by(types) %>% 
  mutate(total = n()) %>%
  filter(total > 100) %>%
  ggplot(aes(age, fct_reorder(types, total))) +
  geom_jitter(aes(color = types)) +
  theme_wsj() +
  labs(title = ""MOST PREFERRED PIES IN THANKSGIVING DINNERS"",
       y = """",
       x = """") +
  theme(legend.position = ""none"",
        plot.title = element_text( size = 16))
```","Other-34"
"838",1506,"https://github.com/ArthurCheib/TidyTuesday","ArthurCheib","TidyTuesday","Week 35/bridges_tt35.Rmd","---
title: ""TidyTuesday35 - Maryland Bridges""
author: Arthur Cheib
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
library(carbonate)
```

Read and summary file
```{r message=FALSE, warning=FALSE}
url <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-27/baltimore_bridges.csv""

bridges_df <- read_csv(url)
```

Defining the features of analysis:
* Responsibility
* Total improvement costs in thousands of dollars
* Bridge condition (Poor, Fair, Good)

```{r fig.width= 8, fig.height = 6}
bridges_df_new <- bridges_df %>% 
  mutate(n_responsibility = case_when(responsibility == ""City or Municipal Highway Agency"" ~ ""County"",
                                responsibility == ""County Highway Agency"" ~ ""County"",
                                responsibility == ""Other Local Agencies"" ~ ""County"",
                                responsibility == ""Town or Township Highway Agency"" ~ ""County"",
                                responsibility == ""State Highway Agency"" ~ ""State"",
                                responsibility == ""State Toll Authority"" ~ ""State"",
                                responsibility == ""Other State Agencies""~ ""State""),
         decade_built = yr_built - yr_built %% 10) %>% 
  filter(decade_built > 1900) %>% 
  select(county, bridge_condition, n_responsibility, avg_daily_traffic, total_improve_cost_thousands, decade_built, inspection_yr) %>% 
  group_by(n_responsibility, decade_built) %>%
  summarize(total_bridges = n(),
            total_spent_in_improvement = sum(total_improve_cost_thousands, na.rm = T),
            avg_traffic_per_bridge = mean(avg_daily_traffic, na.rm = T)) %>% na.omit()
  
bridges_df_new %>% 
    select(n_responsibility, total_spent_in_improvement, decade_built) %>% 
    spread(key = n_responsibility, value = total_spent_in_improvement) %>%
    mutate(abs_per_decade = County + State,
           percent_county_decade = round((County/abs_per_decade), digits = 2),
           percent_state_decade = round(1 - percent_county_decade, digits = 2)) %>% 
    select(-abs_per_decade) %>% 
    gather(percents, values_percent, -County, -State, -decade_built) %>% 
    gather(n_responsibility, total_spent_in_improvement, -decade_built, -percents, -values_percent) %>% 
    filter(percents == ""percent_county_decade"" & n_responsibility == ""County"" |
           percents == ""percent_state_decade"" & n_responsibility == ""State"") %>% 
    select(-percents) %>%  
  ggplot(aes(as.factor(decade_built), values_percent, fill = n_responsibility)) +
  geom_col(position = ""fill"") +
  theme_solarized() +
  labs(title = ""PERCENTAGE AND TOTAL IMPROVEMENT COSTS WITH BRIDGES"",
       subtitle = ""STATE vs. COUNTY - numbers in thousands of dollars"",
       y = ""Percentage"",
       x = """") +
  theme(legend.position = ""bottom"",
        legend.title = element_text(size = 14),
        plot.title = element_text( size = 16)) +
  geom_text(aes(label = str_c(""$"", format(total_spent_in_improvement, big.mark = "",""))), position = position_stack(vjust = 0.5)) +
  scale_fill_discrete(name=""Responsibility"")
```

Second plot:
```{r fig.width= 9.5, fig.height = 5}

bridges_df_new_second <- bridges_df_new %>%
  select(n_responsibility, total_bridges, decade_built)
  

right_label <- bridges_df_new_second %>%
  group_by(decade_built) %>%
  arrange(desc(total_bridges)) %>% 
  slice(1)

left_label <- bridges_df_new_second %>%
  group_by(decade_built) %>%
  arrange(desc(total_bridges)) %>% 
  slice(2)

big_diff <- bridges_df_new_second %>% 
  spread(n_responsibility, total_bridges) %>% 
        group_by(decade_built) %>% 
        mutate(Max = max(State, County),
               Min = min(State, County),
               Diff = Max / Min - 1) %>% 
        arrange(desc(Diff)) %>%
        filter(Diff > .2)

right_label <- filter(right_label, decade_built %in% big_diff$decade_built)
left_label <- filter(left_label, decade_built %in% big_diff$decade_built)

highligth_labels <- filter(bridges_df_new_second, decade_built %in% big_diff$decade_built)

plot_label <- big_diff %>%
    select(decade_built, total_bridges = Max, Diff) %>%
    right_join(right_label)

bridges_df_new_second %>%
  ggplot(aes(total_bridges, as.factor(decade_built))) +
  geom_point(aes(color = n_responsibility), size = 2) +
  geom_line(size = 0.85) +
  geom_point(data = highligth_labels, aes(color = n_responsibility), size = 2) +
  geom_line(data = highligth_labels, aes(group = decade_built)) +
  geom_text(data = plot_label, aes(color = n_responsibility, 
                                         label = paste0(""+"", scales::percent(round(Diff, 2)))),
                  size = 3, hjust = -.5) +
  theme_solarized() +
  labs(title = ""DIFFERENCE OF THE TOTAL AMOUNT OF BRIDGES BUILT"",
       subtitle = ""STATE vs. COUNTY - by decade"",
       y = """",
       x = ""Amount of Bridges"")
```

","Other-35"
"839",1603,"https://github.com/kigtembu/Tidyverse/blob/master/week21.R","kigtembu","Tidyverse","week21.R","#----------------------#
# Week 21 Tidy Tuesday #
# created by Kigen     #
# 21/08/2018           #
#----------------------#

#Packages
library(tidyverse)
library(ggplot2)
library(RCurl)
library(lubridate)

#Read in Data

damage <- read.csv(text = getURL(""https://raw.githubusercontent.com/BuzzFeedNews/2018-07-wildfire-trends/master/data/calfire_damage.csv""),
                                  header = T)
calfire <- read.csv(text = getURL(""https://raw.githubusercontent.com/BuzzFeedNews/2018-07-wildfire-trends/master/data/calfire_frap.csv""),
                                  header = T)
str(calfire)

calfire1 <- calfire %>% select(objectid,alarm_date,cont_date,gis_acres)%>%
            filter(alarm_date != '',cont_date != '')%>%
            mutate(startdate = as.Date(as.character(alarm_date)),
                   enddate = as.Date(as.character(cont_date)),
                   duration = enddate - startdate, yr_st = year(startdate))%>%
            group_by(yr_st)%>%
            summarise(totalDur = sum(duration),count = n())%>%
            transmute(yr = yr_st,avgdur = round(totalDur/count))

ggplot(calfire1,aes(yr,as.numeric(avgdur)))+
        geom_line(size = 1, color = 'blue')+
        labs(title = 'Duration of Wild Fires', x = 'Year', y = 'Average Duration in Days',
             caption = 'Source:US Forest Service\n@kigtembu')+
        theme_minimal()
","Other-21"
"840",1604,"https://github.com/kigtembu/Tidyverse/blob/master/Week27.R","kigtembu","Tidyverse","Week27.R","###-----------------------###
## Week 27 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 02/10/2018              ##
#---------------------------#

library(tidyverse)
library(RCurl)

#read data
url <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-10-02/us_births_2000-2014.csv'
births <- read.csv(text = getURL(url),
                   header = T)
# assign day names
births$day[births$day_of_week == 1]<- 'Monday'
births$day[births$day_of_week == 2]<- 'Tuesday'
births$day[births$day_of_week == 3]<- 'Wednesday'
births$day[births$day_of_week == 4]<- 'Thursday'
births$day[births$day_of_week == 5]<- 'Friday'
births$day[births$day_of_week == 6]<- 'Saturday'
births$day[births$day_of_week == 7]<- 'Sunday'

#Manipulate data to get total births per year per day of the week
birth1 <- select(births,-date_of_month)%>%
             group_by(year,day_of_week,day)%>%
             summarise(TotalBirths = sum(births, na.rm = TRUE))%>%
             mutate(Sqrt.TotalBirths = sqrt(TotalBirths))%>%
             arrange(year,day_of_week)

#factor day to order x-axis
birth1$day1 <- factor(birth1$day,levels = c('Monday','Tuesday','Wednesday','Thursday',
                                            'Friday','Saturday','Sunday'))
#plot
ggplot(birth1,aes(x = day1, y = as.factor(year) , fill = Sqrt.TotalBirths))+
             geom_tile()+
             labs(x = 'Day of The Week', y = 'Year', 
                  caption = 'Source:FiveThirtyEight\n@kigtembu')+
             scale_fill_gradient(name = ""Sqrt(TotalBirths)"",
                               low = ""#FFFFFF"",
                               high = ""#012345"") +
             theme(plot.title = element_text(hjust = 0.5))+
             ggtitle(label = 'US Births Heatmap')+
             theme_bw()

ggsave('week27.png')
","Other-27"
"841",1605,"https://github.com/kigtembu/Tidyverse/blob/master/week18.R","kigtembu","Tidyverse","week18.R","### Tidytuesday  challenge
##  created by kigen Tembu
##  31/7/2018

## libraries

library(tidyverse)
library(readxl)
library(lubridate)
library(ggplot2)

#--- Read in data
das <- read_excel('week18_dallas_animals.xlsx',sheet = 1)

#--- Transform and manipulate data
das1 <- das %>% filter(!is.na(intake_type))%>%
        select(animal_id,animal_type,intake_type,intake_date)%>%
        distinct %>%
        mutate(mth = month(intake_date,label = TRUE,abbr = TRUE),
                yr = year(intake_date),
                 yr2 = paste(mth,yr,sep =' '))%>%
        #find the three most common intake types
        group_by(intake_type)%>%
        summarise(count=n())%>%
        arrange(desc(count))%>%
        mutate(Tot = cumsum(count),mx = max(Tot),Per = (count/mx)*100)

#--- 'stray', 'owner surrender' and 'confiscated'  contribute to 90% of the data
#--- group all other intake type categories as 'other'

das2 <- das %>% filter(!is.na(intake_type))%>%
        select(animal_id,animal_type,intake_type,intake_date)%>%
        distinct %>%
        mutate(mth = month(intake_date,label = TRUE,abbr = TRUE),
               yr = year(intake_date),
               yr2 = paste(mth,yr,sep =' '),
               intake_type1 = str_replace_all(intake_type,c('LOST REPORT'= 'OTHER','WILDLIFE' = 'OTHER',
                                                            'FOSTER' = 'OTHER','FOUND REPORT'= 'OTHER',
                                                             'TRANSFER'='OTHER')))
      


#--- Plot

ggplot(das2,aes(x=yr2))+
       geom_bar(aes(fill = intake_type1))+
       scale_fill_brewer(palette = 'RdBu')+
       guides(fill =guide_legend(title = 'Intake Type'))+
       labs(title = ""Number of animals taken in by Dallas Animal Shelter"" ,
            x = """", y = 'Number of Animals',caption = 'Source:Dallas OpenData')+
       theme(axis.text.x = element_text(angle = 90,size = 10,face = 'plain'),
            axis.text.y = element_text(size = 10, face = 'plain'),
            legend.title = element_text(size = 10,face = 'bold'),
            legend.text = element_text(size = 9, face = 'plain'))
       





","Other-18"
"842",1606,"https://github.com/kigtembu/Tidyverse/blob/master/week24.R","kigtembu","Tidyverse","week24.R","###-----------------------###
## Week 24 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 10/9/2018               ##
#---------------------------#

library(tidyverse)
library(RCurl)
library(sf)
library(tmap)
library(spData)
library(spDataLarge)

#animation
devtools::install_github(""yihui/animation"")

# Read in Data
url <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-09-11/cats_vs_dogs.csv'
pets <- read.csv(text = getURL(url),
                     header = T)
pets1 <- select(pets,state,dog_population,cat_population)%>%
              mutate(state1 = as.character(state))%>%
              rename(NAME = state1,Cats = cat_population, Dogs = dog_population)%>%
              select(-state)%>%
              gather(key = type,value = Population ,-NAME)


# US states sf from spData 

pets_sf <- left_join(us_states,pets1,by = 'NAME')

#map

petsanim = tm_shape(pets_sf)+
            tm_polygons()+
            tm_dots(size = 'Population')+
            tm_facets(along = 'type' ,nrow = 1, free.coords = FALSE)

tmap_animation(petsanim,filename = 'petsanim.gif',delay = 40)","Other-24"
"843",1607,"https://github.com/kigtembu/Tidyverse/blob/master/week15.R","kigtembu","Tidyverse","week15.R","### Tidyverse tuesday challenge
### Week 15 09/07/2018
### created by Kigen tembu


library(readxl)
library(tidyverse)

#read in data and summarise to the 5 cities with the most breweries
brewery <- read_excel('week15_beers.xlsx',sheet =2)

brewery1 <-filter(brewery,city != '')%>%
           group_by(city)%>%
           summarise(count =n())%>%
           arrange(desc(count))%>%
           slice(1:5)
#ggplot geom bar
 ggplot(brewery1,aes(city))+
  
     geom_bar(aes(weight = count),position = position_stack(reverse = TRUE),fill = 'tan3',width = 0.6) +
     coord_flip()+
     theme_minimal()+
     geom_text(aes(y = count,hjust = -0.20,
                   label = format(brewery1$count,trim = TRUE)),color = 'tan3',size = 10) +
     geom_text(aes(y = count ,hjust = 2,
                label = format(brewery1$city,trim = TRUE)),color = 'tan4',size = 8)+
     theme(axis.ticks = element_blank(),axis.text.y = element_blank(),
           axis.title = element_blank(),axis.line = element_line(linetype = 'dotted'))
","Other-15"
"844",1608,"https://github.com/kigtembu/Tidyverse/blob/master/week29.R","kigtembu","Tidyverse","week29.R","###-----------------------###
## Week 29 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 15/10/2018              ##
#---------------------------#


# packages ----------------------------------------------------------------

library(tidyverse)
library(RCurl)
library(skimr)
library(ggthemes)
library(ggalt)

#read in data

url <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-10-16/recent-grads.csv'

Recent_grads <- read.csv(text = getURL(url),header = T)

skim(Recent_grads)

Recent_grads1 <- select(Recent_grads,Major,Major_category,
                        Sample_size,Total,P25th,P75th)%>%
                 mutate(iqr = P75th-P25th)%>%
                 arrange(desc(iqr))%>%
                 top_n(10)
Recent_grads1$Major <- factor(Recent_grads1$Major,levels = Recent_grads1[order(Recent_grads1$iqr,decreasing=F),]$Major)

# Plot --------------------------------------------------------------------
 ggplot(Recent_grads1,aes(x = P25th,xend = P75th,y = Major ))+
        geom_dumbbell(colour_xend = 'brown1',size_x = 2,size_xend = 4)+
        labs( x = 'US $',y = '',
              title = 'Top 10 College Majors with the highest interquartile salary range',
              caption = 'Source: acs/FiveThirtyEight\n@kigtembu')+
              theme_bw()

ggsave('week29.png')

Recent_grads1$Major <- factor(Recent_grads1$Major,levels = Recent_grads1[order(Recent_grads1$Sample_size,decreasing=F),]$Major)

ggplot(Recent_grads1,aes(x = Major, y = Sample_size))+
  geom_bar(stat = 'identity',position = position_stack(reverse = TRUE),fill = 'aquamarine')+
  geom_text(aes(label = Sample_size, hjust = 0))+
  coord_flip()+
  labs(x = 'College Major',y = 'Sample Size(salary)',
       title = 'Sample Size for Median Salary',
       caption = 'Source: acs/FiveThirtyEight\n @kigtembu')+
  theme_bw()

ggsave('week29_samp.png')","Other-29"
"845",1609,"https://github.com/kigtembu/Tidyverse/blob/master/week20.R","kigtembu","Tidyverse","week20.R","### TidyTuesday 13/08/2018
## Created by Kigen Tembu
# Week 20

#Libraries
library(RCurl)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(ggplot2)

#Read in data

twt1 <-read.csv(""IRAhandle_tweets_1.csv"", 
                    header=T)


twt2 <-read.csv(""IRAhandle_tweets_2.csv"", 
                header=T)

twt3 <-read.csv(""IRAhandle_tweets_3.csv"", 
                header=T)

twt4 <-read.csv(""IRAhandle_tweets_4.csv"", 
                header=T)

twt5 <-read.csv(""IRAhandle_tweets_5.csv"", 
                header=T)

twt6 <-read.csv(""IRAhandle_tweets_6.csv"", 
                header=T)

twt7 <-read.csv(""IRAhandle_tweets_7.csv"", 
                header=T)

twt8 <-read.csv(""IRAhandle_tweets_8.csv"", 
                header=T)

twt9 <-read.csv(""IRAhandle_tweets_9.csv"", 
                header=T)

#append data

twt <- suppressWarnings(bind_rows(twt1,twt2,twt3,twt4,twt5,twt6,twt7,twt8,twt9))

tidy_twt <- twt %>%
            select(author,content,account_category,followers)%>%
            distinct%>%
            filter(account_category == 'RightTroll' | account_category == 'LeftTroll')%>%
            group_by(account_category,author)%>%
            summarize(max_followers = max(followers,na.rm = TRUE),
                      No_tweets = n())

#plot
ggplot(tidy_twt,aes(No_tweets,max_followers))+
      geom_jitter(aes(color = account_category))+
      geom_smooth()+
      facet_grid(.~account_category)+
      labs(title = 'Is there a relationship between number of tweets and\nnumber of followers among trolls ?',
            x = 'Number of Tweets', y = 'Number of Followers',
            caption = 'Source:FiveThirtyEight\n@kigtembu')+
      theme_light()+
      theme(legend.position = 'none')

ggplot(tidy_twt,aes(account_category,log(No_tweets)))+
      geom_boxplot(aes(fill = account_category,alpha = 0.6))+
      labs(title = 'Box plots of log adjusted number of tweets',
       x = 'Troll Type', y = 'Log(Number of Tweets)',
       caption = 'Source:FiveThirtyEight\n@kigtembu')+
      theme_light()+
      theme(legend.position = 'none')+
      scale_fill_manual(values = c('blue','red'))
","Other-20"
"846",1610,"https://github.com/kigtembu/Tidyverse/blob/master/week19.R","kigtembu","Tidyverse","week19.R","### TidyTuesday 6/08/2018
## Created by Kigen Tembu
# Week 19

#Libraries
library(RCurl)
library(tidyverse)
library(ggplot2)

#Read in data

airlines <-read.csv(text=getURL(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week19_airline_safety.csv""), 
                      header=T)
airlines_1 <- airlines %>% filter(!is.na(avail_seat_km_per_week))%>%
              mutate(yr1 = str_replace_all(year_range,c('85_99'='Y8599','00_14'='Y0014')))%>%
              spread(yr1,avail_seat_km_per_week)%>%
              filter(!is.na(Y8599))%>%
              select(airline,type_of_event,n_events,Y8599)%>%
              filter(!is.na(airline))

airlines_2 <-  airlines %>% filter(!is.na(avail_seat_km_per_week))%>%
               mutate(yr1 = str_replace_all(year_range,c('85_99'='Y8599','00_14'='Y0014')))%>%
               spread(yr1,avail_seat_km_per_week)%>%
               filter(!is.na(Y0014))%>%
               select(airline,type_of_event,n_events,Y0014)%>%
               filter(!is.na(airline))


#Merge the two by airline;

airline_mg <- inner_join(airlines_1,airlines_2,by = c('airline','type_of_event'))%>%
              mutate(diff_events = n_events.y - n_events.x)%>%
              filter(type_of_event == 'incidents')%>%
              arrange(desc(diff_events))%>%
              top_n(3)%>%
              gather(key = event , value = n , n_events.x, n_events.y)%>%
              mutate(yr = str_replace_all(event,c('n_events.x'='1985-1999','n_events.y'='2000-2014')))
              

#plot 
ggplot(airline_mg,aes(airline,n))+
      geom_bar(aes(fill = yr),position = 'dodge', stat = 'identity')+
      labs(title = 'Airlines with the most increase in incidents comparing\nthe period 1985-2000 with 2000-2014',
           x = 'Airline', y = 'Number of Incidents', caption = 'Source:FiveThirtyEight\n@kigtembu')+
      coord_flip()+
      guides(fill =guide_legend(title = 'Period'))+
      theme_light()
","Other-19"
"847",1612,"https://github.com/kigtembu/Tidyverse/blob/master/week35.R","kigtembu","Tidyverse","week35.R","###-----------------------###
## Week 35 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 27/11/2018              ##
#---------------------------#

# packages ----------------------------------------------------------------
library(readr)
library(tidyverse)
library(skimr)
library(ggrepel)


# read in data ------------------------------------------------------------

bridges_raw <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-27/baltimore_bridges.csv')
skim(bridges_raw)

# manipulate and plot -----------------------------------------------------


bridge_cond <- bridges_raw %>% select(yr_built,bridge_condition,total_improve_cost_thousands,avg_daily_traffic,carries)%>%
                    ggplot(aes(x = yr_built,y = avg_daily_traffic,label = carries))+
                    geom_jitter(color = 'steelblue')+
                    geom_label_repel(aes(label=ifelse(avg_daily_traffic>200000,carries,'')),
                                     box.padding = 0.35,point.padding = 0.5,alpha = 0.6,vjust = 0)+
                    facet_wrap(~bridge_condition)+
                    theme_classic()+
                    labs(x = 'Year Bridge was Built',
                         y = 'Average Daily Traffic',
                         title = 'Scatter Plot of Daily Traffic Vs Year Bridge was Built',
                         subtitle = 'Faceted by Bridge Condition',
                         caption = 'Source:Baltimore Sun\n@kigtembu')
bridge_cond

ggsave('week35.png',plot = bridge_cond)




","Other-35"
"848",1613,"https://github.com/kigtembu/Tidyverse/blob/master/week23.R","kigtembu","Tidyverse","week23.R","###-----------------------###
## Week 22 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 22/08/2018              ##
#---------------------------#

library(tidyverse)
library(RCurl)
library(hrbrthemes)
# Read in Data

fastfood <- read.csv(text = getURL('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-09-04/fastfood_calories.csv'),
                header = T)

fastfood1 <- fastfood %>%
               select(restaurant,item,trans_fat) %>%
               distinct(restaurant,item,.keep_all = TRUE) %>%
               group_by(restaurant) %>%
               summarise(total_tr_ft = sum(trans_fat,na.rm = TRUE))%>%
               arrange(desc(total_tr_ft))

# ggplot

ggplot(fastfood1,aes(x = reorder(restaurant,total_tr_ft), y = total_tr_ft))+
      geom_bar(stat = 'identity',position = position_stack(reverse = TRUE))+
      geom_text(aes(label = total_tr_ft, hjust = 0))+
      coord_flip()+
      labs(x = 'Restaurant',y = 'Total Transfat in Menu',
           title = 'Transfat in Fast Food Restaurant Menus',
           caption = 'Source: Fastfoodnutrition.com\n @kigtembu')+
      theme_ipsum_rc(grid = 'X')

ggsave('week23.png')


","Other-23"
"849",1615,"https://github.com/kigtembu/Tidyverse/blob/master/week31.R","kigtembu","Tidyverse","week31.R","###-----------------------###
## Week 31 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 23/10/2018              ##
#---------------------------#

# packages ----------------------------------------------------------------

library(tidyverse)
library(RCurl)
library(skimr)
library(ggimage)
library(countrycode)
library(ggrepel)
library(scales)



# read in data ------------------------------------------------------------

url <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-10-30/r_downloads_year.csv'
cran <- read.csv(text = getURL(url),header = T)

skim(cran)

cran1 <- cran %>% select(country,os,ip_id,size)%>%
         mutate(country = as.character(country),os = as.character(os))%>%
         filter(!is.na(country),!is.na(os))%>%
         group_by(country)%>%
         summarise(avg_size = mean(as.numeric(size),na.rm = TRUE),count = n())%>%
         mutate(code = country, country = countrycode(sourcevar = country, origin = ""iso2c"", destination = ""genc.name""))%>%
         filter(!is.na(country))%>%
         arrange(desc(count))%>%
         top_n(20,wt=count)
        


cran2 <-ggplot(cran1,aes(x = count,y = avg_size,country = code))+
        geom_flag(aes(image = code))+
        scale_x_continuous(labels = comma)+
        scale_y_continuous(labels = comma)+
        labs(title = 'Average Size of Downloads Vs Number of Downloads',
           x = 'Number of Downloads',
           y = 'Average Size of Downloads(bytes)',
           caption = '@kigtembu')+
        theme_grey()

# Save Plot ---------------------------------------------------------------
ggsave('week31.png',plot = cran2)





","Other-31"
"850",1617,"https://github.com/kigtembu/Tidyverse/blob/master/week26.R","kigtembu","Tidyverse","week26.R","###-----------------------###
## Week 26 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 24/9/2018               ##
#---------------------------#

library(tidyverse)
library(tmap)
library(RCurl)
library(sf)
library(spData)
library(spDataLarge)

## read in data
url<- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-09-25/africa_species.csv'
Invasive_sp <- read.csv(text = getURL(url),
                        header = T) 
Invasive_sp1 <- select(Invasive_sp,country,species)%>%
                distinct()%>%
                count(country)%>%
                mutate('No. of Species'= n,name = as.character(country))%>%
                mutate( name_long = str_replace_all(name,c('United Republic of Tanzania' = 'Tanzania',
                                                           'Gambia \\(the\\)' = 'The Gambia',
                                                            'Swaziland' = 'eSwatini')))
                                                        

##  Merge with Africa shape file

africa_sf <- filter(world,continent == 'Africa')
africa_mg <- left_join(africa_sf,Invasive_sp1,by = 'name_long')

## plot
breaks <- c(0,2.5,5,7.5,10,12.5,15,17.5,20,22.5)*100
africa <-tm_shape(africa_mg)+
         tm_polygons(col = 'No. of Species',breaks = breaks)+
         tm_style('classic')
tmap_save(tm = africa,'week26.png')

","Other-26"
"851",1618,"https://github.com/kigtembu/Tidyverse/blob/master/week16.R","kigtembu","Tidyverse","week16.R","### Tidytuesday  challenge
##  created by kigen Tembu
##  17/7/2018

## libraries

library(tidyverse)
library(readxl)
library(ggplot2)
library(gridExtra)
library(grid)
library(ggpubr)

#read in data

exercise <-read_excel('week16_exercise.xlsx',sheet = 1)

#transpose data, filter out NAs then take top 5 per working category

exercise1 <- gather(exercise,'category','percent',3:9)%>%
            filter( percent != 'NA')%>%
            group_by(category)%>%
            mutate(percent1 = as.numeric(percent))%>%
            top_n(5,percent1)%>% 
            select(state,category,percent1)%>%
            arrange(category,desc(percent1))%>%
            filter(str_detect(category,'working'))
#plots 



plot1 <- ggplot(filter(exercise1,category == 'men_working'),aes(x =reorder(state,-percent1),y =percent1))+
         geom_bar(stat = 'identity',position = position_stack(reverse = FALSE),fill = 'seagreen1',width = 0.8)+
         theme_minimal()+
         labs(title = 'Male Workers', y = 'Percent',x = '')+
         geom_text(aes(y = percent1,label= state,hjust = 0.65))+
         theme(axis.ticks = element_blank(),axis.text.x = element_blank())+
         coord_polar()

plot2 <- ggplot(filter(exercise1,category == 'women_working'),aes(x=reorder(state,-percent1),y=percent1))+
         geom_bar(stat= 'identity',position = position_stack(reverse = FALSE),fill = 'seagreen1',width = 0.7)+
         theme_minimal()+
         labs(title = 'Female Workers', y = 'Percent',x ='')+
         geom_text(aes(y = percent1,label= state,hjust = 0.65 ))+
         theme(axis.ticks = element_blank(),axis.text.x = element_blank())+
         coord_polar()

plot3 <- ggplot(filter(exercise1,category == 'men_nonworking'),aes(x=reorder(state,-percent1),y=percent1))+
         geom_bar(stat='identity',position = position_stack(reverse = FALSE),fill = 'seagreen1',width = 0.8)+
         theme_minimal()+
         labs(title = 'Male Nonworkers', y = 'Percent',x ='')+
         geom_text(aes(y = percent1,label= state,hjust = 0.8 ))+
         theme(axis.ticks = element_blank(),axis.text.x = element_blank())+
         coord_polar()

plot4 <- ggplot(filter(exercise1,category == 'women_nonworking'),aes(x=reorder(state,-percent1),y =percent1))+
         geom_bar(stat = 'identity',position = position_stack(reverse = FALSE),fill = 'seagreen1',width = 0.8)+
         theme_minimal()+
         labs(title = 'Female Nonworkers', y = 'Percent',x ='')+
         geom_text(aes(y = percent1,label= state,hjust = 0.9 ))+
         theme(axis.ticks = element_blank(),axis.text.x = element_blank())+
         coord_polar()

footnote <- text_grob('States with the highest percentage of adults per category\nwho met both aerobic and muscle strengthening federal guidelines\n@kigtembu',face = 'bold',size =10)

grid.arrange(plot1,plot2,plot3,plot4,ncol = 2, nrow =2 , bottom = footnote )


","Other-16"
"852",1619,"https://github.com/kigtembu/Tidyverse/blob/master/week25.R","kigtembu","Tidyverse","week25.R","###-----------------------###
## Week 25 Tidytuesday     ##
## Created by Kigen Tembu  ##
## 17/9/2018               ##
#---------------------------#

#libraries

library(tidyverse)
library(ggplot2)
library(RCurl)
library(sf)
library(tmap)
library(spData)
library(spDataLarge)
library(rvest)

#animation
devtools::install_github(""yihui/animation"")

#read data
url <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-09-18/us-airports.csv'

airports <- read.csv(text = getURL(url),
                     header = T)


airport1 <- select(airports,state,year,passengers)%>%
            group_by(state,year)%>%
            summarise(total = sum(passengers,na.rm = TRUE))

statenames <- tibble(state = state.abb,NAME =state.name)

#merge to get full state names

airport2 <- left_join(airport1,statenames, by = 'state')%>%
            rename('Total Passengers'= total)

#merge with us_states sf

airport3 <- left_join(airport2,us_states, by = 'NAME')
airport_sf <- st_as_sf(airport3)


airport_anim = tm_shape(us_states) + 
               tm_polygons() +
               tm_shape(airport_sf)+tm_bubbles(size = 'Total Passengers',col ='black', border.col = NA)+
               tm_facets(along = 'year', free.coords = FALSE) 


tmap_animation(airport_anim,filename = 'airport.gif',delay = 90)
                
","Other-25"
"853",1620,"https://github.com/douglaszickuhr/General-R-Code/blob/master/tidytuesday/week18.Rmd","douglaszickuhr","General-R-Code","tidytuesday/week18.Rmd","---
title: ""Week18""
author: ""Douglas Zickuhr""
date: ""2/8/2018""
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
```

## Reading the spreadsheet into R
```{r reading excel spreadsheet}
animals <- readxl::read_xlsx(path = ""tidytuesday/data/week18_dallas_animals.xlsx"",
                             sheet = ""simple"")
```


### Analysing the intake of Dogs and Cats across the year.

Apparently there is a sad pattern of abbandoned animals during the summer
```{r animals intake plot echo=FALSE}
p1 <- animals %>%
  dplyr::filter(animal_type %in% c(""CAT"",""DOG"")) %>%
  dplyr::filter(intake_type %in% c(""STRAY"",""OWNER SURRENDER"")) %>%
  dplyr::mutate(intake_type = factor(intake_type),
         animal_type = factor(animal_type),
         intake_type = forcats::fct_recode(intake_type, ""Stray"" = ""STRAY"",
                                  ""Owner Surrender"" = ""OWNER SURRENDER""),
         animal_type = forcats::fct_recode(animal_type, ""Dog"" = ""DOG"",
                                  ""Cat"" = ""CAT"")) %>%
  dplyr::group_by(intake_type,animal_type,intake_date) %>%
  dplyr::summarise(number = dplyr::n()) %>%
  ggplot2::ggplot(ggplot2::aes(x=intake_date,y=number,group=animal_type,colour=animal_type)) + 
  ggplot2::geom_line(alpha = 0.2) + 
  ggplot2::geom_smooth(method = ""loess"") + 
  ggplot2::facet_wrap(~intake_type, 
             scales = ""free_y"", 
             ncol = 1) + 
  ggplot2::theme_minimal() + 
  ggplot2::scale_colour_brewer(palette = ""Set1"") + 
  ggplot2::labs(title = ""Abbandoned Animals Intake by Intake Date"",
       x = ""Intake Date"",
       y = ""Number of Animals"",
       colour = ""Animal Type"")

ggplot2::ggsave(filename = ""Week18-1.png"",
       plot = p1)
  
p1
```

### Analysing the outcome of Dogs and Cats during the year.

Visually, there is a tendency of Dogs to be more adopted than cats.

```{r pressure, echo=FALSE}
p2 <- animals %>%
  dplyr::filter(animal_type %in% c(""CAT"",""DOG"")) %>%
  dplyr::filter(intake_type %in% c(""STRAY"",""OWNER SURRENDER"")) %>%
  dplyr::mutate(animal_type = factor(stringr::str_to_title(animal_type)),
         outcome_type = factor(stringr::str_to_title(outcome_type))) %>%
  dplyr::mutate(outcome_type = forcats::fct_lump(outcome_type, n = 5),
         month = lubridate::month(intake_date,label = TRUE)) %>%
  dplyr::group_by(month,outcome_type,animal_type) %>%
  dplyr::summarise(total = dplyr::n()) %>%
  ggplot2::ggplot() +
  ggplot2::geom_area(ggplot2::aes(x=month, y=total,group = outcome_type, fill = outcome_type)) + 
  ggplot2::facet_wrap(~animal_type, ncol = 1, scales = ""free_y"") + 
  ggplot2::theme_minimal() + 
  ggplot2::scale_fill_brewer(palette = ""Set1"")+ 
  ggplot2::labs(title = ""Abbandoned Animals Outcome by Month"",
       x = ""Month"",
       y = ""Number of Animals"",
       colour = ""Outcome"")

ggplot2::ggsave(filename = ""Week18-2.png"",
       plot = p2)
  
p2
```

","Other-18"
"854",1621,"https://github.com/douglaszickuhr/general_r_code/blob/master/tidytuesday/week16.R","douglaszickuhr","general_r_code","tidytuesday/week16.R","library(readxl)
library(tidyverse)

url <- ""https://github.com/rfordatascience/tidytuesday/blob/master/data/week16_exercise.xlsx?raw=true""
filename <- ""week16_exercise.xlsx""
download.file(url,paste(""data"",filename,sep = ""/""))

df <- read_xlsx(paste(""data"",filename,sep = ""/""),
                sheet = ""tidy"") %>%
  select(-count) %>%
  mutate(exercise = parse_double(exercise))

glimpse(df)

boxplot_by_sex <- df %>%
  filter(state != ""state_average"" & sex != ""both"") %>%
  ggplot() + 
  geom_boxplot(aes(x=sex,y=exercise,fill = sex)) + 
  facet_wrap(~work_status) + 
  labs(title = ""Distribution of Exercise data in the US"",
       y = ""% of adults that meet exercises guidelines"",
       x = ""Sex"") + 
  theme_minimal() + 
  theme(
    legend.position = ""none""
  )

ggsave(boxplot_by_sex, filename = ""week16-1.png"")

boxplot_by_work_status <- df %>%
  filter(state != ""state_average"" & sex != ""both"" & work_status != ""all"") %>%
  ggplot() + 
  geom_boxplot(aes(x=work_status,y=exercise,fill = sex)) + 
  facet_wrap(~sex) + 
  labs(title = ""Distribution of Exercise data in the US"",
       y = ""% of adults that meet exercises guidelines"",
       x = ""Working Status"") + 
  theme_minimal()

ggsave(boxplot_by_work_status, filename = ""week16-2.png"")



histogram_by_sex <- df %>%
  filter(state != ""state_average"" & sex != ""both"" & work_status != ""all"") %>%
  ggplot() + 
  geom_histogram(aes(x=exercise, fill = sex), binwidth = 3) + 
  labs(title = ""Distribution of Exercise data in the US"",
       y = ""Number of observations"",
       x = ""% of adults that meet exercises guidelines"",
       fill = ""Sex"") + 
  theme_minimal()

ggsave(histogram_by_sex, filename = ""week16-3.png"")


histogram_by_work_status <- df %>%
  filter(state != ""state_average"" & sex != ""both"" & work_status != ""all"") %>%
  ggplot() + 
  geom_histogram(aes(x=exercise, fill = work_status), binwidth = 5) + 
  labs(title = ""Distribution of Exercise data in the US"",
       y = ""Number of records"",
       x = ""% of adults that meet exercises guidelines"",
       fill = ""Work Status"") + 
  theme_minimal()
  
ggsave(histogram_by_work_status, filename = ""week16-4.png"")
","Other-16"
"855",1636,"https://github.com/robertopreste/MyTidyTuesday","robertopreste","MyTidyTuesday","Week_19/Week_19.Rmd","---
title: ""TidyTuesday 2018 - Week 19 - Airline Safety""
author: ""Roberto Preste""
date: ""2018-08-07""
output: html_document
---

This is an extract from my work for week 19 (2018) of the [#TidyTuesday](https://thomasmock.netlify.com/post/tidytuesday-a-weekly-social-data-project-in-r/) project.

This weeks dataset was focused on airlines accidents, particularly on differences between the 1985-1999 and 2000-2014 years. I decided to highlight how much each airline company reduced (or not) the amount of incidents, fatalities and fatal accidents in recent years. More information on these categories of accidents can be found in the [original article](https://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/).

All code and data can be found in my dedicated GitHub repository [MyTidyTuesday](https://github.com/robertopreste/MyTidyTuesday).

___

```{r}
library(tidyverse)
library(fivethirtyeight)
data(""airline_safety"")
```

___

These are the starting data (the original article can be found [here](https://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/)):  

```{r}
head(airline_safety)
```

___

## Tidying the data  

Let's calculate the difference of accidents in 2000-2014 vs 1985-1999; lower values mean a reduced number of accidents in recent years. After that, we'll `gather` these values.  

```{r}
airline_diff <- airline_safety %>% 
    mutate(fatal_accidents = fatal_accidents_00_14 - fatal_accidents_85_99, 
           fatalities = fatalities_00_14 - fatalities_85_99, 
           incidents = incidents_00_14 - incidents_85_99) %>% 
    gather(key = ""event"", value = ""occurrences"", fatal_accidents, fatalities, incidents) %>% 
    select(everything(), -c(fatal_accidents_85_99, fatal_accidents_00_14, fatalities_85_99, fatalities_00_14, incidents_85_99, incidents_00_14))
```

The tidy dataset looks like this:  

```{r}
head(airline_diff)
```

___

## Visualizations  


```{r dpi=200}
airline_diff %>% 
    filter(event == ""fatalities"", occurrences != 0) %>% 
    ggplot(aes(x = reorder(airline, occurrences), y = occurrences, fill = occurrences)) + 
    geom_col() + 
    coord_flip() + 
    scale_fill_gradientn(colors = c(""darkgreen"", ""aquamarine3"", ""seagreen3"", ""yellow"", ""orange"", ""darkred"")) +
    labs(x = ""Airline"", y = ""Fatalities"", fill = """", title = ""Difference in number of fatalities"", subtitle = ""Years 1985-1999 vs 2000-2014"")
```

```{r dpi=200}
airline_diff %>% 
    filter(event == ""fatal_accidents"", occurrences != 0) %>% 
    ggplot(aes(x = reorder(airline, occurrences), y = occurrences, fill = occurrences)) + 
    geom_col() + 
    coord_flip() +
    scale_fill_gradientn(colors = c(""darkgreen"", ""aquamarine3"", ""seagreen3"", ""orange"", ""darkred""), values = c(0, 0.6, 0.7, 0.8, 1)) + 
    labs(x = ""Airline"", y = ""Fatal Accidents"", fill = """", title = ""Difference in number of fatal accidents"", subtitle = ""Years 1985-1999 vs 2000-2014"")
```

```{r dpi=200}
airline_diff %>% 
    filter(event == ""incidents"", occurrences != 0) %>% 
    ggplot(aes(x = reorder(airline, occurrences), y = occurrences, fill = occurrences)) + 
    geom_col() + 
    coord_flip() +
    scale_fill_gradientn(colors = c(""darkgreen"", ""aquamarine3"", ""seagreen3"", ""orange"", ""darkred""), values = c(0, 0.7, 0.8, 0.9, 1)) + 
    labs(x = ""Airline"", y = ""Incidents"", fill = """", title = ""Difference in number of incidents"", subtitle = ""Years 1985-1999 vs 2000-2014"")
```

___  

```{r}
sessionInfo()
```

","Other-19"
"856",1637,"https://github.com/robertopreste/MyTidyTuesday","robertopreste","MyTidyTuesday","Week_20/Week_20.Rmd","---
title: ""TidyTuesday 2018 - Week 20 - Russian Troll Tweets""
author: ""Roberto Preste""
date: ""2018-08-15""
output: html_document
---

This is my work for week 20 (2018) of the [#TidyTuesday](https://thomasmock.netlify.com/post/tidytuesday-a-weekly-social-data-project-in-r/) project.

This weeks dataset was focused on Russian Trolls Tweets. As further explained in the [original article](https://fivethirtyeight.com/features/why-were-sharing-3-million-russian-troll-tweets/) from FiveThirtyEight, almost 3000 Twitter troll accounts were found to be active from 2015 to 2018, possibly influencing the American elections outcome as well as subsequent events.
In this notebook I explored a bit the collection of almost 3 millions tweets from these troll handles, highlighting some of their peculiarities and tweeting trends over time.

All code and data can be found in my dedicated GitHub repository [MyTidyTuesday](https://github.com/robertopreste/MyTidyTuesday).

___

```{r, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
```

___ 

The original data are not included in this repo, given their dimension, but are available on fivethirtyeight's [GitHub](https://github.com/fivethirtyeight/russian-troll-tweets) and are detailed in a specific [article](https://fivethirtyeight.com/features/why-were-sharing-3-million-russian-troll-tweets/).  

```{r, results='hide'}
tweet_1 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_1.csv"", col_types = ""ccccccciiicciic"")
tweet_2 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_2.csv"", col_types = ""ccccccciiicciic"") 
tweet_3 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_3.csv"", col_types = ""ccccccciiicciic"")
tweet_4 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_4.csv"", col_types = ""ccccccciiicciic"")
tweet_5 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_5.csv"", col_types = ""ccccccciiicciic"")
tweet_6 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_6.csv"", col_types = ""ccccccciiicciic"") 
tweet_7 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_7.csv"", col_types = ""ccccccciiicciic"")
tweet_8 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_8.csv"", col_types = ""ccccccciiicciic"") 
tweet_9 <- read_csv(""russian-troll-tweets/IRAhandle_tweets_9.csv"", col_types = ""ccccccciiicciic"") 
```

Let's merge all the dataset together.  

```{r}
tweets <- bind_rows(list(tweet_1, tweet_2, tweet_3, tweet_4, tweet_5, tweet_6, tweet_7, tweet_8, tweet_9))
```

___

## Data exploration  

First of all, let's find the top 20 tweeters and distinguish them based on their assigned account category.  

```{r}
top_20_handles <- tweets %>% 
    group_by(author, account_category) %>% 
    summarise(n = n()) %>% 
    arrange(desc(n)) 
top_20_handles <- top_20_handles[1:20, ]
```

```{r, dpi=200}
top_20_handles %>% 
    ggplot(aes(x = reorder(author, n), y = n)) + 
    geom_col(aes(fill = account_category)) + 
    coord_flip() + 
    labs(x = ""Authors"", y = ""Tweets"", title = ""Top 20 tweeters"", fill = """") + 
    theme(legend.position = ""bottom"")
```

The top tweeters are commercial, (fake) news feeds and Right trolls.  

However, even though these are the most active account categories, we can see that the first two groups represent only a small part of the total IRA handles.  

```{r}
categ_count <- tweets %>% 
    select(author, account_category) %>% 
    distinct() %>% 
    group_by(account_category) %>% 
    summarise(n = n())
```

```{r, dpi=200}
categ_count %>% 
    ggplot(aes(x = reorder(account_category, n), y = n)) + 
    geom_col(aes(fill = account_category)) + 
    coord_flip() + 
    labs(x = ""Category"", y = ""Accounts"", title = ""Number of handles per category"") + 
    guides(fill = FALSE)
```

We might want to know the tweeting frequency of these top 20 accounts, to check if there is some tweeting trend.  

```{r}
top_tweets <- tweets %>% 
    filter(author %in% top_20_handles$author) %>% 
    separate(col = publish_date, into = c(""pub_date"", ""pub_time""), sep = "" "") %>% 
    mutate(pub_date = as_date(pub_date, tz = ""UTC"", format = ""%d/%m/%Y""))
```

```{r}
top_tweets_grouped <- top_tweets %>% 
    group_by(pub_date, account_category) %>% 
    summarise(n = n()) %>% 
    filter(!is.na(pub_date))
```

```{r, dpi=200}
top_tweets_grouped %>% 
    ggplot(aes(x = pub_date, y = n)) + 
    geom_line(aes(color = account_category)) + 
    labs(x = ""Date"", y = ""Tweets"", color = """", title = ""Tweeting activity"", subtitle = ""Top 20 handles"")
```

From this plot we can see that, among the top 20 tweeters, the commercial ones posted a number of tweets 4 times greater than the other categories, but suddenly stopped tweeting right before 2016.  
Let's check if this is true taking into account all handles, not just the top 20.  

```{r}
tweets_dates <- tweets %>% 
    separate(col = publish_date, into = c(""pub_date"", ""pub_time""), sep = "" "") %>% 
    mutate(pub_date = as_date(pub_date, tz = ""UTC"", format = ""%d/%m/%Y""))
```

```{r}
tweets_dates_grouped <- tweets_dates %>% 
    filter(pub_date >= ""2015/01/01"", pub_date <= ""2018/01/01"") %>% 
    group_by(pub_date, account_category) %>% 
    summarise(n = n()) %>% 
    filter(!is.na(pub_date))
```

```{r, dpi=200}
tweets_dates_grouped %>% 
    ggplot(aes(x = pub_date, y = n)) + 
    geom_line(aes(color = account_category)) + 
    labs(x = ""Date"", y = ""Tweets"", title = ""Tweeting activity"", subtitle = ""All handles"") + 
    facet_wrap(~ account_category, nrow = 4) + 
    guides(color = FALSE)
```

What we found previously might hold true concerning commercial tweeters: their number of tweets suddenly drops since 2016. However, we can also discover some more interesting insights:  

 - fearmonger accounts (those spreading fake crisis news) seem to disappear right before 2017 (luckily, I would add);  
 - Left trolls had a peak in their activity in mid 2016: I'm no expert in American politics, but this seem to overlap with the Democrats presidential primaries;  
 - Right trolls, although having a fairly constant tweeting rate initially, seem to show some sort of exponential increase starting from the first months of 2016;  
 - all the other categories do not show any particular trend.  

In addition, almost all categories have an almost identical monthly trend in tweets.  


Let's see how the number of followers and followed accounts changed for each of these categories over time.  

```{r}
tweets_foll_grouped <- tweets_dates %>% 
    filter(pub_date >= ""2015/01/01"", pub_date <= ""2018/01/01"") %>% 
    group_by(pub_date, account_category) %>% 
    summarise(followers = sum(followers), following = sum(following)) %>% 
    filter(!is.na(pub_date))
```

```{r, dpi=200}
tweets_foll_grouped %>% 
    ggplot(aes(x = pub_date)) + 
    geom_line(aes(y = log(followers), color = ""red"")) + 
    geom_line(aes(y = log(following), color = ""blue"")) + 
    labs(x = ""Date"", y = ""Accounts (log)"", title = ""Followers and Followed accounts"") + 
    facet_wrap(~ account_category, nrow = 4) + 
    scale_colour_manual(name = """", values = c(""red"" = ""red"", ""blue"" = ""blue""), labels = c(""Followed Accounts"", ""Followers"")) + 
    theme(legend.position = ""bottom"")
```

The log transformation allows to better appreciate fluctuations in these numbers. The number of followers and followed accounts is mostly equal within each category; however, particular trends can be found characterizing 2015, 2016 and 2017, with 2016 being the year with less variation in these numbers, among all categories.  

___

### Disclaimer  

These are just some basic insights, created for simple data exploration and visualization purposes. Furthermore, some of the results shown come from filtering the data to some extent.  
No conclusions should be drawn from what is reported here; more appropriate analysis are being conducted by more qualified people than me, like [Darren Linvill](https://www.clemson.edu/cbshs/faculty-staff/profiles/darrenl) and [Patrick Warren](http://pwarren.people.clemson.edu/) and you should get in touch with them if interested in these data.  

All in all, this was an interesting dataset to work with and I'm keen to come back to it in the future, to explore it more deeply with some text and sentiment analysis techniques.  

___

```{r}
sessionInfo()
```

","Other-20"
"857",1638,"https://github.com/robertopreste/MyTidyTuesday","robertopreste","MyTidyTuesday","Week_21/Week_21.Rmd","---
title: ""TidyTuesday Week 21 - California Fires""
author: ""Roberto Preste""
date: ""`r Sys.Date()`""
output: html_notebook
---

```{r, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(funModeling)
library(gridExtra)
```

___ 

This is the original data provided by [BuzzFeed](https://github.com/BuzzFeedNews/2018-07-wildfire-trends) from their article [""How A Booming Population And Climate Change Made Californias Wildfires Worse Than Ever""](https://www.buzzfeednews.com/article/peteraldhous/california-wildfires-people-climate).  

```{r, results='hide'}
df = read_csv(""data/calfire_frap.csv"", skip = 1, 
              col_names = c(""id"", ""objectid"", ""year"", ""state"", ""agency"", ""unit_id"", ""fire_name"", ""inc_num"", 
                            ""alarm_date"", ""cont_date"", ""cause"", ""comments"", ""report_ac"", ""gis_acres"", ""c_method"", 
                            ""objective"", ""fire_num"", ""shape_length"", ""shape_area"", ""fire_cause"", ""plot_date""))
```

```{r}
head(df)
```

___  

## Data exploration  

Let's have a quick view at the structure and content of this dataset.  

```{r}
df %>% df_status()
```


Let's first check the number of human and natural fires throughout the years.  

```{r}
fire_per_years <- df %>% 
    group_by(year, fire_cause) %>% 
    summarise(fires = n(), 
              tot_area_burnt = sum(shape_area), 
              mean_area_burnt = mean(shape_area))
```

We will plot the same data using a simple line plot and a smooth line plot, to avoid overplotting and visualize better the trends.  

```{r, fig.height=4}
line_1 <- fire_type_years %>% 
    ggplot(aes(x = year, y = fires, colour = fire_cause)) + 
    geom_line()
smooth_1 <- fire_type_years %>% 
    ggplot(aes(x = year, y = fires, colour = fire_cause)) + 
    geom_smooth()
grid.arrange(line_1, smooth_1, nrow = 2)
```

```{r, fig.width=4}
fire_type_years %>% 
    ggplot(aes(x = year, y = fires)) + 
    geom_col(aes(fill = fire_cause), position = ""dodge"") +
    geom_smooth(aes(color = fire_cause)) + 
    facet_grid(~ fire_cause) + 
    guides(fill = FALSE, color = FALSE)
```


We can clearly identify that in recent years, human-caused fires have definitely outnumbered the natural ones!  

Let's see if this increase also regards the burnt area of a fire.  

```{r}
fire_area_years <- df %>% 
    group_by(year, fire_cause) %>% 
    summarise(tot_area_burnt = sum(shape_area), 
              mean_area_burnt = mean(shape_area))
```

```{r, fig.height=4}
line_2 <- fire_area_years %>% 
    ggplot(aes(x = year, y = tot_area_burnt, color = fire_cause)) + 
    geom_line()
smooth_2 <- fire_area_years %>% 
    ggplot(aes(x = year, y = tot_area_burnt, color = fire_cause)) + 
    geom_smooth()
grid.arrange(line_2, smooth_2, nrow = 2)
```

Unfortunately, also the total area burnt each year increased over the years, although with no visible difference between natural- and human-caused fires.  
We may interested in the **mean** area burnt by each fire, though.  

```{r, fig.height=4}
line_3 <- fire_area_years %>% 
    ggplot(aes(x = year, y = mean_area_burnt, colour = fire_cause)) + 
    geom_line()
smooth_3 <- fire_area_years %>% 
    ggplot(aes(x = year, y = mean_area_burnt, colour = fire_cause)) + 
    geom_smooth()
grid.arrange(line_3, smooth_3, nrow = 2)
```

From the first line plot, we can see that the mean area burnt by each fire was roughly the same over the years; in this case the smooth plot is not very useful, because it's biased by the two peaks visible in the first graph. They are due to the 2002 [Biscuit Fire](https://en.wikipedia.org/wiki/Biscuit_Fire) and the 2012 [Rush Fire](https://en.wikipedia.org/wiki/Rush_Fire), which destroyed an impressive number of acres during their life.  
Notably, the Biscuit fire caused more destruction alone than all the other fires (natural and human) in 2002!  

```{r}
biscuit_area <- df %>% 
    filter(fire_name == ""BISCUIT"", year == 2002) %>% 
    select(shape_area)
others_area <- df %>% 
    filter(fire_name != ""BISCUIT"", fire_name != ""RUSH"", year == 2002) %>% 
    summarise(tot = sum(shape_area))

area_comp <- tibble(fire_name = c(""Biscuit"", ""Others""), 
                    area_burnt = c(biscuit_area[[1]], others_area[[1]]))
```

```{r}
area_comp %>% 
    ggplot(aes(x = fire_name, y = area_burnt, fill = fire_name)) + 
    geom_col()
```



```{r}
fire_area_years %>% filter(year == 2012)
```

```{r}
df %>% filter(year == 2012) %>% arrange(desc(shape_area))
```


```{r}
df %>% select(alarm_date) %>% is.na()
```

","Other-21"
"858",1639,"https://github.com/robertopreste/MyTidyTuesday","robertopreste","MyTidyTuesday","Week_23/Week_23.Rmd","---
title: ""TidyTuesday 2018 - Week 23 - Fast Food Calories""
author: ""Roberto Preste""
date: ""2018-09-04""
output: html_document
editor_options: 
  chunk_output_type: inline
---

This is my work for week 23 (2018) of the [#TidyTuesday](https://thomasmock.netlify.com/post/tidytuesday-a-weekly-social-data-project-in-r/) project.

This weeks dataset was about nutritional information from several fast food franchises, with data regarding entrees food in particular. Since I am a bit busy at work after the summer holidays, I havent had much time to deeply explore this dataset. A more complete analysis can be found in the in the [original article](https://www.franchiseopportunities.com/blog/general-franchise-information/fast-food-calorie-comparison-charts), or by visiting [fastfoodnutrition.org](https://fastfoodnutrition.org/), which contains more extensive data on this topic.

All code and data can be found in my dedicated GitHub repository [MyTidyTuesday](https://github.com/robertopreste/MyTidyTuesday).

___

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width = 120)
```

```{r, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(stringr)
library(magrittr)
library(rvest)
library(skimr)
```

___ 

Original data come from [fastfoodnutrition.org](https://fastfoodnutrition.org), and the original article about fast food calories comparison is available on [Franchise Opportunities](https://www.franchiseopportunities.com/blog/general-franchise-information/fast-food-calorie-comparison-charts).  

Firstly, we need to scrape the data from the data source (function kindly provided by [thomas_mock](https://twitter.com/thomas_mock)), then we can combine all the data and save them.  

```{r, eval=FALSE}
food_scrape <- function(restaurant, tbl_sel){
    url <- glue::glue(""https://fastfoodnutrition.org/{restaurant}/chart"")
    url %>% 
        read_html() %>% 
        html_table() %>% 
        .[tbl_sel] %>% 
        bind_rows() %>% 
        select(-X16) %>%
        set_names(nm = c(""item"", ""calories"", ""cal_fat"", ""total_fat"", ""sat_fat"", ""trans_fat"",
                         ""cholesterol"", ""sodium"", ""total_carb"", ""fiber"", ""sugar"", ""protein"",
                         ""vit_a"", ""vit_c"", ""calcium"")) %>% 
        mutate(restaurant = str_replace(restaurant, ""-"", "" ""),
               restaurant = str_to_title(restaurant)) # save restaurant name
} 
```

```{r, eval=FALSE}
mcd_df <- food_scrape(""mcdonalds"", c(1,2,3,9,19))
cfa_df <- food_scrape(""chick-fil-a"", c(1,2,8,13))
sonic_df <- food_scrape(""sonic"", c(1,2,17,18,20))
arbys_df <- food_scrape(""arbys"", c(1:4,8))
bk_df <- food_scrape(""burger-king"", c(1:3,7,11:12))
dq_df <- food_scrape(""dairy-queen"", c(5, 7, 12, 25, 27))
sub_df <- food_scrape(""subway"", c(1,2,3,4,5,6,7,8,9))
taco_df <- food_scrape(""taco-bell"", c(1,2,3,4,5,15,18,19,20,22,23,24))

final_df <- bind_rows(mcd_df, cfa_df, sonic_df, arbys_df, bk_df, dq_df, sub_df, taco_df) %>% 
    select(restaurant, everything()) %>% 
    mutate(salad = case_when(str_detect(item, ""salad"") ~ ""Salad"",
                             TRUE ~ ""Other""))

final_df %>% write_csv(""data/fastfood_calories.csv"")
```

The final dataframe is available in `data/fastfood_calories.csv`.  
It contains nutritional information about entrees (main courses) from the specified fast foot franchises.  

```{r, results=""hide""}
df <- read_csv(""data/fastfood_calories.csv"")
```

___

## Data exploration  

Let's have a quick view at the data.

```{r}
head(df)
```

```{r}
skim(df)
```


We can drop the `salad` feature, because it has the same value (`Other`) for all the observations in the data, so it's uninformative.  

```{r}
df %<>% select(-salad)
```

___

## Visualization  

I chose to focus just on a couple of nutrients from these data, namely some of the most *feared* ones: fat and sugar.  

### Fat content per franchise  

Let's visualize the general fat content of entrees per franchise, distinguished in total grams of fat, saturated fat and trans fat.  

```{r}
fat_content <- df %>% 
    group_by(restaurant) %>% 
    summarise(Fat = mean(total_fat), 
              Saturated = mean(sat_fat), 
              Trans = mean(trans_fat)) %>% 
    gather(measure, value, Fat:Trans)
```

```{r, dpi=200}
fat_content %>% 
    ggplot(aes(x = reorder(restaurant, value))) + 
    geom_col(aes(y = value, fill = measure), position = ""dodge"") +
    coord_flip() + 
    labs(x = ""Franchise"", y = ""Fat (g)"", title = ""Mean fat content per franchise"", fill = """", subtitle = ""Chick-Fil-A seems to have low-fat food."") 
```

Seems like, in general, Chick-Fil-A might offer food with a lower fat content, with Subway and Taco Bell immediately following. Choosing one of these three franchises can be two to three times an healthier options compared to other fast foods.  


### Sugar content per franchise  

Another bad player for our health is sugar, so let's check how well our fast foods behave.  

```{r}
sugar_content <- df %>% 
    group_by(restaurant) %>% 
    summarise(Sugar = mean(sugar))
```

```{r, dpi=200}
sugar_content %>% 
    ggplot(aes(x = reorder(restaurant, Sugar), y = Sugar, fill = restaurant)) + 
    geom_col() + 
    coord_flip() + 
    labs(x = ""Franchise"", y = ""Sugar (g)"", title = ""Mean sugar content per franchise"", subtitle = ""Taco Bell might have low-sugar food."") + 
    guides(fill = FALSE)
```

A histogram can give a better overview of data and show possible outliers, represented by food with extremely high content of sugar.  

```{r, dpi=200}
df %>% 
    ggplot(aes(x = sugar, fill = restaurant)) + 
    geom_histogram(bins = 60) + 
    facet_wrap(~ restaurant, nrow = 4, ncol = 2) + 
    labs(x = ""Sugar (g)"", title = ""Sugar content distribution per franchise"") +
    guides(fill = FALSE)
```

Let's zoom in a bit and remove the above-mentioned outliers.  

```{r, dpi=200}
df %>% 
    filter(sugar <= 30) %>% 
    ggplot(aes(x = sugar, fill = restaurant)) + 
    geom_histogram(bins = 30) + 
    facet_wrap(~ restaurant, nrow = 4, ncol = 2) + 
    labs(x = ""Sugar (g)"", title = ""Sugar content distribution per franchise [0-30 g]"") +
    guides(fill = FALSE)
```

An interesting feature can be noted here: Taco Bell offers food with the lowest sugar content, not exceeding 9 grams, while other franchises span a wide range of sugar content. Nonetheless, seems like Taco Bell, together with Subway, do not offer sugar-free options as other fast foods do.  

___

### Disclaimer  

These are just some basic insights, created for simple data exploration and visualization purposes. I'm not a nutritionist, and these are not comprehensive data from which any useful and trustworthy information can be extracted.  
No conclusions should be drawn from what is reported here.  

___

```{r}
sessionInfo()
```","Other-23"
"859",1640,"https://github.com/robertopreste/MyTidyTuesday","robertopreste","MyTidyTuesday","Week_24/Week_24.Rmd","---
title: ""TidyTuesday 2018 - Week 24 - Cats vs Dogs (USA)""
output: html_document
author: ""Roberto Preste""
date: ""2018-09-11""
editor_options: 
  chunk_output_type: inline
---

This is my work for week 24 (2018) of the [#TidyTuesday](https://thomasmock.netlify.com/post/tidytuesday-a-weekly-social-data-project-in-r/) project.

We are dealing with puppies this week!
While the original article from the [Washington Post](https://www.washingtonpost.com/news/wonk/wp/2014/07/28/where-cats-are-more-popular-than-dogs-in-the-u-s-and-all-over-the-world/?utm_term=.670d783ef6cc) shows the distribution of cats and dogs in the entire globe, for this week well focus only on data coming from the USA, using a dataset offered by [data.world](https://data.world/datanerd/cat-vs-dog-popularity-in-u-s).

All code and data can be found in my dedicated GitHub repository [MyTidyTuesday](https://github.com/robertopreste/MyTidyTuesday).

___

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(width = 120)
```

```{r, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(readxl)
library(skimr)
```

___ 

Let's first read in the data and rename the columns for simplicity.  

```{r}
df <- read_excel(""data/catsvdogs.xlsx"", skip = 1, 
                 col_names = c(""location"", ""households_1000"", ""perc_households_pets"", 
                               ""num_pet_households_1000"", ""perc_dog_owners"", 
                               ""dog_own_households_1000"", ""mean_num_dogs_per_household"", 
                               ""dog_population_1000"", ""perc_cat_owners"", ""cat_own_households_1000"", 
                               ""mean_num_cats_per_household"", ""cat_population_1000""))
```

```{r}
head(df)
```

___ 

## Data Exploration  

Now we can have a look at the data structure.  

```{r}
skim(df)
```

Luckily there are no missing values, so we can proceed with our analysis.  

___ 

### Pet-friendly households per US State

Let's first visualize the percentage of household with pets in each State.  

```{r, dpi=200}
df %>% 
    ggplot(aes(x = reorder(location, -perc_households_pets), 
               y = perc_households_pets, fill = location)) + 
    geom_col() + 
    coord_flip() + 
    labs(x = ""US State"", y = ""%"", title = ""Percentage of households with pets"", subtitle = ""District of Columbia seems to be not so pet-friendly."") + 
    guides(fill = FALSE)
```


It is clear that in every US State at least half of the households have pets; particularly, we can see that Vermont is definitely a pet-friendly State, with more than 70% household having at least one dog or cat.  
District of Columbia, instead, doesn't seem to like pets this much, scoring a little more than 20% in this chart.  

### Dog- and cat-owning households  

Let's see if there is any preference for dogs over cats (or viceversa) in these States.  

```{r, dpi=200}
df %>% 
    ggplot(aes(x = reorder(location, -perc_households_pets), fill = location)) + 
    geom_col(aes(y = dog_own_households_1000 - cat_own_households_1000)) + 
    coord_flip() + 
    labs(x = ""US State"", y = ""Difference (in 1000s households)"", 
         title = ""Dog- vs cat-owning households"", 
         subtitle = ""Households with dogs definitely outnumber those hosting cats."") + 
    guides(fill = FALSE) + 
    scale_y_continuous(breaks = c(-250, 0, 250, 500, 750, 1000, 1250))
```


For this plot I computed the difference between dog-owning households and cat-owning ones, in thousands: negative values represent a preference for cats, while positive values denote a higher number of households hosting dogs.  
A couple of peculiar data points are Texas and Massachusetts, where people seem to definitely love dogs, in the former case, and cats, in the latter.  

### Mean number of dogs/cats per household  

We might be interested in knowing whether, as the number of households with pets increases, so does the mean number of dogs/cats hosted in each household. Let's find out.  

```{r}
gath_df <- df %>% 
    mutate(dogs = mean_num_dogs_per_household, 
           cats = mean_num_cats_per_household) %>% 
    select(location, num_pet_households_1000, dogs, cats) %>% 
    gather(key = ""pet"", value = ""value"", dogs, cats)
```

```{r}
gath_df
```


```{r, dpi=200, message=FALSE}
gath_df %>% 
    ggplot(aes(x = num_pet_households_1000, y = value, color = pet)) + 
    geom_smooth() + 
    geom_point(alpha = 0.5) + 
    labs(x = ""Households (in 1000s)"", y = ""Number of pets"", 
         title = ""Mean number of dogs/cats per household"", 
         subtitle = ""The number of pets per household seems to reach a plateau after 1M households with pets."")
```


Although the data are a bit messy, an interesting trend is visible here: initially, as the number of households with pets grows, the mean number of pets per household steeply grows as well, and this is true for both dogs and cats. However, after about the first million of households with pets, the mean number of pets seems to reach a plateau, with cats outnumbering dogs on average.  

___

## Discussion  

So we have found two interesting things here:  

* most households have a kind of preference for dogs over cats, but  
* on average, there are more cats than dogs in each household.  

With these information, we can try to normalize the number of households with pets by the mean number of dogs/cats hosted.  

```{r}
norm_df <- df %>% 
    mutate(norm_dogs = dog_own_households_1000 * mean_num_dogs_per_household, 
           norm_cats = cat_own_households_1000 * mean_num_cats_per_household) %>% 
    select(location, norm_dogs, norm_cats, perc_households_pets)
```

```{r}
norm_df
```

```{r, dpi=200}
norm_df %>% 
    ggplot(aes(x = reorder(location, -perc_households_pets), fill = location)) + 
    geom_col(aes(y = norm_dogs - norm_cats)) + 
    coord_flip() + 
    labs(x = ""US State"", y = ""Difference (in 1000s households)"", 
         title = ""Dog- vs cat-owning households (normalized)"", 
         subtitle = ""With normalized data, we see that cats win the fight."") + 
    guides(fill = FALSE) + 
    scale_y_continuous(breaks = c(-1000, -500, 0, 500, 1000, 1500))
```

With this computation, we can clearly see that most US States host more cats than dogs in their houses.  
We could have reached the same conclusion by simply plotting the total population of dogs and cats, with a few differences.  

```{r, dpi=200}
df %>% 
    ggplot(aes(x = reorder(location, -perc_households_pets), fill = location)) + 
    geom_col(aes(y = dog_population_1000 - cat_population_1000)) + 
    coord_flip() + 
    labs(x = ""US State"", y = ""Difference (in 1000s pets)"", 
         title = ""Difference of dog/cat population"", 
         subtitle = ""Most US States host cats, rather than dogs."") + 
    guides(fill = FALSE) + 
    scale_y_continuous(breaks = c(-1000, -500, 0, 500, 1000, 1500))
```

___ 

```{r}
sessionInfo()
```

","Other-24"
"860",1641,"https://github.com/robertopreste/MyTidyTuesday","robertopreste","MyTidyTuesday","Week_27/Week_27.Rmd","---
title: ""TidyTuesday 2018 - Week 27 - US Births""
output: html_document
author: ""Roberto Preste""
date: ""2018-10-03""
editor_options: 
  chunk_output_type: inline
---

This is my work for week 27 (2018) of the [#TidyTuesday](https://thomasmock.netlify.com/post/tidytuesday-a-weekly-social-data-project-in-r/) project.  

A funny dataset for this week's TidyTuesday: how many babies are born on Friday 13^th^ compared to other days?  
The [original article](https://fivethirtyeight.com/features/some-people-are-too-superstitious-to-have-a-baby-on-friday-the-13th/) and data are offered by fivethirtyeight ([here](https://github.com/rudeboybert/fivethirtyeight) is their GitHub profile, where all the raw data can be found).  

All code and data can be found in my dedicated GitHub repository [MyTidyTuesday](https://github.com/robertopreste/MyTidyTuesday).   

___

```{r global_options, echo = FALSE, include = FALSE}
options(width = 120)
```

```{r, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(lubridate)
library(skimr)
library(RColorBrewer)
```

___  

We will first load the data into R.  

```{r results='hide'}
df <- read_csv(""data/us_births_2000-2014.csv"")
```

```{r}
head(df)
```

___  

## Data Exploration  

Let's check for missing values and other issues.  

```{r}
skim(df)
```

Everything seems to be in order.  
Let's add another column, `date`, to obtain the proper date from the `year`, `month` and `date_of_month` features.  

```{r}
df %<>% 
    mutate(date = as_date(paste(year, month, date_of_month, sep = ""-"")))
```

```{r}
df
```

I will create a set of colors that I'll use during this analysis.  

```{r}
pastels <- brewer.pal(4, ""Pastel1"")
```

___  

## Discussion  

Now we can have a quick look at the distribution of births over the years.  

```{r, dpi=200}
df %>% 
    ggplot(aes(x = year, y = births)) + 
    geom_boxplot(aes(group = year), fill = pastels[2]) + 
    scale_x_continuous(breaks = c(2000:2014)) + 
    labs(x = ""Year"", y = ""Births"", title = ""Births distribution over years"")
```

The number of births each year seems to be quite constant, with a small increase in 2006-2008.  
Let's plot the same distribution over months this time.  

```{r, dpi=200}
df %>% 
    ggplot(aes(x = month, y = births)) + 
    geom_boxplot(aes(group = month), fill = pastels[2]) + 
    scale_x_continuous(breaks = c(1:12), 
                       labels = month.abb) + 
    labs(x = ""Month"", y = ""Births"", title = ""Births distribution over months"")
```

It looks like most births are occurring in September; this is quite interesting, and my guess is that this may due to couples being able to *""spend more time together""* during Christmas holidays, if you know what I mean...  
Lastly, let's view the distribution of births over days of a month.  

```{r, dpi=200}
day_colors <- c(rep(pastels[2], 12), pastels[1], rep(pastels[2], 18))
df %>% 
    ggplot(aes(x = date_of_month, y = births)) + 
    geom_boxplot(aes(group = date_of_month), fill = day_colors) + 
    scale_x_continuous(breaks = c(1, 10, 20, 30)) + 
    labs(x = ""Day of month"", y = ""Births"", title = ""Births distribution over days of the month"")
```

And there it is! Each 13^th^ day the number of births is a bit lower than the other days; the same is true for the 31^st^, but this may be due to months having only 30 days. Let's explore a bit more by plotting the same per-day distribution splitted by month.  

```{r, dpi=200, message=FALSE, warning=FALSE}
df %>% 
    ggplot(aes(x = date_of_month, y = births)) + 
    geom_boxplot(aes(group = date_of_month)) +
    facet_wrap(month ~ ., nrow = 4, ncol = 3, 
               labeller = function(variable, value) {return(month.abb[value])}) + 
    scale_x_continuous(breaks = c(1, 10, 20, 30)) + 
    labs(x = ""Day of month"", y = ""Births"", title = ""Births distribution over days per each month"")
```

Although this is quite an ugly plot, we can see that usually every 13^th^ of each month few babies are born. The same occurs with national holydays, and this is obvious from the drop in the number of births around Christmas, or on the 4^th^ of July, or during the last few days of November for Thanksgiving.  

But we haven't still explored the number of births occurring on Friday 13^th^.  
Let's first see how birth are distributed over days of the week.  

```{r, dpi=200}
week_colors <- c(rep(pastels[2], 5), rep(pastels[1], 2))
df %>% 
    ggplot(aes(x = day_of_week, y = births)) + 
    geom_boxplot(aes(group = day_of_week), fill = week_colors) + 
    scale_x_continuous(breaks = c(1:7), 
                       labels = c(""Mon"", ""Tue"", ""Wed"", ""Thu"", ""Fri"", ""Sat"", ""Sun"")) +
    labs(x = ""Day of the week"", y = ""Births"", title = ""Births distribution over the week"")
```

We can see a strong dicrease in the number of newborns during the weekends, and this is quite expected.  
Now let's gather all these information and actually check if Friday 13^th^ is really a no-no for delivering babies.  

```{r, dpi=200}
df %>% 
    mutate(lucky = case_when(date_of_month == 13 & day_of_week == 5 ~ ""Friday 13"", 
                             date_of_month == 13 & day_of_week != 5 ~ ""Regular 13"",
                             date_of_month != 13 & day_of_week == 5 ~ ""Regular Friday"", 
                             TRUE ~ ""Other"")) %>% 
    filter(lucky != ""Other"") %>% 
    ggplot(aes(x = date, y = births, color = lucky)) + 
    geom_point() + 
    geom_smooth(method = ""loess"", se = F) + 
    labs(x = ""Date"", y = ""Births"", title = ""Number of births on 13s, Fridays and Friday 13s"") + 
    guides(color = guide_legend(title = NULL)) + 
    theme(legend.position = ""bottom"")
```

From what we see, there is no actual decrease in the number of births on Friday 13^th^, but rather on the 13^th^ of each month, regardless of the day of the week.  

___ 

```{r}
sessionInfo()
```","Other-27"
"861",1652,"https://github.com/pedrow28/tidytuesday","pedrow28","tidytuesday","37 - NYC Restaurants/NYC Restaurants.Rmd","---
title: ""TT 37 - NYC Restaurants""
author: ""Pedro William""
date: ""10 de dezembro de 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(lubridate)
library(ggrepel)
library(ggthemes)
library(tidytext)
library(tm)
library(wordcloud)
library(broom)




```

```{r}
nyc_data <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-12-11/nyc_restaurants.csv"")

nyc_data <- nyc_data %>% mutate(inspection_date = gsub(""/"", ""-"", .$inspection_date))

nyc_data <- nyc_data %>% mutate(inspection_date = mdy(inspection_date))
```



#Number of restaurants inspected by borough

```{r}

number_ofrest <- nyc_data %>% group_by(boro, critical_flag) %>% 
  summarise(n = n()) %>%
  mutate(critical_flag = as_factor(critical_flag)) %>%  
  arrange(desc(n)) %>%
  filter(!is.na(boro), boro != ""Missing"", critical_flag != ""Not Applicable"") %>% 
  mutate(n = case_when(critical_flag == ""Critical"" ~ n,
                       TRUE ~ -n)) %>% 
  ggplot(aes(x = fct_reorder(boro, -n), y = n, fill = critical_flag)) +
    geom_col() +
    geom_label_repel(aes(y = n, label = abs(n), fontface = ""bold""),
                     show.legend = FALSE,
                     vjust = 1, 
                     fill = ""#b3b3b3"",
                     col = ""#ffffff"") +
    coord_flip() + 
    expand_limits(y = c(-15000, 17000)) +
    scale_fill_manual(name = """", values = c(""Not Critical"" = ""#99ccff"", ""Critical"" = ""#ff8080"")) +
    labs(title = ""Inspection situation of NYC restaurants"",
         subtitle = ""Critical flags of inspections by boroughs"",
         caption = ""Source: NYC Department of Health"",
         x = """",
         y = """") +
    theme_economist() +
    theme(legend.position = ""bottom"",
          axis.line.x = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.text.y = element_text(color = ""#808080"", face = ""bold""),
          legend.text = element_text(color = ""#808080""),
          title = element_text(color = ""#808080""))

ggsave(""Inspection situation of NYC restaurants.png"", number_ofrest)
    



```

#Analysis of violations

```{r}

stop_words_my <- stopwords::stopwords(""en"")

violations <- nyc_data %>% mutate(id = row_number()) %>% 
  unnest_tokens(word, violation_description) %>%
  select(id, everything())
  
violations <- violations %>% filter(!(word %in% stop_words_my), !is.na(word))

violations_n <- violations %>% group_by(id, critical_flag, word) %>% 
  summarise(n = n())

violations_tf <- violations_n %>% 
  bind_tf_idf(word, id, n)

```


#More common words by flag - make comparison cloud

```{r}

 matrix_terms <- violations_tf %>% group_by(critical_flag, word) %>%
  summarise(mean_tf = mean(tf_idf)) %>% 
  arrange(desc(mean_tf)) %>% 
  top_n(10) %>%
  group_by(critical_flag) %>%
  arrange(desc(mean_tf)) %>%
  cast_tdm(critical_flag, word, mean_tf) %>% 
  as.matrix() %>% 
  #transpose 
  t()

  colnames(matrix_terms) = c(""Common words in critical violations"", ""Common words in not critical violations"")

png(""Comparison Cloud.png"")
layout(matrix(c(1, 2), nrow = 2), heights = c(1, 4))
par(mar = rep(0, 4))
plot.new()
text(x = 0.5, y = 0.5, ""Most common words in violations description"")
comparison.cloud(matrix_terms, 
                 random.order = FALSE, 
                 title.size = 0.9, 
                 title.bg.colors = ""white"",
                 colors = c(""#6699ff"", ""#ff4d4d""))

dev.off()

```




#Score vs flags - ML Try

```{r}

model_data <- nyc_data %>% filter(critical_flag != ""Not Applicable"", !is.na(score)) %>% 
                           mutate(critical_flag = case_when(critical_flag == ""Critical"" ~ 1,
                                                            critical_flag == ""Not Critical"" ~ 0))

model <- glm(critical_flag ~ score, data = model_data, family = ""binomial"")

mean(model_data$critical_flag)


augmented <- augment(model)

library(pROC)

ROC <- roc(augmented$critical_flag, augmented$.fitted)

plot(ROC)

auc(ROC)

##NOT GOOD MODEL

RMSE <- sqrt(mean(augmented$.resid^2))

Metrics::rmse(augmented$critical_flag, augmented$.fitted)


```





#Score of avaliation by violation code

```{r}
scores <- nyc_data %>% mutate(violation_code = as_factor(violation_code)) %>% 
             select(violation_code, score) %>% 
             filter(!is.na(score)) %>% 
             group_by(violation_code) %>% 
             summarise(min_score = min(score),
                       mean_score = mean(score),
                       max_score = max(score)) %>% 
             arrange(desc(mean_score)) %>%
             top_n(20) %>%
  ggplot() +
    geom_segment(aes(x = violation_code, y = min_score, xend = violation_code, yend = max_score), col =  ""white"") +
    geom_point(aes(x = violation_code, y = max_score, col = ""Max Score"")) +
    geom_text(aes(x = violation_code, y = max_score, label = max_score), hjust = -0.8, col = ""#ff4d4d"") +
    geom_point(aes(x = violation_code, y = min_score, col = ""Min Score"")) +
    geom_text(aes(x = violation_code, y = min_score, label = min_score), hjust = 1.3, col = ""#6699ff"") +
    scale_color_manual(name = ""Scores"", values = c(""#ff4d4d"", ""#6699ff"")) +
    ylim(-5, 200) +
    coord_flip() +
    labs(title = ""Top violation codes by score"",
         subtitle = ""10 more violations codes by average max score"",
         caption = ""NYC Department of Health"",
         x = ""Violation Codes"",
         y = ""Score (higher scores means more violations)"") +
    theme_economist() +
    theme(panel.grid.major = element_blank(),
          axis.line.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.text.x = element_blank(),
          axis.title.x = element_text(hjust = 0.4),
          legend.position = ""bottom"",
          plot.title = element_text(hjust = 0.4),
          plot.subtitle = element_text(hjust = 0.4),
          title = element_text(color = ""#808080""),
          text = element_text(color = ""#808080""))

ggsave(""Top violation codes by score.png"", scores)
    
```

","Other-37"
"862",1659,"https://github.com/mjhendrickson/Tidy-Tuesday","mjhendrickson","Tidy-Tuesday","Week 01 - US Tuition/us_tuition.R","# ===== Introduction =====
# Project: Tidy Tuesday - Week 1 - Average Tuition
# By: Matthew Hendrickson
# Twitter: @mjhendrickson
# GitHub: https://github.com/mjhendrickson/Tidy-Tuesday
# Original source link: https://onlinembapage.com/average-tuition-and-educational-attainment-in-the-united-states/

# ===== Install needed packages =====
install.packages(""tidyverse"")
install.packages(""readxl"")
install.packages(""scales"")
install.packages(""viridis"")
install.packages(""here"")
#install.packages(""RColorBrewer"")


# ===== Load needed packages =====
library(tidyverse)
library(readxl)
library(scales)
library(viridis)
library(here)
#library(RColorBrewer)


# ===== Load & review data =====
average_tuition <- read_excel(here(""Week 01 - US Tuition"", ""us_avg_tuition.xlsx""))
View(average_tuition)
glimpse(average_tuition)


# ===== Data prep =====
average_tuition <- average_tuition %>% # append new fields to df
  rename(state = State) %>%  # adhere to tidy naming convention
  mutate(state_abb = factor(state.abb))  # state abbreviation

avg_tuition <- average_tuition %>% # create new df
  gather(year, tuition, `2004-05`:`2015-16`) # reshape data wide to long

avg_tuit <- average_tuition %>% # append new fields to df
  mutate(tuition_5yr_chg = `2015-16` - `2010-11`) %>% # 5 year tuition change
  mutate(tuition_5yr_pct_chg = (`2015-16` - `2010-11`) / `2010-11` * 100) %>% # 5 year % change
  gather(year, tuition, `2004-05`:`2015-16`) %>% # reshape data wide to long
  select(state, state_abb, year, tuition, tuition_5yr_chg, tuition_5yr_pct_chg) %>% # select needed fields
  filter(year == ""2015-16"")  # keep only last year

# Create bins for % change
avg_tuit$tuition_5yr_pct_bin <- cut(avg_tuit$tuition_5yr_pct_chg,
                            breaks = c(-10, 0, 10, 20, 30, 40, 50, 60), 
                            right = FALSE,
                            include.highest = TRUE,
                            include.lowest = TRUE)

# Check bin counts
avg_tuit %>%
  group_by(tuition_5yr_pct_bin) %>%
  summarize(n = n())


# ===== Create plots =====
# Average Tuition - Box
avg_tuition %>% 
  ggplot(aes(x = fct_reorder(state, tuition), 
             y = tuition)) +
  geom_boxplot() +
  #coord_flip() +
  scale_y_continuous(labels = dollar) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  labs(x = ""State"", 
       y = ""Tuition Range"",
       title = ""College Tuition Ranges by State - Academic Years 2004-2005 - 2015-2016"",
       caption = ""\nDataSource: https://trends.collegeboard.org/ | Graphic: @mjhendrickson"")


# Average Tuition - Point
avg_tuition %>% 
  ggplot(aes(x = fct_reorder(state, tuition), 
             y = tuition, color = year)) +
  geom_point() +
  #coord_flip() +
  scale_y_continuous(labels = dollar) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  labs(x = ""State"", 
       y = ""Tuition"",
       color = ""Academic Year"", 
       title = ""College Tuition by State"",
       caption = ""\nDataSource: https://trends.collegeboard.org/ | Graphic: @mjhendrickson"")


# Average Tuition & 5 Year Change - Point
avg_tuit %>% 
  ggplot(aes(x = fct_reorder(state, tuition), 
             y = tuition, 
             color = tuition_5yr_pct_bin,
             shape = tuition_5yr_pct_bin)) +
  geom_point() +
  #coord_flip() +
  scale_y_continuous(labels = dollar) +
  #scale_color_viridis() +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.5)) +
  labs(x = ""State"", 
       y = ""Average Tuition"",
       size = ""5 yr change"", 
       color = """", 
       title = ""Average College Tuition by State - Academic Year 2015-2016"",
       caption = ""\nDataSource: https://trends.collegeboard.org/ | Graphic: @mjhendrickson"")

# Plot just the outliers
avg_tuit %>% 
  subset(tuition_5yr_pct_chg < 0 | tuition_5yr_pct_chg > 30) %>%
  ggplot(aes(x = fct_reorder(state, tuition), 
             y = tuition, 
             color = tuition_5yr_pct_bin,
             shape = tuition_5yr_pct_bin)) +
  geom_point() +
  #coord_flip() +
  scale_y_continuous(labels = dollar) +
  #scale_color_viridis() +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.5)) +
  labs(x = ""State"", 
       y = ""Average Tuition"",
       size = ""5 yr change"", 
       color = """", 
       title = ""Average College Tuition by State - Academic Year 2015-2016"",
       caption = ""\nDataSource: https://trends.collegeboard.org/ | Graphic: @mjhendrickson"")


# Average Tuition & 5 Year Change - Bar
# Jake Kaupp's updated graph.
avg_tuit %>% 
  ggplot(aes(x = fct_reorder(state, tuition), 
             y = tuition, 
             fill = tuition_5yr_pct_chg)) +
  geom_bar(stat = ""Identity"") +
  geom_text(aes(label = dollar(round(tuition)),
                angle = 0),
            hjust = 1.1, 
            color = ""white"",
            size = 3) +
  coord_flip() +
  scale_y_continuous(labels = dollar, 
                     expand = c(0, 0)) +
  scale_fill_viridis() +
  theme_minimal() +
  labs(x = NULL, 
       y = ""Average Tuition"",
       fill = ""5 yr % change"", 
       title = ""Average College Tuition by State - Academic Year 2015-2016"",
       caption = ""\nDataSource: https://trends.collegeboard.org/ | Graphic: @mjhendrickson"")

# Second take to appear closer to original, incorporating feedback
avg_tuit %>% 
  ggplot(aes(x = fct_reorder(state, tuition), 
             y = tuition, 
             fill = tuition_5yr_pct_chg)) +
  geom_bar(stat = ""Identity"") +
  geom_text(aes(label = dollar(round(tuition)),
                angle = 90),
            hjust = 1.1, 
            color = ""white"",
            size = 3) +
  #coord_flip() +
  scale_y_continuous(labels = dollar, 
                     expand = c(0, 0)) +
  scale_fill_viridis() +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.5)) +
  labs(x = NULL, 
       y = ""Average Tuition"",
       fill = ""5 yr % change"", 
       title = ""Average College Tuition by State - Academic Year 2015-2016"",
       caption = ""\nDataSource: https://trends.collegeboard.org/ | Graphic: @mjhendrickson"")
","Other-1"
"863",1660,"https://github.com/mjhendrickson/Tidy-Tuesday","mjhendrickson","Tidy-Tuesday","Week 02 - NFL Salaries/Examples.R","#===== First example =====

# Scratch pad and other examples - NFL
library(tidyverse)
library(hrbrthemes)

# download https://github.com/rfordatascience/tidytuesday/blob/master/data/tidy_tuesday_week2.xlsx
football <- read_xlsx(""data/tidy_tuesday_week2.xlsx"")

# get the top 16 paid players in each position for each year
to_plot <- football %>%
  mutate(Team = 1:nrow(.)) %>%
  gather(position, salary, -c(year, Team)) %>%
  group_by(position, year) %>%
  arrange(desc(salary)) %>%
  mutate(rank = 1:n()) %>%
  filter(rank <= 16) %>%
  ungroup %>%
  mutate(salary = salary/1e6) %>% # convert to millions
  mutate(position_other = 
           fct_other(position, # we only care about running backs and the highest paid, QBs
                     keep=c(""Quarterback"",
                            ""Running Back"")))

to_plot %>%
  filter(position_other == ""Other"") %>% # plot every other position at rear of image
  ggplot(data=., aes(x= year + (9-rank)/16,  # like a dodge
                     y=salary,
                     color = position_other,
                     group = interaction(year, position))) +
  geom_path(size=1, alpha=0.075, color=""black"") +
  theme_ipsum_rc() +
  ylim(c(0,40)) + # set limits to be pretty-ish
  scale_x_continuous(breaks = unique(to_plot$year)) +
  ylab(""Salary ($m)"") +
  xlab(""Year"") +
  geom_path(data = filter(to_plot,
                          position_other != ""Other""),
            size=1, alpha=0.75) +
  scale_color_manual(values=c(""purple"", ""red""),
                     name=""Position"") +
  theme(legend.position = ""bottom"", 
        panel.grid.minor.x = element_blank()) +
  ggtitle(""Top 16 annual salaries per position (2011-2018)"", 
          subtitle = ""Data: http://www.spotrac.com/rankings/\nGraphic: @samclifford"")



#===== Second example =====
# https://github.com/timschoof/TidyTuesday/blob/master/TT02/TT02.R

# Tidy Tuesday - 10 April 2018
# Average pay for top NFL players per position

# Data source: http://www.spotrac.com/rankings/
# Article with graphic: https://fivethirtyeight.com/features/running-backs-are-finally-getting-paid-what-theyre-worth/
# Tidy Tuesday: https://github.com/rfordatascience/tidytuesday

library(tidyverse)
library(here)
library(openxlsx)

# load data
df<-read.xlsx(here(""tidy_tuesday_week2.xlsx""),sheet=""nfl_salary"")

# convert data frame to tibble - because I want to learn about tibbles
t<-as_tibble(df)

# reorganize tibble from wide to long format
longT <- t %>%
  gather(position,salary,-year) 

# select 16 highest-paid players in each position (n = 10), per year (n = 8)
sub16 <- longT %>%
  group_by(year,position) %>%
  top_n(16) %>%
  ungroup()

# compute average salary for this subset
meanSub16 <- sub16 %>%
  mutate(salary = salary/10^6) %>% # salary in millions
  group_by(year,position) %>%
  mutate(mean_salary = mean(salary)) %>%
  ungroup

# for plotting
meanSub16plot <- meanSub16 %>%
  mutate(position = fct_recode(position, ""Running Back"" = ""Running.Back"",
                               ""Defensive Lineman"" = ""Defensive.Lineman"",
                               ""Offensive Lineman"" = ""Offensive.Lineman"",
                               ""Special Teamer"" = ""Special.Teamer"",
                               ""Tight End"" = ""Tight.End"",
                               ""Wide Receiver"" = ""Wide.Receiver"")) # rename / recode some factor levels

# plot
meanSub16plot %>%
  ggplot() +
  geom_point(aes(x = year, y = salary), colour = ""gray"") +
  geom_line(aes(x = year, y = mean_salary), size = 1.2) + 
  facet_wrap(~position, nrow = 2) +
  labs(x = """", y = ""Average salary \n (USD in millions)"", 
       title = ""Average salary of 16 highest-paid NFL players \n by position"") +
  theme(panel.background = element_rect(fill = ""#fcfcfc"" ),
        plot.background = element_rect(fill = ""#fcfcfc"" ),
        panel.grid.major = element_line(colour = ""#d3d3d3""),
        plot.title = element_text(hjust = 0.5))# center the title

# save
ggsave(""NFL.png"", width = 10, height = 5)



#===== Third example =====
# https://github.com/nikdudaev/tidy_tuesdays/blob/master/week_2/week_2.R

library(tidyverse)
library(readxl)
library(ggrepel)

# Reading data
df_1 <- read_xlsx(""../data/tidy_tuesday_week2.xlsx"")
# Tidying data. In particular columns will become categories and will be put into one variable - player_position
df_1 <- df_1 %>% gather(`Cornerback`:`Wide Receiver`, key = ""player_position"", value = ""salary"", `Cornerback`:`Wide Receiver`)
# Selecting only top 16 salaries
df_2 <- df_1 %>% group_by(year, player_position) %>% top_n(n = 16, wt = salary)
# Making player_position variable a factor
df_2$player_position <- 
  factor(df_2$player_position, levels = c(""Running Back"", ""Quarterback"", ""Offensive Lineman"", ""Tight End"",
                                          ""Wide Receiver"", ""Cornerback"", ""Defensive Lineman"", ""Linebacker"",
                                          ""Safety"", ""Special Teamer""))
# Dividing salary by million in order to get a more readable scale
df_2 <- df_2 %>% mutate(salary_mil = round(salary / 1000000))
# Data preparation for plot 2
# Calculating total spendings per year per position
position_year <- df_2 %>% group_by(player_position, year) %>% summarize(total_spent = sum(salary_mil))
# Calculating total spendings per year for all positions
year <- df_2 %>% group_by(year) %>% summarize(spent_per_year = sum(salary_mil))
# Joining with main data frame
df_2 <- df_2 %>% left_join(position_year, by = c(""player_position"", ""year""))
df_2 <- df_2 %>% left_join(year, by = c(""year""))
# Calculating percentage per year per position
df_2 <- df_2 %>% mutate(pct_total = (total_spent / spent_per_year) * 100)
# Creating categories of Offense and Defense
df_2 <- df_2 %>% mutate(off_def = ifelse(player_position %in% c(""Quarterback"", ""Wide Receiver"", 
                                                                ""Offensive Lineman"", ""Running Back"", 
                                                                ""Tight End""), ""OFFENSE"", ""DEFENSE""))
df_2$off_def <- factor(df_2$off_def, levels = c(""OFFENSE"", ""DEFENSE""))
# Plot number 1
ggplot(df_2) + 
  geom_point(aes(x = year, y = salary_mil), alpha = 1/4) +
  geom_smooth(aes(x = year, y = salary_mil), se = FALSE, color = ""#FF5722"") +
  ylim(0, 25) +
  facet_wrap(~ player_position, nrow = 2, ncol = 5) + 
  labs(title = ""The average pay for top running backs has stalled"",
       subtitle = ""Average cap value of 16 highest-paid players in each position"",
       y = ""Average cap value"") +
  theme(axis.title.x = element_blank(),
        strip.text = element_text(face = ""bold"", size = rel(0.7)),
        strip.background = element_rect(""white""),
        panel.background = element_rect(""white""),
        panel.grid.major = element_line(""grey"", size = 0.2),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5, face = ""bold""),
        plot.subtitle = element_text(hjust = 0.5))
#ggsave(""Plot1.png"", width = 25, height = 15, units = ""cm"")

plot_labels <- data.frame(
  player_position = c(""RB"", ""QB"", ""OL"", ""TE"", ""WR"", ""CB"", ""DL"", ""LB"", ""S"", ""ST""),
  x = c(rep(2018, 10)),
  y = c(5, 21, 10, 7.5, 12, 10, 13.5, 11, 7.5, 3)
)

# Plot 2
ggplot(df_2, aes(x = year, y = pct_total, color = player_position)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  geom_text(data = plot_labels, aes(x = x, y = y, label = player_position), check_overlap = TRUE) +
  facet_wrap(~ off_def) +
  labs(title = ""Teams are spending less on RB's"",
       subtitle = ""Percent of money spent on the top 16 players at each position"",
       y = ""Percent spent on each position"") +
  theme(axis.title.x = element_blank(),
        strip.text = element_text(face = ""bold"", size = rel(0.7)),
        strip.background = element_rect(""white""),
        panel.background = element_rect(""white""),
        panel.grid.major = element_line(""grey"", size = 0.2),
        axis.ticks = element_blank(),
        plot.title = element_text(hjust = 0.5, face = ""bold""),
        plot.subtitle = element_text(hjust = 0.5),
        legend.position = ""none"")
# scale_color_manual(values = c(""#000000"", ""#FF5722"", ""#FFEB3B"", ""#4CAF50"", ""#03A9F4"", ""#009688"",
#                            ""#673AB7"", ""#3F51B5"", ""#9C27B0"", ""#E91E63"")) 

#ggsave(""Plot2.png"", width = 25, height = 15, units = ""cm"")","Other-2"
"864",1661,"https://github.com/mjhendrickson/Tidy-Tuesday","mjhendrickson","Tidy-Tuesday","Week 02 - NFL Salaries/nfl_salaries.R","# ===== Introduction =====
# Project: Tidy Tuesday - Week 2 - NFL Salaries
# By: Matthew Hendrickson
# Twitter: @mjhendrickson
# GitHub: https://github.com/mjhendrickson/Tidy-Tuesday
# Original source links: http://www.spotrac.com/rankings/
  # https://fivethirtyeight.com/features/running-backs-are-finally-getting-paid-what-theyre-worth/

# ===== Install needed packages =====
install.packages(""tidyverse"")
install.packages(""readxl"")
install.packages(""scales"")
install.packages(""viridis"")
install.packages(""here"")
#install.packages(""RColorBrewer"")


# ===== Load needed packages =====
library(tidyverse)
library(readxl)
library(scales)
library(viridis)
library(here)
#library(RColorBrewer)


# ===== Load & review data =====
nfl_salaries <- read_excel(here(""Week 02 - NFL Salaries"", ""nfl_salaries.xlsx""))
View(nfl_salaries)
glimpse(nfl_salaries)


# ===== Data prep =====
nfl <- nfl_salaries %>% # create new df
  gather(position, salary, 'Cornerback':'Wide Receiver') # reshape data wide to long

nfl %>% 
  mutate(salary = salary/10^6) # salary in millions

# ===== Create plots =====
nfl %>% 
  subset(!is.na(salary)) %>% # remove missing salaries
  mutate(salary = salary/10^6) %>% # salary in millions# remove cases with no salary
ggplot() +
  geom_line(mapping = aes(x = year, y = salary)) +
  facet_wrap(~position, nrow = 2) +
  scale_x_discrete() +
  scale_y_continuous(labels = dollar) +
  #theme(axis.title.x = element_blank()) +
  labs(x = NULL, 
       y = ""Salary ($M)"",
       #fill = ""5 yr % change"", 
       title = ""NFL Salary by Position 2011-2018"",
       caption = ""\nDataSource: http://www.spotrac.com/rankings/ | Graphic: @mjhendrickson"")
","Other-2"
"865",1662,"https://github.com/mjhendrickson/Tidy-Tuesday","mjhendrickson","Tidy-Tuesday","Week 29 - Major & Income/major_income.R","# ===== Introduction =====
# Project: Tidy Tuesday - Week 29 - Major and Income
# By: Matthew Hendrickson
# Twitter: @mjhendrickson
# GitHub: https://github.com/mjhendrickson/Tidy-Tuesday
# Article: https://fivethirtyeight.com/features/the-economic-guide-to-picking-a-college-major/
# Data Source: https://github.com/fivethirtyeight/data/tree/master/college-majors
# TidyTuesday: https://github.com/rfordatascience/tidytuesday/tree/master/data/2018-10-16

# ===== Load needed packages =====
library(tidyverse)
library(readr)
library(scales)
library(viridis)
library(DataExplorer)

# ===== Load & review data =====
major_income <- read_csv(""major_income.csv"")
View(major_income)
glimpse(major_income)


# ===== Explore data with DataExplorer =====
create_report(major_income)


# ===== Data prep =====
major_income$Gender_lean <- 
  ifelse(major_income$ShareWomen >= .5,
                        ""More Female"", 
                        ""More Male"")

major_income$Employed_size <- 
  ifelse(major_income$Employed > 250000, ""> 250,000"",
  ifelse(major_income$Employed > 200000, ""200,000 - 250,000"",
  ifelse(major_income$Employed > 150000, ""150,000 - 200,000"",
  ifelse(major_income$Employed > 100000, ""100,000 - 150,000"",
  ifelse(major_income$Employed >  50000, ""50,000 - 150,000"",
         ""< 50,000""
         )))))


# ===== Create plots =====
major_income %>% 
  filter(Employed >= 50000) %>% 
  ggplot(aes(x = fct_reorder(Major, Employed), 
             y = Employed, 
             fill = ShareWomen)) +
  geom_bar(stat = ""Identity"") +
  geom_text(aes(label = dollar(round(Median))),
                #angle = 90),
            hjust = 1.1, 
            color = ""white"",
            size = 3) +
  coord_flip() +
  scale_fill_viridis() +
  scale_y_continuous(labels = comma) +
  theme(axis.text.x = element_text(#angle = 90, 
                                   vjust = 0.5)) +
  labs(x = ""Major"", 
       y = ""Number Employed"",
       fill = ""% Female"", 
       title = ""Share of Employed by Major"",
       caption = ""\nDataSource: https://github.com/fivethirtyeight/data/tree/master/college-majors   |   Graphic: @mjhendrickson"")


major_income %>% 
  filter(Employed >= 50000) %>% 
  ggplot(aes(x = fct_reorder(Major, Employed), 
             y = Employed, 
             fill = Unemployment_rate)) +
  geom_bar(stat = ""Identity"") +
  geom_text(aes(label = percent(round(Unemployment_rate,4))),
            #angle = 90),
            hjust = 1.1, 
            color = ""white"",
            size = 3) +
  facet_grid(. ~ Gender_lean) +
  coord_flip() +
  scale_fill_viridis() +
  scale_y_continuous(labels = comma) +
  theme(axis.text.x = element_text(#angle = 90, 
    vjust = 0.5)) +
  labs(x = ""Major"", 
       y = ""Number Employed"",
       fill = ""Unemployment Rate"", 
       title = ""Share of Employed by Major"",
       caption = ""\nDataSource: https://github.com/fivethirtyeight/data/tree/master/college-majors   |   Graphic: @mjhendrickson"")
","Other-29"
"866",1664,"https://github.com/HaydenMacDonald/hmd-tidy-tuesday/blob/master/week28/week28.Rmd","HaydenMacDonald","hmd-tidy-tuesday","week28/week28.Rmd","---
title: ""Voter Turnout in the United States (1980 - 2014)""
author: ""Hayden MacDonald""
date: ""2018-10-10""
output: github_document
---

```{r setup, include=FALSE}
library(formatR)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)
```

```{r setup}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)

library(rvest)
library(xml2)
library(httr)
library(purrr)
```

```{r warning = FALSE}
vdata <- read_csv(""voter_turnout.csv"") 

wdata <- read_html(""https://en.wikipedia.org/wiki/List_of_U.S._states_by_historical_population"")

popstats <- wdata %>%
    html_nodes(""table"") %>%
    .[[5]] %>%
    html_table()
```

```{r}
names(popstats)[1] <- ""year""

#Convert popstats to long format, filter for years between 1980 & 2014
popstats2 <- popstats %>%
    gather(state, population, -year) %>%
    filter(year >= 1980 & year <= 2014)

#Remove comma separators and convert population to numeric    
popstats2$population <- str_replace_all(popstats2$population, "","", """") %>%
  as.numeric()

#Convert state abbreviations to full state names
popstats2$state <- abbr2state(popstats2$state)
```

```{r}
#Join voting data and population data from wikipedia by year and state
vpdata <- left_join(vdata, popstats2, by = c(""year"", ""state""))
```

```{r}
Pacific <- c(""California"", ""Oregon"", ""Washington"", ""Hawaii"", ""Alaska"")
Mountain <- c(""Nevada"", ""Idaho"", ""Montana"", ""Wyoming"", ""Utah"", ""Colorado"", ""New Mexico"", ""Arizona"")
West_North_Central <- c(""North Dakota"", ""South Dakota"", ""Minnesota"", ""Nebraska"", ""Kansas"", ""Iowa"", ""Missouri"")
West_South_Central <- c(""Oklahoma"", ""Arkansas"", ""Louisiana"", ""Texas"")
East_North_Central <- c(""Wisconsin"", ""Illinois"", ""Indiana"", ""Michigan"", ""Ohio"")
East_South_Central <- c(""Kentucky"", ""Tennessee"", ""Mississippi"", ""Alabama"") 
South_Atlantic <- c(""West Virginia"", ""Virginia"", ""District of Columbia"", ""Maryland"", ""Delaware"", ""North Carolina"", 
                    ""South Carolina"", ""Georgia"", ""Florida"")
Middle_Atlantic <- c(""Pennsylvania"", ""New York"", ""New Jersey"")
New_England <- c(""Connecticut"", ""Rhode Island"", ""Massachusetts"", ""New Hampshire"", ""Vermont"", ""Maine"")

region_list <- list(Pacific = Pacific, 
                    Mountain = Mountain, 
                    West_North_Central = West_North_Central, 
                    West_South_Central = West_South_Central, 
                    East_North_Central = East_North_Central, 
                    East_South_Central = East_South_Central,  
                    South_Atlantic = South_Atlantic, 
                    Middle_Atlantic = Middle_Atlantic, 
                    New_England = New_England)

#Create a tibble to map region onto states
region_df <- region_list %>%
     map_df(~ data_frame(state = .x), .id = ""region"")

region_df
```


```{r}
vpdata <- vpdata %>%
    filter(alphanumeric_state_code != 0) %>%
    group_by(year, state) %>%
    summarize(elig_votes_p = eligible_voters / population, 
              delta_votes = votes / eligible_voters)
    
#Plot turnout and voting proportion of population by state
vpdata %>%
  ggplot(aes(x = year)) +
  geom_line(aes(y = elig_votes_p)) +
  geom_line(aes(y = delta_votes, color = ""red"")) +
  facet_wrap(~state)
```

```{r}
vpdata2 <- left_join(vpdata, region_df, by = ""state"")

vpdata2$region <- str_replace_all(vpdata2$region, pattern = ""_"", replacement = "" "")

vpdata2 <- vpdata2 %>%
  group_by(year, region) %>%
  summarize(reg_elig_votes = median(elig_votes_p, na.rm = TRUE), 
            reg_delta_votes = median(delta_votes, na.rm = TRUE))
```

```{r}

#Originally, I was hoping to highlight standout years in terms of the maximum and minimum differences between turnout and eligible voters by region
#Although, I wasn't able to get it working
big_diff <- vpdata2 %>%
    group_by(region) %>%
    mutate(max_diff = max(reg_elig_votes - reg_delta_votes), 
           min_diff = min(reg_elig_votes - reg_delta_votes)) %>%
    filter((max_diff / reg_elig_votes) >= 0.6 | (min_diff / reg_elig_votes) <= 0.05)

highlight <- vpdata2 %>%
  group_by(region, year) %>%
  filter(region %in% big_diff$region, year %in% big_diff$year)
```

```{r}
vpdata2 %>%
    ggplot(aes(x = year)) +
    geom_point(aes(y = reg_elig_votes), color = ""#003399"") +
    geom_point(aes(y = reg_delta_votes), color = ""#cc0033"") +
    geom_segment(aes(xend = year, y = reg_delta_votes, yend = reg_elig_votes), color = ""#aaaabb"") +
    scale_y_continuous(limits = c(0.0, 1.0)) +
    facet_wrap(~region) +
    theme_classic() + 
    theme(panel.grid.major = element_line(colour = ""gray92""), 
          panel.grid.minor = element_line(colour = ""gray92"")) +
    labs(x = ""Year"", 
         y = """", title = ""Voter Turnout in the Major US Regions (1980 - 2014)"", 
         subtitle = ""Proportion of region population that is eligible to vote (blue) \nProportion of eligible voter turnout (red) \nOver year, faceted by US region"", 
         caption = ""graphic: @HYDNMCDNLD | source: data.world"")
```












","Other-28"
"867",1665,"https://github.com/HaydenMacDonald/hmd-tidy-tuesday/blob/master/week34/friendsgiving.Rmd","HaydenMacDonald","hmd-tidy-tuesday","week34/friendsgiving.Rmd","---
title: ""Tidy Tuesday Week 34 - Thanksgiving Meals""
author: ""Hayden MacDonald""
date: ""2018-11-20""
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(formatR)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)
```

```{r setup}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
```

```{r import}
food <- read_csv(""thanksgiving_meals.csv"")
```

```{r wrangle}
food <- food %>% 
  select(1:2, 52:53, 56:65)
```

```{r}
food %>%
    group_by(age, community_type, gender) %>%
    mutate(prop_friendsgiving = sum(friendsgiving == ""Yes"", na.rm = TRUE) / n()) %>%
    mutate(prop_no_friends = sum(friendsgiving == ""No"", na.rm = TRUE) / n()) %>%
    ggplot() +
    geom_boxplot(aes(x = age, y = prop_friendsgiving))
```


```{r proportion of participants taking part in friendsgiving}
food %>%
    group_by(age, community_type, gender) %>%
    summarize(prop_friendsgiving = sum(friendsgiving == ""Yes"", na.rm = TRUE) / n()) %>%
    ggplot() +
    geom_boxplot(aes(x = age, y = prop_friendsgiving)) +
    facet_wrap(~ community_type)
```

```{r compute percentage attendance / absence across age / community types}
food2 <- food %>%
    group_by(friendsgiving, age, community_type) %>%
    summarize(total = n()) %>%
    na.omit() %>%
    spread(key = age, value = total)

food2[, 3:6] <- round((food2[, 3:6]/rowSums(food2[, 3:6])), digits = 3) * 100

food2 %<>%
    gather(key = age, value = percent_friendsgiving, -friendsgiving, -community_type) %>%
    mutate(age = factor(age, levels = c(""18 - 29"", ""30 - 44"", ""45 - 59"", ""60+""))) %>%
    group_by(age, community_type) %>%
    mutate(percent_diff = sum(percent_friendsgiving, na.rm = TRUE)) %>%
    mutate(percent_friendsgiving = case_when(friendsgiving == ""No"" ~ -percent_friendsgiving, 
                                             friendsgiving == ""Yes"" ~ percent_friendsgiving))
```

```{r mirror lollipop / cleveland dot plot}
friends <- food2 %>%
    ggplot(aes(x = age)) +
    geom_point(aes(y = percent_friendsgiving, 
                   color = friendsgiving)) +
    geom_segment(aes(xend = age, 
                     y = percent_friendsgiving, 
                     yend = 0, 
                     color = friendsgiving)) +
    geom_text(aes(y = percent_friendsgiving, 
                  label = paste0(abs(percent_friendsgiving), ""%""), 
                  color = friendsgiving), 
              vjust = -1) +
    geom_line(aes(y = 0, 
                  group = community_type), 
              linetype = 2) +
    scale_y_continuous(limits = c(-50, 50), 
                       labels = abs(seq(-50, 50, 25))) +
    facet_wrap(~ community_type) +
    coord_flip() +
    theme_classic() +
    theme(panel.grid.major = element_line(size = 0.05, color = ""gray92""), 
          panel.grid.minor = element_line(size = 0.05, color = ""gray92"")) +
    labs(title = ""Percent absence or attendance at Friendsgivings across age groups and community types"",
         subtitle = ""Absence in red, attendance in blue"",
         x = ""Age Group"", 
         y = ""Percent absence & attendance"") +
    scale_color_manual(values = c(""#cc0033"", ""#4292c6""), guide = FALSE)
```

```{r}
library(Cairo)

CairoPNG(filename = ""week34.png"", units = ""in"", width = 9, height = 9, res = 300)

print(friends)

dev.off()
```

![](week34.png)




















","Other-34"
"868",1666,"https://github.com/HaydenMacDonald/hmd-tidy-tuesday/blob/master/week35/baltimore_bridges.Rmd","HaydenMacDonald","hmd-tidy-tuesday","week35/baltimore_bridges.Rmd","---
title: ""[Title]""
author: ""Hayden MacDonald""
date: ""[Current Year]""
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
library(formatR)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)
```

```{r packages, message = FALSE, warnings = FALSE}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
```

```{r import}
bridges <- read_csv(""baltimore_bridges.csv"")
```

```{r wrangle}
bridges$bridge_condition <- factor(bridges$bridge_condition, levels = c(""Poor"", ""Fair"", ""Good""))

bridges %<>%
    group_by(responsibility, bridge_condition) %>%
    summarize(count = n())

bridge_legend <- bridges %>%
  filter(responsibility == ""State Highway Agency"")
```

```{r viz}
library(Cairo)

CairoPNG(filename = ""week35-baltimore-bridges.png"", units = ""in"", width = 9, height = 9, res = 300)

bridges %>%  
    ggplot(aes(x = responsibility, 
               y = count, 
               fill = bridge_condition)) +
    geom_col(position = ""dodge"") +
    geom_text(aes(label = count, 
                  color = bridge_condition), 
              position = position_dodge(width = 0.9), 
              hjust = -0.5, 
              vjust = 0.5) + 
    geom_text(data = bridge_legend, aes(label = bridge_condition, 
                  color = bridge_condition), 
              position = position_dodge(width = 0.9), 
              hjust = c(-1.15, -1.65, -1), 
              vjust = 0.5) +
    scale_y_continuous(limits = c(0, 800)) +
    scale_fill_manual(values = c(""#a50026"", ""#FFB14E"", ""#006837"")) +
    scale_color_manual(values = c(""#a50026"", ""#FFB14E"", ""#006837"")) +
    coord_flip() +
    theme_bw() + 
    labs(title = ""Number of bridges in good, fair and poor condition"",
         subtitle = ""across organizations responsible for their maintenance in Baltimore and Maryland"",
         x = ""Bridge Owner"",
         y = ""Count"") +
    guides(fill = FALSE, color = FALSE)

dev.off()
```

![](week35-baltimore-bridges.png)




















","Other-35"
"869",1667,"https://github.com/HaydenMacDonald/hmd-tidy-tuesday/blob/master/week22/week22nfl.Rmd","HaydenMacDonald","hmd-tidy-tuesday","week22/week22nfl.Rmd","---
title: ""Tidy Tuesday - Week 22 - NFL 2000-2017 Player Data""
author: ""Hayden MacDonald""
date: ""2018-08-28""
output: 
  github_document:
    html_preview: false
---

```{r setup, message = FALSE, warning = FALSE}
library(formatR)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)

library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
```

----

## Import Data
```{r}
fb <- read.csv(""nfl_2010-2017.csv"", header = TRUE)
```

----

## Wrangle

```{r}
fb2 <- fb %>%
    select(game_year, rush_fumbles, rec_fumbles, pass_fumbles) %>%
    group_by(game_year) %>%
    mutate_if(is.numeric, funs(ifelse(is.na(.), 0, .))) %>%
    summarize(pct_rush_fum = sum(rush_fumbles, na.rm = TRUE) / n() * 100, 
              pct_rec_fum = sum(rec_fumbles, na.rm = TRUE) / n() * 100, 
              pct_pass_fum = sum(pass_fumbles, na.rm = TRUE) / n() * 100)

# wide data
fb2

# convert data to long format
fb2l <- fb2 %>%
  gather(fum_type, percent_fum, -game_year)

fb2l
```

----

## Visualize

```{r}
fbvis <- fb2l %>%
    ggplot(aes(x = game_year)) +
    geom_line(aes(y = percent_fum, group = fum_type, color = fum_type)) +
    scale_color_manual(name = ""Fumble Type"", labels = c(""Pass"", ""Receive"", ""Rush""), values = c(""#003399"", ""#aaaabb"", ""#cc0033"")) +
    labs(x = ""Year"", y = ""Percent Fumbled"", title = ""Percentage of fumbles per year by fumble type"", subtitle = ""Fumbles by passing, receiving or rushing"") + 
    theme(axis.line = element_line(size = 0.5, linetype = ""solid""), 
          panel.grid.major = element_line(linetype = ""dashed""), 
          panel.grid.minor = element_line(linetype = ""dashed""), 
          panel.background = element_rect(linetype = ""dashed""),
          legend.position = c(0.4, 0.9),
          legend.direction = ""horizontal"",
          legend.background = element_rect(""gray92""), 
          axis.title = element_text(size = 12),
          axis.text = element_text(size = 12), 
          legend.text = element_text(size = 12), 
          title = element_text(size = 16))
```

----

## Add Logo and Export Visualization

```{r}
library(grid)
library(png)
library(Cairo)

#import logo
logo <- readPNG('nfllogo.png')

#insert logo
fbvis2 <- fbvis + annotation_raster(logo, ymin = 5, ymax = 7, xmin = 2012.5, xmax = 2017.5)


#render final image
png(filename=""week22nfl.png"",
    type=""cairo"",
    units=""in"", 
    width=16,      
    height=12, 
    pointsize=12, 
    res=300)
print(fbvis2)
dev.off()
```

![](week22nfl.png)

----

## Session Info

```{r, echo = FALSE} 
sessioninfo::session_info()
```














","Other-22"
"870",1668,"https://github.com/HaydenMacDonald/hmd-tidy-tuesday/blob/master/week29/week29.Rmd","HaydenMacDonald","hmd-tidy-tuesday","week29/week29.Rmd","---
title: ""Median income distributions by university major category""
author: ""Hayden MacDonald""
date: ""2018-10-16""
output: github_document
---

```{r setup, include=FALSE}
library(formatR)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)

```

```{r setup, message = FALSE}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(Cairo)
```

----

##Import

```{r import, message = FALSE}
grad <- read_csv(""recent-grads.csv"")
```

----

##Wrangle

```{r wrangle}
grad$Major_category <- factor(grad$Major_category)

grad_wom <- grad %>%
     group_by(Major_category) %>%
     summarize(sharewomen_mean = mean(ShareWomen), sharewomen_sd = sd(ShareWomen))

grad_wom$sharewomen_mean <- round(grad_wom$sharewomen_mean, digits = 2)
grad_wom$sharewomen_sd <- round(grad_wom$sharewomen_sd, digits = 2)
```

----

##Visualize

```{r visualize}
#Boxplot of Median income by major category
grad %>%
    mutate(Major_category = fct_reorder(Major_category, ShareWomen)) %>%
    ggplot(aes(x = Major_category, y = Median, fill = Major_category)) +
    geom_boxplot() +
    geom_jitter() +
    coord_flip() +
    guides(fill = FALSE)
```

##Visualize 2

```{r visualize 2}
#Ridge plot with jittered points representing the distributions of median incomes by major categories
#
grad_ridges <- grad %>%
    group_by(Major_category) %>%
    mutate(majority_women = mean(ShareWomen) > 0.50) %>%
    ggplot(aes(x = Median, y = Major_category, fill = majority_women)) +
    geom_density_ridges(quantile_lines = TRUE, quantiles = c(0.25, 0.5, 0.75),
                        jittered_points = TRUE, position = ""raincloud"", alpha = 0.6, scale = 1.0) +
    scale_fill_manual(values = c(""#BFD3E6"", ""#4d004b"")) +
    guides(fill = guide_legend(""Graduate Majority Women"")) +
    labs(x = ""Median Income"",
         y = ""Major Category"",
         title = ""Distributions of graduate median income by major category"", 
         subtitle = ""Each point represents the median income for a unique job title"") +
    theme_classic()
```

Export grad_ridges
```{r export, message = FALSE}
CairoPNG(filename = ""week29.png"", units = ""in"", width = 12, height = 12, pointsize = 12, res = 300)

print(grad_ridges)

dev.off()
```

![center](week29.png)


##Visualize 3

```{r}
#Scatterplot of mean proportion of women graduates across major categories (error bars represent standard deviation)
grad_wom %>%
    group_by(Major_category) %>%
    ggplot(aes(x = reorder(Major_category, sharewomen_mean), y = sharewomen_mean, color = Major_category)) +
    geom_point() + 
    geom_errorbar(aes(ymax = sharewomen_mean + sharewomen_sd, ymin = sharewomen_mean - sharewomen_sd)) +
    coord_flip() +
    guides(color = FALSE)
```


","Other-29"
"871",1669,"https://github.com/HaydenMacDonald/hmd-tidy-tuesday/tree/master/week16","HaydenMacDonald","hmd-tidy-tuesday","week16/tidytuesday_week16_exercise.Rmd","---
title: ""[Title]""
author: ""Hayden MacDonald""
date: ""[Current Year]""
output: github_document
---

```{r setup, echo=FALSE}
library(formatR)
library(knitr)
opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)

library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
library(stringr)
```


## Data import
```{r import}
xdata <- read_xlsx(""week16_exercise.xlsx"", sheet = 1, col_names = TRUE, range = cell_cols(""B:I""))
```

## Data cleaning
```{r cleaning}
#wide to long format
xdata2 <- gather(xdata, group, percent, -state)

#convert percent to numeric, group to factor
xdata2$percent <- as.numeric(xdata2$percent)
xdata2$group <- as.factor(xdata2$group)

glimpse(xdata2)
summary(xdata2)

xdata2 <- xdata2 %>%
  filter(!is.na(percent))
```


## Create a region df to join to our current data
```{r region}
Pacific <- c(""California"", ""Oregon"", ""Washington"", ""Hawaii"", ""Alaska"")
Mountain <- c(""Nevada"", ""Idaho"", ""Montana"", ""Wyoming"", ""Utah"", ""Colorado"", ""New Mexico"", ""Arizona"")
West_North_Central <- c(""North Dakota"", ""South Dakota"", ""Minnesota"", ""Nebraska"", ""Kansas"", ""Iowa"", ""Missouri"")
West_South_Central <- c(""Oklahoma"", ""Arkansas"", ""Louisiana"", ""Texas"")
East_North_Central <- c(""Wisconsin"", ""Illinois"", ""Indiana"", ""Michigan"", ""Ohio"")
East_South_Central <- c(""Kentucky"", ""Tennessee"", ""Mississippi"", ""Alabama"") 
South_Atlantic <- c(""West Virginia"", ""Virginia"", ""District of Columbia"", ""Maryland"", ""Delaware"", ""North Carolina"", 
                    ""South Carolina"", ""Georgia"", ""Florida"")
Middle_Atlantic <- c(""Pennsylvania"", ""New York"", ""New Jersey"")
New_England <- c(""Conneticut"", ""Rhode Island"", ""Massachusetts"", ""New Hampshire"", ""Vermont"", ""Maine"")

region_list <- list(Pacific = Pacific, 
                    Mountain = Mountain, 
                    West_North_Central = West_North_Central, 
                    West_South_Central = West_South_Central, 
                    East_North_Central = East_North_Central, 
                    East_South_Central = East_South_Central,  
                    South_Atlantic = South_Atlantic, 
                    Middle_Atlantic = Middle_Atlantic, 
                    New_England = New_England)

#Create a tibble to map region onto states
region_df <- region_list %>%
     map_df(~ data_frame(state = .x), .id = ""region"")

region_df
```

## Map region onto states
```{r}
xdata2 <- xdata2 %>%
  inner_join(region_df, by = ""state"")

xdata2$region <- str_replace_all(xdata2$region, patter = ""_"", replacement = "" "")

glimpse(xdata2)
```


## Calculate differentials
```{r data wrangling}
xdatam <- xdata2 %>%
    spread(group, percent) %>%
    group_by(region) %>%
    mutate(All = men - women, 
           Working = men_working - women_working, 
           Nonworking = men_nonworking - women_nonworking)
    
m <- xdatam %>%
  gather(group, percent, -state, -region) %>%
  filter(group %in% c(""All"", ""Working"", ""Nonworking"")) %>%
  group_by(region, group) %>%
  summarize(avg_region = mean(percent, na.rm = TRUE))
```


## Visualize
```{r viz}
library(viridis)
palette <- viridisLite::viridis(3)
palette

# Plot
xplot <- ggplot(data = m, aes(x = as.factor(group), y = avg_region, fill = group)) + 
    geom_col(position = ""dodge"") +
    facet_wrap(~ region) + 
    theme_classic() +
    scale_fill_manual(values = palette) +
    labs(title = ""Percent difference between men and women who met exercise guidelines across employment status"", 
         subtitle = ""Faceted by US Region"", 
         caption = ""data: CDC - National Health Statistics Reports | graphic: @HYDNMCDNLD"", 
         x = ""Employment Status"", y = ""Percent Difference"") + 
    theme(panel.background = element_rect(fill = ""gray92""), 
          legend.title = element_blank(), 
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank())
```

![center](xplot.png)
















","Other-16"
"872",1670,"https://github.com/HaydenMacDonald/hmd-tidy-tuesday/blob/master/week15/tidy-tuesday-week15.Rmd","HaydenMacDonald","hmd-tidy-tuesday","week15/tidy-tuesday-week15.Rmd","---
title: ""Craft Beer Names Analysis by Style""
author: ""Hayden MacDonald""
date: ""2018-07-11""
output: github_document
---
## Project Setup
```{r setup, echo=FALSE}
library(formatR)
library(knitr)
opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)

library(readxl)
library(dplyr)
library(tidyr)
library(tidytext)
library(stringr)
library(ggplot2)
```

## Import the data

```{r import}
beer <- read_xlsx(""week15_beers.xlsx"")
glimpse(beer)
summary(beer)
```

## Tidy the data

```{r tidy}
beer$style <- tolower(beer$style)

tidybeer <- beer %>%
  unnest_tokens(word, name) %>%
  anti_join(stop_words) %>%
  count(word, style) %>%
  arrange(desc(n))

head(tidybeer, n = 25)
```

## TF-IDF Analysis

```{r td_idf}
#Generate tf-idf scores for name words not matching style
tidybeer_tfidf <- tidybeer %>%
    filter(!word %in% style) %>%
    group_by(word) %>%
    mutate(word_total = sum(n)) %>%
    bind_tf_idf(word, style, n) %>%
    arrange(desc(tf_idf), desc(word_total))

head(tidybeer_tfidf, n = 25)

#top 16 beer styles by grand total of all words used to describe a style
top16 <- aggregate(word_total ~ style, tidybeer_tfidf, sum) %>%
  top_n(16, word_total)

#Within those top 16 beers, find their respective top 10 words by tf-idf scores
tidybeer_tfidf_top10 <- tidybeer_tfidf %>%
    inner_join(top16, by = ""style"") %>%
    group_by(style) %>%
    top_n(10, wt = rank(tf_idf, ties.method = ""first"")) %>%
    arrange(style, desc(tf_idf)) %>%
    ungroup()

#rename columns for clarity
tidybeer_tfidf_top10 <- tidybeer_tfidf_top10 %>%
    rename(word_total_style = word_total.x) %>%
    rename(word_total_all_beers = word_total.y)

#Create ranks for each word within each style
tidybeer_tfidf_top10 <- tidybeer_tfidf_top10 %>%
    mutate(rank = rep(10:1, 16))

head(tidybeer_tfidf_top10, n = 25)
```

## Visualize

```{r}
beer_plot <- ggplot(tidybeer_tfidf_top10, aes(x = as.factor(rank), y = tf_idf)) + 
  geom_bar(stat = ""identity"", fill = ""goldenrod2"", alpha = 0.75) + 
  coord_flip() + 
  facet_wrap(~ style, ncol = 4) +
  geom_text(aes(label = word, x = rank), y = 0, hjust = 0) + 
  labs(title = ""Top TF-IDF descriptors used to name beers in selected styles"", x = """", caption = ""data: CircleUp | graphic: @HYDNMCDNLD"") +
  theme_classic() +
  theme(axis.text.y = element_blank(), axis.ticks = element_blank())
  
beer_plot
```

![center](/week15/beer-plot.png)






















","Other-15"
"873",1672,"http://github.com/scjones5/TidyTuesday/tree/master/Sep11","scjones5","TidyTuesday","Sep11/Sep11_Rcode.R","library(dplyr)
library(googleVis)

pets <- read.csv(""/Users/sjones/Google Drive/tidyTuesday/Sep11/cats_vs_dogs.csv"", header = TRUE)

all_animals <- pets %>%
  select(state, dog_population, cat_population) %>%
  mutate(diff_total = dog_population - cat_population)

total_chart <- gvisGeoChart(all_animals, ""state"", ""diff_total"",
                                options=list(region=""US"", 
                                             displayMode=""regions"", 
                                             resolution=""provinces"",
                                             colorAxis=""{colors:[\'green', \'white', \'purple']}"",
                                             width=600, height=400))
print(total_chart, file=""/Users/sjones/Google Drive/tidyTuesday/Sep11/total_animal_difference.html"")

by_household <- pets %>%
  select(state, avg_dogs_per_household, avg_cats_per_household) %>%
  mutate(diff_hh = avg_dogs_per_household - avg_cats_per_household)

hh_chart <- gvisGeoChart(by_household, ""state"", ""diff_hh"",
                            options=list(region=""US"", 
                                         displayMode=""regions"", 
                                         resolution=""provinces"",
                                         colorAxis=""{colors:[\'green', \'white', \'purple']}"",
                                         width=600, height=400))

print(hh_chart, file=""/Users/sjones/Google Drive/tidyTuesday/Sep11/avg_by_household_difference.html"")
","Other-1"
"874",1673,"https://github.com/scjones5/TidyTuesday/tree/master/Sep18","scjones5","TidyTuesday","Sep18/Sep18_Rcode.R","library(dplyr)
library(ggplot2)
library(broom)

flights <- read.csv(""/Users/sjones/Google Drive/tidyTuesday/Sep18/us-airports.csv"", header = TRUE)

levels(flights$airport_name)[levels(flights$airport_name)==""Dallas/Fort Worth International""] <- ""Dallas-Fort Worth International""
df_names <- levels(flights$hub_type)
future_years <- c(2018,2019,2020,2021,2022)
for(c in 1:length(df_names)) {
  hub <- flights %>% filter(hub_type == df_names[c]) 
  # Find the top four by passenger in each hub type
  hi_hub <- hub %>% 
    select(year, passengers, airport_name) %>%
    group_by(year) %>%
    arrange(desc(passengers)) %>%
    top_n(4, passengers) 
  ports <- hi_hub$airport_name[hi_hub$year == 2017]
  ports <- droplevels(ports)
  hub2 <- data.frame(airport_name = rep(ports, times = 5), year = c(2018,2019,2020,2021,2022),
                     passengers = 0)
  hub1 <- hub %>%
    filter(as.character(airport_name) %in% ports) %>%
    group_by(airport_name) %>%
    nest() %>%
    inner_join(hub2 %>% select(-passengers) %>% group_by(airport_name) %>% nest(),
               by = c(""airport_name"")) %>%
    mutate(model = data.x %>% map(~lm(passengers ~ year, data=.)),
           value = map2(model, data.y, predict)) 
  
  assign(paste0(df_names[c], ""_mod""), hub1)
  hubOut <- hub1 %>%
    select(-data.x, -model) %>%
    unnest() %>%
    bind_rows(hub)
  
  assign(df_names[c], hubOut)
}

Lslope <- c()
Lints <- c()
for(p in Large_mod$airport_name) {
  Lints <- c(Lints, Large_mod$model[Large_mod$airport_name == p][[1]]$coefficients[1])
  Lslope <- c(Lslope, Large_mod$model[Large_mod$airport_name == p][[1]]$coefficients[2])
}

Large_mod <- Large_mod %>%
  mutate(slope = Lslope) %>%
  mutate(intercept = Lints)

new_Large <- merge(Large, Large_mod, by = ""airport_name"")
new_Large %>% 
  filter(airport_name %in% Large_mod$airport_name) %>%
  select(airport_name, year, value.x, passengers, slope, intercept) %>%
  ggplot(aes(year)) +
    geom_point(aes(y = value.x)) +
    geom_point(aes(y = passengers)) +
    geom_abline(aes(intercept = intercept, slope = slope)) + 
    facet_wrap(~ airport_name) + 
    scale_x_continuous(breaks = unique(new_Large$year)) + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
    ylab(""Passengers"") + 
    labs(title=""Large Airports"")
ggsave(filename = ""/Users/sjones/Google Drive/tidyTuesday/Sep18/large_flights.png"")

Mslope <- c()
Mints <- c()
for(p in Medium_mod$airport_name) {
  Mints <- c(Mints, Medium_mod$model[Medium_mod$airport_name == p][[1]]$coefficients[1])
  Mslope <- c(Mslope, Medium_mod$model[Medium_mod$airport_name == p][[1]]$coefficients[2])
}

Medium_mod <- Medium_mod %>%
  mutate(slope = Mslope) %>%
  mutate(intercept = Mints)

new_Medium <- merge(Medium, Medium_mod, by = ""airport_name"")
new_Medium %>% 
  filter(airport_name %in% Medium_mod$airport_name) %>%
  select(airport_name, year, value.x, passengers, slope, intercept) %>%
  ggplot(aes(year)) +
  geom_point(aes(y = value.x)) +
  geom_point(aes(y = passengers)) +
  geom_abline(aes(intercept = intercept, slope = slope)) + 
  facet_wrap(~ airport_name) + 
  scale_x_continuous(breaks = unique(new_Medium$year)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  ylab(""Passengers"") + 
  labs(title=""Medium Airports"")
ggsave(filename = ""/Users/sjones/Google Drive/tidyTuesday/Sep18/med_flights.png"")


Sslope <- c()
Sints <- c()
for(p in Small_mod$airport_name) {
  Sints <- c(Sints, Small_mod$model[Small_mod$airport_name == p][[1]]$coefficients[1])
  Sslope <- c(Sslope, Small_mod$model[Small_mod$airport_name == p][[1]]$coefficients[2])
}

Small_mod <- Small_mod %>%
  mutate(slope = Sslope) %>%
  mutate(intercept = Sints)

new_Small <- merge(Small, Small_mod, by = ""airport_name"")
new_Small %>% 
  filter(airport_name %in% Small_mod$airport_name) %>%
  select(airport_name, year, value.x, passengers, slope, intercept) %>%
  ggplot(aes(year)) +
  geom_point(aes(y = value.x)) +
  geom_point(aes(y = passengers)) +
  geom_abline(aes(intercept = intercept, slope = slope)) + 
  facet_wrap(~ airport_name) + 
  scale_x_continuous(breaks = unique(new_Small$year)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  ylab(""Passengers"") + 
  labs(title=""Small Airports"")
ggsave(filename = ""/Users/sjones/Google Drive/tidyTuesday/Sep18/small_flights.png"")
","Other-2"
"875",1683,"https://github.com/ChuliangXiao/tidytuesday/tree/master/Week10","ChuliangXiao","tidytuesday","Week10/Week10-Static.Rmd","#### Load library
```{r}
library(tidyverse)
library(Hmisc)
library(lubridate)
library(ggmap)
library(patchwork)
```

##### Tidy time columns 
```{r}
raw_df <- read_csv(""../data/week10_biketown.csv"")

library(glue)
trip_df<- raw_df %>% 
  filter(StartDate != """", StartTime != """") %>%
  mutate(StartDate = mdy(StartDate),
         EndDate = mdy(EndDate),
         Start = parse_date_time(glue(""{StartDate} {StartTime}""), ""Ymd HMS""),
         Hour = parse_factor(hour(Start), c(0, 23:1)),
         Weekday = fct_relevel(wday(Start, label = TRUE),
                               c(""Mon"",""Tue"",""Wed"",""Thu"",""Fri"",""Sat"",""Sun"")
                               ),
         Duration = hms::as.hms(round((EndTime - StartTime)))
         )


top_df <- trip_df %>% 
#  select(-TripType, -Duration, -StartHub, -EndHub) %>% 
#  drop_na() %>% 
  count(StartHub, StartLatitude,StartLongitude) %>% 
  arrange(desc(n)) %>% 
  top_n(148, n) 

trip_top <- trip_df %>% 
  filter(StartHub %in% top_df$StartHub)

ntrip    <- nrow(trip_top)
avgTime  <- mean(trip_top$Duration, na.rm = T) %>% 
  as.duration() %>% as.numeric(""minutes"") %>% round()

head_df <- top_n(top_df, 10)
```


##### Plot 1: Map
```{r}
portland <- get_map(location = c(left = -122.75, 
                                 bottom = 45.47, 
                                 right = -122.55, 
                                 top = 45.57)
                    )
# Non-square (rectangular) maps in R-ggmap
# https://stackoverflow.com/q/31316076/9421451

p1 <- ggmap(portland) + 
  geom_point(data = top_df, 
             aes(x = StartLongitude, y = StartLatitude, size = n),
             color = ""white"", fill = ""#f94d1f"", shape = 21) + 
  scale_x_continuous(limits = c(-122.71, -122.63))+
  labs(title = ""Starting Stations"") + 
  theme_minimal() + 
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = ""none"",
        plot.title = element_text(family = ""Verdana Bold"", size = 10),
        plot.margin = margin(0,0,0,0, ""cm""))
p1  
#ggsave(""map.png"", p, width = 3, height = 6)
```

##### Plot 2: Line with `geom_ribbon`
```{r}
p2 <- trip_df %>% 
  mutate(floor_week = floor_date(Start, ""weeks"")) %>% 
  count(floor_week, PaymentPlan) %>% 
  group_by(floor_week) %>% 
  mutate(nn = sum(n)) %>% 
  filter(PaymentPlan %in% ""Subscriber"") %>% 
  ggplot() + 
  geom_ribbon(aes(x = floor_week, ymin = 0, ymax = nn), 
              fill = ""grey"", color = ""grey50"") +
  geom_ribbon(aes(x = floor_week, ymin = 0, ymax = n),
              fill = ""#f69366"", color = ""grey50"") +
  scale_y_continuous(labels = glue(""{seq(0,15,5)}K"")) + 
  scale_x_datetime(date_labels = ""%b %y"", 
                   breaks = seq(as_datetime(""2016-08-01""), 
                                as_datetime(""2018-02-01""), ""6 months"")) + 
  labs(title = ""Trips Per Week"") + 
  theme_minimal() + 
  theme(panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        axis.title = element_blank(),
        plot.title = element_text(family = ""Verdana Bold"", size = 10),
        axis.text = element_text(family = ""Futura Medium"", size = 10))
```

##### Plot 3: Box with `geom_text`
```{r}
d <- data.frame(x1 = c(0, 1.1), x2 = c(1, 2.1), y1 = c(0, 0), y2 = c(1, 1)/2,
                txt = c(paste0(""Number of Trips\n"", ntrip),
                        paste0(""Average Trip Duration\n"", avgTime, "" minutes"")
                        )
                )
p3 <- ggplot() + 
#  scale_x_continuous(name=""x"") + 
#  scale_y_continuous(name=""y"") +
  geom_rect(d, mapping = aes(xmin = x1, xmax = x2, ymin = y1, ymax = y2),
            fill = ""white"", color = ""black"", alpha = 0.5) +
  geom_text(d, mapping = aes(x = (x1+x2)/2, y = (y1+y2)/2, label = txt), size = 3) +
  coord_fixed()+
  theme_void()
```

##### Plot 4: X-Y Tile
```{r}
p4 <- trip_df %>% 
  count(Weekday, Hour) %>%
  filter(!Hour %in% c(1,2,3,4)) %>% 
  ggplot(aes(x = Weekday, y = Hour, fill = n)) + 
  geom_tile() +
  annotate(""segment"", y = 21, yend = 21, x = -Inf, xend = Inf,
           color = ""black"", size = .3) +
  annotate(""segment"", y = 0, yend = 0, x = -Inf, xend = Inf,
           color = ""black"", size = .3) +
  scale_x_discrete(position = ""top"") + 
  scale_y_discrete(labels = c(""12 AM"",glue(""{c(11:1, 12)} PM""), glue(""{11:5} AM""))) +
  scale_fill_gradient(low = ""white"", high = ""#f94d1f"") + 
  labs(title = ""Trips per Weekday/Hour"") + 
  theme_minimal() + 
  theme(legend.position = ""none"",
        axis.title = element_blank(),
        panel.grid = element_blank(), 
        axis.text.y = element_text(margin = margin(r = 0)),
        plot.title = element_text(family = ""Verdana Bold"", size = 10),
        axis.text = element_text(family = ""Futura Medium""))
```

##### `patchwork`
```{r }
pp <- p1 + 
  (p2 + p3 + p4 + plot_layout(ncol = 1, heights = c (3, 2, 7))) + 
  plot_layout(ncol = 2)
ggsave(""Bike.png"", pp)
```

","Other-10"
"876",1688,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week05/Week05.Rmd","---
title: ""Week05""
author: ""CXiao""
date: ""5/1/2018""
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load library  
```{r message = F, warning = F}
library(tidyverse)
library(Hmisc)
library(maps)
```

### Read in data  
```{r message = F, warning = F}
dfASC <- read_csv(""../data/acs2015_county_data.csv"")
```

### County Map data
```{r}
Upper1  <- function(x){
  substr(x, 1, 1) <- toupper(substr(x, 1, 1))
  x
}

cnty <- map_data(""county"")%>%
  as_tibble()%>%
  rename(State = region, County = subregion) %>%
  mutate(County = str_replace(County, ""Dona Ana"", ""Doa Ana"")) 

#dfASC <- dfASC%>%
#  select(CensusId:County, MeanCommute)
head(cnty)
```

### Join Map and ASC
```{r}
# cnty has 48 states and DC
# ASC has all 50 States, DC and PR
cntyASC <- left_join(cnty, dfASC, by = c(""State"", ""County""))

stASC   <- dfASC %>%
  group_by(State) %>%
  summarise(MeanCommute = sum(MeanCommute * TotalPop)/sum(TotalPop))
```

### Find out missing counties
```{r}
cntyMiss <- cntyASC%>%
  filter(is.na(MeanCommute))%>%
  group_by(State, County)%>%
  summarise(Missing = 1)

#cntyMiss %>% as.data.frame()
# https://en.wikipedia.org/wiki/De_Kalb,_Missouri
# https://en.wikipedia.org/wiki/DeKalb_County,_Alabama
```

## Counties Plot  
### CONUS Plot
```{r message = F, warning = F, fig.width = 10}
plt <- ggplot(cnty, aes(long, lat, group = group)) + 
  geom_polygon(data = cntyASC, aes(fill = MeanCommute), 
 #              show.legend = FALSE, 
               colour = ""grey"") + 
  coord_quickmap()+
  scale_fill_distiller(name = ""Minutes"", palette = ""Spectral"")+
  theme_void()+
  labs(title = ""Mean Commute Time"",
       caption = ""Cource: US Census Demogrpahic Data 2015"")
plt
```

### `albersusa`
```{r message = F, warning = F, fig.width = 10}
library(albersusa)
uscnty <- counties_composite()
# fortify may be deprecated in the future.
usmap  <- broom::tidy(uscnty, region = ""fips"") %>% 
  as.tbl() %>%
  mutate(id = as.integer(id))

albers <- usmap %>%
  left_join(dfASC, by = c(""id"" = ""CensusId"")) %>% 
  ggplot(aes(long, lat, group = group)) + 
  geom_polygon(aes(fill = MeanCommute), 
               colour = ""grey"") + 
  coord_quickmap()+
  scale_fill_distiller(name = ""Minutes"", palette = ""Spectral"")+
  theme_void()+
  labs(title = ""Commute Time"",
       caption = ""Cource: US Census Demogrpahic Data 2015"") #+
#  scale_fill_continuous(guide = guide_legend(title = ""Mins""))+
#  guides(fill = guide_legend(title = ""Minutes""))
albers
```


### plotly  
```{r message = F, warning = F, fig.width = 10}
library(plotly)
#ggplotly(p)
```

### `choroplethr`  
```{r message = F, warning = F, fig.width = 10}
# https://bookdown.org/rdpeng/RProgDA/mapping.html#mapping-us-counties-and-states
# https://github.com/trulia/choroplethr
library(choroplethr)
library(choroplethrMaps)
data(df_pop_county)

# https://twitter.com/nlj/status/991149834085289984
mean_commute <- dfASC %>%
  select(CensusId, MeanCommute) %>%
  rename(region = CensusId, value = MeanCommute)

choro               <- CountyChoropleth$new(mean_commute)
choro$title         <- ""Mean Commute Times""
choro$ggplot_scale  <- scale_fill_brewer(name = ""Minites"", palette = 2, drop = F)
choro$legend
choro$render()
```

## States plot
### `fiftystater`
```{r message = F, warning = F, fig.width = 10}
library(fiftystater)
data(""fifty_states"")

fifty <- stASC %>% 
  mutate(State = tolower(State)) %>% 
  ggplot(aes(map_id = State)) +
  geom_map(aes(fill = MeanCommute), map = fifty_states) +
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  scale_fill_distiller(name = ""Minutes"", palette = ""Spectral"") +
  coord_map() + 
  theme_void() +
  ggtitle( ""Mean Commute Time"" ) +
  labs(caption = ""Cource: US Census Demogrpahic Data 2015"")
fifty
```

### `statebins`
```{r message = F, warning = F, fig.width = 10}
library(statebins)

bin <- stASC %>% 
  mutate(bin = cut(MeanCommute,
                   breaks = c(seq(10, 35, by = 5), Inf),
                   labels = c(seq(10, 30, by = 5), ""35+""),
                   include.lowest = TRUE)) %>% 
  ggplot(aes(state = State, fill = MeanCommute)) + 
  geom_statebins() + 
  scale_fill_distiller(name = ""Minutes"", palette = ""Spectral"") +
  coord_map() + 
  theme_void() +
  ggtitle( ""Mean Commute Time"" ) +
  labs(caption = ""Cource: US Census Demogrpahic Data 2015"") 
bin
```

### `rcstatebin`
```{r include = F, message = F, warning = F, fig.width = 10}
library(rcstatebin)

st_crosswalk <- tibble(State = state.name) %>%
  bind_cols(tibble(ST = state.abb)) %>% 
  bind_rows(tibble(State = ""District of Columbia"", ST = ""DC"")) %>%
  bind_rows(tibble(State = ""Puerto Rico"", ST = ""PR""))
#st_crosswalk$ST <- as.factor(st_crosswalk$ST)

stDemo   <- dfASC %>%
  group_by(State) %>%
  mutate_at(vars(Hispanic : Pacific), funs(. * TotalPop / 100)) %>%
  summarise_at(vars(TotalPop : Pacific), sum, na.rm = TRUE) %>%
  group_by(State) %>%
  mutate_at(vars(Men : Pacific), funs(round(. / TotalPop * 100, 3))) %>%
  left_join(st_crosswalk) %>%
  gather(TotalPop:Pacific, key = ""demo"", value = ""share"") %>% 
  filter(ST != ""PR"")
  
  

statebin(data = stDemo,
  x = ""ST"",
  y = ""share"",
  facet = ""demo"",
  heading =  ""<b>State Demographics</b>"",
  footer = ""<small>Cource: US Census Demogrpahic Data 2015"",
  colors = RColorBrewer::brewer.pal(5, 'PuRd'),
  control = 'dropdown'
)
```


### Hexbin from `geojsonio`
```{r message = F, warning = F, fig.width = 10}
# https://www.r-graph-gallery.com/328-hexbin-map-of-the-usa/
library(geojsonio)
library(broom)
library(rgeos)

spdf            <- geojson_read(""us_states_hexgrid.geojson"",  what = ""sp"")
spdf@data       <- spdf@data %>% mutate(google_name = gsub("" \\(United States\\)"", """", google_name))
spdf_fortified  <- tidy(spdf, region = ""google_name"")

centers <- cbind.data.frame(data.frame(gCentroid(spdf, byid = TRUE), id = spdf@data$iso3166_2))

spdf_fortified <- left_join(spdf_fortified , stASC, by=c(""id"" = ""State"")) 
spdf_fortified$bin <- cut(spdf_fortified$MeanCommute,
                          breaks = c(seq(10, 35, by = 5), Inf),
                          labels = c(seq(10, 30, by = 5), ""35+""),
                          include.lowest = TRUE
                          )
 

library(viridis)
my_palette <- rev(magma(8))[c(-1,-8)]

hex <- ggplot() +
  geom_polygon(data = spdf_fortified, 
               aes(fill =  bin, x = long, y = lat, group = group)) +
  geom_text(data = centers, 
            aes(x = x, y = y, label = id), 
            color = ""white"", size = 3, alpha = 0.6
            ) +
  theme_void() +
  coord_map() +
  scale_fill_manual(values = my_palette, 
                    name=""(units: minute)"", 
                    guide = guide_legend(keyheight = unit(3, units = ""mm""), 
                                         keywidth=unit(12, units = ""mm""), 
                                         label.position = ""bottom"", 
                                         title.position = 'top', nrow=1
                                         ) 
                    ) +
  ggtitle( ""Mean Commute Time"" ) +
  labs(caption = ""Cource: US Census Demogrpahic Data 2015"") +
  theme(legend.position = c(0.5, 0.9),
        text = element_text(color = ""#22211d""))

 hex
```


### `geofacet`
```{r message = F, warning = F, fig.width = 10}

```


## grid
```{r message = F, warning = F, fig.height = 10, fig.width = 10}
library(grid)
library(gridExtra)
d <- choro$render()
grid.arrange(plt, albers, bin, hex, fifty, d, ncol = 2)
```


","Other-05"
"877",1689,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week05/county_maps.Rmd","---
output:
  html_document: default
---

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
```

## clean State and County names in `maps`
```{r message=FALSE, warning=FALSE}
userPath <- .libPaths()[1]

Upper1 <- function(x){
  xsplit  <- str_split(x, "" "")
  fun1    <- function(x) {
    substr(x, 1, 1) <- toupper(substr(x, 1, 1))
    x
    }
  
  sapply(lapply(xsplit, fun1), paste, collapse="" "")
}

# Test
#Upper1 (""new york"")

cName0   <- read_delim(file = paste0(userPath, ""/maps/mapdata/county-old.N""),
                      delim = ""\t"",
                      col_names = F) 


cName <- cName0 %>%
  mutate(X2 = as.integer(X2)) %>%
  rename(name =X1, number = X2)%>%
  separate(name, c(""State"", ""County""), "","")%>%
  mutate(County = str_replace(County, ""mc"", ""mc "")) %>%
  mutate(State = Upper1(State),
         County = Upper1(County)) %>%
  mutate(State = replace(State, State == ""District Of Columbia"", ""District of Columbia"")) %>%
  mutate(County = str_replace(County, ""Mc "", ""Mc"")) %>%
  mutate(County = str_replace(County, ""De "", ""De"")) %>%
  mutate(County = str_replace(County, ""Du "", ""Du"")) %>%
  mutate(County = str_replace(County, ""La "", ""La"")) %>%
  mutate(County = str_replace(County, ""LaCrosse"", ""La Crosse"")) %>%
  mutate(County = replace(County, State == ""Texas"" & County == ""LaSalle"", ""La Salle"")) %>%
  mutate(County = str_replace(County, ""St "", ""St. "")) %>%
  mutate(County = str_replace(County, ""Ste "", ""Ste. "")) %>%
  mutate(County = str_replace(County, "" Of "", "" of "")) %>%
  mutate(County = str_replace(County, "" The "", "" the "")) %>%
  mutate(County = str_replace(County, ""Prince Georges"", ""Prince George's"")) %>%
  mutate(County = str_replace(County, ""St. Marys"", ""St. Mary's"")) %>%
  mutate(County = str_replace(County, ""Queen Annes"", ""Queen Anne's"")) %>%
#  mutate(County = str_replace(County, ""Dona Ana"", ""Doa Ana"")) %>%
  mutate(County = str_replace(County, ""Yellowstone National"", ""Yellowstone"")) %>%
  mutate(County = str_replace(County, ""Newport News"", ""Newport News city"")) %>%
  mutate(County = str_replace(County, ""Virginia Beach"", ""Virginia Beach city""))%>%
  mutate(County = replace(County, State == ""Virginia"" & County == ""Norfolk"", ""Norfolk city""))%>%
  mutate(County = replace(County, State == ""Virginia"" & County == ""Suffolk"", ""Suffolk city""))%>%
  mutate(County = replace(County, State == ""Virginia"" & County == ""Hampton"", ""Hampton city""))%>% 
  mutate(County = replace(County, State == ""Arizona"" & County == ""LaPaz"", ""La Paz""))%>%
  mutate(County = replace(County, State == ""Colorado"" & County == ""LaPlata"", ""La Plata""))%>%
  mutate(County = replace(County, State == ""Illinois"" & County == ""DeWitt"", ""De Witt""))%>%
  mutate(County = replace(County, State == ""Indiana"" & County == ""Lagrange"", ""LaGrange""))%>%
  mutate(County = replace(County, State == ""Iowa"" & County == ""Obrien"", ""O'Brien""))%>%
  mutate(County = replace(County, State == ""Louisiana"" & County == ""DeSoto"", ""De Soto""))%>%
  mutate(County = str_replace(County, ""King And Queen"", ""King and Queen""))%>%
  mutate(County = str_replace(County, ""Lewis And Clark"", ""Lewis and Clark""))%>%
  mutate(County = str_replace(County, ""Fond DuLac"", ""Fond du Lac""))%>%
  mutate(County = replace(County, 
                          State == ""South Dakota"" & County == ""Shannon"", 
                          ""Oglala Lakota""))%>%
  mutate(County = replace(County, 
                          State == ""District of Columbia"" & County == ""Washington"", 
                          ""District of Columbia""))%>%
  mutate(County = str_replace(County, ""DeBaca"", ""De Baca""))%>%
  mutate(County = str_replace(County, ""Miami-dade"", ""Miami-Dade""))%>%
  mutate(County = str_replace(County, ""St. Louis City"", ""St. Louis""))%>%
  mutate(County = str_replace(County, ""Baltimore City"", ""Baltimore""))%>%
  mutate(County = str_replace(County, ""Lac Qui Parle"", ""Lac qui Parle""))%>%
  mutate(S.C = paste(State, County, sep = "","")) %>%
  select(S.C, number, -State, -County)

write_tsv(cName, paste0(userPath, ""/maps/mapdata/county.N""), col_names = F)
```


### Test
```{r eval=FALSE, include=FALSE}
cName %>%
  filter(grepl("" "", County))

cntyMiss %>%
  filter(grepl("" "", County) & !grepl(""st "", County)) %>% as.data.frame()

numASC1 <- dfASC %>%
  group_by(State) %>% 
  filter(State == ""New Mexico"")
numASC1$County[8]
```

","Other-05"
"878",1690,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week06/TimHortons_US.Rmd","---
title: ""TimHortons_US""
author: ""Chuliang Xiao""
date: ""5/9/2018""
output: html_document
---

### Load library  
```{r message = F, warning = F}
library(tidyverse)
library(Hmisc)
```

### Read in data  
```{r message = F, warning = F}
library(readxl)
setwd(""../Week06"")
fname <- ""week6_coffee_chains.xlsx""
excel_sheets(fname)
dfStar <- read_excel(fname, 1)
dfTimh <- read_excel(fname, 2)
dfDunk <- read_excel(fname, 3)
```

### Obtain TH locations
```{r}
# https://stackoverflow.com/a/32505896
# Following the SOF post. Looks like the Google geocode API is very unstable
geocodeAdddress <- function(address) {
  require(RJSONIO)
  url <- ""http://maps.google.com/maps/api/geocode/json?address=""
  url <- URLencode(paste(url, address, ""&sensor=false"", sep = """"))
  x <- fromJSON(url, simplify = FALSE)
  if (x$status == ""OK"") {
    out <- c(x$results[[1]]$geometry$location$lng,
             x$results[[1]]$geometry$location$lat)
  } else {
    cat(paste0(address, ""\n""))
    out <- NA
  }
  Sys.sleep(1)  # API only allows 5 requests per second
  out
}

library(ggmap)
TimhUS <- dfTimh %>% 
  rename(ST = state, Country = country, City = city) %>%
  filter(Country == ""us"") %>% 
  mutate(postal_code = replace(postal_code, 
                               nchar(postal_code) == 4, 
                               paste0(""0"", postal_code))) %>% 
  mutate(Country = ""USA"",
         State = openintro::abbr2state(ST),
         address = paste(address, City, ST, postal_code, sep = "", "")) %>% 
  select(Country, address, State, ST, City)

nTimh <- nrow(TimhUS)
loc <- data.frame(Longitude = rep(NA, nTimh), Latitude = rep(NA, nTimh))
for (i in 1 : nTimh){
  loc[i,] <- geocodeAdddress(TimhUS[i, ""address""])
  cat(paste0(i, ""\n""))
}

# the following loop might need to be tried multiple times
for (i in 1 : nTimh){
  if (is.na(loc[i, 1])) {
    loc[i,] <- geocodeAdddress(TimhUS[i, ""address""])
    cat(paste0(i, ""\n""))
  }
}

TimhUS <- cbind(TimhUS, loc) %>% 
  select(-address) %>% 
  filter(!is.na(Longitude)) %>% 
  mutate(Store = ""Tim Hortons"")

write_csv(TimhUS, ""Week06/TimHortons_US.csv"")
```
","Other-06"
"879",1691,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week06/Week06.Rmd","
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load library  
```{r message = F, warning = F}
library(tidyverse)
library(Hmisc)
```

### Read in data  
```{r message = F, warning = F}
library(readxl)
setwd(""../Week06"")
fname <- ""week6_coffee_chains.xlsx""
excel_sheets(fname)
dfStar <- read_excel(fname, 1)
dfTimh <- read_excel(fname, 2)
dfDunk <- read_excel(fname, 3)
```


### Obtain TH locations
```{r}
TimhUS <- read_csv(""TimHortons_US.csv"")
```


### Data Cleaning
```{r fig.width = 10}
library(usmap)
data(statepop)

# Select US Starbucks  
StarUS <- dfStar %>% 
  rename(ST = `State/Province`) %>%
  filter(Country == ""US"") %>% 
  mutate(State = openintro::abbr2state(ST)) %>% 
  select(Country, State, ST, City, Longitude, Latitude) %>% 
  mutate(Store = ""Starbucks"")

# Starbucks numbers in each states  
avgStarUS <- StarUS %>% 
  group_by(State) %>% 
  summarise(count = n(), ST = unique(ST)) %>% 
  left_join(statepop, by = c(""ST"" = ""abbr"")) %>% 
  mutate(Avg = count/pop_2015 * 1e5) 

# Select US Duckin  
DuckUS <- dfDunk %>% 
  rename(Country = e_country, ST = e_state, City = e_city,
         Longitude = loc_LONG_poly, Latitude = loc_LAT_poly) %>% 
  mutate(State = openintro::abbr2state(ST)) %>% 
  select(Country, State, ST, City, Longitude, Latitude) %>% 
  filter(Country == ""USA"") %>% 
  mutate(Store = ""Dunkin' Donuts"")
  
SDUS <- rbind(StarUS, DuckUS, TimhUS)
avgSDUS <- SDUS %>% 
  group_by(State, Store) %>% 
  summarise(count = n(), ST = unique(ST)) %>% 
  left_join(statepop, by = c(""ST"" = ""abbr"")) %>% 
  mutate(Avg = count/pop_2015 * 1e5)
```

### Fifty States from `albersusa`
```{r fig.width = 10}
library(albersusa)
us      <- usa_composite()
us_map  <- broom::tidy(us, region = ""name"")

p <- ggplot() +
  geom_map(data = avgStarUS, aes(fill = Avg, map_id = State),
           color=""white"", size = 0.01, map = us_map) + 
  scale_fill_distiller(name = ""Number"", palette = ""Spectral"") +
  expand_limits(x = us_map$long, y = us_map$lat) +
  coord_map() +
  theme_void() +
  theme(legend.position=c(.88, .4))+
  ggtitle( ""Starbucks Stores per 100, 000 population"" ) +
  labs(caption = ""Source: US Census Demogrpahic Data 2015"")
  
p
```

### Dot Density Map for CONUS
```{r fig.width = 10}
StarCONUS <- filter(StarUS, ST != ""HI"" & ST != ""AK"")
avgStarCONUS <- filter(avgStarUS, ST != ""HI"" & ST != ""AK"")
 
t <- ggplot() +
  geom_map(data = avgStarCONUS, aes(fill = Avg, map_id = State),
           color=""white"", size = 0.01, map = us_map) + 
  scale_fill_distiller(name = ""Number"", palette = ""Spectral"") +
  geom_point(data = StarCONUS, aes(x = Longitude, y = Latitude), size = 0.04, alpha = 0.1) +

  expand_limits(x = us_map$long, y = us_map$lat) +
  coord_map() +
  theme_void() +
  theme(legend.position=c(.88, .4)) +
  ggtitle( ""Starbucks Stores per 100, 000 population"" ) +
  labs(caption = ""Source: US Census Demogrpahic Data 2015"")
t
#t + coord_map(""polyconic"")
```

### Compare Starbucks and Dunkin' Donuts
```{r fig.width = 10}
StarCONUS <- filter(StarUS, ST != ""HI"" & ST != ""AK"")
SDCONUS   <- filter(SDUS, ST != ""HI"" & ST != ""AK"")
us_map <- filter(us_map, id !=""Hawaii"" & id != ""Alaska"") 

c <- ggplot() +
  geom_map(data = us_map, aes(map_id = id),
           color=""#2b2b2b"", size = 0.1, fill = NA, map = us_map) + 
  #scale_fill_distiller(name = ""Number"", palette = ""Spectral"") +
  geom_point(data = SDCONUS, aes(x = Longitude, y = Latitude, color = Store), 
             size = 0.5, alpha = 0.1) +
  expand_limits(x = us_map$long, y = us_map$lat) +
  coord_map() +
  theme_void() +
#  theme(legend.position = ""top"")+
  ggtitle( ""Starbucks and Dunkin's Donuts Stores"" ) +
  labs(caption = ""Source: US Census Demogrpahic Data 2015"") +
  guides(colour = guide_legend(title = NULL, override.aes = list(size = 3 ))) +
  theme(legend.position=c(.88, .3)) 
c
```

```{r fig.height = 15, fig.width = 10}
library(grid)
library(gridExtra)
grid.arrange(p, t, c, ncol = 1)
```

### Michigan
```{r fig.width = 10}
SDCONUS   <- filter(SDUS, ST  == ""MI"")
us_map <- broom::tidy(us, region = ""name"") %>% filter(id == ""Michigan"") 

m <- ggplot() +
  geom_map(data = us_map, aes(map_id = id),
           color=""#2b2b2b"", size = 0.1, fill = NA, map = us_map) + 
  geom_point(data = SDCONUS, aes(x = Longitude, y = Latitude, color = Store), 
             size = 1, alpha = 0.1) +
  expand_limits(x = us_map$long, y = us_map$lat) +
  coord_map() +
  theme_void() +
#  theme(legend.position = ""top"")+
  ggtitle( ""Coffee Stores"" ) +
  guides(colour = guide_legend(title = NULL, override.aes = list(size = 3 ))) +
  theme(legend.position=c(.3, .3)) 
m
```

### Manhattan
```{r message = F, warning = F, fig.height = 10, fig.width = 10}
library(ggmap)
SDCONUS   <- filter(SDUS, City == ""New York"")
us_map    <- broom::tidy(us, region = ""name"") %>% filter(id == ""New York"") 
nyc_base  <- get_map(""Manhattan"", zoom = 12, maptype = ""toner-lite"")

d <- nyc_base %>% 
  ggmap() +
  geom_point(data = SDCONUS, aes(x = Longitude, y = Latitude, color = Store, shape = Store), 
             size = 2) +
#  coord_map() +
  theme_void() +
  theme(legend.position = ""top"")+
  ggtitle( ""Coffee Stores in Manhattan"" ) +
  guides(shape = guide_legend(title = NULL, override.aes = list(size = 3 ))) +
  guides(colour = guide_legend(title = NULL, override.aes = list(size = 3 ))) 

d
```

","Other-06"
"880",1693,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week07/Week07.Rmd","
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load library  
```{r message = F, warning = F}
library(tidyverse)
library(Hmisc)
```

### Read in data  
```{r message = F, warning = F}
fname <- ""../data/week7_starwars.csv""
dfSW_raw  <- read_csv(fname, col_names = F)
h2        <- dfSW_raw[2,]
dfSW      <- slice(dfSW_raw, 3:n())
names(dfSW) <- c(""id"", ""seen_any"", ""fan"", 
                 ""SW1"", ""SW2"", ""SW3"", ""SW4"", ""SW5"", ""SW6"",
                 ""RSW1"", ""RSW2"", ""RSW3"", ""RSW4"", ""RSW5"", ""RSW6"",
                 h2[16:29],
                 ""shot"", ""ext"", ""fan_ext"", ""Star_Trek"",
                 ""gender"", ""age"", ""income"", ""edu"", ""location"")
```

### Clean data
```{r}
nameSW <- c(""Star Wars: Episode I  \nThe Phantom Menace"", 
            ""Star Wars: Episode II  \nAttack of the Clones"",
            ""Star Wars: Episode III  \nRevenge of the Sith"",
            ""Star Wars: Episode IV  \nA New Hope"",
            ""Star Wars: Episode V \nThe Empire Strikes Back"", 
            ""Star Wars: Episode VI \nReturn of the Jedi"")
funfactor <- function(x){
  factor(x, levels = c(""Very favorably"",
                       ""Somewhat favorably"",
                       ""Neither favorably nor unfavorably (neutral)"",
                       ""Somewhat unfavorably"",
                       ""Very unfavorably"",
                       ""Unfamiliar (N/A)""),
         labels = c(""Very Favorable"",
                    ""Some Favorable"",
                    ""Neutral"",
                    ""Some Unfavorable"",
                    ""Very Unfavorable"",
                    ""Unfamiliar""))
}
clSW  <- dfSW %>% 
  mutate(seen_any = factor(seen_any, levels = c(""Yes"", ""No""), labels = c(""T"", ""F"")),
         fan = factor(fan, levels = c(""Yes"", ""No""), labels = c(""T"", ""F"")),
         ext = factor(ext, levels = c(""Yes"", ""No""), labels = c(""T"", ""F"")),
         fan_ext = factor(fan_ext, levels = c(""Yes"", ""No""), labels = c(""T"", ""F"")),
         SW1 = str_replace(SW1, ""Star Wars: Episode I  The Phantom Menace"", ""T""),
         SW2 = str_replace(SW2, ""Star Wars: Episode II  Attack of the Clones"", ""T""),
         SW3 = str_replace(SW3, ""Star Wars: Episode III  Revenge of the Sith"", ""T""),
         SW4 = str_replace(SW4, ""Star Wars: Episode IV  A New Hope"", ""T""),
         SW5 = str_replace(SW5, ""Star Wars: Episode V The Empire Strikes Back"", ""T""),
         SW6 = str_replace(SW6, ""Star Wars: Episode VI Return of the Jedi"", ""T"")
         ) %>% 
  mutate_at(vars(SW1:RSW6, shot:Star_Trek, location), factor) %>% 
  mutate_at(vars(`Han Solo`:`Yoda`), funfactor) %>% 
  mutate(income = factor(income, levels = c(""$0 - $24,999"",
                                            ""$25,000 - $49,999"",
                                            ""$50,000 - $99,999"",
                                            ""$100,000 - $149,999"",
                                            ""$150,000+"")),
         edu = factor(edu, levels = c(""Less than high school degree"",
                                      ""High school degree"",
                                      ""Some college or Associate degree"",
                                      ""Bachelor degree"",
                                      ""Graduate degree"")))
```

### Plot ""'Star War' ""
```{r Per of SW seen}
clSW %>% 
  select(gender, seen_any) %>% 
  group_by(gender) %>% 
  summarise(count = sum(seen_any == ""T"", na.rm = T),
            perc = round(count/n() * 100, 2)) %>%
  ggplot(aes(x = gender, y = perc)) + 
  geom_bar(stat = ""identity"", fill = ""light blue"") +
#  scale_x_discrete(labels = nameSW) +
  labs(y = ""percentage"") +
  geom_text(aes(label = count), size = 3, vjust = 0.5) +
  ggtitle(""People who have you seen any 'Star Wars'"")
  
```

### Plot ""Which 'Star War' Movie have you seen""
```{r perc of each SW seen, fig.width = 10}
ms <- clSW %>% 
  select(id:SW6, gender) %>% 
  gather(SW1:SW6, key = ""Episode"", value = ""seen"") %>% 
  group_by(Episode, gender) %>% 
  summarise(count = sum(seen == ""T"", na.rm = T),
            perc = round(count/n() * 100, 2)) %>%
  drop_na() %>% 
  ggplot(aes(x = Episode, y = perc, fill = gender)) + 
  geom_bar(stat = ""identity"", position = position_dodge(width = 0.5)) +
  scale_x_discrete(labels = nameSW) +
  scale_fill_discrete(name = NULL) +
  labs(y = ""percentage"") +
  geom_text(aes(label = count), size = 3,
            position = position_dodge(width = 1),
            inherit.aes = T) +
  coord_flip() +
  ggtitle(""Which 'Star Wars' Movie have you seen"")
ms  
```

### Plot ""the best movie""  
```{r best movie, fig.width = 10}
bm <- clSW %>% 
  select(RSW1:RSW6, gender) %>% 
  gather(RSW1:RSW6, key = ""Episode"", value = ""seen"") %>% 
  group_by(Episode, gender) %>% 
  summarise(count = sum(seen == 1, na.rm = T),
            perc = round(count/n() * 100, 2)) %>%
  drop_na() %>% 
  ggplot(aes(x = Episode, y = perc, fill = gender)) + 
  geom_bar(stat = ""identity"", position = position_dodge(width = 0.5)) +
  scale_x_discrete(labels = nameSW) +
  scale_fill_discrete(name = NULL) +
  labs(y = ""percentage"") +
  geom_text(aes(label = count), size = 3,
            position = position_dodge(width = 1),
            inherit.aes = T) +
  coord_flip() +
  ggtitle(""Which 'Star Wars' episode is most favorite"")
bm  
```

### Plot ""favorite charactor""  
```{r favorite charactor, fig.width = 10}
ch <- clSW %>% 
  select(`Han Solo`:`Yoda`, gender) %>% 
  drop_na() %>% 
  gather(`Han Solo`:`Yoda`, key = ""charactor"", value = ""rank"") %>% 
  group_by(charactor, gender, rank) %>% 
  summarise(count = n()) %>% 
  group_by(charactor, gender) %>% 
  mutate(perc = round(count/sum(count) * 100, 2)) %>%
  mutate(rank = factor(rank, levels = c(""Very Favorable"",
                                        ""Some Favorable"",
                                        ""Neutral"",
                                        ""Some Unfavorable"",
                                        ""Very Unfavorable"",
                                        ""Unfamiliar""))) %>%
  ggplot(aes(x = charactor, y = perc, fill = gender)) + 
  geom_bar(stat = ""identity"", position = position_dodge(width = 0.5)) +
  theme_minimal()+
  scale_fill_discrete(name = NULL) +
  labs(y = ""percentage"") +
  coord_flip() +
  ggtitle(""Which 'Star Wars' charactor is most favorite"")+
  facet_grid(~rank)+
  theme(legend.position = ""top"") 
ch  
```

## grid
```{r message = F, warning = F, fig.height = 10, fig.width = 10}
library(grid)
library(gridExtra)
grid.arrange(bm, ch, ncol = 1)
```","Other-07"
"881",1694,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week08/Week08.Rmd","```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load library  
```{r library, message = F, warning = F}
library(tidyverse)
library(Hmisc)
```

### Read in data  
```{r read data, message = F, warning = F}
fname1   <- ""../data/week8_honey_production/honeyraw_1998to2002.csv""
fname2   <- ""../data/week8_honey_production/honeyraw_2003to2007.csv""
fname3   <- ""../data/week8_honey_production/honeyraw_2008to2012.csv""
df_raw1  <- read_csv(fname1, col_names = F, skip = 9)
df_raw2  <- read_csv(fname2, col_names = F, skip = 81)
df_raw3  <- read_csv(fname3, col_names = F, skip = 72)
```

### Extract data from csv 1 and 2  
```{r wrangle csv 1 and 2}
tidyfun <- function(df_raw, year0){
df_raw %>% 
    drop_na()%>% 
  filter(X3 %in% state.abb) %>% 
  mutate_at(vars(X4:X9), as.numeric) %>% 
  mutate(X1 = X1 + year0 -1,
         X4 = X4 * 1000,
         X6 = X4 * X5,
         X7 = X7 * 1000,
         X8 = X8/100,
         X9 = X6 * X8) %>% 
  select(-X2) %>% 
  rename(year = X1, st = X3, numcol = X4, yieldpercol = X5,
         totalprod = X6, stocks = X7, priceperlb = X8, prodvalue = X9)  
}

df_data1 <- tidyfun(df_raw1, 1998)
df_data2 <- tidyfun(df_raw2, 2003)
#df_data3 <- tidyfun(df_raw3)
```

### Extract data from csv 3  
```{r wrangle csv 3}
#names(state.abb) <- state.name  

df_data3 <- df_raw3 %>% 
  mutate(X3 = state.abb[match(X3, state.name)]) %>% 
  tidyfun(2008)
```

### Combine data
```{r}
df_data_all <- bind_rows(df_data1, df_data2, df_data3)
```

### Bar plot
```{r fig.height = 10}
df_data_all %>% 
  group_by(st) %>% 
  summarise(sumprod = sum(totalprod)) %>% 
  arrange(desc(sumprod)) %>% 
  ggplot(aes(x = fct_reorder(st, sumprod), y = sumprod)) + 
  geom_bar(stat = ""identity"") +
  labs(x = ""State"", y = ""Total Production"") +
  coord_flip() +
  ggtitle(""US Honey Production (1998-2012)"")
```


### Top 5 States
```{r}
st10 <- df_data_all %>% 
  group_by(st) %>% 
  summarise(sumprod = sum(totalprod)) %>% 
  arrange(desc(sumprod)) %>% 
  top_n(5)
df_data_all %>% 
  filter(st %in% st10$st) %>% 
  ggplot(aes(x = year, y = totalprod, color = st)) + 
  geom_point() +
  geom_smooth(se = F)+
  guides(color = guide_legend(NULL))+
  labs(x = ""Year"", y = ""Total Production"") +
  ggtitle(""Honey Production of Top 5 States"")
```

","Other-08"
"882",1696,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week09/Week09.Rmd","```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load library  
```{r library, message = F, warning = F}
library(tidyverse)
library(Hmisc)
library(ggthemes)
```

### Read in data  
```{r read data, message = F, warning = F}
df_raw  <- read_csv(""../data/week9_comic_characters.csv"")
```

### DC vs. Marvel by year 
#### New Comic Book Characters Introduced Per Year  
```{r fig.width = 10}
publisher_name = c(""DC, New Earth continuity"", 
                   ""Marvel, Earth-616 continuity"")
p1 <- df_raw %>% 
  group_by(publisher, year) %>% 
  summarise(count = n()) %>% 
  ungroup() %>% 
  mutate(publisher = factor(publisher, labels = publisher_name))%>% 
  ggplot(aes(x = year, y = count, fill = publisher)) +
  geom_bar(stat = ""identity"") +
  scale_fill_manual(values = c(""blue"", ""red""))+
  scale_y_continuous(labels = seq(0,500,100),
                     breaks = seq(0,500,100)) +
  scale_x_continuous(labels = c(1940, ""'60"", ""'80"", 2000),
                     breaks = seq(1940,2000,20)) + 
#  ggtitle(""New Comic Book Characters Introduced Per Year"")+
  labs(title = ""New Comic Book Characters Introduced Per Year"",
       caption = ""Source: FiveThirtyEight"")+
  facet_wrap(~ publisher) +
  theme_fivethirtyeight() +
  theme(strip.text.x = element_text(size = 15))+
  theme(legend.position = ""none"") 
p1
```

#### Gender Ratio by year      
```{r fig.width = 10}
p2 <- df_raw %>% 
  mutate(sex = str_replace(sex, "" Characters"", """"))%>% 
  count(publisher, year, sex) %>% 
  group_by(publisher, year) %>% 
  mutate(total = sum(n)) %>%
  mutate(ratio = n / total * 100) %>% 
  filter(sex == ""Female"") %>% 
  ggplot(aes(x = year, y = ratio, group = publisher, color = publisher)) +
  geom_line() +
  geom_text(aes(x = 2002, y = 25, label = ""Marvel""), 
            color = ""red"", size = 5) + 
  geom_text(aes(x = 2001, y = 44, label = ""DC""), 
            color = ""blue"", size = 5) + 
  scale_x_continuous(limits = c(1980, 2013),
                     labels = c(1980, ""'90"", 2000, ""'10"")) + 
  scale_y_continuous(labels = c(seq(0,40,10), ""50%""),
                     breaks = seq(0,50,10),
                     limits = c(0,50)) + 
  scale_color_manual(values = c(""blue"", ""red"")) +
  labs(title = ""Comics Aren't Gaining Many Female Characters"",
       subtitle = ""Percentage of new characters who are female"",
       caption = ""Source: FiveThirtyEight"") +
  theme_fivethirtyeight() +
  theme(legend.position = ""none"") 
p2
```


#### Gender Ratio cumulated   
```{r fig.width = 10}
p3 <- df_raw %>% 
  mutate(sex = str_replace(sex, "" Characters"", """"))%>% 
  filter(sex %in% c(""Male"", ""Female"")) %>% 
  count(publisher, year, sex) %>% 
  group_by(publisher, year) %>% 
  mutate(total = sum(n)) %>%
  filter(sex == ""Female"") %>% 
  group_by(publisher) %>% 
  mutate(cum_hero = cumsum(total),
         cum_female = cumsum(n),
         ratio = cum_female/cum_hero * 100) %>% 
  ggplot(aes(x = year, y = ratio, group = publisher, color = publisher)) + 
  geom_line() + 
  geom_text(aes(x = 1992, y = 15, label = ""Marvel""),
            color = ""red"", size = 5) + 
  geom_text(aes(x = 1990, y = 30, label = ""DC""), 
            color = ""blue"", size = 5) +
  scale_y_continuous(limits = c(0,50),
                     labels = c(seq(0,40,10), ""50%"")) + 
  scale_x_continuous(limits = c(1939, 2013),
                     labels = c(1940, glue::glue(""'{seq(50,90,10)}""), 2010, ""'10""),
                     breaks = seq(1940,2010, 10)) + 
  scale_color_manual(values = c(""blue"", ""red"")) +
  labs(title = ""The Gender Ratio In Comic Books Is Improving"",
       subtitle = ""Percentage of total characters in universe who are female"",
       caption = ""Source: FiveThirtyEight"") + 
  guides(color = FALSE) + 
  theme_fivethirtyeight() 
p3
```

#### Character Alignment by Gender
```{r fig.width = 10, fig.height = 4}
describe(df_raw$align)
# Credit to https://twitter.com/dylanjm_ds/status/1001688440524673024
df_align <- df_raw %>% 
  mutate(sex = str_replace(sex, "" Characters"", """"),
         align = str_replace(align, "" Characters"", """"),
         align = if_else(is.na(align), ""Neutral"", align)) %>% 
  filter(align != ""Reformed Criminals"") %>%
  filter(sex %in% c(""Female"", ""Male"")) %>% 
  group_by(publisher, sex, align) %>% 
  summarise(count = n()) %>% 
  group_by(publisher, sex) %>% 
  mutate(total = sum(count),
         ratio = count/total * 100,
         align = fct_relevel(align, c(""Bad"", ""Neutral"", ""Good""))) %>% 
  filter(sex %in% c(""Female"", ""Male"")) %>% 
# Mannually set the ration label
  ungroup() %>% 
  mutate(rlab0 = round(ratio),
         rlab1 = if_else(publisher == ""DC"" & sex == ""Female"",
                           paste0(rlab0, ""%""),
                           as.character(rlab0)),
         r1 = if_else(align == ""Good"",
                      rlab1,
                      as.character(NA)),
         r2 = if_else(align == ""Neutral"",
                      rlab1,
                      as.character(NA)),
         r3 = if_else(align == ""Bad"",
                      rlab1,
                      as.character(NA))) 

p4 <- df_align %>% 
  ggplot(aes(x = fct_relevel(sex, c(""Male"", ""Female"")), y = ratio, fill = align)) + 
  geom_bar(stat = ""identity"", width = 0.8, position = position_stack()) + 
  geom_text(aes(y = 1, label = r1), color = ""white"", hjust = 0) + 
  geom_text(aes(label = r2), color = ""white"", position = position_stack(vjust = 0.5)) +
  geom_text(aes(y = 99, label = r3), color = ""white"", hjust = 1) +
  scale_fill_manual(values = c(""#fc2a1c"", ""#f5b92b"", ""#78a949"")) + 
  scale_x_discrete(labels = c(""Male"", ""Female"")) + 
  coord_flip() + 
  facet_wrap(~ publisher, ncol = 1) + 
  labs(title = ""Good Girls Gone Meh"",
       subtitle = ""Character alignment by gender"",
       caption = ""Source: FiveThirtyEight"") + 
  guides(fill = FALSE) + 
  theme_fivethirtyeight() + 
# Left-adjust title 
# https://stackoverflow.com/a/47621310/9421451
  theme(plot.title = element_text(hjust = -0.09),
        plot.subtitle = element_text(hjust = -0.08),
        strip.text.x = element_text(size = 15, hjust = 0),   
        # When hjust Cannot be negative for the trip.text
        panel.grid = element_blank(), 
        axis.text.x = element_blank())
p4 +
  annotate(geom = ""text"", x = 3, y = 0,   label = c(""Good"", NA),    
           color = ""#78a949"", vjust = 0.85, hjust = 0)+
  annotate(geom = ""text"", x = 3, y = 58,  label = c(""Neutral"", NA), 
           color = ""#f5b92b"", vjust = 0.85, hjust = 0.5)+
  annotate(geom = ""text"", x = 3, y = 100, label = c(""Bad"", NA),     
           color = ""#fc2a1c"", vjust = 0.85, hjust = 1)
```

","Other-09"
"883",1698,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week11/Week11.Rmd","
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(treemapify)
library(kableExtra)
library(patchwork)
```

### Read in Data
```{r message = F, warning = F}
raw_df <- read_csv(""../data/week11_fifa_audience.csv"")
```


### Color Table
```{r Color Table}
raw_df %>% 
  arrange(desc(gdp_weighted_share)) %>% 
  top_n(38) %>% 
  kable(format = ""html"",
        col.names = c("""", ""COUNTRY"", ""BODY"",
                      ""GLOBAL\nPOPULATION"",
                      ""WORLD CUP TV\nAUDIENCE"",
                      ""GDP-WEIGHTED\nAUDIENCE"")) %>% 
  add_header_above(c("" "" = 3, ""IN 2010, SHARE OF ..."" = 3)) %>% 
  column_spec(6, background = ""#F5F5F5"") %>% 
  kable_styling()
  
  #ggthemes::theme_fivethirtyeight() 
```


### GDP-weighted Audience Share
```{r GDP-weighted Audience Share}

# https://github.com/ysamano/TidyTuesday/blob/master/week_11/week_11.R
treemap1 <- raw_df %>% 
  ggplot(aes(area = tv_audience_share,
             subgroup = confederation,
             fill = gdp_weighted_share,
             label = country)) +
  geom_treemap(colour = ""gray10"") +
  geom_treemap_text(colour = ""white"", fontface = ""italic"", min.size = 3, reflow = T) +
  geom_treemap_subgroup_border(colour = ""white"", size = 2) +
  geom_treemap_subgroup_text(alpha = 0.6, colour = ""black"") +
  viridis::scale_fill_viridis(direction = -1) +
  labs(title = expression(paste(""FIFA""^"""", "" World Cup TV Audience Share 2010"")),
       caption =""Source: FiveThirtyEight"",
       fill = ""GDP-weighted Audience Share (%)"") +
  theme(plot.title = element_text(size = 20, face = ""bold""),
        legend.position = ""bottom"")


#
```

### FIFA Audience Share (per capita)
```{r FIFA Audience Share per capita}
treemap2 <- raw_df %>% 
  mutate(tv_per_capita = tv_audience_share/population_share) %>% 
  ggplot(aes(area = tv_audience_share,
             subgroup = confederation,
             fill = tv_per_capita,
             label = country)) +
  geom_treemap(colour = ""gray10"") +
  geom_treemap_text(colour = ""white"", fontface = ""italic"", min.size = 3, reflow = T) +
  geom_treemap_subgroup_border(colour = ""white"", size = 2) +
  geom_treemap_subgroup_text(alpha = 0.6, colour = ""black"") +
  viridis::scale_fill_viridis(direction = -1) +
#  ggtitle(expression(paste(""FIFA""^"""", "" World Cup TV Audience Share 2010"")))+
#  ggtitle(expression(paste0(""FIFA""^"""", "" World Cup TV Audience Share 2010"")))
  labs(title = expression(paste(""FIFA""^"""", "" World Cup TV Audience Share 2010"")),
       caption =""Source: FiveThirtyEight"",
       fill = ""TV Audience Share per capita"") +
  theme(plot.title = element_text(size = 20, face = ""bold""),
        legend.position = ""bottom"")
# library(plotly)
# ggplotly(treeplot2) 
# ggplotly not supported
# https://github.com/ropensci/plotly/issues/1031
ggsave(""FIFA_TV.png"", treemap2, height = 8, width = 10, units = ""in"", dpi = 300)
```

","Other-11"
"884",1700,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week12/Week12.Rmd","
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(ggthemes)
library(kableExtra)
library(patchwork)
```

### Read in Data
```{r message = F, warning = F}
raw_df1 <- read_csv(""../data/week12_mediacloud_hurricanes.csv"")
raw_df2 <- read_csv(""../data/week12_mediacloud_states.csv"")
raw_df3 <- read_csv(""../data/week12_mediacloud_top_online_news.csv"")
```


### Time column
```{r}
library(lubridate)
df1 <- raw_df1 %>% 
  select(-Jose) %>% 
  mutate(Date = mdy(Date)) %>% 
  gather(key = ""key"", value = ""value"", -Date) %>% 
  mutate(type = ""Hurricane"", color = key) 

df2 <- raw_df2 %>% 
  mutate(Date = mdy(Date)) %>%
  rename(""Puerto Rico"" = '""Puerto Rico""') %>% 
  gather(key = ""key"", value = ""value"", -Date) %>% 
  mutate(type = ""State"")%>% 
  mutate (color = case_when(key == ""Texas"" ~ ""Harvey"",
                            key == ""Florida"" ~ ""Irma"",
                            key == ""Puerto Rico"" ~ ""Maria""))

hurr_state_df <- bind_rows(df1, df2)
```

### Color Table
```{r Color Table}
p1 <- hurr_state_df %>% 
  ggplot() + 
  geom_ribbon(aes(x = Date, ymin = 0, ymax = value, fill = color), 
              color = ""grey50"")  +
  scale_y_continuous(breaks = seq(0, 4000, 1000),
                     labels = seq(0, 4000, 1000)) + 
  scale_x_date(date_labels = ""%b %d"",
               limits = c(as_date(""2017-08-20""), as_date(""2017-09-24"")),
               breaks = seq(as_date(""2017-08-20""), 
                            as_date(""2017-09-17""), ""1 week"")) + 
  facet_wrap(~ type) + 
  theme_minimal() +
  theme(legend.position = ""none"",
        strip.background = element_blank(),
        strip.text.x = element_blank()) +
  labs(y = ""Sentences per day"",
       x = NULL,
       caption = ""Source: FiveThirtyEight"") 
```


#### Add texts
```{r}
txt <- tribble(
    ~tim, ~cnt, ~lab, ~type,
    ""2017-08-30"", 2700, ""Harvey"", ""Hurricane"",
    ""2017-09-10"", 2700, ""Irma"", ""Hurricane"",
    ""2017-09-20"", 800, ""Maria"", ""Hurricane"",
    ""2017-08-24"", 4000, ""Texas"", ""State"",
    ""2017-09-07"", 3700, ""Florida"", ""State"",
    ""2017-09-20"", 1700, ""Puerto Rico"", ""State""
  )
txt <- mutate(txt, tim = as_date(tim))

pp1 <- p1 + 
  geom_text(data = txt, aes(x = tim, y = cnt, label = lab))

ggsave(""Hurricane.png"", pp1, height = 5, width = 10, units = ""in"", dpi = 300)
```


### Single plot
```{r}
g1 <- raw_df1 %>% 
  mutate(Date = mdy(Date)) %>%  
  ggplot() + 
  geom_ribbon(aes(x = Date, ymin = 0, ymax = Harvey), 
              fill = ""orange"", color = ""grey50"") +
  geom_ribbon(aes(x = Date, ymin = 0, ymax = Irma), 
              fill = ""red"", color = ""grey50"") +
  geom_ribbon(aes(x = Date, ymin = 0, ymax = Maria), 
              fill = ""blue"", color = ""grey50"") +
  theme_minimal() +
  labs(y = ""Sentences per day"") +
  scale_y_continuous(limits = c(0, 4000),
                     breaks = seq(0, 4000, 1000),
                     labels = seq(0, 4000, 1000)) + 
  scale_x_date(date_labels = ""%b %d"",
               breaks = seq(as_date(""2017-08-20""), 
                            as_date(""2018-09-17""), ""1 week""))
```


","Other-12"
"885",1702,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week13/Week13.Rmd","
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(kableExtra)
library(ggthemes)
library(patchwork)
```

#### Read in Data
```{r message = F, warning = F}
raw_df <- read_csv(""../data/week13_alcohol_global.csv"")
```


#### Alcohol Rank
```{r message = F, warning = F}
top10 <- function(df, col){
  quo_col <- enquo(col)
  df %>% 
  select(country, !!quo_col) %>% 
  arrange(desc(!!quo_col)) %>% 
  top_n(10) %>% 
  rename(servings = !!quo_col)
}

beer    <- top10(raw_df, beer_servings)
spirit  <- top10(raw_df, spirit_servings)
wine    <- top10(raw_df, wine_servings)

#beer    <- top10(raw_df, beer_servings) %>% mutate(alcohol = ""Beer"")
#spirit  <- top10(raw_df, spirit_servings) %>% mutate(alcohol = ""Spirit"")
#wine    <- top10(raw_df, wine_servings) %>% mutate(alcohol = ""Wine"")

alcohol <- bind_cols(beer, spirit, wine) %>% as.data.frame()
rownames(alcohol) <- paste0("" "", 1:10)
```

#### Who Drinks The Most Beer, Spirit, And Wine?  
#### `tableGrob`   
```{r tableGrob, message = F, warning = F}
library(grid)
library(gridExtra)
rownames(beer) <- paste0("" "", 1:10)
t1 <- tableGrob(beer,   cols = c("""", ""BEER""))
t2 <- tableGrob(spirit, cols = c("""", ""SPIRIT""), rows = NULL)
t3 <- tableGrob(wine,   cols = c("""", ""Wine""),  rows = NULL)
grid.arrange(t1, t2, t3, widths = c(10, 9, 9),
             top = textGrob('Top 10 countries by servings consumed per person, 2010',
                            gp = gpar(fontsize = 16),
                            hjust = 0.55,  vjust = 5)
             )

```

##### `kableExtra`  
```{r kableExtra}
alcohol %>% 
  kable(""html"", caption = ""Top 10 counties by servings consumed per person, 2010"",
        col.names = c("""", ""BEER"", """", ""SPIRIT"", """", ""WINE"")) %>% 
  kable_styling(""striped"", full_width = F, position = ""left"") 
```


","Other-13"
"886",1704,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week14/Week14.Rmd","---
output: github_document
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(maps)
library(sf)
library(ggthemes)
library(patchwork)
```

#### Read in Data
```{r message = F, warning = F}
raw_df    <- read_csv(""../data/week14_global_life_expectancy.csv"")
# Get non-country rows
cont_code <- raw_df %>% filter(is.na(code)) %>% distinct(country) 
```

##### get world map data
```r
world1 <- sf::st_as_sf(map('world', plot = FALSE, fill = TRUE))
# update country names
map_df <- raw_df %>% 
  mutate(country = case_when(
    country == ""United States"" ~ ""USA"",
    country == ""United Kingdom"" ~ ""UK"",
    country == ""Democratic Republic of Congo"" ~ ""Democratic Republic of the Congo"",
    country == ""Congo"" ~ ""Republic of the Congo"",
    TRUE ~ country)) %>% 
  filter(!is.na(code)) %>% 
  left_join(world1, by = c(""country"" = ""ID"")
```

##### Problem using st_as_sf with non-closed polygons
```r
# https://github.com/r-spatial/sf/issues/430
worldmap <- st_as_sf(rworldmap::getMap())
```

```{r worldmap}
#ggplot() + geom_sf(data = world1)
worldmap <- rnaturalearth::ne_download(scale = 110,
                                       type = ""countries"",
                                       category = ""cultural"",
                                       destdir = tempdir(),
                                       load = TRUE,
                                       returnclass = ""sf"") %>% 
  select(SOVEREIGNT, SOV_A3, ADMIN, ADM0_A3, geometry)

```

##### Join raw_df and worldmap
```{r}
# data countries not in the worldmap
cnty1 <- raw_df %>% 
  filter(!is.na(code)) %>% 
  anti_join(worldmap, by = c(""code"" = ""ADM0_A3"")) %>% 
  distinct(country)

# worldmap countries not in the data
cnty2 <- worldmap %>% 
  anti_join(raw_df, by = c(""ADM0_A3"" = ""code"")) %>% 
  as_tibble() %>% 
  distinct(ID)

map_df <- raw_df %>% 
  filter(!is.na(code)) %>% 
  left_join(worldmap, by = c(""code"" = ""ADM0_A3""))
```

#### Life expectancy, 2015  
```{r life 2015, fig.width = 10, message = F, warning = F}
library(scico)
library(hrbrthemes)
library(glue)
year1 <- 2015
p <- map_df %>% 
  filter(year == year1) %>% 
  ggplot() +
  geom_sf(aes(fill = life_expectancy)) + 
  scale_fill_scico(palette = ""vik"", na.value = ""grey50"") +
  labs(title = glue(""Life expectancy, {year1}""), 
       subtitle = ""Shown in the period of life expectancy at birth. This corresponds to the average estimate a newborn\ninfant would live if prevailing patterns of mortality at the time of birth were to stay the same throughout its life."",
       caption = ""Source: Clio-Infra estimates until 1949; UN Population Division from 1950 to 2015"",
       fill = ""Life\nExpectancy"") + 
  theme_ipsum() + 
  theme(plot.title = element_text(size = 18),
        plot.subtitle = element_text(size = 12),
        axis.title = element_blank(),
        axis.text = element_blank(), 
        panel.background = element_rect(fill = ""grey95"", color = NA), 
        plot.background = element_rect(fill = ""grey95"", color = NA))
p
ggsave(""life2015.png"", p, dpi = 300)
```

#### Animation from 1950 to 2015   
* modified from [dylanjm GitHub](https://github.com/dylanjm/tidy_tuesday/blob/master/tidy_14/tidy_14.R}   
```{r Animation, message = F, warning = F}
library(animation)
library(gganimate)

g <- map_df %>% 
  filter(year %in% seq(1950, 2015, 5)) %>% 
  ggplot(aes(frame = year)) +
  geom_sf(aes(fill = life_expectancy)) + 
  scale_fill_scico(palette = ""vik"", na.value = ""grey50"") +
  labs(title = ""Life expectancy,"", 
       subtitle = ""Shown in the period of life expectancy at birth. This corresponds to the average estimate a newborn\ninfant would live if prevailing patterns of mortality at the time of birth were to stay the same throughout its life."",
       caption = ""Source: Clio-Infra estimates until 1949; UN Population Division from 1950 to 2015"",
       fill = ""Life\nExpectancy"") + 
  theme_ipsum() + 
  theme(plot.title = element_text(size = 18),
        plot.subtitle = element_text(size = 12),
        axis.title = element_blank(),
        axis.text = element_blank(), 
        panel.background = element_rect(fill = ""grey95"", color = NA), 
        plot.background = element_rect(fill = ""grey95"", color = NA))


animation::ani.options(interval = 1/8)
gganimate(g, ""life_expectancy.gif"", title_frame = T, ani.width = 1200,ani.height = 800)
```


","Other-14"
"887",1706,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week15/Week15.Rmd","---
output: github_document
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(readxl)
library(ggthemes)
```

#### Read in Data
```{r message = F, warning = F}
file15    <- ""../data/week15_beers.xlsx""
excel_sheets(file15)
beer_df   <- read_xlsx(file15, 1)
brewer_df <- read_xlsx(file15, 2)

raw_df    <- left_join(beer_df, brewer_df, by = c(""brewery_id"" = ""id"")) %>% 
  mutate(abv = abv * 100)

beer5 <- raw_df %>% count(style) %>% arrange(desc(n)) %>% top_n(5) 
st_beer5 <- crossing(distinct(raw_df, state), beer5)

st_df <- raw_df %>% 
#  right_join(beer5) %>% 
  group_by(state, style) %>% 
  summarize(count = n()) %>% 
  right_join(st_beer5) %>% 
  arrange(state, desc(count)) %>% 
  slice(1:5) %>% 
  mutate(style = case_when(style == ""American Double / Imperial IPA"" ~ ""A D/I IPA"",
                           style == ""American Blonde Ale"" ~ ""ABA"",
                           style == ""American Amber / Red Ale"" ~ ""A A/R A"",
                           style == ""American Pale Ale (APA)"" ~ ""APA"",
                           style == ""American IPA"" ~ ""A IPA"")) %>% 
  {.}
```

### `geofacet` map
```{r geofacet, message = F, warning = F, fig.height = 6, fig.width = 10}
library(geofacet)
p1 <- st_df %>% 
  ggplot(aes(style, count)) + 
  geom_col() +
  coord_flip() +
  facet_geo(~ state) +
  theme_bw() +
  labs(title = ""Numbers of Top 5 nationally most popular beer styles in each state"",
       caption = ""Source: Craft Beer USA""  ) +
  NULL
p1
ggsave(""top5_state.png"", p1, dpi = 300)
```

### _ABV_ Density ridge
```{r ridge, message = F, warning = F, fig.height = 8, fig.width = 10}
library(ggridges)
library(viridis)
library(forcats)
beer10 <- raw_df %>% count(style) %>% arrange(desc(n)) %>% top_n(5) 
p2 <- raw_df %>% 
  filter(style %in% beer5$style) %>% 
  ggplot(aes(x =  abv, y = fct_rev(style), fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis(name = ""ABV"", option = ""%"") + 
  theme_minimal() +
  labs(title = ""Alcohol by Volume (ABV) of Top 5 most popular beer styles"",
       x = ""Alcohol by volume (%)"",
       y = ""Craft Beer Style"",
       caption = ""Source: Craft Beer USA""  ) +
  NULL
p2  
ggsave(""top5_ridge.png"", p2, dpi = 300)
```


### Scatter _ABV_ vs _IBU_
```{r Scatter, message = F, warning = F, fig.height = 8, fig.width = 10}
library(ggridges)
library(viridis)
library(forcats)
p3 <- raw_df %>% 
  filter(style %in% beer5$style) %>% 
  select(abv, ibu, style) %>% 
  drop_na() %>% 
  ggplot() + 
  geom_jitter(aes(x = abv, y = ibu, color = style), 
              size = 3, alpha = 0.8, width = 0.1, height = 1) +
  scale_color_brewer(palette = ""Dark2"")  + 
  theme_minimal() +
  theme(legend.position=""right"") +
  labs(title = ""Bitterness (IBU) and Alcohol Content (ABV)"",
       x = ""Alcohol by volume (%)"", 
       y = ""Bitterness (International Bitterness Units)"", 
       color=""Craft beer styles"",
       caption = ""Source: Craft Beer USA""  ) +
  NULL
p3  
ggsave(""top5_scatter.png"", p3, dpi = 300)
```

### Panel grid
```{r patchwork, fig.height = 8, fig.width = 10}
library(patchwork)
#p1 + {p2 + p3 + plot_layout(ncol = 2)} + plot_layout(ncol = 1)
```

","Other-15"
"888",1708,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week16/Week16.Rmd","---
output: github_document
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(readxl)
library(ggthemes)
```

#### Read in Data
```{r message = F, warning = F}
file16    <- ""../data/week16_exercise.xlsx""
excel_sheets(file16)
source_df <- read_xlsx(file16, 1)
tidy_df   <- read_xlsx(file16, 2) %>% mutate(exercise = as.numeric(exercise))
```

##### US State Maps 
```{r worldmap, message = F, warning = F}
#ggplot() + geom_sf(data = world1)
conus    <- rnaturalearth::ne_download(scale = 110,
                                       type = ""states"",
                                       category = ""cultural"",
                                       destdir = tempdir(),
                                       load = TRUE,
                                       returnclass = ""sf"") %>% 
  filter(!postal %in% c(""HI"", ""AK"")) %>% 
  select(woe_name, postal, region, region_sub, geometry)
```

#### US State Maps with Hawaii and Alaska adjusted  
```{r}
library(albersusa)
usmap <- usa_sf(""laea"")%>% 
  mutate(st = iso_3166_2) %>% 
  select(name, st, geometry)
work_sf <- inner_join(tidy_df, usmap, by = c(""state"" = ""name"")) 
```

#### Join
```{r fig.width = 10, fig.height = 15}
library(scico)
library(hrbrthemes)
p <- work_sf %>% 
  filter(sex != ""both"") %>% 
  ggplot() +
  geom_sf(aes(fill = exercise)) +
# https://github.com/tidyverse/ggplot2/issues/2071
  coord_sf(datum = NA) +  # no graticules
  scale_fill_scico(palette = ""vik"", na.value = ""grey50"") +
  facet_grid(work_status ~ sex) +
  theme_ipsum() + 
  theme(axis.title = element_blank(),
        axis.text = element_blank(),
        panel.grid = element_blank(),
        legend.position = ""bottom"") +
  labs(title = ""Adults 18-64 of aerobic and muscle-strengthening"",
       caption = ""Source: CDC - National Health Statistics Reports""  )+
  NULL
p
ggsave(""exercise.png"", p, dpi = 300)
```

","Other-16"
"889",1710,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week18/Week18.Rmd","---
output: github_document
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(readxl)
library(ggthemes)
```

#### Read in Data
```{r message = F, warning = F}
raw_df <- read_excel(""../data/week18_dallas_animals.xlsx"")
```

```{r}
dist_df <- raw_df %>% 
  group_by(council_district)
```

# Pie Chart
[Adding percentage labels on pie chart in R](https://stackoverflow.com/a/41340766/9421451) from StackOverflow. 
```{r message = F, warning = F, fig.width = 5, fig.height = 6}
library(ggrepel)
library(scales)
pie <- raw_df %>% 
  count(animal_type) %>% 
  mutate(perc = percent(n/sum(n))) %>% 
  arrange(desc(n)) %>% 
  filter(animal_type != ""LIVESTOCK"") %>% 
  ggplot(aes(x = """", y = n, fill = fct_reorder(animal_type, desc(n)))) +
  geom_bar(width = 1, stat = ""identity"") + 
  coord_polar(theta = ""y"") +
# https://stackoverflow.com/a/41340766/9421451
  geom_label_repel(aes(label = paste0(animal_type, "" "", perc)), 
                   size = 5, show.legend = F, nudge_x = 1) +
  theme_void() +
  theme(legend.position = ""bottom"") +
  labs(y = NULL,
       fill = ""Animal Type"")
pie
ggsave(""pie.png"", pie, dpi = 300)
```


","Other-18"
"890",1712,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week19/Week19.Rmd","---
output: github_document
always_allow_html: yes
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(ggthemes)
```

#### Read in Data
```{r message = F, warning = F}
raw_df <- read_csv(""../data/week19_airline_safety.csv"") %>% 
  select(-X1)
```

### `spared()` with one column
```{r}
sp_df <- raw_df %>% 
  filter(type_of_event == ""fatalities"") %>% 
  select(airline, year_range, n_events) %>% 
  # spread the year_range column
  spread(year_range, n_events) %>% 
  rename(a = `85_99`, b = `00_14`) %>% 
  mutate(c = (a + b)/2) %>% 
  bind_cols(select(raw_df, avail_seat_km_per_week) %>% distinct()) 
```

### `spared()` with two columns
#### Method 1
```{r}
sp_df1 <- raw_df %>% 
  # First, unite two columns
  unite(year_type, c(""year_range"", ""type_of_event"")) %>% 
  # Second, spread the united columns
  select(airline, year_type, n_events) %>% 
  spread(year_type, n_events) %>% 
  bind_cols(select(raw_df, avail_seat_km_per_week) %>% distinct()) 
sp_df1
```


#### Method 2
```{r}
sp_df2 <- raw_df %>% 
  # Since there are two `index` columns
  # Combine those two columns
  unite(airline_km, c(""airline"", ""avail_seat_km_per_week"")) %>% 
  unite(year_type, c(""year_range"", ""type_of_event"")) %>% 
  spread(year_type, n_events) %>% 
  separate(airline_km, c(""airline"", ""km""), sep = ""_"") %>% 
  mutate(km = as.numeric(km))
sp_df2
```

### Table 
```{r}
library(knitr)
library(kableExtra)
options(knitr.table.format = ""html"")

sp_df2[, c(1, 2, 8, 6, 7, 5, 3, 4)] %>% 
  mutate(km = round(km / 1e6)) %>% 
  kable(col.names = c(""AIRLINE"", ""AVAILABLE\nSEAT KM\nPER WEEK"",
                      ""INCIDENTS"", ""FATAL\nACCIDENTS"", ""FATALITIES"",
                      ""INCIDENTS"", ""FATAL\nACCIDENTS"", ""FATALITIES"")) %>% 
  kable_styling(""striped"") %>% 
  add_header_above(c("" "" = 1,
                     "" "" = 1,
                     ""1985-1999"" = 3,
                     ""2000-2014"" = 3))
```

","Other-19"
"891",1714,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week20/Week20.Rmd","---
output: github_document
always_allow_html: yes
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(ggthemes)
```

#### Read in Data
##### `data.table`
```{r}
library(data.table)
files <- list.files(path = ""../data/week20/"", pattern = ""*.csv"", full.names = T)
DT <- do.call(rbind, lapply(files[-5], fread))
```

##### file 05
```{r message = F, warning = F}
#df04 <- read_csv(""../data/week20/IRAhandle_tweets_04.csv"")
#df05 <- read_csv(""../data/week20/IRAhandle_tweets_05.csv"", 
#                 col_types = ""dcccccciiicciciddcccc"")
#dfna <- df05 %>% filter(is.na(external_author_id)) %>% knitr::kable()
```

#### Number of tweets group_by account_category
```{r}
DT %>% 
  count(account_category) %>% 
  arrange(desc(n))
```

#### Tweets by Day
```{r fig.width=10, fig.height=6}
library(lubridate)
dday <- DT %>% 
  select(publish_date, account_category) %>% 
  mutate(publish_date = mdy_hm(publish_date),
         date = date(publish_date))
nday <- dday %>% count(account_category, date) 
tday <- dday %>% count(date) %>% mutate(account_category = ""Total"") %>% 
  select(account_category, date, n)

cday <- bind_rows(tday, nday)

p0 <- tday %>% 
  filter(date > ymd(""2015-07-01""),
         date < ymd(""2018-01-01"")) %>% 
  ggplot(aes(x = date, y = n)) +
  geom_bar(stat = ""identity"", fill=""orange"") +
  theme_fivethirtyeight() +
  labs(title = ""Russian troll tweets by day"",
       subtitle = ""Nearly 3 million tweets sent by trolls"",
       caption = ""Source: FiveThirtyEight"") +
  NULL
p0
ggsave(""total.png"", p0, width = 6, height = 4, dpi = 300)
```

#### Tweets by Day by account_category
```{r fig.width=10, fig.height=8}
library(gghighlight)
library(forcats)
cat4 <- c(""RightTroll"", ""LeftTroll"", ""NewsFeed"", ""HashtagGamer"")
lab4 <- c(""Right Troll"", ""Left Troll"", ""News Feed"", ""Hashtag Gamer"")

df4 <- DT %>% 
  select(publish_date, account_category) %>% 
  mutate(publish_date = mdy_hm(publish_date),
         date = date(publish_date)) %>% 
  filter(account_category %in% cat4) %>% 
  mutate(account_category = factor(account_category,
                                   levels = cat4,
                                   labels = lab4)) %>% 
  filter(date > ymd(""2015-07-01""),
         date < ymd(""2018-01-01"")) 
p1 <- df4 %>% 
  ggplot(aes(date, fill = account_category)) +
  geom_histogram(binwidth = 1) +
  theme_fivethirtyeight() +
  labs(title = ""Not all trolls are the same"",
       subtitle = ""Tweets sent by trolls, as categorized by Clemson Researchs"",
       caption = ""Source: FiveThirtyEight"") +
  NULL
p2 <- p1 + gghighlight() +
  facet_wrap(~ account_category)
p2
ggsave(""cat4.png"", p2, width = 6, height = 6, dpi = 300)
```

","Other-20"
"892",1716,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week21/Week21.Rmd","---
output: github_document
always_allow_html: yes
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(magrittr)
library(ggthemes)
```

#### Read in Data
```{r message = F, warning = F}
raw_df <- read_csv(""../data/2018-08-21/week21_calfire_frap.csv"")
```
    
#### Scrape the table from website  
Cause coding: [Cause Code	Description](http://frap.fire.ca.gov/projects/fire_data/fire_perimeters_data_description)
```{r message = F, warning = F}
library(rvest)
raw_web <- read_html(""http://frap.fire.ca.gov/projects/fire_data/fire_perimeters_data_description"")

fire_cause <- raw_web %>% 
  html_nodes(""table"") %>% 
  extract2(5) %>% 
  html_table(header = T) %>% 
  rename(cause = `Cause Code`)
```

```{r fig.width=10}
library(forcats)
fire_df <- left_join(raw_df, fire_cause) %>% 
  mutate(Description = if_else(is.na(cause), 
                               ""Unknown/Unidentified"", 
                               Description))
p1 <- fire_df %>% 
  count(Description, fire_cause) %>% 
  arrange(desc(n)) %>% 
  ggplot(aes(x = fct_reorder(Description, n), y = n, fill = fire_cause)) +
  geom_bar(stat = ""identity"") +
  coord_flip() + 
  theme_minimal() +
  labs(title = ""Californias Wildfires"",
       y = ""Number"",
       x = ""Fire Cause"",
       caption = ""Source: frap.fire.ca.gov"") +
  guides(fill = guide_legend(title = ""Fire Cause"")) +
  NULL
p1
```

> Modified from [BuzzFeedNews/2018-07-wildfire-trends](https://github.com/BuzzFeedNews/2018-07-wildfire-trends/blob/master/index.Rmd) by [Peter Aldhous](https://github.com/paldhous)  

```{r fig.width=10, fig.height=8}
p2 <- fire_df %>% 
  ggplot() +
  geom_point(aes(x = plot_date, y = year_, size = gis_acres, 
                 color=""#ffa500"", alpha = 0.7)) +
  geom_hline(yintercept = seq(1950, 2017, by = 1), color = ""gray"", size = 0.05) +
  scale_size_area(max_size = 10, guide = FALSE) +
  scale_x_date(date_breaks = ""months"", date_labels = ""%b"") +
  scale_y_reverse(limits = c(2017, 1950), breaks = c(2010, 1990, 1970, 1950)) +
  labs(x = NULL, y = NULL) +
  theme_hc(style = ""darkunica"", base_size = 20) +
  theme(axis.text = element_text(color = ""#ffffff"")) + 
  theme(legend.position = ""none"") +
  NULL
p2
```

#### two panels
```{r fig.width=10, fig.height=8}
library(gganimate)
cause_pal <- data.frame(fire_cause = c(""Human"", ""Natural"", ""Unknown""),
                        fire_col = c(""#ffff00"",""#d397fc"",""#ffffff""))
pp <- fire_df %>% 
  left_join(cause_pal) %>% 
  ggplot(aes(frame = fire_cause)) +
  geom_point(aes(x = plot_date, y = year_, size = gis_acres, 
                 color = fire_col, alpha = 0.7)) +
  geom_hline(yintercept = seq(1950, 2017, by = 1), color = ""gray"", size = 0.05) +
  scale_size_area(max_size = 10, guide = FALSE) +
  scale_x_date(date_breaks = ""months"", date_labels = ""%b"") +
  scale_y_reverse(limits = c(2017, 1950), breaks = c(2010, 1990, 1970, 1950)) +
  labs(x = NULL, y = NULL) +
  theme_hc(style = ""darkunica"", base_size = 20) +
  theme(axis.text = element_text(color = ""#ffffff"")) + 
  theme(legend.position = ""none"") +
  NULL
pp

animation::ani.options(interval = 1)
gganimate(pp, ""fire_cause.gif"", title_frame = T, ani.width = 1200, ani.height = 800)
```

#### `gganimate`

","Other-21"
"893",1718,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week22/Week22.Rmd","---
output: github_document
always_allow_html: yes
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(magrittr)
library(ggthemes)
```

#### Read in Data
```{r message = F, warning = F}
raw_df <- read_csv(""../data/2018-08-28/nfl_2010-2017.csv"") %>% select(-1)
```

#### Mean rushing (passing) per Week    
```{r}
ari_df <- raw_df %>% 
  filter(team == ""ARI"")

avg_df <- raw_df %>% 
  group_by(team, game_year, game_week) %>% 
  summarise(rush_total = sum(rush_yds, na.rm = T),
            pass_total = sum(pass_yds, na.rm = T)) %>% 
  group_by(game_year, game_week) %>% 
  summarise(rush_mean = mean(rush_total, na.rm = T),
            pass_mean = mean(pass_total, na.rm = T)) 
```

#### Tile plot
```{r}
library(scico)

plot_tile <- function(df, var, ttext) {
  quo_var = enquo(var)
  ggplot(df, aes(game_year, game_week)) +
  geom_tile(aes(fill = !!quo_var), colour = ""grey50"") +
  scale_fill_scico() +
  scale_x_continuous(limits = c(1999.5, 2017.5), expand = c(0, 0),
                     breaks = seq(2000, 2016, by = 2)) +
  scale_y_continuous(limits = c(0.5, 16.5), expand = c(0, 0),
                     breaks = 1:16) + 
  labs(title = ttext, x = ""Year"", y = ""Week"") +
  guides(fill = guide_legend(title = ""Rush Yards"")) +
  theme_bw() + 
  theme(panel.grid = element_blank(), panel.border = element_blank()) +
  NULL
}

p1 <- avg_df %>% 
  plot_tile(rush_mean, ""Mean Rushing Yards Per Week"")
p2 <- avg_df %>% 
  plot_tile(pass_mean, ""Mean Passing Yards Per Week"")
```
#### Panel plot
```{r fig.width=10, fig.height=12}
library(patchwork)
p1 + p2 + plot_layout(ncol = 1)
```

#### Mean rushing (passing) per year
```{r}
avg_year_df <- raw_df %>% 
  group_by(team, game_year, game_week) %>% 
  summarise(rush_total = sum(rush_yds, na.rm = T),
            pass_total = sum(pass_yds, na.rm = T)) %>% 
  group_by(game_year) %>% 
  summarise(rush_mean = mean(rush_total, na.rm = T),
            pass_mean = mean(pass_total, na.rm = T)) 
```

#### Line plot
```{r fig.width=10}
avg_year_df %>% 
  ggplot() +
  geom_line(aes(x = game_year, y = rush_mean, color = ""blue""), size = 2) +
  geom_line(aes(x = game_year, y = pass_mean, color = ""red""), size = 2) +
  scale_x_continuous(limits = c(2000, 2017), expand = c(0, 0),
                     breaks = seq(2000, 2016, by = 2)) +
  scale_y_continuous(limits = c(25, 275), expand = c(0, 0),
                     breaks = seq(25, 275, by = 25)) +
#  theme(panel.grid = element_blank(), panel.border = element_blank()) +
  labs(title = ""Trends in NFL Rushing and Passing Yards per Team Game"", 
       x = ""Year"", y = ""Team Yards per Game"",
       caption = ""Source: Pro-Football-Reference.com"") +
  NULL
```


","Other-22"
"894",1720,"https://github.com/ChuliangXiao/tidytuesday","ChuliangXiao","tidytuesday","Week23/Week23.Rmd","---
output: github_document
always_allow_html: yes
---
#### Load library
```{r message = F, warning = F}
library(tidyverse)
library(magrittr)
library(ggthemes)
```

#### Read in Data
```{r message = F, warning = F}
raw_df <- read_csv(""../data/2018-09-04/fastfood_calories.csv"")
```
    
","Other-23"
"895",1725,"https://github.com/corybrunson/tidytuesday","corybrunson","tidytuesday","week19/week19.rmd","---
title: """"
author: ""Cory Brunson""
date: ""2018 Aug 7""
output: html_document
---

# Motivation

In [his article](https://fivethirtyeight.com/features/should-travelers-avoid-flying-airlines-that-have-had-crashes-in-the-past/), Nate Silver explored different ways of assessing an airline's future risk of deadly (or near-deadly) incidents from past performance. His analysis is a valuable corrective to the reflexive reaction many of us have toward high-profile crashes. Moreover, his takeaway that safety concerns should, if anything, motivate us to avoid airlines maintained in developing countries reminds us the most familiar explanations for catastrophes---lack of financial, cultural, and political resources---are familiar for good reason.

Silver's takeaway visualization compared home countries' GDP and airlines' safety scores along parallel one-dimensional diverging-color tilings. He stakes the claim that these scores---averages of standardizations of the original measures---provide a more valuable measure of each airline's relative safety performance.

One of the admittedly nice things about these visuals is that they don't require legends---people can usually intuit the meanings of the deeper versus fainter colors and between the extremes. (Shoutout to [ColorBrewer](http://colorbrewer2.org/), [ColorOracle](http://www.colororacle.org/), and other tools to facilitate colorblind figures!)

My personal preference is to preserve as much quantitative information as possible, so i'd like to be sold this message using a more boring scatterplot.
I'd also like to see whether the safety scores themselves are predictive from the earlier interval to the latter, so i'll calculate them separately and take them to be the coordinate axes.

# Production

Here's the setup:

```{r setup}
if (! ""fivethirtyeight"" %in% rownames(installed.packages())) {
  install.packages(""fivethirtyeight"")
}
data(airline_safety, package = ""fivethirtyeight"")
library(tidyverse)
```

The data is already thoroughly processed, but Silver's custom _airline safety score_ has not already been caculated. I'll calculate these scores using **dplyr** and produce the scatterplot using **ggplot2**. I'll also take advantage of the variable naming scheme to restructure the data using **tidyr**, slightly reducing repetitiveness.[^dry] In order to more easily test the incomplete analysis pipeline along the way, i'll connect these steps with **magrittr** pipes.

[^dry]: I recently learned that software developers use the initialism ""DRY""---_don't repeat yourself_. The reason for doing this isn't that it saves time in this particular case, of course---there are only three measures---but that it lowers the ceiling on future time expenditure by allowing additional variables to be added to the dataset without overhauling the script.

```{r calculate safety scores}
airline_safety %>%
  # restructure variables
  gather(""variable"", ""value"", ends_with(""_85_99""), ends_with(""_00_14"")) %>%
  mutate(variable = str_replace(variable, ""([a-z])_([0-9])"", ""\\1___\\2"")) %>%
  separate(""variable"", c(""measure"", ""interval""), sep = ""___"") %>%
  # calculate airline safety scores
  group_by(measure) %>%
  mutate(meas_mean = mean(value), meas_cent = meas_mean - value) %>%
  # note: must include `measure` again here
  mutate(meas_mult = meas_cent * sqrt(avail_seat_km_per_week)) %>%
  mutate(meas_std = (meas_mult - mean(meas_mult)) / sd(meas_mult)) %>%
  ungroup() %>%
  # note: remove `value` to avoid confusion (`NA`s)
  select(-value, -meas_mean, -meas_cent, -meas_mult) ->
  airline_std
```

```{r reorganize data}
airline_std %>%
  # generate scatterplots of safety scores
  spread(interval, meas_std) %>%
  rename_at(vars(matches(""[0-9]{2}_[0-9]{2}"")), funs(paste0(""std_"", .))) %>%
  # average standardized scores across all three measures
  group_by(airline) %>%
  summarize_at(c(""std_85_99"", ""std_00_14""), mean) %>%
  ungroup() ->
  airline_scores
```

```{r generate scatterplots}
airline_scores %>%
  ggplot(aes(x = std_85_99, y = std_00_14, label = airline)) +
  theme_bw() +
  coord_fixed() +
  geom_abline(slope = 1, intercept = 0, linetype = ""dashed"") +
  labs(x = ""1985-99"", y = ""2000-14"") +
  geom_point(alpha = .5) +
  ggtitle(""Safety scores: first versus second interval"") ->
  airline_scatterplot
print(airline_scatterplot)
```

# Conclusion

My immediate takeaway is that, though the safety score integrates all three intuitive measures of safety, it doesn't completely resolve the outlier problem Silver mentioned in his article: The airlines that experienced exceptional numbers of incidents or casualties expand farther into Quadrant III instead of I, but they're still conspicuous, and they still make the correlation more difficult to detect. Nevertheless, it's easy to see that, after (or even after) the outliers are removed, the bulk of data points display a clear correlation---in contrast to the original separate measures. I'm convinced!

Finally, here's a JPEG to post on Twitter:

```{r save scatterplot}
ggsave(""airline-scatterplot.jpg"", airline_scatterplot, height = 4, width = 7)
```
","Other-19"
"896",1728,"https://github.com/fflores97/tidy_tuesday/blob/master/Week_16/Week_16.R","fflores97","tidy_tuesday","Week_16/Week_16.R","
# Load packages -------------------------------------------------------------------------------

library(tidyverse)
library(readxl)

# Import data ---------------------------------------------------------------------------------

data <- readxl::read_xlsx(""week16_exercise.xlsx"") %>%
  # slice(-1) %>% 
  select(-count) %>% 
  type_convert()

# Tidy data -----------------------------------------------------------------------------------

data_tidy <- data %>% 
  select(state, men_working, men_nonworking, women_working, women_nonworking) %>% 
  gather(key = ""class"", value = ""value"", -state) %>% 
  na.omit() %>% 
  separate(col = class, into = c(""Gender"",""Working"")) 


# Plot 1: Differences in gender, working ------------------------------------------------------

data_tidy %>% 
  filter(Working == ""working"") %>% 
  arrange(desc(Gender)) %>% 
  ggplot(aes(x = value, y = reorder(state, value)))+
  geom_line(aes(group = state))+
  geom_point(aes(color = Gender), size = 4)+
  scale_color_hue(direction = -1, h.start = 150)+ # For some reason men were shown pink, kinda confusing
  theme_minimal()+
  labs(title = ""Exercise differences between genders (Working)"",
       # subtitle = """",
       x = ""Percentage of adults who meet federal guidelines"",
       y ="""")
ggsave(filename = ""plot1.png"", width = 7, height = 7)

# Plot 2: Differences in gender, non-working --------------------------------------------------

data_tidy %>% 
  filter(Working == ""nonworking"") %>% 
  arrange(desc(Gender)) %>% 
  ggplot(aes(x = value, y = reorder(state, value)))+
  geom_line(aes(group = state))+
  geom_point(aes(color = Gender), size = 4)+
  scale_color_hue(direction = -1, h.start = 150)+ # For some reason men were shown pink, kinda confusing
  theme_minimal()+
  labs(title = ""Exercise differences between genders (Working)"",
       # subtitle = """",
       x = ""Percentage of adults who meet federal guidelines"",
       y ="""")
ggsave(filename = ""plot2.png"", width = 7, height = 7)

# Plot 3: Differences in work status, men -----------------------------------------------------

data_tidy %>% 
  filter(Gender == ""men"") %>% 
  arrange(desc(Gender)) %>% 
  ggplot(aes(x = value, y = reorder(state, value)))+
  geom_line(aes(group = state))+
  geom_point(aes(color = Working), size = 4)+
  scale_color_hue(direction = 1, h.start = 150)+ # For some reason men were shown pink, kinda confusing
  theme_minimal()+
  labs(title = ""Exercise differences between working status (Men)"",
       # subtitle = """",
       x = ""Percentage of adults who meet federal guidelines"",
       y ="""")
ggsave(filename = ""plot3.png"", width = 7, height = 7)

# Plot 4: Differences in work status, women ---------------------------------------------------

data_tidy %>% 
  filter(Gender == ""women"") %>% 
  arrange(desc(Gender)) %>% 
  ggplot(aes(x = value, y = reorder(state, value)))+
  geom_line(aes(group = state))+
  geom_point(aes(color = Working), size = 4)+
  scale_color_hue(direction = 1, h.start = 150)+ # For some reason men were shown pink, kinda confusing
  theme_minimal()+
  labs(title = ""Exercise differences between working status (Men)"",
       # subtitle = """",
       x = ""Percentage of adults who meet federal guidelines"",
       y ="""")
ggsave(filename = ""plot4.png"", width = 7, height = 7)


data_tidy %>% 
  # spread(key = ""Women"", value = ""value"", Working, value)
  ggplot(aes(x = value, y = reorder(state, value)))+
  # geom_line(aes(group = interaction(state, Gender)))+
  geom_line(aes(group = interaction(state, Gender)))+
  # geom_line(aes(group = state))+
  geom_point(aes(color = Gender, shape = Working), size = 4)+
  theme_minimal()+
  labs(title = ""Exercise differences between working status (Men)"",
       # subtitle = """",
       x = ""Percentage of adults who meet federal guidelines"",
       y ="""")
ggsave(""plot5.png"", width=7,height=7)


# For map plotting ----------------------------------------------------------------------------

# From https://github.com/jasonong/List-of-US-States/blob/master/states.csv
state_symbols <- read_csv(""states.csv"") %>% 
  rename(state = State) %>% 
  rename(state_short = Abbreviation)

data <- data %>% 
  inner_join(state_symbols) %>% 
  mutate(diff_working = men_working - women_working) %>% 
  mutate(diff_nonworking = men_working - women_working)
usmap::plot_usmap(data = data, regions = ""state"", values = ""diff_working"") +
  scale_fill_gradientn(values=c(-2,0,16), colours = c(""red"", ""white"", ""blue""))
","Other-16"
"897",1734,"https://github.com/cteitel/tidy_tuesday/blob/master/tidytuesday0424.R","cteitel","tidy_tuesday","tidytuesday0424.R","library(ggplot2)
library(dplyr)
library(tidyr)

dats <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week4_australian_salary.csv"")
names(dats)
head(dats)

employ <- arrange(dats , desc(average_taxable_income))
employ <- mutate(employ,
                 rank_new = ifelse(gender == ""Female"" , gender_rank + 0.4 , gender_rank))
employH <- filter(employ , gender_rank <= 10)
employL <- filter(employ , gender_rank >= (max(gender_rank)-20))

employWide = select(employ[employ$individuals>1000,] 
                    , gender , occupation , average_taxable_income)
employWide = spread(employWide , gender , average_taxable_income)
employWide = mutate(employWide , 
                    mean_salary = (Male+Female)/2,
                    salary_diff = Male - Female,
                    salary_gain = (Male-Female)/Male)
employWide = filter(employWide , !is.na(salary_diff))
employWide = arrange(employWide , desc(salary_diff))


p <- ggplot(employWide , aes(x = (mean_salary) , y = log10(abs(salary_gain*100)) * sign(salary_gain))) +
  theme_classic()+
  theme(legend.position = c(.99,.01) , legend.justification = c(""right"",""bottom""),
        legend.background = element_rect(linetype = 2 , colour = 1)) +
  geom_point(aes(color = abs(salary_diff))) +
  scale_colour_gradient2(low = ""blue"",mid = ""grey"",high = ""red"" ,name=""Absolute diff. \nin income"") +
  geom_line(aes(y = 0)) +
  scale_y_continuous(name = ""Males make _% of female income"" , breaks = c(-1.48,-1,0,1,1.48) , labels = c(70,90,100,110,130)) +
  # scale_x_continuous(name = ""Average income"" , breaks = c(4.18,4.477,4.7,5,5.255) , 
  #                    labels = paste(round(10^ c(4.18,4.477,4.7,5,5.255)/1000),""K"")) 
  scale_x_continuous(name = ""Average income"" , breaks = c(50,100,150,200)*1000 , labels = paste(c(50,100,150,200),""K"")) 
p



","Other-1"
"898",1735,"https://github.com/cteitel/tidy_tuesday/blob/master/tidytuesday0515.R","cteitel","tidy_tuesday","tidytuesday0515.R","library(tidyverse)
sw <- read.csv(""https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv"",
               header = F , stringsAsFactors = F)
#csv did not read with header b/c of question marks
#get questions and remove from dataset
questions <- as.character(sw[1,])
movies = as.character(sw[2,4:9])
sw = sw[-c(1:2),]

#separate out multiple-choice questions: movies seen
filmsSeen <- select(sw , c(1,4:9))
colnames(filmsSeen)[c(2:7)] <- apply(filmsSeen[,c(2:7)] , 2 , function(x) unique(x[x!=""""]))
filmsSeen <- mutate_at(filmsSeen , c(2:7) , function(x) x!="""")
#NOT used here

#separate out multiple-choice questions: favorite movies
favorites <- select(sw , c(1,11,34:38))
colnames(favorites) <- c(""ID"",""favorite"",questions[c(34:38)])
favorites <- filter(favorites , favorite != """" & Age!="""")
favorites <- mutate(favorites , favorite = as.numeric(favorite))
favorites <- mutate(favorites , faveName = movies[favorites$favorite])
favorites$Age = gsub(""> 60"" , ""60+"" , favorites$Age)


plot <- ggplot(aes(x = Age) , data = favorites) + 
  geom_bar(aes(fill = faveName) , position = ""fill"") + 
  theme_classic() +
  scale_fill_brewer(""Favorite movie"",palette = ""Set2"") +
  ylab(""Proportion"") +
  ggtitle(""Everyone Likes Episode V"") +
  theme(axis.text=element_text(size=11) , 
        axis.title=element_text(size=14),
        title=element_text(size=16))
plot
","Other-3"
"899",1736,"https://github.com/cteitel/tidy_tuesday/blob/master/tidytuesday0605.R","cteitel","tidy_tuesday","tidytuesday0605.R","library(tidyverse)
library(lubridate)
library(RColorBrewer)
library(gridExtra)

bikeRaw <- read_csv(""week10_biketown.csv"")

#http://w2.weather.gov/climate/local_data.php?wfo=pqr
weather <- read_csv(""Portland_dailyclimatedata.csv"" , skip = 6)

bike <- mutate(bikeRaw , bearing = atan((EndLongitude-StartLongitude)/(EndLatitude-StartLatitude)),
               StartDate = mdy(StartDate ))
bike <- mutate(bike , dow = wday(StartDate , label = T),
               durMins = minute(Duration),
               monthYear = format(as.Date(StartDate), ""%Y-%m""))

bikeDates <- group_by(bike , StartDate)
dateSummary <- summarize(bikeDates ,
                         StartTime = mean(StartTime , na.rm = T) ,
                         Distance = mean(Distance_Miles , na.rm = T),
                         count = n(),
                         Duration = median(Duration , na.rm = T))
dateSummary <- mutate(dateSummary , Duration = as.numeric(Duration)/60)

precip <- filter(weather , X3 == ""PR"")
weatherLong <- gather(precip , key = ""day"" , value = ""precip"" , ""1"":""31"")
weatherLong <- filter(weatherLong ,
                      YR %in% c(2016:2018))
weatherLong <- mutate(weatherLong , date = ymd(str_c(YR,MO,day,sep=""-"")),
                      precip = as.numeric(precip))

dateSummary <- left_join(dateSummary , weatherLong , c(""StartDate"" = ""date""))

p <- ggplot(dateSummary , aes(x = StartDate , y = count)) +
  geom_col(aes(fill = Duration)) +
  theme_classic(base_size = 14) +
  scale_fill_gradient2(""Median ride time (mins)"",low =  brewer.pal(8,""PiYG"")[8], mid = brewer.pal(8,""PiYG"")[4],high = brewer.pal(11,""PiYG"")[1],
                       midpoint = 15) +
  ylab(""Number of rides (per day)"") + xlab(""Date"") +
  scale_x_date(date_breaks = ""3 month"", date_labels =  ""%b %Y"") +
  # geom_col(aes(x = StartDate , y = -1 * precip*1000) , color = rgb(.2,.3,1)) +
  # scale_y_continuous(breaks = seq(0,3000,1000),
  #   sec.axis = sec_axis(~ . / (-1000) ,name = ""Precipitation (in)"",
  #          breaks = seq(0,2.2,.5)))+
  # geom_line(y=0) +
  theme(legend.position = c(0.95,0.95) , legend.justification = c(""right"",""top"") ,
        legend.direction = ""horizontal"" , legend.title=element_text(size=10),
        legend.text=element_text(size=8),
        plot.title = element_text(hjust = 0.5,size = 20,face=""bold""),
        #legend.box.background = element_rect(color = ""black""),
        #axis.text.y = element_text(color = brewer.pal(8,""PiYG"")[1]),
        axis.text.y.right = element_text(color = rgb(.2,.3,1))) +
  ggtitle(""Bike when it's dry!"")



p2 <- ggplot(dateSummary , aes(StartDate , y = precip))+
  geom_col( color = rgb(.2,.3,1)) +
  theme_classic(base_size = 14) +
  ylab(""Daily precipitation (in)"") + xlab(""Date"")+
  scale_x_date(date_breaks = ""3 month"", date_labels =  ""%b %Y"") 
  
  
grid.arrange(p,p2,nrow = 2)


","Other-4"
"900",1737,"https://github.com/cteitel/tidy_tuesday/blob/master/tidytuesday0501.R","cteitel","tidy_tuesday","tidytuesday0501.R","library(dplyr)
library(ggplot2)

acs = read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/acs2015_county_data.csv"",
               stringsAsFactors = F)
head(acs)

acs = arrange(acs , desc(Income))
acs_states = group_by(acs , State)

is.numeric_int = function(x) { is.numeric(x) | is.integer(x) }
acs_max = summarize_if(acs_states , is.numeric_int , c(""first"" , ""last"" , ""mean""))

acs_max = arrange(acs_max , Income_first)

p <- ggplot(acs_max) +
  geom_segment(aes(x = Income_first , xend = 0 , y = 1:nrow(acs_max) , yend = 1:nrow(acs_max),
                   color = Black_first) , size = 2) +
  geom_segment(aes(x = (-1) * IncomePerCap_last , xend = 0 , y = 1:nrow(acs_max) , yend = 1:nrow(acs_max),
               color =  Black_last), size = 2) +
  geom_point(aes(x = Income_first ,  y = 1:nrow(acs_max))) +
  geom_point(aes(x = (-1) * IncomePerCap_last ,  y = 1:nrow(acs_max) )) +
  scale_colour_gradient2(low = ""blue"",mid=""grey"",high = ""red"" ,name=""Percent black"",midpoint=12.3) +
  theme_classic() + 
  theme(axis.ticks.y = element_blank() , axis.text.y = element_blank() , 
        axis.title.y = element_blank() , 
        legend.position = c(1,.01) , legend.justification = c(""right"",""bottom"")) +
  ggtitle(""Income of highest- and lowest- earning counties per state"") +
  scale_x_continuous(""Household Income (K USD)"", breaks = c(-50000,0,50000,100000) ,
                     labels = c(50,0,50,100) , expand = c(0.15, 0)) +
  geom_vline(xintercept = 0)+
  geom_text(aes(x = Income_first+3000 , y = seq(1,nrow(acs_max),1) , label = State) , 
            size= 3 ,hjust = 0) +
  geom_text(aes(x = -3000 , y = 54 , label = c(""Lowest earning county"")) , hjust = 1) + 
  geom_text(aes(x = 3000 , y = 54 , label = c(""Highest earning county"")) , hjust = 0) 

p


","Other-2"
"901",1738,"https://github.com/ysamano/TidyTuesday/blob/master/week_13/week13_alcohol_world.R","ysamano","TidyTuesday","week_13/week13_alcohol_world.R","library(tidyverse)
library(stringr)

alcohol_world <- read_csv(""week_13/week13_alcohol_global.csv"")

alcohol_tidy <- alcohol_world %>% 
    gather(alcohol, value, -country) %>% 
    group_by(alcohol) %>% 
    top_n(100, value) %>% 
    mutate(axis_x = rep(1:10, length = n()),
           axis_y = rep(20:1, each = 10, length = n()),
           label = str_c(country, value, sep = ""\n""))

# Theme of plot
theme_samano <- function() {
    theme_minimal(base_family = ""Open Sans"") +
        theme(axis.title = element_blank(),
              axis.text = element_blank(),
              legend.position = ""none"",
              panel.grid = element_blank(),
              plot.title = element_text(face = ""bold"", size = 25, hjust = 0.5),
              plot.subtitle = element_text(size = 13, hjust = 0.5),
              plot.caption = element_text(size = 8),
              plot.margin = margin(20, 10, 10, 10))
}


beer_plot <- 
    alcohol_tidy %>% 
    filter(alcohol == ""beer_servings"") %>% 
    ggplot(aes(axis_x, axis_y)) +
    geom_point(aes(size = value)) +
    scale_size(range = c(0, 17)) +
    geom_text(aes(label = label), size = 2.5, nudge_y = -0.4) +
    labs(title = ""Where Do People Drink The Most Beer?"",
         subtitle = ""The 100 countries with the most servings consumed per person, 2010"",
         caption = ""Source: FiveThirtyEight | Graphic: @ysamano28"") +
    theme_minimal(base_family = ""Open Sans"") +
    theme_samano()

ggsave(""week_13/beer_plot.png"", beer_plot, height = 12, width = 8, units = ""in"", dpi = 300)



wine_plot <- 
    alcohol_tidy %>% 
    filter(alcohol == ""wine_servings"") %>% 
    ggplot(aes(axis_x, axis_y)) +
    geom_point(aes(size = value)) +
    scale_size(range = c(0, 17)) +
    geom_text(aes(label = label), size = 2.5, nudge_y = -0.4) +
    labs(title = ""Where Do People Drink The Most Wine?"",
         subtitle = ""The 100 countries with the most servings consumed per person, 2010"",
         caption = ""Source: FiveThirtyEight | Graphic: @ysamano28"") +
    theme_samano()

ggsave(""week_13/wine_plot.png"", wine_plot, height = 12, width = 8, units = ""in"", dpi = 300)



spirit_plot <- 
    alcohol_tidy %>% 
    filter(alcohol == ""spirit_servings"") %>% 
    ggplot(aes(axis_x, axis_y)) +
    geom_point(aes(size = value)) +
    scale_size(range = c(0, 17)) +
    geom_text(aes(label = label), size = 2.5, nudge_y = -0.4) +
    labs(title = ""Where Do People Drink The Most Spirit?"",
         subtitle = ""The 100 countries with the most servings consumed per person, 2010"",
         caption = ""Source: FiveThirtyEight | Graphic: @ysamano28"") +
    theme_samano()

ggsave(""week_13/spirit_plot.png"", spirit_plot, height = 12, width = 8, units = ""in"", dpi = 300)

","Other-13"
"902",1739,"https://github.com/ysamano/TidyTuesday/blob/master/week_8/week_8.R","ysamano","TidyTuesday","week_8/week_8.R","
library(tidyverse)

honey_data <- read_csv(""week_8/week_8.csv"")

head(honey_data)

growth_prod <- honey_data %>% 
    select(state, totalprod, year) %>% 
    group_by(state) %>% 
    mutate(totalprod_lag = lag(totalprod),
           growth = (totalprod / totalprod_lag - 1) * 100) %>% 
    filter(!is.na(growth))

growth_prod$prodFactor <- cut(growth_prod$growth,
                              breaks = quantile(growth_prod$growth,
                                                probs = seq(0, 1, by= 0.2), na.rm = T),
                              include.lowest = T, 
                              ordered_result = T)

# HONEY PLOT 1
    
honey_plot <-
ggplot(growth_prod, aes(state, year, fill = prodFactor))+
    geom_tile(color = ""white"", size = 0.25) +
    labs(title = ""U.S. Honey Production"",
         subtitle = ""Annual Growth Rate By State"",
         caption = ""Data: USDA-NASS"") +
    scale_y_continuous(breaks = seq(1998, 2012, 1), expand = c(0, 0))+
    scale_fill_brewer(palette = ""YlOrRd"", direction = -1,
                      labels = c(""-21.1%"", ""8.7"", ""3.2"", ""19.3"", ""134""))+
    guides(fill = guide_legend(title = ""Growth Rate"",
                               label.position = ""bottom"",
                               label.hjust = 1,
                               keywidth = 4, 
                               keyheight = .8))+
    ggthemes::theme_fivethirtyeight()+
    theme(panel.grid.major = element_blank(),
          axis.title = element_blank())

ggsave(""honey_plot.png"", honey_plot, height = 7, width = 13, units = ""in"", dpi = 500)


# HONEY PLOT 2

honey_plot_2 <- growth_prod %>% 
    select(state, year, growth) %>% 
    spread(state, growth) %>% 
    rename(Alabama = AL,
           Arizona = AZ,
           Arkanzas = AR,
           California = CA,
           Colorado = CO,
           Florida = FL,
           Georgia = GA,
           Hawaii = HI,
           Idaho = ID,
           Illinois = IL,
           Indiana = IN,
           Iowa = IA,
           Kansas = KS,
           Kentucky = KY,
           Louisiana = LA,
           Maine = ME,
           Maryland = MD,
           Michigan = MI,
           Minnesota = MN,
           Mississippi = MS,
           Missouri = MO,
           Montana = MT,
           Nebraska = NE,
           Nevada = NV,
           `New Jersey` = NJ,
           `New Mexico` = NM,
           `New York` = NY,
           `North Carolina` = NC,
           `North Dakota` = ND,
           Ohio = OH,
           Oklahoma = OK,
           Oregon = OR,
           Pennsylvania = PA,
           `South Carolina` = SC,
           `South Dakota` = SD,
           Tennessee = TN,
           Texas = TX,
           Utah = UT,
           Vermont  = VT,
           Virginia = VA,
           Washington = WA,
           `West Virginia` = WV,
           Wisconsin = WI,
           Wyoming = WY) %>% 
    gather(state, growth, -year) %>% 
    ggplot(aes(year, growth)) +
    geom_line(colour = ""#FFD300"", size = 1) +
    facet_wrap(~state) +
    labs(title = ""U.S. Honey Production"",
         subtitle = ""Annual Growth Rate By State"",
         caption = ""Data: USDA-NASS"")+
    ggthemes::theme_fivethirtyeight()

ggsave(""honey_plot_2.png"", honey_plot_2, height = 7, width = 13, units = ""in"", dpi = 500)




","Other-8/"
"903",1740,"https://github.com/ysamano/TidyTuesday/blob/master/week_12/week_12.R","ysamano","TidyTuesday","week_12/week_12.R","
library(tidyverse)
library(lubridate)


hurricane <- read_csv(""week_12/week12_mediacloud_hurricanes.csv"")
state_hurricane <- read_csv(""week_12/week12_mediacloud_states.csv"")

hurricane <- hurricane %>% 
    gather(mention, sentences, -Date) %>% 
    filter(sentences != 0) %>% 
    mutate(Date = mdy(Date))

state_hurricane <- state_hurricane %>%
    rename(`Puerto Rico` = `""Puerto Rico""`) %>% 
    gather(mention, sentences, -Date) %>% 
    mutate(Date = mdy(Date))


data_mention <- bind_rows(hurricane, state_hurricane) %>% 
    mutate(mention = factor(mention, 
                            levels = c(""Jose"", ""Maria"", ""Irma"", ""Harvey"",
                                       ""Puerto Rico"", ""Florida"", ""Texas"")),
        ty_ment = if_else(mention %in% c(""Harvey"", ""Irma"", ""Maria"", ""Jose""), 
                             ""By Hurricane"", ""By State""))

hurricane_plot <- 
    ggplot(data_mention, aes(Date, mention, colour = mention)) +
    geom_point(aes(size = sentences), alpha = .7) +
    scale_size_area(max_size = 10) +
    guides(color = F,
           size = guide_legend(title = ""Sentences \nper day"")) +
    scale_color_manual(values = c(""#006837"", ""#b30000"", ""#004A94"", ""#1F8FFF"",
                                  ""#b30000"", ""#004A94"", ""#1F8FFF"")) +
    scale_x_date(date_breaks = ""3 days"", date_labels = ""%m/%d"") +
    labs(title = ""Number of sentences mentioning each hurricane and place it made landfall"",
         caption = ""Source: FiveThirtyEight"") +
    facet_wrap(~ ty_ment, ncol = 1, scales = ""free_y"") +
    ggthemes::theme_fivethirtyeight(base_size = 10) + 
    theme(strip.text.x = element_text(hjust = 0, face = ""bold""),
          panel.grid.minor = element_blank(), 
          axis.title = element_blank(), 
          panel.grid.major.y = element_line(colour = ""gray60""),
          legend.title = element_text(size = 8), 
          plot.caption = element_text(size = 8))

ggsave(""week_12/hurricane_plot.png"", hurricane_plot, height = 5, width = 9, units = ""in"", dpi = 500)

","Other-12"
"904",1741,"https://github.com/ysamano/TidyTuesday/blob/master/week_9/week_9_comic.R","ysamano","TidyTuesday","week_9/week_9_comic.R","
library(tidyverse)

comic_data <- read_csv(""week_9/week9_comic_characters.csv"")

glimpse(comic_data)

funModeling::df_status(comic_data)

clear_data <- comic_data %>% 
    select(publisher, sex, year) %>% 
    filter(!is.na(sex), !is.na(year),
           sex %in% c(""Male Characters"", ""Female Characters"")) %>% 
    group_by(year, publisher, sex) %>% 
    summarise(conteo =n())

clear_data <- clear_data %>% 
    mutate(publ_sex = case_when(
        publisher == ""DC"" & sex == ""Male Characters"" ~ ""DC/Male"", 
        publisher == ""DC"" & sex == ""Female Characters"" ~ ""DC/Female"",
        publisher == ""Marvel"" & sex == ""Male Characters"" ~ ""Marvel/Male"",
        publisher == ""Marvel"" & sex == ""Female Characters"" ~ ""Marvel/Female""))

funModeling::df_status(clear_data)

comic_plot <- ggplot(clear_data, aes(conteo, year, size = conteo, colour = publ_sex)) + 
    geom_point(alpha = .7) +
    scale_size_area(max_size = 8)+
    scale_y_continuous(breaks=seq(1935, 2013, 2), limits = c(1935, 2013)) +
    scale_x_continuous(expand = c(0, 0), limits = c(-5, 430)) +
    scale_color_manual(values = c(""#1F8FFF"", ""#004A94"", ""#BC0A7B"", ""#CD1351"")) +
    guides(colour = guide_legend(override.aes = list(size = 5))) +
    labs(title = ""Number of New Comic Book Character by Year and Sex"",
         caption = ""Source: FiveThirtyEight"") +
    ggthemes::theme_fivethirtyeight() +
    theme(legend.title = element_blank(),
          plot.caption = element_text(size = 7),
          axis.text = element_text(size = 7))

ggsave(""week_9/comic_plot.png"", comic_plot, height = 6, width = 10, units = ""in"", dpi = 500)





","Other-9/"
"905",1742,"https://github.com/ysamano/TidyTuesday/blob/master/week_14/week_14.R","ysamano","TidyTuesday","week_14/week_14.R","library(tidyverse)
library(countrycode)

life_exp <- read_csv(""week_14/week14_global_life_expectancy.csv"")

life_exp2 <- life_exp %>% 
    mutate(continent = countrycode(sourcevar = country, 
                                   origin = 'country.name', 
                                   destination = ""continent"")) %>% 
    filter(!is.na(continent))


life_plot <- 
    life_exp2 %>% 
    filter(year >= 1950) %>%
    ggplot( aes(x = code, y = year, fill = life_expectancy)) +
    geom_tile() +
    facet_wrap(~ continent, ncol = 2, scales = ""free"") +
    scale_x_discrete(expand = c(0, 0))+
    scale_y_continuous(breaks = seq(1950, 2015, 10), expand = c(0, 0))+
    scale_fill_distiller(palette = ""Spectral"", direction = 1)+
    labs(title = ""Life Expectancy at Birth, 1950-2015"",
         caption = ""Source: ourworldindata.org | Graphic: @ysamano28"") +
    guides(fill = guide_colourbar(title = ""Years"", title.position = ""top"")) +
    theme_minimal(base_family = ""sans"") +
    theme(axis.text.x = element_text(angle = 90, vjust = .5, size = 6),
          axis.text.y = element_text(size = 7),
          axis.title = element_blank(),
          axis.ticks = element_line(colour = ""grey60""),
          plot.title = element_text(face = ""bold"", size = 22, margin = margin(b = 18)),
          plot.margin = margin(22, 10, 10, 10),
          strip.text.x = element_text(size = 12, hjust = 0, face = ""bold""),
          legend.position = c(0.84, 1.065), 
          legend.direction = ""horizontal"",
          legend.key.width = unit(2.6, ""line""),
          legend.key.height = unit(1, ""line""))

ggsave(""week_14/life_plot.png"", life_plot, height = 11, width = 9, units = ""in"", dpi = 500)

","Other-14"
"906",1743,"https://github.com/ysamano/TidyTuesday/blob/master/week_10/week_10.R","ysamano","TidyTuesday","week_10/week_10.R","
library(tidyverse)
library(purrr)
library(lubridate)

name_files <- list.files(""week_10/PublicTripData"", full.names = T)

data_bike <- name_files %>% 
    map_dfr(~ data.table::fread(.x))

write_csv(data_bike, ""week_10/data_biketown.csv"", na = """")

data_bike <- read_csv(""week_10/data_biketown.csv"")

funModeling::df_status(data_bike)


clear_data <- data_bike %>%
    select(PaymentPlan, StartDate) %>% 
    filter(!is.na(StartDate)) %>% 
    mutate(startdate = mdy(StartDate),
           year = year(startdate),
           week = week(startdate),
           week_day = wday(startdate, label = T, locale = ""C"", week_start = 1))


total_trips <- clear_data %>% 
    group_by(year, week, week_day) %>% 
    summarise(trips = n()) %>%
    ungroup() %>% 
    mutate(quantile = cut(trips,
                          breaks = quantile(trips, probs = seq(0, 1, by= 0.2)),
                          include.lowest = T, 
                          ordered_result = T))


subscriber_trips <- clear_data %>% 
    filter(PaymentPlan == ""Subscriber"") %>% 
    group_by(year, week, week_day) %>% 
    summarise(trips = n()) %>%
    ungroup() %>% 
    mutate(quantile = cut(trips,
                          breaks = quantile(trips, probs = seq(0, 1, by= 0.2)),
                          include.lowest = T, 
                          ordered_result = T))


casual_trips <- clear_data %>% 
    filter(PaymentPlan == ""Casual"") %>% 
    group_by(year, week, week_day) %>% 
    summarise(trips = n()) %>%
    ungroup() %>% 
    mutate(quantile = cut(trips,
                          breaks = quantile(trips, probs = seq(0, 1, by= 0.2)),
                          include.lowest = T, 
                          ordered_result = T))


# Theme of plot

scale_plot <- scale_x_continuous(expand = c(0, 0),
                       breaks = map_dbl(seq.Date(ymd(""2018/1/1""), by = ""month"", length.out = 12), week),
                       labels = c(""Jan"", ""Feb"", ""Mar"", ""Apr"", ""May"", ""Jun"",
                                  ""Jul"", ""Aug"", ""Sep"", ""Oct"", ""Nov"", ""Dec""))

guides_plot <- guides(fill = guide_legend(title = ""Number of Trips"",
                                          label.position = ""bottom"",
                                          label.hjust = .5,
                                          title.position = 'top',
                                          keywidth = 4, keyheight = .8))
theme_heatmap <- function(...) {
    theme_minimal() +
        theme(plot.title = element_text(size = 20, face = ""bold""),
              plot.margin = margin(10, 10, 10, 10),
              legend.position = ""bottom"",
              strip.text.x = element_text(size = 13, hjust = 1, face = ""plain""),
              axis.title = element_text(size = 12, hjust = 1),
              axis.text = element_text(colour = ""Black""))
}



# plot total trips

total_plot <- ggplot(total_trips, aes(week, week_day, fill = quantile)) +
    geom_tile(color = 'gray30') +
    facet_wrap('year', ncol = 1) +
    labs(x = ""Week"", y = ""Day of the Week"",
         title = ""Number of Trips per Weekday"", caption = ""Source: BIKETOWNpdx"") +
    scale_fill_brewer(palette = ""YlOrRd"", direction = 1,
                      labels = c(""20 - 325"", ""325 - 515"", ""515 - 826"", 
                                 ""826 - 1410"", ""1410 - 2990"")) +
    scale_plot +
    guides_plot +
    theme_heatmap()

ggsave(""week_10/total_plot.png"", total_plot, height = 7, width = 12, units = ""in"", dpi = 500)


# Plot Subscriber trips
table(subscriber_trips$quantile)

subscriber_plot <- ggplot(subscriber_trips, aes(week, week_day, fill = quantile)) +
    geom_tile(color = 'gray30') +
    facet_wrap('year', ncol = 1) +
    labs(x = ""Week"", y = ""Day of the Week"",
         title = ""Number of Trips per Weekday"", subtitle = ""Payment Plan: Subscriber"",
         caption = ""Source: BIKETOWNpdx"") +
    scale_fill_brewer(palette = ""YlOrBr"", direction = 1,
                      labels = c(""19 - 221"", ""221 - 350"", ""350 - 473"", 
                                 ""473 - 636"", ""636 - 1020"")) +
    scale_plot +
    guides_plot +
    theme_heatmap()

ggsave(""week_10/subscriber_plot.png"", subscriber_plot, height = 7, width = 12, units = ""in"", dpi = 500)


# Plot Casual trips
table(casual_trips$quantile)

casual_plot <- ggplot(casual_trips, aes(week, week_day, fill = quantile)) +
    geom_tile(color = 'gray30') +
    facet_wrap('year', ncol = 1) +
    labs(x = ""Week"", y = ""Day of the Week"",
         title = ""Number of Trips per Weekday"", subtitle = ""Payment Plan: Casual"",
         caption = ""Source: BIKETOWNpdx"") +
    scale_fill_brewer(palette = ""Oranges"", direction = 1,
                      labels = c(""1 - 72"", ""72 - 149"", ""149 - 365"", 
                                 ""365 - 696"", ""696 - 2310"")) +
    scale_plot +
    guides_plot +
    theme_heatmap()

ggsave(""week_10/casual_plot.png"", casual_plot, height = 7, width = 12, units = ""in"", dpi = 500)











","Other-10"
"907",1744,"https://github.com/ysamano/TidyTuesday/blob/master/week_11/week_11.R","ysamano","TidyTuesday","week_11/week_11.R","
library(tidyverse) 
library(treemapify)

fifa_audience <- read_csv(""week_11/week11_fifa_audience.csv"")

fifa_plot <- ggplot(fifa_audience,
                    aes(area = tv_audience_share,
                        subgroup = confederation,
                        fill = gdp_weighted_share,
                        label = country)) +
    geom_treemap(colour = ""gray10"") +
    geom_treemap_text(colour = ""gray20"", fontface = ""italic"",
                      min.size = 3, reflow = T) +
    geom_treemap_subgroup_border(colour = ""white"", size = 2) +
    geom_treemap_subgroup_text(alpha = 0.6, colour = ""white"") +
    viridis::scale_fill_viridis(direction = -1) +
    labs(title = ""Country's share of global world cup TV Audience in 2010"",
         caption =""Source: How To Break FIFA | FiveThirtyEight"",
         fill = ""GDP-weighted \naudience share \n(%)"") +
    theme(plot.title = element_text(size = 20, face = ""bold""))


ggsave(""week_11/fifa_plot.png"", fifa_plot, height = 7, width = 12, units = ""in"", dpi = 500)

","Other-11"
"908",1745,"https://github.com/context-dependent/tidy-tuesday/tree/master/alcohol-consumption","context-dependent","tidy-tuesday","alcohol-consumption/R/01_main.R",NA,"Other-1"
"909",1746,"https://github.com/michaelpawlus/tidytuesday/blob/master/tidy_tuesday_change_in_rel_cost_diff_final.R","michaelpawlus","tidytuesday","tidy_tuesday_change_in_rel_cost_diff_final.R","# built using the following tutorials as a starting point:

# http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html (Dumbell Plot)
# https://rud.is/b/2017/02/18/putting-it-all-together/ (More on Dumbell Plots)
# http://r-statistics.co/Complete-Ggplot2-Tutorial-Part2-Customizing-Theme-With-R-Code.html (Customizing ggplot2 themes)

# load the libraries
library(tidyverse)
library(readxl)
library(forcats)
library(ggalt)
library(gridExtra)
theme_set(theme_classic())

# load the data
tuition <- read_excel(""us_avg_tuition.xlsx"")

# add rate columns and type to split
tuition <- tuition %>%
  mutate(`2004` = round((tuition$`2004-05`-mean(tuition$`2004-05`))/mean(tuition$`2004-05`),2)) %>%
  mutate(`2016` = round((tuition$`2015-16`-mean(tuition$`2015-16`))/mean(tuition$`2015-16`),2)) %>%
  mutate(type = ifelse(`2016`-`2004` > 0, ""increased"", ""decreased"")) %>%
  select(State, `2004`, `2016`, type)

# split for relative cost increase
tuition_inc <- tuition %>%
  filter(type == ""increased"") %>%
  select(-type) %>%
  gather(year, diff_rate, -State)

# split for relative cost decrease
tuition_dec <- tuition %>%
  filter(type == ""decreased"") %>%
  select(-type) %>%
  gather(year, diff_rate, -State)

# make a df for labels for relative tuition increasing
labs_df_inc <- tuition_inc %>% 
  filter(State == tuition_inc %>% 
           arrange(-as.integer(year),-diff_rate) %>% 
           filter(row_number() ==1) %>% 
           select(State) %>% 
           as.character()
         )

# make a df for labels for realtive tuition decreasing
labs_df_dec <- tuition_dec %>% 
  filter(State == tuition_dec %>% 
           arrange(-as.integer(year),diff_rate) %>% 
           filter(row_number() ==1) %>% 
           select(State) %>% 
           as.character()
  )
  

## make the dataset for tuition going up
tup <- tuition_inc %>% 
  group_by(State) %>% 
  arrange(as.integer(year)) %>% 
  filter(between(row_number(), 1, n())) %>%   # switch from slice () to filter()
  spread(year, diff_rate) %>% 
  ungroup() %>% 
  mutate(State = as_factor(State)) %>%
  mutate(State = fct_reorder(State, `2016`))

## make dataset for tuition going down
tdown <- tuition_dec %>% 
  group_by(State) %>% 
  arrange(as.integer(year)) %>% 
  filter(between(row_number(), 1, n())) %>%   # switch from slice () to filter()
  spread(year, diff_rate) %>% 
  ungroup() %>% 
  mutate(State = as_factor(State)) %>%
  mutate(State = fct_reorder(State, -`2016`))

## plot for relative cost increases
ti <- ggplot(tup) +
  geom_dumbbell(aes(x=`2004`, xend=`2016`, y=State, group=State),
                color=""#c0c0c0"", 
                size=1,
                size_xend =2,
                colour_xend=""#0072B2"") +
  geom_text(data=labs_df_inc, aes(x=diff_rate, y=25.2, label=paste0(""'"",substring(year,3,4))), vjust=0, size=2) +
  scale_x_reverse(labels = scales::percent) + 
  scale_y_discrete(position = ""left"") +
  labs(x=""Tuition Cost as a Percentage Above/Below"", 
       y=NULL, 
       title=""Change in Tuition Costs Relative"", 
       subtitle=""Relative Price has Increased"", 
       caption=""Source: https://onlinembapage.com/average-tuition-and-educational-attainment-in-the-united-states/"") +
  theme(plot.title = element_text(hjust=1, face=""bold"", family = ""Helvetica""),
        plot.subtitle = element_text(hjust=0),
        plot.caption = element_text(color = ""white"", hjust=0),
        axis.title.x = element_text(hjust=1),
        plot.background=element_blank(),
        panel.background=element_blank(),
        panel.grid.minor=element_blank(),
        panel.grid.major.y=element_blank(),
        panel.grid.major.x=element_line(color = ""light grey""),
        text=element_text(size=9,  family=""Arial""),
        axis.ticks=element_blank(),
        legend.position=""top"",
        panel.border=element_blank())
plot(ti)

## plot for relative cost decreases
td <- ggplot(tdown) +
  geom_dumbbell(aes(x=`2004`, xend=`2016`, y=State, group=State),
                color=""#c0c0c0"", 
                size=1,
                size_xend =2,
                colour_xend=""#D55E00"") +
  geom_text(data=labs_df_dec, aes(x=diff_rate, y=25.2, label=paste0(""'"",substring(year,3,4))), vjust=0, size=2) +
  scale_x_reverse(labels = scales::percent) + 
  scale_y_discrete(position = ""right"") +
  labs(x=""Average Cost for Each Year"", 
       y=NULL, 
       title=""to Average Costs (between 2004 and 2016)"", 
       subtitle=""Relative Price has Decreased"", 
       caption=""Source: https://onlinembapage.com/average-tuition-and-educational-attainment-in-the-united-states/"") +
  theme(plot.title = element_text(hjust=0, face=""bold"", family = ""Helvetica""),
        plot.subtitle = element_text(hjust=1),
        axis.title.x = element_text(hjust=0),
        plot.background=element_blank(),
        panel.background=element_blank(),
        panel.grid.minor=element_blank(),
        panel.grid.major.y=element_blank(),
        panel.grid.major.x=element_line(color = ""light grey""),
        text=element_text(size=9,  family=""Arial""),
        axis.ticks=element_blank(),
        legend.position=""top"",
        panel.border=element_blank())
plot(td)

# use grid.arrange to place the plots
tt1 <- grid.arrange(ti, td, padding = 0, ncol=2)
tt1

## save the image
ggsave(""tt1.png"", tt1, width = 8, height = 6, units = ""in"", device = ""png"")
","Other-1"
"910",1749,"https://github.com/JidduAlexander/tidytuesday","JidduAlexander","tidytuesday","week5/TT W5.Rmd","---
title: ""TTW5""
output: html_notebook
---

```{r}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```


```{r}
library(tidyverse)
library(RColorBrewer)
library(ggthemes)
```

```{r}
acs <- read_csv(""../data/acs2015_county_data.csv"")

glimpse(acs)
```

```{r}
md <- read_csv(""acs2015_county_data_md.csv"")
View(md)
```

```{r, fig.width=12, fig.height=6}
sub_group <- ""income""

acs[, c(""Poverty"",
        md %>% filter(subgroup == sub_group) %>% pull(variable))] %>% 
  gather(key = ""subgroup"", value = ""Dollars"", md %>% filter(subgroup == sub_group) %>% pull(variable))%>% 
  ggplot(aes(x = Poverty, y = Dollars, col = subgroup)) + 
  geom_point(shape = ""."") +
  geom_smooth(se = FALSE) +
  scale_color_brewer(palette = ""Dark2"") +
  facet_grid(subgroup ~ ., scales = ""free_y"") +
  labs(title = ""Income versus poverty"", x = ""Poverty in %"")
```

```{r, fig.width=12, fig.height=6}
sub_group <- ""industry""

acs[, c(""Poverty"",
        md %>% filter(subgroup == sub_group) %>% pull(variable))] %>% 
  gather(key = ""subgroup"", value = ""Percentage"", md %>% filter(subgroup == sub_group) %>% pull(variable)) %>% 
  ggplot(aes(x = Poverty, y = Percentage, col = subgroup)) + 
  geom_point(shape = ""."") +
  geom_smooth(se = FALSE) +
  scale_color_brewer(name = ""Industry"", palette = ""Dark2"") +
  # facet_grid(subgroup ~ ., scales = ""free_y"") +
  labs(title = ""Industry versus poverty"", x = ""Poverty in %"")
```



```{r, fig.width=12, fig.height=6}
sub_group <- ""sector""

acs[, c(""Poverty"",
        md %>% filter(subgroup == sub_group) %>% pull(variable))] %>% 
  gather(key = ""subgroup"", value = ""Percentage"", md %>% filter(subgroup == sub_group) %>% pull(variable)) %>% 
  ggplot(aes(x = Poverty, y = Percentage, col = subgroup)) + 
  geom_point(shape = ""."") +
  geom_smooth(se = FALSE) +
  scale_color_brewer(name = ""Sector"", palette = ""Dark2"") +
  # facet_grid(subgroup ~ ., scales = ""free_y"") +
  labs(title = ""Sector versus poverty"", x = ""Poverty in %"") + 
  theme_hc()
```





","Other-5"
"911",1755,"https://github.com/moh-salah/income_density_transit","moh-salah","income_density_transit","analysis.r","#### Exploring income, density, and transit mode share in Vancouver ####

#load libraries
library(tidyverse)
library(plotly)
library(crosstalk)
library(cancensus)

#set api key for cancensus
options(cancensus.api_key = ""YOUR_KEY"")

#set working directory for data cache
options(cancensus.cache_path = getwd())

#list all available census year datasets
list_census_datasets()

#define the dataset and spatial level of analysis
dataset='CA16'
level=""CSD"" #census subdivision

#get a list of all regions
all_regions <- list_census_regions(dataset)

#define study area/region
regions <- all_regions %>%
  filter(level==level) %>% 
  filter(CMA_UID %in% c(59933)) %>% #Vancouver CMA
  as_census_region_list

#get a list of all vectors (variables)
all_vectors <- list_census_vectors(dataset)

#choose income and journey to work vectors
vectors <- all_vectors %>% 
  filter(vector %in% c(""v_CA16_2397"", 
                       ""v_CA16_5792"", 
                       ""v_CA16_5801"")) %>%
  pull(""vector"") 

#get data
data <- get_census(dataset = dataset,
                   level=level,
                   vectors=vectors, 
                   regions=regions, 
                   geo_format = ""sf"",
                   labels='detailed',
                   use_cache=TRUE)

#make better variables names 
names(data) <- tolower(make.names(names(data), unique=TRUE, allow_ = TRUE))

#rename a few variables
names(data)[13] <- ""area_sqkm""
names(data)[14] <- ""median_income""
names(data)[15] <- ""total_allmodes""
names(data)[16] <- ""transit""

#calculate transit mode share and filter missing data
data_transit <- data %>%
  mutate(transit_share = transit/total_allmodes,
         share = round(transit_share*100,2)) %>%
  filter(!is.na(median_income) & !is.na(transit_share))

#create a shared data object to enable linked brushing 
data_transit <- SharedData$new(data_transit, key = ~geouid)

#create ggplot map showing transit mode share
map_transit <- ggplot(data= data_transit) +
  geom_sf(aes(fill = share)) + 
  coord_sf(datum = ""+proj=longlat +datum=WGS84 +no_defs"")+
  scale_fill_distiller(""Mode Share - Trip to Work"", palette = 'RdYlGn', direction = 1, guide = FALSE)+
  theme(panel.grid.major=element_line(colour=""transparent""), 
        rect = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank())+
  ggtitle('Journey To Work - Transit Mode Share\nSource: 2016 Census')

#make it interactive with plotly
maply_transit <- ggplotly(map_transit) %>%
  layout(xaxis = list(scaleanchor = ""y"", scaleratio = 1)) %>%
  highlight(on=""plotly_click"", color = ""blue"", off= ""plotly_relayout"")

#create a scatter plot of income and density
scatterly <- plot_ly(data_transit,
                     x = ~median_income/1000,
                     y = ~(population/area_sqkm), 
                     type = 'scatter',
                     mode = 'markers',
                     marker=list(size=15),
                     color = ~share,
                     colors='RdYlGn',
                     text= ~region.name,
                     hoverinfo = 'text') %>% 
  hide_legend() %>%
  layout(xaxis = list(title = ""Median Household Income ($1000)"") , 
         yaxis = list(title =""Density (population/sq km)"")) %>%
  highlight(""plotly_selected"", color='blue')

#create a combined interactive visualization
bscols(maply_transit, scatterly)
","Other-1"
"912",1756,"https://github.com/sangeetabhatia03/r4ds","sangeetabhatia03","r4ds","week_3/week3.Rmd","---
author:
- name: Sangeeta Bhatia
date: ""`r Sys.Date()`""
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
spacing: double
bibliography: 
biblio-style: apsr
endnote: no
output: html_document
---

```{r setup, eval = TRUE}
library(tidyverse)
library(ggthemes)
library(viridis)
library(gganimate)
```

# Data wrangling

```{r}
global_mortality <- here::here(""week_3/data"", ""global_mortality.xlsx"") %>%
  readxl::read_xlsx(.)
```

Clean up the names for easy access but save the names for pretty 
plotting.

```{r}
names(global_mortality) <- str_trim(
  str_remove_all(names(global_mortality), ""[[:punct:]]"")
)
causes <- colnames(global_mortality)[ -c(1, 2, 3)]



```

Wide to tall so that we can group by countries or causes of death etc.

```{r}

mortality_tall <- tidyr::gather(
  data = global_mortality,
  key = ""cause"",
  value = ""percent"",
  -c(country, countrycode, year),
  factor_key = TRUE
  )

```
Sum by year for each country.

```{r}
mortality_country <- group_by(mortality_tall, country, cause) %>%
  summarise(percent = sum(percent, na.rm = TRUE))
```
Rows where country code is NA are actually groups of countries rather
than a single country. The groups are overlapping (e.g., countries are
grouped according to geographic region as well as SDI). We can explore
each group separately.



```{r}
regions <- c(
  ""Andean Latin America"",
  ""Central Latin America"",
  ""Tropical Latin America"",
  ""Latin America and Caribbean"",
  ""Southern Latin America"",
  ""North America"",
  ""Caribbean"",
  ""Australasia"",
  ""Oceania"",
  ""East Asia"",
  ""South Asia"",
  ""Central Asia"",
  ""Southeast Asia"",
  ""Eastern Europe"",
  ""Central Europe"",
  ""Western Europe"",
  ""North Africa and Middle East"",
  ""Eastern Sub-Saharan Africa"",
  ""Central Sub-Saharan Africa"",
  ""Western Sub-Saharan Africa"",
  ""Southern Sub-Saharan Africa"",
  ""Sub-Saharan Africa""
)

country_groups <- filter(mortality_tall, country %in% regions) %>%
    droplevels()

```

Re-arrange country groups geographically.

```{r}
country_groups$country <- factor(
  country_groups$country,
  levels = regions
)
```
## Leading causes of death in each geographical region

```{r, fig.show = ""animate"", interval = 2}

p <- ggplot(country_groups, aes(country, cause, frame = year)) +
  geom_tile(aes(fill = percent)) +
  scale_fill_viridis(name = ""% Population"") +
  theme_tufte() +
  theme(axis.text.x = element_text(angle = 90)) +
  xlab(""County Group"") + ylab(""Cause"") +
  theme(legend.title = element_blank())

gganimate(p)

```

## Leading causes of death by SDI

```{r, fig.show = ""animate"", interval = 2}
sdi <- c(
  ""High SDI"",
  ""High-middle SDI"",
  ""Middle SDI"",
  ""Low-middle SDI"",
  ""Low SDI""
)

sdi_groups <- filter(mortality_tall, country %in% sdi) %>%
  droplevels()

sdi_groups$country <- factor(
  sdi_groups$country,
  levels = sdi
)

p2 <- ggplot(sdi_groups, aes(country, cause, frame = year)) +
  geom_tile(aes(fill = percent)) +
  scale_fill_viridis(name = ""% Population"") +
  theme_tufte() +
  theme(axis.text.x = element_text(angle = 90)) +
  xlab("""") + ylab(""Cause"")

gganimate(p2)

```

## Leading causes of death in the UK

```{r}
uk <- c(""England"", ""Northern Ireland"", ""Scotland"", ""Wales"")
uk_groups <- filter(mortality_tall, country %in% uk) %>%
  droplevels()

```
Let us look at the top 10 causes rather than the whole data set.
```{r}
top_10 <- group_by(uk_groups, country, year) %>%
    top_n(n = 10, wt = percent)  %>%
    droplevels() %>%
    pull(cause) %>% unique

uk_groups <- filter(uk_groups, cause %in% top_10) %>% droplevels()

```

```{r fig.show = ""animate"", interval = 2}
uk_groups$country <- factor(
  uk_groups$country,
  levels = uk
)

p3 <- ggplot(uk_groups, aes(percent, cause, col = country, frame = year)) +
      geom_point(aes(size = percent)) + theme_tufte()

gganimate(p3)

```
","Other-3"
"913",1757,"https://github.com/timschoof/TidyTuesday/tree/master/TT03","timschoof","TidyTuesday","TT03/TT03.R","# Tidy Tuesday - 17 April 2018
# Global mortality rates

# Data source: https://ourworldindata.org/
# Article: https://ourworldindata.org/what-does-the-world-die-from
# Tidy Tuesday: https://github.com/rfordatascience/tidytuesday

library(tidyverse)
library(here)
library(openxlsx)

# load data
d<-read.xlsx(here(""global_mortality.xlsx""),sheet=""share-of-deaths-by-cause-2016 ("")

# TidyTuesday function of the week (from the stringr package)
# Remove '%' signs from column names
names(d) <- str_trim(str_remove_all(names(d),""[[:punct:]]""))

# select Japan (highest life expectancy) vs. Sierra Leone (lowest life expectancy)
JPN_SLE <- d %>%
  filter(country == ""Japan"" | country == ""Sierra Leone"")

# reorganise data frame: wide to long format
JPN_SLE_long <- JPN_SLE %>%
  gather(Cardiovasculardiseases:Terrorism, key = ""cause"", value=""rate"")

# relevel causes factor according to mean mortality rate Sierra Leone
causeOrder <- JPN_SLE_long %>%
  filter(country==""Sierra Leone"") %>% # select Sierra Leone
  group_by(cause) %>% # group by cause
  summarise(avgMR = mean(rate,na.rm=T)) %>%# take the mean across years
  arrange(avgMR) # order causes according to mean for SLE
# relevel factor (the not so tidy way)
JPN_SLE_long$cause <- factor(JPN_SLE_long$cause,levels=causeOrder$cause)

# plot
JPN_SLE_long %>%
  ggplot(aes(cause, rate, colour=country))+ 
  geom_boxplot()+
  coord_flip()+
  labs(x = """", y = ""Mortality rate (%)"", 
       title = ""Cause of death in Sierra Leone and Japan"", 
       subtitle = ""1990 - 2016"")+
  theme(panel.background = element_rect(fill = ""white"" ),
        plot.background = element_rect(fill = ""white"" ),
        plot.title = element_text(hjust = 0.5))# center the title
# save
ggsave(""MortalityRateJPNvsSLE.png"")

# This plot has so much info, it's hard to read, so let's zoom in a little
# select causes of death that on average account for at least 2% of mortalities
topCauses <- JPN_SLE_long %>%
  group_by(cause) %>% # group by cause
  summarise(avgMR = mean(rate,na.rm=T)) %>%# take the mean across years
  arrange(desc(avgMR)) %>% # order cause according to mean
  filter(avgMR>2)
# select top causes (the not so tidy way)
JPN_SLE_topCauses<- JPN_SLE_long[JPN_SLE_long$cause %in% topCauses$cause,]

# plot: top 10 causes
JPN_SLE_topCauses %>%
  ggplot(aes(cause, rate, colour=country))+ 
  geom_boxplot()+
  coord_flip()+
  labs(x = """", y = ""Mortality rate (%)"", 
       title = ""Cause of death in Sierra Leone and Japan"", 
       subtitle = ""Top 10 causes of death: 1990 - 2016"")+
  theme(panel.background = element_rect(fill = ""white"" ),
        plot.background = element_rect(fill = ""white"" ),
        plot.title = element_text(hjust = 0.5))# center the title
# save
ggsave(""TopMortalityRateJPNvsSLE.png"")


","Other-3"
"914",1758,"https://github.com/timschoof/TidyTuesday/tree/master/TT02","timschoof","TidyTuesday","TT02/TT02.R","# Tidy Tuesday - 10 April 2018
# Average pay for top NFL players per position

# Data source: http://www.spotrac.com/rankings/
# Article with graphic: https://fivethirtyeight.com/features/running-backs-are-finally-getting-paid-what-theyre-worth/
# Tidy Tuesday: https://github.com/rfordatascience/tidytuesday

library(tidyverse)
library(here)
library(openxlsx)

# load data
df<-read.xlsx(here(""tidy_tuesday_week2.xlsx""),sheet=""nfl_salary"")

# convert data frame to tibble - because I want to learn about tibbles
t<-as_tibble(df)

# reorganize tibble from wide to long format
longT <- t %>%
  gather(position,salary,-year) 

# select 16 highest-paid players in each position (n = 10), per year (n = 8)
sub16 <- longT %>%
  group_by(year,position) %>%
  top_n(16) %>%
  ungroup()

# compute average salary for this subset
meanSub16 <- sub16 %>%
  mutate(salary = salary/10^6) %>% # salary in millions
  group_by(year,position) %>%
  mutate(mean_salary = mean(salary)) %>%
  ungroup

# for plotting
meanSub16plot <- meanSub16 %>%
  mutate(position = fct_recode(position, ""Running Back"" = ""Running.Back"",
                             ""Defensive Lineman"" = ""Defensive.Lineman"",
                             ""Offensive Lineman"" = ""Offensive.Lineman"",
                             ""Special Teamer"" = ""Special.Teamer"",
                             ""Tight End"" = ""Tight.End"",
                             ""Wide Receiver"" = ""Wide.Receiver"")) # rename / recode some factor levels

# plot
meanSub16plot %>%
  ggplot() +
  geom_point(aes(x = year, y = salary), colour = ""gray"") +
  geom_line(aes(x = year, y = mean_salary), size = 1.2) + 
  facet_wrap(~position, nrow = 2) +
  labs(x = """", y = ""Average salary \n (USD in millions)"", 
       title = ""Average salary of 16 highest-paid NFL players \n by position"") +
  theme(panel.background = element_rect(fill = ""#fcfcfc"" ),
        plot.background = element_rect(fill = ""#fcfcfc"" ),
        panel.grid.major = element_line(colour = ""#d3d3d3""),
        plot.title = element_text(hjust = 0.5))# center the title

# save
ggsave(""NFL.png"", width = 10, height = 5)



","Other-2"
"915",1759,"https://github.com/timschoof/TidyTuesday","timschoof","TidyTuesday","TT01/TT01.R","# Tidy Tuesday - 3 April 2018
# Average in-state tuition fees in the United States

# Data source: https://onlinembapage.com/average-tuition-and-educational-attainment-in-the-united-states/
# Tidy Tuesday: https://github.com/rfordatascience/tidytuesday

library(tidyverse)
library(here)
library(openxlsx)
library(fiftystater) # USA map with nice Alaska and Hawaii insets
library(viridis) # colour mapping suitable for people with colour blindness
library(gganimate)
library(magick)

# HELLO WORLD

# load data
d<-read.xlsx(here(""us_avg_tuition.xlsx""),sheet=""Table 5"")

# restructure data frame (lower case the States, and convert from wide to long format)
dd<- d %>%
  mutate(State = tolower(State)) %>%
  gather(Year, Fee, -State)

# plot map
p <- ggplot(dd,aes(map_id = State, frame = Year)) +
  geom_map(aes(fill = Fee), map = fifty_states) + 
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  coord_map() +
  scale_x_continuous(breaks = NULL) + 
  scale_y_continuous(breaks = NULL) +
  scale_fill_viridis(name=""USD"", direction = -1) +
  labs(x = """", y = """", title = ""Average in-state tuition fees in the United States:"") +
  theme(legend.position = ""right"", 
        panel.background = element_blank()) 

# little hack to get magick (to create the animation/gif) to work
magickPath <- shortPathName(""C:/Program Files/ImageMagick-6.9.9-Q16-HDRI/convert.exe"")
ani.options(convert=magickPath)

# animate plot
gganimate(p,interval = 1)

# save as gif
gganimate(p, here(""US_tuition_map.gif""))
","Other-1"
"916",1760,"https://github.com/timschoof/TidyTuesday","timschoof","TidyTuesday","TT04/TT04.R","# Tidy Tuesday - 24 April 2018
# Gender differences in Australian salaries

# Data source: https://data.gov.au/dataset/taxation-statistics-2013-14/resource/c506c052-be2f-4fba-8a65-90f9e60f7775?inner_span=True
# Article: http://www.womensagenda.com.au/latest/eds-blog/australia-s-50-highest-paying-jobs-are-paying-men-significantly-more/
# Tidy Tuesday: https://github.com/rfordatascience/tidytuesday

# Figure inspired by https://www.theguardian.com/news/ng-interactive/2018/apr/05/women-are-paid-less-than-men-heres-how-to-fix-it

library(tidyverse)
library(ggrepel)

url_data <- ""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/""
data_file <- ""week4_australian_salary.csv""

data <- read_csv(str_c(url_data,data_file))

# Calculate gender pay gap: https://www.gov.uk/guidance/gender-pay-gap-reporting-make-your-calculations
d <- data %>%
  select(-c(X1,gender_rank,individuals)) %>%
  spread(key = gender, value = average_taxable_income) %>%
  na.omit() %>% # exclude occupations with no data without salary details for both men and women
  mutate(payGap = 100*((Male-Female)/Male))

# add column indicating whether women get paid more or less than  men
d <- d %>%
  mutate(paySkew = ifelse(payGap > 0, 'Women paid less','Women paid more')) %>%
  mutate(labelToPlot = ifelse(payGap < -60, occupation,NA))

# beeswarm-like histogram showing gender pay gap as a percentage of men's pay for differen occupations
d %>%
ggplot(aes(x = payGap, fill = paySkew)) +
  geom_dotplot(method=""histodot"", binwidth = 3,colour = NA) +
  geom_text_repel(aes(label = labelToPlot),box.padding = unit(2,'lines'),y=0,direction = ""y"")+
  labs(x = ""Gender pay gap as a percentage of men's pay"", y = """", 
       title = ""Gender pay gap in Australia"", 
       subtitle = ""2013-14 income year"") +
  theme(panel.background = element_rect(fill = ""white"" ),
        plot.background = element_rect(fill = ""white"" ),
        plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5),
        legend.title=element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank())

# save
ggsave(""PayGap.png"")
","Other-4"
"917",1761,"https://github.com/jklaise/tidytuesday/blob/master/week3.r","jklaise","tidytuesday","week3.r","library(tidyverse)
library(readxl)
library(cartogram)    # for the cartogram
library(ggplot2)      # to realize the plots
library(broom)        # from geospatial format to data frame
library(tweenr)       # to create transition dataframe between 2 states
library(gganimate)    # To realize the animation
library(maptools)     # world boundaries coordinates
library(viridis)      # for a nice color palette
library(gridExtra)

data <- read_xlsx(""data/global_mortality.xlsx"")

# Get the shape file of Africa
data(wrld_simpl)
afr <- wrld_simpl[wrld_simpl$REGION==2,]

# list of African country codes
afr_codes <- afr@data %>% rownames()
afr@data$country_code <- afr_codes

# filter data for African countries and latest year
afr_data <- data %>% filter(country_code %in% afr_codes)
afr_data_16 <- afr_data %>% filter(year==""2016"")

# join data
afr@data <- afr@data %>% left_join(afr_data_16)
rownames(afr@data) <- afr@data$country_code # NB! missing this out will break things as the join reindexes

# construct a cartogram using HIV/AIDS % of all deaths
afr_cartogram <- cartogram(afr, ""HIV/AIDS (%)"")

# Transform these 2 objects in dataframe, plotable with ggplot2
afr_df <- tidy(afr) %>% left_join(. , afr@data, by=c(""id""=""ISO3""))
afr_cartogram_df <- tidy(afr_cartogram) %>% left_join(. , afr_cartogram@data, by=c(""id""=""ISO3"")) 

# plot
plot_map <-function(df) {
  plot <- ggplot() +
  geom_polygon(data = df, aes(fill = `HIV/AIDS (%)`, x = long, y = lat, group = group) , size=0, alpha=0.9) +
  theme_void() +
  scale_fill_viridis(name=""HIV/AIDS (% of all deaths)"",
                     breaks=c(1,5,10,15,20,25,30,35,40,45,50),
                     guide = guide_legend( keyheight = unit(3, units = ""mm""),
                                           keywidth=unit(10, units = ""mm""),
                                           label.position = ""bottom"", 
                                            title.position = 'top', nrow=1)) +
  ylim(-35,35) +
  theme(
    text = element_text(color = ""#22211d""), 
    plot.background = element_rect(fill = ""#f5f5f4"", color = NA), 
    panel.background = element_rect(fill = ""#f5f5f4"", color = NA), 
    legend.background = element_rect(fill = ""#f5f5f4"", color = NA),
    plot.title = element_text(size= 10, hjust=0.5, color = ""#4e4d47""),
    legend.position = c(0.0, 0.0)
  ) +
  coord_map()
  
  return(plot)
}

p1 <- plot_map(afr_df)+
  labs(title=""Percentage of deaths in Africa due to HIV/AIDS (2016)"") +
  guides(fill=FALSE)
p2 <- plot_map(afr_cartogram_df)

p <- grid.arrange(p1,p2, ncol=2)
ggsave(""img/week3.png"", plot=p, width=20, height=10, units=""cm"")
","Other-3"
"918",1762,"https://github.com/jklaise/tidytuesday/blob/master/week2.r","jklaise","tidytuesday","week2.r","library(tidyverse)
library(readxl)
library(scales)

data <- read_xlsx(""data/tidy_tuesday_week2.xlsx"")

# tidy data
data <- data %>% gather(position, salary, -year)

# add offensive/defensive position label
data <- data %>% 
  mutate(ofdef = case_when((position %in% c(""Running Back"",
                                           ""Quarterback"",
                                           ""Offensive Lineman"",
                                           ""Tight End"",
                                           ""Wide Receiver""))~""O"",
                           TRUE~""D""))

# top paid players by position and year
top <- data %>% 
  group_by(position, year) %>% 
  top_n(16, salary)

# represent salaries in millions as there appears no easy way of formatting
# big dollar values using library(scales)
div = 1e6

# add salary rank
top <- top %>% 
  mutate(rank = dense_rank(desc(salary)))

# plot evolution of top salaries
ggplot(top, aes(year, salary/div)) +
  geom_line(aes(group=rank, alpha=1/rank)) +
  geom_smooth(aes(year, salary/div), span=0.3, se=FALSE, linetype=1) +
  facet_wrap(ofdef~position, nrow = 2, labeller = label_wrap_gen(multi_line=FALSE)) +
  theme_minimal() +
  ggtitle(""Evolution of top salaries by position"") +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  guides(alpha=FALSE) +
  scale_y_continuous(labels = dollar_format(suffix=""m"")) +
  xlab(""Year"") +
  ylab(""Salary"") +
  annotate(""segment"", x=-Inf, xend=Inf, y=-Inf, yend=-Inf, size=1)

ggsave(""img/week2.png"", width=20, height=10, units=""cm"")
","Other-2"
"919",1763,"https://github.com/frankfarach/tidytuesday/blob/master/R/tidytuesday_week2.R","frankfarach","tidytuesday","R/tidytuesday_week2.R","# TidyTuesday: Week 2 (2018-04-10) ----------------------------------------
# Author: Frank Farach (@frankfarach)
# TidyTuesday repo: https://github.com/rfordatascience/tidytuesday

library(tidyverse)
library(readxl)

df <- ""data/tidy_tuesday_week2.xlsx"" %>%
  read_excel() %>%
  gather(position, salary, Cornerback:`Wide Receiver`) %>%
  mutate(
    # Only need the last two digits of year
    year = str_match(year, ""\\d\\d$"") %>% as.integer(),
    # DE and DT not in data; included ST which was not in original
    pos_abbr = case_when(
      position == ""Cornerback"" ~ ""CB"",
      position == ""Defensive Lineman"" ~ ""DL"",
      position == ""Linebacker"" ~ ""LB"",
      position == ""Offensive Lineman"" ~ ""OL"",
      position == ""Quarterback"" ~ ""QB"",
      position == ""Running Back"" ~ ""RB"",
      position == ""Safety"" ~ ""S"",
      position == ""Special Teamer"" ~ ""ST"",
      position == ""Tight End"" ~ ""TE"",
      position == ""Wide Receiver"" ~ ""WR""
    ),
    # Ordering of levels controls order of facet panels
    pos_abbr = factor(
      pos_abbr,
      levels = c(""RB"", ""QB"", ""OL"", ""TE"", ""WR"",
                 ""CB"", ""DL"", ""LB"", ""S"", ""ST""),
      ordered = TRUE
    ),
    # Just in case we want to facet by type of position
    # Special teams are not exclusively offense or defense
    pos_type = case_when(
      pos_abbr %in% c(""RB"", ""QB"", ""OL"", ""TE"", ""WR"") ~ ""Offense"",
      pos_abbr %in% c(""CB"", ""DL"", ""DT"", ""LB"", ""S"") ~ ""Defense"",
      pos_abbr %in% ""ST"" ~ ""Special Teams""
    )
  )

# Top 16 highest-paid players in each position each year
df16 <- df %>%
  group_by(year, pos_abbr) %>%
  top_n(16, salary)

# Plot
df16 %>%
  ggplot(aes(x = year,
             # Only need millions
             y = salary / 1e6,
             fill = pos_abbr)) +
  geom_point(alpha = 0.1) +
  geom_smooth(
    method = ""loess"",
    # Default span was not as wiggly as original
    span = .5,
    se = FALSE,
    color = ""orangered""
  ) +
  facet_wrap(~ pos_abbr, nrow = 2) +
  # No legend
  scale_fill_discrete(guide = FALSE) +
  # Hack: Years aren't dollars, but the prefix argument is handy
  scale_x_continuous(labels = scales::dollar_format(prefix = ""'"")) +
  # Lower limit ensures 0 is always shown on y axis
  scale_y_continuous(
    labels = scales::dollar_format(suffix = ""M""),
    breaks = seq(0, 40, 5),
    limits = c(0, NA)
  ) +
  labs(
    title = ""The average pay for top running backs has stalled"",
    subtitle = ""Average cap value of 16 highest-paid players in each position"",
    x = """",
    y = ""Average cap value"",
    caption = ""Sources: FiveThirtyEight, ESPN Stats & Information Group  |  Graphic: @frankfarach""
  ) +
  theme_minimal() +
  theme(
    panel.grid.minor = element_blank(),
    axis.line.x = element_line(),
    axis.text = element_text(color = ""#999999""),
    plot.title = element_text(size = 18),
    plot.subtitle = element_text(size = 13, 
                                 color = ""gray30"",
                                 vjust = 0.5)
  )

ggsave(""plots/tt2_nfl_avg_cap.png"", dpi = 300)","Other-2"
"920",1764,"https://github.com/frankfarach/tidytuesday/blob/master/R/tidytuesday_week3.R","frankfarach","tidytuesday","R/tidytuesday_week3.R","# TidyTuesday: Week 3 (2018-04-20) ----------------------------------------
# Author: Frank Farach (@frankfarach)
# TidyTuesday repo: https://github.com/rfordatascience/tidytuesday

library(tidyverse)
library(readxl)
library(skimr)
library(tweenr)
library(gganimate)

# Import data to tibble
df <- ""data/global_mortality.xlsx"" %>% 
  read_excel() 

# Quick EDA - note missing values for terrorism and conflict
skim(df)

# Tidy, clean country names, and aggregate for plot
share_by_yr_cause <- df %>% 
  gather(cause, 
         share, 
         `Cardiovascular diseases (%)`:`Terrorism (%)`) %>% 
  mutate(cause = str_remove(cause, ""[[:space:]]\\(%\\)""),
         year = as.integer(year)) %>% 
  group_by(year, cause) %>% 
  summarize(avg_share = mean(share, na.rm = TRUE))

# Renaming some columns for convenience in tweenr
# We want cause of death to be the constant grouping across animation frames
# `ease` will tell tweenr what interpolation method to use; nothing fancy here
mydf <- share_by_yr_cause %>% 
  rename(x = avg_share, y = cause, time = year, id = cause) %>%
  mutate(ease = ""linear"")

# The magic: Animation by interpolation!
# nframes: We have 27 years of data and want, say, 2 frames per year
# round the time column because it has interpolated values for year
# Join the aggregated data to the ""tweened"" dataset to get original
# columns alongside the 
mydf_tween <- tween_elements(mydf, ""time"", ""id"", ""ease"", nframes = 54) %>%
  mutate(year = round(time), cause = .group) %>%
  left_join(share_by_yr_cause, by = c(""year"", ""cause""))

# Getting the year to display in the title is tricky because there are
# multiple values of .frame per year, yet we want the frame aesthetic
# to be .frame. I chose to concatenate year and frame, but would love
# to find a better way.
p <- ggplot(mydf_tween, aes(x = x/100, 
                            y = reorder(cause, avg_share, na.rm = TRUE), 
                            frame = paste0(year, "" (#"", .frame, "")""))) +
  geom_point() +
  scale_x_continuous(labels = scales::percent_format()) +
  labs(title = ""Share of deaths by cause, World,"",
       subtitle = ""Data refers to the specific cause of death, which is distinguished from risk\nfactors for death, such as air pollution, diet and other lifestyle factors.\nThis is shown by cause of death as the percentage of total deaths."",
       x = ""Share of deaths (%)"",
       y = NULL,
       caption = ""Sources: IHME, Global Burden of Disease & ourworldindata.org | Graphic: @frankfarach"") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14),
        plot.subtitle = element_text(size = 9),
        axis.text = element_text(size = 8))

# Requires ImageMagick
g <- gganimate(p, ""plots/tt_week3.gif"", saver = ""gif"", interval = 0.05)","Other-3"
"921",1765,"https://github.com/frankfarach/tidytuesday/blob/master/R/tidytuesday_week4.R","frankfarach","tidytuesday","R/tidytuesday_week4.R","# TidyTuesday: Week 4 (2018-04-24) ----------------------------------------
  # Author: Frank Farach (@frankfarach)
  # TidyTuesday repo: https://github.com/rfordatascience/tidytuesday
  
  library(tidyverse)
  library(skimr)
  library(ggalt)
  
  # Import data to tibble
  df <- read_csv(""data/week4_australian_salary.csv"")
  
  # EDA
  df %>%
    skim(gender, individuals, average_taxable_income)
  
  # Organize data for plotting
  plot_df <- df %>%
    select(-X1,-gender_rank,-individuals) %>%
    spread(gender, average_taxable_income) %>%
    rename(female = Female, male = Male) %>%
    mutate(fdiff = female - male,
           fdiff_pct = as.integer(fdiff / male * 100)) %>%
    top_n(10, male) %>%
    arrange(desc(male))
  
  # ggalt - Dumbbell!
  # Adapted from blog post by Bob Rudis
  
  # Handy names for specific colors
  male_color <- ""red""
  female_color <- ""blue""
  dumbbell_color <- ""#b2b2b2""
  sidebar_color <- ""#efefe3""
  
  # Nudge top row
  label_vjust <- -1.4
 
  # Plot it! 
  ggplot() +
    geom_segment(
      data = plot_df,
      aes(
        y = fct_reorder(occupation, male),
        yend = occupation,
        x = 0,
        xend = max(male) * 1.04
      ),
      color = dumbbell_color,
      size = 0.15
    ) +
    geom_dumbbell(
      data = plot_df,
      aes(y = occupation, x = female, xend = male),
      size = 1.2,
      color = dumbbell_color,
      colour_x = female_color,
      colour_xend = male_color,
      dot_guide = FALSE
    ) +
    geom_text(
      data = filter(plot_df, occupation == ""Neurosurgeon""),
      aes(x = female, y = occupation, label = ""Women""),
      color = female_color,
      size = 3,
      vjust = label_vjust,
      fontface = ""bold""
    ) +
    geom_text(
      data = filter(plot_df, occupation == ""Neurosurgeon""),
      aes(x = male, y = occupation, label = ""Men""),
      color = male_color,
      size = 3,
      vjust = label_vjust,
      fontface = ""bold""
    ) +
    # Difference column
    geom_rect(
      data = plot_df,
      aes(
        xmin = max(male) * 1.07,
        xmax = max(male) * 1.2,
        ymin = -Inf,
        ymax = Inf
      ),
      fill = sidebar_color
    ) +
    geom_text(
      data = plot_df,
      aes(
        label = paste0(fdiff_pct, ""%""),
        y = occupation,
        x = max(male) * 1.13
      ),
      fontface = ""bold"",
      size = 3
    ) +
    geom_text(
      data = filter(plot_df, occupation == ""Neurosurgeon""),
      aes(
        x = max(male) * 1.13,
        y = occupation,
        label = ""Diff""
      ),
      color = ""#7a7d7e"",
      size = 3,
      vjust = label_vjust,
      fontface = ""bold""
    ) +
    scale_x_continuous(labels = scales::dollar_format()) +
    labs(
      y = NULL,
      title = ""Women earn less than men in Australia's top-paying jobs"",
      subtitle = ""Gender pay gap in average taxable income (AUD), 2013-14"",
      caption = ""Source: Australian Government, https://bit.ly/2iTTCIy | Graphic: @frankfarach""
    ) +
    theme_bw() +
    theme(
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.border = element_blank(),
      axis.title.x = element_blank(),
      axis.ticks.y = element_blank(),
      plot.title = element_text(face = ""bold""),
      plot.caption = element_text(size = 8, color = ""gray60"", vjust = -1)
    )
  
  ggsave(""plots/tt_week4.png"")
","Other-4"
"922",262,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","WomensWorldCup.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""7/8/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
pacman::p_load(tidyverse, polite, scales, ggimage, ggforce, ggtextures, DT, 
               cowplot, rvest, glue, extrafont, ggrepel, magick)
loadfonts()
```


## WWC theme


```{r}
theme_womenWorldCup <- function(
  title.size = 24,
  subtitle.size = 14,
  caption.size = 8,
  axis.text.size = 14,
  axis.text.x.size = 12,
  axis.text.y.size = 12,
  axis.title.size = 16,
  strip.text.size = 18,
  panel.grid.major.x = element_line(size = 0.5, color = ""black""),
  panel.grid.major.y = element_line(size = 0.5, color = ""black""),
  panel.grid.minor.x = element_blank(),
  panel.grid.minor.y = element_blank(),
  axis.ticks = element_line(color = ""black"")) {
  ## Theme:
  theme(text = element_text(family = ""Roboto Condensed"", color = ""white""),
        plot.title = element_text(family = ""Roboto Condensed"", face = ""bold"", 
                                  size = title.size, color = ""yellow""),
        plot.subtitle = element_text(size = subtitle.size),
        plot.caption = element_text(size = caption.size),
        panel.background = element_rect(fill = ""white""), # red green
        plot.background = element_rect(fill = ""#002776""),
        axis.text = element_text(size = axis.text.size, color = ""white""),
        axis.text.x = element_text(size = axis.text.x.size, color = ""white""),
        axis.text.y = element_text(size = axis.text.y.size, color = ""white""),
        axis.title = element_text(size = axis.title.size),
        axis.line.x = element_blank(),
        axis.line.y = element_blank(),
        panel.grid.major.x = panel.grid.major.x,
        panel.grid.major.y = panel.grid.major.y,
        panel.grid.minor.x = panel.grid.minor.x,
        panel.grid.minor.y = panel.grid.minor.y,
        strip.text = element_text(color = ""yellow"", face = ""bold"", 
                                  size = strip.text.size, 
                                  margin = margin(4.4, 4.4, 4.4, 4.4)),
        strip.background = element_blank(),
        axis.ticks = axis.ticks
        )
}
```




```{r}
wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
```


```{r}
squads_clean <- squads %>% 
  mutate(caps = if_else(is.na(caps), 0, caps),
         goals = if_else(is.na(goals), 0, goals))
```




```{r, fig.height = 8, fig.width = 12}
goals_country_plot <- squads_clean %>% 
  filter(pos %in% c(""MF"", ""FW"")) %>% 
  group_by(country) %>% 
  mutate(median = median(goals)) %>% 
  ungroup() %>% 
  ggplot(aes(x = goals, y = reorder(country, median))) +
  ggridges::geom_density_ridges(fill = ""red"", color = ""black"", scale = 1.1) +
  geom_point(aes(x = median, y = country), position = position_nudge(y = 0.25),
             color = ""yellow"", size = 3) +
  scale_x_continuous(limits = c(0, 190),
                     expand = c(0.01, 0.01),
                     breaks = seq(0, 190, by = 5),
                     labels = seq(0, 190, by = 5)) +
  expand_limits(y = 27) +
  labs(title = ""Distribution of Goals Scored by Midfielders and Strikers"",
       subtitle = ""Women's World Cup 2019 squads, Yellow dot = Median goals"",
       x = ""Goals"", y = NULL,
       caption = glue::glue(""
                            Source: Wikipedia
                            By: @R_by_Ryo"")) +
  theme_womenWorldCup(title.size = 18,
                    subtitle.size = 12, 
                    caption.size = 8,
                    axis.text.x.size = 10,
                    axis.text.y.size = 12,
                    axis.title.size = 16,
                    strip.text.size = 18) 

goals_country_labels <- goals_country_plot +
  ggforce::geom_mark_hull(aes(filter = country == ""Canada"" & goals == 181,
                              label = ""Christine Sinclair: 181 goals""),
                          size = 1.25, con.size = 1.25, color = ""red"",
                          label.buffer = unit(5, ""mm""), label.fontsize = 10,
                          label.fill = ""red"",
                          label.family = ""Roboto Condensed"", 
                          label.colour = ""white"", con.colour = ""red"",
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""Brazil"" & goals == 110,
                              label = ""Marta: 110 goals""),
                          color = ""darkgreen"", size = 1.25,
                          label.buffer = unit(19, ""mm""), label.fontsize = 10,
                          label.fill = ""darkgreen"",
                          label.family = ""Roboto Condensed"", 
                          label.colour = ""white"", 
                          con.colour = ""darkgreen"", con.size = 1.25,
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""US"" & goals == 107,
                              label = ""Carli Lloyd: 107 goals""),
                          color = ""darkblue"", size = 1.25,
                          label.buffer = unit(27, ""mm""), label.fontsize = 10,
                          label.fill = ""darkblue"",
                          label.family = ""Roboto Condensed"", 
                          label.colour = ""white"", 
                          con.colour = ""darkblue"", con.size = 1.25,
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""Brazil"" & goals == 83,
                              label = ""Cristiane: 83 goals""),
                          color = ""darkgreen"", size = 1.25,
                          label.buffer = unit(20, ""mm""), label.fontsize = 10,
                          label.fill = ""darkgreen"",
                          label.family = ""Roboto Condensed"", 
                          label.colour = ""white"", 
                          con.colour = ""darkgreen"", con.size = 1.25, 
                          con.cap = unit(1, ""mm""), con.type = ""straight"") +
  ggforce::geom_mark_hull(aes(filter = country == ""US"" & goals == 101,
                              label = ""Alex Morgan: 101 goals""),
                          color = ""darkblue"", size = 1.25,
                          label.buffer = unit(2, ""mm""), label.fontsize = 10,
                          label.fill = ""darkblue"",
                          label.family = ""Roboto Condensed"", 
                          label.colour = ""white"", 
                          con.colour = ""darkblue"", con.size = 1.25,
                          con.cap = unit(0.1, ""mm""), con.type = ""straight"")

goals_country_labels +
  annotate(geom = ""label"", 
           label = glue(""
                        Canadian striker Christine Sinclair has scored 71 (!)
                        more national team goals than second highest scorer
                        Marta out of the players at the 2019 World Cup!""),
           x = 140, y = 8, label.padding = unit(0.8, ""lines""),
           family = ""Roboto Condensed"", color = ""white"",
           fill = ""#002776"", size = 6)
```

```{r}
ggsave(filename = here::here(""wwc_goal_dist_plot.png""), 
       height = 8, width = 12)
```

","2019-28"
"923",263,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","anime.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""4/23/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse, scales, janitor, gt, rvest, polite, glue, webshot)
```




```{r, eval=FALSE}
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")
```

```{r}
tidy_anime <- readRDS(""tidy_anime.RDS"")

glimpse(tidy_anime)
```

TV Shows ONLY and Movies ONLY

TITLE:
PICTURE: ![]()
RANK
POPULARITY
Producer: TV emoji icon

:Airing:
FROM TO
(date_format)

Genre: emoji icon
Genre average & + / - comparison
Score: bold + icon    COLOR FILL
Favorites >>> Star Icon or emoji?

Synopsis >> link pop-out?

Footnotes: ??? * if Anime original? Note if sequel?


Chronological look at GUNDAM, Ghibli, Monogatari Series??


```{r}
tidy_anime %>% 
  select(title_english, genre, rank, popularity, score, studio, start_date, end_date, synopsis)
```

```{r}
gundam_raw <- tidy_anime %>% 
  select(-related, -background, -premiered, -related, -members, -airing, -favorites,
         -title_synonyms, -title_japanese, -producers, -status, -broadcast, -genre, -source, -rank, -popularity) %>% 
  ## group by title and slice only top... otherwise 4593745 duplicate rows for each genre...
  group_by(title_english) %>% 
  slice(1) %>% 
  ungroup() %>% 
  ## filter for Gundam in title, filter for TV, OVA, Movie
  filter( str_detect(title_english, ""Gundam""), type %in% c(""TV"", ""OVA"", ""Movie"")) %>% 
  ## filter out non-main story stuff and random shorts
  filter(!title_english %in% c(""Mobile Suit Gundam SEED MSV Astray"",
                               ""Mobile Suit Gundam 0083: The Afterglow Of Zeon"",
                               ""Mobile Suit Gundam SEED Destiny Final Plus: The Chosen Future"",
                               ""Mobile Suit Gundam Unicorn Perfectibility"",
                               ""Mobile Suit Gundam Unicorn RE:0096"",
                               ""Mobile Suit Gundam Wing: Operation Meteor"",
                               ""Mobile Suit SD Gundam's Counterattack"",
                               ""Mobile Suit SD Gundam Festival"",
                               ""Musha, Knight, Commando: SD Gundam Emergency Sortie"",
                               ""Mobile Suit Zeta Gundam: A New Translation - Heir to the Stars"",
                               ""Mobile Suit Zeta Gundam: A New Translation II - Lovers"",
                               ""Mobile Suit Zeta Gundam: A New Translation III - Love Is the Pulse of the Stars"",
                               ""Mobile Suit Gundam 00 Special Edition"",
                               ""? Gundam I: Earth Light"",
                               ""? Gundam II: Moonlight Butterfly"")) %>% 
  select(-duration, -scored_by, -synopsis) %>% 
  ## chronological order
  arrange(start_date)
```

```{r}
gundam_df <- gundam_raw %>% 
  ## calculate mean score for entire-ish franchise
  ## fill in end dates, for movies just fill with start_date
  mutate(avg_score = mean(score) %>% round(digits = 2),
         end_date = case_when(
           title_english == ""Gundam Build Fighters Try"" ~ as.Date(""2015-04-01""),
           title_english == ""Mobile Suit Gundam: Iron-Blooded Orphans 2nd Season"" ~ as.Date(""2017-04-02""),
           title_english == ""Mobile Suit Gundam Unicorn"" ~ as.Date(""2014-06-06""),
           title_english == ""Mobile Suit Gundam: The Origin"" ~ as.Date(""2018-05-05""),
           type == ""Movie"" ~ start_date,
           TRUE ~ end_date
         ),
         title_english = case_when(
           lubridate::year(end_date) == 2000 ~ ""Turn A Gundam"",
           TRUE ~ title_english
         )) %>% 
  ## create ""decade"" groupings for gt subheaders
  ## create html link to MAL webpage
  mutate(newscore = score - avg_score, 
         end_year = lubridate::year(end_date),
         decade = case_when(
           end_year %in% c(1980:1989) ~ ""1980's"",
           end_year %in% c(1990:1999) ~ ""1990's"",
           end_year %in% c(2000:2009) ~ ""2000's"",
           end_year %in% c(2010:2019) ~ ""2010's""),
         rating = str_replace(rating, "" -.*"", """"),
         link = map(animeID, ~paste0(""https://myanimelist.net/anime/"", .x)) %>% unlist,
         link = glue(""[MAL Link]({link})""),
         link = md(link)) %>% 
  arrange(desc(score)) %>% 
  mutate(score_rank = row_number()) %>% 
  arrange(start_date)
```


## MAL pic

```{r}
# https://myanimelist.net/anime/2581

mal_


gundam_df %>% 
  mutate(link = map(animeID, ~paste0(""https://myanimelist.net/anime/"", .x)) %>% unlist,
         link = glue(""[MAL Link]({link})""))
```




```{r}
gundam_gt <- gundam_df %>% 
  group_by(decade) %>% 
  gt() %>% 
  tab_header(title = ""Mobile Suit Gundam"", 
             subtitle = md(""All major stories in Universal Century and alternate universes"")) %>% 
  cols_label(
    ""title_english"" = ""Title"",
    ""episodes"" = ""# of Episodes"",
    ""studio"" = ""Studio"",
    ""start_date"" = ""From"",
    ""end_date"" = ""To"",
    ""rating"" = ""Rating"",
    ""score"" = ""Score"",
    ""type"" = ""Type"",
    ""score_rank"" = ""Rank"",
    ""link"" = ""Link"") %>% 
  cols_align(align = ""center"") %>% 
  tab_spanner(
    label = ""Airing Dates"",
    columns = vars(""start_date"", ""end_date"")
  ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""green"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= 0.5 & newscore < 1
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""#49f149"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= 0 & newscore < 0.5
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""orange"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= -0.5 & newscore < 0
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""red"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= -1 & newscore < -0.5
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""purple"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore < -1
      ))
    ) %>% 
  fmt_date(columns = vars(start_date, end_date),
           date_style = 5) %>% 
  cols_hide(columns = vars(newscore, avg_score, end_year, studio, animeID)) %>% 
  tab_style(style = cells_styles(
    text_size = 20,
    text_font = ""Roboto Condensed"",
    text_color = ""white"",
    text_decorate = ""underline"",
    bkgd_color = ""blue""),
    locations = list(cells_group(""1980's""),
                     cells_group(""1990's""),
                     cells_group(""2000's""),
                     cells_group(""2010's""))) %>% 
  tab_options(heading.background.color = ""red"",
              heading.title.font.size = 26,
              heading.subtitle.font.size = 22) %>% 
  tab_style(
    style = cells_styles(text_font = ""Roboto Condensed""),
    locations = list(cells_title(groups = ""title""))
  ) %>% 
  tab_style(
    style = cells_styles(text_weight = ""bolder""),
    locations = cells_data(columns = ""title_english"")
  ) %>% 
  tab_footnote(
    footnote = ""Ranked by Score"",
    locations = cells_column_labels(columns = ""score_rank"")
  ) %>% 
  tab_footnote(
    footnote = ""Color-coded based on average rating: 7.61"",
    locations = cells_column_labels(columns = ""score"")
  ) %>% 
  fmt_markdown(columns = vars(""link"")) %>% 
  cols_move_to_end(columns = vars(""link"")) %>% 
  tab_source_note(source_note = ""Source: MyAnimeList, #TidyTuesday by @R_by_Ryo"") 
```




```{r, fig.width=10}
gundam_df %>% 
  group_by(decade) %>% 
  gt() %>% 
  ## title style
  tab_header(title = ""Mobile Suit Gundam"", 
             subtitle = md(""All major stories in Universal Century and alternate universes"")) %>% 
  tab_options(heading.background.color = ""red"",
              heading.title.font.size = 26,
              heading.subtitle.font.size = 22) %>% 
  tab_style(
    style = cells_styles(text_font = ""Roboto Condensed""),
    locations = list(cells_title(groups = ""title""))
  ) %>% 
  ## change label names
  cols_label(
    ""title_english"" = ""Title"",
    ""episodes"" = ""# of Episodes"",
    ""studio"" = ""Studio"",
    ""start_date"" = ""From"",
    ""end_date"" = ""To"",
    ""rating"" = ""Rating"",
    ""score"" = ""Score"",
    ""type"" = ""Type"",
    ""score_rank"" = ""Rank"",
    ""link"" = ""Link"") %>% 
  ## spanner title
  tab_spanner(
    label = ""Airing Dates"",
    columns = vars(""start_date"", ""end_date"")
  ) %>% 
  ## Color-fill scores
  tab_style(
      style = cells_styles(
        text_color = ""green"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= 0.5 & newscore < 1
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""#49f149"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= 0 & newscore < 0.5
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""orange"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= -0.5 & newscore < 0
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""red"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore >= -1 & newscore < -0.5
      ))
    ) %>% 
  tab_style(
      style = cells_styles(
        text_color = ""purple"",
        text_weight = ""bold""
      ),
      locations = list(cells_data(
        columns = vars(score),
        rows = newscore < -1
      ))
    ) %>% 
  ## Group title style
  tab_style(style = cells_styles(
    text_size = 20,
    text_font = ""Roboto Condensed"",
    text_color = ""white"",
    text_decorate = ""underline"",
    bkgd_color = ""blue""),
    locations = list(cells_group(""1980's""),
                     cells_group(""1990's""),
                     cells_group(""2000's""),
                     cells_group(""2010's""))) %>% 
  ## Show title
  tab_style(
    style = cells_styles(text_weight = ""bolder""),
    locations = cells_data(columns = ""title_english"")
  ) %>% 
  ## Footnotes
  tab_footnote(
    footnote = ""Ranked by Score"",
    locations = cells_column_labels(columns = ""score_rank"")
  ) %>% 
  tab_footnote(
    footnote = ""Color-coded based on average rating: 7.61"",
    locations = cells_column_labels(columns = ""score"")
  ) %>% 
  ## Misc.
  cols_align(align = ""center"") %>% 
  fmt_date(columns = vars(start_date, end_date),
           date_style = 5) %>% 
  cols_hide(columns = vars(newscore, avg_score, end_year, studio, animeID)) %>% 
  fmt_markdown(columns = vars(""link"")) %>% 
  cols_move_to_end(columns = vars(""link"")) %>% 
  tab_source_note(source_note = ""Source: MyAnimeList, #TidyTuesday by @R_by_Ryo"")
```


```{r}
gtsave <- function(data,
                   filename,
                   ...) {

  # Input object validation
  #stop_if_not_gt(data)

  # Get the lowercased file extension
  file_ext <- gtsave_file_ext(filename)

  # Stop function if a file extension is not provided
  if (file_ext == """") {

    stop(""A file extension is required in the provided filename. We can use:\n"",
         "" * `.html`/`.htm` (HTML file)\n"",
         "" * `.tex`/`.ltx`/`.rnw` (LaTeX file)\n"",
         "" * `.rtf` (RTF file)\n"",
         "" * `.png` (PNG file)\n"",
         "" * `.jpg/.jpeg` (JPEG file)\n"",
         "" * `.pdf` (PDF file)"",
         call. = FALSE)
  }

  # Use the appropriate save function based
  # on the filename extension
  switch(file_ext,
          htm = gt_save_html(data, filename, ...),
         html = gt_save_html(data, filename, ...),
          ltx = gt_save_latex(data, filename, ...),
          rnw = gt_save_latex(data, filename, ...),
          tex = gt_save_latex(data, filename, ...),
          rtf = gt_save_rtf(data, filename, ...),
          png = gt_save_webshot(data, filename, ...),
          pdf = gt_save_webshot(data, filename, ...),
         {
           stop(""The file extension used (`."", file_ext, ""`) doesn't have an "",
                ""associated saving function.\n"",
                "" * We can use either of `.html`/`.htm`, `.tex`/`.ltx`/`.rnw`, or `.rtf`"",
                call. = FALSE)
         }
  )
}

#' Saving function for an HTML file
#'
#' @importFrom htmltools as.tags save_html HTML
#' @noRd
gt_save_html <- function(data,
                         filename,
                         ...,
                         inline_css = FALSE) {

  if (inline_css) {

    data %>%
      as_raw_html(inline_css = inline_css) %>%
      htmltools::HTML() %>%
      htmltools::save_html(filename)

  } else {

    data %>%
      htmltools::as.tags() %>%
      htmltools::save_html(filename)
  }
}

#' Saving function for an image file via the webshot package
#'
#' @noRd
gt_save_webshot <- function(data,
                            filename,
                            ...,
                            zoom = 2,
                            expand = 5) {

  # Create a temporary file with the `html` extension
  tempfile_ <- tempfile(fileext = "".html"")

  # Reverse slashes on Windows filesystems
  tempfile_ <-
    tempfile_ %>%
    tidy_gsub(""\\\\"", ""/"")

  # Save gt table as HTML using the `gt_save_html()` function
  gundam_gt %>% gt_save_html(filename = tempfile_)

  # Saving an image requires the webshot package; if it's
  # not present, stop with a message
  if (requireNamespace(""webshot"", quietly = TRUE)) {

    # Save the image in the working directory
    webshot::webshot(
      url = ""gundam_gt.html"",
      file = ""gundam_gt.png"",
      selector = ""table"",
      zoom = 2,
      expand = 5
    )

  } else {
    stop(""The `webshot` package is required for saving images of gt tables."",
         call. = FALSE)
  }
}


gtsave_file_ext <- function(filename) {

  tools::file_ext(filename) %>% tolower()
}

tidy_gsub <- function(x, pattern, replacement, fixed = FALSE) {

  gsub(pattern, replacement, x, fixed = fixed)
}
```




```{r}
gt_save_html <- function(data,
                         filename,
                         ...,
                         inline_css = FALSE) {
  
  if (inline_css) {
  }}



gt_save_webshot <- function(data,
                            filename,
                            ...,
                            zoom = 2,
                            expand = 5) {
  
  # Create a temporary file with the `html` extension
  tempfile_ <- tempfile(fileext = "".html"")
  
  # Reverse slashes on Windows filesystems
  tempfile_ <-
    tempfile_ %>%
    tidy_gsub(""\\\\"", ""/"")
  
  # Save gt table as HTML using the `gt_save_html()` function
  data %>% gt_save_html(filename = tempfile_)
  
  # Saving an image requires the webshot package; if it's
  # not present, stop with a message
  if (requireNamespace(""webshot"", quietly = TRUE)) {
    
    # Save the image in the working directory
    webshot::webshot(
      url = paste0(""file:///"", tempfile_),
      file = filename,
      selector = ""table"",
      zoom = zoom,
      expand = expand
    )
    
  } else {
    stop(""The `webshot` package is required for saving images of gt tables."",
         call. = FALSE)
  }
}

## gtsave PNG
gtsave_png <- function(data,
                       filename,
                       ...) {
  
  
  if (file_ext == """") {
    stop(""A file extension is required in the provided filename. We can use:\n"",
         "" * `.html`/`.htm` (HTML file)\n"",
         "" * `.tex`/`.ltx`/`.rnw` (LaTeX file)\n"",
         "" * `.rtf` (RTF file)\n"",
         "" * `.png` (PNG file)\n"",
         "" * `.jpg/.jpeg` (JPEG file)\n"",
         "" * `.pdf` (PDF file)"",
         call. = FALSE)
  }
  
  switch(file_ext,
         png = gt_save_webshot(data, filename, ...),
         {
           stop(""The file extension used (`."", file_ext, ""`) doesn't have an "",
                ""associated saving function.\n"",
           )
         })
}

gtsave_png(filename = ""gundam_gt.png"")
         
```

















- footnotes: score >>> fill scale dependent on + / - avg score
-- -2 -1 /  -1 -0.5 / -0.5 0 +0.5 / +0.5 +1 / +1 +2
- studio as a sub-header separate
- color fill on rating
- airing and from-to subheader

```{r}
gundam_df %>% 
  #group_by(decade) %>% 
  gt(groupname_col = ""decade"",
     rownames_to_stub = TRUE,
     rowname_col = ""title_english"") %>% 
  #tab_header(title = ""Mobile Suit Gundam"") %>% 
  summary_rows(
    groups = FALSE,
    columns = vars(score, favorites),
    fns = list(thingymacdoodle = ~sum(.)))
```




```{r}
gundam_synopsis <- tidy_anime %>% 
  select(-related, -animeID, -name, -background, -premiered, -related, -members, -episodes, -airing, 
         -title_synonyms, -title_japanese, -producers, -status, -broadcast, -genre, -source, -rank, -popularity) %>% 
  group_by(title_english) %>% 
  slice(1) %>% 
  ungroup() %>% 
  filter(str_detect(title_english, ""Gundam""), type == ""TV"") %>% 
  select(title_english, synopsis) 
```




```{r}
tidy_anime %>% 
  summarize(avg_num_scorers = mean(scored_by))

tidy_anime %>% 
  select(genre) %>% 
  unique()
```




```{r}
tidy_anime %>% 
  select(-genre) %>% 
  filter(type == ""TV"", scored_by > 50000) %>% 
  mutate(premiered = as_factor(premiered),
         rating = as_factor(rating)) %>% 
  group_by(title_english) %>% 
  summarize(score = mean(score)) %>% 
  arrange(desc(score)) %>% 
  head(10)
```

","2019-17"
"924",264,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","plastic_waste.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""5/21/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# pkgs

```{r}
pacman::p_load(tidyverse, scales, janitor, glue, tvthemes)
```

# data

```{r}
coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")
```



```{r}
glimpse(waste_vs_gdp)


waste_vs_gdp %>% 
  janitor::clean_names() %>% 
  rename(waste_percapita_person_day = per_capita_plastic_waste_kilograms_per_person_per_day) %>% 
  filter(year >= 2000) %>% 
  group_by(entity) %>% 
  mutate(sum_na = sum(is.na(waste_percapita_person_day))) %>% # from 28 years
  filter(sum_na < 20) %>% 
  View()
```

","2019-21"
"925",268,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","student-teacher.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""6/2/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse, scales, janitor, rvest, polite, glue)
```




```{r}
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")


student_ratio <- student_ratio %>% 
  select(-edulit_ind, -flag_codes, -flags)


str(student_ratio)
glimpse(student_ratio)
student_ratio %>% select(-student_ratio, -country_code) %>% map(~unique(.))
student_ratio %>% select(indicator) %>% unique()

student_ratio %>% 
  filter(indicator == ""Primary Education"") %>% 
  ggplot(aes(x = year, y = student_ratio, group = country)) +
  geom_point() +
  geom_line() +
  facet_wrap(~region)
```

","2019-19"
"926",269,"https://github.com/Ryo-N7/tidy_tuesday_april_3","Ryo-N7","tidy_tuesday_april_3","tennis.Rmd","---
title: ""Untitled""
author: ""RN7""
date: ""April 9, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
pacman::p_load(tidyverse, scales)
```




```{r}
player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")

grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")

grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")
```

","2019-15"
"927",369,"https://github.com/r0mymendez/R/tree/master/TidyTuesday/20140423-BirdCollisions","r0mymendez","R","TidyTuesday/20140423-BirdCollisions/tidytuesday_29190501.R","rm(list=ls())
library(tidyverse)
library(extrafont)
library(gridExtra)
library(grid)
library(ggpubr)

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")
+ scale_color_jama()

#Gauge plots
df1=bird_collisions%>%
  mutate(year=format(as.Date(bird_collisions$date, format=""%Y-%m/%d""),""%Y""))%>%
  filter(year %in% 1996:2016)%>%
        count(family)%>%
        mutate(
              prop=round(n/sum(n),2),
              label=paste0(round(n/sum(n)*100,0),'%')
                      )%>%
        top_n(5,n)%>%
        arrange(n)%>%
        mutate(val=c(1,1,2,3,3),val=as.factor(val))
      
df1$family=
  factor(df1$family,
            levels = c('Regulidae','Certhiidae',
                 'Turdidae','Parulidae','Passerellidae'))

a=df1%>%
ggplot(aes(fill = val, 
           ymax = prop, 
           ymin = 0, 
           xmax = 2, 
           xmin = 1)) +
  geom_rect(aes(ymax=1, ymin=0, xmax=2, xmin=1),
            fill =""#ece8bd"") +
  geom_rect(color='white') + 
  coord_polar(theta = ""y"",start=-pi/2) + xlim(c(0, 2)) + ylim(c(0,2)) +
  geom_text(aes(x = 0, y = 0, label = label, colour=val), size=6.5, family=""Mr Bedfort"",fontface = ""bold"") +
  geom_text(aes(x=1.5, y=1.5, label=family), family=""Mr Bedfort"", size=6.5,colour='white') + 
  facet_wrap(~family, ncol = 5) +
  theme_void() +
  scale_fill_manual(values = c(""1""=""#C9146C"", ""2""=""#DA9112"", ""3""=""#129188"")) +
  scale_colour_manual(values = c(""1""=""#C9146C"", ""2""=""#DA9112"", ""3""=""#129188"")) +
  theme(strip.background = element_blank(),
        strip.text.x = element_blank()) +
  guides(fill=FALSE) +
  guides(colour=FALSE)+
  theme(plot.background = element_rect(fill='#2a2a2a',colour = ""#2a2a2a""),
        panel.background = element_rect(fill = ""#2a2a2a"", colour = ""#2a2a2a""),
        axis.ticks = element_blank(),
        panel.border = element_blank()
  )





df2=bird_collisions%>%
  mutate(year=format(as.Date(bird_collisions$date, format=""%Y-%m/%d""),""%Y""))%>%
  select(family,year,habitat)%>%
  count(family,year,habitat)%>%
  filter(year %in% 1996:2016)


b=ggplot(df2, aes(x=year,y=family,color=family))+
  geom_quasirandom(alpha=.9,aes(size=n*2),
                   groupOnX = FALSE, 
                   show.legend = FALSE)+
  labs(title='Bird Collisions between 1996-2016',
       subtitle='Data: Winger et al. 2019 (doi: 10.1098/rspb.2019.0364)',
       y='',
       caption='')+
      theme(plot.background = element_rect(fill='#2a2a2a',colour = ""#2a2a2a""),
            panel.background = element_rect(fill = ""#2a2a2a"", colour = ""#2a2a2a""),
            axis.text = element_text(color='white',family = ""Lucida Calligraphy""),
            plot.caption = element_text(color='white'),
            plot.title = element_text(color='white',family = ""Mr Bedfort"",size=30,face = 'bold'),
            plot.subtitle = element_text(color = ""white"",size = 8),
            axis.title = element_text(color = ""white"",family = ""Mr Bedfort"",size = 20),
            panel.grid.major.y = element_line(colour = ""#2a2a2a"", size = .2),
            panel.grid.minor.y = element_blank(),
            panel.grid.major.x = element_line(colour = ""#fdfdf3"", size = .2),
            panel.grid.minor = element_blank())

b


title='#Tidytuesday'

df <- data.frame(
    x = c(1, 1, 2, 2, 1.5),
    y = c(1, 2, 1, 2, 1.5),
    text = c("""", """", """", """", title))
  
  
 g= ggplot(df, aes(x, y)) +
    geom_text(aes(label = text),color=""white"",size=10,family = ""Mr Bedfort"")+
    labs(x='',y='',caption='Visualization by @r0mymendez')+
    theme(
      plot.background  = element_rect(color = '#2a2a2a',fill='#2a2a2a'),
      panel.background = element_rect(color = '#2a2a2a',fill='#2a2a2a'),
      panel.grid =  element_line(colour = '#2a2a2a'),
      axis.text= element_blank(),
      axis.line=element_blank(),
      axis.ticks = element_blank(),
      plot.caption = element_text(color='white',hjust = 0)
      )
  
ggarrange(b,
  ggarrange(g,a,widths= c( 0.5, 1.2),
                      ncol = 2, nrow = 1) +
    theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a'),
          panel.background = element_rect(fill='#2a2a2a',color ='#2a2a2a')), 
          heights = c(2, 0.7),
          ncol = 1, nrow = 2)  +
  theme(plot.background = element_rect(fill='#2a2a2a',color ='#2a2a2a' ))
","2019-18"
"928",383,"https://github.com/r0mymendez/R","r0mymendez","R","TidyTuesday/20140423-anime/anime_script.R","rm(list = ls())
library(ghibli)
library(tidyverse)
library(ggrepel)
library(patchwork)
library(scales)
library(extrafont)
library(showtext)
pacman::p_load(jpeg, png, ggplot2, grid, neuropsychology)
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

df=tidy_anime%>%select(title_english,studio,type,source,scored_by,score,rating,rank,popularity)
df=unique(df%>%filter(is.na(title_english)==FALSE))

imgage1 <- png::readPNG(""16.png"")

 g0=
  df%>%count(rating)%>%filter(is.na(rating)==F)%>%
  mutate(rating=case_when(
    rating==""R - 17+ (violence & profanity)""~ 'R17 \n (violence & profanity)',
    rating==""PG-13 - Teens 13 or older""     ~ 'PG13 \n (Teens 13 or older)',
    rating==""PG - Children""                 ~ 'PG (Children)', 
    rating==""R+ - Mild Nudity""              ~ 'R+ \n (Mild Nudity)',
    rating==""G - All Ages""                  ~ 'G (All Ages)', 
    rating== ""None""                          ~ 'None')
    )%>%
  mutate(rating=reorder(rating,n))%>%
  ggplot(aes(rating,n,fill=rating))+
  annotation_custom(rasterGrob(imgage1, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  
  geom_col(show.legend = F,color='black')+
  scale_fill_ghibli_d(""MarnieMedium1"")+
  coord_flip()+
  labs(x='',y='',title='Anime: classification and studios',subtitle='')+
  theme_bw()+
  theme(axis.text.y = element_text(color=""#233a77"",
                                 size=rel(0.7),hjust=0.5),
        axis.text.x = element_text(color=""#233a77"",
                                   size=rel(1)),
        axis.title = element_text(color=""#233a77"",
                                    size=rel(0.8)),
        text=element_text(size=16, family=""Bangers""),
        plot.title = element_text(size = 25),
        )
 

imgage <- png::readPNG(""16.png"")


g1=
  df%>%count(studio)%>%filter(is.na(studio)==F)%>%
  top_n(5,n)%>%
  mutate(studio=reorder(studio,n))%>%
  ggplot(aes(studio,n,fill=studio))+
  annotation_custom(rasterGrob(imgage, 
                               width = unit(1,""npc""), 
                               height = unit(1,""npc"")), 
                    -Inf, Inf, -Inf, Inf) +
  geom_col(show.legend = F,color='black',alpha=0.6)+
  scale_fill_ghibli_d(""MarnieMedium1"")+
  coord_flip()+
  labs(x='',y='')+
  theme_bw()+
  theme(axis.text.y = element_text(color=""#233a77"",
                                   size=rel(0.8),hjust=0.5),
        axis.text.x = element_text(color=""#233a77"",
                                   size=rel(1)),
        axis.title = element_text(color=""#233a77"",
                                  size=rel(0.8)),
        text=element_text(size=16,  family=""Bangers""),
        plot.title = element_text(size = 25)
  )



img_a <- png::readPNG(""6.png"") 
a <- grid::rasterGrob(img_a, interpolate = T) 


g2=
  df%>%
    select(studio,popularity,rating,score,rank)%>%
    mutate(rating=case_when(
      rating==""R - 17+ (violence & profanity)""~ 'R 17',
      rating==""PG-13 - Teens 13 or older""     ~ 'PG 13',
      rating==""PG - Children""                 ~ 'PG', 
      rating==""R+ - Mild Nudity""              ~ 'R+',
      rating==""G - All Ages""                  ~ 'G', 
      rating== ""None""                          ~ 'None')
    )%>%
  filter(studio=='Toei Animation')%>%
  ggplot(aes(x=rank,y=popularity,color=rating)) +
  geom_point()+
  scale_color_ghibli_d(""MarnieMedium1"") +
  annotation_custom(a, xmin = 8000, xmax = 16000,
                     ymin = 0, ymax = 6000)  +
  labs(x = ""Ranking"", y = ""Popularity"",
       title = ""Toei Animation Studio"",
       subtitle = """")+
  theme_bw() +
  guides(col  = guide_legend(title = ""classif.""))+
  theme(
    text=element_text(size=16,  family=""Bangers""),
    legend.text=element_text(size=rel(0.9)),
    panel.border=element_rect(color=""#f4e3b5"", fill=NA, size=1),
    panel.background = element_blank(),
    plot.title = element_text(size = 25)
  )


imgagec <- jpeg::readJPEG(""sp4.jpg"")


g4= ggplot() + annotation_custom(rasterGrob(imgagec, 
                                            width = unit(1,""npc""), 
                                            height = unit(1,""npc"")), 
                                 -Inf, Inf, -Inf, Inf) 
  
(g0|g1) / (g2 + g4 + plot_layout(ncol=2,widths=c(2,1)))

  
","2019-17"
"929",391,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TiduTuesday_Birdsspotting.R","#TidyTuesday
#===============================================================================
#TidyTuesday
# Birdsspotting @Christmas.
#ChordDiagram
#@sil_aarts
#===============================================================================

#Load libraries
library(tidyverse)
library(circlize)
library(dplyr)
library(chorddiag)  
library(LaCroixColoR)
library(extrafont)

#Read file
birds <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

#Check what is in the data! Yep normal names and Latin have the same n.
unique(birds$species)
unique(birds$species_latin)

#Check unique rows
birds2 <- birds %>%
  select(2:6)

#Order count
birds2 <- birds2[order(-birds2$how_many_counted),]

#Sum count
birds3 <- birds2 %>% 
  group_by(species, species_latin) %>% 
  summarise(total = sum(how_many_counted, na.rm=T))

#Order count
birds4 <- birds3[order(-birds3$total),]

#Select top 10
birds5 <- birds4 %>%
  subset(total > 155000)

#Divide by 1000 for ease of use
birds5$total <- birds5$total/1000

#Change colnames
colnames(birds5) <- c(""names"", ""key"", ""value"")

#Make some colours
col <- lacroix_palette(""Pamplemousse"", n = 10, type = ""continuous"")

#Set some parameters: insert gap to see difference between col and rows
circos.par(start.degree = 0, track.margin = c(-0.1, 0.1), points.overflow.warning = FALSE)
par(mar = rep(0, 4), par(bg = ""grey30""), par(family = ""serif""))

#ChordDiagram plot
chordDiagram(
  x = birds5, 
  grid.col = col,
  transparency = 0.2,
  directional = 1,
  direction.type = c(""arrows""), 
  diffHeight  = -0.05,
  annotationTrack = ""grid"", 
  annotationTrackHeight = c(0.05, 0.3),
  link.arr.type = ""big.arrow"", 
  link.sort = TRUE, 
  link.largest.ontop = TRUE,
  link.border=""white"",
  link.lwd=2,
  link.arr.length = 0.1)

#Add axis all around and text using the labels
circos.trackPlotRegion(track.index = 1, 
                       bg.border = NA, 
                       panel.fun = function(x, y) {
                        xlim = get.cell.meta.data(""xlim"")
                        ylim = get.cell.meta.data(""ylim"")
                        sector.index = get.cell.meta.data(""sector.index"")
                        
#Tick white line all the way around to get the axis.ticks in the white 
circos.rect(xleft=xlim[1], ybottom=3, xright=xlim[2], ytop=1, col = ""white"")

#Add names to the sector, make it facing inside, size letters=cex
circos.text(x = mean(xlim), y = 4.5, labels = sector.index, facing = ""inside"", cex = 0.9, col=""white"")

#Add ticks on axis
circos.axis(major.at = c(0, 200, 400, 600, 800, 1000, 1200, 1400, 1600), direction = ""outside"",  col=""black"") }
)

circos.clear()

#Add title
text(0, 0.1,""TidyTuesday"", cex=3, col=""black"")
text(0, 0, ""Birdspotting since 1921"", cex = 2, col=""black"")

#Add read it info
text(-1.1,-0.92,c(""How to read this plot?""), pos=4, cex=1.2, col=""black"")
text(-1.1,-0.96,c(""Arrows represent names of bird species (bottom) ""), pos=4, cex=1, col=""black"")
text(-1.1,-1.00,c(""and their Latin names (top). Arrows are indicative""), pos=4, cex=1, col=""black"")
text(-1.1,-1.04,c(""for the top 5 most spotted birds (x1000) around Christmas""), pos=4, cex=1, col=""black"")

#Add caption
text(1.1,-1.00,c(""Plot by @sil_aarts""), pos=2, cex=1, col=""black"")
text(1.1,-1.04,c(""Source: Bird Studies Canada | Hamilton area of Ontario""), pos=2, cex=1, col=""black"")
","2019-18"
"930",393,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_AnimeGGanimate.R","#TidyTuesday
#Anime-animated

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)

#Load data
anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

#Delete some columns to make some space and delete all NA
anime$synopsis <- NULL
anime$background <- NULL
anime2 <- na.omit(anime)

#Filter only unique names
anime3 <- unique(anime2[c(""name"", ""score"",""rank"",""start_date"", ""members"",""studio"")])

#Make start_date, year only
anime3$year <- format(anime3$start_date, ""%Y"")
anime3$year <- as.numeric(anime3$year)

#Change members variabele
anime3$members <- anime3$members/1000

#GGplot: scatter
p <- ggplot(anime3, 
  aes(x = members, y=score, size = rank, colour =studio)
) +
  geom_point(show.legend = F, alpha = 0.7) +
  scale_color_viridis_d() +
  scale_size(range = c(2, 10)) +
  labs(x = ""# of members (x1000)"", y = ""Score"", caption = ""Source: MyAnimeList | Plot by @sil_aarts"",
       title = ""TidyTuesday: Anime scatterplot \n Relation between # of members and score (by rank and studio) in {round(frame_time)}"")+
  shadow_mark(colour=""black"", size = 1)+ 
  theme_bw()+
  theme(text=element_text(family=""Times New Roman"", face=""bold"", size=12))+
  transition_time(year) 
  
#Run animation
p2 <- animate(p, nframes = 150, fps=3)

#Save it!
anim_save(""Desktop/R/TidyTuesday/Anime.gif"", p2)
","2019-17"
"931",395,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Birds.R","#TidyTuesday
#===============================================================================
#TidyTuesday
# Birds of feather...collide together?!
#ChordDiagram
#@sil_aarts
#===============================================================================

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

#Load libraries
library(tidyverse)
library(viridis)
library(patchwork)
library(hrbrthemes)
library(circlize)
library(dplyr)
library(RColorBrewer)
library(chorddiag)  
library(wesanderson)

#Read file
birds <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")

#Check what is in the data!
unique(birds$family)
unique(birds$species)
unique(birds$genus)

#Which birds ten to hurt themselves the most?
birds2 <- birds %>% group_by(species, family) %>% mutate(count = n())

#Just check if aggregation worked
birds_check <- birds %>%
  count(species)

#Select unique rows (first delete date)
birds2$date <- NULL
birds3 <- unique(birds2)
#Only select MP
birds4 <- birds3 %>%
  filter(locality==""MP"")

#Select ony those colums we need for our ChordDiagram
birds5 <- birds4 %>%
   select(2,4,8)

#Select birds who hurt themselves the most: top 10
birds6 <- birds5[order(-birds5$count),] 
birds7 <- birds6 %>%
 filter(count > 2300)

#Divide by 1000 for ease of use
birds7$count <- birds7$count/1000

#Change colnames
colnames(birds7) <- c(""names"", ""key"", ""value"")

#Make some colours (n=14 for # of sectors )
pal <- wes_palette(""IsleofDogs1"", 14, type = ""continuous"")

#Set some parameters
circos.clear()
circos.par(start.degree = 90, gap.degree = 5, track.margin = c(-0.1, 0.1), points.overflow.warning = FALSE)
par(mar = rep(0, 5))

#ChordDiargram plot
chordDiagram(
  x = birds7, 
  grid.col = pal,
  transparency = 0.25,
  directional = 1,
  direction.type = c(""arrows"", ""diffHeight""), 
  diffHeight  = -0.03,
  annotationTrack = ""grid"", 
  annotationTrackHeight = c(0.05, 0.8),
  link.arr.type = ""big.arrow"", 
  link.sort = TRUE, 
  link.largest.ontop = TRUE)

#Add axis all around and text using the labels
circos.trackPlotRegion(track.index = 1, bg.border = NA, 
#Set sector.index
panel.fun = function(x, y) {
    xlim = get.cell.meta.data(""xlim"")
    sector.index = get.cell.meta.data(""sector.index"")
    
#Add names to the sector, make it facing inside, size letters=cex
circos.text(x = mean(xlim), y = 3, labels = sector.index, facing = ""inside"", cex = 0.8)
    
#Add ticks on axis
circos.axis(h = ""top"", minor.ticks = 1, major.tick.percentage=1, labels.niceFacing = FALSE) }
)


","2019-18"
"932",398,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_FIFA.R","#TidyTuesday
#FIFA!
#Why? Because I love soccer

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(ggmap)
library(zipcode)
library(ggthemes)
library(extrafont)
library(emoGG)

#Read file
fifa <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018/2018-06-12/week11_fifa_audience.csv"")

#Delete first column
fifa$X1 <- NULL

#Select multiple countries which the Dutch still have matches against in 2019
selection <- c(""Netherlands"", ""United Kingdom"", ""Germany"", ""Estonia"", ""Belarus"")
fifa2 <- filter(fifa, country %in% selection)

#Estonia is all NULL so delete that row!
fifa3 <- fifa3[-c(5),]

#GGplot
p <- ggplot(fifa3, aes (country, tv_audience_share)) + geom_emoji(emoji=""26bd"")+
  ggtitle(label = ""TidyTuesday (2018): World Cup 2010 TV audience"", subtitle=""The Dutch team and some countries we still have to play against in 2019"")+
  xlab("""")+ ylab(""Tv viewership (% of population)"")+labs(caption=""Source: fivethirtyteight.com | Plot by: @sil_aarts"")+
  coord_flip()+
  theme_tufte()+
  theme(panel.background = element_rect(fill = ""darkgreen""),
        text=element_text(family=""Comic Sans MS""),
        plot.title = element_text(color=""black"", face=""bold"", size=16, hjust=0),
        plot.subtitle=element_text(size=14, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=12, hjust=1, color=""black""),
        legend.title = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x= element_text(size=10, vjust = 0.5, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=14,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.5, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))
  
#Run it!
p
","2018-11"
"933",400,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Female earnings II.R","#TidyTuyesday
#Female earnings II

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(readr)

#Read file
female <- read.csv(""Desktop/employed_gender.csv"")

#Subset
female2<- subset(female, year %in% c(1970, 1980, 1990, 2000, 2010))

#Create new data.frame
female3 <- data.frame(part_time = c(female2$part_time_female, female2$part_time_male))
female3$sex <- ifelse(female3$part_time < 20,  c(""male""), c(""female"")) 
female3$year <- c(1970, 1980, 1990, 2000, 2010, 1970, 1980, 1990, 2000, 2010)

#Create colours
fill <- c(""darkmagenta"", ""darkkhaki"")

#GGplot- bar
p <- ggplot(female3, aes(x=year, y=part_time, fill=sex)) + 
  geom_col(position=""dodge"")+
  scale_fill_manual(values=fill)+
  ggtitle(label = ""TidyTuesday: women in the workplace"", subtitle=""Are you working part-time?"")+
  xlab("""")+ ylab(""% of employed"")+labs(caption=""Source: Bureau of Labor,  Plot by @sil_aarts"")+
  theme(panel.background = element_rect(fill = ""white""),axis.line = element_line(size=1, colour = ""black""),
        plot.title = element_text(color=""black"", face=""bold"", size=14, hjust=0),
        plot.subtitle=element_text(size=13, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=10, hjust=1, color=""azure4""),
        legend.title = element_blank(),
        axis.text.x= element_text(size=10,angle = 90, vjust = 0.5, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.5, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold"")
  )

#Check it
p

#Animate it
p+ transition_states(year,wrap=F) +
  shadow_mark()
  
#Save it!
animate(p, height = 600, width =600)
anim_save(""Desktop/R/TidyTuesday/Female_earningsII.gif"")
","2019-10"
"934",401,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Female earnings.R","#TidyTuyesday
#Female earnings
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(gapminder)
library(RColorBrewer)
library(extrafont)
library(readr)

#Read file
female <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/earnings_female.csv"")

#Year to unique
year2 <- unique(female$Year)

#GGplot - geom_area
p <- ggplot(female, aes(x = Year, y = percent, group=group, color=group))+
  geom_line(aes(x=Year, y=percent))+
  scale_color_manual(values = c(""grey"", ""grey"", ""pink"", rep(""gray"", 4), ""black""))+
  geom_point(aes(colour=group), size=2)+   
  ggtitle(label = ""TidyTuesday: Women in workplace"", subtitle=""Female salary percent of male salary"")+
  xlab(""Year"")+ ylab(""Percentage"")+labs(caption=""Source: Bureau of Labor,  Plot by @sil_aarts"")+
  theme(panel.background = element_rect(fill = ""white""),axis.line = element_line(size=1, colour = ""black""),
        plot.title = element_text(color=""black"", face=""bold"", size=16, hjust=0),
        legend.title = element_blank(),
        plot.subtitle=element_text(size=12, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=8, hjust=1, color=""azure4""),
        axis.text.x= element_text(size=10,angle = 90, vjust = 0.5, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.5, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""),
  )

#Check it
p 

#GGplot save
ggsave(""Desktop/R/TidyTuesday/Female_earnings.png"")
","2019-10"
"935",404,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Horror.R","#TidyTuesday
#===============================================================================
#THE HORROR!
#@sil_aarts
#===========================================================================
#Load libraries
library(tidyverse)
library(showtext)
library(showtextdb)
library(ggmap)
library(ggthemes)
library(grid)
library(gridExtra)
library(magick)

#Load files
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

#Select only rows with non-missing filming_locations
data1 <- data %>%
  drop_na(filming_locations)

#String split on filming_locations
data2 <- data1 %>%
  separate(filming_locations, c(""place"", ""city"", ""state""), "","")

#Change value of a column to another column on conditon
data3 <- mutate(data2, city = ifelse(city== ""USA"", city, place))
data3$city[data3$city == ""Wellington""] <- ""Florida""

#Select 20 most horrible movies!
data4 <- data3 %>%
  top_n(-20, review_rating)

#Merge long & lat
data5 <- data4 %>%
  drop_na(city)
register_google(key = ""Your key here"") 
geo <- geocode(data5$city) 
data6 <- merge(data5, geo, by.x = 0, by.y = 0)

#Add an image
image <- image_read(""https://cdn.pixabay.com/photo/2015/06/22/23/21/filmklappe-818198_960_720.jpg"")
image2 <- image_read(""https://www.nicepng.com/png/full/439-4394330_free-blood-drip-png-real-blood-effect-png.png"")
movie <- grid::rasterGrob(image, interpolate = T) 
blood <- grid::rasterGrob(image2, interpolate = T)

#Pixels!
#Low resolution is lot of dots. High is 'dotless'.
resolution <- 1.5
lat <- tibble(lat = seq(-90, 90, by = resolution))
long <- tibble(long = seq(-180, 180, by = resolution))
#Lakes are optional
pixels <- merge(lat, long, all = TRUE) %>%
  mutate(country = maps::map.where(""world"", long, lat),
         lakes = maps::map.where(""lakes"", long, lat)) %>% 
  filter(!is.na(country) & is.na(lakes)) %>%
  select(-lakes)

#Choose font
font_add_google(""Barrio"", ""C"")
showtext_auto()

#Theme
theme <-  theme_map() +
  theme(
    text = element_text(family=""C""),
    plot.background = element_rect(fill = ""white"", color = NA),
    panel.background = element_rect(fill = ""white"", color = NA), 
    plot.title= element_text(size = 50, color=""red"", hjust=0.5),
    plot.subtitle= element_text(size = 14, color=""black"", hjust=0.5),
    plot.caption = element_text(size = 10, color=""red""),
    panel.grid = element_blank(),
    axis.title.x = element_blank(),
    axis.title.y = element_blank())
    

#GGplot: ggmap
pixelsmap <- ggplot() + 
    geom_point(data = pixels, aes(x = long, y = lat), color = ""grey30"", size = 1)

#Run quartz for showtext
quartz()

#GGplot: ggmap
p <- pixelsmap + 
  geom_point(data =data6, aes(x = lon, y = lat), color = ""red"", size = 2) +
  geom_point(data =data6, aes(x = lon, y = lat), color = ""red"", size = 4, alpha=0.4)+
  #Peru
  annotation_custom(movie, xmin= -110, xmax= -150, ymin= -40, ymax= -10)+
  geom_text(aes(x = -130, y = -30), label=""Lima, Peru (2017)\nUna Comedia\nMarcabia\nRating 1.0"", color=""white"", size=2.5, family=""C"")+
  annotation_custom(blood, xmin= -110, xmax= -150, ymin= -50, ymax= -40)+
  #Russia
  annotation_custom(movie, xmin= 130, xmax=170, ymin=10, ymax=40)+
  geom_text(aes(x = 150, y = 20), label=""Pereslavl-Zalessky\nRussia (2017)\nInterstelar 2:\nOperation Terra 2040\nRating 1.6"", color=""white"", size=2.1, family=""C"")+
  annotation_custom(blood, xmin= 130, xmax= 170, ymin= 0, ymax= 10)+
  labs(title= ""THE HORROR"", 
       subtitle=""Where were the most 'horrible' movies shot? Locations where movies with ratings <2.0 were filmed*."", 
       caption=""*Scale 1 (low) - 10 (high) rating | Source: IMDB | Plot by: @sil_aarts"")+
  coord_sf(clip = ""on"",
           ylim = c(-75, 85),
           xlim = c(-160, 170))+
  theme

#Run it!
p
","2019-43"
"936",405,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Meteorites.R","#TidyTuesday
#===============================================================================
#Rainclouds of meteorites.
#@sil_aarts
#===============================================================================
install.packages(""magick"")
install.packages(""grid"")
install.packages(""gridExtra"")

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(tidyr)
library(extrafont)
library(magick)
library(grid)
library(gridExtra)

#Load file
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

#Check levels
data$class <- as.factor(data$class)
levels(data$class)

#Check unique
data$id <- NULL
data2 <- unique(data)

#Only non-missing data
data2$class <- as.character(data2$class)
data3 <- na.omit(data2)

#Select data from 2000 onwards
data4 <- data3 %>% 
  filter(year > 1999)

#Count number of meteorites per class
data5 <- data4 %>%
  group_by(class) %>%
  mutate(count = n())

#Order data on count peer class
data5$count <- as.numeric(data5$count)
data6 <- data5[order(-data5$count),] 

#Select 2 columns to see top 5 class: L6, L5, H5, H6, LL6
data7 <- data6 %>%
  select(3,10)
data8 <- unique(data7)

#Select original dataset with only those 5 top classes that fall on Earth
data_final <- data6 %>%
  filter(class==""L6"" | class==""L5"" | class==""H5""| class==""H6""| class==""LL6"")

#Make some colours
col <- c(""darkred"",""#FC3D21"", ""cornflowerblue"" ,""dodgerblue4"",""#0B3D91"")

#Add Images
#Add image NASA
image2 <- image_read(""Desktop/Nasa.jpg"")
NASA <- grid::rasterGrob(image2, interpolate = T) 
#Add background image: meteorites
image3 <- image_read(""Desktop/meteo.jpg"")
meteo <- grid::rasterGrob(image3, interpolate = T) 

#Calculate year of most meteorites:
data_year <- data_final %>%
  group_by(year) %>%
  mutate(count_year = n())
data_year <- data_year[order(-data_year$count_year),] 

#Start using my own theme
theme_sil <- theme_void() + 
  theme(
    legend.position = ""none"",
    text = element_text(size = 10, family=""Courier New""),
    plot.background = element_rect(fill=""black""),
    panel.background = element_rect(fill= ""transparent""),
    plot.title=element_text(size=20, hjust=0, face='bold', colour=""white"", lineheight = 1),
    plot.subtitle=element_text(size=16, hjust=0, colour=""white""),
    plot.caption=element_text(size=10, hjust=1, colour=""white""),
    axis.text = element_text(size = 12, colour=""white"", face=""bold""))

#GGplot
p <- ggplot(data = data_final, aes(x = class, y = year, fill = class)) +
  annotation_custom(rasterGrob(image3, width = unit(1,""npc""), height = unit(1,""npc"")),-Inf, Inf, -Inf, Inf)+
  annotation_custom(NASA, xmin=0, xmax=1, ymin=1998.5, ymax=1999.5)+
  geom_point(aes(y = year, color = class), position = position_jitter(width = .15), size = 1.5, alpha = 0.8) +
  geom_boxplot(width = .3, alpha = 0.8, colour = ""white"", outlier.shape = 1) +
  geom_flat_violin(position = position_nudge(x=0.25, y=0), alpha = .7) +
  labs(title = ""TidyTuesday: Meteorites"" ,
       subtitle = ""The 5 classes of meteorites that have fallen to Earth the most since 2000"" ,
       caption=""Source: NASA | Plot by @sil_aarts"")+
  scale_fill_manual(values=col)+
  scale_color_manual(values=col)+
  scale_y_continuous(breaks=seq(2000, 2013, 2))+
  coord_flip(clip=""off"")+
  theme_bw() +
  theme_sil

#Run it
p
","2019-24"
"937",408,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Nobelprizes.R","#TidyTuesday
#Nobel prices

#Load libraries
library(dplyr)
library(tidyr)
library(RColorBrewer)
library(ggplot2)
library(extrafont)

#Load data
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

#Filter only females
data1 <- data %>%
  filter(gender==""Female"")

#Add a column
data1[""count""] <- 1

#Aggregate: sum winners per category
data2 <- data1 %>%
  group_by(gender,category) %>% 
  mutate(count=n())

#Make soms colours
mycolors <- c(""#330244"",""#0050B6"",""#250462"",""#003E38"", ""#007067"",""#56416F"")

#GGplot: barchart
p <- ggplot(data=data2, aes(x=category)) + 
  geom_bar(aes(fill=category), width = 0.8)+
  scale_fill_manual(values = mycolors)+
  coord_polar()+
  labs(title=""TidyTuesday: Female Nobel Prize Winners"", 
       subtitle=""Number of Female Winners since first winner in 1903"",
       x="""", 
       y="""",
       caption=""Source: Kaggle | Plot by @sil_aarts"")+
  theme_minimal(10) +
  theme(legend.position = ""none"",
        panel.background = element_rect(fill = 'grey25'),
        plot.title=element_text(size=14, hjust=0.2, family=""Courier New"",face='bold'),
        plot.subtitle=element_text(size=12, hjust=0.2, family=""Courier New""),
        plot.caption=element_text(size=10, hjust=0.2,family=""Courier New""),
        axis.text.x = element_text(size=10, family=""Courier"", face=""bold"", colour=""white""),
        axis.text.y = element_text(size=9, family=""Courier"", face=""bold"", colour=""black""),
        axis.title.x = element_blank(),
        axis.title.y=element_blank(),
        axis.ticks.y= element_blank(),
        axis.ticks.x= element_blank())


#Run it!
p
","2019-20"
"938",409,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Nuclearexplosions.R","#TidyTuesday
#===============================================================================
#Nuclear Explotions
#@sil_aarts
#===========================================================================

#Load libraries
library(ggplot2)
library(dplyr)
library(zoo)
library(tidyverse)
library(ggtext)
library(extrafont)
library(ggforce)
library(showtext)
library(showtextdb)

#Load file
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")
summary(data)
data1 <- data_frame(unique(data$id_no))

#Sort 
data1 <- data[order(-data$magnitude_body),]
#How many explotions with mb=0?
data2 <- data1 %>%
filter(magnitude_body == 0)

#Choose font
font_add_google(""Anton"", ""Anton"")
showtext_auto()

#Make theme
theme_sil <- theme_void() +
  theme(
    plot.background = element_rect(fill = ""grey80""),
    text= element_text(family=""Anton"", face=""bold""),
    legend.text = element_text(margin = margin(0, 20, 0, 0)),
    legend.title = element_text(margin = margin(0, 20, 0, 0)),
    legend.text.align = 0,
    strip.text = element_blank(),
    panel.spacing = unit(2, ""points""),
    plot.margin = margin(20, 20, 20, 20),
    plot.title = element_text(size = 40, hjust = 0, colour=""darkred""),
    plot.subtitle = element_text(size = 25, hjust = 0),
    plot.caption = element_text(hjust = 1, size = 6)) 

#Run quartz for showtext
quartz()

#Make drawing
p <- ggplot()+
  #Circle 1: 7.4
  geom_hline(yintercept = 9, colour=""black"", size=0.5)+
  geom_circle(aes(x0 = -10, y0 = -1, r = 5), fill=""black"")+
  geom_rect(aes(xmin = -12.5, ymin = 1, xmax = -8.5, ymax = 2), fill= ""orange"",color = ""darkred"")+
  geom_text(aes(x = -11, y = 1.5), label=""MB: 7.4"", color=""white"", size=6, family=""Anton"")+
  geom_label(aes(x = -11, y = -0.5), label=""Year: 1987\nCountry: USSR\n Type: SHAFT"", color=""black"", size=3, family=""Anton"")+
  #Circle 2: 7.3
  geom_circle(aes(x0 = -5, y0 = -1, r = 4), colour=""black"", fill=""grey15"")+
  geom_rect(aes(xmin = -7, ymin = 0, xmax = -3, ymax = 1), fill= ""orange"", color = ""darkred"")+
  geom_text(aes(x = -5, y = 0.5), label=""MB: 7.3"", color=""white"", size=6, family=""Anton"")+
  geom_label(aes(x = -5, y = -1.5), label=""Year: 1987\nCountry: USSR\nType: SHAFT"", color=""black"", size=3, family=""Anton"")+
  #Circle 3: 7.2
  geom_circle(aes(x0 = 0, y0 = -1, r = 3), colour=""black"", fill=""grey25"")+
  geom_rect(aes(xmin = -2, ymin = -1, xmax = 2, ymax = 0), fill= ""orange"", color = ""darkred"")+
  geom_text(aes(x = 0, y = -0.5), label=""MB: 7.2** "", color=""white"", size=6, family=""Anton"")+
  geom_label(aes(x = 0, y = -2.5), label=""Year: 1985\nCountry: USSR\nType: SHAFT"", color=""black"", size=3, family=""Anton"")+
  #Circle 4: 0
  geom_circle(aes(x0 = 5, y0 = -1, r = 0.5), colour=""black"", fill=""grey45"")+
  annotate(""segment"", x= 5, xend = 5, y = 3, yend = -1, size=0.5)+
  annotate(geom=""label"", x= 5, y = 3, label = ""1.217 explosions\nhave an 'MB' of zero."", vjust=0.1, size=4, family=""Anton"", fontface=""bold"")+
  #Extra text
  annotate(geom=""label"", x= 10, y = -9, label = 
  ""* 'Biggest' is expressed in 'Body wave magnitude of explosion' (MB).\nBody-waves consist of P-waves or S-waves, or reflections of either. Body-waves travel through rock directly. Source: Wikipedia.
  ** Two explotions have an MB of 7.2. Based on magnitude surface, this explosion was chosen as the 3th biggest."", size=2.5, vjust=0.1, hjust=1, family=""Anton"")+ 
  labs(title=""NUCLEAR EXPLOTIONS"", 
       subtitle=""The three biggest explosions and the smallest ones.*"",
       caption=""Source: Stockholm International Peace Research Institute, SIPRI | Plot by: @sil_aarts"",
       y=""Age of death (z-scores)"")+
  coord_fixed()+
  theme_sil


#Run it!
p
","2019-34"
"939",414,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Plasticpolution.R","#TidyTuesday
#===============================================================================
#Plastic waste; waste no more...
#@sil_aarts
#===============================================================================

#Load libraries
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(extrafont)

#Load data
data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

#Take only rows with per capita plastic waste: omit the others, leaving only 2010
data1 <- na.omit(data)

#Change colnames for ease of use: per capita plastic waste, kg per person per day | gpd in $
colnames(data1)[4] <- c(""capita_waste"")
colnames(data1)[5] <- c(""gdp_capita"")

#Order the data
data2 <- data1[order(-data1$capita_waste),] 

#Check the mean of all countries=0.198
data2 %>%
  summarise((mean_capita=mean(capita_waste)))

#Select 20 countries with most waste per capita > 0.296
data3 <- data2 %>%
  filter(capita_waste > 0.296)

#Check the mean of top 20 countries capita_waste=0.605
data3 %>%
  summarise((mean_capita=mean(capita_waste)))

#Check the median of top 20 countries capita_waste=0.411
data3 %>%
  summarise((median_capita=median(capita_waste)))

#GGplot: Barchart using annotations and curves
p <- data3 %>%
  ggplot(aes(x = Entity, y = capita_waste))+
  geom_hline(yintercept = 0.605, colour=""red"", size=0.8, linetype=""dashed"")+
  geom_hline(yintercept = 0.411, colour=""red"", size=0.8)+
  geom_bar(stat = ""identity"", color=""darkslategray3"")+
  coord_flip()+
  labs(title=""TidyTuesday: Plastic polution in 2010"", 
       subtitle=""Global plastic waste: 20 countries with the most waste in kg per person per day"",
       x="""", 
       y=""Plastic waste in kg per person per day"",
       caption=""Source: Our World in Data | Plot by @sil_aarts"")+
  annotate(geom=""label"", x=""Saint Lucia"", y = 3.3, label = ""Tinidad and Tobago:\n 3.6kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Seychelles"", xend = ""Trinidad and Tobago"", y = 3.6, yend = 3.6 ,size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  annotate(geom=""label"", x=""Netherlands"", y = 1.5, label = ""Netherlands:\n 0.424kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Netherlands"", xend = ""Netherlands"", y = 1, yend = 0.424, size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  annotate(geom=""label"", x=""Ireland"", y = 1.5, label = ""Mean of top 20 countries:\n 0.605kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Ireland"", xend = ""Ireland"", y = 1, yend = 0.605, size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  annotate(geom=""label"", x=""Grenada"", y = 1.55, label = ""Median of top 20 countries:\n 0.411kg per person/day"", family= ""Courier"", vjust=0.1, size=4, fontface=""bold"")+
  annotate(""curve"", x=""Grenada"", xend = ""Grenada"", y = 1, yend = 0.411, size=0.5, arrow=arrow(length=unit(.2, ""cm"")))+
  theme_classic()+
  theme(panel.background = element_rect(fill = ""transparent""),
        plot.background = element_rect(fill = ""grey30""),
        plot.title=element_text(size=18, hjust=0, family=""Courier New"",face='bold', colour=""white""),
        plot.subtitle=element_text(size=14, hjust=0, family=""Courier New"", colour=""white""),
        plot.caption=element_text(size=10, hjust=1,family=""Courier New"", colour=""white""),
        axis.text.x= element_text(size=10, family=""Courier"", face=""bold"", colour=""white""),
        axis.text.y= element_text(size=10, family=""Courier"", face=""bold"", colour=""white""),
        axis.title.x = element_text(size=10, family=""Courier"", face=""bold"", colour=""white""))

#Run it
p
","2019-21"
"940",415,"https://github.com/silaarts/TidyTuesday","silaarts","TidyTuesday","TidyTuesday_Policing.R","#TidyTuesday
#Stanford Open Policing project

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(RColorBrewer)
library(readr)

#Read file
combined_data <- readr::read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")
sort(combined_data$stops_per_year, decreasing=T)

#Alter stops per year for esthetics plot
combined_data$stops_per_year <- combined_data$stops_per_year/100

#GGplot: scatterplot: search rate by arrest rate
#Make colors for the states
nb.cols <- 17
mycolors <- colorRampPalette(brewer.pal(12, ""Paired""))(nb.cols)

#Make the plot (in my tweet about this plot I used geom_count, however, geom_point gives you all the states)
p4 <- ggplot(combined_data, aes(x=search_rate, y=arrest_rate)) + 
  geom_point(aes(col=state, size=stops_per_year)) + 
  xlim(c(0, 0.18)) + 
  labs(subtitle=""Stanford Open Policing Project: relating search rate(%) to arrest rate(%)"", 
       y=""Arrest rate %"", 
       x=""Search rate %"", 
       title=""TidyTuesday"", 
       size=""Stops per year*100"", 
       col=""State"",
       caption = ""Source: Stanford Open Policing Project | Plot by @sil_aarts"")+
  scale_color_manual(values = mycolors)+
  scale_size_continuous(breaks = 1:4, labels = c(""<1"",""1000"",""2000"",""3000""), limits = NULL, trans = ""identity"")+
  guides(size = guide_legend(override.aes = list(size = c(2:5))))+  
  theme(legend.background = element_rect(fill=""lightgrey"", size=0.5, linetype=""solid"", colour=""black""),
        panel.background = element_rect(fill = ""lightgrey""),
        panel.border = element_rect(colour = ""black"", fill=NA, size=0.5),
        panel.grid.major.x =element_blank(),
        panel.grid.major.y =element_blank(),
        panel.grid.minor.x =element_blank(),
        panel.grid.minor.y =element_blank(),
        plot.title = element_text(color=""black"", face=""bold"", size=14, hjust=0),
        plot.subtitle=element_text(size=13, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=10, hjust=1, color=""azure4""),
        legend.title = element_text(size=10, hjust=1, color=""black"", face=""bold""),
        axis.text.x= element_text(size=10, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.6, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))

#Run it
p4

#Make the plot: ZOOM IN!
p5 <- ggplot(combined_data, aes(x=search_rate, y=arrest_rate)) + 
  geom_point(aes(col=state, size=stops_per_year)) + 
  xlim(c(0, 0.05)) + 
  labs(subtitle=""Stanford Open Policing Project: relating search rate(%) to arrest rate(%): ZOOM IN"", 
       y=""Arrest rate %"", 
       x=""Search rate %"", 
       title=""TidyTuesday"", 
       size=""Stops per year*100"", 
       col=""State"",
       caption = ""Source: Stanford Open Policing Project | Plot by @sil_aarts"")+
  scale_color_manual(values = mycolors)+
  scale_size_continuous(breaks = 1:4, labels = c(""<1"",""1000"",""2000"",""3000""), limits = NULL, trans = ""identity"")+
  guides(size = guide_legend(override.aes = list(size = c(2:5))))+  
  theme(legend.background = element_rect(fill=""lightgrey"", size=0.5, linetype=""solid"", colour=""black""),
        panel.background = element_rect(fill = ""lightgrey""),
        panel.border = element_rect(colour = ""black"", fill=NA, size=0.5),
        panel.grid.major.x =element_blank(),
        panel.grid.major.y =element_blank(),
        panel.grid.minor.x =element_blank(),
        panel.grid.minor.y =element_blank(),
        plot.title = element_text(color=""black"", face=""bold"", size=14, hjust=0),
        plot.subtitle=element_text(size=13, hjust=0, face=""italic"", color=""black""),
        plot.caption= element_text(size=10, hjust=1, color=""azure4""),
        legend.title = element_text(size=10, hjust=1, color=""black"", face=""bold""),
        axis.text.x= element_text(size=10, hjust=1, face='bold', colour='black'),
        axis.text.y= element_text(size=10,face='bold', colour='black'),
        axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.6, vjust = 1, face = ""bold""),
        axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))

#Run it
p5
","2019-12"
"941",416,"https://github.com/silaarts/Shiny_TidyTuesday","silaarts","Shiny_TidyTuesday","Female_earnings_app.R","#TidyTuesday
#Female earnings
#Shiny, first try

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(readr)
library(shiny)
library(rsconnect)

#Read file
female <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-05/employed_gender.csv"")

#Subset of file
female2 <- subset(female, year %in% c(1970, 1980, 1990, 2000, 2010))

#Make data.matrix
names(female2)[1] <- """"
female2 <-data.matrix(female2)

#Make variabele year -> rownames
female3 <- female2[,-1]
rownames(female3) <- female2[,1]

#Ui
ui <- fluidPage(
    titlePanel('TidyTuesday:
               Employment through the years for females and males'),
    sidebarLayout(
      sidebarPanel(
      selectInput(""region"", ""Type of employment by gender"",
                  choices=colnames(female3)),
      hr(),
      helpText(""Employment from 1970 to 2010, 
               Source: Bureau of Labor"")),
  mainPanel(
    plotOutput(""EmployeePlot"")
  )
)
)

#Server
server <- function(input, output) {
  
#Fill in the spot we created for the barplot
output$EmployeePlot <- renderPlot ({
    
#Barplot
barplot(female3[,input$region], 
            main="""",
            col = ""darkmagenta"", border = ""black"",
            ylab=""% employed"",
            xlab=""year"")
  })
}

#Run it
shinyApp(ui, server)








","2019-10"
"942",417,"https://github.com/silaarts/Shiny_TidyTuesday","silaarts","Shiny_TidyTuesday","Policing_app.R","#TidyTuesday
#Policing

#Load libraries
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gganimate)
library(extrafont)
library(readr)
library(shiny)
library(rsconnect)
library(RColorBrewer)
library(DT)

#Read file
combined_data <- readr::read_csv(""https://raw.githubusercontent.com/5harad/openpolicing/master/results/data_for_figures/combined_data.csv"")

#Delete columns
data <- select(combined_data, -c(7, 9:11))

#ui
ui <- 
  fluidPage(
    plotOutput(""plot"", click = ""plot_click""),
    hr(),
    helpText(""Source: Stanford Policing Project | Plot by @sil_aarts""),
    fluidRow(
      column(5, 
        selectInput('driver_race',""Driver's race"", choices=unique(data$driver_race)),
        selectInput('state', ""State"", choices =unique(data$state)),
      column(8,
             h4(""Click the points for info!""),
             dataTableOutput(""click_info""))
      )
)
)

#server
server <- function(input, output) {
  
#Make scatterplot
 output$plot <- renderPlot({
        data <- data[data$driver_race == input$driver_race, ]
        data <- data[data$state == input$state, ]
        ggplot(data) +
          geom_point(aes(x = search_rate, y = arrest_rate, color=input$state, shape=input$driver_race)) +
          labs(x = ""search rate %"", 
               y = ""arrest rate %"", 
               title = ""TidyTueday: Search rate & arrest rate"")+
          theme(legend.background = element_rect(fill=""white"", size=0.5, linetype=""solid"", colour=""black""),
                panel.background = element_rect(fill = ""white""),
                legend.position = ""none"",
                panel.border = element_rect(colour = ""black"", fill=NA, size=0.5),
                panel.grid.major.x =element_blank(),
                panel.grid.major.y =element_blank(),
                panel.grid.minor.x =element_blank(),
                panel.grid.minor.y =element_blank(),
                axis.text.x= element_text(size=10, hjust=1, face='bold', colour='black'),
                axis.text.y= element_text(size=10,face='bold', colour='black'),
                axis.title.x = element_text(color = ""black"", size = 14, angle = 0, hjust = 0.6, vjust = 1, face = ""bold""),
                axis.title.y = element_text(color = ""black"", size = 14, angle = 90, hjust = 0.5, vjust = 1, face = ""bold""))
    })

#Make Table
output$click_info <- 
  DT::renderDataTable(DT::datatable({
    nearPoints(data, input$plot_click)},

#Change lay-out table
options = list(pageLength = 5,dom = 'ftl', searching=FALSE), rownames = FALSE, escape = FALSE) %>%   
  formatStyle('state', color = 'white',backgroundColor = 'grey', fontWeight = 'bold'))
}


shinyApp(ui=ui, server=server)


","2019-12"
"943",548,"https://github.com/SaraJKerr/TidyTuesday","SaraJKerr","TidyTuesday","Emperors.R","options(scipen = 999)

library(tidyverse)
library(readr)
library(lubridate)
library(ggthemes)
library(treemap)
library(d3treeR)

# Load data
emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")

# Make summary dataframe
emp_death <- emperors %>% 
        group_by(dynasty, cause, name) %>% 
        summarise(Count = n())

# Create treemap
emp_tree <-  treemap(emp_death,
        index=c(""dynasty"",""cause"", ""name""),
        vSize=""Count"",
        type=""index"",
        border.col=c(""black"",""white""),
        palette = ""Set1"",
        title=""Roman Emperors: Cause of death by dynasty"",                      
        fontsize.title=16
)

emp_int <- d3tree(emp_tree,  rootname = ""Emperors"")

library(htmlwidgets)
saveWidget(emp_int, file=""EmperorTreemap.html"", selfcontained = T)



","2019-33"
"944",549,"https://github.com/SaraJKerr/TidyTuesday","SaraJKerr","TidyTuesday","bird_impacts.R","options(scipen = 999)

library(tidyverse)
library(viridis)
library(ggmap)
library(readr)
library(maps)
library(mapproj)


# Data Source https://wildlife.faa.gov/

wildlife_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/wildlife_impacts.csv"")


# Prepare Data ------------------------------------------------------------

# Remove results where state is NA
wildlife_impacts <- wildlife_impacts %>% 
        filter(state != ""N/A"")

# Select key information for plot and add full state name as regions
w_impacts <- wildlife_impacts %>% 
        group_by(state) %>% 
        summarise(Count = n()) %>% 
        mutate(region = tolower(state.name[match(state, state.abb)]))


# Create a Static Map -----------------------------------------------------

# Pull US state map
us_states <- map_data(""state"")

w_impact_map <- left_join(w_impacts, us_states, by = ""region"")

ggplot(w_impact_map, aes(long, lat, group = group)) +
        geom_polygon(aes(fill = COUNT), colour = ""white"") +
        scale_fill_viridis_c(option = ""D"", alpha = 0.8, name = ""Number of Strikes"") +
        coord_map(projection = ""albers"", lat0 = 39, lat1 = 45) +
        ggtitle(""Aircraft Wildlife Strikes by State"") +
        labs(caption = ""Data source: FAA"")

","2019-18"
"945",550,"https://github.com/SaraJKerr/TidyTuesday","SaraJKerr","TidyTuesday","video_games.R","# Video Games

options(scipen = 999)

library(tidyverse)
library(viridis)
library(readr)
library(anytime)
library(ggthemes)

# Data source: Steam Spy

# Clean dataset from lizawood's github
url <- ""https://raw.githubusercontent.com/lizawood/apps-and-games/master/PC_Games/PCgames_2004_2018_raw.csv""


# Load and prepare data ---------------------------------------------------

# Read in raw data
raw_df <- url %>% 
        read_csv() %>% 
        janitor::clean_names() 

# Clean up some of the factors and playtime data
clean_df <- raw_df %>% 
        mutate(price = as.numeric(price),
               score_rank = word(score_rank_userscore_metascore, 1),
               average_playtime = word(playtime_median, 1),
               median_playtime = word(playtime_median, 2),
               median_playtime = str_remove(median_playtime, ""\\(""),
               median_playtime = str_remove(median_playtime, ""\\)""),
               average_playtime = 60 * as.numeric(str_sub(average_playtime, 1, 2)) +
                       as.numeric(str_sub(average_playtime, 4, 5)),
               median_playtime = 60 * as.numeric(str_sub(median_playtime, 1, 2)) +
                       as.numeric(str_sub(median_playtime, 4, 5)),
               metascore = as.double(str_sub(score_rank_userscore_metascore, start = -4, end = -3))) %>% 
        select(-score_rank_userscore_metascore, -score_rank, -playtime_median) %>% 
        rename(publisher = publisher_s, developer = developer_s)

# Remove comma from date
clean_df <- clean_df %>% 
        mutate(release_date = gsub("","", """", release_date))

# Split date into Month, Day, Year
clean_df <- clean_df %>% 
        separate(release_date, into = c(""Month"", ""Day"", ""Year""))

# Add 0 to numbers under 10
clean_df$Day <- case_when(clean_df$Day %in% c(""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"",
                                              ""8"", ""9"") 
                                                ~ str_pad(clean_df$Day, 2, ""left"", pad = ""0""),
                          clean_df$Day >= 10 ~ clean_df$Day)

# Create date format variable
clean_df <- clean_df %>% 
        mutate(r_date = anydate(paste0(Year, ""-"", Month, ""-"", Day)))

# Remove 0 and NA from focus variables
clean <- clean_df %>% 
        filter(average_playtime > 0) %>% 
        filter(median_playtime > 0) %>% 
        filter(!is.na(r_date)) %>% 
        select(number, r_date, average_playtime, price, metascore,
                median_playtime,developer, Year)

clean$developer <- as_factor(clean$developer)
clean$Year <- as_factor(clean$Year)

clean <- clean %>% 
        filter(!is.na(price))

clean <- clean %>% 
        mutate(price_band = findInterval(price, c(10, 20, 30, 40, 50, 60, 70)))

clean$price_band <- as_factor(clean$price_band)

clean$price_band <- recode_factor(clean$price_band, `0` = ""$0-$9.99"", `1` = ""$10-$19.99"", 
              `2` = ""$20-$29.99"", `3` = ""$30-$39.99"", `4` =""$40-$49.99"",
              `5` = ""$50-$59.99"", `7` = ""$70-$79.99"", .ordered = TRUE)

meta <- clean %>% 
        filter(!is.na(metascore)) %>% 
        filter(!is.na(developer))

play <- clean %>% 
        filter(!is.na(average_playtime)) %>% 
        filter(!is.na(developer))

# Create scatterplot using Economist theme --------------------------------

ggplot(clean, aes(x = r_date, y = average_playtime, colour = price_band)) +
        geom_point(shape = 16) +
        theme_economist() +
        scale_colour_economist() +
        theme(legend.title = element_text(size = 10), 
              legend.text = element_text(size = 8)) +
        ggtitle(""Average Playtime by Release Date"") +
        xlab(""Release Data"") +
        ylab(""Average Playtime"") +
        labs(colour = ""Price Band"",
             caption = ""Data Source: Liza Wood via Steam Spy"")


# Create circular bar plot ------------------------------------------------
# Plots adapted from https://www.r-graph-gallery.com/circular-barplot/

p <- ggplot(meta, aes(x = developer, y = metascore, fill = price_band)) +
        geom_bar(stat = ""identity"") +
        ylim(-15,120) +
        scale_fill_viridis_d(name = ""Price"") +
        theme_minimal() +
        theme(
                axis.text = element_blank(),
                axis.title = element_blank(),
                panel.grid = element_blank()
        ) +

        
        # This makes the coordinate polar instead of cartesian.
        coord_polar(start = 0) +
        labs(caption = ""Data Source: Liza Wood via Steam Spy"") +
        ggtitle(""Metascore by Developer"")

p <- p +  guides(color = guide_legend(override.aes = list(size = 0.5)))
p <- p +  theme(legend.title = element_text(size = 9), 
                legend.text = element_text(size = 7))
p


p2 <- ggplot(play, aes(x = developer, y = average_playtime, fill = price_band)) +
        geom_bar(stat = ""identity"") +
        ylim(-15,120) +
        scale_fill_viridis_d(name = ""Price"") +
        theme_minimal() +
        theme(
                axis.text = element_blank(),
                axis.title = element_blank(),
                panel.grid = element_blank()
        ) +
        
        
        # This makes the coordinate polar instead of cartesian.
        coord_polar(start = 0) +
        labs(caption = ""Data Source: Liza Wood via Steam Spy"") +
        ggtitle(""Average Playtime by Developer"")

p2 <- p2 +  guides(color = guide_legend(override.aes = list(size = 0.5)))
p2 <- p2 +  theme(legend.title = element_text(size = 9), 
                legend.text = element_text(size = 7))
p2 

","2019-31"
"946",551,"https://github.com/larissakostiw/-TidyTuesday/blob/master/meteorites.Rmd","larissakostiw","TidyTuesday","meteorites.Rmd","---
title: ""Tidy Tuesday: Meterorite""
output: html_notebook
---

Import Data
```{r}
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")
```

Summary
```{r}
summary(meteorites)
#summary(meteorites$year)


```

What are the name types?
```{r}
library(tidyverse)
meteorites$name_type<- as.factor(meteorites$name_type)
#name_type<- distinct(meteorites$name_type)
meteorites$year<- as.numeric(meteorites$year)
#meteorites$year<- as.factor(meteorites$year)
```

```{r}
# meteorites$fall<- as.factor(meteorites$fall)
# meteorites$year<- as.factor(meteorites$year)
# 
#Convert NA to 0: Year
meteorites<- meteorites %>%
  filter(!is.na(year))

meteorites<- na.omit(meteorites)

#drop_na in tidyverse
```

Load map
```{r}
#install.packages(""mapdata"")
library(mapdata)

#install.packages(""ggmap"")
library(ggmap)
world<-map_data(""world"")
```

Subset to 1900's onwards
```{r}
meteorites<- meteorites %>%
  filter(year>=1900 & year<2018)
```


```{r}
#install.packages(""mapproj"")
#library(mapproj)
#install.packages(""cowplot"")
#library(cowplot)
map <- ggplot() +
  geom_polygon(
    data = world,
    aes(x = long, y = lat, group = group),
    fill = ""gray50"",
    size = 0.1
  ) +
  labs(
    title = ""Meteorites on Earth"",
    subtitle = ""Year: {round(frame_time)}"",
    caption = ""Source: NASA""
  ) + 
  geom_point(
    data = meteorites,
    aes(
      x = long,
      y = lat,
      size = mass,
      color = mass
    ),     alpha = 0.8
  ) +
  scale_color_distiller(
    palette = ""Reds"",
    direction = 1
    # labels = c(""0"", ""2.5"", ""5.0"", ""7.5"", ""10.0+""),
    # guide = guide_colorbar(
    #   direction = ""horizontal"",
    #   barheight = unit(3, units = ""mm""),
    #   barwidth = unit(60, units = ""mm""),
    #   title.position = ""top"",
    #   title.hjust = 0.5,
    #   label.hjust = 0.5    
    )   +
    theme_map()  +
    theme(plot.title = element_text(hjust=0.5, face='bold', colour=""white""),
        plot.subtitle = element_text(hjust=0.5, face='bold', colour=""white""),
        axis.ticks.x=element_blank(),
        panel.background = element_rect(fill=""black""),
        plot.background = element_rect(fill=""black""),
        legend.position = ""none"") 
        
  
map

```

Animate map
```{r}
#install.packages(""gganimate"")
library(gganimate)
#install.packages(""gifski"")
#library(gifski)
map_gif <- map +
  transition_events(start = year)+
  enter_grow() +
  exit_fade()  transition_time(year)

animate(map_gif, fps=1)
```

Save
```{r}
anim_save(""Meteorites.gif"")
```



","2019-24"
"947",552,"https://github.com/larissakostiw/-TidyTuesday/blob/master/media_franchise_rev.Rmd","larissakostiw","TidyTuesday","media_franchise_rev.Rmd","---
title: ""Media Franchise Revenues""
output: html_notebook
---

```{r}
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")
```

Summary
```{r}
summary(media_franchises)
```

Group the years
```{r}
library(tidyverse)

media_franchises<- media_franchises %>%
  mutate(year_group=ifelse(year_created<1935, ""1924-1934"",
                           ifelse(year_created<1945, ""1935-1944"",
                                  ifelse(year_created<1955, ""1945-1954"",
                                         ifelse(year_created<1965, ""1955-1964"",
                                                ifelse(year_created<1975, ""1965-1974"",
                                                       ifelse(year_created<1985, ""1975-1984"",
                                                               ifelse(year_created<1995, ""1985-1994"",
                                                                      ifelse(year_created<2005, ""1995-2004"", ""2005-2013"")))))))))

revenue_yeargroup<- media_franchises %>%
  group_by(year_group, revenue_category) %>%
  summarise(total_revenue=sum(revenue)) %>%
  select(year_group, revenue_category, total_revenue) %>%
  arrange(year_group)

revenue_yeargroup$year_group<- as.factor(revenue_yeargroup$year_group)
```
Plot a stacked bar chart. 
```{r}
#install.packages(""ggthemes"")
#library(ggthemes)

p<- ggplot(revenue_yeargroup, aes(x=year_group, y=total_revenue))+
  geom_col(aes(fill=revenue_category), width=0.5) +
  scale_fill_brewer(palette=""Set2"")+
  theme_solarized()+
  scale_colour_solarized('blue')+
  scale_x_discrete(limits=unique(rev(revenue_yeargroup$year_group)))+
  labs(
    title = ""Media Franchise Revenues "",
    subtitle = ""By Category in 1924-2013"",
    caption = ""Source: Wikipedia. Plot by Larissa Kostiw"",
    y=""Revenue(billions)"",
    x=""Year Group"",
    fill=""Revenue Category""
  ) +
  coord_flip() +
  theme(plot.margin = unit(c(20,20,20,20),""points""),
        plot.title=element_text(hjust=0.5, face=""bold""),
        plot.subtitle = element_text(hjust=0.5, face=""bold""),
        legend.position = ""bottom"",
        legend.box=""horizontal"",
        legend.text = element_text(size=10, face=""bold""),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank(),
        axis.title.x=element_text(face=""bold""),
        axis.title.y=element_text(face=""bold""))
      

p

#ggsave(""media_franchise_rev.png"")
```

","2019-27"
"948",554,"https://github.com/kuprinaga/tidyverse-video-games","kuprinaga","tidyverse-video-games","analyse.R","library(tidyverse)
library(magrittr)
library(ggthemes) 
library(lubridate)
library(gridExtra)
library(grid)
library(glue)


video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

video_games %<>%
  mutate(release_date_pretty = as.Date(release_date, format = '%b %d, %Y'),
         age = as.numeric(Sys.Date()-release_date_pretty))

ggplot() + 
  geom_point(data = video_games %>% filter(price < 65),
              aes(x = price,
                  y = metascore,
                  group = price))

ggplot() +
  geom_point(data = video_games,
            aes(x = release_date_pretty,
                y = metascore))

p <- ggplot() +
  geom_jitter(data = video_games %>% 
               group_by(release_date_pretty) %>%
               summarise(count_games = n()) %>%
               mutate(day_of_week = weekdays(release_date_pretty),
                      weekend = ifelse(day_of_week %in% c('Saturday', 'Sunday'),
                                       'yes',
                                       'no')),
             aes(x = release_date_pretty,
                 y = count_games,
                 color = weekend),
             alpha = 0.3,
             size = 3) +
  geom_text(aes(x = ymd('2012-01-01'),
              y = 25,
              size = 20,
              label = 'Number of daily releases increased a lot since 2015, \nalthough releases on weekends are more rare')) +
  geom_curve(aes(x = ymd('2012-12-01'),
                 xend = ymd('2014-01-01'),
                 y = 20,
                 yend = 14),
             color = 'slategrey',
             arrow = arrow(length = unit(0.03, ""npc""))) +
  theme_tufte(base_size = 18) + 
  theme(legend.position = 'none') +
  scale_color_brewer(palette = 'Set2') +
  labs(x = 'Date',
       y = 'Releases per day',
       caption = 'Data from #TidyTuesday. Visualisation by @kuprinasha')
  

palette_colors = brewer.pal(3, 'Set2')
title = c('\nNumber of games released daily on','\n workdays','\n and','\n weekends')
colors = c('black', palette_colors[1], 'black', palette_colors[2],'black')

p_grid <- arrangeGrob(p, 
             top = tableGrob(t(title), 
                             theme=ttheme_minimal(padding=unit(c(1,1,1,1),'mm'),
                                                  base_colour = colors,
                                                  base_size = 24)))
ggsave('plot_over_time.png', p_grid,
       width = 10, height = 6, units = 'in')


p_release_day <- video_games %>% 
  group_by(release_date_pretty) %>%
  summarise(count_games = n()) %>%
  mutate(day_of_week = weekdays(release_date_pretty),
         weekend = ifelse(day_of_week %in% c('Saturday', 'Sunday'),
                          'yes', 'no')) %>% 
  group_by(day_of_week) %>% 
  summarise(sum_all = sum(count_games)) %>% 
  arrange(desc(sum_all)) %>%
  na.omit() %>%
  ggplot() + 
  geom_bar(aes(x = reorder(day_of_week, -sum_all),
               y = sum_all),
           stat = 'identity',
           fill = 'steelblue') +
  geom_text(aes(x = reorder(day_of_week, -sum_all),
                y = sum_all+200,
                label = sum_all),
            color = 'slategrey') +
  theme_tufte(base_size = 20) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  labs(x = '',
       title = 'What is the most popular release day?',
       subtitle = glue(' Games released by day of week since ', format(min(video_games$release_date_pretty, na.rm = T), '%B %Y')))

ggsave('plot_release_day.png', p_release_day,
       width = 10, height = 8, units ='in')


","2019-31"
"949",563,"https://github.com/kuprinaga/tidytuesday-r4ds","kuprinaga","tidytuesday-r4ds","using-r4ds-data-only.R","
library(tidyverse)
library(lubridate)
library(anytime)
library(magrittr)
library(scales)

r4ds_members <- read_csv('slack_data.csv')

annotations_df <- tibble(date = as.Date('2019-01-17'), 
       annotation = 'Start of rstudio::conf 2019') %>%
  add_row(date = as.Date('2019-05-31'),
          annotation = 'Mysterious increase #2') %>%
  add_row(date = as.Date('2017-12-29'),
          annotation = 'Mysterious increase #1') %>%
  add_row(date = as.Date('2018-07-10'),
          annotation = 'Start of userR 2018')


data_for_plot <- r4ds_members %>%
  select(date, 
         weekly_active_members) %>%
  left_join(annotations_df, by = c('date' = 'date'))


bottom_annotations <- data_for_plot %>%
  filter(annotation != 'Start of userR 2018')

user_annotation <- data_for_plot %>%
  filter(annotation == 'Start of userR 2018')

ggplot(data = data_for_plot) +
  geom_line(aes(x = date,
                y = weekly_active_members,
                ),
            color = 'grey',
            size = 1.5) +
  geom_point(data = data_for_plot %>%
               filter(is.na(annotation) == F),
             aes(x = date,
                 y = weekly_active_members),
             size = 2,
             color = 'steelblue') +
  geom_curve(data = bottom_annotations,
             aes(x = date+10,
                 xend = date + 5,
                 y = weekly_active_members - 100,
                 yend = weekly_active_members - 10),
             arrow = arrow(length = unit(0.03, ""npc"")),
             color = 'slategrey'
  ) + 
  geom_text(data = bottom_annotations,
            aes(x = date + 10,
                y = weekly_active_members - 110,
                label = annotation)
  ) +
  geom_curve(data = user_annotation,
             aes(xend = date - 5,
                 yend = weekly_active_members + 10,
                 y = weekly_active_members + 100,
                 x = date + 10
             ),
             arrow = arrow(length = unit(0.03, ""npc"")),
             color = 'slategrey'
  ) + 
  geom_text(data = user_annotation,
            aes(x = date + 10,
                y = weekly_active_members + 120,
                label = annotation)) + 
  scale_x_date(labels = date_format(""%B %Y""),
               date_breaks = ""3 months"") +
  theme(legend.position = 'none') +
  labs(x = '', y = 'Weekly active R4DS members',
       title = 'Weekly active R4DS members over time',
       subtitle = 'There is certainly seasonality in the activity, mostly peaking in the beginning of the week.
Additionally, major events like rconf result in big increases of new joiners and weekly actives') +
  theme_classic()

","2019-29"
"950",571,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-20-nobel-prize.R","othomantegazza","code-tidytuesday","2-20-nobel-prize.R","library(tidyverse)
library(lubridate)


# Get data ----------------------------------------------------------------

data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                   ""master/data/2019/2019-05-14/nobel_winners.csv"")

data_path <- ""data/2-20-nobel-prize.Rdata""

if(!file.exists(data_path)) {
  nobel <- read_csv(data_url)
  
  save(nobel, file = data_path)
} else {
  load(data_path)
}


# plot -----------------------------------------------------------------

p <- 
  nobel %>% 
  mutate(age =  prize_year - year(birth_date)) %>% 
  ggplot(aes(x = category,
             y = age,
             colour = gender,
             alpha = gender)) +
  ggbeeswarm::geom_beeswarm() +
  coord_flip() +
  scale_color_manual(values = c(""#BB1288"", ""#5867A6"")) +
  scale_alpha_manual(values = c(1, .4)) +
  theme_minimal() +
  labs(title = ""Way Beyond Gender Imbalance"",
       subtitle = ""Nobel prize laureates until 2016"",
       colour = ""Gender"",
       alpha = ""Gender"",
       x = ""Category"",
       y = ""Age"",
       caption = ""Source: Kaggle | Plot by @othomn"")

# I was wondering if with a beeswarm plot you can show also every nobel price as a point. The picture 

# some checks
nobel %>% filter(gender == ""Female"") %>% select(category, full_name) #%>% View()
nobel %>%
  mutate(age =  prize_year - year(birth_date)) %>% 
  filter(age < 25) %>% select(category, full_name) #%>% View()


# save --------------------------------------------------------------------

png(filename = ""plots/2-20-nobel-prize.png"",
    res = 300,
    height = 1800,
    width = 2400)
p %>% print()
dev.off()

nobel %>% 
  mutate(age =  prize_year - year(birth_date)) %>% 
  ggplot(aes(x = category,
             y = age,
             fill = gender)) +
  geom_boxplot()
  
","2019-20"
"951",577,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-29-r4ds-slack.R","othomantegazza","code-tidytuesday","2-29-r4ds-slack.R","library(tidyverse)
library(tibbletime)
library(grid)
library(lubridate)

# months in english
Sys.setlocale(""LC_TIME"", ""en_US.UTF8"")

# colors
purple <- ""#AA2255""
purple2 <- ""#BB2255""
bg_col <- ""#EAEA9F""
blue <- ""#263A89""

# load data ---------------------------------------------------------------


data_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/"",
                   ""tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")

data_path <- ""data/2-29-r4ds-slack.Rdata""


if(!file.exists(data_path)) {
  r4ds <- 
    data_url %>% 
    read_csv() %>% 
    select(-name)
  
  save(r4ds, file = data_path)
} else {
  load(data_path)
}


# explore -----------------------------------------------------------------

# no na
r4ds %>% map(~is.na(.) %>% sum())

# correlations
prs <- r4ds %>% GGally::ggpairs()

png(filename = ""plots/2-29-r4ds-slack.png"",
    width = 3000,
    height = 3000,
    res = 400)
prs
dev.off()

# what is name?
# r4ds %>% pull(name) %>% range()
# edited name, can be removed


# all timelines
r4ds %>% 
  gather(total_membership:messages_posted,
         key = ""key"", value = ""value"") %>% 
  ggplot(aes(x = date,
             y = value)) +
  geom_line() +
  facet_grid(key ~ ., scales = ""free_y"") +
  theme(strip.text.y = element_text(angle = 0))


# Active members ----------------------------------------------------------

# new years resolution?

roll_weekmean <- rollify(mean, window = 7)

roll_monthmean <- rollify(mean, window = 30)

text_height <- 240

p <- 
  r4ds %>% 
  mutate(weekmean = roll_weekmean(daily_active_members) %>% 
           # recenter rolled mean
           .[c(4:n(), 1:3)]) %>%
  ggplot(aes(x = date,
             y = daily_active_members)) +
  geom_density(stat = ""identity"", colour = NA,
               fill = ""white"") +
  geom_line(colour = ""#E4E484"") + #""#99D0E3"") + # ""#27A6D3"") +
  geom_line(aes(y = weekmean), colour = purple) +
  annotate(geom = ""text"",
           label = ""New Year's Resolutions? ;)"",
           y = text_height,
           x = as.Date(""2018-07-15""), 
           family = ""courier"",
           colour = blue) +
  annotate(geom = ""curve"",
           x = as.Date(""2018-04-01""),
           y = text_height,
           xend = as.Date(""2018-01-15""),
           yend = 160,
           curvature = .25,
           arrow = arrow(length = unit(1.2, ""mm""), type = ""closed""),
           size = .1,
           colour = blue) +
  annotate(geom = ""curve"",
           x = as.Date(""2018-10-27""),
           y = text_height,
           xend = as.Date(""2019-01-20""),
           yend = 155,
           curvature = -.26,
           arrow = arrow(length = unit(1.2, ""mm""), type = ""closed""),
           size = .1,
           colour = blue) +
  annotate(geom = ""text"",
           label = str_wrap(""Mean of 7 days window."", width = 10),
           y = 130,
           x = as.Date(""2019-07-22""), 
           family = ""courier"",
           colour = purple,
           size = 3,
           hjust = 0,
           lineheight = 1) +
  annotate(geom = ""curve"",
           x = as.Date(""2019-08-10""),
           y = 104,
           xend = as.Date(""2019-07-10""),
           yend = 70,
           curvature = -.45,
           arrow = arrow(length = unit(1.2, ""mm""), type = ""closed""),
           size = .1,
           colour = purple) +
  labs(x = """",
       y = ""Daily active members"",
       title = ""Activity of the R4DS Learning Community on Slack"",
       caption = ""Source: R4DS UseR Presentation | Plot by @othomn"") +
  theme_minimal(base_family = ""courier"") +
  scale_x_date(limits = as.Date(c(""2017-08-20"", ""2019-09-05"")),
               expand = c(0,0)) +
  theme(panel.grid = element_blank(),
        plot.margin = margin(10, 20, 5, 30),
        axis.title = element_text(colour = ""grey30""),
        plot.title = element_text(colour = blue,
                                  face = ""bold"",
                                  margin = margin(t = 10, b = 10)),
        plot.caption = element_text(colour = purple))


# save plot ---------------------------------------------------------------

png(filename = ""plots/2-29-r4ds-slack.png"",
    height = 1000,
    width = 3200,
    res = 300)
grid.newpage()
grid.rect(gp = gpar(fill = bg_col))
print(p, vp = viewport())
dev.off()



# save to json for d3 -----------------------------------------------------
library(jsonlite)

a <- 
r4ds %>% 
  select(date, daily_active_members) %>%
  toJSON() %>%
  {paste(""var r4ds = "", .)} %>% 
  cat(file = ""d3/json_data/2-29-r4ds-slack.js"")
  
# easier: monthly visitors
r4ds %>% 
  mutate(month_year = paste(month(date, label = T), year(date)),
         month_year = as_factor(month_year)) %>% 
  group_by(month_year) %>% 
  summarise(active_members = sum(daily_active_members)) %>%
  toJSON() %>% 
  {cat(""var r4ds = "", ., file = ""d3/json_data/2-29-r4ds-slack-months.js"")}





","2019-29"
"952",578,"https://github.com/othomantegazza/code-tidytuesday/blob/master/2-21-plastic-waste.R","othomantegazza","code-tidytuesday","2-21-plastic-waste.R","library(tidyverse)
library(lubridate)
library(countrycode)
library(ggforce)
library(ggrepel)

# Get data ----------------------------------------------------------------

managed_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                   ""master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")

mismanaged_url <- paste0(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/"",
                         ""master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")


data_path <- ""data/2-21-plastic-waste.Rdata""

if(!file.exists(data_path)) {
  waste_ok <- read_csv(managed_url) %>% 
    janitor::clean_names() %>% 
    filter(year == 2010)
  
  waste_lost <- read_csv(mismanaged_url) %>% 
    janitor::clean_names() %>% 
    filter(year == 2010)
  
  save(waste_ok, waste_lost, file = data_path)
} else {
  load(data_path)
}


waste <-
  full_join(waste_ok %>%
              select(entity,
                     code, 
                     gdp_per_capita = gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
                     plastic = per_capita_plastic_waste_kilograms_per_person_per_day),
            waste_lost %>% 
              select(entity,
                     code,
                     lost = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day)) %>% 
  # select(entity, code, year,
  #        ok = per_capita_plastic_waste_kilograms_per_person_per_day,
  #        lost = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day) %>% 
  drop_na() 

# Explore -----------------------------------------------------------------

waste %>% 
  ggplot(aes(x = plastic,
             y = lost)) +
  geom_point() 
  # scale_x_log10() +
  # scale_y_log10()
  # ggrepel::geom_text_repel(aes(label = code))

waste <- 
  waste %>% 
  mutate(ratio_lost = lost/plastic)

# two groups?
waste %>% 
  ggplot(aes(x = ratio_lost)) +
  geom_histogram()

waste %>%
  filter(ratio_lost > .75) %>% 
  pull(entity)

waste %>%
  filter(ratio_lost <.1 ) %>% 
  pull(entity)


# with continent ----------------------------------------------------------

waste_cont <- 
  waste %>% mutate(continent = countrycode(sourcevar = entity,
                                         origin = ""country.name"",
                                         destination = ""continent""),
                 continent = case_when(entity == ""Micronesia (country)"" ~ ""Oceania"",
                                    TRUE ~ continent)) %>% 
  drop_na(continent)

p <- 
  waste_cont %>% 
  ggplot(aes(x = ratio_lost,
             fill = continent,
             colour = continent)) +
  geom_histogram(bins = 25, alpha = .5) +
  # geom_mark_rect(data = tibble(x = .07,
  #                              y = 40,
  #                              label = ""Ciao"",
  #                              description = ""Ciao ciao ciao""),
  #                aes(x = x,
  #                    y = y,
  #                    label = label,
  #                    description = description),
  #                colour = ""white"", position = ""right"",
  #                inherit.aes = F) +
  annotate(geom = ""text"", x = .12, y = 41, 
                label = str_wrap(""High income countries can invest in
                                 plastic waste manegement?"",
                                 width = 20),
           hjust = 0, vjust = 0,
           size = 3, lineheight = 1,
           color = ""grey10"") +
  annotate(geom = ""segment"", x = .12,
           y = 40, yend = 37, xend = .09,
           color = ""grey10"") +
  annotate(geom = ""text"", x = .76, y = 18, 
           label = str_wrap(""Low income countries?"",
                            width = 20),
           hjust = 1, vjust = 0,
           size = 3, lineheight = 1,
           color = ""grey10"") +
  annotate(geom = ""segment"", x = .76,
           y = 17.5, yend = 16, xend = .78,
           color = ""grey10"") +
  geom_hline(yintercept = 0, colour = ""grey50"") +
  theme_minimal() +
  theme(text = element_text(family = ""sans"",
                            colour = ""grey20""),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  labs(x = ""[Mismanaged/Total] waste in Kg per capita"",
       y = ""Number of Countries"",
       fill = ""Continent"", colour = ""Continent"",
       title = ""Does Plastic Waste Management Mirrors Inequality?"",
       subtitle = ""Ratio of mismanaged plastic waste per country in 2010."",
       caption = ""Source: Our World in Data | Plot by @othomn"")

png(""plots/2-21-plastic-waste.png"",
    res = 300,
    height = 1400,
    width = 2200)
p %>% print()
dev.off()

# My Wednesday #TidyTuesday #rstats

# Is inequality mirrored also in waste plastic management?

# I checked the distribution of the percentage of mismanaged plastic waste, and it's kind of bimodal.

# https://ourworldindata.org/plastic-pollution
# https://github.com/othomantegazza/code-tidytuesday/blob/master/2-21-plastic-waste.R


# scatterplot -------------------------------------------------------------

annos_df <- 
  tibble(x = c(),
         y = c)

# p_s <- 
  waste_cont %>% 
  ggplot(aes(x = plastic,
             y = lost,
             size = gdp_per_capita,
             colour = continent)) +
  geom_point(alpha  = .7) +
  geom_text_repel(data = tibble(x = .05,
                                y = .005,
                                label= str_wrap(""High income countries can invest in
                                plastic waste manegement?"",
                                                width = 20)),
                  aes(x = x, y = y, label = label),
                  inherit.aes = F,
                  hjust = 1, vjust = 0,
                  size = 3, lineheight = 1,
                  color = ""grey10"") +
  # annotate(geom = ""text"", x = 1.3, y = 0.014, 
  #          label = str_wrap(""High income countries can invest in
  #                                plastic waste manegement?"",
  #                           width = 20),
           # hjust = 0, vjust = .5,
           # size = 3, lineheight = 1,
           # color = ""grey10"") +
  # annotate(geom = ""segment"",
  #          arrow = arrow(length = unit(1, ""mm""), type = ""closed""), 
  #          x = 1.3, y = .014,
  #          xend = 1, yend = .014) +
  scale_x_log10(limits = c(.001, 10)) +
  scale_y_log10(limits = c(.0005, .3)) +
  theme_minimal() 


png(""plots/2-21-plastic-waste-scatterplot.png"",
    res = 300,
    height = 1400,
    width = 2200)
p_s %>% print()
dev.off()


# cluster -----------------------------------------------------------------

set.seed(49)

waste_clust <- 
  waste_cont %>% 
  transmute(plastic = log(plastic),
            lost = log(lost),
            gdp_per_capita = log(gdp_per_capita)) %>% 
  kmeans(centers = 3) %>% 
  {bind_cols(waste_cont, tibble(cluster = .$cluster))}


cl_1 <- ""Medium GDP, high plastic loss""
cl_2 <- ""High GDP, low plastic loss""
cl_3 <- ""Low GDP, medium plastic loss""


p_clust <- 
waste_clust %>% 
  mutate(label = case_when(cluster == 1 ~ cl_1,
                                 cluster == 2 ~ cl_2,
                                 cluster == 3 ~ cl_3)) %>%
  # mutate(plastic = log(plastic),
  #           lost = log(lost)) %>% 
  ggplot(aes(x = plastic,
             y = lost,
             colour = cluster)) +
  geom_point(aes(size = gdp_per_capita)) +
  geom_mark_ellipse(aes(group = cluster,
                        label = cluster,
                        description = label),
                    # label.margin = .2,
                    size = 1.1, con.size = 1.3,
                    label.fontsize = 10, label.fill = ""grey90"",
                    label.minwidth = 30) +
  scale_x_log10(
    limits = c(.01, 5)
    ) +
  scale_y_log10(
    limits = c(.0008, .8)
    ) +
  theme_minimal() +
  scale_colour_continuous(guide = FALSE) +
  labs(x = ""Per capita plastic waste (kg per person per day)"",
       y = ""Per capita mismanaged plastic waste (kg per person per day)"",
       size = ""GDP per capita"",
       caption = ""Source: Our World in Data | Plot by @othomn"") +
  theme(axis.title = element_text(size = 12))


png(""plots/2-21-plastic-waste-cluster.png"",
    res = 300,
    height = 2300,
    width = 3000)
p_clust %>% print()
dev.off()

waste_clust %>% 
  mutate(label = case_when(cluster == 1 ~ cl_1,
                           cluster == 2 ~ cl_2,
                           cluster == 3 ~ cl_3)) %>%
  # mutate(plastic = log(plastic),
  #           lost = log(lost)) %>% 
  ggplot(aes(x = gdp_per_capita,
             y = lost,
             colour = cluster)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10()

waste_clust %>% 
  mutate(label = case_when(cluster == 1 ~ cl_1,
                           cluster == 2 ~ cl_2,
                           cluster == 3 ~ cl_3)) %>%
  # mutate(plastic = log(plastic),
  #           lost = log(lost)) %>% 
  ggplot(aes(x = gdp_per_capita,
             y = plastic,
             colour = cluster)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10()

","2019-21"
"953",768,"https://github.com/Argaadya/Media_Franchise","Argaadya","Media_Franchise","media.R","library(tidyverse)
library(ggridges)
library(ggrepel)
library(treemap)
library(cowplot)

setwd(""D:/R/datasets/"")
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")
write.csv(media_franchises,""media_franchise.csv"")
data <- read.csv(""media_franchise.csv"")

setwd(""D:/R/tidytuesday/media_franchise/"")

#Comparing Revenue from Revenue Category with the Original Media -------------------
png(""franchise1.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(data)+
  geom_tile(aes(revenue_category,original_media,fill=revenue),color=""gray"")+
  scale_fill_viridis_c(option = ""B"")+
  theme_ridges()+
  labs(title = ""Revenue from Various Category and Original Media"",
       subtitle = ""Overall, Merchandise and Licensing is the highest source of revenue"",
       caption = ""@Argaadya1 | Data: Wikipedia"",
       x= ""Revenue Category"", y= ""Original Media"",fill=""Revenue (in Billions)"")+
  theme(plot.background = element_rect(fill =  ""#1D2024""),
        panel.background = element_rect(fill =  ""#1D2024""),
        panel.grid = element_blank(),
        axis.text.x = element_text(angle=30,hjust = 1),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""))
dev.off()

#Comic vs Manga: Which one is better? -------------------------------------------------------
manga_comic <- data %>% filter(original_media == ""Manga"" | original_media == ""Comic book"") %>% 
  group_by(franchise,original_media) %>% summarise(revenue = sum(revenue))
manga1 <- manga_comic[manga_comic$revenue %in% max(manga_comic$revenue),]
numnum <- data.frame(label = c(paste(""Number of franchise:"",nrow(manga_comic %>% filter(original_media == ""Manga"" ))),
                               paste(""Number of franchise:"",nrow(manga_comic %>% filter(original_media == ""Comic book"")))),
                     original_media=c(""Manga"",""Comic book""),
                     revenue = c(75,30))

png(""franchise2.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(manga_comic)+
  geom_boxplot(aes(y=revenue,x=original_media,fill=original_media),color=""pink"",
               outlier.color = ""orange"")+
  scale_fill_discrete(guide=F)+
  geom_text(data=manga1,aes(x=original_media,y=revenue,label=franchise),color=""white"",nudge_y = -5)+
  geom_text(data=numnum,aes(original_media,revenue,label=label),color=""white"")+
  theme_ridges()+
  theme(plot.background = element_rect(fill =  ""#1D2024""),
        panel.background = element_rect(fill =  ""#1D2024""),
        panel.grid = element_blank(),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""))+
  labs(title = ""Is Manga better than Comic Book?"",
       subtitle = ""Revenue from Manga are more varied, with highest total revenue ever generated is hold by Anpanman"",
       caption = ""@Argaadya1 | Data: Wikipedia"",
       x= ""Original Media"", y= ""Total Revenue (in Billions)"")
dev.off()

#What Original Media Gain Most Revenue -----------------------------------------------
origin <- data %>% group_by(franchise,original_media) %>% 
  summarise(revenue = sum(revenue))
origin <- origin[order(origin$revenue),]
origin$franchise <- factor(origin$franchise,origin$franchise)
origin <- origin[(nrow(origin)-24):nrow(origin),]

png(""franchise3.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(origin)+
  geom_col(aes(franchise,revenue,fill=original_media))+
  geom_text(aes(franchise,revenue,label=round(revenue,2)),nudge_y = 5,color=""orange"")+
  coord_flip()+
  theme_ridges()+
  theme(plot.background = element_rect(fill =  ""#1D2024""),
        panel.background = element_rect(fill =  ""#1D2024""),
        panel.grid = element_blank(),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""))+
  labs(title = ""Top Franchise by Total Revenue"",
       subtitle = ""Manga dominate the chart, with 7 of Top 25 franchise are from Manga"",
       caption = ""@Argaadya1 | Data: Wikipedia"",
       x= ""Franchise"", y= ""Total Revenue (in Billions)"",fill=""Original Media"")
dev.off()


#Treemap of Revenue Category -----------------------------------
png(""franchise4.png"", width = 3840, height = 2160, units = 'px', res = 300)
treemap(data,
        index = c(""revenue_category"",""franchise""),
        vSize = ""revenue"",type = ""index"",
        palette = ""Set1"",
        title = ""Treemap of Revenue by Category""
        )
dev.off()




#combine Plot -----------------------------------------------------------
f1 <- ggplot(data)+
  geom_tile(aes(y=revenue_category,x=original_media,fill=revenue),color=""gray"")+
  scale_fill_viridis_c(option = ""B"")+
  theme_ridges()+
  labs(title = ""Revenue from Various Category and Original Media"",
       subtitle = ""Overall, Merchandise and Licensing is the highest source of revenue"",
       caption = ""@Argaadya1 | Data: Wikipedia"",
       y= ""Revenue Category"", x= ""Original Media"",fill=""Revenue
(in Billions)"")+
  theme(plot.background = element_rect(fill =  ""#1D2024""),
        panel.background = element_rect(fill =  ""#1D2024""),
        panel.grid = element_blank(),
        plot.title = element_text(colour = ""lightgoldenrodyellow""),
        axis.text.x = element_text(angle=45,hjust = 1,size = 10),
        axis.text.y = element_text(hjust = 1,size = 10),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        axis.title = element_text(colour = ""white"",size = 12))

origin <- data %>% group_by(franchise,original_media) %>% 
  summarise(revenue = sum(revenue))
origin <- origin[order(origin$revenue),]
origin$franchise <- factor(origin$franchise,origin$franchise)
origin <- origin[(nrow(origin)-9):nrow(origin),]

f2 <- ggplot(origin)+
  geom_col(aes(franchise,revenue,fill=original_media))+
  geom_text(aes(franchise,revenue,label=round(revenue,2)),nudge_y = 5,color=""orange"")+
  geom_text(aes(franchise,3,label=original_media),size=3,color=""black"",hjust=""left"")+
  coord_flip()+
  scale_fill_discrete(guide=F)+
  theme_ridges()+
  theme(plot.background = element_rect(fill =  ""#1D2024""),
        panel.background = element_rect(fill =  ""#1D2024""),
        panel.grid = element_blank(),
        plot.title = element_text(colour = ""lightgoldenrodyellow""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white"",size = 10),
        axis.title = element_text(colour = ""white"",size = 12))+
  labs(title = ""Top Franchise by Total Revenue"",
       subtitle = ""Manga dominate the chart, with 3 of Top 10 franchise originated from Manga"",
       x= ""Franchise"", y= ""Total Revenue (in Billions)"",fill=""Original Media"")

numnum <- data.frame(label = c(paste(""Number of franchise:"",nrow(manga_comic %>% filter(original_media == ""Manga"" ))),
                               paste(""Number of franchise:"",nrow(manga_comic %>% filter(original_media == ""Comic book"")))),
                     original_media=c(""Manga"",""Comic book""),
                     revenue = c(75,35))

f3 <- ggplot(manga_comic)+
  geom_boxplot(aes(y=revenue,x=original_media,fill=original_media),color=""pink"",
               outlier.color = ""orange"")+
  scale_fill_discrete(guide=F)+
  geom_text(data=manga1,aes(x=original_media,y=revenue,label=franchise),color=""white"",nudge_y = -5)+
  geom_text(data=numnum,aes(original_media,revenue,label=label),color=""white"")+
  theme_ridges()+
  theme(plot.background = element_rect(fill =  ""#1D2024""),
        panel.background = element_rect(fill =  ""#1D2024""),
        panel.grid = element_blank(),
        plot.title = element_text(colour = ""lightgoldenrodyellow""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white"",size = 10),
        axis.title = element_text(colour = ""white"",size = 12))+
  labs(title = ""Manga vs Comic Book"",
       subtitle = ""Revenue from Manga are more varied"",
       x= ""Original Media"", y= ""Total Revenue (in Billions)"")

row1 <- plot_grid(f2,f3,rel_widths = c(2,1))
png(""franchise5.png"", width = 3840, height = 2160, units = 'px', res = 300)
plot_grid(row1,f1,nrow = 2)
dev.off()
","2019-27"
"954",769,"https://github.com/Argaadya/Bird_count/blob/master/bird.R","Argaadya","Bird_count","bird.R","library(tidyverse)
library(ggridges)
setwd(dir = ""D:/R/tidytuesday/bird_count/"")
bird <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")
data <- na.omit(bird)

#What Bird is the Top Species? ------------------------------------------
top_species <- data %>% group_by(species) %>% 
  summarise(total= n(),counted = mean(how_many_counted), hour = mean(total_hours))
top_species <- top_species[order(top_species$counted,decreasing = T),]
top_species <- top_species[1:20,]
top_species <- top_species[order(top_species$counted),]
top_species$species <- factor(top_species$species,top_species$species)

png(""bird1.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(top_species, aes(species,counted))+
  geom_col(aes(fill=species))+
  coord_flip()+
  scale_fill_discrete(guide=F)+
  labs(title = ""What Bird is The Most Observed Overall?"",
       subtitle = ""Mean of Number of Bird Observed Annually"",
       x = ""Species"", y =""Number of Birds"",
       caption = ""Data: Bird Studies Canada"")+
  geom_text(aes(label=round(counted,2)),nudge_y = 1000)+
  theme(panel.grid = element_blank(),
        panel.background = element_rect(fill = ""white"", color = ""lightgray""))
dev.off()

#How is the trend of Bird sighting in years? -----------------------------
top_species <- data %>% group_by(species) %>% 
  summarise(total= n(),counted = mean(how_many_counted), hour = mean(total_hours))
top_species <- top_species[order(top_species$counted),]
top_species <- top_species[(nrow(top_species)-4):(nrow(top_species)),]
data_year <- data[data$species %in% top_species$species,]
data_year$species <- factor(data_year$species,top_species$species)

png(""bird2.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(data_year, aes(year,how_many_counted,color=species))+
  geom_point()+
  geom_line()+
  theme_light()+
  labs(title = ""Trend of Number of Top 5 Bird Species Observed Annually"",
       subtitle = ""Many of bird observed only start to trend just before 2000, while the European Starling sighting was booming after 1960 before starting to decline in 1990"",
       x = ""Year"", y =""Number of Birds"",
       caption = ""Data: Bird Studies Canada"")+
  scale_x_continuous(breaks = c(1920,1940,1960,1980,2000,2020))
dev.off()  

#Distribution of Bird Counted ------------------------------------------
top_species <- data %>% group_by(species) %>% 
  summarise(total= n(),counted = mean(how_many_counted), hour = mean(total_hours))
top_species <- top_species[order(top_species$counted,decreasing = T),]
top_species <- top_species[1:10,]
top_species <- top_species[order(top_species$counted),]
top_species$species <- factor(top_species$species,top_species$species)
data_year <- data[data$species %in% top_species$species,]
data_year$species <- factor(data_year$species,top_species$species)

png(""bird3.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(data_year, aes(species,how_many_counted, fill = species))+
  geom_boxplot(alpha=1/2)+
  scale_fill_discrete(guide=F)+
  theme_ridges()+
  coord_flip()+
  labs(title = ""Number of Bird Observed Annually"",
       subtitle = ""European Starling has the widest range in number of birds observed"",
       x = ""Species"", y =""Number of Birds"",
       caption = ""Data: Bird Studies Canada"")
dev.off()

#How many hours people spend on bird sighting annually? -------------------
sight <- data %>% group_by(year) %>% 
  summarise(total = n(), hour = mean(total_hours))

png(""bird4.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(sight, aes(year,hour))+
  geom_point()+ geom_smooth(alpha=1/8)+
  geom_line()+
  theme_light()+
  labs(title = ""How many hours people spend on bird sighting annually?"",
       subtitle = ""There is an increase in number of hours people spend to observe birds"",
       x = ""Year"", y =""Number of Hours"",
       caption = ""Data: Bird Studies Canada"")+
  scale_x_continuous(breaks = c(1920,1940,1960,1980,2000,2020))
dev.off()  

#How many species of bird spotted every year? -------------------------------
birda <- data %>% filter(how_many_counted > 0)
birda <- birda %>% group_by(year) %>% 
  summarise(hour = mean(total_hours), bird = sum(how_many_counted), 
            species = n())
birda <- birda %>% filter(year>1930)

png(""bird5.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(birda, aes(year,species))+
  geom_line(color=""navy"",alpha=1/2)+
  geom_point(aes(size=bird,color=bird),alpha=1/2)+
  theme_light()+
  theme(panel.grid = element_blank())+
  labs(title = ""How many species of bird spotted every year?"",
       subtitle = ""There is positive trend on number of species observed every year"",
       x = ""Year"", y =""Number of Species"",
       caption = ""Data: Bird Studies Canada"",
       color = ""Bird Observed"")+
  scale_x_continuous(breaks = c(1920,1940,1960,1980,2000,2020))+
  scale_size(guide=F)
dev.off()  

#Correlation between total hour and number of species ----------------------
sight <- data %>% filter(how_many_counted > 0 & year > 1930) %>% 
  group_by(year) %>% 
  summarise(species = n(), hour = mean(total_hours), bird = sum(how_many_counted))

png(""bird6.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(sight, aes(hour,species,color=bird,size=bird))+
  geom_point(alpha=1/2)+
  theme_ridges()+
  labs(title = ""Correlation Between Total Hour and Number of Species"",
       subtitle = ""The more hour you spend, the more species of bird you can found"",
       x = ""Total Hour"", y =""Number of Species"",
       caption = ""Data: Bird Studies Canada"",
       color = ""Bird Observed"")+
  scale_size(guide=F)+
  scale_color_gradient(low = ""red"",high = ""yellow"")
dev.off()       
","2019-18"
"955",770,"https://github.com/Argaadya/Nobel_Laureate","Argaadya","Nobel_Laureate","nobel.R","library(tidyverse)
library(ggridges)

setwd(""D:/R/datasets/"")
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")
write.csv(nobel_winners,""nobel_winners.csv"")
write.csv(nobel_winner_all_pubs,""nobel_winners_pubs.csv"")

nob_win <- read.csv(""nobel_winners.csv"")
nob_pub <- read.csv(""nobel_winners_pubs.csv"")

setwd(""D:/R/tidytuesday/nobel/"")

#Filter data with no NA in relevant attribute
data <- nob_win %>% filter(is.na(organization_name)==F)

#Data Grouping
by_yc <- nob_win %>% group_by(prize_year,category) %>% 
  summarise(freq = n())

#Nobel Laureate By Year -------------------------------------------------------------
png(""nobel1.png"", width = 3840, height = 2160, units = 'px', res = 300)
ggplot(by_yc)+
  geom_tile(aes(prize_year,category,fill=freq),color=""#1D2024"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        panel.grid.major.x =  element_blank(),
        panel.grid.minor.x = element_blank(),
        text = element_text(colour = ""lightyellow""),
        axis.text = element_text(colour = ""gold""),
        legend.background = element_rect(fill = ""#1D2024""))+
  scale_fill_gradient2(low = ""black"",mid = ""navy"",high = ""lightyellow"")+
  scale_x_continuous(breaks = seq(1900,2020,10))+
  labs(title = ""Nobel Prize Category by Year"",
       subtitle = ""During the WW2 (1940-1945) no Nobel Prize are given"",
       x = ""Prize Year"", y = ""Category"", fill = ""Number of Prize"",
       caption = ""data: dataverse.harvard.edu"")
dev.off()

#Which Organization Type Has The High Number of Individual Laureate ---------------------------
by_org <- data %>% 
  mutate(organization_type = case_when(str_detect(organization_name,""Universi"")==T ~ ""University"",
                                       str_detect(organization_name,""Institut"")==T ~ ""Institute"",
                                       str_detect(organization_name,""Lab"")==T ~ ""Laboratory"",
                                       str_detect(organization_name,""Colle"")==T ~ ""College"",
                                       TRUE ~ ""Other"")) %>% 
  group_by(category,organization_type) %>% 
  summarise(freq = n())
by_org2 <- by_org %>% group_by(organization_type) %>% summarise(t = sum(freq),)
by_org2 <- by_org2[order(by_org2$t),]
by_org$organization_type <- factor(by_org$organization_type,
                                   levels = unique(by_org2$organization_type))

png(""nobel2.png"", width = 3840, height = 2160, units = 'px', res = 300)                           
ggplot(by_org)+
  geom_col(aes(organization_type,freq,fill=category))+
  coord_flip()+
  scale_fill_brewer(palette = ""Set3"")+
  theme_ridges()+
  labs(title = ""Number of Individual Laureate by Organization Type"",
       subtitle = ""University Dominate the Nobel Prize"",
       y = ""Number of Laureate"", x = ""Organization Type"", fill = ""Category"",
       caption = ""data: dataverse.harvard.edu""
       )+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        panel.grid.major.x =  element_blank(),
        panel.grid.minor.x = element_blank(),
        text = element_text(colour = ""lightyellow""),
        axis.text = element_text(colour = ""gold""),
        legend.background = element_rect(fill = ""#1D2024""))
dev.off()  

#Where most of Nobel Laureate Organization is -------------------------------------------------
by_organ <- data %>% group_by(organization_name,category) %>% 
  summarise(freq = n())
by_organ2 <- by_organ %>% group_by(organization_name) %>% summarise(tot = sum(freq))
by_organ2 <- by_organ2[order(by_organ2$tot,decreasing = T),]
by_organ2 <- by_organ2[1:6,]
by_organ2 <- by_organ2[order(by_organ2$tot),]
by_organ <- by_organ[by_organ$organization_name %in% by_organ2$organization_name,]
by_organ$organization_name <- factor(by_organ$organization_name,by_organ2$organization_name)

png(""nobel3.png"", width = 3840, height = 2160, units = 'px', res = 300)                           
ggplot(by_organ)+
  geom_col(aes(organization_name,freq,fill = category))+
  facet_grid(facets = by_organ$category)+
  scale_fill_brewer(guide=F,palette = ""Set2"")+
  coord_flip()+
  labs(title = ""Top 6 Organization with High Number of Nobel Laureate"",
       x=""Organization Name"", y = ""Number of Laureate"",
       caption = ""data: dataverse.harvard.edu"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""lightyellow""),
        panel.grid = element_blank(),
        text = element_text(colour = ""white"",size=14),
        axis.text = element_text(colour = ""lightyellow""),
        legend.background = element_rect(fill = ""#1D2024""))
dev.off()  

#Top 15 People With Nobel Prize -------------------------------------------------
win_name <- nob_pub %>% filter(is.na(title)==F) %>% 
        group_by(laureate_name,is_prize_winning_paper) %>% 
        summarise(tot = n())
win_name2 <- win_name %>% filter(is_prize_winning_paper==""YES"")
win_name2 <- win_name2[order(win_name2$tot,decreasing = T),]
win_name2 <- win_name2[1:30,]
win_name2 <- win_name2[order(win_name2$tot),]
win_name <- win_name[win_name$laureate_name %in% win_name2$laureate_name,]
win_name$laureate_name <- factor(win_name$laureate_name,win_name2$laureate_name)
win_name3 <- win_name %>% filter(is_prize_winning_paper==""NO"")
win_name3 <- win_name3[order(win_name3$laureate_name),]
ratio <- data.frame(name = win_name2$laureate_name, 
                    win = win_name2$tot, no = win_name3$tot,
                    ratio = round(win_name2$tot/(win_name2$tot+win_name3$tot)*100,2),
                    prop = paste(win_name2$tot,""/"",win_name2$tot+win_name3$tot,sep = """"))
  
png(""nobel4.png"", width = 3840, height = 2160, units = 'px', res = 300)                           
ggplot(win_name)+
  geom_col(aes(laureate_name,tot,fill=tot),color=""white"")+
  geom_text(data = ratio, aes(name,win_name3$tot,label= prop),hjust = ""left"",
            nudge_y = 10,color=""lightyellow"")+
  scale_fill_viridis_c()+
  coord_flip()+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""lightyellow""),
        panel.grid = element_blank(),
        text = element_text(colour = ""white"",size=14),
        axis.text = element_text(colour = ""lightyellow""),
        legend.background = element_rect(fill = ""#1D2024""))+
  labs(title = ""Individual with High Number of Nobel Prize"",
       subtitle = ""Number shows proportion of nobel winning publications with his/her total number of publications"",
       x= ""Laureate Name"", y = ""Number of Publications"", fill = ""Publications"",
       caption = ""data: dataverse.harvard.edu"")
dev.off()
","2019-20"
"956",771,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","anime/anime.R","library(tidyverse)
library(lubridate)
library(tidytext)
library(ggrepel)
library(cowplot)

#data import
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")
tidy_anime <- write.csv(tidy_anime,""D:/R/datasets/tidy_anime.csv"")
tidy_anime <- read.csv(""D:/R/datasets/tidy_anime.csv"")

setwd(""D:/R/tidytuesday/anime/"")
names(tidy_anime)

#Who is the most productive studio?
#Studio with the highest rank
top_studio <- tidy_anime %>% group_by(studio) %>% 
  summarise(total = n(), score = mean(score,na.rm = T)) %>% 
  arrange(desc(score)) %>% top_n(15,score)
studio <- tidy_anime[tidy_anime$studio %in% top_studio$studio,]
studio$studio <- factor(studio$studio,levels = rev(top_studio$studio))
low_bandai <- studio %>% filter(studio==""Bandai Namco Pictures"" & score == min(score))
low_bandai <- low_bandai[1,]
low_bandai$name <- ""MILPOM Pilot""
low_geno <- studio %>% filter(studio==""Geno Studio"") %>% arrange(score) 
low_geno <- low_geno[1,]
low_marvy <- studio %>% filter(studio==""Marvy Jack"") %>% arrange(score) 
low_marvy <- low_marvy[1,]
low_minami <- studio %>% filter(studio==""Minami Machi Bugyousho"") %>% arrange(score) 
low_minami <- low_minami[1,]

png(""anime1.png"", width = 3960, height = 2160, units = 'px', res = 300)
studio %>% ggplot()+
  geom_boxplot(aes(studio,score,fill=studio),color=""pink"",show.legend = F)+
  geom_text_repel(data=low_bandai,aes(studio,score,label=paste(name,"", eps."",episodes,sep = """")),
            color=""lightyellow"",nudge_x = 1,hjust=""left"")+
  geom_text_repel(data=low_geno,aes(studio,score,label=paste(name,"", eps."",episodes,sep = """")),
                  color=""lightyellow"",nudge_x = 1,hjust=""right"")+
  geom_text_repel(data=low_marvy,aes(studio,score,label=paste(name,"", eps."",episodes,sep = """")),
                  color=""lightyellow"",nudge_x = -1,hjust=""right"")+
  geom_text_repel(data=low_minami,aes(studio,score,label=paste(name,"", eps."",episodes,sep = """")),
                  color=""lightyellow"",nudge_x = 1,hjust=""right"")+
  coord_flip()+
  labs(title = ""What is studio with high number of good anime score?"",
       subtitle = ""Bandai Namco has a really wide spread of anime score"",
       x = ""Studio"", y=""Score"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""white""))
dev.off()

#What is the most lucrative genre & their rating?
top_genre <- tidy_anime %>% group_by(genre) %>% 
  summarise(score = mean(score,na.rm = T), total = n()) %>% 
  arrange(desc(score)) %>% top_n(20,score)
gen_rating <- tidy_anime %>% group_by(genre,rating) %>% 
  summarise(score = mean(score,na.rm = T), total = n())
gen_rating <- gen_rating[gen_rating$genre %in% top_genre$genre,]
gen_rating$genre <- factor(gen_rating$genre,levels = rev(top_genre$genre))

png(""anime2.png"", width = 3960, height = 2160, units = 'px', res = 300)
gen_rating %>% ggplot()+
  geom_tile(aes(rating,genre,fill=score),color=""#1D2024"")+
  scale_fill_viridis_c(option = ""A"")+
  labs(title = ""What is the most lucrative genre & their rating?"",
       subtitle = ""Thriller anime has a great score especially for those with PG-13 rating"",
       x = ""Rating"", y=""Genre"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""white""))
dev.off()

#Top anime and their unique word plot
anime <- studio %>% group_by(name,synopsis) %>% 
  summarise(total = n(),score = mean(score,na.rm = T)) %>% arrange(desc(score))
anime <- anime[1:6,]
colnames(anime) <- c(""name"",""text"",""total"",""score"")
anime$text <- as.character(anime$text)
custom_stop <- tibble(word = c(""season"",""final"",""arc""))

text_anime <- anime %>% unnest_tokens(word,text) %>% count(name,word,sort = T) %>% 
  bind_tf_idf(word,name,n) %>% arrange(desc(tf_idf)) %>% anti_join(stop_words) 

png(""anime3.png"", width = 3960, height = 2160, units = 'px', res = 300)
text_anime %>% 
  mutate(word = factor(word,levels = rev(unique(word)))) %>% 
  group_by(name) %>% top_n(5) %>% ungroup() %>% 
  ggplot(aes(word,tf_idf,fill=name))+
  geom_col(show.legend = F)+
  coord_flip()+
  facet_wrap(facets = ~name,nrow = 2,scales = ""free_y"")+
  labs(title = ""What is the unique word in synopsis in Top 6 anime?"",
       subtitle = ""Each word in each anime reflect what their unique character and plots are compared to other anime
Both Gintama: Shirogane no Tamashii-hen only describe that they are the first and the second season of the final arc of Gintama"",
       x = ""Word"", y = ""Term Frequency - Inverse Document Frequency"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""white""))
dev.off()

#What is the best season to launch anime?
tidy_anime <- tidy_anime %>% separate(premiered,c(""season"",""year""))
anime_season <- tidy_anime %>% filter (is.na(season)==F & is.na(year)==F)%>% 
  group_by(season,year) %>% 
  summarise(score = mean(score,na.rm = T), popularity = mean(popularity,na.rm = T))
anime_season$season <- factor(anime_season$season,levels = c(""Spring"",""Summer"",""Fall"",""Winter""))

popular <- anime_season %>% ggplot()+
  geom_tile(aes(year,season,fill=popularity),color=""#1D2024"")+
  scale_fill_gradient(low = ""navy"",high = ""lightyellow"")+
  scale_x_discrete(breaks = seq(1960,2020,2))+
  labs(title = ""Older anime is more popular than the new one"",
       subtitle = ""Popular: how many members/users have the respective anime in their list"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        axis.text.x = element_text(angle = 45),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""white""))

score <- anime_season %>% ggplot()+
  geom_tile(aes(year,season,fill=score),color=""#1D2024"")+
  scale_fill_gradient(low = ""red"",high = ""lightyellow"")+
  scale_x_discrete(breaks = seq(1960,2020,2))+
  labs(title = ""Although newer anime has better score, it doesn't translate into popularity"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        axis.text.x = element_text(angle = 45),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""white""))

png(""anime4.png"", width = 3960, height = 2160, units = 'px', res = 300)
plot_grid(popular,score,nrow = 2)
dev.off()
","2019-17"
"957",772,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","horror_movies/horror.R","library(tidyverse)
library(ggrepel)
library(lubridate)
library(fishualize)
library(treemap)
library(ggalluvial)

# IMPORT DATA

horror_movies <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

# INSPECT
glimpse(horror_movies)


## DATA PREPROCESSING
df <- horror_movies %>% 
  mutate(language = word(str_replace(language,""[|]"","" ""), 1),
         genres = str_remove(word(genres, 1L),""\\|"")) %>%
  mutate_at(.vars = vars(title,genres,language,filming_locations,release_country,movie_rating), 
            .funs = as.factor) %>% 
  mutate(release_date = dmy(release_date),
         month = month(release_date,label = T, abbr = T),
         year = year(release_date),
         movie_run_time = as.numeric(str_remove(movie_run_time,"" min"")),
         budget = as.numeric(str_remove_all(str_extract(budget, ""\\(?[0-9,.]+\\)?""),"",""))) 

glimpse(df)
unique(df$language)

## HEATMAP -----------------
png(""horror1.png"", width = 3960, height = 2160, units = 'px', res = 300)
df %>% 
  group_by(month,year) %>% 
  summarise(run_time = mean(movie_run_time,na.rm = T), 
            review = mean(review_rating,na.rm = T)) %>% 
  drop_na(month) %>% 
ggplot(aes(month,year, fill = review))+
  geom_tile(color = ""#1D2024"")+
  geom_point(aes(month,year,size=run_time,color=run_time), shape = ""square"")+
  scale_fill_gradient(low = ""black"", high = ""hotpink"")+
  scale_size_continuous(range = c(3,20),guide = F)+
  scale_color_gradient(low = ""gray30"",high = ""greenyellow"")+
  scale_x_discrete(expand = c(0,0))+
  scale_y_continuous(breaks = seq(2010,2020,1),expand = c(0,0))+
  labs(title = ""Horror movies rating across month and year"",
       fill = ""Rating"", x = ""Month"",
       color = ""Run time"", y = ""Year"",
       caption = ""@Argaadya1"")+
  theme(panel.background = element_blank(),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_blank(),
        text = element_text(colour = ""lightyellow""),
        axis.text = element_text(colour = ""goldenrod""),
        plot.title = element_text(size = 20))
dev.off()

# VIOLIN CHART -----------------
png(""horror2.png"", width = 3960, height = 2160, units = 'px', res = 300)
df %>% 
  filter(!(movie_rating %in% c(""E"",""TV-PG"",""X"",""NC-17""))) %>%
  drop_na(movie_rating) %>% 
  ggplot(aes(movie_rating, review_rating, fill = movie_rating, color = movie_rating))+
  geom_violin(show.legend = F)+
  geom_jitter(alpha=0.5, show.legend = F)+
  scale_fill_fish_d(""Centropyge_loricula"")+
  labs(title = ""Horror Movies Reviews Across Age Rating"",
       x = ""Rating"", y = ""Reviews"")+
  theme(panel.background = element_blank(),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_blank(),
        text = element_text(colour = ""lightyellow""),
        axis.text = element_text(colour = ""goldenrod""),
        plot.title = element_text(size = 20),
        panel.grid = element_blank())
dev.off()

# SANKEY DIAGRAM ------------------------
png(""horror3.png"", width = 3960, height = 2160, units = 'px', res = 300)
df %>% 
  drop_na(movie_rating,genres,budget) %>%
  mutate(budget = factor(case_when(budget <= 30000 ~ ""Low Budget"",
                            budget > 30000 & budget <= 85000 ~ ""Mid Budget"",
                            budget > 85000 ~ ""High Budget""),
                         levels = c(""Low Budget"", ""Mid Budget"", ""High Budget""))) %>% 
  group_by(movie_rating,genres,budget,year) %>% 
  summarise(frequency = n()) %>%
  filter(frequency>3) %>% 
  ggplot(aes(axis1 = year, axis2 = genres, axis3 = movie_rating, y = frequency))+
  geom_alluvium(aes(fill = budget),alpha=0.6)+
  geom_stratum()+
  geom_text(stat = ""stratum"", label.strata = T)+
  theme_minimal()+
  scale_x_continuous(expand = c(0,0))+
  scale_y_continuous(expand = c(0,0))+
  scale_fill_fish_d(""Centropyge_loricula"",direction = -1)+
  theme(axis.text.x = element_blank(),
        panel.grid = element_blank())+
  labs(title = ""Sankey Diagram"",
       caption = ""@Argadya1"")
dev.off()  
","2019-43"
"958",773,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","moore_law/moore.R","library(tidyverse)
library(scales)
library(extrafont)
library(cowplot)
library(ggrepel)
options(scipen = 10)

setwd(""D:/R/tidytuesday/moore_law/"")
#DATA
cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")
write.csv(cpu,""D:/R/datasets/moore/cpu.csv"")
cpu <- read.csv(""D:/R/datasets/moore/cpu.csv"")

gpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")
write.csv(gpu,""D:/R/datasets/moore/gpu.csv"")
gpu <- read.csv(""D:/R/datasets/moore/gpu.csv"")

ram <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")
write.csv(ram,""D:/R/datasets/moore/ram.csv"")
ram <- read.csv(""D:/R/datasets/moore/ram.csv"")

#Moore's Law in CPU --------------------------------------------------------------------
cpu_mod <- lm(log2(transistor_count) ~ date_of_introduction,data = cpu)

png(""moore1.png"", width = 3960, height = 2160, units = 'px', res = 300)
cpu %>% mutate(transistor_count = log2(transistor_count)) %>% 
  filter(is.na(transistor_count)==F) %>% 
  ggplot()+
  geom_line(aes(date_of_introduction,predict(cpu_mod)),color=""white"")+
  geom_segment(aes(x=date_of_introduction,xend=date_of_introduction,
                   y=transistor_count,yend=predict(cpu_mod)),
               color=""gray80"",linetype=""dashed"")+
  geom_point(aes(date_of_introduction,transistor_count, size = transistor_count, color=process),
             alpha=.6)+
  geom_text(aes(1970,30,label=""With the size of transistors being smaller,
the CPU could fit more and more transistors inside"",family=""mono""),
            hjust=""left"",color=""orange"",size=4.5)+
  scale_y_continuous(labels = number_format(big.mark = "",""))+
  scale_x_continuous(breaks = seq(1970,2020,5))+
  scale_color_gradient(low = ""maroon"",high = ""orange2"")+
  scale_size_continuous(guide=F)+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))+
  labs(title = ""Moore's Law on CPU"",
       color = ""Size (nanometers)"",
       x = ""Year"", y = ""Log2 (Transistor Count)"",
       subtitle = ""Moore's Law: The observation that the number of transistors in a dense integrated circuit doubles approximately every two years."")
dev.off()

#Moore's Law in GPU --------------------------------------------------------------------
gpu_mod <- lm(log2(transistor_count) ~ date_of_introduction,data = gpu)

png(""moore2.png"", width = 3960, height = 2160, units = 'px', res = 300)
gpu %>% mutate(transistor_count = log2(transistor_count)) %>% 
  filter(is.na(date_of_introduction)==F) %>% 
  ggplot()+
  geom_line(aes(date_of_introduction,predict(gpu_mod)),color=""white"")+
  geom_segment(aes(x=date_of_introduction,xend=date_of_introduction,
                   y=transistor_count,yend=predict(gpu_mod)),
               color=""gray80"",linetype=""dashed"")+
  geom_point(aes(date_of_introduction,transistor_count, size = transistor_count,color=process),
             alpha=.6)+
  geom_text(aes(1980,30,label=""With the size of transistors being smaller,
the GPU could fit more and more transistors inside"",family=""mono""),
            hjust=""left"",color=""orange"",size=4.5)+
  scale_y_continuous(labels = number_format(big.mark = "",""))+
  scale_x_continuous(breaks = seq(1970,2020,5))+
  scale_color_gradient(low = ""maroon"",high = ""orange2"")+
  scale_size_continuous(guide=F)+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))+
  labs(title = ""Moore's Law on GPU"",
       color = ""Size (nanometers)"",
       x = ""Year"", y = ""Log2 (Transistor Count)"",
       subtitle = ""Moore's Law: The observation that the number of transistors in a dense integrated circuit doubles approximately every two years."")
dev.off()

#Moore's Law on RAM -------------------------------
ram_mod <- lm(log2(transistor_count) ~ date_of_introduction,data = ram)

png(""moore3.png"", width = 3960, height = 2160, units = 'px', res = 300)
ram %>% mutate(transistor_count = log2(transistor_count)) %>% 
  filter(is.na(transistor_count)==F) %>% 
  ggplot()+
  geom_line(aes(date_of_introduction,predict(ram_mod)),color=""white"")+
  geom_segment(aes(x=date_of_introduction,xend=date_of_introduction,
                   y=transistor_count,yend=predict(ram_mod)),
               color=""gray80"",linetype=""dashed"")+
  geom_point(aes(date_of_introduction,transistor_count, size = transistor_count,color=process),
             alpha=.6)+
  geom_text(aes(1960,30,label=""With the size of transistors being smaller,
the ram could fit more and more transistors inside"",family=""mono""),
            hjust=""left"",color=""orange"",size=4.5)+
  scale_y_continuous(labels = number_format(big.mark = "",""))+
  scale_x_continuous(breaks = seq(1960,2020,5))+
  scale_color_gradient(low = ""maroon"",high = ""orange2"")+
  scale_size_continuous(guide=F)+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))+
  labs(title = ""Moore's Law on RAM"",
       color = ""Size (nanometers)"",
       x = ""Year"", y = ""Log2 (Transistor Count)"",
       subtitle = ""Moore's Law: The observation that the number of transistors in a dense integrated circuit doubles approximately every two years."")
dev.off()

#Combine 3 plots -----------------------------------------------------
plot_cpu <- cpu %>% mutate(transistor_count = log2(transistor_count)) %>% 
  filter(is.na(transistor_count)==F) %>% 
  ggplot()+
  geom_line(aes(date_of_introduction,predict(cpu_mod)),color=""white"")+
  geom_text(aes(1990,5,label=""CPU"",family=""mono""),size=36,hjust=""center"")+
  geom_segment(aes(x=date_of_introduction,xend=date_of_introduction,
                   y=transistor_count,yend=predict(cpu_mod)),
               color=""gray80"",linetype=""dashed"")+
  geom_point(aes(date_of_introduction,transistor_count, size = transistor_count, 
                 color=transistor_count),
             alpha=.5,show.legend = F)+
  scale_y_continuous(labels = number_format(big.mark = "",""),limits = c(0,40))+
  scale_x_continuous(breaks = seq(1970,2020,10))+
  scale_color_gradient(low = ""maroon"",high = ""orange2"")+
  scale_size_continuous(guide=F)+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))+
  labs(x = """", y = ""Log2 (Transistor Count)"")

plot_gpu <- gpu %>% mutate(transistor_count = log2(transistor_count)) %>% 
  filter(is.na(date_of_introduction)==F) %>% 
  ggplot()+
  geom_text(aes(2000,5,label=""GPU"",family=""mono""),size=36,hjust=""center"")+
  geom_line(aes(date_of_introduction,predict(gpu_mod)),color=""white"")+
  geom_segment(aes(x=date_of_introduction,xend=date_of_introduction,
                   y=transistor_count,yend=predict(gpu_mod)),
               color=""gray80"",linetype=""dashed"")+
  geom_point(aes(date_of_introduction,transistor_count, size = transistor_count,
                 color=transistor_count),
             alpha=.5,show.legend = F)+
  scale_y_continuous(labels = number_format(big.mark = "",""),limits = c(0,40))+
  scale_x_continuous(breaks = seq(1970,2020,10))+
  scale_color_gradient(low = ""maroon"",high = ""orange2"")+
  scale_size_continuous(guide=F)+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))+
  labs(x = """", y = """")

plot_ram <- ram %>% mutate(transistor_count = log2(transistor_count)) %>% 
  filter(is.na(transistor_count)==F) %>% 
  ggplot()+
  geom_text(aes(1990,5,label=""RAM"",family=""mono""),size=36,hjust=""center"")+
  geom_line(aes(date_of_introduction,predict(ram_mod)),color=""white"")+
  geom_segment(aes(x=date_of_introduction,xend=date_of_introduction,
                   y=transistor_count,yend=predict(ram_mod)),
               color=""gray80"",linetype=""dashed"")+
  geom_point(aes(date_of_introduction,transistor_count, size = transistor_count,
                 color=transistor_count),
             alpha=.5,show.legend = F)+
  scale_y_continuous(labels = number_format(big.mark = "",""))+
  scale_x_continuous(breaks = seq(1970,2020,10))+
  scale_color_gradient(low = ""maroon"",high = ""orange2"")+
  scale_size_continuous(guide=F)+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))+
  labs(x = """", y = """")

png(""moore4.png"", width = 3960, height = 2160, units = 'px', res = 300)
plot_grid(plot_cpu,plot_gpu,plot_ram,nrow = 1)
dev.off()

#Pattern between number of transistor with computational capacity ---------------------
ram <- ram %>% 
  mutate(capacity = case_when(bit_units == ""Bits"" ~ capacity_bits*1,
                              bit_units == ""kb"" ~ capacity_bits*8000,
                              bit_units == ""Mb"" ~ capacity_bits*8*10^6,
                              bit_units == ""Gb"" ~ capacity_bits*8*10^9))

cap_mod <- lm(log10(capacity)~log10(transistor_count),data=ram)

#labeling smallest and biggest RAM capacity
one_bit <- ram %>% filter(is.na(capacity)==F) %>% 
  filter(transistor_count == min(transistor_count))
large_bit <- ram %>% filter(is.na(capacity)==F) %>% filter(capacity == max(capacity))

png(""moore5.png"", width = 3960, height = 2160, units = 'px', res = 300)
ram %>% 
  mutate(transistor_count = log10(transistor_count),
         capacity = log10(capacity)) %>% 
  filter(is.na(transistor_count)==F) %>% 
  ggplot()+
  geom_line(aes(predict(cap_mod),transistor_count),color=""snow3"")+
  geom_point(aes(capacity,transistor_count,color=capacity),size=4,alpha=.5)+
  geom_text_repel(aes(capacity,transistor_count,
                       label=manufacturer_s),
                   size=3,min.segment.length = 2,color=""snow2"")+
  scale_color_gradient(low = ""purple"",high = ""violet"")+
  scale_x_continuous(breaks = seq(0,14,2))+
  scale_y_continuous(breaks = seq(0,14,2))+
  scale_size_continuous(labels = number_format(big.mark = "",""))+
  coord_flip()+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))+
  labs(title = ""RAM Capacity In 50 Years"",
       subtitle = ""From a single bit computer to gigabytes computer only in 50 years"",
       y = ""Log10 (Transistor Count)"", x = ""Log10 (RAM Capacity in bits)"")
dev.off()

","2019-36"
"959",774,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","nuclear/nuclear.R","library(tidyverse)
library(lubridate)
library(treemap)
library(maps)
library(ggrepel)

#Data Preparation
nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")
write.csv(nuclear_explosions,""D:/R/datasets/nuclear_explosion.csv"")
nuclear_explosions <- read.csv(""D:/R/datasets/nuclear_explosion.csv"")

world <- map_data(""world"")

setwd(""D:/R/tidytuesday/nuclear_explosion/"")

#Location of Nuclear Explosion -------------------------------------------------------
Japan_WW2 <- nuclear_explosions %>% filter(region == ""HIROSHIMA"" | region == ""NAGASAKI"")

png(""nuclear1.png"", width = 3960, height = 2160, units = 'px', res = 300)
ggplot(world)+
  geom_polygon(mapping = aes(x=long,y=lat,group=group),fill=""black"", color=""grey28"")+
  geom_point(data = nuclear_explosions, 
             aes(x=longitude,y=latitude, 
                 color = country, size = yield_upper),alpha=1/2)+
  geom_text_repel(data = Japan_WW2, aes(x=longitude,y=latitude,label=region),
                  color=""lightyellow"",nudge_x = 30,size=3,segment.alpha = 0.5)+
  geom_text_repel(data = nuclear_explosions %>% filter(year>1991),
                  aes(x=longitude,y=latitude),label=""AFC"",segment.alpha = 0.5,
                  color=""lightyellow"",size=2.5)+
  scale_color_discrete()+
  labs(x="""",y="""",
       size = ""Kilotons"", colore = ""Country"",
       caption = ""AFC : After Cold War Ended (1991)"",
       title = ""Nuclear Explosion Around The World"",
       subtitle = ""USA and USSR has more powerful nuclear warhead compared to the one dropped at Hiroshima and Nagasaki,
More countries have tested nuclear weapon since the end of cold war, while no ex-USSR nations done a nuclear testing yet"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_blank(),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))
  
dev.off()

#Power of Nuke over time ---------------------------------------------------

nuclear_explosions$type <- str_replace(nuclear_explosions$type,""WATERSUR"",""WATER SURFACE"")
nuclear_explosions$type <- str_replace(nuclear_explosions$type,""WATER SU"",""WATER SURFACE"")
nuclear_explosions$type <- str_replace(nuclear_explosions$type,""ATMOSPH"",""ATMOSPHERIC"")
nuclear_explosions$type <- str_replace(nuclear_explosions$type,""WATER SURFACERFACE"",
                                       ""WATER SURFACE"")
top_method <- nuclear_explosions %>% group_by(type) %>% 
  summarise(total=n(),magn = mean(magnitude_surface,na.rm = T)) %>% arrange(desc(magn))

nuclear_explosions$type <- factor(nuclear_explosions$type,levels = top_method$type)

png(""nuclear2.png"", width = 4500, height = 3240, units = 'px', res = 300)
nuclear_explosions %>% ggplot()+
  geom_point(aes(year,country,color=yield_upper,size=magnitude_surface),
             show.legend = F,alpha=.5)+
  facet_wrap(~type,scales = ""free_y"",nrow = 7,ncol = 3)+
  geom_text_repel(data = Japan_WW2[1,], aes(x=year,y=country,label=region),
                  color=""khaki1"",segment.alpha = 0.5,size=4,nudge_y = -2)+
  scale_color_gradient(low = ""orange"",high = ""lightyellow"")+
  scale_x_continuous(breaks = seq(1945,2000,10))+
  labs(x="""",y="""",
       title = ""Method of Nuclear Warhead Deployment and Their Power
"",
       caption = ""Size indicate magnitude surface"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        plot.title = element_text(size=18),
        plot.caption = element_text(size=16),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"",size=10),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""gray28""),
        strip.text = element_text(colour = ""snow"",size=12))
dev.off()

#Underground vs Airborne Nuclear Warhead --------------------------------------
heigh <- nuclear_explosions %>% filter(depth < - 30)
strong <- nuclear_explosions %>% filter(yield_upper > 15000)

png(""nuclear3.png"", width = 3960, height = 2160, units = 'px', res = 300)
nuclear_explosions %>% ggplot()+
  geom_point(aes(yield_upper,-depth,color=yield_upper,
                 size=magnitude_body),alpha=.5)+
  scale_color_gradient(low = ""orange"",high = ""lightyellow"",guide = F)+
  scale_y_continuous(breaks = seq(-100,400,50))+
  geom_text_repel(data = heigh, aes(x=yield_upper,y=-depth,
                                    label=paste(name,region,sep = "", "")),
                  color=""snow1"",segment.alpha = 0.5,size=3,nudge_y = 20)+
  geom_text_repel(data = strong, aes(x=yield_upper,y=-depth,
                                    label=paste(name,region,sep = "", "")),
                  color=""snow1"",segment.alpha = 0.5,size=3,nudge_y = 20)+
  labs(x=""Yield (Kilotons of TNT)"", y=""Height (in Km)"",
       size = ""Magnitude Surface"",
       title = ""Is Airborne Explosion Weaker Than The Ground/Underground One?"",
       subtitle = ""Interesting, many of USSR strongest nuke is a secret weapon (no name)"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""snow2""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))
dev.off()

#Treemap
png(""nuclear4.png"", width = 4500, height = 3240, units = 'px', res = 300)
treemap(nuclear_explosions %>% count(country,purpose,type),
        index = c(""country"",""purpose"",""type""),
        vSize = ""n"",type = ""index"",
        fontsize.labels = c(20,14,10),
        border.lwds = c(6,4,1),
        align.labels = list(c(""center"",""top""),c(""left"",""bottom""),c(""right"",""center"")),
        palette = ""Set1"",
        title = ""How and Why Every Country Use A Nuclear Warhead"")
dev.off()

","2019-34"
"960",775,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","nyc_squirrel/squirrel.R","library(tidyverse)
library(ggrepel)
library(lubridate)
library(gganimate)

nyc_squirrels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

squirrel <- nyc_squirrels %>% 
  mutate(date = mdy(date),
         year = year(date),
         month = month(date),
         day = day(date),
         wday = wday(date, label = T, abbr = T)) %>%   
  pivot_longer(cols = c(running, chasing,eating, foraging),
               names_to = ""activities"", values_to = ""value"") %>%
  mutate(value = as.numeric(value)) %>% 
  group_by(shift, year, month, day, wday, activities) %>% 
  summarise(sighting = sum(value)) %>% 
  ungroup() %>% 
  na.omit()
squirrel

p <- ggplot(squirrel, aes(activities, shift, fill = sighting))+
  geom_tile(color = ""white"")+
  geom_point(shape=21, aes(size = sighting), color = ""firebrick1"", stroke=3)+
  scale_fill_viridis_c(option = ""B"")+
  scale_size_continuous(guide = F, range = c(1,35))+
  geom_text(aes(x = 4, y =2.7, label = paste0(wday,"", "",""Oct "",day)), 
            size = 8, color = ""khaki1"")+
  scale_y_discrete(expand = c(0,0.8))+
  labs(title = ""Squirrels Sighting And Their Activities"",
       subtitle = ""Color and ring size indicates the number of sighting"",
       x = ""Activities"", y = ""Time of the Day"",
       caption = ""@Argaadya1"")+
  theme(panel.background = element_blank(),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_blank(),
        text = element_text(colour = ""lightyellow""),
        axis.text = element_text(colour = ""goldenrod"",size = 12),
        plot.title = element_text(size = 20),
        panel.grid = element_blank())

p

anim <- p + 
  transition_states(states = day,
                    transition_length = 2,
                    state_length = 1)
animate(anim, 200, fps = 20,  width = 720, height = 480, 
        renderer = gifski_renderer(""squirrel_anim.gif""))


squirrel_area <- nyc_squirrels %>% 
  mutate(date = mdy(date),
         year = year(date),
         month = month(date),
         day = day(date),
         wday = wday(date, label = T, abbr = F),
         wday = factor(wday, levels = c(""Sunday"",""Monday"",""Wednesday"",""Thursday"",""Friday"",""Saturday"")))
squirrel_area



p <- ggplot(squirrel_area, aes(lat,long))+
  geom_hex(color = ""white"")+
  geom_text(aes(40.765,-73.95, label = wday), size = 14, color = ""khaki1"", hjust = 0)+
  scale_fill_gradient(low = ""red4"", high = ""greenyellow"")+
  labs(title = ""Weekly Movement of Squirrels"",
       caption = ""@Argaadya1"")+
  theme(panel.background = element_blank(),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_blank(),
        text = element_text(colour = ""lightyellow""),
        axis.text = element_blank(),
        axis.title = element_blank(),
        plot.title = element_text(size=20),
        panel.grid = element_blank())

p

anim <- p + 
  transition_states(states = wday,
                    transition_length = 5,
                    state_length = 2)
anim
animate(anim, 200, fps = 20,  width = 720, height = 720, 
        renderer = gifski_renderer(""squirrel_area.gif""))
","2019-44"
"961",776,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","power_lift/power.R","#Load the Data
ipf_lifts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-08/ipf_lifts.csv"")


#Load the Package
library(tidyverse)
library(ggridges)
library(fishualize)

# Inspect the Data
glimpse(ipf_lifts)

# Data Preprocessing
power_clean <- ipf_lifts %>% 
  mutate_at(.vars = c(""age_class"",""weight_class_kg"",""federation"",""equipment""),
            .funs = as.factor) %>% 
    pivot_longer(cols = c(best3squat_kg,best3deadlift_kg,best3bench_kg),
                 names_to = ""best3"",
                 values_to = ""value"") %>% 
  drop_na(age_class) %>% 
  filter(value > 0) %>% 
  mutate(best3 = case_when(best3 == ""best3bench_kg"" ~""Best 3 Bench"",
                           best3 == ""best3deadlift_kg"" ~""Best 3 Deadlift"",
                           best3 == ""best3squat_kg"" ~""Best 3 Squat"")) %>% 
  mutate(age_class = if_else(age_class == ""80-999"", ""80+"", as.character(age_class)),
         sex = if_else(sex == ""F"", ""Female"", ""Male"")) %>% 
  mutate(age_class = factor(age_class, 
                            levels = c(""5-12"",""13-15"",""16-17"",""18-19"",""20-23"",""24-34"",""35-39"",
                                       ""40-44"",""45-49"",""50-54"",""55-59"",""60-64"",""65-69"",
                                       ""70-74"",""75-79"",""80+""))) %>% 
  filter(age_class != ""5-12"")

# Data for Annotation
power_mean <- ipf_lifts %>% 
  mutate(sex = if_else(sex == ""F"", ""Female"", ""Male"")) %>% 
  group_by(name, date, sex,age_class) %>% 
  summarise(bench = mean(best3bench_kg),
            deadlift = mean(best3deadlift_kg),
            squat = mean(best3squat_kg)) %>% 
  ungroup() %>% na.omit() %>% 
  group_by(sex)

maxbench <- power_mean %>% filter(bench == max(bench))
maxdeadlift <- power_mean %>% filter(deadlift == max(deadlift))
maxsquat <- power_mean %>% filter(squat == max(squat))
power_max <- rbind(maxbench,maxdeadlift,maxsquat)
power_max <- power_max %>%
  group_by(sex) %>% 
  mutate(best3 = case_when(bench == max(bench) ~ ""Best 3 Bench"",
                           deadlift == max(deadlift) ~ ""Best 3 Deadlift"",
                           squat == max(squat) ~ ""Best 3 Squat""))
maxcol <- apply(power_max[, 5:7], 1, max)
power_max$best <- maxcol

# Create the Plot
png(filename = ""power1.png"", height = 2160, width = 3960, res = 300)
ggplot(power_clean, aes(value, age_class, fill = age_class))+
  geom_density_ridges(alpha=.8, color = ""gray30"")+
  facet_grid(cols = vars(best3), rows = vars(sex))+
  scale_fill_fish_d(option = ""Acanthurus_sohal"", guide = F)+
  labs(title = ""Power Lift Performance Accross Ages and Sex"",
       subtitle = ""Best record of each category is shown on the right side"",
       x = ""Value (in Kg)"", y = """", caption = ""@Argaadya1 | #TidyTuesday"")+
  scale_y_discrete(expand = c(0,0))+
  scale_x_continuous(breaks = seq(0,600,100), expand = c(0,0))+
  theme(panel.grid = element_blank(),
        panel.background = element_blank(),
        plot.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"", size = 10),
        strip.background = element_rect(fill = ""maroon""),
        strip.text = element_text(colour = ""snow"", size = 12),
        plot.title = element_text(size=18, colour = ""lightyellow""))+
  geom_label(data = power_max, aes(500, 14, label = name), hjust=1, fill = ""white"", size = 4.5)+
  geom_text(data = power_max, aes(500, 10, label = maxcol), hjust = 1, size = 8, color = ""gray80"")+
  geom_text(data = power_max, aes(500, 12, label = date), hjust = 1, size = 6, color = ""gray80"")
dev.off()


# Second Plot
png(filename = ""power2.png"", height = 2160, width = 3960, res = 300)
ggplot(power_clean, aes(equipment, value, fill= equipment))+
  geom_boxplot(color = ""lightyellow"", show.legend = F)+
  scale_fill_fish_d(option = ""Chromis_vanderbilti"")+
  facet_grid(cols = vars(best3), rows = vars(sex), scales = ""free_y"")+
  labs(y = ""Value"", x = ""Equipment"",
       title = ""Distribution of Lift Performance Based on Equipment Used"",
       subtitle = """",
       caption = ""@Argaadya1 | #TidyTuesday"")+
  theme(panel.grid = element_blank(),
        panel.background = element_blank(),
        plot.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""lightyellow"", size = 10),
        strip.background = element_rect(fill = ""maroon""),
        strip.text = element_text(colour = ""snow"", size = 12),
        plot.title = element_text(size=18, colour = ""lightyellow""))
dev.off()

","2019-41"
"962",777,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","roman_emperor/emperor.R","library(tidyverse)
library(lubridate)
library(cowplot)
library(ggridges)
library(treemap)

emperors <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv"")
write.csv(emperors,""D:/R/datasets/emperor.csv"")
emperors <- read.csv(""D:/R/datasets/emperor.csv"")

setwd(""D:/R/tidytuesday/roman_emperor/"")
#Relation between rise of power to death cause ------------------------------------------
png(""emperor1.png"", width = 3960, height = 2160, units = 'px', res = 300)
emperors %>% count(cause,rise,killer) %>% 
  ggplot()+
  geom_tile(aes(killer,cause,fill=n),color=""#1D2024"")+
  scale_fill_gradient(low = ""maroon"",high = ""lightyellow"")+
  facet_wrap(~rise,ncol = 3,scales = ""free"")+
  labs(title=""How Emperor Rise to Power and Death"",
       x = ""Killer"", y=""Rise of Power"",fill=""count"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        axis.text.x = element_text(angle=30,vjust=1,hjust=1),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))
dev.off()

#Most common cause of death for an emperor ------------------------------------------------
cause <- emperors %>% count(cause) %>% mutate(cause = reorder(cause,n)) %>% 
  ggplot()+
  geom_col(aes(cause,n,fill=n))+
  geom_text(aes(cause,n,label=n),nudge_y = 1,color=""lightyellow"")+
  scale_fill_viridis_c(option = ""B"")+
  coord_flip()+
  labs(x=""Cause of Death"",y=""Count"",fill=""count"",
       title = ""Emperor's Cause of Death"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))

rise <- emperors %>% count(rise) %>% mutate(rise = reorder(rise,n)) %>% 
  ggplot()+
  geom_col(aes(rise,n,fill=n))+
  geom_text(aes(rise,n,label=n),nudge_y = 1,color=""lightyellow"")+
  scale_fill_viridis_c()+
  coord_flip()+
  labs(x=""Rise of Power"",y=""Count"",fill=""count"",
       title = ""How Emperor Rise to Power"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))

#Dynasty
dinas <- emperors %>% count(dynasty) %>% mutate(dynasty = reorder(dynasty,n)) %>% 
  ggplot()+
  geom_col(aes(dynasty,n,fill=n))+
  geom_text(aes(dynasty,n,label=n),nudge_y = 1,color=""lightyellow"")+
  scale_fill_viridis_c(option = ""C"")+
  coord_flip()+
  labs(x=""Dynasty"",y=""Count"",fill=""count"",
       title = ""Dynasty of Emperor"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))

#Birth Province
birth <- emperors %>% count(birth_prv) %>% mutate(birth_prv = reorder(birth_prv,n)) %>% 
  ggplot()+
  geom_col(aes(birth_prv,n,fill=n))+
  geom_text(aes(birth_prv,n,label=n),nudge_y = 1,color=""lightyellow"")+
  scale_fill_viridis_c(option = ""D"")+
  coord_flip()+
  labs(x=""Birth Province"",y=""Count"",fill=""count"",
       title = ""Birth Province of Emperor"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))

png(""emperor2.png"", width = 3960, height = 2160, units = 'px', res = 300)
plot_grid(rise,cause,dinas,birth,nrow = 2)
dev.off()

#Expected Age of Emperor from each dinasty
emperors <- emperors %>% mutate(year_birth = year(emperors$birth),
                    year_death = year(emperors$death),
                    ages = if_else(year_death - year_birth > 0,
                                   year_death - year_birth,
                                   year_death + year_birth))

png(""emperor3.png"", width = 3960, height = 2160, units = 'px', res = 300)
emperors %>% ggplot()+
  geom_density_ridges(aes(ages,dynasty,fill=era),alpha=.5)+
  scale_x_continuous(breaks = seq(0,100,10))+
  labs(x=""Ages"",y=""Dynasty"",fill=""Era"",
       title = ""Age Distribution of Roman Emperors"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""gold"",size=14))
dev.off()

#Tree map of Rise and Death of Emperor
png(""emperor4.png"", width = 3960, height = 2160, units = 'px', res = 300)
treemap(emperors %>% count(rise,cause,killer),
        index = c(""rise"",""cause"",""killer""),
        vSize = ""n"",type = ""index"",
        fontsize.labels = c(20,14,10),
        border.lwds = c(6,4,1),
        align.labels = list(c(""center"",""top""),c(""left"",""bottom""),c(""right"",""center"")),
        palette = ""Set1"",
        title = ""Rise and Death of Emperors"")
dev.off()
","2019-33"
"963",778,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","simpsons/simpson.R","library(tidyverse)
library(tidytext)
library(widyr)
library(ggraph)
library(igraph)

setwd(""D:/R/tidytuesday/simpsons/"")
#Data 
simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")
write.csv(simpsons,""D:/R/datasets/simpsons.csv"")
simpsons <- read.csv(""D:/R/datasets/simpsons.csv"")
simpsons$season <-as.numeric(simpsons$season)
simpsons$season <- factor(simpsons$season,levels = sort(unique(simpsons$season)))

#Number of Guest Star by Season
simpsons_season <- simpsons %>% filter(is.na(role)==F) %>% 
  mutate(role = case_when(str_detect(role,""Himself"") ~ ""Himself"",
                          str_detect(role,""Herself"") ~ ""Herself"",
                          role != ""Himself"" & role != ""Herself""  ~ ""Other"")) %>% 
  group_by(season,role) %>% summarise(total = n()) 

#Top Guest Star in each season?
top_guest <- simpsons %>% filter(is.na(role)==F) %>% 
  group_by(season,guest_star) %>% summarise(total = n()) %>% ungroup() %>% 
  group_by(season) %>% filter(total>1) %>% top_n(1,total) 

#Number of Guest Star in each season -------------------------------------------------
number_guest <- simpsons %>% count(season)
top_guest <- top_guest %>% inner_join(number_guest) %>% arrange(desc(n))
top_guest$guest_star <- factor(top_guest$guest_star,
                               levels = unique(top_guest$guest_star))

png(""simpson1.png"", width = 3960, height = 2160, units = 'px', res = 300)
simpsons_season %>% ggplot()+
  geom_col(aes(season,total,fill=role),position = ""stack"")+
  geom_text(data=top_guest,aes(season,n,label=guest_star),
            color=if_else(top_guest$guest_star==""Marcia Wallace"",""gold"",""white""),
            angle=90,hjust=""left"",nudge_y = 2,check_overlap = T)+
  scale_fill_brewer(palette = ""Spectral"",direction = -1)+
  scale_y_continuous(limits = c(0,85),breaks = seq(1,81,5))+
  labs(x="""",y=""Number of Guest Stars"",fill=""Role as"",
       title = ""Guest Star's Role in Each Season"",
       subtitle = ""Marcia Wallace is the top guest star on many season"",
       caption = ""Vertical Name Shows Top Guest Star In Each Season"")+
  theme(legend.position = ""bottom"",
        panel.background = element_rect(fill = ""#1D2024""),
              plot.background = element_rect(fill = ""#1D2024""),
              legend.background = element_rect(fill = ""#1D2024""),
              text = element_text(colour = ""white""),
              axis.text = element_text(colour = ""snow2""),
              panel.grid = element_blank(),
              strip.background = element_rect(fill = ""#1D2024""),
              strip.text = element_text(colour = ""gold"",size=14))
dev.off()

#Link Between Guest Star in an Episode ---------------------------------------------
cor_role <- simpsons %>% 
  pairwise_count(guest_star,episode_title,sort=T) 

png(""simpson2.png"", width = 4560, height = 2160, units = 'px', res = 300)
cor_role %>% filter(n > 1) %>% 
  graph_from_data_frame() %>%
  ggraph(layout = ""fr"") +
  geom_edge_link(color=""orange"")+
  geom_node_point(color = ""lightblue"",size=3) +
  geom_node_label(aes(label = name), repel = T,color=""black"",alpha=.6) +
  theme_void()+
  labs(title = ""    Guest Stars Who Played Together in A Single Episode More Than Once
"",y="""")+
  theme(panel.grid = element_blank(),
        panel.background = element_rect(fill = ""#1D2024"",color=NULL),
        plot.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white"",size=12),
        axis.text = element_blank(),
        strip.background = element_rect(fill = ""gray80""),
        strip.text = element_text(colour = ""#1D2024"",size=12),
        legend.background = element_blank(),
        legend.text = element_text(colour = ""lightyellow""))
dev.off()

#Top 5 Guest Star in Each Season ---------------------------------------------
png(""simpson3.png"", width = 3960, height = 2160, units = 'px', res = 300)
simpsons %>% count(guest_star,season,sort = T,name = ""total"") %>% filter(total>1) %>% 
  mutate(guest_star = factor(guest_star,levels = rev(unique(guest_star)))) %>% 
  group_by(season) %>% top_n(5,total) %>% ungroup() %>% 
  ggplot()+
  geom_segment(aes(x=0,xend=total,y=guest_star,yend=guest_star),color=""gray80"")+
  geom_vline(aes(xintercept=5),color=""red"",linetype=""dashed"")+
  geom_point(aes(total,guest_star,color=if_else(total>5,""yes"",""no"")),
             size=2,show.legend = F)+
  facet_wrap(~season,ncol = 5,scales=""free_y"")+
  theme(panel.grid = element_blank(),
        panel.background = element_rect(fill = ""#1D2024"",color=NULL),
        plot.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white"",size=12),
        axis.text = element_text(colour = ""white""),
        strip.background = element_rect(fill = ""pink""),
        strip.text = element_text(colour = ""#1D2024"",size=12),
        legend.background = element_blank(),
        legend.text = element_text(colour = ""lightyellow""))+
  labs(title= ""Top Guest Star with More Than One Appearance In A Single Season"",
       subtitle = ""Marcia Wallace and Phil Hartman Are The Only Guest Star to Appear More Than 5 Times In A Single Season"",
       x="""",y="""")
dev.off()

#Heatmap Number of Top 10 Guest Star in Each Season ----------------------------------
top_guest <- simpsons %>% count(guest_star,name = ""total"",sort = T) %>% top_n(20,total)
guest_season <- simpsons[simpsons$guest_star %in% top_guest$guest_star,]
guest_season <- guest_season %>% count(guest_star,season,sort = T,name = ""total"") %>% 
  mutate(guest_star = factor(guest_star,rev(unique(guest_star))))
guest_appear <- guest_season %>% count(guest_star)

png(""simpson4.png"", width = 3960, height = 2160, units = 'px', res = 300)
guest_season %>% 
  ggplot()+
  geom_tile(aes(guest_star,season,fill=total),color=""#1D2024"")+
  scale_fill_viridis_c(option = ""B"")+
  coord_flip()+
  theme(panel.grid = element_blank(),
        panel.background = element_rect(fill = ""#1D2024"",color=NULL),
        plot.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white"",size=12),
        axis.text = element_text(colour = ""white""),
        strip.background = element_rect(fill = ""gray80""),
        strip.text = element_text(colour = ""#1D2024"",size=12),
        legend.background = element_blank(),
        legend.text = element_text(colour = ""lightyellow""))+
  labs(title = ""Number of Star Appearance in Each Season for Top 20 Guest Star"",
       x=""Season"",y="""",fill=""Appearance"",
       subtitle = paste(""On average, a guest star appear at least on"",
                        median(guest_appear$n),
                        ""seasons for the Top 20 Guest Stars""))
dev.off()
","2019-35"
"964",779,"http://github.com/Argaadya/tidytuesday","Argaadya","tidytuesday","video_games/video.R","library(tidyverse)
library(lubridate)
library(ggridges)
setwd(""D:/R/tidytuesday/video_game"")
video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")
write.csv(video_games,""D:/R/datasets/video_games.csv"")
video_games <- read.csv(""D:/R/datasets/video_games.csv"")

#Is there any pattern in release date with price? -------------------------------
video_games$release_date <- mdy(video_games$release_date)
video_games <- video_games %>% filter(is.na(release_date)==F)
video_games <- video_games %>% mutate(month = month(release_date), year=year(release_date))
release_game <- video_games %>% group_by(month,year) %>% 
  summarise(playtime = mean(average_playtime), price = median(price,na.rm = T), total = n()) %>% 
  filter(is.na(price)==F)

png(""game1.png"", width = 4240, height = 2160, units = 'px', res = 300)  
release_game %>% ggplot()+
  geom_tile(aes(year,month,fill=price),color=""#1D2024"")+
  scale_fill_viridis_c(option = ""B"")+
  scale_y_continuous(breaks = seq(1,12,1),labels = month.abb)+
  scale_x_continuous(breaks = seq(2004,2020,2))+
  labs(title = ""Median Price of Video Game"",
       x = ""Year"", y = ""Month"")+
  theme_ridges()+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""white""))
dev.off()

#Owner distribution ------------------------------------------------------------------
png(""game2.png"", width = 4240, height = 2160, units = 'px', res = 300)  
video_games %>% ggplot()+
  geom_boxplot(aes(year,metascore,group=year,fill=year),color=""pink"",show.legend = F)+
  scale_x_continuous(breaks = seq(2004,2018,1))+
  scale_y_continuous(breaks = seq(0,100,10))+
  scale_fill_viridis_c(option = ""B"")+
  coord_flip()+
  theme_ridges()+
  labs(title = ""Are games getting better by year?"",
       x=""Year"", y = ""Metascore"")+
  theme(panel.background = element_rect(fill = ""#1D2024""),
        plot.background = element_rect(fill = ""#1D2024""),
        legend.background = element_rect(fill = ""#1D2024""),
        text = element_text(colour = ""white""),
        axis.text = element_text(colour = ""white""),
        panel.grid = element_blank(),
        strip.background = element_rect(fill = ""#1D2024""),
        strip.text = element_text(colour = ""white""))
dev.off()

","2019-31"
"965",781,"https://github.com/oscarbaruffa/tidytuesday_2018-11-20_thanksgiving_meals/blob/master/thanksgivng_script.R","oscarbaruffa","tidytuesday_2018-11-20_thanksgiving_meals","thanksgivng_script.R","library(tidyverse)

tgiv_raw <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-20/thanksgiving_meals.csv"")

#DataExplorer::create_report(tgiv_raw)

#let's see if there's any correlation between number of sides and number of desserts

tgiv_processed <- tgiv_raw %>% 
  filter(celebrate == ""Yes"") %>%
  #Select only side and desserts, drop ""Other"" columns
  select(id, side1:side13, side15, dessert1:dessert10, dessert12) %>%
  gather(side1:side15, key = ""side_number"", value = ""side_name"") %>% 
  gather(dessert1:dessert12, key = ""dessert_number"", value = ""dessert_name"") 

respond_id <- tgiv_raw %>% select(id) 

dessert_count <- 
  tgiv_processed %>% 
  select(id, dessert_name)%>% 
  filter(!is.na(dessert_name)) %>%
  group_by(id) %>%
  filter(!duplicated(dessert_name)) %>%
  summarise(dessert_num = n())

side_count <- 
  tgiv_processed %>% 
  select(id, side_name)%>% 
  filter(!is.na(side_name)) %>% 
  group_by(id) %>% 
  filter(!duplicated(side_name)) %>% 
  summarise(side_num = n()) 
  

respond_id <- respond_id %>% 
  left_join(dessert_count, by = ""id"") %>% 
  left_join(side_count, by = ""id"")

respond_id[is.na(respond_id)] <- 0

respond_id$id <- as.character(respond_id$id)

respond_id$dessert_num <- as.factor(respond_id$dessert_num)
respond_id$side_num <- as.factor(respond_id$side_num)

ggplot(respond_id, aes(side_num, dessert_num)) + 
  geom_point(colour = ""orange"", alpha = 0.7) + 
  geom_jitter(colour = ""orange"", alpha = 0.7) +
  labs(x = ""# Sides"", 
       y = ""# Desserts"",
       title = ""Does a balanced Thanksgiving meal"",
        subtitle = ""mean more sides than desserts?"",
        caption=""*0's could be N/A or 0 \n Plot by @oscar_b123 \n Data: fivethirtyeight "") +
    theme_minimal() 

","2018-34"
"966",782,"https://github.com/oscarbaruffa/tidytuesday-2018-11-27-Baltimore_bridges/blob/master/baltimore_bridges_script.R","oscarbaruffa","tidytuesday-2018-11-27-Baltimore_bridges","baltimore_bridges_script.R","library(tidyverse)
library(scales)
library(extrafont)


bridge_raw <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018-11-27/baltimore_bridges.csv"") 

#DataExplorer::create_report(bridge_raw)

bridge_raw$bridge_condition <- factor(bridge_raw$bridge_condition, 
                                      levels = c(""Poor"", ""Fair"", ""Good""))
bridge_raw <- bridge_raw %>% 
  mutate(ID = row_number()) #add UniqueID for later comparison
  
#Filter only Poor and Fair bridges, arrange by Condition and then by daily traffic
bridge_processed <- bridge_raw %>% 
  filter(bridge_condition != ""Good"") %>%
  arrange(bridge_condition, -avg_daily_traffic) %>% 
  mutate(cumulative = cumsum(avg_daily_traffic)) 

adt_pareto_val <- 0.8 * sum(bridge_processed$avg_daily_traffic)

bridges_to_repair <- bridge_processed %>% 
  filter(cumulative <= adt_pareto_val)

number_of_bridges <- count(bridges_to_repair)
percentage_of_bridges <- round((number_of_bridges / count(bridge_processed))*100, 0)
percentage_of_bridges <- paste0(percentage_of_bridges,""%"", collapse = """")

title <- paste('Pareto to Maryland: ""Fix these', number_of_bridges, 'first""')
subtitle <- paste(percentage_of_bridges, ""of bridges rated Poor or Fair condition carry\n80% of Poor and Fair combined traffic."")

bridges_to_repair %>% 
  ggplot(aes(x = long, y = lat, alpha = .5)) + geom_point(colour = ""maroon"") + 
  borders(""county"", ""Maryland"") +
  theme_void() +
  labs(title = title, 
       subtitle = subtitle,
       caption = ""Notes:Lots of caveats :)\nData: Balitmore Sun Data Desk\nPlot:@oscar_b123"") +
  theme(legend.position = ""none"", 
        plot.margin = unit(c(5,5,5,5), ""mm""),
        text = element_text(family = ""Merriweather""))


","2018-35"
"967",912,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/Christmas_Birds.Rmd","catrwilliams","rprojects","tidytuesday/Christmas_Birds.Rmd","---
title: ""Christmas Birds""
author: ""Catherine Williams""
date: ""June 18, 2019""
output:
  html_document:
    hightlight: tango
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 2
    toc_float: yes
---
# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data came from [Bird Studies Canada](https://www.birdscanada.org/index.jsp). The data includes meteorite information such as year, bird species, and number of birds.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(""~/../Google Drive/Data Analysis/Tidy Tuesday/06-18-19 - Christmas Bird Counts/"")
```

# Setup

## Load Libraries

```{r library, message=FALSE, results=FALSE}
#function to check if packages are installed, if not then install them, and load all packages
libraries <- function(packages){
  for(package in packages){
    #checks if package is installed
    if(!require(package, character.only = TRUE)){
      #If package does not exist, then it will install
      install.packages(package, dependencies = TRUE)
      #Loads package
      library(package, character.only = TRUE)
    }
  }
}

packages <- c(""data.table"",""tidyverse"",""visdat"",""zoo"",""extrafont"",""stringr"")

libraries(packages)

theme_set(theme_classic())
```

## Import Data

```{r import, message=FALSE}
df <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"", stringsAsFactors = TRUE)
```
# Exploratory Data Analysis

- There are 18,706 observations and 6 variables.
- how_many_counted_by_hour is how_many_counted divided by total_hours.
- There are many NA values with total_hours which results in NAs in how_many_counted_by_hour.

## View Data

```{r view}
glimpse(df)
head(df)
summary(df)
sapply(df, function(x) n_distinct(x)) %>% sort()
```

## Missing Values

View missing values in more detail.

```{r missing}
#Visualize missing values
vis_miss(df, sort_miss=TRUE)

#see count of missing values
na_values <- function(df){
  na <- colSums(is.na(df)) %>% sort(decreasing=TRUE)
  na[na>0]
}

na_values(df)
```

## Visualize Trends

```{r eda, warning=FALSE, out.width=""75%""}
df %>% ggplot(aes(year,(how_many_counted/total_hours)))+
  geom_bar(stat=""identity"")+
  labs(title=""Christmas Bird Counts Per Hour Over Time"", x=""Year"", y=""Count per Hour"")

df %>% ggplot(aes(total_hours, how_many_counted))+
  geom_jitter(alpha=0.3, size=1)+
  labs(title=""Total Christmas Bird Counts"",x=""Hours"", y=""Count"")
```

# Data Wrangling

Remove/replace missing values and drop unnecessary columns

```{r wrangle}
#remove NA hours if how_many_counted is 0
df <- df[!(df$how_many_counted==0 & is.na(df$total_hours)),]

#view missing data again
na_values(df)

# use interpolated values to replace NA values, grouped by species
df <- df %>% group_by(species) %>% mutate(total_hours = na.approx(total_hours)) %>% ungroup()

#view missing data again
na_values(df)

#drop how_many_counted_by_hour. this can be recalculated later
df <- df %>% select(1:5)
```

# Final Visualization

```{r viz, out.width=""100%""}
# how many owls were seen
df_owl <- df %>% filter(str_detect(species, ""Owl""))
df_owl <- df_owl %>% group_by(species) %>% summarize(counted = sum(how_many_counted))
df_owl <- df_owl %>% mutate(species = str_sub(species, end=-4))
df_owl$species <- fct_reorder(df_owl$species, df_owl$counted)

df_owl %>% ggplot(aes(species,counted))+
  geom_col(fill=""steelblue"")+
  geom_text(aes(label=counted), hjust=-0.1, vjust=0.5, family=""Bodoni MT"", fontface=""bold"")+
  coord_flip()+
  labs(title=""Christmas Owl Spottings"", subtitle=""From 1921 - 2017"", y=""Number Spotted"")+
  theme(legend.position=""none"",
        text=element_text(family=""Bodoni MT"", size=14),
        axis.title.y=element_blank(),
        plot.title=element_text(face=""bold"", size=24, hjust=0.175),
        plot.subtitle=element_text(hjust=0.325),
        plot.background=element_rect(fill=""#fff7e6""),
        panel.background=element_rect(fill=""#fff7e6""))

ggsave(""christmas_owls.png"", limitsize=FALSE)
```

","2019-18"
"968",913,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/UFO_Sightings.Rmd","catrwilliams","rprojects","tidytuesday/UFO_Sightings.Rmd","---
title: ""UFO Sightings""
author: ""Catherine Williams""
date: ""June 26, 2019""
output:
  html_document:
    hightlight: tango
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 2
    toc_float: yes
---
# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data came from [The National UFO Reporting Center](http://www.nuforc.org/). The data includes UFO sighting information such as date/time it was observed, location, UFO shape, and a description of the event.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
setwd(""~/../Google Drive/Data Analysis/Tidy Tuesday/06-25-19 - UFO Sightings/"")
```

# Setup

## Load Libraries

```{r library}
if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(""data.table"",""tidyverse"",""visdat"",""lubridate"",""rworldmap"",""sp"",""rworldxtra"",""maps"",""countrycode"",""ggridges"")

theme_set(theme_classic())
```

## Import Data

```{r import}
df <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")
```
# Exploratory Data Analysis

- There are 80,332 observations and 11 variables.
- Most of the missing values are with state and country which could be looked up based on the coordinates.

## View Data

```{r view}
glimpse(df)
head(df)
summary(df)
sapply(df, function(x) n_distinct(x)) %>% sort()

df %>% count(ufo_shape, sort=TRUE)
```

## Missing Values

View missing values in more detail.

```{r missing}
#Visualize missing values
vis_miss(df, sort_miss=TRUE)

#see count of missing values
na_values <- function(df){
  na <- colSums(is.na(df)) %>% sort(decreasing=TRUE)
  na[na>0]
}

na_values(df)
```

# Data Wrangling

Remove/replace missing values and drop unnecessary columns

```{r wrangle}
df$latitude[is.na(df$latitude)] <- 33.2001

# The single argument to this function, points, is a data.frame in which:
#   - column 1 contains the longitude in degrees
#   - column 2 contains the latitude in degrees
coords2country = function(points){  
  countriesSP <- getMap(resolution='high') # uses high res map from rworldxtra

  #setting CRS directly to that from rworldmap
  pointsSP = SpatialPoints(points, proj4string=CRS(proj4string(countriesSP)))  

  # use 'over' to get indices of the Polygons object containing each point 
  indices = over(pointsSP, countriesSP)

  # return the names of each country
  indices$ISO3
}

df$country <- coords2country(df[,c(11,10)])

#function to find if any string value matches, then make replacement 
find_string <- function(x, patterns, replacements=patterns, fill=NA, ...){
  stopifnot(length(patterns) == length(replacements))

  ans = rep_len(as.character(fill), length(x))    
  empty = seq_along(x)

  for(i in seq_along(patterns)) {
      greps = grepl(patterns[[i]], x[empty], ...)
      ans[empty[greps]] = replacements[[i]]  
      empty = empty[!greps]
  }
  return(ans)
}

#prepare to match on country names found in city_area column
country <- map(""world"")
country <- country$names %>% as_data_frame()
country$iso <- country$value %>% countrycode(origin=""country.name"",destination=""iso3c"")

country <- separate_rows(country, value, sep="":"")
country <- country %>% filter(str_detect(value, ""[:alpha:]+"") & !is.na(iso)) %>% distinct()

df$country <- find_string(df$city_area, country$value, country$iso, df$country, ignore.case = TRUE)


#prepare to match on state abbreviations for countries in the USA
data(state.fips)
state.fips <- state.fips %>% select(abb) %>% distinct()
state.fips <- add_row(state.fips, abb = c(""AK"",""HI""))
state.fips <- add_column(state.fips, country = ""USA"")

df$country <- find_string(df$state, state.fips$abb, state.fips$country, df$country, ignore.case = TRUE)

#sort out country values that are still NA
df[is.na(df$country),] %>% select(city_area) %>% distinct()

df <- df %>% 
  mutate(date_time = parse_date_time(date_time, 'mdy_hm'),
         country = as.character(country),
         country = case_when(is.na(country) & str_detect(city_area, ""u\\.|uss|whitehouse"") ~ ""USA"",
                             is.na(country) & str_detect(city_area, ""viet nam"") ~ ""VNM"", 
                             is.na(country) & str_detect(city_area, ""britsh virgin islands"") ~ ""VGB"",
                             is.na(country) & str_detect(city_area, ""virgin"") ~ ""VIR"",
                             is.na(country) & str_detect(city_area, ""playa del cura|costa adeje|gibraltar"") ~ ""ESP"",
                             is.na(country) & str_detect(city_area, ""faliraki"") ~ ""GRC"",
                             TRUE ~ country),
        ufo_shape = case_when(ufo_shape %in% ""changed"" ~ ""changing"",
                              ufo_shape %in% ""round"" ~ ""circle"",
                              ufo_shape %in% ""flare"" ~ ""light"",
                              ufo_shape %in% c(""pyramid"",""delta"") ~ ""triangle"",
                              is.na(ufo_shape) ~ ""unknown"",
                              TRUE ~ ufo_shape),
         country = replace_na(country, ""Ocean""))

#view missing data again
na_values(df)


df$continent <- df$country %>% countrycode(origin=""iso3c"",destination=""continent"")
df$continent[is.na(df$continent)] <- ""Other""

```

# Visualizations

```{r viz, out.width=""100%""}
df_country <- df %>% group_by(country) %>% summarize(count=n()) %>% arrange(count) %>% tail(10)
df_top_country <- df %>% filter(country %in% df_country$country)


df_country %>% mutate(country = fct_reorder(country, count)) %>% 
  ggplot(aes(country, log(count), fill=count))+
  geom_col()+
  coord_flip()+
  labs(title=""Top Countries for UFO Sightings"")


df_top_country %>% ggplot(aes(hour(date_time),country,fill=country))+
  geom_density_ridges()+
  scale_x_continuous(limits=c(0,24),breaks=c(0,4,8,12,16,20,24),labels=c(""12am"",""4am"",""8am"",""noon"",""4pm"",""8pm"",""12am""))+
  labs(title=""UFO Sightings by Time of Day"",x=""Time"",y=""Country"")+
  theme(legend.position=""none"")


df %>% ggplot(aes(as.factor(month(date_time))))+
  geom_bar(fill=""olivedrab3"")+
  facet_wrap(~continent, scales=""free_y"")+
  labs(title=""UFO Sightings by Month & Continent"",subtitle=""From November 1906 - April 2014"",x=""Month"",y=""Number of sightings"")+
  scale_x_discrete(breaks=c(1,3,5,7,9,11),labels=c(""Jan"",""Mar"",""May"",""Jul"",""Sep"",""Nov""))+
  theme(panel.background=element_rect(fill=""gray16""),
        plot.title=element_text(hjust=0.5, size=18, face=""bold""),
        plot.subtitle=element_text(hjust=0.5))
              
ggsave(""ufo_sightings.png"")
```

","2019-26"
"969",914,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/Media-Franchises.Rmd","catrwilliams","rprojects","tidytuesday/Media-Franchises.Rmd","---
title: ""Media Franchises""
author: ""Catherine Williams""
date: ""July 3, 2019""
output:
  html_document:
    hightlight: tango
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 2
    toc_float: yes
---
# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data came from [Wikipedia](https://en.wikipedia.org/wiki/List_of_highest-grossing_media_franchises). The data includes information such as franchise name, revenue generated, year created, and owners/creators of the franchise.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
setwd(""~/../Google Drive/Data Analysis/Tidy Tuesday/07-02-19 - Media Franchises/"")
```

# Setup

## Load Libraries

```{r library}
if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(""tidyverse"",""visdat"",""extrafont"",""ggpubr"",""png"")

theme_set(theme_classic())
```

## Import Data

```{r import}
df <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")
```
# Exploratory Data Analysis

- There are 321 observations and 7 variables.
- Revenue is shown in 'billions' so the numbers seem small.
- Many of the variables are characters and appear to need cleaning.
- There are no missing values.
- 1996 brought in the most revenue.
- Pokmon, Hello Kitty, Winnie the Pooh, Mickey Mouse & Friends, Star Wars, and Anpanman have earned the most revenue.
- Merchandise, Licensing & Retail is the highest earning revenue category.

## View Data

```{r view}
glimpse(df)
head(df)
summary(df)
sapply(df, function(x) n_distinct(x)) %>% sort()

df %>% count(revenue_category, sort=TRUE)
df %>% count(original_media, sort=TRUE)
```

## Missing Values

View missing values in more detail.

```{r missing}
#Visualize missing values
vis_miss(df, sort_miss=TRUE)
```

## Data Cleaning

Clean fields to make them easier to read/visualize.

```{r wrangle}
df <- df %>% mutate(original_media = case_when(original_media %in% ""Book"" ~ ""Novel"",
                                               original_media %in% ""Cartoon character"" ~ ""Cartoon"",
                                               original_media %in% ""Visual novel"" ~ ""Comic book"",
                                               original_media %in% ""Animated cartoon"" ~ ""Animated series"",
                                               TRUE ~ original_media),
                    franchise = str_replace(franchise, ""A Song of Ice and Fire \\/ "", """"),
                    franchise = str_replace(franchise, ""Wizarding World \\/ "", """"),
                    franchise = str_replace(franchise, ""Middle-earth \\/ "", """"),
                    revenue_category = str_replace(revenue_category, "", Licensing & Retail"", """"),
                    revenue_category = str_replace(revenue_category, ""\\/Entertainment"", """"),
                    revenue_category = str_replace(revenue_category, ""\\/Games"", """"),
                    revenue_category = str_replace(revenue_category, "" sales"", """"),
                    revenue_category = str_replace(revenue_category, ""Comic or Manga"", ""Comic\\/Manga""))

```

## Visualizations

```{r eda}
df %>% ggplot(aes(year_created, revenue, fill=revenue_category))+
  geom_col()+
  scale_fill_viridis_d(option=""E"")+
  labs(title=""Franchise Revenue by Year"", x=""Year"", y=""Revenue (in billions)"")

df %>% filter(year_created > 1970) %>% 
  ggplot(aes(year_created, revenue, fill=revenue_category))+
  geom_col()+
  scale_fill_viridis_d(option=""E"")+
  labs(title=""Franchise Revenue after 1970"", x=""Year"", y=""Revenue (in billions)"")

df_revenue <- df %>% group_by(franchise) %>% summarize(total_revenue = sum(revenue)) %>% arrange(desc(total_revenue)) %>% ungroup()

df <- left_join(df,df_revenue)

df %>% filter(year_created == 1996) %>% mutate(franchise = fct_reorder(franchise, total_revenue)) %>%
  ggplot(aes(franchise, revenue, fill=revenue_category))+
  geom_col()+
  scale_fill_viridis_d(option=""E"")+
  coord_flip()+
  labs(title=""Franchise Revenue in 1996"", y=""Revenue (in billions)"")+
  theme(axis.title.y = element_blank())

df %>% filter(total_revenue > 50) %>% mutate(franchise = fct_reorder(franchise, total_revenue)) %>%
  ggplot(aes(franchise, revenue, fill=revenue_category))+
  geom_col()+
  scale_fill_viridis_d(option=""E"")+
  coord_flip()+
  labs(title=""Top Franchises' Revenue"", y=""Revenue (in billions)"")+
  theme(axis.title.y = element_blank())

df_revenue <- df %>% group_by(original_media) %>% summarize(media_revenue = sum(revenue)) %>% arrange(desc(media_revenue)) %>% ungroup()

df <- left_join(df,df_revenue)

df %>% mutate(original_media = fct_reorder(original_media, media_revenue)) %>%
  ggplot(aes(original_media, revenue, fill=revenue_category))+
  geom_col()+
  scale_fill_viridis_d(option=""E"")+
  coord_flip()+
  labs(title=""Revenue by Original Media Type"", x=""Original Media"", y=""Revenue (in billions)"")

df_revenue <- df %>% group_by(revenue_category) %>% summarize(category_revenue = sum(revenue)) %>% arrange(desc(category_revenue)) %>% ungroup()

df <- left_join(df,df_revenue)

df %>% mutate(revenue_category = fct_reorder(revenue_category, category_revenue)) %>%
  ggplot(aes(revenue_category, revenue, fill=original_media))+
  geom_col()+
  scale_fill_viridis_d(option=""E"")+
  coord_flip()+
  labs(title=""Revenue by Category"", x=""Category"", y=""Revenue (in billions)"")
```

# Final Visualization

Image found at http://www.greeklibrary.org/wp-content/uploads/2019/05/books.jpg

```{r viz, out.width=""100%""}
img <- readPNG(""books.png"")

df %>% filter(original_media == ""Novel"") %>% mutate(franchise = fct_reorder(franchise, total_revenue)) %>%
  ggplot(aes(franchise, revenue, fill=revenue_category))+
  background_image(img)+
  geom_col(color=""gray"", size=0.2)+
  scale_fill_brewer(palette=""Blues"")+
  scale_y_continuous(expand = c(0.01,0))+
  coord_flip()+
  labs(title=""Franchised Novels' Revenue by Category"", y=""Revenue (in billions)"", fill=""Category"")+
  theme(plot.title = element_text(hjust=0.5, face=""bold""),
        text=element_text(family=""Candara"", size=13),
        plot.background = element_blank(),
        panel.background = element_blank(),
        axis.title.y = element_blank(),
        axis.text = element_text(face=""bold""),
        legend.background = element_blank(),
        legend.text = element_text(size=8),
        legend.title = element_text(size=10))

ggsave(""media-franchises.png"")
```

","2019-27"
"970",915,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/Womens_World_Cup.Rmd","catrwilliams","rprojects","tidytuesday/Womens_World_Cup.Rmd","---
title: ""Women's World Cup""
author: ""Catherine Williams""
date: ""`r format(Sys.time(), '%B %d, %Y')`""
output: 
  html_fragment:
    number_sections: yes
    toc: yes
    toc_depth: 2
---

# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data comes from both [data.world](https://data.world/sportsvizsunday/womens-world-cup-data) and [Wikipedia](https://en.wikipedia.org/wiki/FIFA_Women%27s_World_Cup). The data includes information about each country such as total score, year, and whether they won, lost, or tied. There is also information about individual squads such as player name, age, position played, number of games played, and number of goals scored.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
setwd(""~/../Google Drive/Data Analysis/Tidy Tuesday/07-09-19 - Womens World Cup"")
```

# Setup

## Load Libraries

```{r library}
if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(""data.table"",""tidyverse"",""visdat"")

theme_set(theme_classic())
```

## Import Data

```{r import}
df_wwc_outcomes <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
df_squads <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
df_codes <- fread(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

df_wwc_outcomes <- left_join(df_wwc_outcomes, df_codes, by = ""team"")
```

# Exploratory Data Analysis

- There are 3 different data frames.

  - df_codes has 212 observations and 2 variables. This is just to get full country names in df_wwc_outcomes
  - df_squads has 552 observations and 9 variables.
  - df_wwc_outcomes has 568 observations and 7 variables.

## View Data

```{r view}
#df_squads
glimpse(df_squads)
head(df_squads)
summary(df_squads)

sapply(df_squads, function(x) n_distinct(x))

#df_wwc_outcomes
glimpse(df_wwc_outcomes)
head(df_wwc_outcomes)
summary(df_wwc_outcomes)

sapply(df_wwc_outcomes, function(x) n_distinct(x))
```

## Missing Values

Only df_squads has missing values- with caps and goals

```{r missing}
#Visualize missing values
vis_miss(df_squads, sort_miss=TRUE)
vis_miss(df_wwc_outcomes, sort_miss=TRUE)

#see count of missing values
na_values <- function(df){
  na <- colSums(is.na(df)) %>% sort(decreasing=TRUE)
  na[na>0]
}

na_values(df_squads)
```

## Data Wrangling

- For missing caps values, a 1 was supplied since it is assumed that player was present in the recent World Cup games.
- For missing goals values, 0 was supplied since it is assumed that if any goals were scored, they would have been recorded.

```{r wrangle}
df_squads <- df_squads %>% mutate(caps = replace_na(caps, 1),
                                  goals = replace_na(goals, 0))

df_wwc_outcomes <- df_wwc_outcomes %>% mutate(country = str_replace(country, ""Ivory Coast.*"", ""Ivory Coast""))

# see total number of games by country
df_games <- df_wwc_outcomes %>% group_by(country) %>% summarize(games = n())

# see total number of wins and losses by country
df_wins <- df_wwc_outcomes %>% filter(win_status == ""Won"") %>% group_by(country) %>% summarize(wins = n())
df_loss <- df_wwc_outcomes %>% filter(win_status == ""Lost"") %>% group_by(country) %>% summarize(loss = n())

# get percentage of games won
df_games_won <- inner_join(df_games, df_wins) %>% mutate(percent_won = (wins/games)*100)

# get net wins/losses by country
df_games <- left_join(df_games, df_wins) %>% mutate(wins = replace_na(wins, 0))
df_games <- left_join(df_games, df_loss) %>% mutate(loss = replace_na(loss, 0),
                                                    net = wins-loss)

# capitalize country to be more consistent with FIFA France 2019 theme
df_games <- df_games %>% mutate(country = str_to_upper(country))
```

## Visualizations

```{r viz, out.width=""100%""}
#Win status per country
df_wwc_outcomes %>% ggplot(aes(country))+
  geom_bar()+
  facet_wrap(~win_status)+
  coord_flip()+
  labs(title=""Game Status Per Country"", y=""number of games"")

#Win percentage per country
df_games_won %>% mutate(country = fct_reorder(country,percent_won)) %>% ggplot(aes(country, percent_won))+
  geom_col()+
  coord_flip()+
  labs(title=""Percentage of Games Won Per Country"", y=""percent"")

#ages of players
mean <- mean(df_squads$age)
median <- median(df_squads$age)

h <- hist(df_squads$age, breaks = ""FD"", plot = FALSE) #histogram with Freedman-Diaconis rule for binwidth

df_squads %>% ggplot(aes(age))+
  geom_histogram(aes(y = ..density..), breaks = h$breaks, alpha = 0.5, col = ""white"")+
  geom_vline(xintercept=mean, color=""red"", size=2)+
  geom_vline(xintercept=median, color=""blue"", size=1.5)+
  labs(title=""Distribution of Players' Ages"", subtitle=""mean: red, median: blue"")
```

# Final Visualization
Branding information was found here:
- [Colors](https://www.schemecolor.com/2019-fifa-womens-world-cup-logo-colors.php)
- [Font](http://freefootballfont.blogspot.com/2019/05/fifa-womens-world-cup-2019-france-font.html)

``` {r final}
# load custom fonts
windowsFonts(Elegance = windowsFont(""Elegance""))
windowsFonts(OpenSans = windowsFont(""Open Sans""))

df_games %>% mutate(country = fct_reorder(country,net)) %>% 
  ggplot(aes(country, net, fill=net < 0))+
    geom_col(width=0.95, color=""white"", size=0.3)+
    coord_flip()+
    scale_fill_manual(name = ""net < 0"", values = setNames(c(""#D6000A"",""#F08C01""), c(T,F)))+
    scale_y_continuous(expand=c(0,0), limits=c(-37,37), breaks=c(-30,-20,-10,0,10,20,30))+
    labs(title=""Women's World Cup - Net Wins Per Country"", subtitle=""From 1991 - 2019"", y=""NET WINS / LOSSES"", fill=""Net Game Status"")+
    theme(plot.background = element_rect(fill=""#23207C""),
          panel.background = element_rect(fill=""#23207C""),
          legend.position=""none"",
          axis.line = element_line(color=""white""),
          axis.text = element_text(color=""white"", family=""OpenSans""),
          axis.text.y = element_text(size=7.5),
          axis.ticks = element_line(color=""white""),
          axis.title = element_text(family=""OpenSans"", face=""bold"", color=""white""),
          plot.title = element_text(hjust=0.5, family=""Elegance"", face=""bold"", size=16, color=""#00B5ED""),
          plot.subtitle = element_text(hjust=0.5, family=""Elegance"", face=""bold"", size=13, color=""#FDDB00""),
          axis.title.y = element_blank(),
          axis.title.x = element_text(size=8))

ggsave(""womens-world-cup.png"")
```
","2019-28"
"971",916,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/R4DS_Community_Stats.Rmd","catrwilliams","rprojects","tidytuesday/R4DS_Community_Stats.Rmd","---
title: ""R4DS Community Stats""
author: ""Catherine Williams""
date: ""`r format(Sys.time(), '%B %d, %Y')`""
output: 
  html_fragment:
    number_sections: yes
    toc: yes
    toc_depth: 2
---

# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data came from [R4DS](https://docs.google.com/presentation/d/1jfo_CvTmLf-PtKq2uS5-biklXJRe5hVnhzUjtWTQI3Y/edit#slide=id.gc6f919934_0_0). The data includes the date, information about the number of members, number of messages, and the breakdown by direct messages, public, private, or shared channels.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)

directory <- ""07-16-19 - R4DS Community Stats""

if(!getwd() == paste0(""C:/Users/Cat/Google Drive/Data Analysis/Tidy Tuesday/"",directory)) {
  setwd(paste(directory))
  }
```

# Setup

## Load Libraries

```{r library}
if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(""tidyverse"",""visdat"",""grid"",""gridExtra"")

theme_set(theme_minimal())
```

## Import Data

```{r import}
df <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")
```

# Exploratory Data Analysis

- There are 678 observations and 21 variables.
- name, guests, and messages_in_shared_channels only have one unique value in the column. 
- total_membership and full_members are duplicate columns.
- entries prior to 2017-09-01 only have 1 member. This is likely when R4DS was just getting started.

## View Data

```{r view}
glimpse(df)
head(df)
summary(df)
sapply(df, function(x) n_distinct(x)) %>% sort()
```

## Missing Values

There are no missing values in the data set.

```{r missing}
#Visualize missing values
vis_miss(df, sort_miss=TRUE)
```

# Data Wrangling

Remove/replace missing values and drop unnecessary columns

```{r wrangle}
# remove columns with only 1 unique value
df <- df[, sapply(df, function(x) n_distinct(x)) > 1] %>% select(-full_members)
df <- df %>% filter(date >= ""2017-09-01"")
```

# Visualizations

- When R4DS launched, initial users were very active at first and then usage gradually declined.
- Numbers dramatically increased just before the start of 2018.
- What happened on 2018-06-19? Total messages posted dropped. Did the site go down?

```{r viz, out.width=""100%""}
# active vs total membership
df %>% ggplot(aes(x=date))+
  geom_area(aes(y=total_membership, fill=""Total Membership""))+
  geom_area(aes(y=weekly_active_members, fill=""Active Members""))+
  scale_fill_manual(values = c(""steelblue1"",""steelblue4"")) +
  labs(title=""Active Members vs Total Membership"", fill="""")

# total members posting messages
df %>% ggplot(aes(x=date))+
  geom_line(aes(y=weekly_members_posting_messages), color=""red"")+
  labs(title=""Number of Members Posting Messages"")

# messages posted
df %>% ggplot(aes(x=date))+
  geom_line(aes(y=messages_posted), color=""purple4"", size=1.2)+
  labs(title=""Total Messages Posted"")

## FINAL VISUALIZATION
# active vs. total membership
p1 <- df %>% ggplot(aes(x=date))+
  geom_area(aes(y=total_membership), fill=""steelblue4"")+
  geom_area(aes(y=weekly_active_members), fill=""steelblue1"")+
  labs(x=""Date"", y=""Total Number"")+
  theme(axis.title = element_text(size=9))

# messages posted vs. membership
p2 <- df %>% ggplot(aes(x=date))+
  geom_area(aes(y=total_membership, fill=""Total Membership""))+
  geom_area(aes(y=weekly_active_members, fill=""Active Members""))+
  geom_line(aes(y=messages_posted, color=""Messages Posted""), size=1.2)+
  scale_fill_manual(values = c(""steelblue1"",""steelblue4"")) +
  scale_color_manual(values = ""purple3"") +
  labs(x=""Date"", y=""Total Number"")+
  theme(legend.position=""bottom"",
        legend.title=element_blank(),
        legend.spacing.x = unit(0.4, 'cm'),
        axis.title = element_text(size=9))+
  guides(fill = guide_legend(order=1),
         color = guide_legend(order=2))

#https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs
#function to create a common legend for two plots
g_legend<-function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == ""guide-box"")
  legend <- tmp$grobs[[leg]]
  return(legend)}

mylegend<-g_legend(p2)

tg <- grobTree(textGrob(""Membership Status vs. Messages Posted"", 
                        y=1, 
                        vjust=1, 
                        gp=gpar(fontface=""bold"", fontsize = 16)),
               textGrob(""Messages posted are rapidly increasing, despite active members staying fairly constant"", 
                        y=0, 
                        vjust=0, 
                        gp = gpar(fontsize=11, col=""grey20"")),
               cl=""titlegrob"")

heightDetails.titlegrob <- function(x) do.call(sum,lapply(x$children, grobHeight))

#create final plot
p3 <- grid.arrange(arrangeGrob(p1 + theme(legend.position=""none""),
                         p2 + theme(legend.position=""none""),
                         nrow=1),
             mylegend, 
             nrow=2, 
             heights=c(10, 1),
             top = tg)

ggsave(""R4DS-community-stats.png"", p3)
```","2019-29"
"972",918,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/Ramen_Ratings.Rmd","catrwilliams","rprojects","tidytuesday/Ramen_Ratings.Rmd","---
title: ""Ramen Ratings""
author: ""Catherine Williams""
date: ""June 8, 2019""
output:
  html_document:
    hightlight: tango
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 2
    toc_float: yes
---
# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data came from [The Ramen Rater](https://www.theramenrater.com/resources-2/the-list/). The data includes ratings for different ramen brands, varieties, and style by country.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup

## Load Libraries

```{r library, message=FALSE, results=FALSE}
#function to check if packages are installed, if not then install them, and load all packages
libraries <- function(packages){
  for(package in packages){
    #checks if package is installed
    if(!require(package, character.only = TRUE)){
      #If package does not exist, then it will install
      install.packages(package, dependencies = TRUE)
      #Loads package
      library(package, character.only = TRUE)
    }
  }
}

packages <- c(""tidyverse"",""naniar"",""rvest"",""textstem"",""modeest"",""countrycode"",""ggridges"",""viridis"")

libraries(packages)

theme_set(theme_classic()) #applies classic theme to all charts
```

## Import Data

```{r import, message=FALSE}
df <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")
```

# Data Wrangling

- There are 3180 observations and 6 variables.
- 1 review_number is missing while another must be duplicated, as there is 1 NA value and 3178 unique values in that column. 
- stars has 14 NA values.
- style has 2 NA values.

## View Data

```{r view}
glimpse(df)
head(df)
summary(df)
sapply(df, function(x) n_distinct(x)) %>% sort()
```

## Missing Values

The visualization shows the same thing that was aleady determined before from the initial analysis. It is good to have a visual check though.

```{r missing}
#Visualize missing values
gg_miss_var(df) + labs(title=""Missing Values"")

#see count of NA values
df %>% is.na() %>% colSums() %>% sort(decreasing=TRUE)

#view only rows with NAs
df <- df %>% rownames_to_column()  #add row number to make it easier to locate observations
df %>% filter_all(any_vars(.==""NA""|is.na(.)))

#add in missing value for review_number
df[189:191,]
df[190,2] <- 2991

#find missing values for style and stars
df <- df %>% group_by(country, brand)%>% mutate(style = replace_na(style, mfv1(style, na.rm=T)),
                                                stars = replace_na(stars, mean(stars, na.rm=T))) %>% ungroup()

#see count of NA values again
df %>% is.na() %>% colSums() %>% sort(decreasing=TRUE)

#there are still some missing values, so we'll try again with less grouping
#find missing values for stars
df <- df %>% group_by(country)%>% mutate(stars = replace_na(stars, mean(stars, na.rm=T))) %>% ungroup()
```

## Change Data Types

```{r type}
df <- df %>% mutate_if(is.character,as.factor)
```

## Data Cleaning
### Country

This uses a country list to see if country names match up with known country names. If not, they are assumed to have typos or be incorrectly labeled (such as using city names).

Country data obtained from [https://data.humdata.org/dataset/countries-and-territories-beta]

```{r country, warning=FALSE, message=FALSE}
#import data frame with list of countries
country <- read_csv(""https://docs.google.com/spreadsheets/d/1NjSI2LaS3SqbgYc0HdD8oIb7lofGtiHgoKKATCpwVdY/export?format=csv&gid=1088874596"", skip=1)
head(country)

#there appear to be 2 columns with slightly different names. gathering these into one column
country <- country %>% gather(column, name, c(`#country +name +i_en +alt +v_unterm`, `#country +name +preferred`)) %>% select(name) %>% distinct()

#sort out country values that are NOT in the country name to correct them
country_fix <- df[!df$country %in% country$name,] %>% select(country) %>% distinct()
country_fix

#change values to appropriate names
df <- df %>% mutate(country = as.character(country),
                    country = (case_when(country %in% ""USA"" ~ ""United States"",
                                        country %in% ""Dubai"" ~ ""United Arab Emirates"",
                                        country %in% ""Holland"" ~ ""Netherlands"",
                                        country %in% ""Sarawak"" ~ ""Malaysia"",
                                        country %in% ""UK"" ~ ""United Kingdom"",
                                        country %in% ""Phlippines"" ~ ""Philippines"",
                                        TRUE ~ country)),
                    country = as.factor(country)) 
```

### Brand

```{r brand}
df <- df %>% mutate(brand = str_replace_all(brand, ""[:punct:]+"", "" ""),
                    brand = str_replace(brand, "" s"", ""'s""),
                    brand = str_to_title(brand),
                    brand = str_squish(brand),
                    brand = stem_words(brand) %>% as.factor())
```

### Variety

```{r variety}
df <- df %>% mutate(variety = str_replace_all(variety, ""[:punct:]+"", "" ""),
                    variety = str_replace(variety, "" s"", ""'s""),
                    variety = str_to_title(variety),
                    variety = str_squish(variety),
                    variety = stem_words(variety) %>% as.factor())
```

### Style

```{r style}
df %>% count(style, sort=T)
df <- df %>% group_by(style) %>% filter(n()>4) %>% ungroup()
```

## Feature Engineering

There are a lot of countries that will be hard to visualize. A region column will be added.

```{r feature}
# change countries into regions
df$region <- df$country %>% countrycode(origin=""country.name"",destination=""region"") %>% as.factor()
df <- df %>% group_by(region) %>% filter(n()>10) %>% ungroup()

count(df, region, sort=TRUE)

# change countries into continents
df$continent <- df$country %>% countrycode(origin=""country.name"",destination=""continent"") %>% as.factor()

count(df, continent, sort=TRUE)
```

# Exploratory Data Analysis
## Country Ratings

```{r country mean, out.width=""75%""}
df_country <- df %>% group_by(country) %>% summarize(stars=mean(stars)) %>% ungroup()

df_country %>% mutate(country = fct_reorder(country, stars)) %>% 
  ggplot(aes(country, stars))+
  geom_bar(stat=""identity"")+
  coord_flip()
```

## Region Ratings

```{r region mean, out.width=""75%""}
df_region <- df %>% group_by(region) %>% summarize(stars=mean(stars)) %>% ungroup()

df_region %>% mutate(region = fct_reorder(region, stars)) %>%
  ggplot(aes(region, stars))+
  geom_bar(stat=""identity"")+
  coord_flip()
```

## Continent Ratings

```{r continent mean, out.width=""75%""}
df_continent <- df %>% group_by(continent) %>% summarize(stars=mean(stars)) %>% ungroup()

df_continent %>% mutate(continent = fct_reorder(continent, stars)) %>%
  ggplot(aes(continent, stars))+
  geom_bar(stat=""identity"")+
  coord_flip()
```

## Style Ratings

```{r style mean, out.width=""75%""}
df_style <- df %>% group_by(style) %>% summarize(stars=mean(stars)) %>% ungroup()

df_style %>% mutate(style = fct_reorder(style, stars)) %>%
  ggplot(aes(style, stars))+
  geom_bar(stat=""identity"")+
  coord_flip()
```

# Final Visualization

```{r final, message=FALSE}
df %>% mutate(region = fct_reorder(region, stars)) %>% 
  ggplot(aes(stars, region, fill = region)) +
  geom_density_ridges() +
  scale_fill_viridis(option = ""D"", discrete = TRUE) +
  theme(legend.position = ""none"") +
  scale_x_continuous(breaks=0:5) +
  labs(title=""Ramen Ratings by Region"", x=""Rating"", y=""Region"")
```

","2019-23"
"973",919,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/Video_Games.Rmd","catrwilliams","rprojects","tidytuesday/Video_Games.Rmd","---
title: ""Video Games""
author: ""Catherine Williams""
date: ""`r format(Sys.time(), '%B %d, %Y')`""
output: 
  html_fragment:
    number_sections: yes
    toc: yes
    toc_depth: 2
---

# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data came from [Steam Spy](https://cruiseofdimensionality.home.blog/2019/07/24/pc-video-games-we-still-play/). The data includes time played, ownership, release date, publishing information, and for some a metascore.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)

directory <- ""07-31-19 - Video Games""

if(!getwd() == paste0(""C:/Users/Cat/Google Drive/Data Analysis/Tidy Tuesday/"",directory)) {
  setwd(paste0(""C:/Users/Cat/Google Drive/Data Analysis/Tidy Tuesday/"",directory))
  }
```

# Setup

## Load Libraries

```{r library}
if (!require(""pacman"")) install.packages(""pacman"")
pacman::p_load(""tidyverse"",""naniar"",""zoo"",""textclean"",""lubridate"",""grid"",""gridExtra"")

theme_set(theme_minimal())
```

## Import Data

```{r import}
df <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")
```

# Data Wrangling & Analysis

- There are 26688 observations and 10 variables.

## View Data

```{r view}
glimpse(df)
head(df)
summary(df)
sapply(df, function(x) n_distinct(x)) %>% sort()
```

## Missing Values

View missing values in more detail.

```{r missing}
#Visualize missing values
gg_miss_var(df) + labs(title=""Missing Values"")

#see count of missing values
na_values <- function(df){
  na <- colSums(is.na(df)) %>% sort(decreasing=TRUE)
  na[na>0]
}

na_values(df)
```

## Data Wrangling

Remove/replace missing values and drop unnecessary columns

```{r wrangle}
#group by most specific attributes to less specific to get the mean for missing price
groups <- c(""game"",""publisher"",""developer"")

for(group in groups){
  df <- df %>% group_by(get(group)) %>% mutate(price = na.aggregate(price)) %>% ungroup()
}

df$average_playtime[(is.na(df$average_playtime))] <- 0

#check missing values again
na_values(df)

#for the remaining missing prices, use the mean of the entire dataset
df <- df %>% mutate(price = na.aggregate(price)) %>% select(-11,-metascore)

na_values(df)

#check for string abnormalities in game
check_text(df$game)

#fix strings and other data anomalies
df <- df %>% mutate(game = str_replace_all(game, ""[^\x20-\x7E]"", """"), #removes unicode characters
                    game = replace_non_ascii(game), #did not work for everything. line above is better
                    game = replace_emoticon(game),
                    game = replace_date(game),
                    game = replace_hash(game),
                    game = replace_kern(game),
                    game = str_trim(game),
                    game = str_squish(game),
                    game = str_to_title(game),
                    game = str_replace_all(game, ""\\d/\\d"", """"),
                    game = str_replace(game, ""^[:punct:]+"", """"),
                    game = str_replace(game, ""\\|.*"", """"),
                    game = str_replace(game, ""(?<=\\w):(?=\\w)"", "": ""),
                    game = str_replace(game, ""\\s-|-\\s"", "": ""),
                    game = paste0(game, "": ""), #add : to end to make it easy to extract into a group
                    game = str_replace(game, ""[:punct:]:$"", "":""),
                    game_group = str_extract(game,""([^:]+(?=[:punct:]+\\s))""),
                    game_group = str_trunc(game_group,25),
                    game = str_replace(game, "": $"", """"), #clean it up: remove the trailing :
                    publisher = str_replace_all(publisher, ""[:punct:]+"", """"),
                    publisher = str_replace_all(publisher, ""[^\x20-\x7E]"", """"),
                    publisher = str_to_title(publisher),
                    owners = str_replace_all(owners, "","", """"),
                    owners_lower = str_extract_all(owners, ""\\d+(?=\\s\\.\\.\\s)"") %>% as.integer(),
                    owners_upper = str_extract_all(owners, ""(?<=\\s\\.\\.\\s)\\d+"") %>% as.integer(),
                    release_date = as.Date(release_date, ""%b %d, %Y""),
                    average_playtime_group = case_when(average_playtime <= max(average_playtime)*0.2 ~ ""Very Low"",
                                                       average_playtime > max(average_playtime)*0.2 & 
                                                         average_playtime <= max(average_playtime)*0.4 ~ ""Low"",
                                                       average_playtime > max(average_playtime)*0.4 & 
                                                         average_playtime <= max(average_playtime)*0.6 ~ ""Medium"",
                                                       average_playtime > max(average_playtime)*0.6 & 
                                                         average_playtime <= max(average_playtime)*0.8 ~ ""High"",
                                                       average_playtime > max(average_playtime)*0.8 ~ ""Very High""),
                    average_playtime_group = fct_relevel(average_playtime_group,c(""Very Low"",""Low"",""Medium"",""High"",""Very High""))) 

#remove rows that do not have any alpha characters
df <- keep_row(df, ""game"",""\\w+"")

#change strings back to factors to make them easier to work with
df <- df %>% mutate_if(is.character, as.factor)

```

# Visualizations

```{r viz, out.width=""100%""}
df_price <- df %>% group_by(game_group) %>% summarize(total_revenue=sum(price)) %>% ungroup() %>%
  mutate(game_group = fct_reorder(game_group, total_revenue)) %>% arrange(total_revenue) %>% tail(20)

#practice with lollipop chart
df_price %>% ggplot(aes(game_group,total_revenue))+
  geom_point(size=1.75, color=""gray10"")+
  geom_segment(aes(x=game_group, xend=game_group, y=0, yend=total_revenue), size=1.25, color=""deepskyblue4"")+
  scale_color_gradient()+
  coord_flip()+
  labs(title=""Highest Grossing Video Games"", caption=""Data: Steam Spy | Graphics: Cat Williams @catrwilliams"",
       x = ""Game"", y = ""Total Revenue"")+
  theme(plot.title = element_text(size=14, hjust=0.5, face=""bold""),
        plot.caption = element_text(size=6))

#################

#determine if there is a relationship between price and average playtime
outliers <- boxplot(df$price, plot=FALSE)$out
price_lim <- summary(outliers)[[""3rd Qu.""]]

outliers <- boxplot(df$average_playtime, plot=FALSE)$out
playtime_lim <- summary(outliers)[[""3rd Qu.""]]

p1 <- df %>% ggplot(aes(price, average_playtime))+
  geom_point(alpha=0.3,color=""deepskyblue4"")+
  labs(title=""Summary for all data"",x=""Game Price"",y=""Average Playtime"")+
  theme(text= element_text(color=""gray10""),
        plot.title = element_text(size=13,hjust=0.5),
        axis.title = element_text(size=10))

p2 <- df %>% ggplot(aes(price, average_playtime))+
  geom_point(alpha=0.3,color=""deepskyblue4"")+
  xlim(0,price_lim)+
  ylim(0,playtime_lim)+
  labs(title=""Zoomed in to remove outliers"",x=""Game Price"",y=""Average Playtime"")+
  theme(text= element_text(color=""gray10""),
        plot.title = element_text(size=13,hjust=0.5),
        axis.title = element_text(size=10))

tg <- grobTree(textGrob(""Price vs. Average Time Played: No Distinct Relationship"", 
                        y=1, 
                        vjust=1, 
                        gp=gpar(fontface=""bold"", fontsize = 16, color=""deepskyblue4"")),
               cl=""titlegrob"")

heightDetails.titlegrob <- function(x) do.call(sum,lapply(x$children, grobHeight))

#create final plot
p3 <- grid.arrange(arrangeGrob(p1,p2,nrow=1),top = tg)

#################

df_publisher <- df %>% group_by(publisher) %>% summarize(total_price=sum(price)) %>% ungroup() %>% 
  filter(publisher != """") %>% mutate(publisher = fct_reorder(publisher, total_price)) %>% 
  arrange(total_price) %>% tail(20)

df_publisher %>% ggplot(aes(publisher, total_price))+
  #geom_col(fill=""deepskyblue4"")+
  geom_point(size=1.75, color=""gray10"")+
  geom_segment(aes(x=publisher, xend=publisher, y=0, yend=total_price), size=1.25, color=""deepskyblue4"")+
  coord_flip()+
  labs(title=""Top Video Game Publishers by Total Revenue"", x=""Revenue"", y=""Publisher"")+
  theme(text= element_text(color=""gray10""),
        plot.title = element_text(size=14, hjust=0.5, face=""bold""),
        axis.title = element_text(size=10))
  
#################

#does having more players encourage more playtime?
df %>% ggplot()+
  geom_segment(aes(x=owners_lower, xend=owners_upper, y=average_playtime_group, yend=average_playtime_group), 
               size=1.25, color=""deepskyblue4"")+
  scale_x_continuous(labels=c(""0"",""50"",""100"",""150"",""200""))+
  labs(title=""Video Games: Does having more players encourage more playtime?"", 
       subtitle=""It appears that more players correlates with lower average playtime"",
       x=""Number of Players (in millions)"", y=""Time Played"", 
       caption=""Data: Steam Spy | Graphics: Cat Williams @catrwilliams"")+
  theme(plot.title=element_text(hjust=0.5, color=""deepskyblue4"", face=""bold""),
        text = element_text(color=""gray10""),
        plot.subtitle=element_text(hjust=0.5, face=""bold""),
        plot.caption = element_text(size=6),
        axis.title = element_text(size=10))

ggsave(""video-games.png"")
```

# Conclusions

I do not have specific knowledge of most video games, however, I have heard the names of many of the highest grossing video games in passing. They also appear to be of multiple genres (ie. war, mystery, trivia) which comes as a surprise to me. I would not have placed a trivia game in the top 20 highest grossing video games.

Another surprise to me is that there is no obvious relationship between average time played and the price of the game. I would have expected more expensive games to be played more as it is a larger investment and logically higher prices tend to equate to better things. What these charts do show is that lower priced games are slightly more popular, due to the concentration of the data points closer to 0.

As for top video game publishers, it appears that Magix Software is doing much better than the other publishers. Big Fish Games, Ubisoft, Koei Tecmo Games, and Slitherine are in a slightly higher bracket than the other top performers. After that, revenue numbers seem to decrease gradually. I also wonder if the top publishers correlate to the highest grossing games. Further analysis would need to be done to determine this.

Lastly, having more overall players for a particular game does not encourage more playtime. At first thought it would seem that more popular games would have more playtime. Based on the data, however, one may infer that because there are more people involved (perhaps only occasional players) with more popular games, it skews the average rankings.

","2019-31"
"974",920,"https://github.com/catrwilliams/rprojects/blob/master/tidytuesday/Meteorites.Rmd","catrwilliams","rprojects","tidytuesday/Meteorites.Rmd","---
title: ""Meteorites""
author: ""Catherine Williams""
date: ""June 12, 2019""
output:
  html_document:
    hightlight: tango
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_depth: 2
    toc_float: yes
---
# Project Description

Tidy Tuesday has a weekly data project aimed at the R ecosystem. An emphasis is placed on understanding how to summarize and arrange data to make meaningful charts with ggplot2, tidyr, dplyr, and other tools in the tidyverse ecosystem.

# Dataset
Data came from [NASA](https://data.nasa.gov/Space-Science/Meteorite-Landings/gh4g-9sfh/data). The data includes meteorite information such as the class, mass, and location when meteorites were found/fallen.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(""~/../Google Drive/Data Analysis/Tidy Tuesday/06-11-19 - Meteorites"")
```

# Setup

## Load Libraries

```{r library, message=FALSE, results=FALSE}
#function to check if packages are installed, if not then install them, and load all packages
libraries <- function(packages){
  for(package in packages){
    #checks if package is installed
    if(!require(package, character.only = TRUE)){
      #If package does not exist, then it will install
      install.packages(package, dependencies = TRUE)
      #Loads package
      library(package, character.only = TRUE)
    }
  }
}

packages <- c(""tidyverse"",""readxl"",""visdat"",""modeest"",""maps"",""ggthemes"",""RColorBrewer"",""SDMTools"")

libraries(packages)

theme_set(theme_classic()) #applies classic theme to all charts
```

## Import Data

```{r import, message=FALSE}
df <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")
```

# Data Wrangling

- There are 45,716 observations and 10 variables.
- There are several NA values that will be looked at in more detail later.
- name and id are both unique identifiers
- geolocation is just the summary of both lat and long
- there a bunch of coordinates entered as 0 - these are basically NA

## View Data

```{r view}
glimpse(df)
head(df)
summary(df)
sapply(df, function(x) n_distinct(x)) %>% sort()
```

## Missing Values

View missing values in more detail and remove or fix them.

```{r missing}
#Visualize missing values
vis_miss(df[,colSums(is.na(df)|df==0) >0], sort_miss=TRUE)

#see count of missing values
na_values <- function(df){
  na <- colSums(is.na(df)|df==0) %>% sort(decreasing=TRUE)
  na[na>0]
}

na_values(df)

#remove NA coordinates
df <- df %>% drop_na(geolocation)

#remove missing coordinates
df <- subset(df, lat!=0 & long!=0)
```

## Feature Engineering

Meteorite classification data came from [The Meteorite Market](http://www.meteoritemarket.com/type.htm). The table includes merged cells so it came over a lot cleaner after copy/pasting into Excel and then unmerging all cells.

```{r feature, message=FALSE}
#import classification table to match class and determine category
df_class <- read_xlsx(""classifications.xlsx"", skip=3)
df_class <- df_class %>% select(category=Category,class=`Letter Designation`,comp=`Composition Type`)

#remove rows with NA in class
df_class <- df_class %>% drop_na(class)

#set category to the correct values and clean data to make the class column optimal for matching
df_class <- df_class %>% 
  mutate(category = case_when((row_number() <= which(df_class[,2] == ""R"")) ~ ""Chondrites"",
                             (row_number() >= which(df_class[,2] == ""HOW"") & 
                                row_number() <= which(df_class[,2] == ""WIN"")) ~ ""Achondrites"",
                             (row_number() >= which(df_class[,2] == ""H"") & 
                                row_number() <= which(df_class[,2] == ""D"")) ~ ""Irons (structural)"",
                             (row_number() >= which(df_class[,2] == ""IAB"") & 
                                row_number() <= which(df_class[,2] == ""Anom"")) ~ ""Irons (chemical)"",
                             (row_number() >= which(df_class[,2] == ""PAL"")) ~ ""Stony Irons"",
                              TRUE ~ category),
        comp = str_replace(comp,""([:graph:]+\\s+[:graph:]+)\\s.*"",""""),
        class = str_split(class, "",\\s|.\\s|-"")) %>% unnest(class)

#replace blank values with NAs
df_class$comp[df_class$comp == """"]<-NA

df_class <- df_class %>% mutate(comp = str_split(comp, ""\\s\\("")) %>% unnest(comp)
df_class <- df_class %>% mutate(comp = str_replace(comp, ""\\*|\\)"", """"),
                                comp = str_extract(comp, "".*[^s$]""))

#combine the comp and class column since the data uses both variations as its classification
df_class <- df_class %>% gather(column, class, comp:class) %>% select(-column) %>% distinct() %>% drop_na()

#make sure the original df has clean class columns for matching
df <- df %>% mutate(class = str_replace_all(class, ""[:punct:]+|~+"", "" ""))

#function to find if any string value in class matches in df_class 
find_cat <- function(x, patterns, replacements=patterns, fill=NA, ...){
  stopifnot(length(patterns) == length(replacements))

  ans = rep_len(as.character(fill), length(x))    
  empty = seq_along(x)

  for(i in seq_along(patterns)) {
      greps = grepl(patterns[[i]], x[empty], ...)
      ans[empty[greps]] = replacements[[i]]  
      empty = empty[!greps]
  }
  return(ans)
}

df$category <- find_cat(df$class, df_class$class, df_class$category, NA, ignore.case = TRUE)

#view the class values that still need to be worked on
df[!df$class %in% df_class$class & df$category %in% NA,] %>% select(class,category) %>% distinct()

#classify the remaining classes
#according to https://en.wikipedia.org/wiki/Ordinary_chondrite OC is a Chondrite
df <- df %>% mutate(category = case_when(str_detect(class, ""^C|LL|L|E|OC"") ~ ""Chondrites"",
                                        TRUE ~ category),
                    category = replace_na(category, mfv(category, na.rm=T))) #the remaining values cannot be classified. Using mode to give them a value
```

## Data Types

Convert characters to factors

```{r data}
#finally change the data types back to factors and remove duplicates that were made above
df <- df %>% mutate_if(is.character,as.factor)
```

# Visualizations

## World
```{r world, out.width=""100%""}
world <- map_data(""world"")

#practice using geom_polygon
ggplot(world, aes(x=long, y=lat, group=group))+
  geom_polygon(fill=""#f2e6d9"",color = ""white"")+
  geom_point(df, mapping=aes(group=category, color=category), alpha=0.5, size=0.5)+
  coord_map(xlim=c(-180,180))+
  theme_map()+
  scale_color_brewer(palette=""Set1"")+
  labs(title=""Meteorite Categories Across The World"", color=""Category"")+
  guides(color=guide_legend(override.aes=list(size=4)))+
  theme(plot.background=element_rect(fill=""#ccefff""),
        legend.position=c(0, 0.09),
        legend.background=element_rect(fill=""#ccefff""),
        legend.key=element_rect(fill=""#ccefff""),
        plot.title=element_text(size=14, hjust=0.5),
        legend.title.align=0.5,
        legend.title=element_text(face=""bold""))
```

## United States

### Prepare Data Frame
```{r usa data, message=FALSE, warning=FALSE}
state <- map_data(""state"")
usa <- map_data(""usa"")

#filter out points that do not belong in the usa
x=usa$long
y=usa$lat
long=df$long
lat=df$lat

#define the points and polygon
points <- cbind(long,lat)
polypoints <- cbind(x,y)

#plot the polygon and all points to be checked
plot(rbind(polypoints,points))
polygon(polypoints,col=""red"")

#check which points fall within the polygon
out <- pnt.in.poly(points,polypoints)
summary(out)

#identify points not in the polygon with an x
plot(rbind(polypoints,points))
polygon(polypoints,col='#99999990')
points(out[which(out$pip==0),1:2],pch=4,col=""red"")

#filter df for only the relevant points
df_usa <- bind_cols(df,out) %>% select(-long1,-lat1) %>% filter(pip==1)
```

### Visualization

```{r usa, message=FALSE, warning=FALSE, out.width=""100%""}
##practice using geom_map
ggplot() +
  geom_map(data=state, aes(x=long, y=lat, group=group, map_id=region), fill=""#f8f2ec"",color=""grey"", map=state)+
  geom_map(data=usa, map=usa, aes(long, lat, map_id=region), color=""black"", fill=NA, size=0.5)+
  geom_point(df_usa, mapping=aes(x=long, y=lat, group=category, color=category), alpha=0.8, size=0.9)+
  coord_map(""polyconic"", xlim=c(-124.7, -67.1), ylim = c(25.2, 49.4)) +
  theme_map()+
  labs(title=""Meteorite Categories Across The United States"", color=""Category"")+
  scale_color_brewer(palette=""Set1"")+
  guides(color=guide_legend(override.aes=list(size=4)))+
  theme(plot.background=element_rect(fill=""#e6f7ff""),
        legend.position=c(0.83, 0.02),
        legend.background=element_rect(fill=""#e6f7ff""),
        legend.key=element_rect(fill=""#e6f7ff""),
        plot.title=element_text(size=14, hjust=0.5),
        legend.title.align=0.5,
        legend.title=element_text(face=""bold""))
```
","2019-24"
"975",933,"https://github.com/symplyelah/Tidytuesday/blob/master/wwc.Rmd","symplyelah","Tidytuesday","wwc.Rmd","---
title: ""wwc""
author: ""Ifeoma Egbogah""
date: ""7/17/2019""
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(tidyverse)
library(circlize)
library(ggrepel)
library(broom)
library(countrycode)

wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

```


```{r}

theme_set(theme_light())


MF_age <- squads%>%
  group_by(pos)%>%
  filter(pos == ""MF"", age >= 35)

age_boxplot<- squads%>%
  ggplot(aes(fct_reorder(pos, age), age))+
  geom_boxplot()+
  expand_limits(y = 0)+
  geom_label_repel(data = MF_age, aes(label = player))+
  theme(plot.subtitle = element_text(size = 10,
                                 color = ""#939184"",
                                 margin = margin(b = 0.1,
                                                 t = -0.1,
                                                 l = 2,
                                                 unit = ""cm""),
                                 face = ""bold""),
      
        
        plot.caption = element_text(size = 7,
                                hjust = .5,
                                margin = margin(t = 0.2,
                                                b = 0,
                                                unit = ""cm""),
                                color = ""#939184""))+
  
  labs(x = ""Players Position"",
       y = ""Age of Players"",
       title = ""Age Distribution Of Players at the Women's World Cup"",
       subtitle = ""France 2019, Women's World Cup"",
       caption = ""Source: Data.World | Visualization: Ifeoma Egbogah"")
  

goals_wwc<- squads%>%
  ggplot(aes(caps, goals, colour = pos))+
  geom_point()+
  scale_colour_viridis_d(option = ""B"")+
  geom_smooth(method = lm)+
  facet_wrap(~pos)+
  theme(plot.subtitle = element_text(size = 10,
                                 color = ""#939184"",
                                 margin = margin(b = 0.1,
                                                 t = -0.1,
                                                 l = 2,
                                                 unit = ""cm""),
                                 face = ""bold""),
      
        
        plot.caption = element_text(size = 7,
                                hjust = .5,
                                margin = margin(t = 0.2,
                                                b = 0,
                                                unit = ""cm""),
                                color = ""#939184""))+
  
  labs(x = ""Caps"",
       y = ""Goals"",
       title = ""Relationship Between Goals and Caps"",
       subtitle = ""For ladies who featured in the 2019 FIFA women's world cup based on players positon on the field"",
       caption = ""Source: data.world | Visualization: Ifeoma Egbogah"")


model <- squads%>%
  lm(goals ~ pos + caps + age, data = .)

est <- model%>%
  tidy(conf.int = TRUE)%>%
  filter(term != ""(Intercept)"")%>%
  mutate(term = str_replace(term, ""posFW"", ""Forward""),
         term = str_replace(term, ""posMF"", ""Midfielder""),
         term = str_replace(term, ""posGK"", ""Goal Keeper/Goalie""),
         term = str_replace(term, ""caps"", ""Caps""),
         term = str_replace(term, ""age"", ""Age""),
         term = fct_reorder(term, estimate))%>%
  ggplot(aes(estimate, term))+
  geom_point(show.legend = FALSE)+
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), show.legend = FALSE)+
  geom_vline(xintercept = 0, col = ""red"")+
  theme(plot.subtitle = element_text(size = 10,
                                 color = ""#939184"",
                                 margin = margin(b = 0.1,
                                                 t = -0.1,
                                                 l = 2,
                                                 unit = ""cm""),
                                 face = ""bold""),
      
        
        plot.caption = element_text(size = 7,
                                hjust = .5,
                                margin = margin(t = 0.2,
                                                b = 0,
                                                unit = ""cm""),
                                color = ""#939184""))+
  
  labs(x = ""Coefficent Estimate"",
       y = ""Term"",
       title = ""Coefficent Estimated Effect On Goals"",
       subtitle = ""Based on players position, caps and age"",
       caption = ""Source: data.world | Visualization: Ifeoma Egbogah"")
  

age_boxplot
goals_wwc
est

ggsave(""C:/Users/Egbogah/Desktop/wwc_boxplot.png"", age_boxplot, width = 8, height = 8)
ggsave(""C:/Users/Egbogah/Desktop/goal_wwc.png"", goals_wwc, width = 8, height = 8)
ggsave(""C:/Users/Egbogah/Desktop/est.png"", est, width = 8, height = 8)
```


#Circlize plot of countries participating in the FIFA Women's World Cup 2019
```{r}

wwc_2019 <- wwc_outcomes%>%
  filter(year == ""2019"")

wwc_2019 <- wwc_2019%>%
  mutate(stage = case_when(round == ""Group"" & team == ""FRA"" ~ ""Group A"",
                          round == ""Group"" & team == ""KOR"" ~ ""Group A"",
                          round == ""Group"" & team == ""NGA"" ~ ""Group A"",
                          round == ""Group"" & team == ""NOR"" ~ ""Group A"",
                          round == ""Group"" & team == ""GER"" ~ ""Group B"",
                          round == ""Group"" & team == ""CHN"" ~ ""Group B"",
                          round == ""Group"" & team == ""ESP"" ~ ""Group B"",
                          round == ""Group"" &  team== ""RSA"" ~ ""Group B"",
                          round == ""Group"" &  team== ""ITA"" ~ ""Group C"",
                          round == ""Group"" &  team== ""AUS"" ~ ""Group C"",
                          round == ""Group"" &  team== ""BRA"" ~ ""Group C"",
                          round == ""Group"" &  team== ""JAM"" ~ ""Group C"",
                          round == ""Group"" &  team== ""ENG"" ~ ""Group D"",
                          round == ""Group"" &  team== ""JPN"" ~ ""Group D"",
                          round == ""Group"" &  team== ""ARG"" ~ ""Group D"",
                          round == ""Group"" &  team== ""SCO"" ~ ""Group D"",
                          round == ""Group"" &  team== ""CAN"" ~ ""Group E"",
                          round == ""Group"" &  team== ""CMR"" ~ ""Group E"",
                          round == ""Group"" &  team== ""NZL"" ~ ""Group E"",
                          round == ""Group"" &  team== ""NED"" ~ ""Group E"",
                          round == ""Group"" &  team== ""USA"" ~ ""Group F"",
                          round == ""Group"" &  team== ""SWE"" ~ ""Group F"",
                          round == ""Group"" &  team== ""THA"" ~ ""Group F"",
                          round == ""Group"" &  team== ""CHI"" ~ ""Group F""),
         stage = coalesce(stage, round))

group <- wwc_2019%>%
  filter(round == ""Group"")


circos.clear()
circos.par(start.degree = 30, gap.degree = 4)
circos.initialize(factors = group$stage, xlim = c(0, 10))

#First Group Stage track
circos.trackPlotRegion(factors= group$stage, ylim = c(0, 6), track.height = 0.2,
                       panel.fun = function(x, y){
                       circos.text(x = seq(2, 8, 2), 
                                   y = 1,
                                   labels = c("" "", "" "", "" "", "" ""),
                                   facing = ""clockwise"",
                                   niceFacing = TRUE,
                                   adj = 0.6,
                                   cex = 0.9
                                   )})

circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group A"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""FRA"", ""NOR"", ""NGA"", ""KOR""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.2,
                cex = 0.82))

circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group F"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""USA"", ""SWE"", ""CHI"", ""THA""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.2,
                cex = 0.82))

circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group B"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""GER"", ""ESP"", ""CHN"", ""RSA""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.2,
                cex = 0.82))

circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group C"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""ITA"", ""AUS"", ""BRA"", ""JAM""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.2,
                cex = 0.82))

circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group D"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""ENG"", ""JPN"", ""ARG"", ""SCO""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.2,
                cex = 0.82))


circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group E"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""NED"", ""CAN"", ""CMR"", ""NZL""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.2,
                cex = 0.82))




#Group of 16 track
circos.trackPlotRegion(factors= group$stage, ylim = c(0, 2),track.height = 0.2,
                       panel.fun = function(x, y){
                       circos.text(x = seq(2, 8, 2), 
                                   y = 1,
                                   labels = c("" "", "" "", "" ""),
                                   facing = ""clockwise"",
                                   niceFacing = TRUE,
                                   adj = 0.5,
                                   cex = 0.9
                                   )})


circos.update(track.index = 2, bg.border = ""black"",
              sector.index = ""Group A"",
              circos.text(x = seq(2, 6, 2), 
                          y = 1,
                labels = c(""FRA"", ""NOR"", ""NGA""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 2, bg.border = ""black"",
              sector.index = ""Group F"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""USA"", ""SWE""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 2, bg.border = ""black"",
              sector.index = ""Group B"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""GER"", ""ESP"", ""CHN""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 2, bg.border = ""black"",
              sector.index = ""Group C"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""ITA"", ""AUS"", ""BRA""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 2, bg.border = ""black"",
              sector.index = ""Group D"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""ENG"", ""JPN""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))


circos.update(track.index = 2, bg.border = ""black"",
              sector.index = ""Group E"",
              circos.text(x = seq(2, 8, 2), 
                          y = 1,
                labels = c(""NED"", ""CAN"", ""CMR""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))




#Quaterfinals track
circos.trackPlotRegion(factors= group$stage, ylim = c(0, 2), track.height = 0.2,
                       panel.fun = function(x, y){
                       circos.text(x = seq(2, 8, 2), 
                                   y = 1,
                                   labels = c("" "", "" "", "" ""),
                                   facing = ""clockwise"",
                                   niceFacing = TRUE,
                                   adj = 0.5,
                                   cex = 0.9
                                   )})


circos.update(track.index = 3, bg.border = ""black"",
              sector.index = ""Group A"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""FRA"", ""NOR""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 3, bg.border = ""black"",
              sector.index = ""Group F"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""USA"", ""SWE""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 3, bg.border = ""black"",
              sector.index = ""Group B"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""GER""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 3, bg.border = ""black"",
              sector.index = ""Group C"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""ITA""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))

circos.update(track.index = 3, bg.border = ""black"",
              sector.index = ""Group D"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""ENG""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))


circos.update(track.index = 3, bg.border = ""black"",
              sector.index = ""Group E"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""NED""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))


#Colour
#red
highlight.sector(group$stage[3],
                 border = NA, 
                 col = NA,
                 text = group$stage[3],
                 facing = ""bending.inside"",
                 niceFacing = TRUE,
                 text.vjust = ""20mm"",
                 cex = 1.03)

highlight.sector(group$stage[9],
                 border = NA,
                 col = NA,
                 text = group$stage[9],
                 facing = ""bending.inside"",
                 niceFacing = TRUE,
                 text.vjust = ""20mm"",
                 cex = 1.03)

highlight.sector(sector.index = c(group$stage[3], group$stage[9]), #peach
                 col = ""#FF000080"")


#white
highlight.sector(group$stage[1],
                 border = NA,
                 col = NA,
                 text = group$stage[1],
                 facing = ""bending.inside"",
                 niceFacing = TRUE,
                 text.vjust = ""20mm"",
                 cex = 1.03)



highlight.sector(group$stage[13],
                 border = NA, 
                 col = NA,
                 text = group$stage[13],
                 facing = ""bending.inside"",
                 niceFacing = TRUE,
                 text.vjust = ""20mm"",
                 cex = 1.03)


#blue
highlight.sector(group$stage[17],
                 col = NA,
                 text = group$stage[17],
                 facing = ""bending.inside"",
                 niceFacing = TRUE,
                 text.vjust = ""20mm"",
                 cex = 1.03)

highlight.sector(group$stage[21],
                 col = NA,
                 text = group$stage[21],
                 facing = ""bending.inside"",
                 niceFacing = TRUE,
                 text.vjust = ""20mm"",
                 cex = 1.03)

highlight.sector(sector.index= c(group$stage[17], group$stage[21]), 
                 col = ""#0000FF40"")


#Semifinals track
circos.clear()
par(new = TRUE)

factors = paste(""Group"", sep = "" "", LETTERS[4:6])
circos.par(canvas.xlim = c(-3, 3), canvas.ylim = c(-3, 3), gap.degree = 4)
circos.initialize(factors = factors, xlim = c(0, 10))
circos.track(ylim = c(0, 2), track.height = 0.49, panel.fun = function(x, y){
  circos.text(x = seq(0, 10, 2),
              y = 1,
              labels = c("" "", "" "", "" ""),
              facing = ""clockwise"",
              niceFacing = TRUE,
              adj = 0.5)
  
})


circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group F"",
              circos.text(x = seq(4, 8, 2), 
                          y = 1,
                labels = c(""USA"", ""SWE""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))


circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group D"",
              circos.text(x = seq(6, 10, 2), 
                          y = 1,
                labels = c(""ENG""),
                           facing = ""clockwise"", 
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))


circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group E"",
              circos.text(x = seq(6, 10, 2), 
                          y = 1,
                labels = c(""NED""),
                           facing = ""clockwise"",
                           niceFacing = TRUE,
                           adj = 0.5,
                cex = 0.82))



#Finals
circos.clear()
par(new = TRUE)
factors1 = paste(""Group"", sep = "" "", LETTERS[5:6])
circos.par(canvas.xlim = c(-6.4, 6.4), canvas.ylim = c(-6.4, 6.4), gap.degree = 4)
circos.initialize(factors = factors1, xlim = c(0, 2))
circos.track(ylim = c(0, 1), track.height = 0.5,
             panel.fun = function(x, y) {
               circos.text(x = c(0, 2),
                           y= 1,
                           labels = "" "",
                           facing = ""bending"",
                           niceFacing = TRUE,
                           adj = 0.5)
             })


circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group E"",
              circos.text(x = 1, 
                          y = 1,
                labels = c(""NED""),
                           facing = ""bending"",
                           niceFacing = TRUE,
                           adj = 1,
                cex = 0.82))


circos.update(track.index = 1, bg.border = ""black"",
              sector.index = ""Group F"",
              circos.text(x = 1, 
                          y = 1,
                labels = c(""USA""),
                           facing = ""bending"",
                           niceFacing = TRUE,
                           adj = 1,
                cex = 0.82))

#winner
text(0,0, ""USA"", cex = 0.82)
text(8.2, -6.8, cex= 0.6, ""Source: data.world | Visualization: Ifeoma Egbogah"")
title(""2019 FIFA Women's World Cup"")

```


#Number of games played, won, lost, and tied since featuring in the world cup
```{r}

wwc_continent <- wwc_outcomes%>%
  left_join(., codes)%>%
  mutate(continent = countrycode(country, ""country.name"", ""continent""))%>%
  mutate(continent2 = case_when(country == ""England"" ~ ""Europe"",
                               country == ""Scotland"" ~ ""Europe""),
         continent = coalesce(continent, continent2))%>%
  select(-continent2)

processed <- wwc_continent%>%
  arrange(team, year)%>%
  group_by(team)%>%
  mutate(rolling_play = row_number(),
         rolling_play_win = cumsum(win_status == ""Won""))%>%
  ungroup()


processed2 <- processed%>%
  group_by(team, win_status)%>%
  summarise(total_win = n())%>%
  ungroup()%>%
  group_by(team)%>%
  mutate(total = sum(total_win),
         pct = total_win/sum(total_win))

processed2<- processed2%>%
  left_join(., codes)%>%
  mutate(continent = countrycode(country, ""country.name"", ""continent""))%>%
  mutate(continent2 = case_when(country == ""England"" ~ ""Europe"",
                               country == ""Scotland"" ~ ""Europe""),
         continent = coalesce(continent, continent2))%>%
  select(-continent2)


pct_games<-processed2%>%
  ggplot(aes(team, pct))+
  geom_bar(stat = ""identity"", aes(fill = win_status))+
  coord_flip()+
  scale_y_continuous(labels = scales::percent_format())+
  scale_fill_viridis_d(option = ""E"")+
  facet_wrap(~continent, scales = ""free_y"")+
  theme(plot.subtitle = element_text(size = 10,
                                 color = ""#939184"",
                                 margin = margin(b = 0.1,
                                                 t = -0.1,
                                                 l = 2,
                                                 unit = ""cm""),
                                 face = ""bold""),
      
        plot.caption = element_text(size = 7,
                                hjust = .5,
                                margin = margin(t = 0.2,
                                                b = 0,
                                                unit = ""cm""),
                                color = ""#939184""))+
  
  labs(x = ""Teams"",
       y = ""Percentage of Games"",
       title = ""Percentage of Games Won, Lost or Tied Per Country"",
       subtitle = ""Since featuring in the Women's World Cup"",
       caption = ""Source: Data.World | Visualization: Ifeoma Egbogah"",
       fill = ""Game Status"")
  

pct_games

ggsave(""C:/Users/Egbogah/Desktop/pct_games.png"", pct_games, width = 8, height = 8)
```

","2019-28"
"976",934,"https://github.com/symplyelah/Tidytuesday","symplyelah","Tidytuesday","Nobel Prize.Rmd","---
title: ""NobelPrizeWinners""
author: ""Ifeoma Egbogah""
date: ""5/23/2019""
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tmap)
library(tmaptools)
library(tidyverse)

theme_set(theme_light())

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")

#Remove duplicates of Nobel Winners
nobel_winners <- nobel_winners%>%
  arrange(full_name, prize_year, category, motivation)%>%
  distinct(full_name, prize_year, category, motivation, .keep_all = TRUE)

```

#Laureates who have won the Nobel Prize More Than Once. ICRC have won it thrice.
(Marie Curie won her Nobel Prizes in the Physics and Chemistry Categories)
```{r}

#Laureates who have won more than once.
multiple<-nobel_winners%>%
  separate(prize_share, c(""number"", ""share""))%>%
 count(full_name, laureate_id, sort=TRUE)%>%
  head(6)%>%
  mutate(full_name = fct_reorder(full_name, n))%>%
  ggplot(aes(full_name, n))+
  geom_col(fill= ""hotpink2"")+
  coord_flip()+
  labs(title= ""Laureates who have won the Nobel Prize More Than Once"",
       subtitle = ""Marie Curie won her Nobel Prizes in the Physics and Chemistry Categories"", x=""Name of Laureates"", y=""Number of Nobel Prizes"", caption = ""Source: Kaggle / Visualization: Ifeoma Egbogah"")

multiple

ggsave(""multiple.png"", multiple, width = 16, height =10)
```

#Age Distribution of Laureates By Category
```{r}

#Age at the time of Award
Age <- nobel_winners%>%
  mutate(age = prize_year - lubridate::year(birth_date))%>%
  filter(!is.na(age))%>%
  ggplot(aes(category, age, fill=gender))+
  geom_boxplot()+
  scale_fill_manual(values = c(""hotpink"",""skyblue""))+
  labs(x = ""Category"", y= ""Age of Laureates"", title = ""Age Distribution of Noble Prize Winners By Category and Gender"", subtitle = ""Malala Yousafzai (at 17yrs) is the youngest laureate (Peace) and Leonid Hurwicz (at 90yrs) is the oldest laureate (Economics)"", caption = ""Source: Kaggle / Visualization: Ifeoma Egbogah"", fill=""Gender"")

Age

ggsave(""Age.png"", Age, width = 16, height =10)

```


```{r}
#Separating the birth country column because old countries names were merged with new countries names

by_country<- nobel_winners%>%
  filter(!is.na(birth_country))%>%
  separate(birth_country, c(""old_name"", ""country""), sep= ""\\("", extra = ""merge"", fill = ""right"")%>%
  separate(country, c(""country"", NA), sep=""[)]"")%>%
  mutate(country = coalesce(country, old_name))

#Top and Bottom countries With Nobel Prize Wins
Top.Bottom<- by_country%>%
  filter(!is.na(country))%>%
  count(country, sort=TRUE)%>%
  arrange(desc(n))%>%
  slice(c(1:15, seq(n()- 15, n())))%>%
   mutate(country = fct_reorder(country, n))%>%
  ggplot(aes(country, n))+
  geom_point(colour=""hotpink4"")+
  coord_flip()+
  labs(title = ""Top 15 Countries with the Most Nobel Prize Wins"",
       subtitle = ""Bottom 15 Countries with the least Nobel Prize Wins"",
       x= ""Number of Nobel Prize wins"", y=""Country"", caption = ""Source: Kaggle / Visualization: Ifeoma Egbogah"")

Top.Bottom

ggsave(""Top.Bottom.png"", Top.Bottom, width = 16, height =10)
```


#Mapping the Nobel Prize Winners Based on their Country of Birth
```{r}
#Changing the names of some countries and getting the iso3 codes for each country to enable merging with the map data (World)

map <- by_country%>%
  mutate(country =str_replace(country, ""Scotland"", ""United Kingdom"" ))%>%
  mutate(country =str_replace(country, ""Northern Ireland"", ""United Kingdom""))%>%
  mutate(iso3 = countrycode::countrycode(country, ""country.name"", ""iso3c""))%>%
  mutate(country1 = countrycode::countrycode(iso3, ""iso3c"", ""country.name""))


map2 <- map%>%
  group_by(iso3)%>%
  filter(!is.na(iso3))%>%
  summarise(Total = n())%>%
  arrange(desc(Total))


data(""World"")
data(""land"", ""rivers"")


map3 <- append_data(World, map2, key.data =""iso3"", key.shp = ""iso_a3"", ignore.na = TRUE, ignore.duplicates = TRUE)


winners<-tm_shape(land)+
  tm_raster(""elevation"", legend.show = FALSE)+
  tm_shape(rivers)+
   tm_lines(""lightblue"", lwd = ""strokelwd"", scale = 1.5, legend.lwd.show = FALSE)+
   tm_shape(World, is.master = TRUE)+
   tm_borders(""grey20"", lwd = .5)+
  tm_grid(projection = ""longlat"", labels.size = 0.4, lwd = 0.25)+
  tm_shape(map3)+
  tm_dots(""Total"", col=""Total"", palette=""Spectral"", n=10, scale = 1.4, legend.show = FALSE)+
  tm_style(""beaver"", bg.color = ""lightblue"", space.color = ""gray90"")+
  tm_layout(main.title= ""Number of Nobel Prize Winners By Country"", earth.boundary = TRUE, inner.margins = c(0.04, 0.04, 0.03, 0.02), title.size = 1.1, main.title.position = c(""center"") ,  frame = FALSE, legend.position = c(""left"", ""bottom""))+
   tm_compass( type = ""rose"", position = c(0.08, 0.45), size = 3, show.labels =1)+
  tm_credits(""Source: Kaggle / Visualization: Ifeoma Egbogah"")

winners

tmap_save(winners, ""winners.png"")

```

","2019-20"
"977",935,"https://github.com/symplyelah/Tidytuesday","symplyelah","Tidytuesday","Plastic Waste.Rmd","---
title: ""Plastic Waste""
author: ""Ifeoma Egbogah""
date: ""5/29/2019""
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(countrycode)
library(patchwork)
library(cartogram)
library(tmap)
library(tmaptools)

theme_set(theme_light())

coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")


mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")


waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")
```

#Making A Cartogram
```{r}

data(""World"")

mismanaged2010 <- mismanaged_vs_gdp%>%
  left_join(coast_vs_waste)

mismanaged2010 <- mismanaged2010%>%
  filter(!is.na(`Coastal population`))

write.csv(mismanaged2010, ""mismanaged.csv"")
  
mismanaged <- read.csv(""mismanaged.csv"", stringsAsFactors = TRUE)

World<- World%>%
  left_join(., mismanaged,  by= c(""iso_a3"" = ""Code""))


pop<- cartogram_cont(World, ""Coastal.population"")
  
cart <- tm_shape(pop)+
  tm_polygons(""Mismanaged.plastic.waste..tonnes."", n=6, style = ""jenks"", palette = ""viridis"", n=20, title= ""Mismanged Plastic Waste(tonnes)"")+
  tm_text(""Entity"", size = ""Coastal.population"", legend.size.show = FALSE)+
  tm_style(""beaver"", bg.color = ""lightblue"", space.color = ""gray90"")+
  tm_layout(main.title = ""Cartogram of Coastal Population, 2010"", title.size = 0.7, title =""Colour shows plastic waste that is not properly managed by a given country (2010)"",frame = FALSE, legend.position = c(""left"", ""bottom""))+
  tm_credits(""Source: Our World in Data | Visualisation: Ifeoma Egbogah"")

cart



#By absolute quantity China is the largest contributor of mismanaged waste but however its relative contribution (i.e kg per person per day) is not as much as Sri Lanka, Malaysia, Thailand, Egypt, Vanuatu, South Africa, Syria or Trinidad.

waste<- cartogram_cont(World, ""Mismanaged.plastic.waste..tonnes."")

cart1 <- tm_shape(waste)+
  tm_polygons(""Per.capita.mismanaged.plastic.waste..kilograms.per.person.per.day."", n=6, style = ""jenks"", palette = ""viridis"", n=10, title= ""Plastic waste per person per day"")+
  tm_text(""Entity"", size = ""Mismanaged.plastic.waste..tonnes."", legend.size.show = FALSE)+
  tm_style(""beaver"", bg.color = ""lightblue"", space.color = ""gray90"")+
  tm_layout(main.title = ""Cartogram of Mismanaged Plastic Waste (tonnes)"", title.size = 0.6, title =""By absolute quantity, China is the largest contributor of mismanaged waste but its relative contribution (kg per person per day) is low"",  frame = FALSE, legend.position = c(""left"", ""bottom""))+
  tm_credits(""Source: Our World in Data | Visualisation: Ifeoma Egbogah"")

cart1



GDP<- cartogram_cont(World, ""GDP.per.capita..PPP..constant.2011.international.....Rate."")
  
cart2 <- tm_shape(GDP)+
  tm_polygons(""Mismanaged.plastic.waste..tonnes."", n=6, style = ""jenks"", palette = ""viridis"", n=20, title= ""Mismanged Plastic Waste(tonnes)"")+
  tm_text(""Entity"", size = ""GDP.per.capita..PPP..constant.2011.international.....Rate."", legend.size.show = FALSE)+
  tm_style(""beaver"", bg.color = ""lightblue"", space.color = ""gray90"")+
  tm_layout(main.title = ""Cartogram of GDP per capita (2010)"", title.size = 0.7, title = ""Countries with high GDP have low mismanaged plastic waste"",  frame = FALSE, legend.position = c(""left"", ""bottom""))+
  tm_credits(""Source: Our World in Data | Visualisation: Ifeoma Egbogah"")

cart2

tmap_save(cart, ""cart.png"", width = 16, height = 10)
tmap_save(cart1, ""cart1.png"", width = 16, height = 10)
tmap_save(cart2, ""cart2.png"", width = 16, height =10)


```

","2019-21"
"978",936,"https://github.com/symplyelah/Tidytuesday","symplyelah","Tidytuesday","Ramen_ratings.Rmd","---
title: ""Ramen Ratings""
author: ""Ifeoma Egbogah""
date: ""6/10/2019""
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggpubr)
library(ggridges)
library(RColorBrewer)
library(viridis)
library(patchwork)
library(countrycode)

theme_set(theme_light())

ramen_ratings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-04/ramen_ratings.csv"")%>%
  mutate(brand = str_replace(brand, ""Mama"", ""mama""),
         brand = str_replace(brand, ""Nissin Miojo"", ""Nissin-Miojo""),
         brand = str_replace(brand, ""MAMA"", ""mama""))

```


###Curvature plot showing the country of origin for the top 20 ramen brands
```{r}

rate <- ramen_ratings%>%
  count(country = fct_lump(country, 15), brand = fct_lump(brand, 20), sort=TRUE)%>%
  mutate(colour = case_when(country == ""Japan"" ~ ""red"",
            country == ""United States"" ~ ""blue"",
            country == ""South Korea"" ~ ""yellow"",
            country == ""Taiwan"" ~ ""green"",
            country == ""China"" ~ ""purple"",
            country == ""Thailand"" ~ ""hotpink"",
            T ~ ""grey60""))%>%
  ggplot(aes(x = 0,
             y = fct_rev(factor(country)),
             xend = brand,
             yend = 1, 
             colour= colour,
             alpha = (colour != ""grey60"")
             ))+ 
  geom_curve(aes(colour = colour), curvature = -0.3, arrow = arrow(length = unit(0.01, ""npc"")), show.legend = FALSE)+
  scale_x_discrete()+
  scale_y_discrete()+
  scale_color_identity()+
  scale_size_identity()+
  scale_alpha_manual(values = c(0.45, 0.45), guide = F)+
  scale_size_manual(values = c(0.5, 0.6), guide = F)+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  labs(y= ""Country"",
       x= ""Brand of Ramen"",
       title = ""Countries of Origin for the Top 20 Ramen Brands"",
       caption = ""Source: The Ramen Rater | Visualization: Ifeoma Egbogah"")

rate

ggsave(""rate.png"", rate, width = 16, height =10)

```


###Extracting and creating a new column for the different varieties/flavour of ramen from the data
```{r}

ramen_ratings <- ramen_ratings%>%
  mutate(flavour = str_extract(variety, ""Chicken""))%>%
  mutate(flavour2 = str_extract(variety, ""Beef""))%>%
  mutate(flavour3 = str_extract(variety, ""Shrimp""))%>%
  mutate(flavour1 = str_extract(variety, ""Vegetable""))%>%
  mutate(flavour4 = str_extract(variety, ""Onion""))%>%
  mutate(flavour5 = str_extract(variety, ""Curry""))%>%
  mutate(flavour6 = str_extract(variety, ""Pork""))%>%
  mutate(flavour7 = str_extract(variety, ""BBQ""))%>%
  mutate(flavour8 = str_extract(variety, ""Rice""))%>%
  mutate(flavour9 = str_extract(variety, ""Chili""))%>%
  mutate(flavour11 = str_extract(variety, ""Seafood""))%>%
  mutate(flavour12 = str_extract(variety, ""Salt""))%>%
  mutate(flavour13 = str_extract(variety, ""Sesame""))%>%
  mutate(flavour14 = str_extract(variety, ""Soy""))%>%
  mutate(flavour15 = str_extract(variety, ""Chill""))%>%
  mutate(flavour10 = str_extract(variety, ""Spicy""))%>%
  mutate(flavour = coalesce(flavour, flavour2))%>%
  mutate(flavour = coalesce(flavour, flavour3))%>%
  mutate(flavour = coalesce(flavour, flavour1))%>%
  mutate(flavour = coalesce(flavour, flavour4))%>%
  mutate(flavour = coalesce(flavour, flavour5))%>%
  mutate(flavour = coalesce(flavour, flavour6))%>%
  mutate(flavour = coalesce(flavour, flavour7))%>%
  mutate(flavour = coalesce(flavour, flavour8))%>%
  mutate(flavour = coalesce(flavour, flavour9))%>%
  mutate(flavour = coalesce(flavour, flavour11))%>%
  mutate(flavour = coalesce(flavour, flavour12))%>%
  mutate(flavour = coalesce(flavour, flavour13))%>%
  mutate(flavour = coalesce(flavour, flavour14))%>%
  mutate(flavour = coalesce(flavour, flavour15))%>%
  mutate(flavour = coalesce(flavour, flavour10))
  
```


###Coord.polar plot of Ramen rating by brand, style, variety(flavour) and continent of origin
```{r}

ramen_ratings <- ramen_ratings%>%
   select(-flavour1,-flavour2,-flavour3,-flavour4,-flavour5,-flavour6,-flavour7,-flavour8,-flavour9,-flavour10,-flavour11,-flavour12,-flavour13,-flavour14, -flavour15)%>%
  mutate(country = str_replace(country, ""Holland"", ""Netherlands""),
         country = str_replace(country, ""Dubai"", ""UAE""),
         country = str_replace(country, ""Phlippines"", ""Philippines""),
         country = str_replace(country, ""Sarawak"", ""Malaysia""))%>%
  mutate(continent = countrycode(country, ""country.name"", ""continent""))

ramen <- ramen_ratings%>%
  group_by(brand, continent)%>%
  summarise(stars = mean(stars))

ramen1 <- ramen%>%
  group_by(continent)%>%
  top_n(10, stars)%>%
  ggplot(aes(reorder(brand, stars), stars, fill = continent))+
  geom_col(width = 0.8, show.legend = FALSE)+
  coord_flip()+
  facet_wrap(~continent, scales = ""free"")+
  labs(x= ""Ramen Brands"",
       y = ""Ramen Ratings"",
       title= ""Top 10 Ramen Brands In Each Continent Based On Ramen Ratings"",
       subtitle = ""Lots of Brands in Asia Have a Rating of 5"",
       caption = ""Source: The Ramen Rater | Visualization: Ifeoma Egbogah"")

ramen1

nb.cols<-8
cols<-colorRampPalette(brewer.pal(8, ""PiYG""))(nb.cols)

ramen2 <- ramen_ratings%>%
  filter(!is.na(stars), !is.na(style))%>%
  group_by(style, continent)%>%
  summarise(stars = mean(stars), num = n())%>%
  ggplot(aes(reorder(style, stars), stars))+
  geom_col(aes(fill = style), show.legend = FALSE)+
  facet_wrap(~continent)+
  coord_polar()+
  geom_text(aes(label = num))+
  scale_fill_manual(values = cols)+
  labs(x = ""Style of Ramen"",
       y = ""Ramen Ratings"",
       title = ""Ratings of Ramen Styles For Each Continent"")

ramen2

nb.col<-16
col<-colorRampPalette(brewer.pal(16, ""PiYG""))(nb.col)
  
ramen3 <- ramen_ratings%>%
  mutate(flavour = str_replace(flavour, ""Chill"", ""Chili""))%>%
  filter(!is.na(flavour), !is.na(stars))%>%
  group_by(flavour, continent)%>%
  summarise(stars = mean(stars), num = n())%>%
  ggplot(aes(reorder(flavour, stars), stars))+
  geom_col(aes(fill = flavour), show.legend = FALSE)+
  facet_wrap(~continent)+
  coord_polar()+
  geom_text(aes(label = num))+
  scale_fill_manual(values = col)+
  labs(x = ""Style of Ramen"",
       y = ""Ramen Ratings"",
       title = ""Ratings of Ramen Variety For Each Continent"",
       subtitle = ""Numbers are the Varieties Extracted from the Ramen Data"",
       caption = ""Source: The Ramen Rater | Visualization: Ifeoma Egbogah"")

ramen3

ggsave(""ramen1.png"", ramen1, width = 16, height =10)
ggsave(""ramen2.png"", ramen2, width = 16, height =10)
ggsave(""ramen3.png"", ramen3, width = 16, height =10)


```


###Distribution of Ramen ratings by country and style
```{r}

ramen4 <- ramen_ratings%>%
  filter(!is.na(style))%>%
  mutate(style = fct_reorder(style,stars))%>%
  ggplot(aes(stars, style, fill= style, colour = style))+
  geom_density_ridges_gradient(alpha= 0.8, 
                               show.legend = FALSE)+
  scale_fill_viridis_d(option = ""E"")+
  scale_color_viridis_d(option = ""E"")+
  labs(x= ""Ramen Ratings"",
       y= ""Style of Ramen"",
       title= ""Distribution of Style Of Ramen"",
       caption= ""Source: The Ramen Rater | Visualization: Ifeoma Egbogah"")

ramen4

ramen5 <- ramen_ratings%>%
  mutate(country = fct_lump(country, 10))%>%
  mutate(country = fct_reorder(country, stars))%>%
  ggplot(aes(stars, country, fill = country, colour=country))+
  geom_density_ridges_gradient(alpha = 0.8, show.legend = FALSE)+
  scale_fill_viridis_d(option = ""D"")+
  scale_color_viridis_d(option = ""D"")+
  labs(y=""Country"",
       x= ""Ramen Rating"")

ramen5

ramen6 <- ramen_ratings%>%
  filter(!is.na(country), !is.na(stars))%>%
  mutate(country = fct_lump(country, 10))%>%
  mutate(country = fct_reorder(country, stars))%>%
  ggplot(aes(country, stars, fill = country))+
  geom_boxplot(alpha = 0.8, show.legend = FALSE)+
  scale_fill_viridis_d(option = ""D"")+
  coord_flip()+
  labs(x=""Country"",
       y= ""Ramen Rating"")

ramen6


plots<- wrap_plots(ramen5, ramen6)+ plot_annotation(title= ""Distribution of Ramen Ratings by Country"",
  caption= ""Source: The Ramen Rater | Visualization: Ifeoma Egbogah"")

plots

ggsave(""ramen4.png"", ramen4, width = 16, height =10)
ggsave(""plots.png"", plots, width = 16, height =10)


```

","2019-23"
"979",937,"https://github.com/symplyelah/Tidytuesday","symplyelah","Tidytuesday","UFO sights.Rmd","---
title: ""UFO""
author: ""Ifeoma Egbogah""
date: ""7/17/2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}

library(tidyverse)
library(sf)
library(viridis)
library(cowplot)
library(fuzzyjoin)
library(RColorBrewer)



ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")


district <- read_sf(""C:/Users/Egbogah/Desktop/Ifeoma/GB/bd_uk/Data/GB/district_borough_unitary_region.shp"")

europe <- read_sf(""C:/Users/Egbogah/Desktop/Ifeoma/GB/bd_uk/Data/GB/european_region_region.shp"")

district <- district%>%
  st_transform(4326)


pop <- read_csv(""C:/Users/Egbogah/Desktop/Ifeoma/pop_uk.csv"")


```


#Bivariate Choropleth Showing UFO Sightings and Population (mid 2017) In The UK
```{r}

gb1 <- ufo_sightings%>%   #top 5 counties with the most sightings
  filter(country == ""gb"")%>%
  separate(city_area, ""county"",  sep = "" \\("", remove = FALSE, fill = ""right"")%>%
  group_by(county, longitude, latitude)%>%
  summarise(total = n())%>%
  ungroup()%>%
  mutate(ratio = 100 * total/sum(total))%>%
  arrange(desc(ratio))%>%
  head(5)%>%
  st_as_sf(crs = 4326, coords = c(""longitude"", ""latitude""))


gb2 <- ufo_sightings%>%  #calculating ratio of sightings per county
  filter(country == ""gb"")%>%
  separate(city_area, ""county"",  sep = "" \\("", remove = FALSE, fill = ""right"")%>%
  group_by(longitude,latitude)%>%
  summarise(total = n())%>%
  ungroup()%>%
  mutate(ratio = 100 * total/sum(total))%>%
  st_as_sf(crs = 4326, coords = c(""longitude"", ""latitude""))

ufo_map <- st_join(district, gb2, join = st_intersects) # joining data to the map



join <- ufo_map%>%  #joining population data to the map
  fuzzy_left_join(., pop, by = c(""NAME"" = ""Name""), match_fun = str_detect)


bivariate_color_scale <- tibble(
  ""3 - 3"" = ""#804d36"",
  ""2 - 3"" = ""#976b82"", #
  ""1 - 3"" = ""#9972af"", # high sightings, high population
  ""3 - 2"" = ""#af8e53"", # low sightings, high population
  ""2 - 2"" = ""#c8ada0"",
  ""1 - 2"" = ""#cbb8d7"", # 
  ""3 - 1"" = ""#c8b35a"", # high sightings, low population
  ""2 - 1"" = ""#e4d9ac"",
  ""1 - 1"" = ""#e8e8e8""  #  low sightings, low population
) %>%
  gather(""group"", ""fill"")



join2 <- join%>%
  replace_na(list(ratio = 0, `All ages` = 0 ))%>%
  mutate(ratio_quantiles = cut(ratio,
                         breaks = unique(quantile(ratio, probs = seq(0, 1, length.out = 6))),
                         include.lowest = TRUE),
         
         pop_quantiles = cut(`All ages`,
                             breaks = unique(quantile(`All ages`, probs = seq(0, 1, length.out = 4))),
                         include.lowest = TRUE),
         
         group = paste(as.numeric(ratio_quantiles), ""-"",
                       as.numeric(pop_quantiles)))%>%
  left_join(bivariate_color_scale, by = ""group"")

  
 
map <- ggplot(data = join2)+
  
  geom_sf(aes(fill = fill), colour = ""grey85"",  size = 0.1)+
  
  scale_fill_identity()+
  
  geom_sf(data = europe, fill = ""transparent"", colour = ""white"", size = 0.7)+
  
  
  theme(panel.grid.major = element_line(color = ""#dbdbd9"", linetype = ""dashed"", size = 0.2),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = ""aliceblue""),
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        plot.margin = unit(c(.5, .5, .2, .5), ""cm""),
        panel.border = element_blank(),
        panel.spacing = unit(c(-.1, 0.2, .2, 0.2), ""cm""),
        legend.title = element_text(size = 11),
        
        legend.text = element_text(size = 9, hjust = 0),
    
        plot.title = element_text(size = 12, hjust = 0.5,
                              color = ""#939184""),
    
        plot.subtitle = element_text(size = 13, hjust = 0.5,
                                 color = ""grey75"",
                                 margin = margin(b = -0.1,
                                                 t = -0.1,
                                                 l = 2,
                                                 unit = ""cm""),
                                 debug = F),
    
    plot.caption = element_text(size = 7,
                                hjust = .5,
                                margin = margin(t = 0.2,
                                                b = 0,
                                                unit = ""cm""),
                                color = ""#939184""))+
  
  labs(title =""Bivariate Choropleth Showing UFO Sightings and Population (mid 2017) In The UK"",
       x = "" "",
       y = "" "",
       caption = ""Source: NUFORC, OS Open Data, Office Of Natioinal Statistics (ONS) | Visualization: Ifeoma Egbogah"")

    
  bivariate_legend <-  bivariate_color_scale %>%
  separate(group, into = c(""ratio"", ""pop""), sep = "" - "") %>%
  mutate(ratio = as.integer(ratio),
         pop = as.integer(pop))



legend <- ggplot(bivariate_legend)+
  geom_tile(aes(ratio, pop, fill = fill))+
  scale_fill_identity() +
  labs(x = ""Sightings ??"",
       y = ""Population ??"") +
  theme_minimal()+
  theme(axis.title = element_text(size = 7)) +
  coord_fixed(clip = ""off"")
 

bivariate <- ggdraw() +
  draw_plot(map, 0, 0, 1, 1) +
  draw_plot(legend, 0.05, 0.075, 0.2, 0.2)

bivariate

ggsave(""C:/Users/Egbogah/Desktop/bivariate.png"", bivariate, width = 6, height = 6)

```","2019-26"
"980",938,"https://github.com/symplyelah/Tidytuesday","symplyelah","Tidytuesday","UNESCO.Rmd","---
title: ""UNESCO""
author: ""Ifeoma Egbogah""
date: ""5/14/2019""
output: 
  html_document: 
    keep_md: yes
---

##Analysising the global student to teacher ratio dataset from UNESCO
```{r}

library(tidyverse)
library(patchwork)
library(maps)
library(countrycode)

theme_set(theme_light())

unesco <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")

```

##Changing the name of the country Cote d'Ivoire to Ivory Coast
```{r}

IV <-unesco%>%
  filter(country == ""Cte d'Ivoire"")%>%
  mutate(country = paste0(""Ivory Coast""))
  
unesco2 <- unesco%>%
  filter(country != ""Cte d'Ivoire"")%>%
  bind_rows(IV)
```

##Calculating the change in student/teacher ratio for primary education between 2012 and 2015
```{r}

#Subset data/calculating change in student to teacher ratio

unesco_spread <- unesco2%>%
  mutate(continent = countrycode(country_code, ""iso3c"", ""continent""))%>%
  mutate(region = countrycode(country_code, ""iso3c"", ""region""))%>%
  filter(!is.na(region))%>%
  filter(!is.na(continent))%>%
  filter(indicator == c(""Primary Education""))%>%
  mutate(year = paste0(""Y"", year))%>%
  spread(year, student_ratio)%>%
  mutate(current=Y2015,
         change =Y2015 - Y2012)
 
#Visualization

  plot_region<- function(data) {
    
    ggplot(data, aes(x= current, y = change, group= region, colour=continent))+
    geom_point(show.legend = FALSE)+
    geom_hline(aes(yintercept=0), show.legend = FALSE)+
  facet_wrap(~region)+
    geom_text(aes(label=country), vjust = 1, hjust = 1, check_overlap = TRUE, show.legend = FALSE)+
    scale_y_continuous(limits = c(-20, 20))+
    expand_limits(x=0)+
    labs(x=""Student/Teacher ratio"", y=""Change"")
  
}

by_region<- unesco_spread%>%
  group_by(current, change, region, continent)%>%
  split(.$continent)%>%
  purrr::map(plot_region)


  
plot_continent<-function(data) {
  
  ggplot(data, aes(current, change, ratio, colour=continent))+
  geom_point(show.legend = FALSE)+
  geom_hline(aes(yintercept = 0), show.legend = FALSE)+
  facet_wrap(~continent, ncol=1)+
  geom_text(aes(label=country), vjust = 1, hjust = 1, check_overlap = TRUE, show.legend = FALSE)+
    scale_y_continuous(limits = c(-20, 20))+
    expand_limits(x=0)+
    labs(x=""Student/Teacher ratio"", y=""Change"")
  
}


by_continent<-unesco_spread%>%
  group_by(current, change, continent)%>%
  split(.$continent)%>%
  purrr:: map(plot_continent)


cont <-wrap_plots(by_continent) + plot_annotation(title=""Change in Student/Teacher Ratio For Primary Education Between 2012 and 2015"", 
caption = ""Data:UNESCO Institute Of Statistic| Graphics: Ifeoma Egbogah"")

reg <-wrap_plots(by_region)+ plot_annotation(title=""Change in Student/Teacher Ratio For Primary Education Between 2012 and 2015"", 
caption = ""Data:UNESCO Institute Of Statistic| Graphics: Ifeoma Egbogah"")


ggsave(""unesco.png"", cont, width = 16, height =10)
ggsave(""unesco2.png"", reg, width = 16, height =10)

```

","2019-19"
"981",940,"https://github.com/symplyelah/Tidytuesday","symplyelah","Tidytuesday","squirrel.Rmd","---
title: ""NYC Squirrel Census""
author: ""Ifeoma Egbogah""
date: ""11/7/2019""
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(tidyverse)
library(ggmap)
library(viridis)
library(extrafont)
font_import()
loadfonts(device = ""win"")

nyc_squirrels <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv"")

ny.map2 <- get_map(""Central Park, New York"", maptype = ""terrain"", zoom = 14) #Get map of central park from google

```

```{r}

nyc <- ggmap(ny.map2)+
  stat_density_2d(data = nyc_squirrels%>%
                  filter(!is.na(highlight_fur_color)), 
                  aes(long, lat, fill = stat(level)), 
                  alpha = 0.1, bins = 20, geom = ""polygon"")+
  scale_fill_viridis(option = ""C"")+
  facet_wrap(~ `highlight_fur_color`)+
  theme_minimal()+
  theme(axis.text = element_blank(),
        strip.text.x = element_text(size = 13))+
  labs(x = "" "",
       y = "" "",
       title = ""Geographic Density of Squirrels in Central Park, New York"",
       subtitle = ""The geographic density is faceted based on the highlight colour of the squirrels' fur"",
       caption = ""Data: NYC Squirrel Census | Visualization: Ifeoma Egbogah"",
       fill = ""Level"")


nyc2 <- ggmap(ny.map2)+
  stat_density_2d(data = nyc_squirrels%>%
                  filter(!is.na(primary_fur_color)), 
                  aes(long, lat, fill = stat(level)), 
                  alpha = 0.1, bins = 20, geom = ""polygon"")+
  scale_fill_viridis(option = ""C"")+
  facet_wrap(~ `primary_fur_color`)+
  theme_minimal()+
  theme(axis.text = element_blank(),
        strip.text.x = element_text(size = 13))+
  labs(x = "" "",
       y = "" "",
       title = ""Geographic Density of Squirrels in Central Park, New York"",
       subtitle = ""The geographic density is faceted based on the squirrels' primary fur colour"",
       caption = ""Data: NYC Squirrel Census | Visualization: Ifeoma Egbogah"",
       fill = ""Level"")


```


```{r}

ggsave(""map.jpeg"", nyc,  width = 12, height = 12)
ggsave(""map2.jpeg"", nyc,  width = 12, height = 10)

```

","2019-44"
"982",941,"https://github.com/symplyelah/Tidytuesday","symplyelah","Tidytuesday","transistor.Rmd","---
title: ""Moore's Law""
author: ""Ifeoma Egbogah""
date: ""9/11/2019""
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(ggthemes)
library(gameofthrones)
library(extrafont)
loadfonts()
#font_import(device = ""win"")


cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")


moore_law <- cpu%>%
  filter(!is.na(transistor_count), !is.na(area))%>%
  ggplot(aes(date_of_introduction, transistor_count))+
  geom_point(aes(size = area, colour = designer))+
  geom_text(aes(label = designer), family = ""Gabriola"", size = 4, hjust = -0.2, vjust = -0.2, check_overlap = TRUE)+
  #geom_smooth(method = ""auto"", lty = 2, colour = ""darkred"")+
  scale_colour_got_d(option = ""wildfire"")+
  scale_x_continuous(breaks = seq(1970, 2020, 5), limits = c(1970, 2022))+
  scale_y_log10(labels = scales::comma)+
  theme_minimal()+
  theme(plot.title = element_text(family = ""Leelawadee UI"", colour = ""black""),
        axis.title = element_text(family = ""Microsoft Himalaya"", size = 15, colour = ""black""),
        plot.subtitle = element_text(family = ""Microsoft Himalaya"", size = 15),
        plot.caption = element_text(family = ""Gabriola"", size = 11))+
  guides(colour = F)+
  labs(y = ""Transistor Count (Log)"",
       x = ""Date of Introduction"",
       title = ""The Number of Transistors (1970 - 2018)"",
       subtitle = ""Moore's Law: The Number of Transistors Doubles Approximately Every Two Years"",
       size = expression(paste(""Area of Chip "", (mm^2))),
       caption = ""Data Source: Wikipedia | Visualization: Ifeoma Egbogah"")



area_of_chip <- cpu%>%
  filter(!is.na(transistor_count), !is.na(area))%>%
  mutate(year = as.integer(date_of_introduction))%>%
  group_by(designer, year)%>%
  ggplot(aes(transistor_count, area, label = designer))+
  geom_point(aes(size = area, colour = designer), show.legend = FALSE)+
  geom_text(hjust = -0.2, vjust = -0.2, check_overlap = TRUE)+
  geom_smooth(method = ""auto"")+
  scale_x_continuous(labels = scales::comma)+
  scale_colour_got_d(option = ""tully"")+
  guides(size = F, colour = F)+
  theme_minimal()+
  theme(plot.title = element_text(family = ""Leelawadee UI"", colour = ""black"", size = 30),
        axis.title = element_text(family = ""Microsoft Himalaya"", size = 19, colour = ""black""),
        plot.subtitle = element_text(family = ""Microsoft Himalaya"", size = 18),
        plot.caption = element_text(family = ""Gabriola"", size = 11)) +
    labs(title = ""The Number of Transistors on Intergrated Circuit Chip"",
       subtitle = ""Processing power amongst other things is mostly dependent on the transistor count in a chip. The Transistor count also determines the size or area footprint of the chip. 
The plot shows the Area of chip over time plateaued at about 800 sq mm and a regression analysis shows no significant increase in area is likely.
Newer technologies favour smaller footprint or Area of chip while still boasting high processing power. In this bracket you have chips with transistor count between\n5 Billion - 10 Billion integrated within an area of less than 300 sq mm. 
While some older devices still use the likes of IBM processors with similar processing power and bigger footprint, newer designers go for the likes of AMD,\nQualcomm and Apple, which provides the high processing power in a much reduced area, with Qaulcomm boasting the highest processing power close to 20 Billion transistors within 400 sq mm"",
       y = expression(paste(""Area of Chip "", (mm^2))),
       x = ""Transistor Count"",
       caption = ""Data Source: Wikipedia | Visualization: Ifeoma Egbogah"")


ggsave(""area.png"", area_of_chip, height = 7, width = 15)
ggsave(""mooore.png"", moore_law, height = 5, width = 10)
```

","2019-36"
"983",945,"https://github.com/rockmama/Anime-Analysis","rockmama","Anime-Analysis","Anime Analysis.Rmd","---
title: ""Anime Analysis""
author: ""Vaibhav""
date: ""April 23, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(gganimate)
theme_set(theme_minimal())
```

```{r}
tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

head(tidy_anime)
str(tidy_anime)

tidy_anime <- tidy_anime %>%
  mutate(
    start_date = lubridate::ymd(start_date),
    end_date = lubridate::ymd(end_date)
  ) %>%
  filter(rank != 0, popularity != 0)
```

Most Popular Anime
```{r}
top_16_genre <- tidy_anime %>% select(name, genre, popularity) %>% count(genre, sort = TRUE) %>% top_n(16) %>% pull(genre)

tidy_anime %>%
  select(name, genre, popularity) %>%
  group_by(name, genre) %>%
  summarise(pop = sum(popularity)) %>%
  arrange(desc(pop)) %>%
  ungroup() %>%
  top_n(20) %>%
  mutate(name = fct_reorder(name, pop)) %>%
  ggplot(aes(reorder(name, pop), pop)) + geom_col() + coord_flip() +
  labs(title = ""Most Populat Anime"", y = """", x = """")
```

Episodes per Genre (Top 10)

```{r}
tidy_anime %>%
  select(genre, episodes) %>%
  group_by(genre) %>%
  summarise(episodes = mean(episodes, na.rm = TRUE), count = dplyr::n()) %>%
  arrange(desc(count)) %>%
  top_n(10) %>%
  mutate(genre = fct_reorder(genre, episodes)) %>%
  ggplot(aes(genre, episodes, fill = genre)) + geom_col(show.legend = FALSE) + coord_flip() +
  labs(title = ""Episodes in a season Per Genre (Top 10)"", x = """", y = """")
```

Top 10 Ranked Anime (Already Aired Vs Currently Running )

```{r}

tidy_anime %>%
  select(name, airing, rank) %>%
  distinct(name, airing, rank) %>%
  group_by(airing) %>%
  top_n(n = 20, wt = -rank) %>%
  ungroup() %>%
  mutate(
    name = fct_reorder(name, -rank),
    airing = as.factor(airing),
    airing = fct_recode(airing,
      ""ALREADY AIRED"" = ""FALSE"",
      ""CURRENTLY AIRING"" = ""TRUE""
    )
  ) %>%
  ggplot(aes(name, rank, fill = name)) + geom_col(show.legend = FALSE) + coord_flip() + labs(title = ""Top Ranked Anime (Already Aired Vs Current Airing)"", y = """", x = """") +
  facet_wrap(~airing, scales = ""free"")
```

Which Genre was popular in which year

```{r}

p<- tidy_anime %>%
  select(name, genre, airing, start_date, end_date, rank) %>%
  filter(genre %in% top_16_genre) %>%
  mutate(start_year = lubridate::year(start_date)) %>%
  select(start_year, genre) %>%
  add_count(start_year, genre) %>%
  filter(start_year < 2019 ) %>%
  arrange(start_year) %>%
  unique() %>%
  ggplot(aes( start_year,n, color = genre)) + geom_point(show.legend = FALSE)  +
  geom_path(show.legend = FALSE)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  +
  facet_wrap(~genre) + 
  labs(title = ""Analysing Genre Treng in Anime by Year"",
subtitle= ""Year: {round(frame_along,0)}"", y="""",x="""")+
  transition_reveal(along=start_year) +
  ease_aes('linear')
  

animate(p,102,3)

```

","2019-17"
"984",947,"https://github.com/NewMirai/Tidytuesday/blob/master/tidytuesdayR4DS/plot.r","NewMirai","Tidytuesday","tidytuesdayR4DS/plot.r","library(tidyverse)
library(ggTimeSeries)
library(viridis)

r4ds_members <-read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"")


#visdat::vis_miss(r4ds_members)


r4ds_members %>% 
  ggplot_calendar_heatmap('date','daily_active_members',monthBorderSize = 1.5,monthBorderColour = ""black"")+
  scale_fill_viridis(option = ""D"")+
  theme_minimal()+
  facet_wrap(~Year, ncol = 1,strip.position = ""right"")+
  theme(panel.spacing = unit(5, ""lines""),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = NA, fill=""black""),
        plot.background = element_rect(fill=""black""),
        legend.position = ""bottom"",
        axis.text.x = element_text(size = 12,colour =""#bfbfbf"",vjust = -2),
        axis.text.y = element_text(size=12,colour = ""#bfbfbf""),
        strip.text = element_text(size=14,colour=""#bfbfbf""),
        legend.text = element_text(colour = ""#bfbfbf"",size=8),
        legend.title = element_text(colour = ""#bfbfbf"",vjust = .9,size=14),
        plot.title = element_text(size=20,colour=""#bfbfbf"",hjust = .5),
        plot.subtitle = element_text(size=16,colour = ""#bfbfbf"",hjust = .5),
        plot.caption = element_text(colour = ""#bfbfbf""))+
  labs(y='',
       fill=""Daily active members"",
       title = ""Calendar heatmap of the active members"",
       subtitle = ""Made with the ggTimeSeries package for super easy calendar heatmap\n"",
       caption = ""#Tidy tuesday | Source: R4DS Slack | @alangel12407606"")


ggsave(""calendar_heatmap.png"",width = 16,height = 9,dpi = 400)
","2019-29"
"985",948,"https://github.com/NewMirai/Tidytuesday/blob/master/tidytuesdayvideogame/plot.r","NewMirai","Tidytuesday","tidytuesdayvideogame/plot.r","#### Import libraries ####

library(tidyverse)
library(lubridate)
library(ggforce)
library(ggrepel)
library(cowplot)
library(glue)

#### get the data ####

video_games <- 
  readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"")

#### some cleaning ####

video_games_cleaned <- video_games %>% 
  mutate(release_date=mdy(str_replace(release_date,pattern = "","",replacement = """"))) %>% 
  arrange(release_date) %>% 
  mutate(Year=as_factor(year(release_date)),
         Month=as_factor(month(release_date)))



#### Grouping & aggegation ####

grouped_average <- video_games_cleaned %>%
  group_by(Year) %>% 
  summarise(average_price_by_year=mean(price,na.rm = T),
            median_price_by_year=median(price,na.rm = T)) %>% 
  ungroup() %>% 
  #drop_na() %>% 
  mutate(Year=ymd(Year,truncated = 2))

mean_2008 <- grouped_average %>%
  filter(year(Year)==""2008"") %>%
  pull(average_price_by_year) %>% 
  round(digits = 2)


mean_2013 <- grouped_average %>%
  filter(year(Year)==""2013"") %>%
  pull(average_price_by_year) %>% 
  round(digits = 2)


#### Plot ####

grouped_average%>% 
  ggplot(aes(x=Year,y=average_price_by_year))+
  scale_x_date(date_breaks = ""1 year"",date_labels = ""%Y"",expand = c(0.01,0.01))+
  geom_line(size=1.2,colour=""#FFCD29"",alpha=.65)+
  geom_point(size=5,color=""#FFCD29"")+
  geom_mark_circle(data=subset(grouped_average,
                               Year==ymd(""2013"",truncated = 2)),
                   aes(label=paste(substr(as.character(Year),start = 0,stop = 4),"": Highest peak""),
                       description=glue(""In 2013, the highest peak of price was observed with a yearly average of {mean_2013}$."")),
                   color=""red"",
                   fill=""red"",
                   expand =unit(7,""mm""),
                   label.minwidth = unit(70,""mm""),
                   label.hjust = 0.5,con.colour = ""#D4D4D4"",label.fill = ""#423F3F"",label.colour = ""#D4D4D4"")+
  geom_mark_circle(data=subset(grouped_average,
                               Year==ymd(""2008"",truncated = 2)),
                   aes(label=paste(substr(as.character(Year),start = 0,stop = 4),"": First peak""),
                       description=glue(""In 2008, the first peak of price was observed with a yearly average of {mean_2008}$."")),
                   color=""red"",
                   fill=""red"",
                   expand =unit(7,""mm""),
                   label.minwidth = unit(70,""mm""),
                   label.hjust = 0.5,con.colour = ""#D4D4D4"",label.fill = ""#423F3F"",label.colour = ""#D4D4D4"")+
  theme_minimal()+
  labs(x="""",
       y="""",
       caption = ""#Tidy tuesday | Source: Steam Spy | @alangel12407606"",
       subtitle = ""From 2004 to 2013 the average game's prices have increased steadily. Howewer since 2013 prices are decreasing.\n\n"",
       title = ""Average price by year"")+
  theme(plot.background =element_rect(fill = ""#423F3F""),
        plot.caption = element_text(size = 10,colour = ""#D4D4D4""),
        panel.grid = element_line(colour = ""#C78F50"",size = 0.01),
        axis.text.x = element_text(size=10,colour = ""#FFCD29""),
        plot.title = element_text(hjust = .5,size=20,colour = ""#FFCD29""),
        plot.subtitle = element_text(hjust = .5,size = 14,colour = ""#D4D4D4""),
        axis.text.y = element_text(size=10,color = ""#FFCD29""))

ggsave(""plot.png"",dpi = 400,width = 16,height = 9)
","2019-31"
"986",949,"https://github.com/NewMirai/Tidytuesday/blob/master/tidytuesdayWWC/plot.R","NewMirai","Tidytuesday","tidytuesdayWWC/plot.R","library(readr)
library(tidyverse)
library(ggridges)
library(viridis)
library(ggthemes)
library(hrbrthemes)
library(ggThemeAssist)
library(ggrepel)
library(visdat)

wwc_outcomes <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

wwc_outcomes <- left_join(wwc_outcomes, codes, by = ""team"")


median_age_plot <- squads %>%
  group_by(country) %>% 
  mutate(median_age=median(age))%>% 
  ungroup() %>% 
  mutate( country=case_when(
    country==""China PR"" ~ ""China"",
    country==""US"" ~ ""USA"",
    TRUE ~ country
  )) %>% 
  mutate(country=fct_reorder(country,median_age))


p1 <- ggplot(data = median_age_plot,aes(x=age,y=country,fill=age))+
  stat_density_ridges(quantile_lines = TRUE, quantiles = 2,
                      scale=.95,rel_min_height=0.005,fill=""#a3c2c2"")+
  scale_x_continuous(breaks = seq(10,45,5))+
  theme_ridges(center_axis_labels = T)+
  labs(x=""Age"",
       y="""",
       title = ""Distribution of age per country and ranked by median age"",
       subtitle = ""We observe that the most experienced team in terms of median age is also the winner of the competition\n"",
       caption = ""@alangel12407606\n#TidyTuesday"")+
theme(axis.title.x = element_text(hjust = .5,size=14,color = ""black"",vjust = -1),
      plot.title = element_text(size=20,hjust = .5),
      plot.subtitle = element_text(size = 16,hjust = .5),
      axis.text.y = element_text(size=12),
      plot.background = element_rect(fill=""#ffffe6""))

p1


p2_data <- squads %>% 
  top_n(50,wt =goals) %>% 
  arrange(-goals) %>% 
  mutate(gp=round(goals/caps,digits = 1)) %>% 
  mutate(player=fct_reorder(player,goals),
         country=as_factor(country)) %>% 
  mutate(player_category=case_when(
    age<=25 ~""- 25"",
    age<=30 ~""25-30"",
    age<=35 ~""30-35"",
    age>35 ~""35+"")) %>% 
  arrange(-gp,country)


p2 <- p2_data %>% ggplot(aes(x = player,y=goals,fill=gp))+
  geom_bar(stat = ""identity"",colour=NA)+
  geom_vline(aes(x = country,y=player),xintercept=0.5)+
  facet_wrap(~player_category,nrow = 1)+
  coord_flip()+
  scale_fill_viridis(option = ""A"")+
  theme_modern_rc()+
  theme(
    axis.text.x = element_text(angle = 90),
    axis.title.x= element_text(hjust = .5,size=18,vjust = -2),
    legend.position = ""right"",
    plot.title = element_text(size=20,hjust = .5),
    plot.subtitle = element_text(size=16,hjust = .5),
    legend.direction = ""vertical"",
    plot.caption = element_text(size=12),
    legend.title = element_text(size=16),
    strip.text = element_text(hjust = .5,color=""#f0f5f5"",size = 16,vjust = 2))+
  geom_text(hjust=-0.1,label=paste(p2_data$caps,""games""),color=ifelse(p2_data$gp>0.75,""#f0f5f5"",NA),size=5)+
  labs(x="""",
       y=""Goals scored"",
       fill=""Goal per games "",
       title = ""Top 50 scorers by age category"",
       subtitle = ""This plot higlight the consistency of each scorers by looking at the goal per games indicator.3 players scored more than 0.75 goals per games and are highlighted.
       But if the goal per games stats is the highest for Khadija Shaw, Martha from Brazil with 6 times more  games  shows a much more impressive consistency.\n"",
       caption = ""@alangel12407606\n#TidyTuesday"")


p2
","2019-28"
"987",973,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","R4DS_membership.Rmd","---
title: ""R4DS_membership""
author: ""Tony Galvan""
date: ""7/16/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(ggridges)
theme_set(theme_light())

r4ds_members <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-16/r4ds_members.csv"") %>%
  filter(date > '2017-08-31') %>%
  select(-guests, -name, -messages_in_shared_channels) %>%
  mutate(month = factor(month(date, label = TRUE)),
         day = factor(wday(date, label = TRUE)), 
         year = factor(year(date)),
         season = case_when(
           date < '2017-09-22' ~ ""Summer"",
           date >= '2017-09-22' & date < '2017-12-21' ~ ""Fall"",
           date >= '2017-12-21' & date < '2018-03-20' ~ ""Winter"",
           date >= '2018-03-20' & date < '2018-06-21' ~ ""Spring"",
           date >= '2018-06-21' & date < '2018-09-22' ~ ""Summer"",
           date >= '2018-09-22' & date < '2018-12-21' ~ ""Fall"",
           date >= '2018-12-21' & date < '2019-03-20' ~ ""Winter"",
           date >= '2019-03-20' & date < '2019-06-21' ~ ""Spring"",
           date >= '2019-06-21' ~ ""Summer""))
```

#### EDA

```{r}
r4ds_members %>%
  summary()
```

This data is stats for the R4DS community from it's founding through the start of July (8/27/2017 to 7/5/2019).

Let's explore the daily active members variable.

```{r}
r4ds_members %>%
  group_by(month, year) %>%
  summarise(total_active_members = sum(daily_active_members)) %>%
  ggplot(aes(month, total_active_members, fill = month)) +
  geom_col(show.legend = FALSE) +
  labs(x = """",
       y = ""# of daily active members"",
       title = ""Daily active R4DS members by month"",
       subtitle = ""Fewer active members the second half of the year"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: R4DS Slack"")
```

Let's try to create a ridgeline plot for the number of messages posted by month.

```{r}
r4ds_members %>%
  ggplot(aes(daily_active_members, fct_rev(month))) + 
  geom_density_ridges(aes(fill = year), alpha = 0.5) + 
  theme_ridges(grid = FALSE) + 
  labs(x = """",
       y = """",
       title = ""R4DS daily active members by month"",
       fill = ""Year"",
       subtitle = ""Fewer active members the second half of the year"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: R4DS Slack"") +
  theme(legend.position = ""top"")
```

Let's look at daily active members by season

```{r}
r4ds_members %>%
  group_by(season) %>%
  summarise(avg_active_members = sum(daily_active_members) / n()) %>%
  mutate(season = fct_reorder(season, avg_active_members)) %>%
  ggplot(aes(season, avg_active_members, fill = season)) +
  geom_col(show.legend = FALSE) +
  coord_flip() + 
  labs(x = """",
       y = ""Avg. daily active members"",
       title = ""R4DS daily active members by season"",
       subtitle = ""Fewer active members in Fall"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: R4DS Slack"")
```

Let's try to create a lollipop plot

```{r}
r4ds_members %>%
  ggplot(aes(date, total_membership)) +
  geom_line()
```

","2019-29"
"988",974,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","bird_collisions.Rmd","---
title: ""bird_collisions""
author: ""Tony Galvan""
date: ""April 29, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chicago Bird Collisions
### Tidy Tuesday 2019 Week 18

```{r}
library(tidyverse)

theme_set(theme_minimal())

bird_collisions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/bird_collisions.csv"")
mp_light <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-30/mp_light.csv"")
```

#### EDA

```{r}
glimpse(bird_collisions)
```

```{r}
summary(bird_collisions$date)
```

The ""bird_collisions"" data contains observations of birds colliding with various lighted structures in Chicago from 9/15/1978 to 11/30/2016.

```{r}
mp_light %>%
  summary()
```

The ""mp_light"" data contains light scores (proportion of the 17 window bays that were illuminated) at McCormic Place (locality = ""MP"" from the ""bird_collisions"" data) in Chicago between 3/6/2000 and 5/26/2018.

Are there dates with multiple light_scores?

```{r}
mp_light_processed <- mp_light %>%
  group_by(date) %>%
  summarise(n = n()) %>%
  filter(n == 1) %>%
  select(date) %>%
  left_join(mp_light)
```

Let's plot this data to see if there is a pattern based on the day of the week.

```{r}
mp_light_processed %>%
  mutate(weekday = lubridate::wday(date, label = TRUE)) %>%
  group_by(weekday) %>%
  summarize(pct_light_score = mean(light_score)/100) %>%
  ggplot(aes(weekday, pct_light_score, fill = weekday)) +
  geom_col(show.legend = FALSE) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = ""Weekday"", 
       y = ""Average % of window bays illuminated"",
       title = ""Thursday was the most illuminated day of the week"",
       subtitle = ""McCormick Place Between 3/6/2000 and 5/26/2018"")
```

Let's plot this data to see if there is a pattern based on the month.

```{r}
mp_light_processed %>%
  mutate(month = lubridate::month(date, label = TRUE)) %>%
  group_by(month) %>%
  summarize(pct_light_score = mean(light_score)/100) %>%
  ggplot(aes(month, pct_light_score, fill = month)) +
  geom_col(show.legend = FALSE) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = ""Month"", 
       y = ""Average % of window bays illuminated"",
       title = ""September was the most illuminated month"",
       subtitle = ""McCormick Place Between 3/6/2000 and 5/26/2018"")
```

Let's join the data together.

```{r}
mp_bird_collisions <- bird_collisions %>%
  filter(locality == ""MP"") %>%
  left_join(mp_light_processed) %>%
  filter(date > ""2000-03-05"" & !is.na(light_score)) %>%
  mutate(light_score = light_score/100) %>%
  group_by(date, light_score) %>%
  summarise(n = n())

summary(mp_bird_collisions$date)
```

```{r}
mp_bird_collisions %>%
  ggplot(aes(date, light_score, color = n)) +
  geom_point(aes(size = n), alpha = 0.25) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = ""Date"", 
       y = ""Average % of window bays illuminated"",
       title = ""More bird collisions occur when more windows are illuminated"",
       subtitle = ""McCormick Place Between 3/6/2000 and 5/26/2018"")
```

```{r}
mp_bird_collisions %>%
  ggplot(aes(light_score, n)) +
  geom_point() +
  scale_x_continuous(labels = scales::percent_format()) +
  geom_smooth(method = ""loess"") +
  labs(x = ""Average % of window bays illuminated"", 
       y = ""# of bird collisions"",
       title = ""More bird collisions occur when more windows are illuminated"",
       subtitle = ""McCormick Place Between 3/6/2000 and 5/26/2018"")
```

Fit a Poisson model for comparison.

```{r}
mod_pois <- glm(n ~ light_score, data = mp_bird_collisions, family = poisson)
summary(mod_pois)
pcount_pois <- colSums(pscl::predprob(mod_pois))[0:10]
```

Fit a negative binomial regression model to the data.

```{r}
mod_negb <- MASS::glm.nb(n ~ light_score, data = mp_bird_collisions)
summary(mod_negb)
```

```{r}
ocount <- table(mp_bird_collisions$n)[0:10]
pcount_negb <- colSums(pscl::predprob(mod_negb))[0:10]
data.frame(ocount, pcount_pois, pcount_negb)
```

#### Conclusion
The Negative Binomial Regression model fits better than the Poisson model.","2019-18"
"989",977,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","christmas_birds.Rmd","---
title: ""Christmas Birds""
author: ""Tony Galvan""
date: ""6/17/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
theme_set(theme_light())

bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")
```

```{r}
bird_counts %>%
  summary()
```

This data is from 1921 to 2017.

```{r}
bird_counts %>%
  group_by(year) %>%
  summarise(total = sum(how_many_counted)) %>%
  ggplot(aes(year, total)) +
  geom_line() + 
  labs(x = """",
       y = ""# of birds"",
       title = ""Christmas birds counted"",
       subtitle = ""from 1921 to 2017"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Bird Studies Canada"")
```

```{r}
bird_counts %>%
  filter(!is.na(total_hours)) %>%
  group_by(year) %>%
  summarise(hours = mean(total_hours)) %>%
  ggplot(aes(year, hours)) +
  geom_line() + 
  labs(x = """",
       y = ""# of hours"",
       title = ""Hours spent counting Christmas birds"",
       subtitle = ""from 1921 to 2017"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Bird Studies Canada"")
```

","2019-18"
"990",979,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","french_trains.Rmd","---
title: ""french_trains""
author: ""Tony Galvan""
date: ""February 28, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## French Train Delays
### TidyTuesday 2019 Week 9

```{r}
library(tidyverse)

theme_set(theme_light())
```

```{r}
small_trains <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/small_trains.csv"") 
```

Glimpse the data
```{r}
glimpse(small_trains)
```

Do some pre-processing of the data:

* Create a date variable combining the year and day
```{r}
trains_processed <- small_trains %>%
  mutate(date = lubridate::ymd(paste(year, month, 1, sep = ""-"")))

summary(trains_processed$date)
```

The data goes from January 2015 to November 2018.  Let's plot the number of trains arriving late over time.
```{r}
trains_processed %>%
  group_by(date) %>%
  summarise(late_total = sum(num_arriving_late, na.rm = TRUE)) %>%
  ggplot(aes(date, late_total)) +
  geom_line() + 
  geom_smooth(method = ""lm"") +
  labs(x = """",
       y = ""# of trains arriving late"",
       title = ""French trains arriving late"",
       subtitle = ""Increasing from Jan 2015 to Nov 2018"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SNCF"")
```

Let's plot this as percentages of the total number of trips
```{r}
trains_processed %>%
  group_by(date) %>%
  summarise(pct_late = sum(num_arriving_late, na.rm = TRUE) / 
              sum(total_num_trips, na.rm = TRUE)) %>%
  ggplot(aes(date, pct_late)) +
  geom_line() + 
  scale_y_continuous(labels = scales::percent_format()) +
  geom_smooth(method = ""lm"") +
  labs(x = """",
       y = ""% of trains arriving late"",
       title = ""Percentage of French trains arriving late"",
       subtitle = ""Increasing from Jan 2015 to Nov 2018"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SNCF"")
```


Are there any trends for late arriving trains by month?
```{r}
avg_pct_late <- sum(trains_processed$num_arriving_late, na.rm = TRUE) / 
  sum(trains_processed$total_num_trips, na.rm = TRUE)

p <- trains_processed %>%
  mutate(month_name = month.name[month]) %>%
  group_by(month_name) %>%
  summarise(pct_late = sum(num_arriving_late, na.rm = TRUE) / 
              sum(total_num_trips, na.rm = TRUE)) %>%
  mutate(month_name = fct_reorder(month_name, pct_late),
         above_or_below_avg = if_else(pct_late > avg_pct_late, ""above"", ""below"")) %>%
  ggplot(aes(month_name, pct_late, fill = above_or_below_avg)) +
  geom_col(show.legend = FALSE) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = c(""#0568ae"", ""#d2d2d2"")) +
  geom_hline(yintercept = avg_pct_late, linetype = 2) +
  annotate(""text"", x = ""January"", y = avg_pct_late + 0.005, angle = 90, 
           size = 3, label = ""13.5% average"") +
  coord_flip() +
  labs(x = """",
       y = ""% of trains arriving late"",
       title = ""% of French trains arriving late"",
       subtitle = ""Summer and Fall trains are late more often"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SNCF"")
p
ggsave(""sncf.png"", p)
```

","2019-09"
"991",980,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","house_mortgage.Rmd","---
title: ""House and Mortgage data""
author: ""Tony Galvan""
date: ""February 6, 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages message=FALSE, warning=FALSE, error=FALSE}
library(tidyverse)
library(maps)
library(gganimate)
library(USAboundaries)

theme_set(theme_light())
```


```{r}
state_hpi <- read.csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"", stringsAsFactors = FALSE)
```

# State HPI

```{r}
state_hpi_processed <- state_hpi %>% 
  left_join(data.frame(I(state.abb), I(state.name), state.region,  
                             state.division, I(state.area),
                             state.center[[1]], state.center[[2]]), 
            by = c(""state"" = ""state.abb"")) %>%
  rename(region = state.region, division = state.division, name = state.name, 
         area = state.area, x = state.center..1.., y = state.center..2..) %>%
  mutate(price_index_diff = price_index - us_avg,
         name = as.character(ifelse(state == ""DC"", ""Washington D.C."", name)),
         region = factor(ifelse(state == ""DC"", 2, region)),
         division = factor(ifelse(state == ""DC"", 3, division)),
         area =  ifelse(state == ""DC"", 68.34, area),
         x = ifelse(state == ""DC"", -77.0369, x),
         y = ifelse(state == ""DC"", 38.9072, y),
         date = as.Date(paste(year, month, ""01"", sep = ""-"")))

levels(state_hpi_processed$region) <- levels(state.region)
levels(state_hpi_processed$division) <- levels(state.division)
state_hpi_processed$state_lower <- tolower(state_hpi_processed$name)
```

How has the home price index changed over time by region?

```{r}
state_hpi_processed %>%
  group_by(year, region) %>%
  summarise(avg_diff = mean(price_index_diff)) %>%
  ggplot(aes(x = year, y = avg_diff, color = region)) + 
  geom_line(size = 1)
```

How has the home price index changed over time by division?

```{r}
state_hpi_processed %>%
  group_by(year, division) %>%
  summarise(avg_diff = mean(price_index_diff)) %>%
  ggplot(aes(x = year, y = avg_diff, color = division)) + 
  geom_line(size = 1)
```



```{r}
map <- map_data(""state"")

state_hpi_processed %>%
  filter(year == 2018) %>%
  group_by(state_lower) %>%
  summarise(avg_diff = mean(price_index_diff),
            area = mean(area),
            x = mean(x),
            y = mean(y)) %>%
  ggplot(aes(fill = avg_diff)) +
  geom_map(aes(map_id = state_lower), map = map) +
  expand_limits(x = map$long, y = map$lat) + 
  theme_void() +
  coord_map() +
  labs(title = ""2018 House Price Index (HPI) difference from the US average"")
```


```{r}
state_hpi_yearly <- state_hpi %>% 
  mutate(price_index_diff = price_index - us_avg,
         date = as.Date(paste(year, month, ""01"", sep = ""-""))) %>%
  group_by(year, state) %>%
  summarise(avg_price_index_diff = mean(price_index_diff)) %>%
  inner_join(us_states(), by = c(""state"" = ""state_abbr"")) %>% 
  filter(name != ""Alaska"", 
         name != ""Hawaii"", 
         jurisdiction_type != ""territory"")

state_hpi_yearly %>% 
  ggplot() +
  geom_sf(aes(fill = avg_price_index_diff)) +
  scale_fill_gradient2(low = ""red"", high = ""blue"", mid = ""white"", midpoint = 0) + 
  #facet_wrap(~year)
  labs(title = ""Home Price Index difference from US Average in {frame_time}"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: FreddieMac"") + 
  transition_time(year) +
  coord_sf() + 
  theme_void() + 
  theme(panel.grid = element_line(color = 'white'))
```


```{r, eval=FALSE, echo=FALSE}
anim_save(filename = ""hpi.gif"", animation = last_animation())
```

","2019-19"
"992",981,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","media_franchises.Rmd","---
title: ""Media Franchises""
author: ""Tony Galvan""
date: ""7/1/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
theme_set(theme_light())

media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"") %>%
  distinct()
```

Let's look at the data.

```{r}
media_franchises %>%
  glimpse()
```

Which media franchises have the highest total revenue?

```{r}
top10_media_franchises <- media_franchises %>%
  group_by(franchise) %>%
  summarise(total_revenue = sum(revenue)) %>%
  top_n(10) %>%
  mutate(franchise = fct_reorder(franchise, total_revenue)) 

top10_media_franchises %>%
  ggplot(aes(franchise, total_revenue, fill = franchise)) +
  geom_col(show.legend = FALSE) + 
  scale_y_continuous(labels = scales::dollar_format()) +
  coord_flip() + 
  labs(x = ""Franchise"",
       y = ""Revenue (in billions)"",
       title = ""Top 10 media franchises by revenue"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Wikipedia"")
```

Which categories have the highest total revenue?

```{r}
media_franchises %>%
  group_by(revenue_category) %>%
  summarise(total_revenue = sum(revenue)) %>%
  mutate(revenue_category = fct_reorder(revenue_category, total_revenue)) %>%
  ggplot(aes(revenue_category, total_revenue, fill = revenue_category)) +
  geom_col(show.legend = FALSE) + 
  scale_y_continuous(labels = scales::dollar_format()) +
  coord_flip() + 
  labs(x = ""Category"",
       y = ""Revenue (in billions)"",
       title = ""Revenue by category"",
       subtitle = ""For media franchises"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Wikipedia"")
```

What is the breakdown of the top media franchise revenue by the top categories?

```{r}
top10_media_franchises %>%
  inner_join(media_franchises) %>%
  mutate(franchise = fct_reorder(franchise, total_revenue))  %>%
  ggplot(aes(franchise, revenue, fill = revenue_category)) +
  geom_col() + 
  scale_y_continuous(labels = scales::dollar_format()) +
  coord_flip() + 
  labs(x = ""Franchise"",
       y = ""Revenue (in billions)"",
       fill = ""Category"",
       title = ""Most revenue comes from merchandise, licensing & retail"",
       subtitle = ""For 7 of top 10 media franchises by total revenue"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Wikipedia"")
```

#### Appendix

Future work:

* Explore the top creators, owners, original media
* Look at revenue in relation to the year the franchise was created







","2019-27"
"993",982,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","meteorites.Rmd","---
title: ""meteorites""
author: ""Tony Galvan""
date: ""6/14/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(tidyverse)
theme_set(theme_light())

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  filter(!is.na(year) & !is.na(mass)) %>%
  mutate(decade = 10 * (year %/% 10))
```

```{r}
meteorites %>%
  ggplot(aes(decade)) +
  geom_histogram(binwidth = 30)
```

There are some meteorites found a long time ago, but most were found after 1800.

What classes of meteorites are found the most?

```{r}
meteorites %>%
  mutate(class = fct_lump(class, 24)) %>%
  count(class, sort = TRUE) %>%
  mutate(class = fct_reorder(class, n)) %>%
  ggplot(aes(class, n, fill = class)) + 
  geom_col(show.legend = FALSE) + 
  coord_flip() + 
  labs(x = ""Class"",
       y = ""# of meteorites"",
       title = ""Top meteorite classes"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Meteoritical Society"")
```

What does the distribution of the mass look like?

```{r}
meteorites %>%
  mutate(log_mass = log10(mass)) %>%
  ggplot(aes(log_mass)) +
  geom_histogram()
```


```{r}
meteorites %>%
  mutate(class = fct_lump(class, 24)) %>%
  ggplot(aes(long, lat, size = mass, color = class)) + 
  geom_point(alpha = 0.5) + 
  coord_map() + 
  theme_void() + 
  theme(legend.position = ""none"") +
  facet_wrap(~class)
```



```{r}
meteorites %>%
  filter(!is.na(mass) & mass > 0) %>%
  group_by(decade) %>%
  summarise(n = n(),
            average = mean(mass),
            heaviest = max(mass),
            lightest = min(mass))
```

#### Future work

* Put a maps behind the points in the viz above
* Box plot of the masses of the top 8 classes","2019-24"
"994",983,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","moores_law.Rmd","---
title: ""Moore's Law""
author: ""Tony Galvan""
date: ""9/3/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r ttsetup, echo=FALSE, warning=FALSE, message=FALSE}
# Load libraries, set the default theme & caption, and grab the data
library(tidyverse)
theme_set(theme_light())

default_caption <- ""Source: Wikipedia  |  Designer: Tony Galvan @gdatascience1""

cpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/cpu.csv"")

gpu <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/gpu.csv"")

ram <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-09-03/ram.csv"")
```

```{r}
cpu %>%
  ggplot(aes(date_of_introduction, transistor_count, color = if_else(designer == ""Intel"", ""Intel"", ""Other""))) +
  geom_point(alpha = 0.5) + 
  scale_y_log10(labels = scales::comma_format()) + 
  scale_color_manual(values = c(""darkblue"", ""gray50"")) +
  labs(x = """",
       y = ""# of transistors"",
       color = ""CPU Designer"",
       title = ""Is Moore's Law true?"",
       subtitle = ""The number of transistors in a dense integrated circuit\ndoubles approximately every two years"",
       caption = default_caption)

##ggsave(""moores_law.png"", width = 6, height = 4)
```

","2019-36"
"995",984,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","nobel_prizes.Rmd","---
title: ""nobel_prize""
author: ""Tony Galvan""
date: ""5/13/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(tidyverse)

theme_set(theme_minimal())

nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")
```

```{r}
nobel_winners %>%
  group_by(laureate_id, birth_country) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  ungroup() %>%
  mutate(birth_country = fct_lump(birth_country, n = 7)) %>%
  group_by(birth_country) %>%
  summarise(n2 = n()) %>%
  filter(!is.na(birth_country)) %>%
  mutate(birth_country = fct_reorder(birth_country, n2)) %>%
  ggplot(aes(birth_country, n2, fill = birth_country)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(x = """",
       y = ""# of multiple Nobel Prize winners"", 
       title = ""The USA has the most multiple Nobel Prize winners"")
```

","2019-20"
"996",985,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","nuclear_explosions.Rmd","---
title: ""nuclear_explosions""
author: ""Tony Galvan""
date: ""8/19/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
theme_set(theme_light())

nuclear_explosions <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"") %>%
  mutate(country = fct_recode(country, 
                              ""United States"" = ""USA"",
                              ""Russia"" = ""USSR"",
                              ""France"" = ""FRANCE"",
                              ""United Kingdom"" = ""UK"",
                              ""China"" = ""CHINA"",
                              ""India"" = ""INDIA"",
                              ""Pakistan"" = ""PAKIST""),
         date  = ymd(date_long),
         decade = 10 * (year %/% 10),
         day_of_decade = yday(date) * (year - decade + 1),
         president = case_when(date < ""1953-01-20"" ~ ""Truman"",
                               date < ""1961-01-20"" ~ ""Eisenhower"",
                               date < ""1963-11-22"" ~ ""Kennedy"",
                               date < ""1969-01-20"" ~ ""Johnson"",
                               date < ""1974-08-09"" ~ ""Nixon"",
                               date < ""1977-01-20"" ~ ""Ford"",
                               date < ""1981-01-20"" ~ ""Carter"",
                               date < ""1989-01-20"" ~ ""Reagan"",
                               date < ""1993-01-20"" ~ ""Bush (H. W.)"",
                               TRUE ~ ""Clinton"")) %>%
  select(-date_long)

summary(nuclear_explosions)
```

President data from https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States

#### Which countries conducted nuclear weapons tests?

```{r}
nuclear_explosions %>%
  count(country, sort = TRUE) %>%
  mutate(country = fct_reorder(country, n)) %>%
  ggplot(aes(country, n)) +
  geom_col(aes(fill = country), show.legend = FALSE) + 
  coord_flip() + 
  geom_text(aes(label = n, color = country), show.legend = FALSE,
            nudge_y = 40, size = 4, fontface = ""bold"") + 
  labs(x = """",
       y = ""# of nuclear weapons tests"",
       title = ""Nuclear weapons tests conducted 1945 - 1998"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SIPRI"")
```

#### Map the nuclear weapons tests

```{r}
nuclear_explosions %>%
  ggplot(aes(longitude, latitude, size = yield_upper)) +
  borders(""world"", colour = ""gray75"", fill = ""gray75"") +
  geom_point(aes(fill = country), pch = 21, color = ""black"", alpha = 0.5) +
  coord_quickmap() + 
  theme_void() + 
  labs(size = ""Blast yield (in tons)"",
       fill = ""Country"",
       title = ""Nuclear weapons tests conducted 1945 - 1998"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SIPRI"")
```

#### Create an overlayed step plot

```{r}
nuclear_explosions %>%
  filter(date > ""1949-12-31"" & date < ""1990-01-01"") %>%
  group_by(day_of_decade, decade) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  mutate(counter = 1) %>%
  group_by(decade) %>%
  mutate(counter = cumsum(n)) %>%
  ungroup() %>%
  ggplot(aes(day_of_decade, counter, group = decade, color = factor(decade))) + 
  geom_step() + 
  scale_color_discrete(labels = c(""1950's"", ""1960's"", ""1970's"", ""1980's"")) +
  scale_x_continuous(breaks = c(750, 3000),
                     labels = c(""Beginning of the decade"", ""End of the decade"")) +
  labs(x = """",
       y = ""# of nuclear weapons tests"",
       color = ""Decade"",
       title = ""Nuclear weapons tests conducted by decade: 1950's - 1980's"",
       subtitle = ""The number of tests flattens out toward the end of every decade"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SIPRI"")
```


```{r}
ggsave(""nuclear_explosions.png"", width = 5.75)
```

#### Create a bar plot by U.S. President

```{r}
nuclear_explosions %>%
  filter(country == ""United States"" & 
           president != ""Truman"" & president != ""Clinton"") %>%
  group_by(president) %>%
  summarise(n = n()) %>%
  mutate(president = fct_reorder(president, n)) %>%
  ggplot(aes(president, n, fill = president)) + 
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(x = """",
       y = ""# of nuclear weapons tests"",
       title = ""Nuclear weapons tests conducted by U.S. Presidents"",
       subtitle = ""Between 1/20/1953 and 1/20/1993"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SIPRI"")
```

#### Create a step plot by U.S. President

```{r}
nuclear_explosions %>%
  filter(country == ""United States"") %>%
  group_by(president) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  bind_rows(data.frame(president = ""Clinton"", n = 0)) %>%
  mutate(president = fct_reorder(president, n)) %>%
  ggplot(aes(president, n, fill = president)) + 
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(x = """",
       y = ""# of nuclear weapons tests"",
       title = ""Nuclear weapons tests conducted by U.S. Presidents 1945 - 1998"",
       subtitle = ""Bill Clinton did not conduct any nuclear weapons tests during this time"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: SIPRI"")
```

```{r}
ggsave(""nuclear_presidents.png"", width = 6.5)
```","2019-34"
"997",986,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","plastic_waste.Rmd","---
title: ""Plastice Waste""
author: ""Tony Galvan""
date: ""8/23/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# load tidyverse library and data; set the default theme
library(tidyverse)
library(scales)
theme_set(theme_light())

coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"")

mismanaged_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-mismanaged-plastic-waste-vs-gdp-per-capita.csv"")

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"")
```

```{r}
library(janitor)

# Create a function to clean the data sets
clean_data_set <- function(data_set) {
  data_set %>%
    clean_names() %>%
    rename(country = entity) %>%
    filter(year == 2010) %>%
    select(-year)
}

plastic_waste <- coast_vs_waste %>%
  clean_data_set() %>%
  inner_join(clean_data_set(mismanaged_vs_gdp), by = c(""country"", ""code"")) %>%
  inner_join(clean_data_set(waste_vs_gdp), by = c(""country"", ""code"")) %>%
  select(country, 
         code, 
         population = total_population_gapminder, 
         coastal_population, 
         gdp_per_capita = gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
         waste = mismanaged_plastic_waste_tonnes,
         waste_per_capita = per_capita_mismanaged_plastic_waste_kilograms_per_person_per_day)
```

#### Bring in continent data

```{r}
library(countrycode)

df <- data.frame(plastic_waste)

plastic_waste$continent <- countrycode(sourcevar = df[,""country""], 
                                       origin = ""country.name"",
                                       destination = ""continent"")
plastic_waste %>%
  filter(is.na(continent))
```


#### Is there a relationship between log of GDP per capita and kilograms of plastic waste per person per day?

```{r}
g1 <- plastic_waste %>%
  arrange(-population) %>%
  ggplot(aes(gdp_per_capita, waste_per_capita)) +
  geom_point(aes(color = continent, size = population)) + 
  geom_text(aes(label = country), vjust = 1, hjust = 1, check_overlap = TRUE) +
  scale_x_log10(labels = dollar_format()) +
  scale_y_log10() +
  scale_size_continuous(guide = FALSE) +
  labs(x = ""GDP per capita (log scale)"",
       y = ""Mismanaged plastic waste (kg per person per day)"",
       color = ""Continent"",
       title = ""Do wealthier countries manage plastic waste better than poor ones?"",
       subtitle = ""Chart shows data from 2010; size = total population"",
       caption = ""Influenced by: David Robinson  |  Source: Our World In Data"")

## Future work:  color by continent
g1
```

#### Plot David Robinson's quote

```{r}
library(magick)
dr_quote <- data.frame(line1 = '""Go to war with the data you have ...', 
                       line2 = '... not the data you want""',
                       author = ""David Robinson"")

dr_image <- image_read(""https://pbs.twimg.com/profile_images/876529727284039680/dfvG_Dy4_400x400.jpg"")

ggplot(dr_quote, aes()) + 
  geom_text(aes(0, 0.5, label = line1), size = 7.5, fontface = ""bold"") +
  geom_text(aes(0, 0.25, label = line2), size = 7.5, fontface = ""bold"") +
  geom_text(aes(0, 0, label = author), size = 6) +
  theme_void() + 
  scale_y_continuous(limits = c(-1, 1)) + 
  labs(caption = ""Designer: Tony Galvan @gdatascience1  |  Source: https://youtu.be/BRdLOYtJk9o"")

ggsave(""quote.png"")
quote_image <- image_read(""quote.png"")
final_image <- image_composite(quote_image, dr_image, offset = ""+625+575"")
image_write(final_image, ""drob_quote.png"")
```

#### Where is plastic waste mismanaged?

```{r}
library(fuzzyjoin)

iso3166 <- as_tibble(maps::iso3166)

plastic_data <- plastic_waste %>%
  inner_join(iso3166, by = c(""code"" = ""a3"")) 

map_data(""world"") %>%
  as_tibble() %>%
  filter(region != ""Antarctica"") %>%
  regex_left_join(plastic_data, by = c(""region"" = ""mapname"")) %>%
  ggplot(aes(long, lat, group = group, fill = waste_per_capita)) + 
  geom_polygon() + 
  scale_fill_gradient2(trans = ""log10"",
                       low = ""dark blue"",
                       high = ""orange"",
                       mid = ""grey"",
                       midpoint = log10(0.02)) +
  coord_fixed(2) + 
  ggthemes::theme_map() + 
  labs(fill = ""Mismanaged plastic waste per capita"",
       title = ""Where is plastic waste mismanaged?"", 
       caption = ""Influenced by: David Robinson  |  Source: Our World In Data"")
```

#### Pull in other indicators

```{r}
library(WDI)

wdi_data <- WDI(indicator = c(""co2_emissions_per_capita"" = ""EN.ATM.CO2E.PC""), 
                  start = 2010, end = 2010) %>%
  as.tibble() %>%
  select(-country)

plastic_with_indicators <- wdi_data %>%
  inner_join(plastic_data, by = c(iso2c = ""a2"")) %>%
  arrange(desc(population))

g2 <- plastic_with_indicators %>%
  ggplot(aes(gdp_per_capita, co2_emissions_per_capita)) +
  geom_point(aes(color = continent, size = population)) +
  geom_text(aes(label = country), vjust = 1, hjust = 1, check_overlap = TRUE) +
  scale_size_continuous(guide = FALSE) +
  scale_x_log10(labels = dollar_format()) +
  scale_y_log10() +
  labs(x = ""GDP per capita (log scale)"",
       y = ""CO2 emissions (tons per capita)"",
       color = ""Continent"", 
       title = ""Do wealthier countries manage CO2 emissions better than poor ones?"",
       subtitle = ""Chart shows data from 2010; size = total population"",
       caption = ""Influenced by: David Robinson  |  Source: Our World In Data"")

library(patchwork)

g2 +
  labs(title = ""CO2 emissions are correlated with country income, but not plastic waste"",
       caption = """") + 
  scale_color_discrete(guide = FALSE) +
  g1 +
  labs(title = """",
       subtitle = """")

ggsave(""plastic_vs_co2.png"", width = 10, height = 6)
```

","2019-21"
"998",987,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","simpsons.Rmd","---
title: ""Simpsons Guest Stars""
author: ""Tony Galvan""
date: ""8/26/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load libraries, set the default theme & caption, and grab the data
library(tidyverse)
library(patchwork)
theme_set(theme_light())

default_caption <- ""Source: Wikipedia  |  Designer: Tony Galvan @gdatascience1  |  #TidyTuesday 2019 Week 35""

simpsons <- readr::read_delim(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-27/simpsons-guests.csv"", delim = ""|"", quote = """")

glimpse(simpsons)
```

#### Which season had the most guest stars?

```{r}
p1 <- simpsons %>%
  filter(season != ""Movie"") %>%
  group_by(season) %>%
  summarise(n = n()) %>%
  mutate(season = as.integer(str_replace(season, ""Movie"", ""0""))) %>%
  ggplot(aes(season, n)) +
  geom_line(color = ""#FED90F"", size = 3) +
  scale_x_continuous(breaks = c(1, 10, 20, 30), labels = c(1, 10, 20, 30)) +
  geom_smooth(method = ""lm"", se = FALSE, 
              color = ""#70D1FE"", linetype = 5, size = 2) +
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),) +
  labs(x = ""Season"",
       y = ""# of guest stars"",
       title = ""The Simpsons: guest stars per season"",
       subtitle = ""Seasons 1 - 30"",
       caption = default_caption)

p1
```

#### Which guest stars had the most unique roles?

```{r}
roles <- simpsons %>%
  unnest(role = strsplit(role, "";"")) %>%
  mutate(role_name = if_else(role %in% c(""Himself"", ""Herself"", ""Themselves""), guest_star, role))

glimpse(roles)
```

```{r}
p2 <- roles %>%
  group_by(role_name, guest_star) %>%
  summarise(n = n()) %>%
  group_by(guest_star) %>%
  summarise(star_roles = n()) %>%
  top_n(10, wt = star_roles) %>%
  mutate(guest_star = fct_reorder(guest_star, star_roles)) %>%
  ggplot(aes(guest_star, star_roles)) +
  geom_col(fill = ""#FED90F"") + 
  coord_flip() +
  theme(panel.border = element_blank(),
        panel.grid = element_blank(),) +
  labs(x = """",
       y = ""# of unique roles"",
       title = ""Top 10 guest stars with the most unique roles"",
       subtitle = ""The Simpsons: seasons 1 - 30"",
       caption = default_caption)

p2
```

#### Combine the 2 plots

```{r}
p1 + 
  labs(title = ""The Simpsons: seasons 1 - 30"",
       subtitle = ""More guest stars per season; Maurice LaMarche has played the most unique roles"",
       caption = """") +
  p2 +
  labs(title = """",
       subtitle = """")

#ggsave(""simpsons.png"", width = 10)
```

","2019-35"
"999",989,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","student_teacher_ratio.Rmd","---
title: ""student_teacher_ratio""
author: ""Tony Galvan""
date: ""5/9/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
library(tidyverse)

theme_set(theme_minimal())

student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"")
```

What years are covered in this data?

```{r}
summary(student_ratio)
```

Load the GDP per capita for 2012 to 2018 and join it to our data.

```{r}
library(WDI)

gdp_per_capita <- WDI(indicator = ""NY.GDP.PCAP.CD"", start = 2012, end = 2018, 
                      extra = TRUE) %>%
  tbl_df() %>%
  transmute(year, country_code = as.character(iso3c), 
           gdp_per_capita = NY.GDP.PCAP.CD)

student_ratio_GDP <- student_ratio %>%
  inner_join(gdp_per_capita, by = c(""country_code"", ""year"")) %>%
  filter(!is.na(student_ratio))
```

Let's plot a histogram of student/teacher ratios on a log scale.

```{r}
student_ratio_GDP %>%
  ggplot(aes(student_ratio)) + 
  geom_histogram() + 
  scale_x_log10()
```

Let's create a scatter plot of student/teacher ratios with GDP per capita.

```{r}
student_ratio_GDP %>%
  ggplot(aes(gdp_per_capita, student_ratio, color = indicator)) +
  geom_point() + 
  scale_x_log10() + 
  scale_y_log10() + 
  geom_text(aes(label = paste(year, country, sep = "":"")), vjust = 1, hjust = 1, check_overlap = TRUE) +
  labs(x = ""GDP per capita"",
       y = ""Student/teacher ratio"",
       title = ""GDP per capita and student/teacher ratio are negatively correlated"",
       subtitle = ""2012 to 2018"")
```

","2019-19"
"1000",991,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","ufo_sightings.Rmd","---
title: ""ufo-sightings""
author: ""Tony Galvan""
date: ""6/24/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(tidytext)
library(sentimentr)
theme_set(theme_light())

ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"") %>%
  rownames_to_column(var = ""id"") %>%
  mutate(id = as.numeric(id),
         date = mdy(date_documented),
         year = year(date))
```

What date range is covered in this data?

```{r}
summary(ufo_sightings$date)
```

Let's look at UFO shapes.

```{r}
ufo_sightings %>%
  mutate(ufo_shape = if_else(is.na(ufo_shape), ""unknown"", ufo_shape),
         ufo_shape = fct_lump(ufo_shape, 10, other_level = ""other"")) %>%
  group_by(ufo_shape) %>%
  summarise(n = n()) %>%
  mutate(ufo_shape = fct_reorder(ufo_shape, n)) %>%
  ggplot(aes(ufo_shape, n, fill = ufo_shape)) +
  geom_col(show.legend = FALSE) + 
  coord_flip() + 
  labs(x = ""UFO shape"",
       y = ""# of sightings"",
       title = ""Top 10 UFO Shapes"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: NUFORC"")
```


Let's create a word cloud from the UFO sighting descriptions.

```{r}
ufo_sightings %>%
  unnest_tokens(tbl = ., output = word, input = description) %>%
  count(word, sort = TRUE) %>%
  filter(is.na(as.numeric(word))) %>%
  anti_join(get_stopwords()) %>%
  filter(n > 2000) %>%
  na.omit() %>%
  wordcloud2::wordcloud2(shape = ""cardiod"")
```

Perform sentiment analysis

```{r}
ufo_sentences <- ufo_sightings %>%
  pull(description) %>%
  get_sentences()
```

```{r}
ufo_sentiment <- sentiment_by(ufo_sentences)
```

```{r}
ufo_sightings %>%
  inner_join(ufo_sentiment, by = c(""id"" = ""element_id"")) %>%
  group_by(country) %>%
  summarise(avg_sentiment = mean(ave_sentiment)) %>%
  mutate(country = fct_reorder(country, avg_sentiment)) %>%
  ggplot(aes(country, avg_sentiment, fill = country)) +
  geom_col(show.legend = FALSE) +
  coord_flip()
```

```{r}
ufo_sightings %>%
  inner_join(ufo_sentiment, by = c(""id"" = ""element_id"")) %>%
  filter(country == ""us"") %>%
  group_by(state) %>%
  summarise(avg_sentiment = mean(ave_sentiment)) %>%
  mutate(state = fct_reorder(state, avg_sentiment)) %>%
  ggplot(aes(state, avg_sentiment, fill = state)) +
  geom_col(show.legend = FALSE) +
  coord_flip()
```

Let's plot US UFO sightings over time

```{r}
ufo_sightings %>%
  filter(country == ""us"" & state != ""hi"" & state != ""ak"" & state != ""pr"") %>%
  ggplot() + 
  geom_map(data = map_data(""state""), 
           map = map_data(""state""), 
           aes(long, lat, map_id = region, group = group),
           fill = ""white"", color = ""black"", size = 0.1) + 
  geom_point(aes(longitude, latitude), 
             size = 0.75, alpha = 0.25, color = ""blue"") +
  theme_void() + 
  coord_map() +
  gganimate::transition_states(year) +
  #facet_wrap(~year) + 
  labs(title = ""US UFO Sightings in {closest_state}"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: NUFORC"")
```

```{r, eval=FALSE, echo=FALSE}
gganimate::anim_save(filename = ""us_ufo_sightings.gif"", animation = gganimate::last_animation())
```

","2019-26"
"1001",993,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","video_games.Rmd","---
title: ""video_games""
author: ""Tony Galvan""
date: ""8/1/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Load libraries and data
Do some basic pre-processing:

* Change the game titles to title case
* Transform the release_date variable from string to date
* Create year and month variables
* Transform the owners variable to store lower number of the range
* Create a revenue variable by multiplying the owners by price
* Remove the unnecessary number variable

```{r}
library(tidyverse)
library(lubridate)
theme_set(theme_light())

video_games <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-30/video_games.csv"") %>%
  mutate(game = str_to_title(game),
         release_date = str_replace(release_date, ""8 Oct, 2014"", ""Oct 8, 2014""),
         release_date = mdy(release_date),
         release_year = year(release_date),
         release_month = month(release_date, label = TRUE),
         owners = as.numeric(gsub("","","""",str_extract(owners,""[0-9]+(,[0-9]+)*""))),
         owners = if_else(owners == 0, 1, owners),
         revenue = owners * price) %>%
  select(-number)
```

####Which games have the most owners?

```{r}
video_games %>%
  arrange(desc(owners)) %>%
  select(game, release_date, price, owners, revenue) %>%
  top_n(7, owners)
```

Why do so many of the top games have a missing price.  It turns out that these may be ""free to play"" games.

####How many games have a missing price?

```{r}
paste0(sum(is.na(video_games$price)), "" out of "", nrow(video_games), "" = "", round(100*sum(is.na(video_games$price))/nrow(video_games), 2), ""%"")
```

Are the missing prices ""free to play"" games or truly missing data?

####How are missing prices changing over time?

```{r}
video_games %>%
  filter(is.na(price)) %>%
  group_by(release_year) %>%
  summarise(n = n()) %>%
  ggplot(aes(release_year, n)) + 
  geom_col()
```


####How are game prices changing over time?

```{r}
video_games %>%
  ggplot(aes(release_date, price)) + 
  geom_point(alpha = 0.25) + 
  geom_smooth(method = ""lm"")
```

Prices are decreasing over time.  Could it be because of the increase in apps?

Let's look at average price by year.

```{r}
video_games %>%
  group_by(release_year) %>%
  summarise(avg_price = mean(price, na.rm = TRUE)) %>%
  ggplot(aes(release_year, avg_price)) + 
  geom_col() +
  geom_smooth(method = ""lm"")
```


####How do game prices change by month?

```{r}
avg_video_game_revenue <- mean(video_games$revenue, na.rm = TRUE)

video_games %>%
  group_by(release_year, release_month) %>%
  summarise(avg_revenue = mean(revenue, na.rm = TRUE)) %>%
  ggplot(aes(release_month, avg_revenue, fill = as.factor(release_month))) + 
  geom_col() + 
  facet_wrap(~release_year, scales = ""free_y"") +
  geom_hline(yintercept = avg_video_game_revenue, linetype = 2)
```


####Which games have the highest estimated revenue?

```{r}
video_games %>%
  arrange(desc(revenue)) %>%
  select(game, release_date, price, owners, revenue)
```


####What does revenue look like over time?

```{r}
video_games %>%
  ggplot(aes(release_date, revenue)) + 
  geom_point(alpha = 0.25) +
  geom_smooth(method = ""lm"")
```

Revenue is decreasing over time.  Let's look at revenue by year.

```{r}
video_games %>%
  group_by(release_year) %>%
  summarise(total_revenue = sum(revenue, na.rm = TRUE)) %>%
  ggplot(aes(release_year, total_revenue, fill = as.factor(release_year))) + 
  geom_col(show.legend = FALSE) +
  scale_y_continuous(labels = scales::dollar_format(scale = 0.000000001, suffix = ""B"")) + 
  labs(x = ""Release year"",
       y = ""Total revenue (in billions)"",
       title = ""2017 PC video games generated over $4 billion"",
       subtitle = ""Based on price multiplied by the number of owners"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Steam Spy"")
```


####Create a word cloud from game names

```{r}
video_games %>%
  tidytext::unnest_tokens(tbl = ., output = word, input = game) %>%
  count(word, sort = TRUE) %>%
  filter(is.na(as.numeric(word))) %>%
  anti_join(get_stopwords()) %>%
  filter(n > 100) %>%
  na.omit() %>%
  wordcloud2::wordcloud2(shape = ""cardiod"")
```

","2019-31"
"1002",995,"https://github.com/gdatascience/tidytuesday","gdatascience","tidytuesday","womens_world_cup.Rmd","---
title: ""Women's World Cup""
author: ""Tony Galvan""
date: ""7/8/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
theme_set(theme_light())

codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")
wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"") %>%
  left_join(codes, by = ""team"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
```

```{r}
glimpse(wwc_outcomes)
```

#### How many games are played each round by year?

```{r}
wwc_outcomes %>%
  group_by(year, round) %>%
  summarise(games = n() / 2) %>%
  ungroup() %>%
  mutate(round = fct_relevel(round, ""Final"", ""Third Place Playoff"", 
                             ""Semi Final"", ""Quarter Final"", ""Round of 16"")) %>%
  ggplot(aes(year, games, fill = round)) +
  geom_col()
```


#### Which countries have the most wins?

```{r}
wwc_outcomes %>%
  filter(win_status == ""Won"") %>%
  mutate(country = fct_lump(country, 9)) %>%
  group_by(country) %>%
  summarise(n = n()) %>%
  mutate(country = fct_reorder(country, n, desc = TRUE)) %>%
  ggplot(aes(country, n, fill = country)) + 
  geom_col(show.legend = FALSE) + 
  coord_flip() + 
  labs(x = """",
       y = ""# of wins"",
       title = ""Countries with the most Women's World Cup wins"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Wikipedia"")
```

#### Which countries have the most losses?

```{r}
wwc_outcomes %>%
  filter(win_status == ""Lost"") %>%
  mutate(country = fct_lump(country, 9)) %>%
  group_by(country) %>%
  summarise(n = n()) %>%
  mutate(country = fct_reorder(country, n, desc = TRUE)) %>%
  ggplot(aes(country, n, fill = country)) + 
  geom_col(show.legend = FALSE) + 
  coord_flip() + 
  labs(x = """",
       y = ""# of losses"",
       title = ""Countries with the most Women's World Cup losses"",
       caption = ""Designer: Tony Galvan @gdatascience1  |  Source: Wikipedia"")
```

#### How has scoring changed over time?

```{r}
wwc_outcomes %>%
group_by(year) %>%
summarise(goals = sum(score)) %>%
ggplot(aes(year, goals)) + 
geom_col() +
geom_smooth(method = ""loess"", se = FALSE)
```

```{r}
avg_age <- squads %>%
  group_by(country) %>%
  summarise(avg_age = mean(age)) %>%
  mutate(country = fct_recode(country, ""United States"" = ""US""))

wwc_outcomes %>%
  left_join(avg_age, by = ""country"") %>%
  group_by(win_status) %>%
  summarise(avg_age = mean(avg_age, na.rm = TRUE)) %>%
  ggplot(aes(win_status, avg_age, fill = win_status)) + 
  geom_col(show.legend = FALSE) + 
  coord_flip()
```

#### Histogram of the score variable

```{r}
wwc_outcomes %>%
  ggplot(aes(score)) +
  geom_histogram()
```

#### Combine the winning and losing team into a single observation

```{r}
wwc_winners <- wwc_outcomes %>%
  filter(win_status == ""Won"") %>%
  select(year, yearly_game_id, round, w_country = country, w_score = score) 

wwc_losers <- wwc_outcomes %>%
  filter(win_status == ""Lost"") %>%
  select(year, yearly_game_id, l_country = country, l_score = score) 
```


```{r}
wwc_winners %>%
  left_join(wwc_losers, by = c(""year"" = ""year"", 
                               ""yearly_game_id"" = ""yearly_game_id"")) %>%
  group_by(w_country, l_country) %>%
  summarise(games = n(),
            avg_score_diff = mean(w_score - l_score)) %>%
  filter(games > 2) %>%
  select(w_country, l_country, avg_score_diff) %>%
  circlize::chordDiagram(order = c(""United States"", ""China PR"", ""Brazil"", ""South Korea"", ""Norway"", ""France"", ""Japan"", ""Germany"", ""Nigeria"", ""Canada"", ""Sweden"", ""North Korea""))

title(""Women's World Cup: scoring differentials chord diagram 
      Designer: Tony Galvan @gdatascience1  |  Source: Wikipedia"")
```

","2019-28"
"1003",1046,"https://github.com/thebioengineer/TidyTuesday/tree/master/Fifa_World_Cup_Audience","thebioengineer","TidyTuesday","Fifa_World_Cup_Audience/Fifa_Analysis.Rmd","---
title: ""Tidy Tuesday: Fifa Audience""
author: ""Ellis Hughes""
output: rmarkdown::github_document
editor_options: 
  chunk_output_type: console
---

```{r dl_dataset, include=FALSE}
library(tidyverse)
fifa_audience<-read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week11_fifa_audience.csv"")
```

## First Look
The data provided for this [#TidyTuesday](https://github.com/rfordatascience/tidytuesday) is provided via [FiveThirtyEight.com](https://fivethirtyeight.com/features/how-to-break-fifa/).

```{r initial_look}
str(fifa_audience)
```

It looks like this dataset is actually pretty small, with stats for 191 countries and 6 variables including country name. 

## Initial Thoughts

The data shows what percent of the total viewership that watched the 2010 FIFA world cup. My first thought is what would be a key indicator for viewership. That would likely be rankings of your countries teams for the past 5 years. I will extract that information directly from the FIFA website, as well as the historical average ranking. Not all the country names matched between the two datasets. I attempted to match best I could figure. I apologize for any mistakes.

```{r Rankings, echo=TRUE, warning=FALSE}
library(rvest)

extractRankings<-function(url,country){
  
  urlhtml<-read_html(url)
  
  Rankings <- urlhtml%>%
    html_nodes("".col-xs-12"")%>%
    html_nodes("".tbl-ranking"")%>%
    html_table()%>%as.data.frame()%>%
    select(Rank,Date)
  
  Recent_Rankings<-Rankings%>%
    filter(Date<=2010, Date >= 2005)%>%
    {
      tmp<-rep(NA,6)
      names(tmp)<-paste0(""Ranking_"",2005:2010)
      if(nrow(.)>0){
        tmp[which(names(tmp)%in%paste0(""Ranking_"",.$Date))]<-.$Rank
      }
      return(tmp)
      }%>%
    as.data.frame%>%t
  
  Historical_Ranking<-Rankings%>%
    filter(Date<=2010)%>%
    data.frame%>%
    `$`(""Rank"")%>%
    as.numeric%>%
    mean(na.rm = TRUE)
  
  data.frame(Country=country,Recent_Rankings,Historical_Ranking=Historical_Ranking)
}

available_countries<-read_html(""https://www.fifa.com/fifa-world-ranking/associations/"")%>%
  html_nodes("".ranking-teamlist"") %>%
  html_nodes(""a"") %>%
  {data.frame(Country=html_text(.),link=html_attr(.,""href""), stringsAsFactors = FALSE)}%>%
  mutate(url=paste0(""https://www.fifa.com"",link))%>%
  select(Country,url)%>%
  mutate(Country=dplyr::recode(Country,
                               USA=""United States"",
                               England=""United Kingdom"",
                               ""China PR""=""China"",
                               ""Korea Republic""=""South Korea""
                               ))

available_countries%>%
  filter(Country %in% fifa_audience$country)%>%dim

rankings<-available_countries%>%
  filter(Country %in% fifa_audience$country)%>%
  split(., seq(nrow(.)))%>%
  map_df(function(.x){
    rankings<-try(extractRankings(.x$url,.x$Country))
    if(inherits(rankings,""try-error"")){
      data.frame(Country=.x$Country,NA,NA,NA,NA,NA,NA,NA)
    }else{
      rankings
    }})%>%
  rename(country=Country)

str(rankings)

```

Not every country was included in the FIFA rankings for every country, so we are left with `r nrow(rankings)`. Doing a quick linear regression between the years will give us an indicator which ranking is most significant for predicting viewership.

```{r Modeling, echo=FALSE, warning=FALSE}
library(car)

FIFA<-merge(fifa_audience,rankings,by=""country"")

rankingsLM<-lm(tv_audience_share~Historical_Ranking+Ranking_2010+Ranking_2009+Ranking_2008+Ranking_2007+Ranking_2006+Ranking_2005, data=FIFA)

Anova(rankingsLM, type=""III"")

```

Surprisingly, it looks like the previous year, and historical ranking are the most significant for predicting viewership for the world cup! 2009 rankings were the next most significant (but not very significant), and I found that 2009 rankings were used for the seeding of the world cup after some investigation online (wikipedia) and clicking on a link to [FIFA.com](https://web.archive.org/web/20111225043322/http://www.fifa.com/worldcup/archive/southafrica2010/finaldraw/news/newsid%3D1142262/). Considering that the world cup takes place partway though the 2010 year (June-July), the 2009 rankings could provide some insight.

## Visualization

I thought the most interesting way to show viewership would be comparing historical vs 2009 ranking, and setting the size of the points based on the population, and color by viewership share

```{r visualization_1}

library(ggrepel)


FIFA_PLOT<-ggplot(FIFA)+
  geom_point(aes(x=Historical_Ranking,y=Ranking_2009,color=tv_audience_share,size=population_share))+
  geom_abline(slope=1, intercept=0, color=""red"")+
  scale_x_reverse()+scale_y_reverse()+
  geom_label_repel(aes(label=country,x=Historical_Ranking,y=Ranking_2009),
                   data=FIFA[which(FIFA$tv_audience_share>3 | FIFA$population_share>5),],
                   arrow = arrow(length = unit(0.03, ""npc""), type = ""closed"", ends = ""last""),
                   force = 100,
                   nudge_x = 40)+
  ggtitle(""FIFA TV Viewer Share by Country"")


FIFA_PLOT
```

Interestingly, most of the countries with the large populations and viewership underperformed in the 2009 year versus their historical success. 

```{r save_vis, echo=FALSE}
png(""FIFA_Viewship.PNG"",width = 1000,height=1000)
FIFA_PLOT
dev.off()
  
```

","2018-11"
"1004",1072,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","6_5_208/Bike_Survival.R","library(data.table)
library(tidyverse)
library(survival)
library(survminer)


bikeData<-lapply(list.files(""PublicTripData/Quarterly/"",pattern = "".csv"",full.names = TRUE),function(filepath){
    fread(filepath,data.table = FALSE)
  })%>%
  do.call('rbind',.)%>%
  as.tibble%>%
  filter(Distance_Miles<50)

#If a bike has not been used within 30 days, assume removal from the system
removaldate<-max(as.Date(bikeData$StartDate,format=""%m/%d/%Y""))-30

bikeLevelData<-bikeData%>%
  filter(BikeName!="""")%>%
  group_by(BikeName)%>%
  mutate(StartDate=as.Date(StartDate,format=""%m/%d/%Y""))%>%
  summarise(
    usuallyCasual=sum(PaymentPlan==""Casual"")>sum(PaymentPlan==""Subscriber""),
    totalMiles=sum(Distance_Miles,na.rm=TRUE),
    RemovedFromService=max(StartDate,na.rm = TRUE)<removaldate
    )%>%
  data.frame()


coxphModel<-coxph(Surv(totalMiles,event=RemovedFromService)~usuallyCasual, data=bikeLevelData)

ggsurvplot(survfit(formula(coxphModel),data=bikeLevelData),
           conf.int = TRUE,
           risk.table = TRUE,
           legend=""none"",
           pval=TRUE,
           title=""Bike Survival by Ridership type"",
           xlab=""Miles""
          )
","2018-10"
"1005",1073,"https://github.com/thebioengineer/TidyTuesday","thebioengineer","TidyTuesday","Hurricanes_and_PuertoRico/Hurricanes_and_Puerto_Rico_Analysis.Rmd","---
title: ""Tidy Tuesday: Hurricanes & Puerto Rico""
author: ""Ellis Hughes""
output: 
  html_document:
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r dl_dataset, include=FALSE}
library(tidyverse)

Hurricane_Coverage_Online<-read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_mediacloud_hurricanes.csv"")%>%
   mutate(Date=as.Date(Date,""%m/%d/%y""))

Hurricane_Google_Trends<-read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/week12_google_trends.csv"",skip = 2)%>%
  rename(Date=""Day"")%>%
   mutate(Date=as.Date(Date,""%m/%d/%y""))

```

## Media Coverage by Hurricane and State
The data provided for this [#TidyTuesday](https://github.com/rfordatascience/tidytuesday) is provided via [FiveThirtyEight.com](https://fivethirtyeight.com/features/how-to-break-fifa/). It is a look at media coverage of the three major hurricanes of 2017. This was somewhat significant to me because I was on my honeymoon during this time period, and was in Barbados while some of this was occuring. Some of my new family was unable to make it to the wedding due to the hurricanes.

This specific datasets I am looking at is the Media Coverage of the hurricanes and the google search trends of the Hurricanes names. ""Media Coverage"" was calculated based off of the number of sentences mentiontion either the state or hurricane among the outlets in Media Cloud's ""U.S. Top Online News"" collection. I merged the two datasets together and was left with a dataset that covered August 20th to September 25th, 2017.

```{r initial_look}

coverage<-merge(Hurricane_Coverage_Online,Hurricane_Google_Trends,by=""Date"")

head(coverage)

```


## Google vs The Internet 

The reason I decided on these two data sets is that realistically google is the front door to the internet. When querying on the internet to learn more, google is usually the tool one would use. At the same time, I would surmise that querying leads to a higher probability of coverage due to the fact that internet news gets its revenue from page clicks. 

Unsurprisingly, the google trend highlights that the more the term is searched for, the more it is written about. Or vice versa.

However, one interesting thing I am seeing is a weekly cyclical pattern to the coverage of Hurricane Harvey. Perhaps something to look into at another time.

```{r Plotting, echo=FALSE, warning=FALSE}

coveragePlot<-coverage%>%
  {lapply(c(""Harvey"",""Irma"",""Maria"",""Jose""),
         function(Hurricane,data){
           data[,c(1,grep(Hurricane,colnames(data)))]%>%
             set_names(c(""Date"",""Media_Coverage"",""Google_Trends""))%>%
             mutate(Hurricane=Hurricane)
         }
         ,.)%>%{do.call('rbind',.)}}%>%
  ggplot(aes(x=Date))+
  geom_point(aes(y=Media_Coverage,size=Google_Trends,color=Hurricane))+
  ggthemes::theme_fivethirtyeight()+
  ggtitle(""Media Coverage over time,\ncompared to Google Search Trends"")

coveragePlot
```

```{r save_vis, echo=FALSE}
png(""Hurricane_Media_and_GoogleTrends.png"",width = 500,height=500)
coveragePlot
dev.off()
  
```
","2018-12"
"1006",1079,"https://github.com/ethantenison/TidyTuesday-","ethantenison","TidyTuesday-","nuclear_explosion.rmd","---
title: ""PhD's in the United States""
author: ""Ethan Tenison""
date: ""8/6/2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Source Nuclear Data 
```{r source, warning=FALSE}
library(readr)
library(lubridate)
library(tidyverse)

df <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-20/nuclear_explosions.csv"")

country_file <- ""https://raw.githubusercontent.com/google/dspl/master/samples/google/canonical/countries.csv""

country_codes <- read_csv(country_file)

```

## Data Cleaning 

```{r cleaning}

#Removing the country name variable. The name of lat and log are changed so that the final dataframe has coordinates for the explosions and the countries. 
country_codes <- select(country_codes, country, source.lat = latitude, source.long = longitude)

#Get data for plotting world map. Then rename countries so that they match the country_codes data frame, and ensure the former USSR countires have the same name. 


world.data <- left_join(map_data(""world""), data_frame(region = c(""USA"", ""Russia"", ""UK"", ""France"", ""India"", ""Pakistan"", ""China"", ""Georgia"", ""Ukraine"", ""Moldova"", ""Belarus"", ""Armenia"", ""Azerbaijan"", ""Kazakhstan"", ""Uzbekistan"", ""Turkmenistan"", ""Kyrgyzstan"", ""Tajikistan""), country = c(""US"", ""RU"", ""GB"", ""FR"", ""IN"", ""PK"", ""CN"", ""RU"", ""RU"", ""RU"", ""RU"", ""RU"" ,""RU"" ,""RU"" ,""RU"" ,""RU"" ,""RU"" ,""RU"")))

#Recode the TidyTuesday dataset to ensure the names match the country codes and then merge the two dataframes


df2 <- df %>% mutate(country = recode(country, ""USA"" = ""US"", ""USSR"" = ""RU"", ""UK"" = ""GB"", ""FRANCE"" = ""FR"", ""INDIA"" = ""IN"", ""PAKIST"" = ""PK"", ""CHINA"" = ""CN"")) %>% left_join(country_codes, by = ""country"")

```

```{r plotting}

#labels 
text.df <- df2 %>% select(source.long, source.lat, country) %>% unique 
text.df$label <- c(""USA"", ""USSR"", ""UK"", ""France"", ""China"", ""India"", ""Pakistan"")


#the actual plot.
df2 %>% ggplot() + geom_polygon(data = world.data, aes(x=long, y =lat, group= group), fill =""lightgray"") + 
  
  geom_polygon(data = world.data, aes(x=long, y =lat, group = group, fill = country), alpha = 0.8) +
    
  theme_void() + 
  
  theme(panel.background = element_rect(fill = ""grey8""), plot.background = element_rect(fill = ""grey8""), legend.position = ""none"", plot.title = element_text(color = ""lightgray"", hjust = 0.5), plot.caption = element_text(color = ""lightgray"", size = 8), plot.subtitle = element_text(color = ""lightgray"", size = 9, hjust=0.5)) + 
  
  geom_point(aes(x=source.long, y = source.lat), color = ""white"", size = 5.3) +
  
  geom_point(aes(x=source.long, y = source.lat, color = country), size = 4) +
  
  geom_point(aes(x = longitude, y = latitude, color = country, size = (yield_upper + yield_lower)/2)) + 
  
  geom_curve(aes(x= source.long, y = source.lat, xend = longitude, yend = latitude, color = country, size = (yield_upper + yield_lower)/2, alpha = 0.3)) +
  
  scale_fill_manual(values = c(""darkred"", ""mediumaquamarine"", ""navy"", ""orange"", ""springgreen3"", ""brown4"", ""slateblue"", ""lightgray"")) +
  
  scale_color_manual(values = c(""darkred"", ""mediumaquamarine"", ""navy"", ""orange"", ""springgreen3"", ""brown1"", ""slateblue"", ""lightgray"")) +
  
  geom_label(data = text.df, aes(x=source.long, y=source.lat, label = label, fill = country), color = ""white"", hjust =0, nudge_x=4, size =3) +
  
  labs(title = ""Nuclear Explosions (1945 - 1998)"", subtitle = ""Source country and target location of nuclear explosions. \nLine thickness indicates size of the bomb."", caption = ""Data: SIPRI. Plot: Ethan Tenison"")
  

    
```","2019-34"
"1007",1087,"https://github.com/deanmarchiori/tidytuesday/blob/master/bird-strike.Rmd","deanmarchiori","tidytuesday","bird-strike.Rmd","---
title: ""FAA Wildlife Strike Database""
author: ""Dean Marchiori""
date: ""7/23/2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(lubridate)
library(cowplot)

bird_impacts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-23/bird_impacts.csv"")
```


```{r}
p1 <- bird_impacts %>% 
  select(time, time_of_day, species) %>% 
  filter(!is.na(time), time >= 0) %>% 
  mutate(time_char = as.character(paste0(""000"",time)),
         species = fct_lump(species, 5)) %>% 
  mutate(hour = substr(time_char, nchar(time_char)-3, nchar(time_char)-2)) %>% 
  count(hour) %>% 
  mutate(ampm = ifelse(hour %in% c('00','01','02','03','04','05',
                                   '06','07','08','09', '10','11'), ""AM"", ""PM"")) %>% 
  filter(ampm == ""PM"") %>% 
  ggplot(aes(hour, n, group = 1)) +
  geom_line(colour = ""#429bf5"", alpha = 0.7, size = 1) +
  scale_x_discrete(expand = c(0, 0)) + 
  labs(y = """",
       x = """",
       title = ""PM"") +
  coord_polar() +
  theme_dark() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.background = element_rect(fill = ""transparent"", colour = NA)) 
```

```{r}
p2 <- bird_impacts %>% 
  select(time, time_of_day, species) %>% 
  filter(!is.na(time), time >= 0) %>% 
  mutate(time_char = as.character(paste0(""000"",time)),
         species = fct_lump(species, 5)) %>% 
  mutate(hour = substr(time_char, nchar(time_char)-3, nchar(time_char)-2)) %>% 
  count(hour) %>% 
  mutate(ampm = ifelse(hour %in% c('00','01','02','03','04','05',
                                   '06','07','08','09', '10','11'), ""AM"", ""PM"")) %>% 
  filter(ampm == ""AM"") %>% 
  ggplot(aes(hour, n, group = 1)) +
  geom_line(colour = ""#ff7940"", alpha = 0.7, size = 1) +
  theme_dark() +
  scale_x_discrete(expand = c(0, 0)) + 
  labs(y = """",
       x = """",
       title = ""AM"") +
  coord_polar() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.background = element_rect(fill = ""transparent"", colour = NA)) 
```


```{r}
p3 <- bird_impacts %>% 
  select(phase_of_flt) %>% 
  mutate(phase_of_flt = str_to_lower(phase_of_flt)) %>% 
  count(phase_of_flt, sort = TRUE) %>% 
  filter(phase_of_flt != ""unknown"", !is.na(phase_of_flt)) %>% 
  mutate(phase_of_flt = fct_recode(phase_of_flt, approach = ""arrival""), 
         phase_of_flt = fct_relevel(phase_of_flt, ""taxi"", ""take-off run"", 
                                    ""departure"", ""climb"", ""en route"", ""descent"", 
                                    ""approach"", ""landing roll"", ""parked"" )) %>% 
  ggplot(aes(phase_of_flt, n)) +
  geom_col(fill = ""#B5C949"", alpha = 0.7) +
  labs(title = ""Bird Strike During Flight Phases"",
       subtitle = ""FAA wildlife strike reports for the US big 4 airlines (1990 - present)"",
       x = ""Flight Phase"",
       y = ""Recorded Bird Strikes"",
       caption = ""source: FAA Wildlife Strike Database"") +
  theme_dark() +
  theme(plot.background = element_rect(fill = ""grey50"", colour = NA),
        axis.text = element_text(colour = ""grey20"")) 
```

```{r}
ggdraw() +
  draw_plot(p3) +
  draw_plot(p2, x = 0.1, y = 0.45, width = 0.2, height = 0.5) +
  draw_plot(p1, x = 0.3, y = 0.45, width = 0.2, height = 0.5) 
```


































","2019-18"
"1008",1088,"https://github.com/deanmarchiori/tidytuesday/blob/master/space-launches.Rmd","deanmarchiori","tidytuesday","space-launches.Rmd","---
title: ""Space Launches""
author: ""Dean Marchiori""
date: ""6/21/2019""
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

```{r}
library(tidyverse)
library(skimr)

launches <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-15/launches.csv')

```

```{r}
vehicles <- launches %>% 
  mutate(state_code = fct_recode(state_code, 
                                 `Soviet Union / Russia`  = ""SU"",
                                 `Soviet Union / Russia`  = ""RU""),
         state_code = fct_lump(state_code, 2),
         category = fct_recode(category,success = ""O"",
                               failure = ""F"")) %>% 
  filter(agency_type == ""state"",
         state_code != ""Other"") %>% 
  group_by(type) %>% 
  filter(!is.na(launch_date)) %>% 
  mutate(min_date = min(launch_date, na.rm = TRUE),
         max_date = max(launch_date, na.rm = TRUE)) %>% 
  group_by(type, state_code, category, min_date, max_date) %>% 
  count() %>% 
  spread(category, n, fill = 0) %>% 
  ungroup() %>% 
  mutate(type = fct_reorder(type, min_date, .desc = TRUE),
         total_launches = failure + success,
         success_pct = success / total_launches) %>% 
  filter(max_date < as.Date('2020-01-01')) %>% 
  filter(total_launches > 0) %>% 
  mutate(label = ifelse(total_launches > 134, glue::glue(""{as.character(type)}: {total_launches} launches""), NA))


ggplot(vehicles) +
  geom_segment(aes(x = min_date, 
                   xend = max_date, 
                   y = type, 
                   yend = type, 
                   colour = success_pct, 
                   alpha = total_launches), 
               lwd = 1) +
  geom_text(data = vehicles, 
            aes(max_date, type, label = label), 
            size = 3, 
            hjust = ""inward"", 
            colour = ""white"", 
            check_overlap = TRUE) +
  facet_wrap(~state_code, scales = ""free_y"", ncol = 1) +
  scale_colour_gradient2(low = ""red"", 
                         high = ""green"", 
                         mid = ""orange"", 
                         midpoint = 0.5, 
                         labels = scales::percent) +
  theme_dark() +
  theme(axis.text.y = element_blank(), 
        axis.ticks.y = element_blank(), 
        panel.grid.major.y  = element_blank())+
  scale_alpha(range = c(0.2, 1)) +
  guides(alpha = FALSE) +
  labs(title = ""How do the US and Russia compare in space?"",
       subtitle = ""Comparing state run launches for the US and Soviet Union/Russia since 1960. While Russia iterates launch vehicles less,\nthey far outweight US state launches."",
       x = """", 
       y = """",
       colour = ""Launch \nSuccess"",
       caption = ""source: http://www.planet4589.org/space/lvdb/index.html"")

```






","2019-3"
"1009",1089,"https://github.com/daranzolin/tidyTuesdaysD3/tree/master/global_mortality","daranzolin","tidyTuesdaysD3","global_mortality/load_and_clean.R","library(readxl)
library(tidyverse)

global_mortality <- readxl::read_excel(""tidytuesday/data/global_mortality.xlsx"")

global_mortality <- janitor::clean_names(global_mortality)

global_mortality <- mutate_at(global_mortality, vars(contains(""percent"")), ~round(., 3))

names(global_mortality) <- stringr::str_remove_all(names(global_mortality), ""_percent"")

global_mortality <- global_mortality %>% 
  gather(cause_of_death, percent, 
         cardiovascular_diseases:terrorism, 
         -country, -country_code, -year)

usa_drugs <- global_mortality %>% 
  filter(country == ""United States"",
         cause_of_death == ""drug_disorders"") %>% 
  select(year, percent) 

write_csv(global_mortality, ""tidyTuesdaysD3/data/global_mortality_cleaned.csv"")
write_csv(usa_drugs, ""tidyTuesdaysD3/data/usa_drugs.csv"")
","2018-03"
"1010",1104,"https://github.com/agailloty/R-projects/tree/master/meteorites","agailloty","R-projects","meteorites/meteorites.R","# Read in the dataset :
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")

#Loading the libraries
library(tidyverse)
library(ggrepel)

# Create a map objet with ggplot2
world_map <- ggplot2::borders(""world"") # require {map} package installed

# Remove outbond longitude
cleaned_data <- meteorites %>% filter(long <300)


# Drawing the plot

options(repr.plot.height = 5.6, repr.plot.res = 450, repr.plot.width = 8) # Plot size and resolution
cleaned_data %>%
ggplot(aes(x = long, y = lat, col = fall)) +
geom_point(size = 0.8, alpha = 1/5) + theme_void() +
geom_label_repel(aes(label=ifelse(mass>2e07, name,''), 
                     fill = fall, size = mass), col = ""black"") + 
world_map +
labs(title = ""World Map of Meteorites \n"", subtitle = ""The impact zones show where scientists have found meteorites, or the impact craters of meteorites, \n
some dating back as far as the year 2,300BC"", caption = "" Data source : Meteocritical Society"") + 
guides(size = FALSE) +
theme(plot.background=element_rect(fill=""#f4f8ff""),
      plot.subtitle = element_text(size = 8),
     plot.caption = element_text(size = 6))
","2019-24"
"1011",1105,"https://github.com/agailloty/R-projects","agailloty","R-projects","UFOs/ufos.r","# The dataset url
ufo_sightings <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")

# Loading the packages
suppressPackageStartupMessages(library(tidyverse)) # It loads also ggplot2 and other useful packages
library(tidytext)
library(hrbrthemes) # For beautiful themes
library(lubridate) # FOr dealing with dates and times


# Text cleaning 
ufo <- ufo_sightings %>% 
select(date_time, state, country, description) %>%
unnest_tokens(output = word, input = description)
ufo <- ufo %>% anti_join(stop_words, by = ""word"") # remove stop words
ufo <- ufo %>%
filter(!str_detect(word, '[[:digit:]]+')) # remove numbers

# Most used words for describing UFOs
options(repr.plot.res = 400)
ufo2 %>%
count(word, sort = TRUE) %>%
  filter(n > 1000) %>% top_n(20) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
theme_ft_rc() +
  geom_col(fill = ft_cols$yellow) +
geom_text(aes(label=n), hjust = 1, col = ""black"") +
  xlab(NULL) + ylab(NULL) + labs(title = ""Most used words for describing UFO's"") +
  coord_flip()


ufo2 <- ufo %>%
mutate(date_time = dmy_hm(date_time),
      month = month(date_time),
      weekday = weekdays(date_time),
      year = year(date_time))
      
ufo_selected_years <- ufo2 %>%
filter(year %in% c(1950, 1980, 2000, 2010, 2012))

# Common words used to describe UFOs
options(repr.plot.res = 450, repr.plot.height = 7)
ufo_selected_years %>%
  count(year, word) %>%
  group_by(year) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(year, proportion) %>%
gather(year, proportion, `1950`:`2010`) %>%
ggplot(aes(x = proportion, y = `2012`, color = abs(`2012` - proportion))) +
  geom_abline(color = ""gray40"", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(name = ""Proportion"", 
                       limits = c(0, 0.001), low = ""darkslategray4"", high = ft_cols$yellow) +
  facet_wrap(~year, ncol = 2) +  theme_ft_rc() +
  theme(legend.position=""bottom"", legend.key.width = unit(15, ""mm"")) +
  labs(title = ""Common words used to describe UFOs"", x = NULL, y= NULL) 
  
# World map
  options(repr.plot.height = 6)
ufo_sightings %>%
ggplot(aes(x = longitude, y = latitude)) +
borders(""world"") + 
geom_point(alpha = 1/8, col = ft_cols$yellow, size = 1/2) + 
theme_ft_rc() + 
labs(title = ""Where in the world UFOs are seen ?"", 
     subtitle = ""It seems that UFOs really love to appear in the United States"",
    x = NULL, y = NULL) +
theme(axis.text = element_blank())
  
","2019-26"
"1012",1106,"https://github.com/agailloty/R-projects","agailloty","R-projects","bird-count/bird_count.R","# Read the dataset
bird_counts <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-18/bird_counts.csv"")

# The packages 
library(tidyverse) # of course
library(treemap)
library(ggthemes)

# The treemap
options(repr.plot.width = 8, repr.plot.height = 7, repr.plot.res = 500)
bird_counts %>% group_by(species, year) %>%
summarize(total_count = sum(how_many_counted), total_hours = sum(total_hours)) %>%
na.omit %>% filter(total_count>0, year %in% c(1930,1950,1960,1970,1990,2000,2010,2017)) %>%
treemap(index = c(""year"", ""species""), 
        vSize = ""total_count"",
        palette = ""Set1"",
        title=""Most observed bird species by year"",
        fontsize.title = 14)
        
 # Comparison 1950 - 2017
 bird_counts %>%
group_by(year, species) %>%
summarize(total_count = sum(how_many_counted)) %>%
filter(total_count >0) %>%
spread(year, total_count) %>%
select(species, `1950`, `2017`) %>% na.omit %>%
ggplot() + geom_segment( aes(x=reorder(species, `1950`), xend=species, y=`1950`, yend=`2017`), color=""#6E6A6A"") +
geom_point( aes(species, y=`1950`), color=""#F74B4B"", size=3 ) +
  geom_point( aes(x=species, y=`2017`),color=""#36ACD7"", size=3 ) +
  coord_flip() + theme_solarized_2() +
labs(title = ""Bird species counts in 1950 and 2017"", x ="""", y = """", subtitle = ""Red : 1950 \nBlue : 2017"")
","2019-18"
"1013",1107,"https://github.com/agailloty/R-projects","agailloty","R-projects","media franchise/media_franchise.r","# Loading the packages
library(tidyverse)
library(hrbrthemes) # for nice ggplot2 themes
library(treemapify) # beautiful ggplot2 base treemaps


# Now let's read the dataset
media_franchises <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-02/media_franchises.csv"")

# Set the default theme for the plots
theme_set(theme_ft_rc())


# First plot : Franchise by revenue category

options(repr.plot.height = 6.5, repr.plot.width = 10)
ggplot(media_franchises, 
       aes(area = revenue, fill = revenue_category, 
           label = franchise, subgroup = original_media)) +
  geom_treemap() +
  geom_treemap_text(grow = TRUE, reflow = TRUE, colour = ""black"") +
  scale_fill_brewer(palette = ""Set1"") +
  theme(legend.position = ""bottom"") +
  labs(
    title = ""Franchise by revenue category"",
    caption = ""The area of each tile represents the 
revenue of the franchise as a proportion of all revenue from 1924 to 2013."",
    fill = ""Revenue category""
  ) + theme(plot.title = element_text(size = 25))
  
  # Second plot : owners revenue by year
  
  options(repr.plot.height = 17, repr.plot.res = 350, repr.plot.width = 15)
ggplot(franchise, aes(x = year_created, y = owners)) +
geom_point(aes(size = revenue, col = revenue_category)) +
scale_fill_brewer(palette = ""Set1"") +
labs(title = ""Owners revenue by year"",
     subtitle = ""From 1924 to 2014"",
    y = ""Owners"", x = ""Year"") +
theme(plot.title = element_text(size = 30))

# Third plot : Original media by revenue category

options(repr.plot.height = 15, repr.plot.res = 350, repr.plot.width = 12)
media_franchises %>% 
group_by(original_media, revenue_category) %>%
summarize(revenue = sum(revenue)) %>%
ggplot(aes( x= reorder(original_media, revenue), y = revenue)) +
geom_col(fill = ft_cols$green, col = ""black"") + coord_flip() + 
facet_wrap(~revenue_category, scale = ""free"", nrow = 4) +
labs(title = ""Original media worth by revenue category"", 
     subtitle = ""Total of revenue from 1920 to 2017"",
    x = ""Revenue category"", y = ""Revenue"") +
theme(plot.title = element_text(size = 30))

  
","2019-27"
"1014",1108,"https://github.com/agailloty/R-projects","agailloty","R-projects","women-worl-cup/women_wc.R","options(warn = -1)
suppressPackageStartupMessages(library(tidyverse))
library(ggthemes)
library(hrbrthemes)
library(FactoMineR)
library(factoextra)
options(repr.plot.res = 480)

# Reading the datasets

wwc_outcomes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/wwc_outcomes.csv"")
squads <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/squads.csv"")
codes <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-07-09/codes.csv"")

# Combine
wwc_outcomes <- dplyr::left_join(wwc_outcomes, codes, by = ""team"")

# First plot : winning status

wwc_outcomes %>%
group_by(country, win_status) %>% 
count() %>%
ggplot(aes(x = reorder(country, n), y = n)) +
geom_col(aes(fill = win_status), col = ""white"") + coord_flip() +
labs(title = ""Winning status of Women's World Cup"",
    subtitle = ""The length of the bar indicates the number of disputed match and the 
colors indicates the result of the match"",
    caption = ""Source : data.world \n #Tidytuesday"",
    fill = ""Win status"") +
theme(legend.title = element_text(""Winning status""),
     plot.subtitle = element_text(face = ""italic"", size = 8))
     
 # Second plot : Correlation circle
 ## spread the pos column into 4 dummy columns
 wide_df <- squads %>%
mutate(dummy = 1) %>%
spread(pos, dummy, fill = 0) %>%
select(-squad_no, -dob, -club, -country) %>%
data.frame(row.names = ""player"")

## PCA on the wide df
acp <- PCA(wide_df)

fviz_pca_var(acp, fill.var = ""blue"") + 
theme_ipsum_rc() + theme(line = element_blank()) +
labs(title = ""Correlation between players attributes"",
    subtitle = ""Circle of correlation based on players individual attributes"") +
theme(axis.title = element_blank())

# Third plot : Sample of players
set.seed(121)
selected_player <- sample(
    squads %>% select(player) %>% pull,
    size = 60
)
fviz_pca_biplot(acp, labelsize = 2, repel = TRUE, geom = ""text"",
                select.ind = list(name = selected_player, col = ""blue""),
               title = ""Sample of players with attributes"") +
theme_ipsum_rc() + theme(axis.text = element_blank(), axis.title = element_blank())
","2019-28"
"1015",1154,"https://github.com/Rikagx/tidytuesday-1/blob/master/Nobel.Rmd","Rikagx","tidytuesday-1","Nobel.Rmd","---
title: ""Nobel Prize winners""
output: html_document
author: Rika Gorn
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

For this Tidy Tuesday, let's look at Nobel Prize winners from 1901 to 2016 and see if we can find some fun trends. I'm going to go ahead and guess that a majority of winners are males from the U.S. or Europe. The first female winner was Marie Curie, I believe, but I could be wrong!

First we setup our libraries:
```{r setup2, warning = FALSE, message=FALSE}
library(tidyverse)
library(janitor)
library(scales)
library(readr)
library(lubridate)
library(ggbeeswarm)
library(ggridges)
library(maps)


```
Let's import the data for [Tidy Tuesday](https://github.com/rfordatascience/tidytuesday) which comes to us from [Kaggle](https://www.kaggle.com/nobelfoundation/nobel-laureates). 
```{r import, warning = FALSE, message=FALSE}
nobel <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
```
Now lets take a quick look at our variables with `glimpse`. They are all primarily characters and integers which makes sense.
```{r}
glimpse(nobel)
```
First, let's look at how men and women compare in different categories. Medicine has received the most winners across all the categories, and women have the most winners in the Peace, Literature, and Medicine categories. 
```{r barchart}
nobel %>% 
  mutate(age =  prize_year - year(birth_date)) %>% 
  filter(!is.na(gender)) %>% 
  ggplot(aes(x = category,
             fill = gender)) +
  geom_bar(width = 0.5)+ 
  theme_minimal()+
  scale_fill_manual(values=c(""#BB1288"", ""#5867A6"", ""gray""))+
  labs(title = ""Noble Prize Winners By Gender"",
       colour = ""Gender"",
       x = ""Category"",
       y = ""# of Winners"")
      
```
```{r}
nobel %>% 
  filter(gender == ""Female"") %>%
  select(full_name, prize_year, category) %>% 
  group_by(category) %>% 
  count() %>% 
  arrange(desc(n))
```
```{r}
nobel %>% 
  filter(gender == ""Female"") %>% 
  select(full_name, prize_year, category) %>% head()
```
So in the last `r 2016 -1901` years we've had 50 female nobel price laureates. And I was right! The first winner was Marie Curie!

There were a few NA's that I filtered out for gender in the above chart that I'd like to check out.

```{r}
nobel %>% filter(is.na(gender)) %>% select(full_name, category)
```
Fascinating, there were 26 organizations rather than individuals that won the Nobel Peace Prize. 

A fellow TidyTuesdayer [Othomenantegazza](https://twitter.com/othomn/status/1128426237834276865) had a really awesome way of showing similar information with a beeswarm graph that I wanted to recreate here. They also changed the alpha in their chart which changes the translucency of the dots, but I left that alone here. I also wanted to try out the `ggridges` package so I made a similar graph looking at age and gender across categories.

```{r beeswarm chart, warning = FALSE}
nobel %>% 
  mutate(age =  prize_year - year(birth_date)) %>% 
  ggplot(aes(x = category,
             y = age,
             colour = gender)) +
  ggbeeswarm::geom_beeswarm() +
  coord_flip() +
  scale_color_manual(values = c(""#BB1288"", ""#5867A6"")) +
  theme_minimal() +
  labs(title = ""Noble Prize Winners By Gender and Age"",
       colour = ""Gender"",
       x = ""Category"",
       y = ""Age"")
```

```{r ggridges, message = FALSE, warning=FALSE}
nobel %>% 
  mutate(age =  prize_year - year(birth_date)) %>% 
  ggplot(aes(x = age,
             y = category,
            fill = gender)) +
  geom_density_ridges(scale = 0.9) + 
  scale_x_continuous(limits = c(16, 100))+
   scale_fill_manual(values = c(""#BB1288"", ""#5867A6"")) +
  theme_minimal() +
  labs(title = ""Noble Prize Winners By Age"",
       colour = ""Gender"",
       x = ""Age"",
       y = ""Category"")
```

I want to make a heat map but for this will need to bring in longitude and latitude data and also clean up our countries since many of them no longer exist. In general, I want our birth_country variable to conform to the region available in the `maps` package. 


```{r}
map.world <- map_data('world') 
map_countries <- distinct(map.world, region)
```
Now let's filter the original dataset to only include birth_countries that have more than 5 winners and is not missing. This cuts our dataset down from 969 to 792 winners and top 24 countries. Then we can take a look at some of our birth_country mismatches which we will need to recode. 

```{r}
nobel_countries <- nobel %>% group_by(birth_country) %>% count() %>% filter(n >5, !is.na(birth_country)) %>% arrange(desc(n))

anti_join(nobel_countries, map.world, by = c('birth_country' = 'region')) %>% select(birth_country) %>% group_by(birth_country) %>% count(sort = T)
```
And let's fix those mismatches by recoding them to the names that are in our map.world dataset.
```{r}
nobel <- nobel %>% mutate(birth_country = recode(birth_country,
                                                 ""United States of America"" = ""USA"",
                                                 ""United Kingdom"" = ""UK"",
                                                 ""Scotland"" = ""UK"",
                                                 ""Northern Ireland"" = ""Ireland"",
                                                 ""Germany (Poland)"" = ""Poland"",
                                                 ""Prussia (Germany)"" = ""Germany"",
                                                 ""Prussia (Poland)"" = ""Poland""
                                                  )
                            )
```



```{r}


country_list <- nobel_countries$birth_country

nobel_small <- nobel %>% filter(birth_country %in% country_list)
```
Let's make sure Now let's make our map dataset by combining the nobel dataset and the map dataset.
```{r}
nobel_small <- left_join(nobel_small, nobel_countries, by =""birth_country"") %>% rename(""num_winners"" = ""n"") #this add the count of winners

nobel_map <- left_join( map.world, nobel_small, by = c(""region""= ""birth_country""))
```

```{r}
ggplot(nobel_map, aes( x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = num_winners))+
  scale_fill_gradientn(colours = c('#461863','#404E88','#2A8A8C','#7FD157','#F9E53F')
                       ,values = scales::rescale(c(5, 50, 100, 200, 300))
                       ,labels = comma
                       ,breaks = c(5, 50, 100, 200, 300)
  ) +
  labs(fill = '# of Nobel Winners'
              ,title = 'U.S. and Europe Win Most Nobel Prizes'
       ,x = NULL
       ,y = NULL) +
  theme(text = element_text(family = 'Gill Sans', color = '#EEEEEE')
        ,plot.title = element_text(size = 20)
        ,plot.subtitle = element_text(size = 14)
        ,axis.ticks = element_blank()
        ,axis.text = element_blank()
        ,panel.grid = element_blank()
        ,panel.background = element_rect(fill = '#333333')
        ,plot.background = element_rect(fill = '#333333')
        ,legend.position = c(.18,.36)
        ,legend.background = element_blank()
        ,legend.key = element_blank()
  ) +
  annotate(geom = 'text'
           ,label = 'Source: Kaggle | Plot by @RikaGorn '
           ,x = 18, y = -55
           ,size = 3
           ,family = 'Gill Sans'
           ,color = '#CCCCCC'
           ,hjust = 'left'
  )
```


","2019-20"
"1016",1155,"https://github.com/meensrinivasan/tidytuesdaysubmissions/tree/master/plastic","meensrinivasan","tidytuesdaysubmissions","plastic/plastic.R","extrafont::loadfonts(device = ""win"")

library(tidyverse)
library(janitor)
library(countrycode)
library(ggrepel)
library(ggsci)
library(ggbeeswarm)
library(patchwork)
library(scales)
devtools::install_github(""thomasp85/patchwork"")

codes <- codelist %>%
  select(iso3c, country.name.en, region, continent) %>%
  janitor::clean_names() %>%
  filter(!is.na(continent)) %>%
  filter(!is.na(region))


coast_vs_waste <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/coastal-population-vs-mismanaged-plastic.csv"") %>%
  janitor::clean_names() %>%
  filter(!is.na(mismanaged_plastic_waste_tonnes)) %>%
  left_join(codes, by = c(""code"" = ""iso3c"")) %>%
  select(-country_name_en) %>%
  filter(!is.na(continent)) %>%
  mutate(mmwpercap = mismanaged_plastic_waste_tonnes/total_population_gapminder)

p1 <- coast_vs_waste %>%
  filter(coastal_population > 30000000) %>%
ggplot(aes(coastal_population, mismanaged_plastic_waste_tonnes, color = continent, label = entity)) +
  geom_point() +
  scale_x_log10(labels = scales::comma_format()) +
  scale_color_nejm(name = ""Continent"") +
  scale_fill_nejm(name = ""Continent"") +
  geom_label_repel(aes(fill = continent), colour = ""white"", fontface = ""bold"", show.legend = F) +
  labs(x = ""Coastal population (log)"",
       y = ""Mismanaged plastic waste (tonnes)"",
       title = ""Coastal population > 30 million"") +
  theme(text = element_text(family = ""Papyrus""),
        axis.line = element_line(size = 1),
        panel.grid = element_blank(),
        panel.background = element_rect(fill = ""#f2f5f7""),
        plot.title = element_text(hjust = 0.5, size = 18, face = ""bold""),
        plot.subtitle = element_text(hjust = 0.5, size = 14),
        plot.caption = element_text( size = 12),
        axis.text = element_text(size = 14, face = ""bold""),
        axis.title = element_text(size = 14, face = ""bold""),
        legend.position = c(0.1, 0.8), 
        legend.justification = c(0.1, 0.8), 
        legend.background = element_rect(colour = NA, fill = ""white""),
        legend.text = element_text(size = 12, face = ""bold""),
        legend.title = element_text(size = 14, face = ""bold""))

p1

p2 <- ggplot(coast_vs_waste, aes(coastal_population, mismanaged_plastic_waste_tonnes, color = continent)) +
  geom_point(size = 3) +
  scale_x_log10(labels = scales::comma_format()) +
  scale_y_continuous(labels = scales::comma_format()) +
  scale_color_nejm(name = ""Continent"") +
  scale_fill_nejm(name = ""Continent"") +
  labs(x = ""Coastal population (log)"",
       y = ""Mismanaged plastic waste (tonnes)"",
       title = ""All countries"") +
  theme(text = element_text(family = ""Papyrus""),
        axis.line = element_line(size = 1),
        panel.grid = element_blank(),
        panel.background = element_rect(fill = ""#f2f5f7""),
        plot.title = element_text(hjust = 0.5, size = 18, face = ""bold""),
        plot.subtitle = element_text(hjust = 0.5, size = 14),
        plot.caption = element_text(size = 12),
        axis.text = element_text(size = 14, face = ""bold""),
        axis.title = element_text(size = 14, face = ""bold""),
        legend.position = c(0.1, 0.8), 
        legend.justification = c(0.1, 0.8), 
        legend.background = element_rect(colour = NA, fill = ""white""),
        legend.text = element_text(size = 12, face = ""bold""),
        legend.title = element_text(size = 14, face = ""bold""))
p2

p3 <- coast_vs_waste %>%
  filter(!is.na(mmwpercap)) %>%
  ggplot() +
  geom_quasirandom(aes(x = continent, y = mmwpercap, color = continent), size = 2.5) +
  coord_flip() +
  scale_color_nejm() +
  geom_label_repel(data=subset(coast_vs_waste, mmwpercap > 0.030),
                   aes(continent,mmwpercap,label=entity, fill = continent), colour = ""white"", fontface = ""bold"")+
  labs(x = "" "",
       y = ""Mismanaged plastic waste (tonnes)per capita"",
       title = ""Could per capital estimates could be misleading?"") +
  theme(text = element_text(family = ""Papyrus""),
        axis.line = element_line(size = 1),
        panel.grid = element_blank(),
        panel.background = element_rect(fill = ""#f2f5f7""),
        plot.title = element_text(hjust = 0.5, size = 18, face = ""bold""),
        plot.subtitle = element_text(hjust = 0.5, size = 14),
        plot.caption = element_text(size = 12),
        axis.text = element_text(size = 14, face = ""bold""),
        axis.title = element_text(size = 14, face = ""bold""),
        legend.position = ""none"")
p3                 

( p2 / p3 ) | p1
ggsave(""facet.png"", width = 18, height = 9)

waste_vs_gdp <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-21/per-capita-plastic-waste-vs-gdp-per-capita.csv"") %>%
  janitor::clean_names() %>%
  filter(!is.na(per_capita_plastic_waste_kilograms_per_person_per_day)) %>%
  left_join(codes, by = c(""code"" = ""iso3c"")) %>%
  select(-country_name_en) %>%
  filter(!is.na(continent)) 

ggplot(waste_vs_gdp, mapping = aes(x = gdp_per_capita_ppp_constant_2011_international_constant_2011_international, y = per_capita_plastic_waste_kilograms_per_person_per_day, size = total_population_gapminder, color = continent)) +
  geom_point() +
  scale_size_continuous(name = ""Population"", range = c(2, 12), labels = scales::comma_format()) +
  scale_x_log10(labels = comma_format()) +
  scale_fill_nejm(name = ""Continent"")+
  scale_color_nejm(name = ""Continent"") +
  geom_label_repel(data=subset(waste_vs_gdp, per_capita_plastic_waste_kilograms_per_person_per_day > 0.5),
                   aes(gdp_per_capita_ppp_constant_2011_international_constant_2011_international,
                       per_capita_plastic_waste_kilograms_per_person_per_day,label=entity, color = continent), 
                    size = 5, show.legend = F) +
  labs(x = ""GDP per capita"",
       y = ""Per capital plastic waste (kg)"",
       title = ""Looking like Caribbean countries have a higher per capita plastic waste"",
       subtitle = ""Surprising...What could be the reason? Tourism?"",
       caption = ""Source: Our World in Data \n Code: @srini_meen"") +
  theme(text = element_text(family = ""Papyrus""),
        panel.background = element_rect(fill = ""#f9feff""),
        plot.title = element_text(hjust = 0.5, size = 18, face = ""bold""),
        plot.subtitle = element_text(hjust = 0.5, size = 14),
        plot.caption = element_text(size = 12),
        axis.text = element_text(size = 14, face = ""bold""),
        axis.title = element_text(size = 14, face = ""bold""),
        legend.title = element_text(size = 14, face = ""bold""))

ggsave(""plasticpercap.png"", width = 15, height = 8)
","2019-21"
"1017",1156,"https://github.com/meensrinivasan/tidytuesdaysubmissions/tree/master/nobel","meensrinivasan","tidytuesdaysubmissions","nobel/nobel.R","## Special thanks to https://www.r-bloggers.com/bitcoin-world-map-bubbles/ and 
## @WireMonkey https://twitter.com/WireMonkey/status/1128761148541677568 
## for some of the code inspiration

extrafont::loadfonts(device = ""win"")
library(tidyverse)
library(countrycode)
library(ggplot2)
library(ggalt)
library(ggthemes)
library(lubridate)
library(viridis)
library(ggpubr)


nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"") %>%
  mutate_all(., tolower) %>%
  mutate(prize_year = as.integer(prize_year)) %>%
  mutate(birth_country = ifelse(grepl('\\(', birth_country), str_extract(birth_country, ""(?<=\\().*?(?=\\))""), birth_country),
         death_country = ifelse(grepl('\\(', death_country), str_extract(death_country, ""(?<=\\().*?(?=\\))""), death_country)) %>%
  mutate(birth_country = case_when(birth_country == ""scotland"" ~ ""united kingdom"",
                                   birth_country == ""northern ireland"" ~ ""united kingdom"",
                                   grepl(""czech"", birth_country) ~ ""czechia"",
                                   birth_country == ""east_germany"" ~ ""germany"",
                                   TRUE ~ birth_country),
         death_country = case_when(death_country == ""scotland"" ~ ""united kingdom"",
                                   death_country == ""northern ireland"" ~ ""united kingdom"",
                                   grepl(""czech"", death_country) ~ ""czechia"",
                                   death_country == ""east_germany"" ~ ""germany"",
                                   TRUE ~ death_country)) %>%
  select(prize_year, category, birth_date, birth_country, gender, organization_name, organization_country, death_country)


nobel_winners_cntry <- nobel_winners %>%
  count(birth_country) %>%
  filter(!is.na(birth_country)) %>%
  mutate(iso3 = countrycode(birth_country, ""country.name"", ""iso3c""))

codes <- codelist %>%
  select(iso3c, country.name.en, region, continent) %>%
  janitor::clean_names() %>%
  filter(!is.na(continent)) %>%
  filter(!is.na(region)) %>%
  rename(iso3 = iso3c) %>%
  left_join(CoordinateCleaner::countryref %>% select(iso3, capital.lon, capital.lat)) %>%
  distinct() %>%
  filter(!is.na(capital.lon)) %>%
  filter(!is.na(capital.lat)) 

 nobel_winners_cntry_coord <- nobel_winners_cntry %>%
  left_join(codes)
 
 
 world <- map_data(""world"")
 world <- world[world$region != ""Antarctica"", ]
 
 names_dif <- anti_join(nobel_winners_cntry_coord, world, by = c(""country_name_en"" = ""region""))

 nobel_winners_cntry_coord2 <- nobel_winners_cntry_coord %>%
   mutate(country_name_en = recode(country_name_en, 
                                   ""United Kingdom"" = ""UK"",
                                   ""United States"" = ""USA"",
                                   ""Bosnia & Herzegovina"" = ""Bosnia and Herzegovina"",
                                   ""Czechia"" = ""Czech Republic"",
                                   ""Trinidad & Tobago"" = ""Trinidad"",
                                   ""Myanmar (Burma)"" = ""Myanmar"",
                                   ""St. Lucia"" = ""Saint Lucia""))
 
ggplot() +
   geom_cartogram(
     data = world, map = world,
     aes(x = long, y = lat, map_id = region),
     color = ""#113c7a"", fill = ""#113c7a"", size = 0.125
   ) +
   geom_point(
     data = nobel_winners_cntry_coord, aes(capital.lon, capital.lat, size = n), fill = ""#ffe923"",
     shape = 21, alpha = 0.8, stroke = 0.25, color = ""#ffe923""
   ) +
   coord_proj(""+proj=robin"") +
   scale_size_area(name = ""Number of Nobel Laureates"", breaks = c(10, 50, 100, 200), max_size = 30, labels = scales::comma) +
   labs(
     x = NULL, y = NULL,
     title = ""Nobel Winners by country"",
     subtitle = ""Size of bubble indicates number of Nobel lauretes"",
     caption = ""Source: Kaggle""
   ) +
   theme_map(base_family = ""Britannic Bold"") +
   theme(plot.title = element_text(hjust = 0.5, size = 25)) +
   theme(plot.subtitle = element_text(hjust = 0.5, size = 15)) +
   theme(plot.caption = element_text(size = 15)) +
   theme(legend.position = ""bottom"") +
   theme(legend.title = element_text(size = 18)) +
   theme(legend.text = element_text(size = 18)) 

 ggsave(""map.png"", width = 15, height = 8)
 
 
 nobel_winners_age <- nobel_winners %>%
   mutate(age = prize_year - year(birth_date)) %>%
   mutate(category = str_to_title(category)) %>%
   filter(!is.na(gender)) %>%
   mutate(gender = str_to_title(gender))
 
 ggplot(data = nobel_winners_age)+
   geom_point(aes(prize_year, age, color = gender))+
   geom_smooth(aes(prize_year, age)) +
   facet_wrap(~category, scale = ""free_y"")+
   theme_minimal(base_family = ""Britannic Bold"")+
   labs(
     x = ""Year of prize"", y = ""Age of winner (years)"",
     title = ""Age of Nobel winners at the time of being awarded"",
     subtitle = ""Recent winners of Chemistry and Physics seem to be older"",
     caption = ""Source: Kaggle""
   ) +
   scale_color_manual(name = ""Gender"", values = c(""red"", ""darkblue"")) +
   theme(strip.text = element_text(face = ""bold"", hjust = 0, size = 15)) +
   theme(plot.title = element_text( hjust = 0.5, size = 25)) +
   theme(plot.subtitle = element_text( hjust = 0.5, size = 15)) +
   theme(plot.caption = element_text(size = 15)) +
   theme(legend.title = element_text(size = 15)) +
   theme(legend.text = element_text(size = 15)) +
   theme(axis.title = element_text(size = 15)) +
   theme(axis.text = element_text(size = 12))
 
 
 ggsave(""age.png"", width = 15, height = 8)
   
 
 nobel_winners_usa <- nobel_winners %>%
   filter(birth_country == ""united states of america"") %>%
   filter(organization_country == ""united states of america"") %>%
   filter(!is.na(organization_name)) %>%
   group_by(category, organization_name) %>%
   summarise(wins = n()) %>%
   mutate(organization_name = recode(organization_name, 
                                     ""massachusetts institute of technology (mit)"" = ""MIT"",
                                     ""massachusetts institute of technology (mit), center for cancer research"" = ""MIT"",
                                     ""california institute of technology (caltech)"" = ""Caltech"",
                                     ""university of texas southwestern medical center at dallas"" = ""UT Southwestern"",
                                     ""research division of infectious diseases, children's medical center"" = ""children's medical center"",
                                     ""rockefeller institute for medical research"" = ""rockefeller institute"",
                                     ""university of california school of medicine"" = ""University Of California Med"",
                                     ""johns hopkins university school of medicine"" = ""Johns Hopkins University"")) %>%
   mutate(organization_name = str_to_title(organization_name)) %>%
   mutate(organization_name = recode(organization_name, 
                                     ""Mit"" = ""MIT""))
   
                                        
                                    
 
 nobel_winners_usa_economics <- nobel_winners_usa %>%
   filter(category == ""economics"") %>%
   mutate(organization_name = fct_reorder(organization_name, wins)) %>%
   filter(wins > 1)
 
 nobel_winners_usa_medicine <- nobel_winners_usa %>%
   filter(category == ""medicine"") %>%
   mutate(organization_name = fct_reorder(organization_name, wins)) %>%
   filter(wins > 1)
   
 nobel_winners_usa_physics <- nobel_winners_usa %>%
   filter(category == ""physics"") %>%
   mutate(organization_name = fct_reorder(organization_name, wins)) %>%
   filter(wins > 1)
 
 nobel_winners_usa_chemistry <- nobel_winners_usa %>%
   filter(category == ""chemistry"") %>%
   mutate(organization_name = fct_reorder(organization_name, wins)) %>%
   filter(wins > 1)
 
 
e <- ggplot(nobel_winners_usa_economics, mapping = aes(x = as.factor(organization_name), y = wins, fill = organization_name)) +
   geom_col() +
   coord_flip() +
   scale_fill_viridis_d(option = ""magma"") +
   theme_minimal(base_family = ""Britannic Bold"") +
   labs(
     y = ""Number of Nobel Prizes"", x = """",
     title = ""Economics"") +
   theme(legend.position = ""none"") +
   theme(plot.title = element_text(size = 25)) +
   theme(axis.title = element_text(size = 15)) +
   theme(axis.text = element_text(size = 12))
 
 
 
m <- ggplot(nobel_winners_usa_medicine, mapping = aes(x = organization_name, y = wins,
                                                  fill = organization_name)) +
   geom_col() +
   coord_flip() +
   scale_fill_viridis_d(option = ""magma"") +
   theme_minimal(base_family = ""Britannic Bold"") +
   labs(
     y = ""Number of Nobel Prizes"", x = """",
     title = ""Medicine"") +
   theme(legend.position = ""none"") +
   theme(plot.title = element_text(size = 25)) +
   theme(axis.title = element_text(size = 15)) +
   theme(axis.text = element_text(size = 12))
 
 
p <- ggplot(nobel_winners_usa_physics, mapping = aes(x = organization_name, y = wins,
                                                  fill = organization_name)) +
   geom_col() +
   coord_flip() +
   scale_fill_viridis_d(option = ""magma"") +
   theme_minimal(base_family = ""Britannic Bold"") +
   labs(
     y = ""Number of Nobel Prizes"", x = """",
     title = ""Physics"") +
   theme(legend.position = ""none"") +
   theme(plot.title = element_text(size = 25)) +
   theme(axis.title = element_text(size = 15)) +
   theme(axis.text = element_text(size = 12))
 
c <- ggplot(nobel_winners_usa_chemistry, mapping = aes(x = organization_name, y = wins,
                                                 fill = organization_name)) +
   geom_col() +
   coord_flip() +
   scale_fill_viridis_d(option = ""magma"") +
   theme_minimal(base_family = ""Britannic Bold"") +
   labs(
     y = ""Number of Nobel Prizes"", x = """",
     title = ""Chemistry"") +
   theme(legend.position = ""none"") +
   theme(plot.title = element_text(size = 25)) +
   theme(axis.title = element_text(size = 15)) +
   theme(axis.text = element_text(size = 12))

ggarrange(m, e, p, c, ncol=2, nrow=2)

ggsave(""uni.png"", width = 15, height = 7)
","2019-20"
"1018",1157,"https://github.com/meensrinivasan/tidytuesdaysubmissions/tree/master/Anime","meensrinivasan","tidytuesdaysubmissions","Anime/Anime.Rmd","```{r}
library(tidyverse)
library(paletteer)
library(lubridate)
```




```{r}
anime <- read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")
```


```{r}
barchart_theme <-  theme(axis.text.y   = element_text(size=13, face=""bold"", colour = ""black""),
                  axis.text.x   = element_text(size=13, face=""bold"", colour = ""black""),
                  axis.title.x  = element_text(size=13, face=""bold""),
                  axis.title.y  = element_text(size=13, face = ""bold""),
                  panel.background = element_rect(fill = ""white""),
                  axis.ticks.length = unit(.25, ""cm""),
                  plot.title = element_text(lineheight=.8, face=""bold"", hjust = 0.5),
                  plot.caption = element_text(size = 10),
                  plot.subtitle = element_text(hjust = 0.5, size = 10),
                  strip.background = element_rect(fill = ""white""),
                  strip.text = element_text(size = 18, hjust = 0, colour = ""black"", face =""bold""),
                  legend.position = ""none"",
                  legend.title = element_text(size = 13, face = ""bold""),
                  legend.text = element_text(size = 13),
                  panel.border = element_rect(color = ""black"", fill = NA, size = 2),
                  panel.grid.major.x = element_blank(),
                  panel.grid.minor.x = element_blank(),
                  panel.grid.major.y = element_line(colour = ""grey60"", linetype = ""dashed""))
  
```

```{r}
anime2 <- anime %>%
  group_by(animeID) %>%
  select(name, title_english, type, source, genre, start_date, end_date, score, popularity, favorites) %>%
  slice(1)
  
```
```{r}
anime3 <- anime2 %>%
  group_by(genre) %>%
  summarise(median_score = median(score)) %>%
  na.omit() %>%
  arrange(desc(median_score)) %>%
  head(14)

#   geom_errorbar(aes(ymin = pct_5, ymax = pct_97.5), col = ""red"")

ggplot(anime3 , aes(x = median_score, y = reorder(genre, median_score), color = genre)) +
  geom_segment(aes(yend = genre), xend = 0, color = ""black"", size = 1) +
  geom_point(size = 8) +
  scale_color_paletteer_d(package = ""LaCroixColoR"", palette = ""paired"") +
  labs(x = ""Median Score"",
       y = """",
       title = ""Highest scored Anime genres"",
       subtitle = ""There was a genre called 'Dementia' in the dataset. Why?"") +
  barchart_theme

ggsave(""Highest scored.png"", width = 10, height = 7, units = ""in"")

```



```{r}

anime4 <- anime2 %>%
  select(name, genre, start_date, score, popularity) %>%
  mutate(year = year(start_date))%>%
  group_by(year, genre) %>%
  summarise(n = n()) %>%
  na.omit() %>%
  filter(genre %in% c(""Kids"", ""Comedy"", ""Romance"", ""Action"", ""Adventure"", ""Dementia""))

ggplot(anime4, aes(year, n, color = genre)) +
  geom_point(size = 2.5) +
  scale_color_paletteer_d(name = ""Genre"", package = ""LaCroixColoR"", palette = ""PassionFruit"")+
  labs(x = ""Year"",
       y = ""Number of shows"",
       title = ""Number of shows by genre."", 
       subtitle = ""Hmmm.. So they have few shows in the 'Dementia' genre. WHY?"") +
  barchart_theme +
  theme(legend.position = ""bottom"")

ggsave(""genre year.png"", width = 10, height = 7, units = ""in"")
  
```

","2019-17"
"1019",1177,"https://github.com/meensrinivasan/tidytuesdaysubmissions/tree/master/teacherstudent","meensrinivasan","tidytuesdaysubmissions","teacherstudent/studentratio.R","extrafont::loadfonts(device = ""win"")

library(tidyverse)
library(countrycode)
library(rworldmap)
library(scico)
library(ggsci)
library(scales)
library(ggthemes)

## Loading the data
student_ratio <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-07/student_teacher_ratio.csv"") %>%
  select(-flag_codes, -flags) %>%
  select(-edulit_ind) %>%
  group_by(indicator, country_code) %>%
  summarize(median_ratio = median(student_ratio, na.rm = TRUE)) 

## Getting a dataframe of countries
rworldmap_countries<-getMap(resolution = ""coarse"", projection = NA)
rworldmap_countries_list<- rworldmap_countries@data #saved in a dataframe

# Using the robinson projection that would enable showing the entire world at once. 
# Also Antarctica is not needed in this map
map_world <- broom::tidy(spTransform(getMap(), CRS(""+proj=robin""))) %>% 
  filter(id != ""Antarctica"")

# Just need to check what are the countries to avoid discrepancies between this and other dfs
map_world_countries <- map_world %>%
  select(id)

# codes from countrycode package
codes <- codelist %>%
  select(iso3c, country.name.en, region, continent) %>%
  janitor::clean_names() %>%
  filter(!is.na(continent)) %>%
  filter(!is.na(region)) 

# Joining the country codes to the ratio data
student_ratio2 <- student_ratio %>%
  left_join(., codes, by = c(""country_code"" = ""iso3c"")) %>%
  filter(!is.na(continent)) 

# Checking if there is any discrepancy in names
names_dif <- anti_join(student_ratio2, map_world_countries, by = c(""country_name_en"" = ""id"")) 

# Yes, there is. Correcting that. 
student_ratio3 <- student_ratio2 %>%
  mutate(country_name_en = recode(country_name_en, 
                                  ""Antigua & Barbuda"" = ""Antigua and Barbuda"",
                                  ""Bahamas"" = ""The Bahamas"",
                                  ""Bosnia & Herzegovina"" = ""Bosnia and Herzegovina"",
                                  ""Cte d'Ivoire"" = ""Ivory Coast"",
                                  ""Congo - Kinshasa""  = ""Democratic Republic of the Congo"",
                                  ""Congo - Brazzaville"" = ""Republic of the Congo"",     
                                  ""Czechia"" = ""Czech Republic"",
                                  ""Micronesia (Federated States of)"" = ""Federated States of Micronesia"",
                                  ""Hong Kong SAR China"" = ""Hong Kong S.A.R."", 
                                  ""St. Kitts & Nevis""=  ""Saint Kitts and Nevis"",                   
                                  ""St. Lucia""= ""Saint Lucia"", 
                                  ""Myanmar (Burma)"" = ""Myanmar"",  
                                  ""Macau SAR China"" = ""Macau S.A.R"",
                                  ""Serbia"" = ""Republic of Serbia"",
                                  ""French Southern Territories"" = ""French Southern and Antarctic Lands"", 
                                  ""So Tom & Prncipe"" = ""Sao Tome and Principe"",
                                  ""Turks & Caicos Islands""= ""Turks and Caicos Islands"",
                                  ""Tanzania"" =  ""United Republic of Tanzania"",
                                  ""United States"" =  ""United States of America"",                             
                                  ""Vatican City""= ""Vatican"",            
                                  ""St. Vincent & Grenadines""= ""Saint Vincent and the Grenadines""))             
 
# Checking if the discrepancies still exist                                 
names_dif <- anti_join(student_ratio3, map_world_countries, by = c(""country_name_en"" = ""id""))                                 

# Filtering df for Primary Education
student_ratio3_prim <- student_ratio3 %>%
  filter(indicator == ""Primary Education"")


# Map
ggplot() +
  geom_map(data = map_world, map = map_world,
           aes(x = long, y = lat, map_id = id),
           fill = ""grey50"") + 
  geom_map(data = student_ratio3_prim, map = map_world,
           aes(fill = median_ratio, map_id = country_name_en)) + 
  theme_minimal(base_family = ""Comfortaa"", base_size = 14) +
  scale_fill_scico(palette = ""lajolla"", na.value = ""grey50"") +
  labs(title = ""Student to teacher ratios in Primary Education by country"",
    subtitle = ""Is S:T ratio and GDP per capita related?"",
    caption = ""Source: UNESCO Institute of Statistics"",
    fill = ""Student to teacher ratio"") + 
  theme_map(base_family = ""Segoe Script"", base_size = 15) +
  theme(plot.title = element_text(hjust = 0.5, size = 18),
                     plot.caption = element_text(size = 12),
                     plot.subtitle = element_text(hjust = 0.5, size = 14),
                     legend.title = element_text(size = 15, face = ""bold""),
                     legend.text = element_text(size = 13),
                     legend.position = ""bottom"")

ggsave(""Map.png"", width = 15, height = 8)

# Downloading gdp data
gdpercap <- read_csv(""API_NY.GDP.PCAP.CD_DS2_en_csv_v2_10576699\\API_NY.GDP.PCAP.CD_DS2_en_csv_v2_10576699.csv"",
                     skip = 4) %>%
  janitor::clean_names() %>%
  select(country_name, country_code, x2017) %>%
  rename(""gdpercap_17"" = ""x2017"") %>%
  mutate(country_name = recode(country_name, ""United States"" = ""United States of America""))

# Downloading population data
pop <- readxl::read_excel(""TotalPopSex-20190510084722.xlsx"", sheet = ""Data"", skip = 1) %>%
  janitor::clean_names() %>%
  select(-sex, -note, -x1951) %>%
  rename(""pop_2017_000"" = ""x2017"")

# Combining into one dataframe
pop_gdp <- gdpercap %>%
  left_join(., pop, by = c(""country_name"" = ""location"")) %>%
  left_join(., student_ratio3, by = c(""country_name"" = ""country_name_en"")) %>%
  filter(!is.na(continent)) %>%
  select(-iso_3166_1_numeric_code, -country_code.y) %>%
  filter(!is.na(median_ratio)) %>%
  drop_na()


# Relationship between gdp and ts ratio
pop_gdp %>%
  filter(indicator == ""Primary Education"") %>%
ggplot(pop_gdp, mapping = aes(x = gdpercap_17, y = median_ratio, size = pop_2017_000, color = continent)) +
  geom_point() +
  scale_size_continuous(name = ""Population"", range = c(2, 12), labels = comma_format()) +
  scale_x_log10(labels = comma_format()) +
  scale_color_startrek(name = ""Continent"") +
  labs(x = ""GDP per capita"",
       y = ""Median teacher student ratio"",
       title = ""As GDP increases, teacher to student ratio decreases"",
       subtitle = ""Makes sense, countries with lower GDP have fewer teachers"",
       caption = ""Source: UNESCO Institute of Statistics \n Code: @srini_meen"") +
  theme_minimal(base_family = ""Segoe Script"", base_size = 15) +
  theme(plot.background = element_rect(fill = ""#f9feff""),
               plot.title = element_text(hjust = 0.5, size = 18, face = ""bold""),
               plot.subtitle = element_text(hjust = 0.5, size = 14),
               plot.caption = element_text( size = 12),
               axis.text = element_text(face = ""bold""),
        axis.title = element_text(face = ""bold""),
        legend.title = element_text(size = 14, face = ""bold""))

ggsave(""gdp.png"", width = 15, height = 8)

countries <- c(""Brazil"", ""India"", ""China"", ""Rwanda"", ""United States of America"")

pop_gdp$indicator <- fct_relevel(pop_gdp$indicator, ""Tertiary Education"", ""Post-Secondary Non-Tertiary Education"", 
                                 ""Upper Secondary Education"", ""Secondary Education"", ""Lower Secondary Education"",
                                 ""Primary Education"", ""Pre-Primary Education"")

indicator_needed <- c(""Tertiary Education"", 
                                 ""Upper Secondary Education"", ""Secondary Education"", ""Lower Secondary Education"",
                                 ""Primary Education"", ""Pre-Primary Education"")

# Specific countries bar plot
pop_gdp %>%
  filter(country_name %in% countries) %>%
  filter(indicator %in% indicator_needed) %>%
  mutate(country_name = recode(country_name, ""United States of America"" = ""USA"")) %>%
  ggplot(pop_gdp, mapping = aes(x = country_name, y = median_ratio, fill = country_name)) +
  geom_col() +
  facet_wrap(~ indicator, scales = ""free_y"")+
  coord_flip() +
  labs(x = "" "",
       y = ""Median teacher student ratio"",
       title = ""China catching up with USA in teacher student ratio"",
       subtitle = ""Amazing that China is investing heavily in teachers."",
       caption = ""Source: UNESCO Institute of Statistics \n Code: @srini_meen"") +
  scale_fill_startrek() +
  theme_minimal(base_family = ""Segoe Script"", base_size = 15) +
theme(plot.background = element_rect(fill = ""#f9feff""),
      plot.title = element_text(hjust = 0.5, size = 18, face = ""bold""),
      plot.subtitle = element_text(hjust = 0.5, size = 14),
      plot.caption = element_text( size = 12),
      axis.text = element_text(face = ""bold""),
      axis.title = element_text(face = ""bold""),
      legend.title = element_text(size = 14, face = ""bold""),
      legend.position = ""none"",
      strip.text = element_text(face = ""bold""))

ggsave(""countries.png"", width = 15, height = 8)


# Primary education by region
pop_gdp %>%
  filter(indicator == ""Primary Education"") %>%
  mutate(region = fct_reorder(region, median_ratio)) %>%
  ggplot(pop_gdp, mapping = aes(x = region, y = median_ratio, fill = continent)) +
  geom_boxplot() +
  coord_flip() +
  scale_fill_startrek() +
  labs(x = "" "",
       y = ""Median teacher student ratio"",
       title = ""Teacher student ratio in Primary Education by region"",
       subtitle = ""Investment in primary education is super important in Africa and Southern Asia"",
       caption = ""Source: UNESCO Institute of Statistics \n Code: @srini_meen"") +
  theme_minimal(base_family = ""Segoe Script"", base_size = 15) +
  theme(plot.background = element_rect(fill = ""#f9feff""),
        plot.title = element_text(hjust = 0.5, size = 18, face = ""bold""),
        plot.subtitle = element_text(hjust = 0.5, size = 14),
        plot.caption = element_text( size = 12),
        axis.text = element_text(face = ""bold""),
        axis.title = element_text(face = ""bold""),
        legend.title = element_text(size = 14, face = ""bold""),
        legend.position = ""none"",
        strip.text = element_text(face = ""bold""))

ggsave(""box.png"", width = 15, height = 8)

","2019-19"
"1020",1178,"https://github.com/meensrinivasan/tidytuesdaysubmissions/tree/master/meteorite","meensrinivasan","tidytuesdaysubmissions","meteorite/meteorite.R","library(tidyverse)
library(ggthemes)
library(scales)

meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"") %>%
  filter(!is.na(year)) %>%
  filter(!is.na(lat)) %>%
  filter(!is.na(long)) %>% 
  filter(!is.na(mass)) %>%
  mutate(year_cat = case_when(year < 1700 ~ 1,
                              year >= 1700 & year < 1800 ~ 2,
                              year >= 1800 & year < 1850 ~ 3,
                              year >= 1850 & year < 1900 ~ 4,
                              year >= 1900 & year < 1950 ~ 5,
                              year >= 1950 ~ 6))
ggplot() + 
  borders(""world"", colour = ""#232323"", fill = ""#232323"") +
  theme_map(base_family = ""Merriweather"") +
  coord_map(projection = ""mercator"", orientation = c(90, 0, 0)) +
  geom_point(data = subset(meteorites, year_cat == 1), color = ""#fcef02"",
             aes(x = long, y = lat, size = mass), alpha = .7) +
  geom_point(data = subset(meteorites, year_cat == 2), color = ""#fcdf02"",
             aes(x = long, y = lat, size = mass), alpha = .7) +
  geom_point(data = subset(meteorites, year_cat == 3), color = ""#fcd602"",
             aes(x = long, y = lat, size = mass), alpha = .7) +
  geom_point(data = subset(meteorites, year_cat == 4), color = ""#fcc202"",
             aes(x = long, y = lat, size = mass), alpha = .7) +
  geom_point(data = subset(meteorites, year_cat == 5), color = ""#fc9402"",
             aes(x = long, y = lat, size = mass), alpha = .7) +
  geom_point(data = subset(meteorites, year_cat == 6), color = ""#fc7202"",
             aes(x = long, y = lat, size = mass), alpha = .7) +
  scale_size_continuous(name = ""Mass"", range = c(1, 20), labels = comma_format()) +
  theme(legend.position = ""none"") +
  theme(plot.title = element_text(color = ""white"", hjust = 0.5, size = 20,
                              face = ""bold""),
    plot.subtitle = element_text(color = ""white"", hjust = 0.5, size = 15, face = ""italic""),
    plot.caption = element_text(color = ""white"", size = 6),
    plot.background = element_rect(fill = ""#1D1B1C""),
    panel.background = element_rect(fill = ""#1D1B1C"", color = ""#1D1B1C""),
    plot.margin = unit(c(0.25, 0.25, 0.25, 0.25), ""cm"")) +
  labs(title = ""Every recorded meterorite strike on Earth since 860 AD mapped"",
    subtitle = ""Life goal: To see a meteor shower :) "",
    caption = ""Lighter points indicate older strikes and darker points indicate newer strikes\nData: NASA, Code: @srini_meen"") +
  annotate(""text"", x = -170, y = -60 , color = ""#f1f1f1"", hjust = 0,
           fontface = ""italic"", size = 3, family = ""Merriweather"",
           label = ""A meteorite is a solid piece of debris\n from a comet, asteroid, or meteoroid,\n that originates in outer space and \nsurvives its passage through the atmosphere\n to reach the surface of a planet"") 


ggsave(""meteormap.png"", width = 15, height = 8)
","2019-24"
"1021",1180,"https://github.com/meensrinivasan/tidytuesdaysubmissions","meensrinivasan","tidytuesdaysubmissions","Birds/collapsibletree.Rmd","```{r}
library(tidyverse)
library(here)
library(collapsibleTree)
library(r2d3)
```



```{r}
clean_birds <- read_csv(here(""bird_collisions.csv""))

clean_birds2 <- clean_birds %>%
  mutate_if(is.character, as.factor)

str(clean_birds2)
  
```

```{r}
Chicago_birds <- clean_birds2 %>%
  group_by(family, genus, species) %>% 
  summarise(
    n = n()) %>%
  ungroup() 

  
image <- collapsibleTreeSummary(Chicago_birds, 
    hierarchy = c(""family"", ""genus"", ""species""),
    attribute = ""n"",
    nodeSize = ""n"",
    fillFun = colorspace::terrain_hcl,
    collapsed = FALSE
  )

save_d3_html(image, file = ""image.html"", selfcontained = FALSE)
```

","2019-18"
"1022",1181,"https://github.com/meensrinivasan/tidytuesdaysubmissions","meensrinivasan","tidytuesdaysubmissions","house and mortgage.Rmd","---
title: ""House and mortgage data""
output: html_document
---

## Tidy Tuesday: Housing and Mortgage Data

Aim- Plot Texas HPI as compared to average USA HPI over the years

Load libraries
```{r}
library(tidyverse)
```

Load the dataset
```{r}
state_hpi <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-05/state_hpi.csv"")
```

#### Examine and clean the dataset
```{r pressure, echo=FALSE}
head(state_hpi)

# Filtering for states Texas and Newyork and calculating avg HPI per year
tx_hpi <- state_hpi %>%
  filter(state == ""TX"") %>%
  select(-month)%>%
  group_by(year) %>%
  summarise(avg_price_index = mean(price_index),
            us_avg_1 = mean(us_avg)) %>%
  mutate(region = ""TX"")

# Filtering only USA average
us_year <- tx_hpi %>%
  select(year, us_avg_1) %>%
  mutate(region = ""USA"") %>%
  rename(avg_price_index = us_avg_1)

# creating a new dataset without the USA average HPI values
tx_hpi2 <- tx_hpi %>%
  select(-us_avg_1)

# Joining them to form a tidy dataset
tidydf <- union(tx_hpi2, us_year) %>%
  arrange(region, year)

```

#### Plot
##### Plot annotations added
```{r}
ggplot(tidydf, aes(x = year, y = avg_price_index, colour = region)) +
  geom_line(size = 1) +
  scale_colour_manual(name = ""Region"",
                      values = c(""#CC2200"", ""#000066""),
                      labels = c(""Texas"", ""USA"")) +
  labs(title=""Housing Price Index by year"",
       subtitle = ""Texas HPI did not rise steeply during the housing bubble/ economic recession"",
       x = ""Year"",
       y = ""Average Housing Price Index"")+
  theme_bw()+
  theme(plot.title = element_text(size = 15),
        plot.subtitle = element_text(size = 10),
        legend.position = ""none"") +
  geom_label(aes(x = 2007, y = 100, label = ""Dip seen here""), 
             hjust = 0, 
             vjust = 0.5, 
             lineheight = 0.8,
             colour = ""#00001A"", 
             fill = ""white"", 
             label.size = NA, 
             #family=""Helvetica"", 
             size = 4)+
  geom_label(aes(x = 2011, y = 175, label = ""Texas""), 
             hjust = 0, 
             vjust = 0.5, 
             colour = ""#CC2200"", 
             fill = ""white"", 
             label.size = NA, 
             #family=""Helvetica"", 
             size = 4) +
  geom_label(aes(x = 2016, y = 150, label = ""USA""), 
             hjust = 0, 
             vjust = 0.5, 
             colour = ""#000066"", 
             fill = ""white"", 
             label.size = NA, 
             #family=""Helvetica"", 
             size = 4) +
  geom_curve(aes(x = 2008, y = 110, xend = 2006, yend = 120), 
                             colour = ""#00001A"", 
                             size=0.5, 
                             curvature = -0.2,
                             arrow = arrow(length = unit(0.03, ""npc"")))+
  annotate(""rect"", xmin = 2005, xmax = 2010, ymin = 0, ymax = Inf,
        alpha = .2, fill = ""#0D4D00"")

ggsave(""housing.png"", width = 25, height = 15, units = ""cm"")
```

","2019-19"
"1023",1202,"https://github.com/lhehnke/tidytuesday","lhehnke","tidytuesday","meteorite-impacts/meteorite-impacts.R","##-----------------------------------------------------------------------##
##                    #TIDYTUESDAY: METEORITE IMPACTS                    ##
##-----------------------------------------------------------------------##


## R version 3.5.3 (2019-03-11)

## Author: Lisa Hehnke (dataplanes.org | @DataPlanes)


#-------#
# Setup #
#-------#

# Install and load packages using pacman
if (!require(""pacman"")) install.packages(""pacman"")
library(pacman)

p_load(extrafont, gganimate, maps, tidyverse)

# Retrieve data
meteorites <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv"")


#-----------#
# Set theme #
#-----------#

# Theme for map
map_theme <- theme(axis.line = element_blank(), 
                   axis.text.x = element_blank(), 
                   axis.text.y = element_blank(), 
                   axis.ticks = element_blank(), 
                   axis.ticks.length = unit(0, ""pt""),
                   legend.position = ""none"", 
                   panel.background = element_rect(fill = ""#212121""), 
                   panel.border = element_blank(), 
                   panel.grid.major = element_blank(), 
                   panel.grid.minor = element_blank(), 
                   plot.background = element_rect(fill = ""#212121"", colour = NA), 
                   plot.caption = element_text(colour = ""#ffffff"", size = 12), 
                   plot.margin = margin(10, 2, 2, 10),
                   plot.subtitle = element_text(colour = ""#ffffff"", size = 14), 
                   plot.title = element_text(face = ""bold"", colour = ""#ffffff"", size = 18), 
                   text = element_text(family = ""Lato""))


#----------------#
# Data wrangling #
#----------------#

# Add decade and filter data
met_df <- meteorites %>%
  #filter(fall == ""Fell"") %>%
  select(year, long, lat, mass) %>%
  mutate(decade = floor(year / 10) * 10) %>%
  filter(decade >= 1900 & year <= 2010) %>%
  na.omit()


#------------------#
# Create dot frame #
#------------------#

# Generate a data frame with all dots
## Approach by Taras Kaduk (https://taraskaduk.com/2017/11/26/pixel-maps/).
lat <- tibble(lat = seq(-90, 90, by = 1))
long <- tibble(long = seq(-180, 180, by = 1))
dots <- lat %>% 
  merge(long, all = TRUE) %>%
  mutate(country = map.where(""world"", long, lat),
         lakes = map.where(""lakes"", long, lat)) %>% 
  filter(!is.na(country) & is.na(lakes)) %>% 
  select(-lakes)
  

#------------#
# Static map #
#------------#

# Plot static map
## Inspired by Taras Kaduk (https://taraskaduk.com/2017/11/26/pixel-maps/).
ggplot() +
  borders(""world"") +
  geom_point(data = dots, aes(x = long, y = lat), col = ""grey45"", size = 0.7) + 
  geom_point(data = met_df, aes(x = long, y = lat, size = 0.8, colour = ""red"")) +
  geom_point(data = met_df, aes(x = long, y = lat, size = sqrt(mass)), colour = ""red"", alpha = 0.4) +
  labs(title = ""\n#TidyTuesday: Meteorite impacts from 1900-2010"", 
       subtitle = ""Point sizes indicating meteorite mass in grams"", 
      caption = ""dataplanes.org | @DataPlanes \nInspired by @taraskaduk \nData source: NASA \n"", x = NULL, y = NULL) + 
  coord_cartesian(ylim = c(-50, 90)) + map_theme

# Save map
ggsave(""meteorite-impacts/meteorite_map.png"", width = 18, height = 9, units = ""in"", dpi = 100)


#--------------#
# Animated map #
#--------------#

# Plot animated map using gganimate
meteorite_map <- ggplot() +
  borders(""world"", colour = ""#353535"", fill = ""#2b2b2b"") +
  geom_point(data = met_df, aes(x = long, y = lat, size = sqrt(mass)), colour = ""red"", alpha = 0.5) +
  transition_states(met_df$decade, transition_length = 1, state_length = 3, wrap = FALSE) +
  shadow_mark() + enter_fade() + exit_fade() + ease_aes(""quadratic-in-out"") +
  labs(title = ""#TidyTuesday: Meteorite impacts from 1900-{closest_state} by decade"", 
       subtitle = ""Point sizes indicating meteorite mass in grams"", 
       caption = ""dataplanes.org | @DataPlanes \nData source: NASA"", x = NULL, y = NULL) + 
  coord_cartesian(ylim = c(-50, 90)) + map_theme + 
  theme(plot.caption = element_text(size = 16), 
        plot.subtitle = element_text(size = 20), 
        plot.title = element_text(size = 28))

# Save GIF
anim_save(""meteorite-impacts/meteorite_map_animated.gif"", meteorite_map, width = 1800, height = 900)
","2019-24"
"1024",1203,"https://github.com/lhehnke/tidytuesday","lhehnke","tidytuesday","ufo-sightings/ufo-sightings.R","##-----------------------------------------------------------------------##
##                      #TIDYTUESDAY: UFO SIGHTINGS                      ##
##-----------------------------------------------------------------------##


## R version 3.5.3 (2019-03-11)

## Author: Lisa Hehnke (dataplanes.org | @DataPlanes)


#-------#
# Setup #
#-------#

# Install and load packages using pacman
if (!require(""pacman"")) install.packages(""pacman"")
library(pacman)

p_load(emo, extrafont, grid, jpeg, maps, threejs, tidyverse)
## Additional fonts: Exan (https://www.behance.net/gallery/36169711/Exan-3-Free-Font) | Orbitron (https://www.theleagueofmoveabletype.com/orbitron)

# Retrieve data
ufo_df <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv"")


#-------------#
# UFO mappin' #
#-------------#

# Download NASA night lights image (grayscale)
download.file(""https://eoimages.gsfc.nasa.gov/images/imagerecords/144000/144897/BlackMarble_2016_01deg_gray.jpg"", 
              destfile = ""ufo-sightings/BlackMarble_2016_01deg_gray.jpg"", mode = ""wb"")

# Load jpg and render
earth <- readJPEG(""ufo-sightings/BlackMarble_2016_01deg_gray.jpg"", native = TRUE)
earth <- rasterGrob(earth, interpolate = TRUE)

# Plot UFO sightings around the world
ggplot() +
  annotation_custom(earth, xmin = -180, xmax = 180, ymin = -90, ymax = 90) +
  geom_point(data = ufo_df, aes(x = longitude, y = latitude), alpha = 0.8, size = 0.1, colour = ""green"") + # Alien: 1f47d | UFO: 1f6f8
  theme(axis.title = element_blank(), 
      axis.text = element_blank(), 
      axis.ticks.length = unit(0, ""cm""),
      legend.position = ""none"",
      panel.background = element_rect(fill = ""#05050f"", colour = ""#05050f""), 
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(), 
      plot.margin = grid::unit(c(0, 0, 0, 0), ""mm"")) +
  annotate(""text"", x = -160, y = -18, hjust = 0, size = 14,
           label = paste(str_c(""UFO sightings "", emo::ji(""alien""))), color = ""green"", family = ""Exan"", alpha = 0.9) + # Open Sans
  annotate(""text"", x = -160, y = -26, hjust = 0, size = 7, 
           label = paste(str_c(""Data: National UFO Reporting Center"")), color = ""white"", family = ""Orbitron"", alpha = 0.8) +
  annotate(""text"", x = -160, y = -30, hjust = 0, size = 6, 
           label = paste(""@DataPlanes""), color = ""white"", family = ""Orbitron"", alpha = 0.5) +
  coord_equal()

ggsave(""ufo-sightings/UFO_map.png"", width = 36, height = 18, units = ""in"", dpi = 100)


#----------#
# 3D globe #
#----------#

# Plot UFO sightings on 3D globe
globejs(img = ""ufo-sightings/BlackMarble_2016_01deg_gray.jpg"",
        bg = ""black"",
        lat = ufo_df$latitude,
        long = ufo_df$longitude,
        val = 3,
        color = ""#32CD32"",
        pointsize = 0.5,
        atmosphere = TRUE)","2019-26"
"1025",1429,"https://github.com/izzyroselle/Tidy_Tuesday/blob/master/nobel.rmd","izzyroselle","Tidy_Tuesday","nobel.rmd","---
title: ""Nobel""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prep

```{r, results = 'hide'}
library(ggplot2)
library(dplyr)
library(tidyr)
```

##Import data
```{r}
1595
nobel_winner_all_pubs <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winner_all_pubs.csv"")
nobel_winners <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-14/nobel_winners.csv"")
```

##Data Wrangling
```{r}
n <- nobel_winners
np <- nobel_winner_all_pubs
head(np)
ne <- aggregate(pub_year ~ laureate_name, data = np, min)
g <- np[which(np$is_prize_winning_paper == 'YES'),]
g2 <- g[, c(1,2,3, 5),]
nbig <- aggregate(pub_year ~ laureate_name, data = np, max)
b <- left_join(g2, ne, by = 'laureate_name') %>% left_join(., nbig, by = 'laureate_name')
names (b) [4] <- 'prizepub'
names (b) [5] <- 'firstpub'
names (b) [6] <- 'lastpub'
f <- np[, c(2, 11)]
b2 <- left_join(b, f, by = 'laureate_name')
b3 <- b2[which(!duplicated(b2$laureate_id)),]
```

NB: I'm using the np dataset, which means I can only do the Medicine, Chemistry and Physics prizes.
##Graphing

We know Nobel prizes are offset, often by a long time, from the publication year of the winning paper. 
```{r cars}

ggplot(b3, aes(x = prizepub, y = prize_year, color = category)) + geom_point() + coord_cartesian(xlim = c(1880, 2020), ylim = c(1880, 2020)) + geom_abline(slope = 1, intercept = 0) + ggtitle('Delay in Nobel Prizes') + xlab('Publication Year of Winning Paper') + ylab('Year Prize Awarded')





```


##Diagnosing a problem with the data
But look - there's a blue (physics) point below the 45 degree line (which denotes a Nobel Prize awarded the same year as the cited paper was published), which is impossible. Let's investigate that.

```{r}
b3[which(b3$prizepub > 1960 & b3$prize_year < 1920),]

```
Because I know that's about where the outlying point is.

Then to generalise and make sure there aren't other impossible values (with regard to this error, not to other errors) there: 
```{r}
b3[which(b3$prizepub > b3$prize_year),]
```
This shows that the laureate was Wien, who won his prize in 1911. Now I want to see if it's a problem with the source data or some error I introduced in my processing, by looking at this entry in the original dataframe: 
```{r}
np[which(np$laureate_id == 10189),]
```

This shows that the problem existed in the original data, which says that Wien won his Nobel prize in 1911 (true) for a paper published in 1983 (...less so.)

So now I know there's something wrong with the data, so I'll be excluding outliers in future but otherwise continuing since this is for fun and learning.

Now I want to look at how far through their careers laureates published the paper that would win them the Nobel prize. Firstly, looking at years since their first paper: 

```{r}
ggplot(b3[which(b3$prizepub - b3$firstpub < 50),], aes(x = category, y = prizepub - firstpub, fill = category)) + geom_boxplot() + ylab('Years Between First Publication and Winning Publication') + xlab('Category') + labs(subtitle = 'In physics, Nobel laureates hit their stride soon after first publication.') + ggtitle('Incubation Period of the Lesser Spotted Nobel Laureate') + coord_flip() + theme(legend.position = 'none') + theme_classic()
```

yadyada. Now looking at it percentage-wise:
```{r}
ggplot(b3[which(b3$prizepub - b3$firstpub < 50),], aes(x = category, y = (prizepub - firstpub)/(lastpub - firstpub), fill = category)) + geom_boxplot() + ylab('Winning paper publication date as fraction of time from first to last paper') + xlab('Category') + labs(subtitle = 'In physics, Nobel laureates hit their stride soon after first publication.') + ggtitle(""How far through a laureate's career is their winning paper published?"") + coord_flip()  + theme_classic() + theme(legend.position = 'none')
```

We can see that physics laureates publish their winning paper soonest after their first paper, followed by biologists, then chemists. But is that because their winning paper is early or their first paper is late? Let's check using their age at time of publication of first paper. 

To do that, let's get their year of birth by extracting it from their birth date:
```{r}
n2 <- separate(n, birth_date, c('birthyear', NA, NA), sep = ""-"") 
```
Now the problem is, how to join the laureate dataset with the papers dataset, when neither the names nor the IDs match? Perhaps for individual prizes I could use a combination of year prize awarded and category, but I'd like something better. Spoiler alert: Couldn't find a way, unfortunately, although I did check whether there were any major differences in the raw year of first publication across category and didn't see any. Let me know if you have a way of connecting them! 
```{r}
ggplot(b3, aes(x = category, y = prizepub)) + geom_boxplot()
```
Okay, now let's lay out the year of their first publication, winning publication, last publication and prize award together. I want to use geom_point() and show the different types as different colours, which means I'll need to first put this data into long format using gather().
```{r}
head(b3)
b4 <- gather(b3, Type, Year, prize_year:lastpub)
head(b4)
```

What I want here is to have each laureate's name on a line on the y axis, as if I was doing a lollipop plot or joyplot. Unfortunately, there are like 1000 laureates, so I'm going to just pick some, namely the Medicine & Physiology laureates from 2000 to 2019. This is arbitrary; I just played around to see what fit nicely onto the graph.

The basic working version of this is here. Note the filtering for outliers - the 50 year mark is fairly arbitrary and may get rid of some legitimate data, but it does exclude obviously wrong ones.
```{r}
ggplot(b4[which(b3$prize_year %in% c(2000:2019) & b4$category == 'medicine' & b3$prizepub - b3$firstpub < 50),], aes(x = Year, y = laureate_name, color = Type, size = 2)) + geom_point()
```

However, I wanted to make some changes for cosmetic and information purposes, particularly ordering the names by year of prize. Unfortunately, having converted my data to long format to color code the types of publication meant that I no longer had prize_year available to use to order the name factors, so I made b5, which has prize_year added to it. 
```{r}
priz <- b3[, c(1,3)]
b5 <- left_join(b4, priz, by = 'laureate_id')
```
This means I can make:
```{r}
ggplot(b5[which(b3$prize_year %in% c(2000:2019) & b5$category == 'medicine' & b3$prizepub - b3$firstpub < 50),], aes(x = Year, y = reorder(laureate_name, prize_year), color = Type)) + geom_point() 
```


And with cosmetic alterations (e.g. decreasing opacity to 0.8 because some of the points overlap) and labelling:
```{r}
ggplot(b5[which(b3$prize_year %in% c(2000:2019) & b5$category == 'medicine' & b3$prizepub - b3$firstpub < 50),], aes(x = Year, y = reorder(laureate_name, prize_year), color = Type, size = 2, alpha = .8)) + geom_point() + guides(size = FALSE, alpha = FALSE) + ylab('Laureate name') + ggtitle('Milestones in Nobel Laureate Publications')
```




","2019-20"
"1026",1453,"https://github.com/will-r-chase/tidy_tuesday","will-r-chase","tidy_tuesday","trains.R","library(tidyverse)

trains_raw <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-26/full_trains.csv"")

","2019-09"
"1027",1464,"http://github.com/emily-ho/tidytuesday","emily-ho","tidytuesday","anime/anime.R","require(tidyverse)
require(tidytext)
require(ggthemes)

# April 23, 2019
# tidy tuesday dataset

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

# sentiment analysis
# 'sentiments' dataset taken from tidytext
# afinn lexicon :continuous 
afinn <- sentiments %>% 
           dplyr::filter(lexicon == ""AFINN"") %>% 
           dplyr::select(word, score) 

# nrc lexicon: categorical
nrc <- sentiments %>% 
          dplyr::filter(lexicon == ""nrc"") %>%
          dplyr::select(word, sentiment)

tokens <- tidy_anime %>% 
            tidytext::unnest_tokens(word, synopsis) %>% 
            dplyr::count(genre, word, sort = T)

total_words <- tokens %>%
                dplyr::group_by(genre) %>%
                dplyr::summarize(total = sum(n))

synopsis_words <- tokens %>% 
  dplyr::left_join(., total_words) 

# ti-idf

ti_idf <- synopsis_words %>%
            tidytext::bind_tf_idf(word, genre, n) %>%
            dplyr::arrange(desc(tf_idf)) 

# sentiment analysis
anime_sentiment <- ti_idf %>%
  dplyr::left_join(., afinn, by = ""word"") %>% 
  dplyr::left_join(., nrc, by = ""word"") 



ggplot2::theme_set(ggthemes::theme_economist())

afinn_barplot <- anime_sentiment %>%
                    dplyr::filter(!is.na(score)) %>%
                    dplyr::select(genre, word, tf_idf, score) %>%
                    dplyr::group_by(genre) %>%
                    dplyr::summarize(mean_sentiment = mean(score)) %>% 
                    dplyr::mutate(genre = reorder(genre, mean_sentiment)) %>%
                    ggplot2::ggplot(ggplot2::aes(x=genre, 
                                                 y = mean_sentiment,
                                                 fill = mean_sentiment)) +
                    ggplot2::geom_col() +
                    ggplot2::coord_flip() + 
                    ggplot2::labs(title = ""Average Sentiment Rating by Genre using AFINN lexicon"",
                                  x = """",
                                  y = ""Sentiment (negative to positive)"",
                                  caption = ""figure by @EmilyHHo"") +
                    ggplot2::scale_fill_gradient(low = ""black"", high = ""red"")
  
# using nrc sentiment dictionary
nrc_biplot <- anime_sentiment %>% 
                dplyr::select(genre, sentiment) %>% 
                na.omit() %>%
                table(.) %>%
                FactoMineR::CA(., graph = F) %>%
                factoextra::fviz_ca_biplot(., repel = T, labelsize = 5,
                                           title = ""Correspondence Analysis of Genre and Sentiment using NRC lexicon"")

gridExtra::grid.arrange(afinn_barplot, nrc_biplot, ncol = 2)

 


","2019-17"
"1028",1466,"http://github.com/emily-ho/tidytuesday","emily-ho","tidytuesday","seattlebike/seattlebike.r","require(magrittr)
require(ggplot2)
require(gganimate)
require(transformr)

bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")

# formatting time and date

bike_traffic %<>% 
         dplyr::mutate(date_time = lubridate::mdy_hms(date),
                      # date = format(date_time, '%d/%m/%Y'),
                      # time = format(date_time, '%H:%M:%S'),
                       hour = lubridate::hour(date_time))

# summarizing mean traffic by hour 
mean_traffic <- bike_traffic %>%
  dplyr::group_by(hour, crossing, direction) %>%
  dplyr::summarize(bike_count =mean(bike_count, na.rm=T)) #%>% head()



# rush hour 

rushhr <- data.frame(rush = c(""AM Rush (6 - 9AM)"", ""PM Rush (4 - 7PM)""),
                     lb = c(6, 16),
                     ub = c(9, 19))
# static plot 
ggplot2::ggplot(mean_traffic, 
             ggplot2::aes(x=hour, y=bike_count, size = bike_count, 
                    group = crossing, color = crossing)
     ) +
  ggplot2::geom_point(alpha = 0.8, show.legend = F) + geom_line(size = 1.25) + 
  ggplot2::facet_wrap(~direction) +
  ggplot2::theme_classic() +
  ggplot2::geom_rect(data = rushhr, 
                     ggplot2::aes(xmin = lb, xmax = ub, 
                                  ymin = -Inf, ymax = Inf,
                                  fill=rush
                     ),
                     alpha = 0.25,  
                     inherit.aes = F) +
  ggplot2::ylab(""Bike Count"") +
  ggplot2::xlab(""Hour of Day"") +
  ggplot2::theme(legend.position =""bottom"", 
                 legend.title = ggplot2::element_blank(),
                 legend.text = ggplot2::element_text(size = 16),
                 axis.text = ggplot2::element_text(size = 16),
                 axis.title = ggplot2::element_text(size = 20))


animated_traffic <- ggplot2::ggplot(mean_traffic, 
                              ggplot2::aes(x=hour, y=bike_count, 
                              group = crossing, color = crossing)
     ) +
  ggplot2::geom_point(alpha = 0.8, show.legend = F) + 
  ggplot2::geom_line(size = 1.25, show.legend = F) + 
  # geom_segment(aes(xend=25, yend = bike_count), linetype = 2, colour = 'grey') + 
  

  ggplot2::facet_wrap(~direction) +
  ggplot2::theme_classic()   +
  ggplot2::geom_text(aes(x=hour, y = bike_count + 8, label = crossing), show.legend = F) + 
  ggplot2::geom_rect(data = rushhr, 
                     ggplot2::aes(xmin = lb, xmax = ub, 
                                  ymin = -Inf, ymax = Inf,
                                  fill=rush
                     ),
                     alpha = 0.25,  
                     inherit.aes = F) +
    ggplot2::ylab(""Bike Count"") +
    ggplot2::xlab(""Hour of Day"") +
    ggplot2::theme(legend.position =""top"", 
                 legend.title = ggplot2::element_blank(),
                 legend.text = ggplot2::element_text(size = 16),
                 axis.text = ggplot2::element_text(size = 16),
                 axis.title = ggplot2::element_text(size = 20)) +

  ggplot2::labs(title = 'Hour: {frame_along}') + 
#  transition_time(date_time) #+
  gganimate::transition_reveal(hour) 


gganimate::animate(animated_traffic, fps = 6)
  

gganimate::anim_save(""animated_traffic.gif"", animated_traffic)","2019-14"
"1029",1467,"http://github.com/emily-ho/tidytuesday","emily-ho","tidytuesday","tennis/040919_tennis.r","
require(magrittr)

player_dob <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/player_dob.csv"")
grand_slams <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slams.csv"")
grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

age_slams_comb <- dplyr::left_join(grand_slams, player_dob, by = c(""name"")) %>% 
  dplyr::mutate(age = tournament_date - date_of_birth) %>% # needs to be datetime
  dplyr::group_by(name, age, gender) %>% 
  dplyr::summarize(counts = n()) %>% 
  dplyr::group_by(name) %>% 
  dplyr::mutate(total_wins = cumsum(counts)) %>% 
  dplyr::arrange(desc(total_wins))
  

# test plot
age_slams_comb %>% 
  ggplot2::ggplot(ggplot2::aes(x = age, 
  	y = total_wins, group = name)) +
  ggplot2::geom_point() +
  ggplot2::geom_step() +
  ggplot2::facet_wrap(~gender) +
  ggplot2::theme_bw()


tmp <- dplyr::left_join(grand_slams, player_dob, by = c(""name"")) %>% 
         dplyr::mutate(age = tournament_date - date_of_birth)

df <- grand_slam_timeline %>% 
	dplyr::rename(name = ""player"") %>% 
	dplyr::left_join(., age_slams_comb, by = c('name', 'year'))

##############

dplyr::glimpse(df)

dat <- grand_slam_timeline %>% 
			dplyr::filter(outcome == ""Won"") %>% 
			dplyr::arrange(year) %>% 
			dplyr::group_by(player) %>% 
			dplyr::mutate(count = seq(n())) 

dat <- grand_slam_timeline %>%
				dplyr::filter(outcome == ""Won"") %>%
				dplyr::mutate(outcome == ifelse(outcome == ""Won"", 1,0)) 

theme_bluewhite <- function (base_size = 11, base_family = """") {
    ggplot2::theme_classic() + 
        ggplot2::theme(
            panel.grid.major  = ggplot2::element_line(color = ""white""),
            panel.background = ggplot2::element_rect(fill = ""lightblue""),
          #  panel.border = ggplot2::element_rect(color = ""lightblue"", fill = NA),
            axis.line = ggplot2::element_line(color = ""lightblue""),
            axis.ticks = ggplot2::element_line(color = ""lightblue""),
            axis.text = ggplot2::element_text(color = ""steelblue"")
        )
}




dat %>% 
    ggplot2::ggplot(., ggplot2::aes(x=player, y = count, col = player,
                                    group = player)) + 
    ggplot2::geom_point() + 
    ggplot2::geom_line() + 
    ggplot2::facet_wrap(~tournament) +
    theme_bluewhite() +
    ggplot2::theme(legend.position = ""none"")

    
dat %>% 
    ggplot2::ggplot(., ggplot2::aes(x=year, y = count, col = player,
                                 group = player)) + 
    ggplot2::geom_point() + 
    ggplot2::geom_line() + 
    ggplot2::facet_wrap(~tournament) +
    ggplot2::theme_bw() +
    ggplot2::theme(legend.position = ""none"") +
  #  ggplot2::geom_text() +
    ggplot2::labs(title = 'Hour: {frame_along}') + 
    #  transition_time(date_time) #+
    gganimate::transition_reveal(count)


gganimate::animate(anim, fps = 6)
  
","2019-15"
"1030",1468,"https://github.com/npaterno/TidyTuesdayProjects/blob/master/SeattleBikes.Rmd","npaterno","TidyTuesdayProjects","SeattleBikes.Rmd","---
title: ""R Notebook""
output: html_notebook
---

```{r}
library(tidyverse)
```
#Load the data from the TidyTuesday Github repository
```{r}
bike_traffic <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-02/bike_traffic.csv"")
```
#Filter and clean the data to only include month, day and average riders per day.
```{r}
bike_traffic_clean<-bike_traffic%>%
  select(-c(ped_count,crossing,direction))%>%
  extract(date, into = c(""Mo"",""Day"",""Yr""),regex=""([0-9]{2})/([0-9]{2})/([0-9]{4})"")%>%
  filter(!Yr %in% c(""2013"",""2019""))%>%
  group_by(Mo,Day,Yr)%>%
  summarize(count=sum(bike_count,na.rm=TRUE))%>%
  group_by(Mo,Day)%>%
  summarize(avg_bike=mean(count))
```
#Split the data into four data sets by season.
```{r}
Winter<-bike_traffic_clean%>%
  filter(Mo %in% c(""12"",""01"",""02""))

Spring<-bike_traffic_clean%>%
 filter(Mo %in% c(""03"",""04"",""05""))

Summer<-bike_traffic_clean%>%
  filter(Mo %in% c(""06"",""07"",""08""))

Fall<-bike_traffic_clean%>%
  filter(Mo %in% c(""09"",""10"",""11""))
```
#Plot histograms for each season overlayed into one plot.
```{r}
ggplot(mapping=aes(x=avg_bike))+
         geom_histogram(data=Winter, color=""purple"",fill=""purple"",alpha=0.2,binwidth=250,boundary=0.4,na.rm=TRUE)+
         geom_histogram(data=Spring, color=""green"",fill=""green"",alpha=0.2,binwidth=250,boundary=0.4,na.rm=TRUE)+
         geom_histogram(data=Summer, color=""blue"",fill=""blue"",alpha=0.2,binwidth=250,boundary=0.4,na.rm=TRUE)+
         geom_histogram(data=Fall, color=""red"",fill=""red"",alpha=0.2,binwidth=250,boundary=0.4,na.rm=TRUE)+
  xlim(500,6000)+
         labs(title=""Number of Bike Riders in Seattle per Day"", x=""Bike Riders per Day"", y=""Number of Days"")+
         theme_bw()
```
#Add season variable and join data back into one data set.
```{r}
Winter2<-Winter%>%
  mutate(Season=""Winter"")

Spring2<-Spring%>%
  mutate(Season=""Spring"")

Summer2<-Summer%>%
  mutate(Season=""Summer"")

Fall2<-Fall%>%
  mutate(Season=""Fall"")

Seasons_data<-Winter2%>%
  full_join(Spring2)%>%
  full_join(Summer2)%>%
  full_join(Fall2)
```
#Plot individual histograms via facet wrap.
```{r}
ggplot(Seasons_data%>%group_by(Season),mapping=aes(x=avg_bike,color=Season,fill=Season))+
  geom_histogram(alpha=0.3,binwidth=250,boundary=0.4,na.rm=TRUE)+
        facet_wrap(~Season)+
         xlim(0,6000)+
         labs(title=""Number of Bike Riders in Seattle per Day"", x=""Bike Riders per Day"", y=""Number of Days"")+
         theme_bw()
```


","2019-14"
"1031",1470,"https://github.com/npaterno/TidyTuesdayProjects","npaterno","TidyTuesdayProjects","Anime.R","library(tidyverse)

tidy_anime <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-23/tidy_anime.csv"")

toei_tv <- tidy_anime %>% 
  filter(studio==""Toei Animation"" & type == ""TV"") %>% 
  group_by(name,episodes, rank) %>% 
  summarize(score=mean(score)) %>% 
  mutate(highlight = case_when(name==""Dragon Ball Z""~""highlight"",
                               TRUE ~ ""normal""))

my_colors <- c(""highlight""=""dark red"",""normal""=""blue"")


ggplot(toei_tv)+
  geom_point(mapping=aes(episodes, score,size=rank, color = highlight) ,alpha=0.3)+
  scale_color_manual(""Status"", values = my_colors,guide=FALSE) +
  geom_text(data = subset(toei_tv,name==""Dragon Ball Z""),
                           aes(x = episodes, y = score, label = name),hjust=1,vjust=-0.5) +
  theme_bw()+
  labs(title=""Average Rating for Toei Studios"",
      subtitle = ""TV Shows"",
      size= ""Rank"",
       x=""Number of Episodes"",
       y=""Average Rating"",
       caption = ""Source: myanimelist.net | Graph: @Mathl3t3"")

ggplot()+
  geom_point(toei_tv,mapping=aes(rank, score, color=highlight), alpha=0.3)+
  scale_color_manual(""Status"", values = my_colors,guide=FALSE) +
  geom_text(data = subset(toei_tv,name==""Dragon Ball Z""),
            aes(x = episodes, y = score, label = name),hjust=-0.2) +
  theme_bw()+  labs(title=""Average Rating for Toei Studios"",
       subtitle = ""TV Shows"",
       x=""Rank"",
       y=""Average Rating"",
       caption = ""Source: myanimelist.net | Graph: @Mathl3t3"")
","2019-17"
"1032",1472,"https://github.com/npaterno/TidyTuesdayProjects","npaterno","TidyTuesdayProjects","HorrorMovies.R","# Load Libraries
library(tidyverse)
library(extrafont)
library(ggthemes)

# Set up fonts
font_import()
loadfonts(device = ""win"")

# Read Data
raw_data <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv"")

# Tidy runtime data
horror_movies<-raw_data%>%
  separate(movie_run_time, 
           into = c(""movie_length"", ""drop""), 
           sep = "" "", 
           convert = TRUE)%>%
  select(-drop)

# Plot heat map of length v rating
p<-ggplot(horror_movies, aes(movie_length, review_rating))+
  geom_hex(na.rm = TRUE)+
  scale_fill_gradient2_tableau()+
  theme_economist()+
  theme(text = element_text(family = ""Rockwell""),
    plot.title = element_text(size = 15))+
  labs(title = ""Movie Length V Rating"",
       subtitle = ""Horror Movies"",
       x = ""Movie Length (min)"",
       y = ""Review Rating"",
       aesthetic = ""Frequency"",
       caption = ""Source: imdb.com | Graph: @Mathl3t3"")

ggsave(""HorrorHeatmap.jpg"")
","2019-43"
"1033",1473,"https://github.com/npaterno/TidyTuesdayProjects","npaterno","TidyTuesdayProjects","SeattlePets.Rmd","---
title: ""R Notebook""
output: html_notebook
---

```{r}
library(tidyverse)
```
```{r}
seattle_pets <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-03-26/seattle_pets.csv"")
```
Renaming Variable
```{r}
seattle_pets<-seattle_pets%>% 
  rename(PetName='animals_name',PBreed='primary_breed')
```
Sort By Pet Species
```{r}
dogs<-seattle_pets%>%
  filter(species==""Dog"")%>%
  select(c(PetName,species,PBreed))

cats<-seattle_pets%>%
  filter(species==""Cat"")%>%
  select(c(PetName,species,PBreed))

#Ended up not using the other data yet. 
other<-seattle_pets%>%
  anti_join(dogs)%>%
  anti_join(cats)
```
Count and Filter for Top Pet Names 
```{r}
dogs_counted<-dogs%>%
  group_by(PetName)%>%
  summarize(count=n())%>%
  top_n(n=10,wt=count)

dogs_counted$PetName <- factor(dogs_counted$PetName) %>%
  fct_reorder(dogs_counted$count)

cats_counted<-cats%>%
  filter(!is.na(PetName))%>%
  group_by(PetName)%>%
  summarize(count=n())%>%
  top_n(n=10,wt=count)

cats_counted$PetName <- factor(cats_counted$PetName) %>%
  fct_reorder(cats_counted$count)

all_counted<-seattle_pets%>%
  filter(!is.na(PetName))%>%
  group_by(PetName)%>%
  summarize(count=n())%>%
  top_n(n=10,wt=count)

all_counted$PetName <- factor(all_counted$PetName) %>%
  fct_reorder(all_counted$count)
```
Plot Top Names
```{r}
dog_names<-ggplot()+
  geom_col(data=dogs_counted,mapping=aes(x=PetName,y=count), fill=""navy blue"")+
  labs(title=""Top Dog Names in Seattle"",x=""Name"",y=""Total"")+
  coord_flip()+
  theme_bw()
png(""~/R/Tidy Tuesday/SeattlePetNames/dog_names.png"",
    width = 200, height = 150, res = 500, units = 'mm')
print(dog_names)
```
```{r}
cat_names<-ggplot()+
  geom_col(data=cats_counted,mapping=aes(x=PetName,y=count), fill=""dark green"")+
  labs(title=""Top Cat Names in Seattle"",x=""Name"",y=""Total"")+
  coord_flip()+
  theme_bw()
png(""~/R/Tidy Tuesday/SeattlePetNames/cat_names.png"",
    width = 200, height = 150, res = 500, units = 'mm')
print(cat_names)
```
```{r}
all_names<-ggplot()+
  geom_col(data=all_counted,mapping=aes(x=PetName,y=count),fill=""dark red)+
  labs(title=""Top Pet Names in Seattle"",x=""Name"",y=""Total"")+
  coord_flip()+
  theme_bw()
png(""~/R/Tidy Tuesday/SeattlePetNames/all_names.png"",
    width = 200, height = 150, res = 500, units = 'mm')
print(all_names)
```
","2019-14"
"1034",1475,"https://github.com/npaterno/TidyTuesdayProjects","npaterno","TidyTuesdayProjects","Tennis.R","#load libraries
library(tidyverse)
library(gganimate)

#load data
grand_slam_timeline <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-04-09/grand_slam_timeline.csv"")

#Clean data to analyze number of tournaments played per player by year
gst_clean <- grand_slam_timeline %>%
  mutate(player=str_replace_all(player,""[[:punct:]+]"","""")) %>%
  #Above line: some players were entered with a / or // before there name.
  #This replaces those with a space.
  mutate(player=str_remove(player,""^\\s"")) %>%
  #Above line: removes the space added above.
  mutate(player=iconv(player, from = 'UTF-8', to = 'ASCII//TRANSLIT')) %>%
  #Above line: converts all letters to Latin Alphabet
  filter(outcome!=""Absent"") %>%
  select(-tournament) %>%
  group_by(player,year,gender) %>%
  summarize(n=n())

#select the top 20 appearing players
top_players_all <-  gst_clean %>%
  group_by(player) %>%
  summarize(total=sum(n)) %>%
  ungroup() %>%
  top_n(20,total)

#select the top 20 players and calculate cumulative appearances by year
top_appearing <- gst_clean %>%
  filter(player %in% top_players_all$player) %>%
  group_by(player) %>%
  mutate(csum= cumsum(n))

#create base plot for animation
base_plot <- ggplot(top_appearing,aes(player,csum,fill=gender))+
  geom_col()+
  coord_flip()+
  theme_bw()

#create animation
base_plot+geom_text(aes(label = csum, hjust = -1))+
  transition_reveal(year,keep_last=TRUE)+
  labs(title=""Number of Grand Slam Appearances: Top 20* Players"", subtitle=""Year: {round(frame_along,0)}"",y=""Number of Appearances"",x="""",caption=""*includes ties| Source: Wikipedia| Graphic: @Mathl3t3"")

#save animation
anim_save(""top.gif"")
","2019-15"
"1035",1480,"https://github.com/npaterno/TidyTuesdayProjects","npaterno","TidyTuesdayProjects","fueleconomy.R","# Load libraries
library(tidyverse)
library(gganimate)
library(viridis)
library(ggdark)

altrenderer <- gifski_renderer(loop=FALSE)

# Load data
big_epa_cars <- readr::read_csv(""https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-15/big_epa_cars.csv"")

# Filter variables to be used in analysis
make_class_data<-big_epa_cars%>%
  select(c(comb08, city08, highway08, 
           fuelCost08, fuelType, fuelType1, 
           make, model, VClass, year, cylinders))
  
# Filter Major US automakers by brand
american<-make_class_data%>%
  mutate(brand = case_when(
    str_detect(make, paste(c(""Ford"", ""Lincoln"", ""Mercury""), collapse = '|')) ~ ""Ford Motor Company"",
    str_detect(make, paste(c(""Chrysler"", ""Dodge"", ""Jeep"", ""Ram"",""Plymouth"",""Eagle""), collapse = ""|"")) ~ ""Chrysler Group"",
    str_detect(make, paste(c(""General Motors"",""GMC"",""Cheverolet"",""Hummer"", ""Buick"", ""Pontiac"",""Saturn"", ""Oldsmobile""),collapse = ""|""))~""General Motors""))

################### Need to figure out why I can't just pipe this after the mutation above
american2<-american%>%
  filter(!is.na(brand))%>%
  group_by(brand, year, cylinders)%>%
  summarize(mean_city = mean(city08),
            mean_highway = mean(highway08),
            mean_fuel = mean(fuelCost08))

# Calculate number of years in data set
n_years <-length(unique(american2$year))

# Creat baseplot for animation
p<-ggplot(american2, 
       aes(x = mean_city, 
           y = mean_highway, 
           color = brand, 
           size = cylinders))+
  geom_point(alpha = 0.8, 
             na.rm = TRUE)+
  scale_x_continuous(limits = c(0,60))+
  scale_y_continuous(limits = c(0,60))+
  scale_color_viridis_d()+
  dark_theme_minimal()+
  theme(panel.grid.major = element_line(""Red"", 
                                        size = 0.1),
        panel.grid.minor = element_line(""Red"",
                                        size = 0.1),
        plot.title = element_text(color = ""Green1""),
        plot.subtitle = element_text(color = ""Green1""),
        plot.caption = element_text(color = ""Green1""),
        axis.title.x = element_text(color = ""Green1""),
        axis.title.y = element_text(color = ""Green1""),
        axis.text = element_text(color = ""Red""),
        legend.text = element_text(color = ""Green1""),
        legend.title = element_text(color = ""Green1""))
  

# Create animated plot
p_animate<-p+
  transition_states(year, transition_length = 3, state_length = 9)+
  ease_aes('linear')+
  labs(title = ""Fuel Efficiency: City v. Highway"", 
       subtitle = ""Year: {closest_state}"",
       x = ""City (mpg)"",
       y = ""Highway (mpg)"",
       color = ""Auto Group"",
       size = ""Cylinders"",
       caption = ""Source: fueleconomy.gov | Graph: @mathl3t3"")+ 
  view_follow(fixed_x=TRUE, fixed_y=TRUE)


# Animate plot
p_gif<-animate(p_animate,
               renderer = altrenderer,
               nframes = n_years*10,
               fps=10, 
               width = 800, 
               height = 500,
               rewind = FALSE)

# Save animation
anim_save(
  animation = p_gif,
  filename = here::here(""brandfuel.gif"")
)
","2019-42"
"1036",1622,"https://github.com/douglaszickuhr/General-R-Code/blob/master/tidytuesday/french-trains.Rmd","douglaszickuhr","General-R-Code","tidytuesday/french-trains.Rmd","---
title: ""Untitled""
author: ""Douglas Zickuhr""
date: ""27 February 2019""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(forcats)
library(ggridges)
```


```{r}
small_trains <- readr::read_csv(""https://github.com/rfordatascience/tidytuesday/raw/master/data/2019/2019-02-26/small_trains.csv"") 
```


```{r}
small_trains %>% 
  group_by(service,year,month,departure_station,arrival_station) %>% 
  summarise_at(vars(journey_time_avg,total_num_trips,avg_delay_all_arriving,avg_delay_all_departing),mean) %>% 
  mutate(avg_delay = avg_delay_all_arriving + avg_delay_all_departing) %>%
  filter(avg_delay > -5,
         avg_delay <= 20) %>%
  ungroup() %>%
  mutate(month = lubridate::month(month,
                                  label = TRUE),
         month = forcats::fct_rev(month)) %>%
  ggplot() +
  geom_density_ridges_gradient(aes(x = avg_delay,
                                   y = month,
                                   fill = ..x..),
                               scale = 2,
                               rel_min_height = 0) +
  scale_fill_viridis_c(direction = -1,
                       option = ""plasma"") + 
  labs(title = ""Average Delay on French trains"",
       x = ""Average Delay (min)"",
       y = NULL,
       fill = ""Average Delay (min)"") + 
  theme_ridges() + 
  facet_wrap(~year)
    
```

","2019-09"
"1037",1654,"https://github.com/pedrow28/tidytuesday","pedrow28","tidytuesday","Baltimore Bridges/Baltimore Bridges.Rmd","---
title: ""Tidy Tuesdat - Baltimore Bridges""
author: ""Pedro William""
date: ""27 de novembro de 2018""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggthemes)
library(plotly)

bridges <- read_csv(""Baltimore Bridges.txt"") #Colocar URL



```



###Conditions of bridges across Maryland

```{r}

bridges$county <- str_replace(bridges$county, ""Baltimore city"", ""Baltimore City"")

condition_n <- bridges %>%
  mutate(bridge_condition = factor(bridge_condition, levels = c(""Good"", ""Fair"", ""Poor"")),
         county = factor(county)) %>% 
  group_by(county, bridge_condition) %>% 
  summarise(n = n())

condition_n$county <- fct_reorder(condition_n$county, condition_n$n)



 
  ggplot(condition_n, aes(x = county, y = n, fill = bridge_condition)) +
    geom_col() +
    coord_flip() +
    geom_label(aes(label = n), show.legend = FALSE, position = position_stack(0.9)) +
    scale_fill_manual(name = ""Bridge condition"", values = c(""#71BBD0"", ""#ABD5E1"", ""#CCCCCC"")) +
    labs(x = """",
         y = """",
         title = ""Condition of the bridges by county"") +
    theme_economist() +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.line.x = element_blank(),
          legend.position = ""bottom"")
```



###Owners 
```{r}

bridges$owner <- as.factor(bridges$owner)


bridges_lump <- bridges %>% mutate(owner = fct_lump(bridges$owner, 4)) %>% 
                            filter(!is.na(owner))
  

```

```{r}

bridges_lump %>% group_by(owner, bridge_condition) %>%
  summarise(n_bridges = n()) %>% 
  ggplot(aes(x = owner, y = n_bridges, fill = bridge_condition)) +
    geom_col() +
    coord_flip() +
    theme_bw()


```



```{r}
ggplot() +
  geom_polygon(data = maryland, aes(x = long, y = lat, group = group), fill = ""white"", col = ""black"") +
  geom_point(data = bridges_lump, (aes(x = long, y = lat, col = owner)), alpha = 0.2) +
  coord_map() +
  labs(title = ""Distribution of bridges-owners across Maryland"") +
  scale_color_discrete(name = ""Owners"") +
  guides(colour = guide_legend(override.aes = list(alpha = 1))) +
  theme_void()

```

### Mean traffic evolution

```{r}
bridges %>% group_by(yr_built) %>% 
  summarise(avg_traffic = mean(avg_daily_traffic)) %>% 
  ggplot(aes(x = yr_built, y = avg_traffic)) +
    geom_line()
```

","2018-35"
"1038",1766,"https://github.com/aammd/tidytuesday/blob/master/mortality.R","aammd","tidytuesday","mortality.R","library(tidyverse)
library(readxl)
library(janitor)
library(broom)
library(ggridges)

global_mortality <- read_xlsx(""data/global_mortality.xlsx"")

tidy_mortality <- global_mortality %>% 
  clean_names %>% 
  gather(""cause"", ""percent_mortality"", -country, -country_code, -year) %>% 
  # we don't need ""percent"" all the time
  mutate(cause = cause %>% str_replace(""_percent"", """"))

# how does mortality change over time? 
safe_mortality_models <- tidy_mortality %>% 
  group_by(country, country_code, cause) %>% 
  nest %>% 
  mutate(change_model = map(data, ~ safely(lm)(log(percent_mortality) ~ year, data = .)))

tidy_mortality_models <- safe_mortality_models %>% 
  mutate(model_result = map(change_model, ""result""),
         model_output = map(model_result, tidy)) %>% 
  unnest(model_output)

tidy_mortality_models %>% 
  filter(term == ""year"") %>% 
  # how is that different among countries?
  group_by(cause) %>% 
  mutate(sd_cause = sd(estimate, na.rm = TRUE),
         med_cause = median(estimate, na.rm = TRUE)) %>% 
  ungroup %>% 
  mutate(cause = fct_reorder2(cause, med_cause, sd_cause, .desc = TRUE)) %>% 
  ggplot(aes(x = estimate, y = cause, fill = sd_cause)) + 
  geom_density_ridges() + scale_fill_viridis_c() + geom_vline(xintercept = 0) +
  labs(x = ""Change with time"")
","2018-03"
